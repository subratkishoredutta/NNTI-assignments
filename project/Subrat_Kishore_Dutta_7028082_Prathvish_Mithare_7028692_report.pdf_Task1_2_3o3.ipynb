{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0d7f6a8a",
   "metadata": {
    "id": "454e0124"
   },
   "source": [
    "# Speaker-Independent Spoken Digit Recognition (xSDR)\n",
    "\n",
    "\n",
    "One of the successful stories of deep neural networks is the proliferation of commercial of automatic speech recognition (ASR) systems. This project aims to explore one application of ML-powered ASR to the problem of spoken digit recognition (SDR). Since digits are widely used as unique identifiers for bank information, social security numbers, post codes, etc, SDR systems can be an efficient alternative to fully-fledged ASR systems since the domain is more predictable than other applications of ASR. \n",
    "\n",
    "In this project, we focus on developing a SDR system in a speaker-independent setting. That is, the speakers in the evaluation set are disjoint from the training set speakers. We do so because we expect real-world ASR systems to generalize to different speakers than those we have data for. Moreover, for many languages that are under-resourced, we have have (limited) annotated speech data from a single speaker, but we would still want the system to be deployed to work on any speaker of that language. We tackle the problem of spoken digit recognition as a sequence classification task. Concretely, the inputs are short audio clips of a specific digit (in the range 0-9), then the goal is to build deep neural network models to classify a short audio clip and predict the digit that was spoken."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38659000",
   "metadata": {},
   "source": [
    "# Notes\n",
    "\n",
    "## Code Submission\n",
    "\n",
    "You don't necessarily need to complete the code in this Jupyter Notebook, you are free to use another notebook or a python script file, as you would like. You are expected to submit the code by **22.03.2023**.\n",
    "\n",
    "Your code should be clean and well commented. We also expect that if we decide to run it on our system, it should be straighforward to do so. We recommend creating a ```requirements.txt``` file with the names of all the libraries with their versions. If applicable, please mention the python version in a ```README.md``` file, which should also include instructions on how to run your code.\n",
    "\n",
    "As mentioned for the assignments, always remember to cite the code with the links as comments, if you decide to use it from a public repository.\n",
    "\n",
    "## Report Submission\n",
    "\n",
    "With the code, you are also expected to submit a report with a maximum of 4 pages. You should write your report in LaTeX using this template for ACL 2023 [Overleaf Link](https://www.overleaf.com/latex/templates/acl-2023-proceedings-template/qjdgcrdwcnwp). Use this document to fill in any missing information that are not necessarily covered during your presentation for the sake of time in the presentation. While writing your report, we would highly encourgae you to cite the papers behind each tool / library / function that you might use for your experiments. We have also released an example on how to write equations in LaTeX [here](https://piazza.com/class/l9so16qqvk34hu/post/52).\n",
    "\n",
    "You art also expected to submit this report with your code. You should provide the **.tex, .pdf and all image files** zipped with the same naming convention as it was in your assignment(s).\n",
    "\n",
    "## Presentation\n",
    "\n",
    "During the last week of March 2023, i.e. 27.03 -- 31.03, each team will be presenting their works for 15 minutes. We expect equal contribution from each member in delivery and content of the presentation. So roughly 5 minutes for one person, if you have 3 people in your team. There will be 5 minutes for some Q&A. At-least one person from your team should be present to do an in-person presentation, rest of your team could join remotely, if they are not present.\n",
    "\n",
    "## Important Dates\n",
    "\n",
    " - Code & Report Submission: 22.03.2023 (08.00)\n",
    " - Presentation: 27.03.2023 -- 31.03.2023\n",
    " \n",
    " You'll get a precise date and time for your team's presentation at a later time."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcc3b479",
   "metadata": {},
   "source": [
    "### Grading\n",
    "\n",
    "In this project, your final grades will be determined as follows:\n",
    "\n",
    " - **30%**: &emsp; Completing all the tasks\n",
    " - **30%**: &emsp; Providing scientific-backings for all the methods used\n",
    " - **20%**: &emsp; Quality of the content of the presentation\n",
    " - **20%**: &emsp; Delivery of the presentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "4df9934d",
   "metadata": {
    "executionInfo": {
     "elapsed": 3612,
     "status": "ok",
     "timestamp": 1674212543207,
     "user": {
      "displayName": "Hyoseung Kang",
      "userId": "00233629824676120159"
     },
     "user_tz": -60
    },
    "id": "020b704f"
   },
   "outputs": [],
   "source": [
    "#%matplotlib inline\n",
    "import numpy as np\n",
    "import scipy, matplotlib.pyplot as plt, IPython.display as ipd\n",
    "import librosa, librosa.display\n",
    "import torch\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn  import preprocessing\n",
    "\n",
    "\n",
    "from collections import defaultdict, Counter\n",
    "\n",
    "# add this to ignore warnings from Librosa\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from tqdm import tqdm\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a9f8672b",
   "metadata": {
    "executionInfo": {
     "elapsed": 20,
     "status": "ok",
     "timestamp": 1674212543209,
     "user": {
      "displayName": "Hyoseung Kang",
      "userId": "00233629824676120159"
     },
     "user_tz": -60
    },
    "id": "2b2719f5"
   },
   "outputs": [],
   "source": [
    "# for linear models \n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.manifold import TSNE as tsne"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "74207f4a",
   "metadata": {
    "executionInfo": {
     "elapsed": 18,
     "status": "ok",
     "timestamp": 1674212543209,
     "user": {
      "displayName": "Hyoseung Kang",
      "userId": "00233629824676120159"
     },
     "user_tz": -60
    },
    "id": "f70e4098"
   },
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c0c96824",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.is_available()\n",
    "device = torch.device(\"cuda\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0417688f",
   "metadata": {
    "id": "6a0a0884"
   },
   "source": [
    "## Exploring the Dataset \n",
    "\n",
    "The speech samples are already divied into training, development, and test spilts. The splits are made in such way that evaluation speakers are not present in training split. You should use the splits as they are. \n",
    "\n",
    "**CAUTION:** \n",
    "\n",
    "In this project, you are not allowed to use any external data for this problem (at least for the main three tasks). Exploring the effect of additional datasets in this project can only included as a further step after completing the main requirements with the given data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e3c46ba8",
   "metadata": {
    "id": "c40503e1"
   },
   "outputs": [],
   "source": [
    "# read tsv file into a dataframe \n",
    "sdr_df = pd.read_csv('SDR_metadata.tsv', sep='\\t', header=0, index_col='Unnamed: 0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ace53014",
   "metadata": {
    "executionInfo": {
     "elapsed": 16,
     "status": "aborted",
     "timestamp": 1674212543211,
     "user": {
      "displayName": "Hyoseung Kang",
      "userId": "00233629824676120159"
     },
     "user_tz": -60
    },
    "id": "b9a087bc"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>identifier</th>\n",
       "      <th>speaker</th>\n",
       "      <th>split</th>\n",
       "      <th>label</th>\n",
       "      <th>file</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>5_theo_23</td>\n",
       "      <td>theo</td>\n",
       "      <td>TRAIN</td>\n",
       "      <td>5</td>\n",
       "      <td>speech_data/5_theo_23.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2_yweweler_39</td>\n",
       "      <td>yweweler</td>\n",
       "      <td>TEST</td>\n",
       "      <td>2</td>\n",
       "      <td>speech_data/2_yweweler_39.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>6_yweweler_34</td>\n",
       "      <td>yweweler</td>\n",
       "      <td>DEV</td>\n",
       "      <td>6</td>\n",
       "      <td>speech_data/6_yweweler_34.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>6_yweweler_16</td>\n",
       "      <td>yweweler</td>\n",
       "      <td>DEV</td>\n",
       "      <td>6</td>\n",
       "      <td>speech_data/6_yweweler_16.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>9_yweweler_2</td>\n",
       "      <td>yweweler</td>\n",
       "      <td>TEST</td>\n",
       "      <td>9</td>\n",
       "      <td>speech_data/9_yweweler_2.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>95</td>\n",
       "      <td>1_nicolas_26</td>\n",
       "      <td>nicolas</td>\n",
       "      <td>TRAIN</td>\n",
       "      <td>1</td>\n",
       "      <td>speech_data/1_nicolas_26.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>96</td>\n",
       "      <td>3_jackson_18</td>\n",
       "      <td>jackson</td>\n",
       "      <td>TRAIN</td>\n",
       "      <td>3</td>\n",
       "      <td>speech_data/3_jackson_18.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>97</td>\n",
       "      <td>0_yweweler_41</td>\n",
       "      <td>yweweler</td>\n",
       "      <td>DEV</td>\n",
       "      <td>0</td>\n",
       "      <td>speech_data/0_yweweler_41.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>98</td>\n",
       "      <td>9_yweweler_22</td>\n",
       "      <td>yweweler</td>\n",
       "      <td>DEV</td>\n",
       "      <td>9</td>\n",
       "      <td>speech_data/9_yweweler_22.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>99</td>\n",
       "      <td>6_jackson_28</td>\n",
       "      <td>jackson</td>\n",
       "      <td>TRAIN</td>\n",
       "      <td>6</td>\n",
       "      <td>speech_data/6_jackson_28.wav</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       identifier   speaker  split  label                           file\n",
       "0       5_theo_23      theo  TRAIN      5      speech_data/5_theo_23.wav\n",
       "1   2_yweweler_39  yweweler   TEST      2  speech_data/2_yweweler_39.wav\n",
       "2   6_yweweler_34  yweweler    DEV      6  speech_data/6_yweweler_34.wav\n",
       "3   6_yweweler_16  yweweler    DEV      6  speech_data/6_yweweler_16.wav\n",
       "4    9_yweweler_2  yweweler   TEST      9   speech_data/9_yweweler_2.wav\n",
       "..            ...       ...    ...    ...                            ...\n",
       "95   1_nicolas_26   nicolas  TRAIN      1   speech_data/1_nicolas_26.wav\n",
       "96   3_jackson_18   jackson  TRAIN      3   speech_data/3_jackson_18.wav\n",
       "97  0_yweweler_41  yweweler    DEV      0  speech_data/0_yweweler_41.wav\n",
       "98  9_yweweler_22  yweweler    DEV      9  speech_data/9_yweweler_22.wav\n",
       "99   6_jackson_28   jackson  TRAIN      6   speech_data/6_jackson_28.wav\n",
       "\n",
       "[100 rows x 5 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sdr_df.head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f1adf602",
   "metadata": {
    "executionInfo": {
     "elapsed": 17,
     "status": "aborted",
     "timestamp": 1674212543212,
     "user": {
      "displayName": "Hyoseung Kang",
      "userId": "00233629824676120159"
     },
     "user_tz": -60
    },
    "id": "4c34786a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'george', 'jackson', 'lucas', 'nicolas', 'theo', 'yweweler'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(sdr_df.speaker.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "451fa26b",
   "metadata": {
    "executionInfo": {
     "elapsed": 17,
     "status": "aborted",
     "timestamp": 1674212543213,
     "user": {
      "displayName": "Hyoseung Kang",
      "userId": "00233629824676120159"
     },
     "user_tz": -60
    },
    "id": "155ea375"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>identifier</th>\n",
       "      <th>speaker</th>\n",
       "      <th>split</th>\n",
       "      <th>label</th>\n",
       "      <th>file</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>7_theo_0</td>\n",
       "      <td>theo</td>\n",
       "      <td>TRAIN</td>\n",
       "      <td>7</td>\n",
       "      <td>speech_data/7_theo_0.wav</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    identifier speaker  split  label                      file\n",
       "700   7_theo_0    theo  TRAIN      7  speech_data/7_theo_0.wav"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# explore one sample: 7_theo_0\n",
    "sdr_df.loc[sdr_df['identifier'] == '7_theo_0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1013005e",
   "metadata": {
    "executionInfo": {
     "elapsed": 18,
     "status": "aborted",
     "timestamp": 1674212543214,
     "user": {
      "displayName": "Hyoseung Kang",
      "userId": "00233629824676120159"
     },
     "user_tz": -60
    },
    "id": "e03e0920"
   },
   "outputs": [],
   "source": [
    "sample_wav_file = sdr_df.loc[sdr_df['identifier'] == '7_theo_0'].file[700]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4ed6e9a",
   "metadata": {
    "id": "6ab5f7e7"
   },
   "source": [
    "## The Speech Waveform\n",
    "\n",
    "The acoustic realization of speech segment can be (digitally) viewed as a time-variant wavform $\\mathbf{S} \\in \\mathbb{R}^{n}$. Here, $n$ depends on both the duration of the speech segment and the sampling rate of the continous speech singal. Let's check out one sample from the data set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "34c77f5c",
   "metadata": {
    "executionInfo": {
     "elapsed": 18,
     "status": "aborted",
     "timestamp": 1674212543214,
     "user": {
      "displayName": "Hyoseung Kang",
      "userId": "00233629824676120159"
     },
     "user_tz": -60
    },
    "id": "ac93353b"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "                <audio  controls=\"controls\" >\n",
       "                    <source src=\"data:audio/wav;base64,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\" type=\"audio/wav\" />\n",
       "                    Your browser does not support the audio element.\n",
       "                </audio>\n",
       "              "
      ],
      "text/plain": [
       "<IPython.lib.display.Audio object>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# play and listen to a sample \n",
    "SAMPLING_RATE = 8000 # This value is determined by the wav file, DO NOT CHANGE\n",
    "\n",
    "x, sr = librosa.load(sample_wav_file, sr=SAMPLING_RATE) #, \n",
    "ipd.Audio(x, rate=sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fee8ab8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3428,)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "679ed313",
   "metadata": {
    "executionInfo": {
     "elapsed": 19,
     "status": "aborted",
     "timestamp": 1674212543215,
     "user": {
      "displayName": "Hyoseung Kang",
      "userId": "00233629824676120159"
     },
     "user_tz": -60
    },
    "id": "b7438910"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAm8AAACqCAYAAAD7jKimAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAgAElEQVR4nO2dd7gUVdKHfyVIcJGclAyCCCqygBkFCUZExYCygjms8TPsqqwYURcD4JpgjYiZVRczCGJYBQFBEBXJgqJIEMlyob4/qo99pm+nSXfCrfd55pmZjudM95yuU5GYGYqiKIqiKEphsEuuG6AoiqIoiqLER4U3RVEURVGUAkKFN0VRFEVRlAJChTdFURRFUZQCQoU3RVEURVGUAkKFN0VRFEVRlAJChTdFUQoSIupGRCus7/OIqFsGj7+UiHpm6nhlCRHdSUSrieinXLdFUZTMo8KboigZh4imENE6IqpcVudk5vbMPMU5/61ENLaszp1PEFETANcCaMfMDXPdHkVRMo8Kb4qiZBQiag6gKwAGcGJOG1M+aQZgDTOvSnZHIqqYhfYoipJhVHhTFCXTDAQwFcDTAAbZK4joaSJ6hIjeIaKNRPQ/ImpIRCMcTd23RNTR2n4pEd1IRF87658ioip+JzVmTiI6BsBNAM5wzvGlvd7aPkE7R0RnE9EyIlpDRIM9x96FiG4gokXO+peJqHZAOz4kon7O58OJiInoOOd7TyKa7XxuRUSTneOtJqLniKims+4GIhrnOe5IInrQ+VyDiJ4gopVE9INjJq3g9G8igD2dvj/tbH+iY1b+1dGK7uP53f5ORHMAbCKiis6y64loDhFtcs7VwLluG4jofSKq5dd/RVGyjwpviqJkmoEAnnNeRxNRA8/60wH8A0BdANsAfAbgC+f7OAAPeLYfAOBoAK0AtHH2DYSZ3wVwF4CXmLkaM3eIajARtQPwKICzAewJoA6AxtYmVwI4CcCRzvp1AB4OONyHALo5n48AsNjZz3z/0JwWwN3O8fYB0ATArc66FwAcR0TVnfZVgPxuzzvrnwFQAmAvAB0B9AZwATO/D+BYAD86fT+HiNo4x7saQD0AbwN4g4gqWW0+E8DxAGoyc4mzrB+AXpDfvA+AdyBCcV3Is+PKgP4ripJlVHhTFCVjENHhELPdy8w8E8AiAGd5NnuNmWcy81YArwHYysxjmHkHgJcgwojNQ8y8nJnXAhgKETQyzakA3mTmj5h5G4CbAey01l8MYDAzr3DW3wrg1AAz44dIFNbutr4f6awHMy9k5onMvI2Zf4EIrUc665ZBBNqTnP2OArCZmac6wvCxAK5m5k2OeXQ4gP4BfTsDwFvOubYDuA9AVQCHWts86PzGW6xl/2Lmn5n5BwAfA5jGzLOc/r+G0tdJUZQyQoU3RVEyySAAE5h5tfP9eXhMpwB+tj5v8flezbP9cuvzMoimKtPsaZ+HmTcBWGOtbwbgNcfs+CuAbwDsAODVKgKiSWzjCFkHABgDoAkR1QVwIICPAICI6hPRi47Z8zcAYyFaLcPzcAXVs+Bq3ZoB2BXASqs9owDUD+nbMqtvO52+NrK2We7dCclfJ0VRygh1TlUUJSMQUVWIaa+ClaKiMoCaRNSBmb9M8dBNrM9NAfwYYx/2WbYJwG7WdzsScyXEdAkAIKLdIKZTw3IA5zHz/yJPzLyZiGYCuArAV8z8OxF9CuAaAIsswfZup537M/MaIjoJwEPWoV4BcD8RNQZwMoBDrLZsA1DXMnGG8SOA/ay+EeQ3/cFudozjKIqSJ6jmTVGUTHESRBvVDqJxOgAiEH0M8YNLlcuIqLETIHATxLQaxc8AmhORPcbNBtCfiHYlos4QU6lhHIATnACDSgBuR+L4+BiAoUTUDACIqB4R9Q05/4cALofr3zbF8x0AdgewEcCvRNQIwPX2ARxT6hQATwFYwszfOMtXApgAEeyqO8EUrYjoSPjzMoDjiagHEe0KSSOyDcCnIe1XFCWPUeFNUZRMMQjAU8z8PTP/ZF4QbdKAAP+wODwPEVYWO687Y+zzivO+hoi+cD7fDAl6WAfgNrhmSDDzPACXOctWOtv8kQAYwEgA4wFMIKINkGjag0LO/yFEOPso4DucNvwZwHoAbwF41ec4zwPoabfVYSCASgC+dto6DsAefg1h5vkA/gLgXwBWQ4IP+jDz7yHtVxQljyFm1ZYripKfENFSuFGUiqIoClTzpiiKoiiKUlCo8KYoiqIoilJAqNlUURRFURSlgFDNm6IoiqIoSgGhwpuiKIqiKEoBUa6S9NatW5ebN2+e62YoiqIoiqJEMnPmzNXMXM+7vFwJb82bN8eMGTNy3QxFURRFUZRIiGiZ33I1myqKoiiKohQQKrwpiqIoiqIUECq8KYqSF8yaBdx7L6DZixRFUcJR4U1RlLzgrruAt98G1q/PdUsURVHyGxXeFEXJC9auDV7HDLz7LrBuXdm1pzzy44/AokW5boWiKFGo8KYoSt7z/ffAP/8JPPxwrluSyObNwLZt/utKSoCHHgKWLi3TJqXFZZcBF1yQ61YoihKFCm+KouQ9JSXyvmRJ5o+9eTOwY0dq+557LnDllf7rli0D/vOf/BM4w/j111y3QFGUOKjwpihKwRCk5UqHfv2A225Lbd9Vq4DvvvNfZwIv8sXUu3EjcO21wLx5uW6JoijposKboih5D5G8//CD//pVq4ANG1I79tatwMcf+69btgy4/XYRfAqdhQuBL74Ann461y1RFCVdVHhTFCXvqVBB3itV8l9/5pnAiSdm/rxjxwIffCBpTLKBMQeXJdu3l/05FUXJLCq8KYpSUPz8s0RF2uzcmZ1zZcNMa5g1C+jdW7RhfjADP/2Uubx3mj9PUYoHFd4URck71q4FVq70X3fJJRIoUOjMnSsC1Zdf+q//6CPRKH7ySWbOZ4I9Ug3OUBQlf1DhTVGUvOOqq4ABA9zva9a4n3/9Ffj99+SOl6o/XCZYtSq1/RYvlve4EbaTJwN33x2sYTMm5yZNoo+lWjpFyW9yKrwR0TFENJ+IFhLRDT7rKxPRS876aUTU3Fnei4hmEtFc5/2osm67oiiZxTZ9rliRKEBs2iTvlSsnf9yxY8Ufbvbs9NqXLLs4o2umBMe5c4HPPw9ef8cdwIQJ0YLXLjFG/WSFY0VRypaKuToxEVUA8DCAXgBWAJhOROOZ+Wtrs/MBrGPmvYioP4B/AjgDwGoAfZj5RyLaF8B7ABqVbQ8URSkrTLRpvXrJC0Mm2KCsc5gZISkVgdMPk0/ugw8yczxFUQqXXGreDgSwkJkXM/PvAF4E0NezTV8AzzifxwHoQUTEzLOY2bgszwNQhYgyNEQqipJLvv8+s8czQlTVqpk9bjJMmQL88kvuzp8pmIFrrgHefDPXLVGU8k0uhbdGAJZb31egtPbsj22YuQTAegB1PNv0AzCLmbMYF6YoSlkxZ05y22/d6n5+6y0xH2Yr+jQVtm2TJMD33JP54953X7BPHLOsnzYtc+csKRFN5v33Z+6YiqIkTy6FN/JZ5vXWCN2GiNpDTKkXB56E6CIimkFEM34phqmvohQ5yZo37Vxp990njvthRe5TYcsW4L33gn3BFi6MDkzIdGWDb78VYXXUKP/1W7fK+lSrRyiKkr/kzOcNommz454aA/gxYJsVRFQRQA0AawGAiBoDeA3AQGZeFHQSZh4NYDQAdO7cWWOoFCXPyVVk6PjxQK1aQNeupdc98YQIZyUlwPHHl15/4YUSxTlmTPbbaTDm5fXrw7fbsiX7bVEUpWzJpeZtOoDWRNSCiCoB6A9gvGeb8QAGOZ9PBTCZmZmIagJ4C8CNzPy/MmuxoigZY8uWxMjIOFGQQceJw86dwJNPSskrP4YPB4YM8V9ntGph51q+PHgdkPkIzl13lfdmzRKXr16d2fMoipJ/5Ex4c3zYLodEin4D4GVmnkdEtxORKXTzBIA6RLQQwDUATDqRywHsBeBmIprtvOqXcRcURUkRZuCEE4Bhw+Jtb3zY/IQnOwecH2b9ypXAs88CI0e666LMq6bovAl2SEcr2LJl6vsmQzKatg8/FLOq5nVTlMIip3nemPltZm7DzK2YeaizbAgzj3c+b2Xm05h5L2Y+kJkXO8vvZOY/MfMB1ivFVJiKouSCnTuBd9+Nt60Romz/trhBCV6H/p9/dj9HVRswQpsRvDKV9sNmyxbg44/j9yeoHmrFFJxgbrtNImE1r5uiFBZaYUFRlLynWjV5b9jQXeatbxpFOmWhyC90yocwDdaiAM/cV14Rc+306cm3K12ypXHbsCH69/74YykBFgZztE+fopRHVHhTFCWv2LgxO8edOlXebUEsHcEgSvCZMSPxe5TW7oknRAuWb1x3nZTdSoYTTwSGDg3fZsgQ4JZbwrcZMwY46aTMRw8rSqGjwpuiKHmB0a5ti5mxMdnMPyYgomNHd1mUD9vSpcHrfvghfN8XXwxf7zVzLliQn2k9Zs6UslvJkolKEJMmyXu2BHpFKVRUeFMUJS+oVUveg8yLXuIKeV5MgXYbE7npxQh8K1aUXhdlFuzRI3x9gwbh6wuVqAASRVHSR4U3RVHygnr15L1Kldy2w6Zu3dT3rVlT3o1Q6mX+fP/lyfry5RuZzCtX1vVoFaVQUOFNUZQyx8+HKdU8b374CUBBwhIAbN/uv3y33TLTHkAiOj/80I3sfOUV/+2M8PPbb+HHW7cu8XtQFGohk6uEzYqS76jwpihKmbNpU2r7zZ0bbzu/tBt/+pO8G9+6ILIVgckM3HprdHoUE1BhEgObdnsxwlv16sm1o5CqBJrfIm60r6KUFyKFNyLajYhuJqJ/O99bE9EJ2W+aoihKIsYUmU3CzH5h2jsgnlAa1yfMRKdWr+5fFcL47tWoEe94ZvsojV4qfPppblN6vPYa8P77uTu/opQ1cTRvTwHYBuAQ5/sKAHdmrUWKopRr/DRfxtQY1weKOTigISpK1A8jSAVpwQxeU6Zpix8HHRTv3HfdBZxzTunlyQpLJrrVL2ADSD0P3qpVwODBwL/+ldr+meDBB6NTkyhKMRFHeGvFzMMAbAcAZt4CQJXYiqJkBbsCgiFK4+Vl5EgpIO9nPk2lmkA6ZrsggTPKfBukIdu8Wd5/+kneg9q2dWt02wxLlgC9e8ff3sb4C379dWr722zerGlBFCUOcYS334moKgAGACJqBdHEKYqiZIwvv0z8vvvu7udkzaXLlokmyc+JPygtSBhGUIpi69Zon7nateMda+ZM/+Um2MMEU5SUAP/9b+nt4rYZEMErTnmuOEXvgzSbcX6b449P1DKa7Qs9AldRMk0c4e0WAO8CaEJEzwGYBOBvWW2VoijlDm9KjQ0bgLffBgYMSD2n28qV6bfLpkKF8PUXXQQ88ED4NqZeahDff59cmz7+GBgxIr3jxK1gEOYPaH5rPwFt0ybg2GOBZ56JPoftE2hMvLZJd8UKYNSo4oyuVZS4RApvzDwRwCkAzgHwAoDOzDwlu81SFKW8YB72fua/e+8VrYuff9czz4ijepgPW5QfVzYEgDffjLfdF1/4L082ZcrChYnfjdBmNIxBeebKEhPI8dpr8m5Mv1H4mbhHj5bqFd99l5m2FQsbNwKPP6658coLFYNWENGfPYvMHLYpETVl5oChR1EUJZgnnkj8vn59alGk334rr8GDU2/L4sWp75sqy5fLe716/gEO6ZLJfHlxTKmpENevjai0Js9oCbOV0qVQmTQJeO45SQVz4425bo2SbQKFNwD3O+9VAHQG8CUkUGF/ANMAHJ7dpimKUoyMHZvrFrhEmTCNoJVJjHAVFQTRurXUO00Wb6DCjh3AffcFR5mGYQtvn3ySqDFbvBho2TL5Y6aLEdp++glo374whLhPP5Xf7/rrE/P4zZ8PdO2a/PG2bJF7Y//93WUmEjoqFUxJCXDttcDJJwPduiV/biU/CJyjMXN3Zu4OYBmAPzNzZ2buBKAjgIVB+ymKogSRqu9aGMlEVSZLmNk1mYAAm1SEqGTw+rr99hvw1luuydKv/FgcTdjNNwN33+1+P//85Csg+AkWyUb/mqTEJso16BqtWuWfHy/bTJ9eOm3KLbcA77yT2Nc77wSGDEkUiDdvjmcOHjUKuOqqxJq7JoAlSvO6cSMwZw5w223R51HylzgK9rbM/Edec2b+CsAB2WuSoijFitc/KxOkkvojLmEBCqn6y337bWr7xcVoE4O0dqaGrI1ftCoQXac0E799WLCEn1bNJCXeskWCG4LaeMYZ/vnxss3f/ga8+mpi4IW5V+wkzqZaiC18PvAAcPHFiUIxc+k+fvWVvGdz4qLkN3GEt2+I6HEi6kZERzqVFr7JdsMURSk+Ro0q2/P5BTNs2QLcf388k6jXtDl/PvDUU+mZ6qIS/UZh0mZEaWiCTMKLFsl72IPfCFRRpbyiAkKyIVgbDdOcOcCppwI33JDe8RYuBP73v+jtZswQbVVcfz2/oAw/H0dbeP3sM3m3f7fnngOOOy7aHGq0cFH3RVAdX6WwiCO8nQtgHoCrAFwN4GtnmaIUhL+Jkj/su2/pZelGx9mmIy/2/Wk0IXPnSkTo008nf64FC4AxY+JVNzDakWSJEniMwORn/gSAN94IP4aptBAWjPD88yKkBOWaM/zwQ7gwcPTRpU2X3hJiRiiJW7arTh15N0JUusmBL7wQ+Mc/ogXRZ54BpkyRhMaGSZOkuoONEfjjCnn27+En8I0fL+/2eQ22MGju9caNE5e99FLif8ROn2P/Px55RMy7Njt3avRqvhInVchWZh7OzCc7r+HMrMpaBcOGAZddlutWKPkMc6Ig4eePs2GDbJdqTra4EwgjZBihxZsUONOkWofV7yHtR1Cy4R9/DNdwxvmd33xTTH9RAR1E0Ql0V61KTO7rFdKMIGwLk2HX1Pj0pWIyHDMmWGiPuo+Mj+O8ee6yO+90fQkNRngLSgWTLMbHz/YXNeXabAHRnNdoJgGZQDz2WKKvYlCgzCuvAB99lLhs5EgJbLDNuJs2SQCMJk7OLXEK0y8hosXeV1k0Tslv3nkH+MZjQDdRUIoCSILdk0+O3i4dDW6ypbPMQz9O4EDcou+ZxH74+mE0NRVDcgXMnBksnK5ZA1x+eXQ74ibujUpcDIQLWn7CxJw5wYXmzfniVHsAEoWep56KlyjYD+O3tnRpvO3NPR11b/uZ9m1tnN8kwFwbv99u9mz3s5k4peob56f1mz5dAmCefz56/99/Tz2wRwknjtm0M4AuzqsrgAcB5FGwv5JrbLPIpZdKlvkoXxmlfLByZaIpKBt1K6M0SV5tX1TusnnzpGoBEGyatB+QqRIldAYJCf/6V7wi7Ma86IetPQoj2ZquQ4f6B3J4TaVRZuerr07soy0AvPNO6WVhxI2IjTre3nvLu1/tXZtmzeTd+J5FBX2Ya2ELmXawg8H+XY3fpJ/g7Fd+Leg/4nceGzORePRRd5n5/3h/159/BiZOTFw2bBhw5pkaWJEN4phN11ivH5h5BICjyqBtSp6yYwfw73+73885R5Zt3uwKch98kJOmKXmKGfBTTd0QFqUapUELMi8GPdD+9jdJ4RD2YIt6IMfBmL6CCIpm3bw5WCuVSZiBFi2S2+f998VM6sVrYrOFNxM4Eubzlmzgg3193n473j52wuZZs4LHMLvmrsHWrhktVZjW1r62xixq32+20GwmEJ98Enw8G3tf8zsH/Uei7mMTmWxHSJtjeaOmr7kGuOuuxP/VpEnyHldbqcQnjtn0z9arMxFdAsDn9lXC2LED6N490VxRUlKYzqAvvVRaZT5jRqJfRbowi1B4zz1yvrhs3VqYv2kxYj+MTFoE86BKljABzU9YMHz8ceq55bIVlWce9EHmRuPTle18cFGMHx/PJOrFm+MMSBS+Z8/2D+YIE96SrRph3xMbN8r9FxWQsHw5cOWV4tx/zTXA7bcnrjfCitGU2RrcX35xP4cJ5X5tMIJtkJnamMft45qIYRtzv27aBFxwgfi6GS2lbYr3m7QE+Uiaic+RR7rLjNbPK5yafmQjHZBSmrAKC4b7rc8lAJYAOD07zSlezKxp3jygXz/gtNPcP8z//Z8MeAMHAg0aAD16hA+azDJwpDKwZgK/P6c3XH/WLPfztGlicojrwP377zL4LF/uamqOO85/xmvo3l3emzWTfSZNymyZICV5bD+ZdFNGpHotozRUcc2HmcT+b4SRrMnSZtkyoE2b8G3i+rRF4SdIeLGd94cN89/Gm1w4HWw/sldekdfFF4fvM2aM3KfGz8tL1aqiyTLjkC2wGYF8587SkwVbK+d3Xcz2Qb7CXjNtkEbYmOHXrpWXfV322MP9bAuQN90E/PnPiX1mdu89M2bb9+I117jb+bFoUXTVCCNoBmnF/bDbpcTzeTvfVFtg5l7MfBGALKbFLD7WrAFuvdX9vnZt4kxn+HDRwj35pGivJkzwP85HH0lpoRtvBHr2DNc4ZApmiTgaMUIGt6eeiqfZ2r5dBKpFi0Swu+eexPXbtgGTJ5fWbmzZItpJbw4u70CxebNExHkHSiPs5eKhnA47d4qQG6Ql2ro1O9UJMs2aNcA//ymaFfvhFqb1yGW6mVQ1gWGETTIA/yS5NpmalEX5emXK/9B2ofDj99/jCYpxHsxxEyP7/YZ+2iX7NzITjKAoStO+ZctknLY1hUYLZ5uDTQoT+3h+wsry5aIlCxqzjMbv7bdlTLU1m7aQGubLGZRbcMWK0sJq2ETL/q96/RgNxvxsm2S943mfPkDv3sB777nLtm+Xusd+QuyVV4pSw5x/yRKpMJGpCUghEkfzNg6At0j9OACdMt+c4sQbSh7FsGFAw4bi6zBihMzUzj23dA6eM84AOncGjjlGBpauXcNnMosXS027IUNkJjZ/vgzg9eoBBx7objd2rPyJOnQAjjgCeP315Npv88Yb8j5tmpiwunSRfj32mBy3Y0fJKm64++7gGeiyZSIQdOoEjB4tWeHvv99/2wceED+Lm24CevVyl+/cKQJor15A06al9/vkE6BVq8SZahjMIpiERf7Z265b5+9QPH26CLlduohgftRR4rDduLEI6XPnilBQ1kluk2XoUNEsvftuYt3LRYuAgw/2f0AtXuyf/60siAo88IsETBcjBAQJaT//nBmfuihBJ0jDlAxxtGVx/Z3C2mu0TVEa3E2bkkuC7Ceo1a9fepk3lc2ECYmarRUrSo8Zu+wiee769g1vw7JlpX1B/X4L0/cPP3SX2QJb2GTeNlP7BYu0bJno82cw13fKFKB/f2DqVHedNyp6991FGP7qK3lu2b+HVzA3E9F77pFjX3yxREePHSsvr7+hcbuYPFmEuHHjJCK5X79g30Rm+S+tXi01cKMmB99+KwF3AwaI5SffCXzkEFFbAO0B1CCiU6xV1SHF6tOGiI4BMBJABQCPM/M9nvWVAYyBCIprAJzBzEuddTcCOB/ADgBXMvN7yDHjxsmf6XSPUfm555I/llFNAxK19Oab/tvNmCEvQASSm24SrdSaNSIo7LOPCEPLlkn6gF9/FYEq6Ib/619FcAPkz5RuLiy77M6QISKMVKrkDhSzZsmAcPDB0i4T5edl6tTkfOrMA+Ouu+RPedFFMmC88YY7QBx7rDinr1/vOgXffLO8f/CBCGVbtgDVqonm64knRLBq0sQduB5+GPjPfyTT++TJIoxef70MtEQiTFeuLMLrU0+JwHzSSTKDtotKm1n89OnyWrhQBjWblSslIq5BA7mejRrJQPn113LcIUMShcht2+T37NDB1fbs3JlogjQz2UyZI/bayzUL2g8DE8lXvXpps0+U4z6QPT/GMKE7TCO4bl36Wrsg4e2LLxI19UF40/QkS7r7A/ECUKJyxRnCgpz8KhP4ERVJ7MUvp17cFCS2T6KfWd+4l7zySul1UffzkiUyMY/SStv/27BoWds/zdaIG/wEN+ZEgfCSSxLX2/0vKXG1mOvWlS63FpYTbupUGav8JtNA4mR+8mTRttkTgu3bSyst5s0rnQ7n8MOBE0+UCbIfl14q76aixZ57+m83e7a4OgEyAYrStGeLMH3B3gBOAFATQB9r+QYAF6Z7YiKqAOBhAL0ArAAwnYjGM7OdL/t8AOuYeS8i6g/gnwDOIKJ2APpDhMs9AbxPRG2YOcIlNbs8/rjchA0bAgcdJDOusjR1TZxYOlTbj7BB8pFHMtceP/yy4d94Y/R+6QRDvPqqvLy8847r0Ovlk0/Eb27KFPnDd+okwvm4cbJ+4kTJyj5tmnw3yydNklfFiu7s+aCD3O0A0ThGaTP9BnxAwu6vu06SZHrp1Utmsq1ayQPouutc00bNmokPjL59RbBr2VIGui1bRLBesUKE1EaNxEzftq0Iq4ZNm+Q3+/VXmZUPHCgD53ffiWAbJIgZDVbcBLRespVqIEyzFpaC5N//lolOGFGCTdiD+fPPg9OUGHbbzT8jf1yi0kQAot0II46JN67gHSbEx033sW6dPEzD0rDYAo+f0GVPII87TgIXbC2ywRZ+Z8yQMSLKleW222RsaNQofDuj8Yq6RrawGuQX2rlz4nHiTJaA6AAPW+CL0hT/738yVgD+9/2sWYm+oFu2uEL/p5+6yz/9NPE7ANxxhxtc8ttvwZrOTz6Rl/3827BBJuxeJcWAAaWfk5s2iZnXNlvnyu8cCBHemPm/AP5LRIcw82dZOPeBABYy82IAIKIXAfSFlN8y9AVwq/N5HICHiIic5S8y8zYAS4hooXO8bLQzNkZQ85o3lcLDaOAAmV15TUy2KdYP2+xhC26ZwE9wMwTVefQ+QM3M2PYZMYL1+efHb4v9oFu3TjSafuQ6eKRhQ3/NhDH1+BH28KpWLfrhFuZ3WVISr8RWGOk+OBo2TN8vzvistm8f3N+oYxifrqVLRavsl0dt6lQRpqOSJptzZcoXassW8fW9/nr5vuee/lqkF18ETjghXmDOzTeLf7Mf++wjQmFUombDhAliQahdWyZRdeqUFvjiaj4NAwaIW0tYgJkJDDMETUSqV5cJhq3EiBONOmeOTHqB6FQv9hhkm5QNu+6a6FttAh+YZWJuM3CgXG9ArmWlStL2E04obcoePjz+dcoGgUMqEf3N+SJ0ufgAACAASURBVHgWET3ofWXg3I0A2G6MK5xlvtswcwmA9QDqxNwXAEBEFxHRDCKa8YufvlhRlIxgJ/K0TcL77OMKb7vuKkJDWRNkTgsTKsNShcTRXgSZVefNK20SzwVxAkXi+vxFRbaGUa2avFeu7K9JNGaps85yBb2gBMRmAmKud8+epbex+x2nhJVtRq1VK3g7I+BFbReGcbd4+eVE/7Igvv8+UQPsNR/Wri3XcMkSd7LgDR4wmN90zRqxJBhhxa6VCkjuP+O3e9FF8nua+6Rv38Q2NG8ubhvLlonw/d57rqXlH/9wtzvnnMRz2OmhjDbTzw+5aVP3t16zxvWfrlhR7qcxY0TA3Wcfdx/TVjsSvWZNMQufc4749gHAZ5/JfXTMMaUFt8mTgQMOKN2esiRsPmyUwjMAzPR5pYufl413OAnaJs6+spB5NDN3ZubO9aLCvBRFARDPB+7YY2Ug9jr3nnKKWxKrb18Z3O0HZlyzTSaJG6VoE/bwDPNz2bAhOpVPnAoJ6WorjS9sEHFryXbuHLwumUhh24/X5tVXxW9zl138H4i2+dgUgY/SOu6yi2jpbrxRBKEHHhAhpHdvWW80ju95PKX9BISVK12H/8MPB/bbz/+cK1dGC5eGIK1r69bub3rjja4m0Z4MAdIG468ZVvFhxw73v3zeeXLsoGS/tkZ/0ybgQsc5qls38dc1gRxLlrhm3wULZJJjBNdDDhFhqW5d+b5smSssnXWWuHUYzWC7dnLOxx6TseSEE9ysBLNmSduNvxuRaLruvtvd5qGHxK1j3TrZ1vaDmzBBgqaMy8cjj4h/MyDWgR07xB8aEBeI116TAEAiCRYDxA3Kz/XhkUfyI2VJmNn0Dec9xUpwkawAYHnToDEAr0LabLOCiCoCqAFgbcx9yxyjSiaSAW/69Ny2Z9QouaEbNhSfgDg+LkadXJb06CEDSjb9A0ePlhn+88/LbNX48vTvLyYPP047TQacW26R7bt2FRV95coyMLz7rqTFsHn4YZltTpwoEVdB9O8vzv1Tp4pZtXr1eFqOiRPlQWIcZv24+WaZVX4W4kRwwQUyKK9bVzrSc8cOefjNnSumxt9/l4fF6tUyGPpF4339teuLUqOGHLtbN/l+4YWJGo7atVOvtJAuQeZTP8KCGYjCI3+D7qlkiBPBnA5BqR6SwZi0wgIFjP9WmIkpLOrXFtSM+T/Ix2rmTEkou2OHex/XqyevZ5+V4KIJE8Qv9aST3P1atZLo0T59ZKzwYkpddeki/92ePeX43ihNExXZtm2iedBrbjVCo+0ba/pn36PnnivvXqNRgwbuuQAZs1evLv3fXL8euPNO4IorxJQcZqq3zaSffeY+L1q1kjFt8GBJz3HoodJ/E0Q3a5Z7L5kSYtdfD/z97xI0sHSpf9BelSriJ2i49trE3+Kdd9xsAkOGSJ8bNJDvxh/N/I4//yw+voD81n7CVdeuksnhvfcShfa99krcrnVreV+xQgReQM47YoQIpdn+X8YlLNr0DQRoswCAmU8MWheT6QBaE1ELAD9AAhDO8mwzHsAgiC/bqQAmMzMT0XgAzxPRA5CAhdYAPk+zPWlz990isPXpk3jzmASyydCxY/xknp06yTl69ZJZ0PLlMoOsUcM1Zzz0kPyBPvxQZhxXXJF4jB49ZEB79NHSUUWZ4sADRc1eo4Y8wHv0kOWDB8sA71WdZ4ojj3T/kNdeK7PZUaNEMNtjD9ESffGFDMImUGDoUBmkAMlzZ7ATRR5zjLwMGza4Gpm+fV2tE+DOei+/XIQlo00wv8HKldIeQ7t2bp4om4oVRTsxapQEFlx+uQxEPXuKZmH+fNn3qKOkPdWqyT3xww9yb9atK4PiWWdJP/wcp83Dcv/9E2f8pmajH716ucKbMYPZba5XT/q/fbuYOuLe29nGL4AmE4wZk74/TFjFASC+E382qV1bHpydOpWOMDQYjUiYP1jYxLJOHVeYOf54mYBddJE82L2+VxMmyD39zjv+D9levWQs9E4UH3pIJkWdOgGHHSaCmXlwA26Akfm/7LuvOLl7g0qM/5X3f+X1k5s6Ve6PXr0Sf7dGjfyjgM04ctBBYnbv2VPGKyM4mgwH1auHB00MGRK8zhbebIHZ+A/uv7/8vhUrJgaEPOOod44+2j3GgQeKaZFINFh++GmvK1YUIfvssxPTQNkVHvyOMWCAuyzIJ9g7LgGi9fPj5JMTU3y98EJ+aNtswmTIELfo9GHmEiK6HMB7kFQhTzLzPCK6HcAMZh4P4AkAzzoBCWshAh6c7V6GBDeUALgs15GmgAgCXgdIQBzATfqNuAwbJhFnU6fKn6ZnT1cIfP11mTU2bCgDmX1TVaoksz4vDRuK4HLttfL91VdFg7R6teRFqlNHZi72YHT44TJYjBwps5Nvv5U+xjW3eBk6NHFAfeQReUARySD81luisXj22dL7Xn21RH49/7wIL1dfHe+c48aVNmFUq+b+DoDMVo0QVqWKCDhGcPMS9gf2G4zM9k89Fd7OPfaQSLT27aW9U6bI98MOk+ty882JWcvbtHG1frbZsn370u2pVEn8VEydSmMWyCS2n4sRlA1Nm8qM32gLs1Gc3qZCheBgAnt5WLBCFFFRs8mmrMgVjRplJ5edjbk3WraUsWnJktLCk9+D1WCnCTHHMhoY892O6P7lF7m2flGuZvvHHpO2VK4sD+oqVVzzcNOmwdYHMz6ae7h+ffE5s9NSNGsmQtnSpTJRffnl0scxbTO+Y3XqyH+kd2/RDnrbPHq09K9rV9ftYMECV3gzfnlt2ojGz1hQzjgj8bc12rpzz5WJatOm/pNEWwC0tZzm97PHOrP+739PPIYZ+w4/3F/zFqTB8vrY9eoVPO6eeWZiqcbRo8NzdB5/vDxnAEnHYzSFXq64Qo6zzz7xcsTlgjCz6R9xG0RUCUBbiCZuPjNnpMICM78N4G3PsiHW560ATgvYdyiAGJ4juecvfxHhJyolhok0GjtWbuxDD00UIiZPFofeP/0p/cLvxsnTzq1jBibvsU84IfH7p5+KtiwOAwa4f1zvn9V2IgVkJnreeeL/cJZHB2vCvwcNkvfXX5eZb/v2kmOtY0dJ9Gi0hieeKNq0KN8TL/Zsu6w54gj38yGHyADbp4/MZv3qReYT5mEK+Gvztm93w/FPPVUebGYGv2FDZkx4hqpVgwXEZs1cE5QR3IK0nOnUNo2KRC0UMpFfzxZkH31UtJ1nn524TZAfZOvWInx462Yaf8BVq8R8V7myGwFeu7Zo+fwiwu3Iy7AJIFHpVCwdO5Y+zvz5MgZdfLFrRjeT4RtucMfSc8+VMe2KK1y/uK5dXcHqzDMl4awfZ54pwpI3+ML4ldls3Cg+p717u4KJfQ1NNGr//qIAqFTJ9Vvzo3t3EXi82FG/5r8cJOC0bSuaQVuI7dPHf1vDiBHu9bEnpF6qVRNXku3b40XVXned/D716oX7rRKJ20w+E2m9JaLjATwGYBEkUKAFEV3MzAEZshQ/ghIQAqJpqls3Oq8TUXLZw7OFn7Nwly6lffxGj5bBt3r10g63YTRsKMJakBkGkMHDCDsvvCB/RrtdV12V+/QU6VC5spsXqRCwB0K/SDs7Yq9ZM7k3Nm0SIfurr9KvsGD7CSWr2Qsyb/olLgVcLUlYEETz5vETy2aTzp2jAxeiCNMiGmf5khKZdM6cKY7lNkaLYyZvjRqJFu7II0VoNhqzJUsStS7jx8sD2RayjLnOJFCtW7f0mLh0qQhdcXPgff65f93Tt96S62x84+ykrf36yX3rNxbakbfdu4vw0rChjN/durnCW82aIhjVrZtY4cZLkH+fn9a4USMxKQexc6c8ZypVcpPsBgVgAMFmVm9Ua1RAkB15/eSTrhUgiA4dRGv47rsymQ+jYsXk/ND8cvYVInEeb/cD6M7M3Zj5SADdAQyP2EfxYHwBmjSRWdjpp4v26IMPZMCKEtzyneuuK50LzZjPTj/d35QbBJEIX1GzM0PDhu4gOnGiFqXPBfXry0M0zMRhqFpVro8R+D7+uLTJJVskM/kxzt1+ZmBA/tNBD4LFi/NDeAsyCxl27ixtpvISlJHeZo89RHCwNbBeTIoYInEjGTjQFQ5MgIctcFWrVvqhbCYB9eqJdskvgtX42EX1yxD3wW9fTzPZOPVUebf9+bya5z32cP8TzZu7y0tKZJJ2xBGJ479dLhAoff+F4Xd/16jh3qfr1oUHhsX9zSpXFmHdCHFh/rCA+zsBiUm/w7jkEnlG2pUcFJc4t+0qZrbT6i0GUAYl0YuL3XZL39SZL7Rq5WbjN1SsmKh98VPpJwORDMwDBybnl5QvkUDlDaLgEm622cYrxJtou2z7wRn86sraNG/uPvyDfMHMRKFCBTlekIauLNhvv8SoQy9R/8M4v3ucZMDG7HnggSLA7b23VOiw8RPqjdazRQvRwu29t2hj160LngT07i33TZAbiolujVu26I474m1nCxF160pEt/lt7PsqrL60bdoL0j517Cj+rqkke/dL60IkkyOjXQz7D9x5pygX4mQcaNRIhNhZs6KTE9tm8Xz0HytE4ugn5hHR20R0DhENAvAGpJTVKZ6ap0o5oW7d0kEFZuZoTJlRpYOSOVeUil3Jb2zfxrAUJ5kmlWTAN90UntcMkICdkpLMFI9PlzDBLQ7t2oX7FAHxHuTGLEYkWrTbbnNLxkVxwAFiMi0pEV/BI45ILHFkp/Swz5Upwqo22IKY1w/XFmpt/7pMjFf2eYOijtu1S5ys9ugRrGm1/wthVolmzcTqERfjg9ihQ/S2o0dLyqpclpQqJuIIb1UA/AzgSADdAPwCoDak3ukJwbsp5YWXXnJn0GbQUbOlYrB9yryO6akkz80mrVsnlkbzw2jk0qkrmk+EmToBmZj17h0e/OMnUNWpIwJGFKtXu9p1P61Mz57AvfdGHycuZ5/tCj39+oUnjbbv3TDzpX2MsEAXO/IzbDv7mgQVdW/fXnzCDN58ZTa2FjLKhSUZq4m5bnFM661bJ0bMK+kRaWRi5nPLoiFK4fHAA+JjYSeGPOsseajlunSIkj/Y90dUkRMTeBBU4zIO1aqlZ4bNtGYn3znnHPHjC4porl9f/E937HA1TPvvH120Pi777uu6YBxySOrHueSSxLxdQcc67zwxDZaUhJs4DW3bxvPZvftuSVsRVirM9ocLS49ia8rCBGBbixWVVNpEz0ZpvuKamwE3uXE65dGU1IgTbdoCwBUAmtvbZyBJr1Lg2KHzhpYt3bIjipJJ0skxaKhZU7QEdeokai28mLQ9gPuA79VL/PfsqOqyqkbiTVth8Gbo9+Oyy8Qv752A/AA1a0r6hLB0NERyrqOOEqF6xAipnLFoUfw+BKVysIWOdDT2Z5whQmUclw2ieIIbkFizN4yDD5ZXGLaG7rDDgrez/etMIu8o/HKM2pj7J0qzloxP2u23i69i3EAHJXPEce9+HZIs9w0ABZJ6UlGUfMGe6afj79KoUerCm3kgVawoCbAXLQoX3oxQZkc8tmsn/ld2nsNcm31vuEECLMaODd7m1FMlK3+Q8JYMppg4UWL6lyhq1cqco3pY7rlCcoYPM0OnEngVNyozKvWG8dkzdWDD2HPPxBQqStkR5xbZyswPZr0liqIUJXbG86ii9KkmxrXzvPlpw5JNxWPSQvg9EG0zVosWbvLhbBLkX1e9ulRwmTbNLeLth0kVUatWeilMbOFo//3dclCZ8nGNU5kiLCegLfSkG/Gea845J7PJq4cOlTx8UXnOqlUDnn46tYAfpeyII7yNJKJbAEwA8EeGGGb+IngXRVGU5GnRIrzOZRD2Q9s88IwgUKWK+OQkUwaqTZvUfe689TbLgkGDXK2YH1WrStmlOXMkEjQTGC1qxYqZiyD0FlY3hPmH2bRqJdUDiPLXd3H48HiTFFNNJlN4K/aEEZW3Tck9cYS3/QCcDeAouGZTdr4riqKEkqsE1I0bhxfpDiNOqZ0grrkmON1CxYqipYrKi2UYPBhYvlwK3YcRx1xYu3bptBi26TOoJmyUP5Nd0Dxdgu6VuOcg8q+WkE9kOphr2LDCqaWrZI44yu6TAbRk5iOZubvzUsFNUZRYhEWYeutLRkWjJkNcU16yJr8oLVNYFYcmTaS+ZVzatZPIyEzhFYLssnWjR7v1OZPBVKIII5PCRaoCebHSpQtw0EG5boVS1sQZtr4EkMG5laIo5YnKlSUC0E8wsJOxmm3LmmRSI3i3N0XubcIy2Kfqw+RXBgpw/ftS1W7agmjLlmIuPiHJ7J1x6han6stosAXs5cvTO5aiFANxhLcGAL4loveIaLzzCikZriiKkshpp5V9LihbyAqr52hXgDAY82FUKpB0E/WaYI4oobVPH//yeqZOZIcOUi5qxIjEFBSptO/qq+OVZooT+GB+vzAzdJycfLZGtpAiShUlW8QR3m6BmE7vAvAAgM8BhORyVhRFiU+3bu7nTJgwTTSd7bA+f768+/l0+QkD5rg7d4YLQFHpMvzMwH4mxDDhMg4VKkhqhw4dgJNPdpcnU9TcPlZUDVgguug94P523mLtNnYC3CAhz75GdikqRSmvRA6VzPwhgPUAjgfwNIAeAB4L20dRFCUu11/vfjYaqLh5rvyEozvukFQHNiaCNW5SXaMRW78+XEjZujX8OBdckPh91arESL4o7VW6WqZsaqnimLiNEBj2u9vr4hzz8MOjt1GUYidQeCOiNkQ0hIi+AfAQgOUAyAlYCMnFrSiKEh9bwDC1Eu3ccGGYLPl2kfjddw9OdWB8r6J8xOL6aJ1+evj6WrXC10dpkTKda6tRI6mSUFYY4drPN9AQlXfMMHKkmxxZUco7YZq3byFatj7MfLgjsPkYHRRFUTKDMWvG1a4YM2uy/nSZSuDar1+87ewC57/95n4+7zxJK3LPPSJ0PvuslHkyZFpzVqkScPPNQPPm8fdJJ4ebMRGHBTUYv70oE+/++0uRekVRwvO89QPQH8AHRPQugBcBqKuooigZxdaCGTOin19Y3HQTfsJG/fpiskyl7NDSpfIeRxvnTQxrhFHbb84+Ts2aUnILAMaPl3fjHxaWciSMTOfVi9L+hf0upnxYWB3RPfYA7r3XP3BEURR/AocyZn4NwGtE9CcAJwH4PwANiOhRAK8x84QyaqOiKEWMrV0ykYe2psoQ14Tot+8xx0ii27iaLDuJ7vffy3uY0z0APPJI6UoAdk6y+vXja+qA1NOKZDJXHhD8mxnB7Jtvoo8R9dt17pxcmxSlvBMnYGETMz/HzCcAaAxgNoAbst4yRVHKLVFmzUcfBe67LzPnqlRJIh5vsEY1UxrrlFNcrVGrVuHH2Wcf1wQIlNY2vfRStI8cEB5xG1VUvCwxptdMVwxQFCWapIwIzLwWwCjnpSiKkhGuuAKoUwcYNy54G1t4stNLAOF+WSUl7nq/7XbsEGHQjw4dgLlzgbVr/den45PWvbv/8j33DN7nb3+TCM7nnkv9vIBb59X2v7PRckuKkt+k4AGiKIqSWU45Rd7HjpX3OIlbATfNRJgQVVIiZtMlSyQXWrJccw3w3nvB5sjBg4GmTZM/bhBG62jnv7OxtXtx8rH5YfzUPvvMf32Yj1oyGJ8/FQYVJbOo8KYoSt5Qvz6wcKE4+O+2W3SFABPgELZd69Zy3KCqAVEO/m3bltb02XgjIE1QRJcurhBkVz0w64PKcjVpAjz0UHC6E5t0y4mZ1Cxe2rWL3tcIZGE53IwJWIU3RcksKrwpipI31Kjhfh45UsyVf/+7fPfTfBnBYe+9galT3WS8gCvQ2cEHfqSijQtj992B4cMlf9kuu4jGz07/0aWL+L6FBS+0b5+ZtkT1PUhwjWMONgEVYTnc4ubrUxQlOVR4UxQlL9nLU4QvKs3HyJGJPlwmQe6yZeH7ZaMKge3E/9e/Jq6rWhW49NLMnzOqHX5cdVXwuqFDxd8vCCP41a8fvM1PP8l7kIZPUZTUSLKSYGYgotpENJGIFjjvvnnIiWiQs80CIhrkLNuNiN4iom+JaB4R3VO2rVcUJV8wvnHMko7CzhUWpXUKw+z766+pHyMf8EubYnPMMcHrDj0UuPji4PUNGsi7N7edjTGXBpmIFUVJjZwIb5BUI5OYuTWASfBJPUJEtQHcAuAgAAcCuMUS8u5j5rYAOgI4jIjyKIBeUZRUOe448fnab7/k9rPNpV5SKTFVp468q8YomP32k0CTc88N3iaTgRyKorjkSnjrC+AZ5/MzkCTAXo4GMJGZ1zLzOgATARzDzJuZ+QMAYObfAXwByT+nKEqBs+++kky3cQb/0XFyq3mpWTNz5y9WKleWFC9hCXgPO0yE54MPLrt2KUp5IFc+bw2YeSUAMPNKIvLzmmgEYLn1fYWz7A+IqCaAPgBGZquhiqLkD4cdBnTqlP3zmNJUVatm/1zZIh8E0LZtgRdeyHUrFKX4yJrwRkTvA/AzWAyOewifZX8EpRNRRQAvAHiQmReHtOMiABcBQFPV4StKQXPnnfG3TSc9RZ8+kh/u6KP911euDGzblvrx02HvvSXZ8JVX5ub8iqLknqwJb8zcM2gdEf1MRHs4Wrc9AKzy2WwFgG7W98YApljfRwNYwMwjItox2tkWnTt3DslIpChKPhOWT8yP5Y7ePpXAhd13BwYODF4/alS8QvXZoHlz4P33c3NuRVHyg1yZTccDGATgHuf9vz7bvAfgLitIoTeAGwGAiO4EUAPABdlvqqIo+Y4pkm5jSmG1bFl6XVTakSjiJNDNZ+66C1iwINetUBQlVXIVsHAPgF5EtABAL+c7iKgzET0O/FFH9Q4A053X7cy8logaQ0yv7QB8QUSziUiFOEUpx5x2WvA6vzxuYbVQywOHHBKuWVQUJb/JieaNmdcA6OGzfAYsbRozPwngSc82K+DvD6coShFy0EHAtGnh2+SDc36+UK2aaBbPOivXLVEUJVtohQVFUfKaVX4esUogu+0GvPuuahcVpZhR4U1RlLzGBAb4ZfI/7LDUE+lef31iLdViQgU3RSluVHhTFKUg8BO0kkkd4uW441LfV1EUJZfkKmBBURQlFnXr5roFiqIo+YVq3hRFyWuuvFJ8uPbcM7n91HSoKEqxosKboih5TYsWwKWXJr/f2WcDW7cCbdpkvk2Koii5RIU3RVGKkvbtgRGh9VcURVEKE/V5UxRFURRFKSBUeFMURVEURSkgVHhTFEVRFEUpIFR4UxRFURRFKSBUeFMURVEURSkgVHhTFEVRFEUpIFR4UxRFURRFKSCImXPdhjKDiH4BsCzLp6kLYHWWz5EvaF+Ll/LUX+1rcVKe+gqUr/6Wp742Y+Z63oXlSngrC4hoBjN3znU7ygLta/FSnvqrfS1OylNfgfLV3/LU1yDUbKooiqIoilJAqPCmKIqiKIpSQKjwlnlG57oBZYj2tXgpT/3VvhYn5amvQPnqb3nqqy/q86YoiqIoilJAqOZNURRFURSlgFDhLQIiOoaI5hPRQiK6wWd9ZSJ6yVk/jYiaW+tudJbPJ6Kj4x4zV6TaVyJqTkRbiGi283rM2qcTEc119nmQiKjsehRMjL4eQURfEFEJEZ3qWTeIiBY4r0HW8mLs6w7ruo63lrdw7oEFzj1RqSz6EkWMvl5DRF8T0RwimkREzax1xXZdw/paUNcViNXfS5zrNJuIPiGidta6YhuLfftajGOxtd2pRMRE1NlaVlDXNaMws74CXgAqAFgEoCWASgC+BNDOs81fATzmfO4P4CXncztn+8oAWjjHqRDnmAXY1+YAvgo47ucADgFAAN4BcGyB9LU5gP0BjAFwqrW8NoDFznst53OtYuyrs25jwHFfBtDf+fwYgEsLpK/dAezmfL7UuoeL8br69rXQrmsS/a1ufT4RwLvO52Ici4P62hxFNhY72+0O4CMAUwF0LsTrmumXat7CORDAQmZezMy/A3gRQF/PNn0BPON8HgeghzOj6QvgRWbexsxLACx0jhfnmLkgnb76QkR7QAaZz1j+bWMAnJT5pidNZF+ZeSkzzwGw07Pv0QAmMvNaZl4HYCKAY4q0r7441/woyD0AyD1RKH39gJk3O1+nAmjsfC7G6xrUV1/y+LoC8fr7m/X1TwCMQ3fRjcUhffWlkO9jhzsADAOw1VpWaNc1o6jwFk4jAMut7yucZb7bMHMJgPUA6oTsG+eYuSCdvgJACyKaRUQfElFXa/sVEcfMBelcg7DrWmx9BYAqRDSDiKYSkRns6wD41bkHUjlmtki2r+dDNBBh+xbLdbX7ChTWdQVi9peILiOiRZAH/ZUR+xbyWBzUV6DIxmIi6gigCTO/GXPffL2uGaVirhuQ5/hplbwznKBtgpb7Ccz5EPKbTl9XAmjKzGuIqBOA14mofcxj5oJ02pXs9c416barKTP/SEQtAUwmorkAfvPZrqD6SkR/AdAZwJER+xb8dfXpK1BY1xWI2V9mfhjAw0R0FoB/ABgUsm8hj8VBfS2qsZiIdgEwHMA5Seybr9c1o6jmLZwVAJpY3xsD+DFoGyKqCKAGgLUh+8Y5Zi5Iua+O2noNADDzTIi/QRtne9tUU0h9TXbfYuwrmPlH530xgCkAOkJqCtZ07oGkj5lFYvWViHoCGAzgRGbeFrFvQV/XgL4W2nUFkr+PX4RrFizGsdjmj74W4Vi8O4B9AUwhoqUADgYw3glaKLTrmlly7XSXzy+IZnIxxBnSOD6292xzGRKd+F92PrdHojPlYogjZeQxC7Cv9QBUcD63BPADgNrO9+mQP5xxkj2uEPpqbfs0SgcsLIE4tddyPhdrX2sBqOx8rgtgARzHXwCvINGx/a+F0FeIkLIIQGvP8qK7riF9LajrmkR/W1uf+wCY4XwuxrE4qK9FOxY720+BG7BQUNc1479drhuQ7y8AxwH4zhkEBzvLbofMZAGgijPgLYRE87S09h3s7DcfVmSP3zHz4ZVq4xj6OQAAAilJREFUXwH0AzDP+ZN8AaCPdczOAL5yjvkQnMTQuX7F6GsXyAxuE4A1AOZZ+57n/AYLAZxbrH0FcCiAuc51nQvgfOuYLZ17YKFzT1TOdT9j9vV9AD8DmO28xhfxdfXtayFe15j9HemMQ7MBfADrgY3iG4t9+4oiHIs9206BI7wV4nXN5EsrLCiKoiiKohQQ6vOmKIqiKIpSQKjwpiiKoiiKUkCo8KYoiqIoilJAqPCmKIqiKIpSQKjwpiiKoiiKUkBohQVFURQLIqoDYJLztSGAHQB+cb5vZuZDc9IwRVEUB00VoiiKEgAR3QpgIzPfl+u2KIqiGNRsqiiKEhMi2ui8d3MKf79MRN8R0T1ENICIPieiuUTUytmuHhH9h4imO6/DctsDRVGKARXeFEVRUqMDgKsA7AfgbABtmPlAAI8DuMLZZiSA4czcBZL9/vFcNFRRlOJCfd4URVFSYzozrwQAIloEYIKzfC6A7s7nngDaEZHZpzoR7c7MG8q0pYqiFBUqvCmKoqTGNuvzTuv7Trhj6y4ADmHmLWXZMEVRihs1myqKomSPCQAuN1+I6IActkVRlCJBhTdFUZTscSWAzkQ0h4i+BnBJrhukKErho6lCFEVRFEVRCgjVvCmKoiiKohQQKrwpiqIoiqIUECq8KYqiKIqiFBAqvCmKoiiKohQQKrwpiqIoiqIUECq8KYqiKIqiFBAqvCmKoiiKohQQKrwpiqIoiqIUEP8PcKtuU89Dyt4AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 720x144 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot as a waveform \n",
    "fig, ax = plt.subplots(figsize=(10, 2), sharex=True)\n",
    "\n",
    "img = librosa.display.waveshow(y=x, sr=sr, alpha=0.75, x_axis='time', color='blue')\n",
    "\n",
    "ax.set(title='Amplitude waveform')\n",
    "ax.set_ylabel('Amplitude')\n",
    "ax.label_outer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ca9253d4",
   "metadata": {
    "executionInfo": {
     "elapsed": 20,
     "status": "aborted",
     "timestamp": 1674212543216,
     "user": {
      "displayName": "Hyoseung Kang",
      "userId": "00233629824676120159"
     },
     "user_tz": -60
    },
    "id": "3c4297e5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "428.5"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sample duration in milliseconds\n",
    "(1000*len(x))/SAMPLING_RATE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06788411",
   "metadata": {
    "id": "3df44120"
   },
   "source": [
    "In the cell above, you can see the temporal duration of the audio is 428.5 milliseconds. For digits in the range 0-9, the duration of the speech segment should be around 0.5 seconds with reasonable variation depending on speech rate (i.e., how fast the speaker speaks). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa4910ff",
   "metadata": {
    "id": "d2a0c08e"
   },
   "source": [
    "## The Speech Signal Representation - Mel Spectrograms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8638b94",
   "metadata": {
    "id": "6370d9c2"
   },
   "source": [
    "Humans can recognize and differentiate different speech sounds based on the frequency characteristics of the sounds. For machine learning applications, human speech is represented using spectro-temporal features in the [Mel-scale](https://en.wikipedia.org/wiki/Mel_scale) extracted from the speech sample. Mel-scale features are inspired by human speech perception and auditory processing whereby the human ear has difference sensitivity (or resolution) in differet frequency bandes. That is, the human ear can better recognize differences in in lower range frequences, while higher range frequences have a lower resolution. The Mel-scale is linear for frequencies in the range (0-1kHz), and logarithmic for frequencies above 1kHz.\n",
    "\n",
    "In the spectro-temporal representation of speech, a speech sample can be seen as a sequence of $T$ spectral vectors as $\\mathbf{X} = (\\mathbf{x}^1, \\mathbf{x}^2, \\dots, \\mathbf{x}^T)$. Each spectral vector $\\mathbf{x}^t \\in \\mathbb{R}^{k}$ at time-step $t$ is extracted from a short speech segment (~25 milliseconds) with the assumption that the signal is time-invariant in this small time window. Here, $k$ is the number of frequency bands in the [spectrogram](https://en.wikipedia.org/wiki/Spectrogram) and this is a parameter of the feature extraction pipeline. The representation is based on the Fourier transform to convert the temporal signal into the frequency domain. \n",
    "\n",
    "In automatic speech recognition (ASR) research and applications, spectral vectors are usually referred to as \"acoustic frames\". Morover, adjacent frames are extracted with some overlap between them, usually ~10 milliseconds. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fa1bb05c",
   "metadata": {
    "executionInfo": {
     "elapsed": 20,
     "status": "aborted",
     "timestamp": 1674212543217,
     "user": {
      "displayName": "Hyoseung Kang",
      "userId": "00233629824676120159"
     },
     "user_tz": -60
    },
    "id": "ef41492d"
   },
   "outputs": [],
   "source": [
    "def extract_melspectrogram(signal, sr, num_mels):\n",
    "    \"\"\"\n",
    "    Given a time series speech signal (.wav), sampling rate (sr), \n",
    "    and the number of mel coefficients, return a mel-scaled \n",
    "    representation of the signal as numpy array.\n",
    "    \"\"\"\n",
    "    \n",
    "    mel_features = librosa.feature.melspectrogram(y=signal,\n",
    "        sr=sr,\n",
    "        n_fft=200, # with sampling rate = 8000, this corresponds to 25 ms\n",
    "        hop_length=80, # with sampling rate = 8000, this corresponds to 10 ms\n",
    "        n_mels=num_mels, # number of frequency bins, use either 13 or 39\n",
    "        fmin=50, # min frequency threshold\n",
    "        fmax=4000 # max frequency threshold, set to SAMPLING_RATE/2\n",
    "    )\n",
    "    \n",
    "    # for numerical stability added this line\n",
    "    mel_features = np.where(mel_features == 0, np.finfo(float).eps, mel_features)\n",
    "\n",
    "    # 20 * log10 to convert to log scale\n",
    "    log_mel_features = 20*np.log10(mel_features)\n",
    "\n",
    "    # feature scaling\n",
    "    scaled_log_mel_features = preprocessing.scale(log_mel_features, axis=1)\n",
    "    \n",
    "    return scaled_log_mel_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1501d884",
   "metadata": {
    "executionInfo": {
     "elapsed": 21,
     "status": "aborted",
     "timestamp": 1674212543218,
     "user": {
      "displayName": "Hyoseung Kang",
      "userId": "00233629824676120159"
     },
     "user_tz": -60
    },
    "id": "3600d78e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13, 43)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "melspectrogram = extract_melspectrogram(x, sr, num_mels=13)\n",
    "\n",
    "melspectrogram.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08d3868a",
   "metadata": {
    "id": "7ae0a639"
   },
   "source": [
    "Note that the shape of the array (K x T) represents the number of frequency bands (K) and the number of spectral vectors in this representation (here, K=13, T=43). K is a hyperparameter and the recommended values in ASR research are (13, 39, 81, etc). Here, we fix K = 13. On the other hand, T varies from sample to sample depending on the duration of the sample.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a2248b48",
   "metadata": {
    "executionInfo": {
     "elapsed": 22,
     "status": "aborted",
     "timestamp": 1674212543219,
     "user": {
      "displayName": "Hyoseung Kang",
      "userId": "00233629824676120159"
     },
     "user_tz": -60
    },
    "id": "f17e8976"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x144 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot and view the spectrogram\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 2), sharex=True)\n",
    "\n",
    "img = librosa.display.specshow(\n",
    "    melspectrogram, \n",
    "    sr=sr, \n",
    "    x_axis='time', \n",
    "    y_axis='mel', \n",
    "    cmap='viridis', \n",
    "    fmax=4000, \n",
    "    hop_length=80\n",
    ")\n",
    "\n",
    "ax.set(title='Log-frequency power spectrogram')\n",
    "\n",
    "ax.label_outer()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc61c522",
   "metadata": {
    "id": "e6c872b6"
   },
   "source": [
    "As you can see above from the figure, the spectrogram representation can be viewed as a matrix $\\mathbf{X} \\in \\mathbb{R}^{T} \\times \\mathbb{R}^{k}$.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88ac9abc",
   "metadata": {
    "id": "d5392b92"
   },
   "source": [
    "## Task I\n",
    "1. One problem with the spectrogram as a speech feature represetation is that different speech samples would have dfferent durations due to inherent speech variability (e.g., speech rate, speaker dialect, etc). That is, the $T$ in the $(T \\times k)$-dimensional representation would be different for each sample. Therefore, for the baseline model, we will implement a method to have a fixed-size representation for all speech samples. Write a function downsample_spectrogram(X, N) that takes as input a spectrogram $\\mathbf{X} \\in \\mathbb{R}^{T \\times k}$ and a parameter N <= 25. The function should (1) make N equally-sized splits of S across the time-axis, (2) apply a pooling technique (e.g., mean pooling) to each split across the frequency axis to obtain an array that represents a downsampled version of the spectrogram $\\mathbf{X}' \\in \\mathbb{R}^{N \\times k}$, and (3) re-arange $\\mathbf{X}'$ as a vector $\\mathbf{v} \\in \\mathbb{R}^{Nk}$.    \n",
    "\n",
    "2. Using the downsample_spectrogram(X, N) function, transform all the speech samples into vectors $\\mathbf{v} \\in \\mathbb{R}^{Nk}$. \n",
    "\n",
    "3. Given the speaker-based train/dev/test spilts in the SDR_metadata.tsv, fit a linear model on the training samples. That is, your model should be build on data from 4 speakers {'nicolas', 'theo' , 'jackson',  'george'}. Hint: you can experiment with a few model alternatives in the SGDClassifier module in scikit-learn. \n",
    "\n",
    "4. Evaluate you model on the dev and test splits. Use accuracy as an evaluation metric. Analyze the model performance using a [confusion matrix](https://en.wikipedia.org/wiki/Confusion_matrix) of the all possible labels (0-9), Analyze [precision, recall](https://en.wikipedia.org/wiki/Precision_and_recall), [F1-score](https://en.wikipedia.org/wiki/F-score) for each label. Report your observation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78b0e983",
   "metadata": {
    "id": "1bbe63ed"
   },
   "source": [
    "## Baseline Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "40e9a65c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def maxmin(x):\n",
    "    maxi=np.max(x)\n",
    "    mini=np.min(x)\n",
    "    if abs(maxi)>abs(mini):\n",
    "        return maxi\n",
    "    elif abs(maxi)<=abs(mini):\n",
    "        return mini"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dd32810",
   "metadata": {},
   "source": [
    "x=np.random.randn(5)\n",
    "print(\"input array:\\n\",x)\n",
    "print(\"output:\\n\")\n",
    "print(maxmin(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43f6a824",
   "metadata": {},
   "source": [
    "#### Reasoning behind downsampled_spectrogram()\n",
    "for the downsampled_spectrogram() fucntion we have first padded the given signal to a value where its sequence length is divisible by the value of N given. To aggregate the values we have used absolute pooling so that the variation at the maximum level both negative and positve can be preserved[1].\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "06cd84e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def downsample_spectrogram(X, N):\n",
    "    \"\"\"\n",
    "    Given a spectrogram of an arbitrary length/duration (X âˆˆ K x T), \n",
    "    return a downsampled version of the spectrogram v âˆˆ K * N\n",
    "    \"\"\"\n",
    "    # ... your code here\n",
    "    x=X\n",
    "    lrb = N-x.shape[1]%N #remaining values\n",
    "    zp=np.zeros((x.shape[0],lrb))\n",
    "    x=np.concatenate((x,zp),axis=1)\n",
    "    zX = np.zeros((x.shape[0],N))\n",
    "    #number of split\n",
    "    wsn = int(x.shape[1]/N) #within split population\n",
    "    for i in range(x.shape[0]):\n",
    "        for j in range(N):\n",
    "            zX[i,j] = maxmin(x[i,j*wsn:(j+1)*wsn])\n",
    "            \n",
    "    X=torch.tensor(zX).view(1,-1)\n",
    "    X=X.numpy()\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "66a43b9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 325)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "downsample_spectrogram(melspectrogram,25).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "43c41e2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3000it [00:16, 179.74it/s]\n"
     ]
    }
   ],
   "source": [
    "# prepare data and split \n",
    "N=25\n",
    "dummy=np.zeros((1,N*13))\n",
    "datadict = {'TRAIN':dummy,'DEV':dummy,'TEST':dummy}\n",
    "labeldict = {'TRAIN':[],'DEV':[],'TEST':[]}\n",
    "for path,split,label in tqdm(zip(sdr_df['file'],sdr_df['split'],sdr_df['label'])):\n",
    "        x, sr = librosa.load(path, sr=SAMPLING_RATE)\n",
    "        melspectrogram = extract_melspectrogram(x, sr, num_mels=13)\n",
    "        data=downsample_spectrogram(melspectrogram, N)\n",
    "        datadict[split]=np.concatenate((datadict[split],data),axis=0)\n",
    "        labeldict[split].append(label)\n",
    "train_data = datadict['TRAIN'][1:]\n",
    "test_data = datadict['TEST'][1:]\n",
    "val_data = datadict['DEV'][1:]\n",
    "train_y = labeldict['TRAIN'] \n",
    "test_y = labeldict['TEST']\n",
    "val_y = labeldict['DEV']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2a7a5fc",
   "metadata": {},
   "source": [
    "The data produced is normalised using the simple standardscalar() function and the regularisation penalty used is elasticnet [2]. This is because elastic net combines both L1 and L2 regularization methods to balance between the sparsity of the model and the size of the coefficients. To find the optimal hyperparameter we have ran multiple training sessions and evaluated on the validation dataset. We then used the set of hyperparameter with the best validation set error for further training and evaluated the trained model on the test dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "cd2ce521",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy on validation set: 34.80885311871227%\n",
      "The accuracy on train set: 95.39999999999999%\n",
      "the best validation accuracy achieved is:35.2112676056338%\n",
      "\n",
      "the optimal regularisation value acheived is: 0.0001\n",
      "\n",
      "the optimal l1 ratio is :0.35\n",
      "\n",
      "\n",
      "The accuracy on test set: 40.15904572564612%\n",
      "\n",
      "Confusion Matrix onn the test data \n",
      " [[26  0  3  0  0  0  7 15  0  2]\n",
      " [ 0 26  0  0  0  0 18  6  2  3]\n",
      " [ 0  0  8  1  0  1 30 13  1  0]\n",
      " [ 0  0  0  7  1  0 30  1  0  7]\n",
      " [ 0  1  1  2  8  0 17 15  0  2]\n",
      " [ 0  0  0  1  1 13 30  4  0  1]\n",
      " [ 0  0  0  1  0  0 40  2  0  3]\n",
      " [ 0  0  0  1  0  1 14 30  1  0]\n",
      " [ 0  1  1  0  1  1 29  3 19  1]\n",
      " [ 0  1  0  0  0  6 13  4  1 25]]\n",
      "\n",
      "The Classification Report for test set classification\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.49      0.66        53\n",
      "           1       0.90      0.47      0.62        55\n",
      "           2       0.62      0.15      0.24        54\n",
      "           3       0.54      0.15      0.24        46\n",
      "           4       0.73      0.17      0.28        46\n",
      "           5       0.59      0.26      0.36        50\n",
      "           6       0.18      0.87      0.29        46\n",
      "           7       0.32      0.64      0.43        47\n",
      "           8       0.79      0.34      0.47        56\n",
      "           9       0.57      0.50      0.53        50\n",
      "\n",
      "    accuracy                           0.40       503\n",
      "   macro avg       0.62      0.40      0.41       503\n",
      "weighted avg       0.63      0.40      0.42       503\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# train a linear model\n",
    "PPD = StandardScaler()\n",
    "PPD.fit(train_data)\n",
    "Xtrain = PPD.transform(train_data)\n",
    "Xtest = PPD.transform(test_data)\n",
    "Xdev = PPD.transform(val_data)\n",
    "#model defined\n",
    "model1 = SGDClassifier(loss=\"log\",penalty='elasticnet',l1_ratio=0.15,alpha=0.0001,max_iter=1000)\n",
    "#model training\n",
    "model1.fit(Xtrain, train_y)\n",
    "print(f'The accuracy on validation set: {accuracy_score(val_y, model1.predict(Xdev))*100}%')\n",
    "\n",
    "#tuning of hyperparameter using the dev set\n",
    "\n",
    "acc=0\n",
    "lam=0\n",
    "l1r=0\n",
    "lambdas = [0.1,0.01,0.005,0.001,0.0005,0.0001]\n",
    "l1_rat = [0.15,0.25,0.35]\n",
    "\n",
    "\n",
    "for l1_r in l1_rat:\n",
    "    for l in lambdas:\n",
    "        model1 = SGDClassifier(loss=\"log\",penalty='elasticnet',l1_ratio=l1_r,alpha=l,max_iter=1000)\n",
    "        model1.fit(Xtrain, train_y)\n",
    "        if acc < accuracy_score(val_y, model1.predict(Xdev)):\n",
    "            lam=l\n",
    "            l1r=l1_r\n",
    "            acc=accuracy_score(val_y, model1.predict(Xdev))\n",
    "\n",
    "\n",
    "        \n",
    "# model trained with optimal parameter \n",
    "model1 = SGDClassifier(loss=\"log\",penalty='elasticnet',l1_ratio=l1r,alpha=lam,max_iter=1000)   \n",
    "model1.fit(Xtrain, train_y)\n",
    "print(f'The accuracy on train set: {accuracy_score(train_y, model1.predict(Xtrain))*100}%')\n",
    "print(f'the best validation accuracy achieved is:{accuracy_score(val_y, model1.predict(Xdev))*100}%\\n')\n",
    "print(f'the optimal regularisation value acheived is: {lam}\\n')\n",
    "print(f'the optimal l1 ratio is :{l1r}\\n')\n",
    "\n",
    "# evaluate the model using accuracy metric on test set\n",
    "print(f'\\nThe accuracy on test set: {accuracy_score(test_y, model1.predict(Xtest))*100}%')\n",
    "# analyze the confusion matrix of the baseline\n",
    "print('\\nConfusion Matrix onn the test data \\n', confusion_matrix(test_y,model1.predict(Xtest)))\n",
    "# report precision, recall, F1-score for each label\n",
    "print(\"\\nThe Classification Report for test set classification\\n\",classification_report(test_y, model1.predict(Xtest), labels=list(range(10))))\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2991415f",
   "metadata": {},
   "source": [
    "#### Visualization using TSNE [10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "e6af5651",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_emb =tsne(n_components=2,init='random', perplexity=3).fit_transform(Xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "147606ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x196fc50ef88>"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAmYAAAJcCAYAAABTzWhBAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAgAElEQVR4nOzde3yU5Z3//9c1h2TIARIgAQNoFBrloLgYT8VWKkXUb7WeSq1126VUl267a+1vu/Xb79ft+m3d0tr1sD2xtaw9uGptVwVshcUoKukBooIiSASNApGEBEJCkpnM4f79MZkhk8yEJJPMPYf38/HgIbnue+58gjD55Lo+1+cylmUhIiIiIvZz2B2AiIiIiIQpMRMRERFJE0rMRERERNKEEjMRERGRNKHETERERCRNKDETERERSRNKzERExpAxZosx5m/sjkNEMoMSMxFJa8aY431+hYwx3X0+/myC19xmjNljjOkwxhwyxjxjjCnsvfZI73MW9Ln/LGNMoM/HW4wx3n6f+6kx/jpnGWPUWFIkx7nsDkBEZDCWZRVFfm+MaQC+aFnWc4nuN8YsBu4GrrAsa4cxZhJwdb/bjgLfAa4a5FOvtCzrFyONW0RkJDRjJiLZ5nyg1rKsHQCWZbValvULy7I6+9zzMFBtjFmY7CczxnzRGPOSMeYnxphjxpjdxpiPJbjXYYz5Z2PMe8aYZmPML4wx43svv9R7T2SG7vxkYxORzKPETESyzZ+B/2WM+ZYx5sPGmPw49xwHVgH3jNLn/DDwFjAZ+DbwlDGmJM59XwRuARYBM4FS4MHeax+F8Axh769toxSbiGQQJWYiklUsy9oM3Eh45uxZoMUYc68xpv/73U+ADxljliR41E+MMW19fn1rkE/7AfBDy7L8lmU9CrwDXBnnvs8CP7As613LsjqAbwI3x4lNRHKU3gxEJGMZY5z9CvQrACzL+r1lWZ8gPCN1PXArsLzvay3L8hKuM/tOgsf/nWVZJX1+3T1IKAcsy+pbuP8eUBHnvorea33vywPKBnm2iOQQJWYikrEsywr2Wforsiyrsd/1kGVZm4DNwLw4j/g54aTomiRDmd7v41OBxjj3NQKn9buvBzgMaEemiCgxE5HsYoy5zhizzBhTasIuAj5CuPYshmVZfsI7OL+R5Kc9xRjzFWOMyxhzE+H6sQ1x7nsM+JoxptIYU0y4xu0xy7JCQDNgGWPOSDIWEclgSsxEJNu0ASuBvUA78EvgXy3L+k2C+x8hnBT1t7rfMunWQT7nH4G5wBHgX4AbLMs6Gue+h4DfAC8TrkPrAG4H6K05+y7wl96aturBv0wRyUYmtixCRESGwxjzReAWy7IW2R2LiGQ+zZiJiIiIpAklZiIiIiJpQkuZIiIiImlCM2YiIiIiaSIrDjGfPHmyVVlZaXcYIiIiIif1yiuvtFiWFbexdFYkZpWVldTV1dkdhoiIiMhJGWPeS3RNS5kiIiIiaUKJmYiIiEiaUGImIiIikiayosZMREREcovf7+fAgQN4vV67Q0nI4/Ewffp03G73kF+jxExEREQyzoEDByguLqayshJjjN3hDGBZFq2trRw4cIDTTz99yK/TUqaIiIhkHK/Xy6RJk9IyKQMwxjBp0qRhz+gpMRMREZGMlK5JWcRI4lNiJiIiIpImlJiJiIiIjMD+/fv52Mc+xuzZs5k7dy4PPvhg0s9U8b+IiIjICLhcLv7t3/6NBQsW0NHRwXnnnceSJUuYM2fOyJ85ivGJiIiIpKXju2toq32YYMdhnMVllCxcTtHsxUk985RTTuGUU04BoLi4mNmzZ3Pw4MGkEjNblzKNMXcYY940xuw0xjxmjPEYY043xvzFGPO2MeY3xpg8O2MUERGRzHZ8dw1HnnuAYEczYBHsaObIcw9wfHfNqH2OhoYGXnvtNS688MKknmNbYmaMmQb8A1BtWdY8wAncBHwPuN+yrA8BR4EVdsUoIiIima+t9mGsgC9mzAr4aKt9eFSef/z4cW644QYeeOABxo8fn9Sz7C7+dwHjjDEuoAD4ALgM+F3v9V8C19oUm4iIiGSBYMfhYY0Ph9/v54YbbuCzn/0s119/fdLPsy0xsyzrIPAD4H3CCdkx4BWgzbKsQO9tB4Bp8V5vjLnNGFNnjKk7fDj5P1gRERHJTs7ismGND5VlWaxYsYLZs2fzta99LalnRdi5lFkKfBI4HagACoEr49xqxXu9ZVk/syyr2rKs6rKy5P5gRUREJHuVLFyOceXHjBlXPiULlyf13NraWn7961/z/PPPc+6553Luuefyhz/8Ialn2rkr8+PAu5ZlHQYwxjwJfBgoMca4emfNpgONNsYoIiIiGS6y+3K0d2VecsklWFbc+aMRszMxex+4yBhTAHQDi4E64AXgRuBx4PPAWtsiFBERkaxQNHtx0olYKthZY/YXwkX+rwJv9MbyM+AbwNeMMXuBScAau2IUERERSSVbG8xalvUt4Fv9ht8BLrAhHBERERFb2d0uQ0RERER6KTETERERSRNKzERERETShBIzEcl6G2sa+X8PbuTP7z3N211Ps/voH2gP7Lc7LBHJcA8++CDz5s1j7ty5PPDAA6PyTCVmIpLVNtY08vzW17jhc91MLgdjwO3p4ZD3NSVnIjJiO3fu5KGHHmLr1q3s2LGDZ555hrfffjvp5yoxE5GstnpNPdfd7CffEzvucIY4EthlT1AiknIbaxq57ubNLFyygetu3szGmuT61+/evZuLLrqIgoICXC4Xl156KU899VTScSoxE5Gs1nzYy6TJ8a8FrO7UBiMitthY08iq+3bS1OzFsqCp2cuq+3YmlZzNmzePl156idbWVrq6uvjDH/7A/v3Jz8IrMRORrFZe5qG1Jf41lxmX2mBExBar19Tj84Vixny+EKvX1I/4mbNnz+Yb3/gGS5Ys4YorrmD+/Pm4XMm3h1ViJiJZbeWKKp561I3PGzseCjqY6JpjT1AiklLNh73DGh+qFStW8Oqrr/LSSy8xceJEPvShDyX1PLC587+IyGAC/gaC/h1gdYEpwOmej8tdOaxnLF1cAcB//+oNLr+2m0llEPDlMa34bMa7ZoxB1CKSbsrLPDQ1D0zCyss8ce4euubmZsrLy3n//fd58skn+dOf/pTU80CJmYikqYC/gWDPViAYHrC6ej9mRMlZJEEDoGB0YhSRzLByRRWr7tsZs5yZn+9g5YqqpJ57ww030Nraitvt5sc//jGlpaXJhqrETETSU9C/g2hSdmKUoH/HsBMzEcltkR/MVq+pp/mwl/IyDytXVMX+wDYCL7/88miEF0OJmYiknb0tjUz3dGFMnItWV8rjEZHMN2DmPE2p+F9E0srelka2vLeTTn+CtyejdUgRyV5KzEQkrfz5/d0EQyG2N3sIhPpfdeJ0z7cjLBGRlNBSpoikjb0tjfiCfgAa2vMBOLfcS6E7RKffwYSiC1RfJiJZTYmZiKSNuoOxzR4b2vOjCVphnoeb5lfaEJWISOooMRORtFHS1cDCwDuMs3x0m3zedJ3BQddUAKqnJbetXUQkE6jGTETSgrfpVRb491Bg+TBAgeXjr/x7mBY4RJ7TxazJ6b+bSkRyyxe+8AXKy8uZN2/eqD1TiZmIpIXuho04ia32dxFibuBdLj5VRyeJSPr5m7/5GzZs2DCqz9RSpoikhZCvLe74OMvLDM2WiUiSGmo3seOJh+hqbaZgUjnzl91K5cIlST3zox/9KA0NDaMTYC8lZiKSFhz5JXGTM2d+iQ3RiEg2aajdxNY19xLs8QHQ1drE1jX3AiSdnI02LWWKSFoYV7kUHO7YQYc7PC4ikoQdTzwUTcoigj0+djzxkE0RJaYZMxFJC54pC4BwrVnI14Yjv4RxlUuj4yIiI9XV2jyscTspMRORtOGZskCJmIiMuoJJ5XS1NsUdTzdayhQREZGsNn/ZrTjz8mPGnHn5zF92a1LP/cxnPsPFF1/Mnj17mD59OmvWrEnqeaAZMxEREclykQL/0d6V+dhjj41GeDGUmImIiEjWq1y4JO12YMajpUwRERGRNKHETERERCRNKDETERERSRNKzERERETShIr/RUSSFPA3EPTvAKsLTAFO93xc7kq7wxKRDKQZMxGRJAT8DQR7toaTMgCri2DPVgL+BlvjEpHUaGtr48Ybb+Sss85i9uzZ/OlPf0rqeZoxExFJQtC/Awj2HyXo36FZM5EccPvtt3PFFVfwu9/9jp6eHrq6upJ6nhIzEZFkWAnehHvHG2o3jXpTSxEZvkOBRvYF6vHhJR8PM11VTHVVJPXM9vZ2XnrpJX7xi18AkJeXR15eXlLPVGImIpIMUxA3OXvuxSL+Y80GWo5ZFDtu4OKizZzJLrauuRdAyZlICh0KNPJWYCchQgD48PJWYCdAUsnZO++8Q1lZGcuXL2fHjh2cd955PPjggxQWFo74maoxExFJgtM9H3DGjD33Yj4/+HEeLccADB2hCTzffiV7uuYQ7PGx44mH7AhVJGftC9RHk7KIECH2BeqTem4gEODVV1/lS1/6Eq+99hqFhYWsWrUqqWdqxkxE0kamLfvtbWmk7mADnT3jKXRbnFvWyemlbn7+SCE+XyDm3gB5/On4Is4s2EVXa7NNEYvkJh/eYY0P1fTp05k+fToXXnghADfeeGPSiZlmzEQkLTTUbmLrmnvpam0CLLpam9i65l4aajfZHVpce1sa2fLeTjp7wm/sBQVBAkVu9mPRdDgQ9zUdofHheyeVpyxOEYF8PMMaH6qpU6cyY8YM9uzZA0BNTQ1z5sxJ6plKzEQkLex44iGCPb6YsXRe9qs7WE8wFF4aKZsQ4MxpATx5FhiYNDkU9zXFjnacefnMX3ZrKkMVyXkzXVU4+qU8DhzMdFUl/ewf/vCHfPazn+Wcc85h+/btfPOb30zqeVrKFJG0kGh5L12X/SIzZQBnTAng7POe/6nPBfjPH7np8ZnomAs/l57yGhes+HpaL8+KZKNIgf9o78oEOPfcc6mrq0v6ORFKzEQkLRRMKu9dxhw4no4K8zzR5CzfHXvtw4tCgJ/f/srFkRYH5WUeVq44h6WLr059oCIChJOz0UjExpoSMxGx1caaRlavqaep+QsUO9u5uPAFzizYBRBd9ttY08gDP97NsXY/AOOLXdzxlTksXWzfm2z1tCq2vLeTYCiEzw+efq2LPrwoxEc/5qTSs9SeAEUkIykxExHbbKxpZNV9O/H5wjVZHcHxPN9xFQB/NaOV+ctuZY93Lv967xv4A1b0de0dAb7z/dcBbEvOZk0Of966g/W80xSuMeu7nGlwMtGVXBGwiOQeJWYiYpt1W3bxydtDFJXA8Tao2wjv7HCzw/Np/uXBRQDccfPmmKQsIhiE1WvqbZ01mzW5IpqgtQf2cySwi4DVjcuMY6JrDuNdM2yLTUQykxIzEbHF3pZGzv54AHfvEmBxKVxyffj3775+orC++XDiPkODXUu18a4ZSsREJGlqlyEitqg7WB9NyiLceVC9FMrLTvQW6vv7/ga7JiKSiZSYidhs2/oN3HXZtXxl9sXcddm1bFu/we6QUqJvu4m+ikpg5YoTvYVWrqjC7TID7nM6Y+8TEUm1DRs2cOaZZzJr1qykO/5HKDETsdG29Rt49K5VHG08BJbF0cZDPHrXqpxIzgrz4s92uSx3TN3Y0sUVfPPrZzNh/ImeFOOLXfzffzrH1voyEcltwWCQL3/5yzz77LPs2rWLxx57jF27diX9XNWYidho3f2r8XtjZ478Xi/r7l/N+VdfYVNUqdG33USE0+HgktNnD7h36eIKJWEikpRt6zew7v7VHP2gidJTpnDNHSuTep/dunUrs2bN4owzzgDgpptuYu3atUkfyaTETMQGhwKN7AvUs+iZv6Xr0DHe/GENB559I3r96AcDG61mm77tJjp7vBTmeaieVhUdFxEZLZHVicgPwpHVCWDEydnBgweZMePEhp/p06fzl7/8JelYlZiJpNihQCNvBXYSIoRxGAorSljwz+GO8JHkrPSUKXaGmDJ9202IiIyVsVidsKyBbXyMGVgPO1xKzERG2fHdNbTVPkyw4zDO4jJKFi6naPbi6PV9gXpCxB5y7RqXx9y/X8yBZ9/A7fFwzR0rUx22iEjWSrQKkczqxPTp09m/f3/04wMHDlBRkfwPmrYmZsaYEuDnwDzAAr4A7AF+A1QCDcAyy7KO2hSiyLAc313DkecewAr4AAh2NHPkuQc4sPMN9mz5I12tzZQ/9I24P1UVTJ1AacXUpOseREQkVukpU8KbrOKMj9T555/P22+/zbvvvsu0adN4/PHHefTRR5MJE7B/V+aDwAbLss4C5gO7gTuBGsuyPgTU9H4skhHaah+OJmURzU2d7Fj/dO8B3Rah1va4r/U4xvHt559WUiYiMsquuWMlbk/sTvBkVydcLhc/+tGPWLp0KbNnz2bZsmXMnTs32VDtmzEzxowHPgr8DYBlWT1AjzHmk8Ci3tt+CWwGvpH6CEWGL9hxeMDY+41B+mw85PhTmyn+3JU48k90V3XgYKZLPblERMZC5Afe0dyVCXDVVVdx1VVXjUaIUXYuZZ4BHAYeNsbMB14BbgemWJb1AYBlWR8YY8rjvdgYcxtwG8Cpp56amohFTsJZXEawozlmzNcTe4/3L+E+N0XXLcI5aQL5xsNMVxVTXSqCzzSjvf1eRMbO+VdfkRH/Pu1cynQBC4CfWpb1V0Anw1i2tCzrZ5ZlVVuWVV1WVjZWMYoMS8nC5RhXfsxYft7AejLvX3bRcudP6LjzP1noWaSkLAPlcnNgERk7diZmB4ADlmVFmn78jnCi1mSMOQWg97/NCV4vknaKZi9m4se/irO4HDA4i8s5+6Pns2BeHhcvyGPBvDwml574Z9fVqr/emWqw7fciIiNl21KmZVmHjDH7jTFnWpa1B1gM7Or99XlgVe9/19oVo8hIFM1eHG2PcXx3DaHnHsDKD8+aefJh5mkuIEDL0RAFk+Ku1EsGGIvt9yIidvcx+3vgv4wxecA7wHLCs3hPGGNWAO8Dn7IxPpGkxNul6XQaTp3m4minYf6yW22KTJKxbf0GHA5DKDiwwWSuNAcWkbFha2JmWdZ2oDrOpcVxxkQyTrxdmhCuO7tgxdepXLgkxRFJsiK1ZaFgaMA1NQcWkWTZ3cdMJKs5i+NvTHGNL1dSlqF+d8/9A2rLABxOBzd/+86M2PUlIqPD6/VywQUXMH/+fObOncu3vvWtpJ9p91KmSFYrWbg85iQAAOPKp2ThchujssfelsaMP7B82/oNdLYdi3stFLKUlInkmPz8fJ5//nmKiorw+/1ccsklXHnllVx00UUjfqYSM5ExFNkEMNjZmblgb0sjW97bSbC3025nj5ct7+0EyIjkLNqvLM6RLhGqLRNJb96mV+lu2EjI14Yjv4RxlUvxTFmQ1DONMRQVFQHg9/vx+/1JH2SuxExkjPXdpZmr6g7WR5OyiGAoxJ/f3532iVmkpize8mVfqi0TSV/eplfpfPtJCPkBCPnawh9D0slZMBjkvPPOY+/evXz5y1/mwgsvTOp5qjETkTHX2RM/qfEF/extaUxxNMMTr19ZfwUl47WMKZLGuhs2RpOyqJA/PJ4kp9PJ9u3bOXDgAFu3bmXnzp1JPU+JmYiMucI8T8JrdQfrUxjJ8J2sL5nb4+FT/+drKYpGREYi5Gsb1vhIlJSUsGjRIjZsSO70DyVmIjLmqqcNPKC9cAJMPxPKqrzUejdzKJCeM2eD1Y6VVkzVTkyRDODILxnW+FAdPnyYtrZwctfd3c1zzz3HWWedldQzlZiJyJibNbmCPOeJktbCCTB5OrjzwBjw4eWtwM60TM6uuWMlbk/sjJ/b4+Hz9/4L337+aSVlIhlgXOVScLhjBx3u8HgSPvjgAz72sY9xzjnncP7557NkyRI+8YlPJPVMFf+LSEpcfOqc6M7M0qng6PdjYYgQ+wL1aXegeyTxWnf/ao5+0ETpKVO45o6VSshEMkikwH+0d2Wec845vPbaa6MRYpQSMxFJicjuy7qD9bjcCTYDMHiRvV3Ov/oKJWIiGc4zZUHSiVgqaClTRFJm1uQKbpq/CI+Jvxkgn8SbBEREcoFmzERSYPu+RjbV1XOs08uEQg9Lqqs4d2Z6Ldml0kxXFW8FdhLiRG8zBw5mugZuEhARySVKzETG2PZ9jazdshN/76HXxzq9rN0S7nOTq8lZpI5sX6AeH17y8TDTVZV29WUiIqmmxExkjG2qq48mZRH+YIhNdfU5m5hBODlTIhYWPfJJmwtEcp4SM5ExdqwzfkF7onHJLb+5+/u8/PiTYIU/Ptp4iEfvWgWg5EwkB6n4X2SMTSiMX9BuTHiZU3LXtvUbePmxE0lZhN/rZd39q+0JSkSGbM+ePZx77rnRX+PHj+eBBx5I6pmaMRMZY0uqq2JqzCIsi5yvNct1gyVfJzsKSkaHlpElGWeeeSbbt28HwoeZT5s2jeuuuy6pZyoxExljkaTrv196Hav/zIhqzbLetvUb+O0999HV1g5AYckEbvw/d3D+1VcMmnwNdhSUjA4tI+eWvS2N1B2sp7PHS2Geh+ppVdH+iqOhpqaGmTNnctpppyX1HC1liqTAuTMrBiRlEcc6vfzf/9zAvb/ZrKXNLLNt/QZ+/b+/E03KADrbjvHIN+9h2/oNiZMvEz4KSsaOlpFzy96WRra8t5POnnBtb2ePly3v7WRvy+i95z7++ON85jOfSfo5SsxEUiRRrVlEpI2GkrPsse7+1YQCgQHjQb+fdfevjnsOJ8BHbrpeMzZjTMvIuaXuYD3BUGw5STAUou5g/ag8v6enh3Xr1vGpT30q6WcpMRNJkSXVVbidg/+TiyxtSnYY7Bv80Q+aOP/qK7j523dSWjEVjKG0Yiqfv/df+PS3/imFUWavbes3cNdl1/KV2Rdz12XXsm39hug1LSPnlshM2VDHh+vZZ59lwYIFTJmS/N8d1ZiJpEikjmz9lt14A368XfD+LpgwGaaefuI+tdHIHqWnTOFo46GE10DncI6Vbes38Ohdq/B7w/+e+tePJfx/o2XkrFSY54mbhBXmjc4xcI899tioLGOCZsxEUqqpAZ5/IsgLj8Gf1sLBt+GtrXDo3RP3nGzJ006HAo3UejfzvHcDtd7NHApo2XUw19yxEodr4M+/Trdb3/zH2Lr7V0eTsoi+9WNaRs4t1dOqcDpiUx6nw0H1tOSPgevq6mLTpk1cf/31ST8LNGMmklKr19Tj88XWOYSCsG9HeNbM7XSwpDo9zos8FGiMOTJpHAW0cSR63YeXtwLhdh/q4B9f5Bt8ol2ZMnYSLVVGxiN//mqVkRsiuy/HYldmQUEBra2tST8nQomZSAo1H46/TOnrgvYPXHzhpjlp0TrjUKAx5pBxH158DIw9RIh9gXolZoPQUqU9Ei1VOhyGbes3RP+/6P9N7pg1uWJU22OMFS1liqRQeVniZco3/hiiqSF1sQxmX6A+mpSdTLyETcRuiZYqQ8EQj961KmYjQK5qqN3E2tuX8dgti1h7+zIaajfZHZKgxEwkpVauqCI/P/4/O58vxOo16bEjczjJVj7pWxMnuSuy49URZye03+vlt/fcZ0NU6aOhdhNb19xLV2sTYNHV2sTWNfcqOUsDSsxEUmjp4gru/Nq8hNcTLXWm2nCSrZmu9KiJE+nv/KuvIBSK39m5q609p2fNdjzxEMEeX8xYsMfHjicesikiiVBiJpJiSxdXMKU8fuIz2FJnKs10VeEYwttDhZmh+jJJa4P1JMvlDv9drc3DGpfUUWImYoN4S5r5+Q5WrkiP2aeprgrOcs2Lzpzl46HCzCAfD9tfgB8sh7uuhv+9/DAba9QyQ9LXYG1JcrnDf8Gk8mGNS+poV6bIGNi2fsOg2/CXLg7PMq1eU0/zYS/lZR5WrqiKjqeDqa6KAbNhG2saWf+jndGWH03NXlbdF26ZkU6xi0Scf/UV/O6e++lsOzbgWi53+J+/7Fa2rrmX/R2TGO9qp9BxnM5QEaGJF9odWsaprKykuLgYp9OJy+Wirq4uqecpMRMZZSfrOB6xdHFFxiUz8fqwRTYtpMPXsrGmMa2TXbHHgisXhw8s72fepR+2IZr0ULlwCbXPvU7Znj/gdoTPcy1yHsdf/wfW/WwG19y2zOYIM8sLL7zA5MmTR+VZWsoUGWUn6zieyRJtTkiHTQsbaxpZdd9Ompq9WNaJ2TwttcrOF/84rPFc0V3/YjQpi3CbAM0vPmJTRGOrPbCfBu9G9nY/TYN3I+2B/XaHFJdmzESS1H/ZMtLUsvTis6lYthj3pAn4W4/R+NsamyNNXnmZh6bmgUlYOmxaSPfZPLHPyU4ByFUFDFzeHWw8k7UH9nPYvx2LIAABq5vD/u0AjHfNSOrZxhguv/xyjDH87d/+LbfddltSz9OMmUgSIsuWRxsPgWWF/2vCSdmMFVeTN7kEYwx5k0s4dcU17G3J7NmbdN60kM6zeWKvRLVkuVxjBtDFhGGNZ7IjgV3RpCzCIsiRwK6kn11bW8urr77Ks88+y49//GNeeumlpJ6nxEzkJI7vruHAz2/hvfuXcuDnt3B894mZr7Xff2DAsiUWVCxbjDM/L2bYkeem7mB6NJAdqUgftinlHoyBKeUe7vzavLSYkSouir8AkGg8V2ysaeS6mzezcMkGrrt5c04u7SaqJcvlGjOA8ktvwW/F/vvwWy7KL73FpojGTsDqHtb4cFRUhN//ysvLue6669i6dWtSz8vtdyyRkzi+u4Yjzz2AFQg3Ygx2NHPkuQei19sOt8V9nXtS/J84O3syf/YmXTctGGOGNZ4LInV3fXfR3v3d13njzaP84z/MtTm61BmsxuzTKY4lnVxz2zJ+fKAT19tPUuxopyM0nsCHrudzWVj47zLj4iZhLjMuqed2dnYSCoUoLi6ms7OT//mf/+Gf//mfk3qmEjORQbTVPhxNyiKsgI+22ocBGF9kaD8+sLN4sO04rtLiAeOFefbXYmWr9g7/sMZzQby6O4An1+3n7LmlaZlgjwXVmMW3saaR370yDZ/vy9Gx/HYHs2oas+7vxkTXnJgaMwCDk4muOUk9t6mpieuuuw6AQCMcqd0AACAASURBVCDAzTffzBVXXHGSVw1OiZmktfbAfo4EdhGwunGZcUx0zUm6UHM4gh2HBx3/yAX5bHzJS6DPxiaXC043xTQ6HARDJ74pOh0OqqfZX4s1FhpqN7HjiYfoam2mYFI585fdSuXCJSmNIZ03JthlsPq6XNoU0XdTTv/xXJZLG2Yi3zdG+/vJGWecwY4dO0YjxCjVmEnaiuyiiUw/R3bRpHKLs7O4LOG4s7iMvDlnU3z5lZjx4aXLccV5XHl5OZcvuYJLTpsXnSErzPNwyWnzmDU5u97sIH0OQ060MeGGS3ysvX0Zj92yiLW3L8upQ5oTJaWFJbDob7wZvxllqC784k048twxY448Nxd+8SabIkoPubZhZrxrBpWepcwady2VnqUp/SF/ODRjJmkr0S6aZv+rQPJbnIeiZOHymBozAOPKp2Thct48HOTlt31Y89xMmBfulu2y/JR8KB+AWZMrsjIR62+ww5BTOWu2dHEFb7x5lKef2U8oBA4HfOTsEHl199HVG18kaQRSPqNnh5Urqrj7u6/HjDndUH05FJXClvfCpzZk+9/T43OnMuMLV9P42xr8rcdwT5pAxacWc3zuVLtDs5VmmdOTEjNJW4l3y1ij1n/mZIpmLwbCtWbBjsM4i8soWbicotmLeen1zQRM7DJAwLh56YM8culQk5Mdhnx8d03cP7/RtrGmkd9vPEhk9TgUgs2v+HEUz+TMghNb4u1IGk/mZEd4jVQkWX1yXXiWubAknJTN+qvw9WAoRN3B+qxPzDp7vExceA4TF54zYDyXrVxRFbM5BNKn/U0uU2ImaSvRLho40X8mFbNmRbMXx00kjnXGf1NPNJ6tCiaV9y5jDhwfbFfraCVnkWOY4v3kH7DcbGq/GiAmOUuUTKZSNBnr7X1H7x6SREd4jdQ//sNczp5byv7i14m3QTUXkpPCPE/crzPXN+Nkwpm9uUg1ZpK2JrrmYHAmvJ4oadvb0sjjOzazZtsGHt+xeczqaCYUxn9TTzSereYvuxVnXn7MmOVy0XXRQna9+cKgu1qT1fcYpkQsHDzffiV7uk7sviqYVD4qn3+kYhoTQzQpixjtI7yWLq6gKD/x38ux/HeSDqqnVeF0xH67y+bNOMOxdHEFTz26iNpNV/DUo4uUlKUBzZhJ2orMhoVryga2pOjbfyayK/DYpEn4l1wFrnChb2ePly3v7SQUPMxpxQ1gdYEpwOmej8tdmVR8S6qrWLtlJ/7giWUAt9PBkurcerOPLAm+8vhqfEdbsIrH4//wIoKzzuTN4BmEuo9xSsuemNck2u06XInaQfQXII8/HV/EmQW7cOblM3/ZraPy+YcrZpbsJEa7lUP1tCq2vLczZqdwROTfCWRnvVnka6o7WE9nj5fCPA/V06qy8muVzKfETNJaJDmL138m+E6Qtf+xLGYZLXDNDdGkLCIYCvHsjkY2P+zii3/t5uOXdhHsCXdmTiY5O3dm+E19U109xzq9TCj0sKS6KjqeSyoXLuHPRW66+y0XhZxu9lV+ZEBilmi363ANZ/dYR2g8BZOm2NLKA07Mkg04KSKB0W7l0D856S/b681yZTOOpF4wGKS6uppp06bxzDPPJP08JWaS9uL1nwm+E+SVHzwwYDegVTw+7jMKSwxNh5384MeFQCcfv9RP0L8j6Vmzc2dW5GQiFk+iWiVvfmyj3ciu1tGQaFdZPFPKx/HJB58Ylc87EuvuXz3kpMzt8XDNHStHPYZIcrJm24a413Oh3kxktD344IPMnj2b9vb2UXmeaswkI/TvP7PzP34xICkDMB3x/2Ec7z05yecz/PzXvUugVtdYhZvV2gP7afBuZG/30zR4N9Ie2E97YD8Xnenjo3O9XFjlpWzCiY67BQ6Ds7gcCP934se/OmqF//F6lzmd4HYNrHLv7g7Yck7ktvUbuOuya4e0fAlQWjGVm79956gU/ieSqOg914vhJbsF/A34utbi63wMX9daAv6GpJ954MABfv/73/PFL34x+QB7acZMMlKiXXWu2s34P34luE8cIO7vgbqNJ+5pbun9Rm4KxjLErBRp+htZVg5Y3dG+cvnucB2gJw/OnBZOzI505HH+afOYXv3ImMSTaFcZwAM/3s2x9hPHMbV3BFh1386Y1421oS5fllZMHbUWGUMRr95MxfCSzQL+ht4Slt6SGGt0Slq++tWv8v3vf5+Ojo7kg+ylxEwyUqIWDe76cEuEwCUfI1RUzPE2Q91GeKfPiRlFE+CRXSUUut1UT29U3ckwxGv6G29jhtMBM6cGmTNx7E87SHSo+uo19TGJGaT+uJmTLV+6PZ4xnx2LR8XwkmuC/h0w4L0rmFRJyzPPPEN5eTnnnXcemzdvTjLCE5SYSUaav+xWtq65N+5y5oTWVubnl7KnYy6rHoxtnuhyWyy4PLzM1ekPZPVOtLGQuOlvrD9udvDbX7k40vI65WX1tvRGsvu4mW3rNwy6fJnqWbL+VAwvOSVR6UoSJS21tbWsW7eOP/zhD3i9Xtrb27nlllt45JHkVgiUmElGiuyqG+zg7Mre/0aWuYpKYMESE+16DtmzEy1Vh70P1vQ34o+bHfznj9z0+MIJcFOzl3tWvcLhPW9wy98tHfWYErHzuJnIEmYipRVT+fbzT495HCLSyxTET8KSKGn57ne/y3e/+10ANm/ezA9+8IOkkzJQYiYZrHLhkpO2Pei7zJWtO9Hi1329Qov/DSa7zx7VBG2ia86A1iXhtvUQWdL87a9c0aQsImC5+fXaY1wyf1PKWlXYedzMYEuYY7XjUkQSc7rnx9aYhUdxuufbFVJCSswkZ2TrsSzx674gRA/N/ldo9r8yarNo8VqXTHTNiRlrbYm/2bsjWJzSMyrtPG5msOawdtSUieS6SB1Z0L9jVBuNRyxatIhFixaNyrNsT8yMMU6gDjhoWdYnjDGnA48DE4FXgb+2LKvHzhglO2TrTrSh1H0FrO5RO/h9vGtG3GdExqaUbY67hFjsaE/5GZWJNgaMtdJTpsStLyutmKqkTMQmLnflqCViYykd+pjdDuzu8/H3gPsty/oQcBRYYUtUknVmTa7gktPmRWfICvM8XHLa2O8aHGt9j6YaTOTg97G2ckUVLhO7G9JFDxcXbbb9jMpUueaOlbg9sTOxWsIUkaGwdcbMGDMd+F/APcDXjDEGuAy4ufeWXwL/AvzUlgAl62TjTrT4dV/xDXVXZTKWLq7g8J43+PXaY3QEiyl2tHNx0WbmlOxj/rKvj/nnTweRWbF196/m6AdNlJ4yxdYdmCOxt6VR7TREbGD3UuYDwD8BkTNbJgFtlmVF2oYfAKbFe6Ex5jbgNoBTTz11jMMUSV8nzhN9HQv/oPcOdXYtWbf83VIumb+p367Zr9tyRqVdzr/6ioxKxPra29IYs+yf7Yeci6QT2xIzY8wngGbLsl4xxiyKDMe5dWD3SsCyrJ8BPwOorq6Oe49IrojUffVtm9GfwRkt1E+F/rtmj++u4cDPbyHYcRhncRklC5eP2tFMMrrqDtbH1GLCidYyR//0ekbPBIqkOztnzBYC1xhjrgI8wHjCM2glxhhX76zZdCD1h9uJZKi+hfmp6m02FMd313DkuQewAuGGwMGOZo489wCAkrM0lKiFTKevm0fv+l60FcjRxkM8etcq3nn1dV559jm62sJn1RaWTODG/3OHEjaREbCt+N+yrP9tWdZ0y7IqgZuA5y3L+izwAnBj722fB9baFKJIRut/8LtdSRlAW+3D0aQswgr4aKt92KaIZDCJWsjk+zqYOS0QM+b3enn5sSejSRlAZ9sxHvnmPWxbH793oEi2uP/++5k7dy7z5s3jM5/5DN6TnIs7FOmwK7O/bxDeCLCXcM3ZGpvjEZEkBTsOD2tc7FU9rQpHKDYBcwT9zGp4mY9eOLS+f0G/n3X3r054fdv6Ddx12bV8ZfbF3HXZtUriJOMcPHiQf//3f6euro6dO3cSDAZ5/PHHk36u3cX/AFiWtRnY3Pv7d4AL7IxHREaXs7iMYMfAHmbO4jIbopGTmTW5gpZnV7Gv8hK8+cV4fB3MbHiZU1r2YBXFKwWOL1Gj3ciRVf2XRAEtf9pkY02jLc2YU2n7vkY21dVzrNPLhEIPS6qrOHdmcl9jIBCgu7sbt9tNV1cXFRXJ/5mlRWImItmtZOHymBozAOPKp2ThchujkkSO767hlNZ6Tml5a8C1js5+A4YEW7TCjXbjiXdkld/r5dd3/j9AyVmqbaxpjDm+rKnZy6r7wrtwsyU5276vkbVbduIPhr/GY51e1m4Jf40jTc6mTZvGP/7jP3Lqqacybtw4Lr/8ci6//PKkY03HpUwRyTJFsxcz8eNfxVlcDhicxeV0XPr3PNPjZM22DTy+YzN7W7TPJx1ENmpghQZcM658rDOuorRiKhhDacVUPnLT9ThcA3/Gd7rdCRvqJppJCwVD/PLr/8I3Llqqpc0UWr2mPuZMWQCfL8TqNfU2RTT6NtXVR5OyCH8wxKa6kX+NR48eZe3atbz77rs0NjbS2dmpQ8xFJHMUzV4c3YG5t6WRbe/tJBgKz5qoT1b6iLdRAwDjYOLHv8qpsxdzzmfviLl0xoJz+O099w15V2aiI6siOtuOaWlzBLbva+T3f9pFd0+4PrAg381VF80+6YxQvCPUAJoPJ1/Ini6Odcb/WhKND8Vzzz3H6aefTllZuCTj+uuv549//CO33HLLiJ8JSsxExAaD9clKJjHbWNPIAz/ezbH2cKPd8cUu7vjKnKxZjkmFhBsyLCtha5PhNtO95o6VMTVm8fi9Xtbdv1qJ2RBt39fIky+9TqjPsnKXz89TL78BJF6u21iTeKa6vGxoGz0ywYRCT9wkbELhyL/GU089lT//+c90dXUxbtw4ampqqK6uTiZMQEuZImKDhH2yEowPxcaaRv713jeiSRlAe0eA73z/9UG/+UisRBsyRnOjxvlXX8HN374Th3Pwb0GJljxloE119TFJWUQwZA1YrmsP7KfBu5G93U/z45+/nvCZK1dUjXaYtllSXYW73983t9PBkuqRf40XXnghN954IwsWLODss88mFApx2223JRuqZsxEJPUK8zxxk7B8p5vHd2we0fmMq9fU4w8M/M4UDIavadZsaFK1USMyEzbYzFnfzQPb1m/QiQODGGxJru+19sD+mLN1W1os4h+6kz2F/3BixnC0d2Xefffd3H333aMRYpQSMxFJueppVTFnMQI4jKEn6McXDM94dfZ4efHd12nqOMrC0+ee9JmD1cNkU63MWIssV7bVPjzmx2dFEqu+9WkRbo8nunlA7TVOLtFSXeRaxJHArmhSBjBpskXr4YGJ2ZTy7FnGjDh3ZkXSiVgqKDETkZSLzILVHayPzo75gwF6goEB977Vsp8pxaUnnTkrL/MkLGLOplqZVOi7UWOsRerTBpsRS9ReQzVoJyyprhpQYwbgdJiY5br+5+h+6nMB/vNHbnp8J5Kz/HwH1y0rG/HstSRHiZmI2GLW5IqYN/o12xK3RxjKpoCVK6r413vfGLCc6XRmV61MthpsA0GiWrOjHzTh61oLVheYApzu+bjclWMYZfqKzASdbFemy4yLSc4+vCgE+Pndr/JobQn/EHPZ1QX4p+3H3xO+Zzi7pve2NMb8wDXWCZ1lWRgz9KbHqWZZCZr8DUKJmYikhUR1ZzC0TQGRehjtysw+idprlE4pCidlAFYXwZ6tADmdnJ1sqW6ia05MjRnAwkWGa5fMZbxrBntbGnnx3YEbAoaya3pvS2NMicJYt8HxeDy0trYyadKktEzOLMuitbUVj2d4M/ZKzEQkLVRPq4r7DQESH6rd39LFFUrCslC89hpuj4srv/LhfncG8bVu4tAzL45ZXVymG++aAYRrzQJWNy4zjomuOdHxuoOJG64O9gPS3pZGXnr39QGHQIxGG5xEpk+fzoEDBzh8OH3P3PV4PEyfPn1Yr1FiJiJpYdbkCpo6jvJWy/6YcafDQfU0LUXmsr61ZpEatCv/bj7nXXnWgHt7Dh0i2NFM64bvcXTzTyld9CUlaP2Md82IJmL9DZZ8JfoBKTJTlmjRLpk2OINxu92cfvrpY/JsOykxE5G0sfD0uUwpLk1pjYpkhv41aNHasj663t5H+0t/jH4c8raHj5cCJWdDlO90R3dG95foB6R4DaP7GuqMt4QpMRORtNJ/U0Cm+s3d36f2iacJBUM4nA4WLruWT3/rn+wOK2s43fN7a8pO1Eod3/pKuHFdH1bAR1vtw0rMhmBvSyM9CZKysybPSPzvcpyX6aeDyw0BPxw9BJ3Hwpc04z18SsxEREbZb+7+Pi8/9mT041AwFP1YydnoiBT4B/07sEKdBI93EursjHtvwmOmJEbdwfq4y5F5TlfCXoKHAo2UTQfT21TfnQeTe0uquo7BJafNy4oftFJJRzKJiIyy2ieeHta4jIzLXUl+wScJ7J9C62/XJbxvNI+TymaJasHi9ReM2BeojyZlEQ4HTJwKHz39HCVlI6AZM+H47pqUdPkWyRWhYPx6m0Tjo2ljTSOr19TTfNhLeZmHlSuqsn6nauT96sgLP8HydcRcG4vjpLJVopY1g9WI+YifzLncMGt8dv+9GytKzHLc8d01MefiBTuaVSwrkiSH0xE3CTvZod3J2ljTyKr7duLzhT93U7OXVfeF+0jlQnJWNHuxftBMQryj0k5WI5aPJ25ylm+SL/hPdbPadKHELMe11T4cc1gxhItlWzfeCyg5ExmJhcuujakx6zs+llavqY8mZRE+XyinDnFP5XFS2SbeUWknS4Zmuqp4K7CTEH3OvcXBTFdyBf+pblabTpSY5biERbFWSDNnIiMUKfBP9a7MRIe16xB3Garh7oqe6grfuy9Qjw8v+XiY6aqKjo9UvBYcY9msNp0oMctxzuIygh3Nca9ZAR9HXviJEjOREfj0t/4p5Tswy0qg+Wj8cZGxMtVVkXQi1l+ijQjHfV6uu3kzK1dUcem8Q3Q3bCTka8ORX8K4yqV4piwY1TjsoF2ZOa5k4XKMKz/hdcvXwfHdNSmMSERG6tNnbiHPGduHKs/p59NnbrEpIpGRSbTh4HhbuHbynntf5/f//RIhXxsAIV8bnW8/ibfp1VSGOSaUmOW4otmLmfjxrzJgv3MfbbUPpzAiyWXtgf00eDeyt/tpGrwbaQ/sP/mLJOrDk7Zx69n/w+Rx7RgsJo9r59az/4cPT9pmd2giw1I9rQqnI/b7kr8H6jaGfx8IwM+ePSP2RSE/3Q0bUxTh2NFSpkSXKls3fC/udTVnlFRoD+znsH87Vm8n94DVzWH/doCE5/pJLGdxGZdM28Ml0/b0Gy+3KSKRkem7EeG4z8vxtnBS9s6OE/d0dLsHvC4yg5bJNGMmQDg5c3jGx72m5oySCkcCu6JJWYRFkCOBXTZFlHnilSaoj5dkqlmTK7hp/iL+85vwxPdjk7JEHPmZX1CpGTOJKl30pZieZqA39WzhbXo17YtkA1b3sMZloMjst/p4STYZX+yivWPg6QPF4/qd6+lwM65yaYqiGjtKzCRKb+rZydv0Kp1vPwmh8JtYpEgWSKvkzEEeIXrijsvQqY+XZJs7vjKH73z/9Zjz6Z1O+Pvlk3Dkl6T1D5wjocRMYuhNPft0N2yMJmVRIT+de54A0ic5s+Ien5x4XEZGnfEl00SaI8c/amyhvcGNASVmIlkucTGsRfvOR3nlVz9k2odvpnLhkpTGNTAa/7DGZfh0BJtkqqWLK3Lm9AolZiJZLjLVH4/T7eS0ORP445rwEVx2JWeDtcVwmXEpjCRzDWUmLNERbG21DysxE0kTSsxEsty4yqUxNWb9eYryCPb42PHEQ7YlZoPtvJzompPCSDLTYDNhcKJulATLwmqJI5I+lJiJZLlIDVm4pmzgN2bv8XDBfVdr/KO5UmGwnZfqYXZyiWbCjm7+KVbAN+Baf2qJI+kqE3aUjzYlZjIi29ZvYN39qzn6QROlp0zhmjtWcv7VV9gdliQQTc76zZwF/UHe3vo+AAWT7GtCWmQ5KLa6cGIRxHAMF10Ol5YxhyjRjFfI237S16oljqSrjvqn6Dn05+jHkR3lOw9288Lbfo51eplQ6GGmw8trP82e70dKzGTYtq3fwCPfvIegP/wN/mjjIR755j0AGf2PIdtFkrOOPWsxVjfe4z28vfV9Du1rxZmXz/xlt9oSV8DfQInVjemdzXNhUYofQg6K8rWMORTO4jKCHcOd8TTalSm2aQ/s50hgFwGrG5cZx0TXnJjZcW/TqzFJWcTutlKee7uNgOUE4Finl1f8fromlEHjIY42HuLRu1YBmfv9yFhW5m9Fr66uturq6uwOI2d846KldLYdGzBeWDKB7/05888pywUNtZvY8cRDdLU2UzCpnPnLbrWtvszXtRasrgHjFvl4Cq+3IaLM07/G7GScxeVM/+IjYxyVSHz9j18DCAUdPL4mn43PWJSXefjrS9/i0tnvDnjtzxsuoiMwcCY9eKyNjv84UVdZWjGVbz//9Nh8AaPAGPOKZVnV8a5pxkyGLV5SNti4pJ/KhUtsb48RFScpAzAMLcmQ+M2hB5tB85x+QapCExkg3vFrDmeIy6/tZsN6D03NXn749AysQCeLzo79e9wR8MR9pmP8hJiPj37QNLpBp5ASMxGxlymIn5yZgtTHksH6N4c+8PNbEiZnXbs2cbxirpYwxRaJNvtMmnzi9z6/k189f8aAxKzY5Y07YxZqj50YKD1lSvKB2kSHmMuwucfF/4kl0bjIYJzu+YCz/2jvuIxUvAPNIyK9y0TskGhTT2tL7MctxwZ+T7n0DCduZ2zqYvn9eF+qiX7s9ni45o6VyQdqEyVmMmx5+fHf7BONiwzG5a7EmXfBiRkyU4Az7wJc7kpb48p0RbMXM/HjX014Xb3LxC4TXXMw/X4Y83nht7+KXcQrm+zEkV8ChBtlF575aS665Bo+eck8JhSGk7YJhR7Om+im6NhhMIbSiqnc/O07M7bwH7SUKSPQeSz+FvxE4yIn43JXKhEbA0WzF/fWnQ1c0lTvMrFLZPdlZFfmm2v38Ny9zxPqPMZc5wQaxy+ma+K5fOnWeZReePmA1587s4JzZ8Yez3T9pzI3EetPiZkMW+kpUzjaeCjuuIik3t6WRuoO1tPZ46Uwz0P1tCpmTQ5/4ypZuHzAjk31LhO7jXfNYLxrBtvWb2DzqmexvF4MkB88xmlt6znvmlNz5mzM/rSUKcN2zR0rcXti1/4zfU1fJFPtbWlky3s76ezxAtDZ42XLezvZ29IInFjSdBaXE+5dVs7Ej3+VotmLORRopNa7mee9G6j1buZQoNHGr0Ry0br7V+P3emPGHJafhk2P2xSR/TRjJsMWWbtX538R+9UdrCcYCsWMBUMh6g7WR2fN+u/YBDgUaOStwE5ChF/rw8tbgZ0ATHXl5kyFpF6ithaZ3O4iWUrMZETOv/oKJWIiaSAyUzbU8Yh9gfpoUhYRIsS+QL0SM0kZlcYMpKVMEZEMdSjQiMsd/1ph3uDta3zET9wSjYuMBZXGDKTETEQkA0WWIkumgDGx15wOB9XTqgZ9fT6JEzfVmkmqnH/1Fdz87TsprZiaNe0ukqWlTBGRDBRZiiwuDX98tAmCfnC5YeH0edH6skRmuqrYFXg94bOnuirYtn6DakllzKk0JpYSMxGRDNR3ybG4lGiCBjDLc/IasamuioSJmQ8v29Zv4NG7VkV3zB1tPMSjd60C0DdRkTGkpUwRkQyUaClysCXK/lzEL1Bz4Y7bxsDv9bLu/tVDD1JEhk2JmYhIBprpqsLR7y3cgYOZrsFry/qysBKOq42BiD2UmImIZKCprgrOcs2LzpDl4+Es17xhtboIEkg4nqhdQS63MRBJBdWYiYhkqKmuiqR6juXjidseI59wu4K+NWagNgYiqaDETEQkR810VcV0/4cTy6FTrw4nfNqVKZJaSsxERHJUZLZtX6AeH17y8YSTst5xtTEQST3bEjNjzAzgV8BUIAT8zLKsB40xE4HfAJVAA7DMsqyjdsUpIpLNkl0OFZHRZWfxfwD4/yzLmg1cBHzZGDMHuBOosSzrQ0BN78dis23rN3DXZdfyldkXc9dl17Jt/Qa7QxIREck6ts2YWZb1AfBB7+87jDG7gWnAJ4FFvbf9EtgMfMOGEKWXGk2KZK6NNY2sXlNP82Ev5WUeVq6oYulizZCJpCtjWfH72KQ0CGMqgZeAecD7lmWV9Ll21LKs0jivuQ24DeDUU08977333ktNsDnorsuu5WjjoQHjBSXjyS8oUGGwSJraWNPIqvt24vOdKO5fsBiu+5Ib4/EPqCkTkdQwxrxiWVZ1vGu29zEzxhQB/w181bKs9qG+zrKsn1mWVW1ZVnVZWdnYBSgJG0p2tbWHEzbLis6iaYlTJH2sXlMfk5Sdcyl84ktgPH4gfPTSW4GdOrRcJI3YmpgZY9yEk7L/sizryd7hJmPMKb3XTwGa7YpPwobaUFLHtYikl+bDsT3Klnwe8vqd2BQixL5AfQqjEpHB2JaYGWMMsAbYbVnWfX0urQM+3/v7zwNrUx2bxBpOQ0kd1yKSPsrLYrOwksnx74vXZDZTHAo0UuvdzPPeDdR6N2v2TzKenTNmC4G/Bi4zxmzv/XUVsApYYox5G1jS+7HYaDh1Y+l8XIu36VWO/uW7tL70DY7+5bt4m161OySRMbVyRRX5+Sfe5tta4t83nIPP08mhQCNv+t6IJpY+vLzpe0PJmWQ0O3dlbgFMgsuLUxmLnFxpxdS4GwBimOHNrqWSt+lVOt9+EkLh2pqQry38MeCZssDO0ETGTGT35eo19TQ1e9n0S7j272OXM3u8MKdo6Aefp5M3j+/GeGI3sBmnxZvHdzO1RBsaJDPZXvwvmeGaO1bi9gz+U/VHbro+bXdldjdsjCZlUSF/eFwkiy1dXMFTjy5iVi6VNQAAIABJREFUSrmH11+Ep38IR5vBCoX/+/wvXZm7KzPfP7xxkQygI5lkSCIJV+TcvIIJxRgMncfaM6JVRsjXNqxxkWyzckUVq+7byesvhnj9xfBYfr6DO782x97AktB2GErL449zasrDERkVSsxkyDL53DyfVUy+6Rgw7g0V0uDdSMDqxmXGMdE1h/GuGTZEKDK2+i5rZkuz2b885eKyzwcGLM3+5SkXN9xuX1wiyVBiJjnhVzWn89cf3Ykn70RPJ2+Pg1+8eCqfvrAbgIDVzWH/dgAlZ5J1vE2vckHRRqpXtuHIL2Fc5VI8UzI3KQNYPG8O63/6Oh/7bHjHaVsLvPBfcPUFmTsLKKLETEbF8d01tNU+TLDjMM7iMkoWLqdodvrs4Vj/p0kcO3Ymn1v8DpMn+Gg5ls+vas7gxV1T+DS+6H0WQY4Edikxk6ySrZtforOAd2bPLKCIEjNJ2vHdNRx57gGsQDjBCXY0c+S5BwBsS872tjTy5/d34wuGvxF99v/CH9dNZcW/T425b1JZaMBrA1Z3SmIUSZXBNr9kcmIG4eRMiZhkE+3KlKS11T4cTcoirICPttqHbYlnb0sjLze8EU3KAPIL4KM3whnzT9yXlw+f+lxgwOtdZlwqwhRJGW1+EckcSswkacGOw8MaH2t1B+sJWdaAcacLLrwKjIEp5R6+evs0Fi6KbaVncDLRpfoUyS6O/JJhjYuIfbSUKUlzFpcR7Bh4pKmz2J7D5Tt7Eh8vUzAeajed2FnaHijhSGCXdmVKVhtXuTSmxgwAh5txlUvtC0pE4lJiJkkrWbg8psYMIOhwETjnWlviKczzJEzOCvud4DzeNUOJmGS9SB1Zd8NGQr6+uzIzu75MJBspMZOkFc1eTFPHUfx1j+PxtePNL2bvaZfQ4hyP1dLIrMmpLcytnlbFyw1vxCxnOo3FRE+QOVMz8+gZkWR5pixQIiaSAZSYyajYlj+ZzvO/GDsYClF3sD7lidmsyRWEgod5pfEgXQFDoSvEueXdnDYhiDu/J6WxiIh9Gmo3seOJh+hqbaZgUjnzl91K5cIldoclMiglZjIqEi0dDlbvNZZOK27gtKquAeNB/w5c7srUByRpL9178cnwNNRuYuuaewn2hEssulqb2LrmXgAlZ5LWtCtTRkX/2q2TjY85a2BSNui45LRIL77wJhYr2ovv+O4au0OTEdrxxEPRpCwi2OOj7lf/blNEIkOjxExGRfW0KpyO2L9OToeD6ml21XS54w+bgtSGIRkh3XrxSfK6WgfuFAfwd7bTULsJCM+qrb19GY/dsoi1ty+LjovYSUuZMioidWR1B+vp7PFSmOehelpVyuvLAAL+BiAY54rB6Z4fZ1xy1Ynly/jfxO3qxSfJK5hUTldrU9xrO554CEBLnZKWlJjJqJk1ucKWRKy/oH8HMPCoJXCrvizHBPwN4b8PVheYApzu+dG/A/2PEovHrl58krz5y27lTz/9TtxrXa3NCZc6dzzxkBIzsZUSM8k+CevItCMzlwT8DQR7thKdPbW6ej8Gl7sy7vJlX8aVT8nC5SmIVFItPJsWf5Y00bhIqqjGTLJPojoy1ZfllPDMaf8l7WDv+ODLlM7iciZ+/KvalZnBIsuV8cxfdisFk8rjXks0LpIqmjGTrON0z4+dKQmPqr4s15xkZ27io8TKmf7FR8YyspyXitYkg818RZYq+9aYATjz8pm/7NZRjUNkuDRjJlnH5a7EmXfBiRkyU4Az7wLVl+WaBDOkgVA+ED5KzLjyY1+i5csxl6rWJIlnxKYA4eTsghVf7/3YUDBpChes+Lrqy8R2mjGTrORyVyoRy3FO93z8vr/gMCc2ggRCsPUDF6fu/h35rz8drjEzDrBCOIvL1VQ2BRK1Jjnywk9G9c9+/rJbTzojVrlwiRIxSTtKzEQkK7nclfz5/V3MnthBoTtEp9/B9mYP3Xv3YfZuIhgKhG+0QtGZMiVlYy9ebd/h1gDvN7ZQe8ulFEyaMipHJ0VeP9IjmXSck9hFiZmIZK09RxzsOTIhZmzhe1twRpKyXpFmskrMRq49sJ8jgV0ErG5cZhwTXXMY75ox4L7+tX2HWwPsey9IyAp/PJr9xPonZ5ENASd7ro5zEjupxkxEsla8I8E8vo6496qZ7Mi1B/Zz2L+dgNUNQMDq5rB/O+2B/QPu7V/D937jiaQsItJPLFmRBCvcaNaKJlgn6/A/WI8zkbGmxExEsla8o8K8+ePj32wM792/lAM/v0VnZA7TkcAurH6tSSyCHAnsGnBv0ezFODwn/h/4ErQXHI1+YiNNsNTjTOykxExEstasyRVcctq86MxZYZ4Hd/VNA3ZjAmCF0AHmIxOZKRvqeOmiL0X/H+TnxX/maPQTG2mClfBzG/jd316tszVlTKnGTESyWryjwo4Xl0b7aGFMb1J2gmrOhsdlxsVNwlxmXNz7I3+ubbUPc2rFB+x7P0ioz3rmaPUTS3Re5smSvng7OgGwLPyd7YDqzmTsKDHLQXtbGtPisHERuxTNXkzR7MUc311D64bvxb1HNWdDN9E1h8P+7QOWM0NWkPbA/ribACL/D6YDk8doB+RQWmbEE/ncf/6Pf8UKxTt3N0xna8r/z969h0d13ffC/66ZPRdJCAQChIWx5QiEjbFFsIydYMduMMVJjk2Sk9K0p02Pj0uOz9tL4jxvmrg97WneNidu3cZJTvvGNSU5b9qTJjTFt9Y1kUmxjWoMgkiAuQgUywYUhCQugpHmsves94+ZPZrL3ntmpJnZe898P8/jx5q198wsRprZv1nrt36rHBiY1ZjTY8PY++5RaMkPm1A0jL3vHgUABmdUU/RCp2a4gXnh9MBrNHYYErFUexxRjMb6Ms4xUq56YjMpmZFeJgOQpufpmHdGpcbArMb0nhtIBWU6LR7HvveOMzCjmmK1iTl3ACjeXGVZslxGLKNdXwRgFZiVUzFB34HvPo3Tu58v6vG5tyaVGgOzGhOKhg3bI1oMp8eGGZyRY107vhuX9nwb8XAix0cEGrHgF/6vGeeBGe2TqeMG5sVJr2FmRJVTplOaTjHU0110UMa9NakcuCqzxhjVddL1nhuoYE+ICnft+G6M//gvU0EZAMjIVYzv+ouZr54UJh9/wsOgrAjZNczMmNU1c4r8NcoE/HPmwdcwF9xbk8qJI2Y1pmtpB15757DhMbPRNCK7Xe75LpBVrR8AILWZr56UJkndZu1kyKiGmRG7pzTzscoVq29uweZv7qhgb6iWccSsxixf2Aq/1zgeFwC2H3gFP+jfg9Njw5XtGJEFqxWSM1096W00zg0yaydj+UbKZnpupVnlinG6kiqJgVkN+sANq3KqoQPT649C0TBee+cwet55u7Ido4oa6unGC5/b4opimVYrJGe6erJp/SM5hWaZ9F88s1plsz230jq3bIXXn1t4ePmGj3O6kiqKU5k1SE/w12uZCRgvCj8xdgYtjfO5IKDKDPV04+Df/S9Er11JtTm9WGbT+kcw/uO/zJ3OFN4ZB1LpRU61q6PwNi5C0/pHmF9WJOMaZiL5f5nW4sUCZVVF+1aMmZTWICoHIWX+Oi1O19XVJXt7e+3uhmttP/CK6bEGfxCf7ry/cp2hkshYJRcROPPcXpzffQC+hkZokSnE1Zjh/ZycS1PqVZlUOul/b4qoSwVg2W1OzS8jqjQhxEEpZZfRMY6YERr8QdPEfy4IcB99lVxqBCMg0fqJdYhevYKL+09a3tfJxTL1SvHkPHOVZYZBFwMxouIxx4zQtbTD9JhVeQ1yJqNVct6AD9d/4p6892WxTCIiezEwIyxf2IqbF+Z+s/V6PJZBGzmT2co3f3Oj5f1YLJOIyH4MzAgAsP6mW3HfTbenRsga/EHcc+NqJv67kNnKt+j4VdP7+BrmslgmEZEDMMeMUpYvbGUgVgWMVslpkRjOPrcXACC8Xvjq5iB6bYIrz4hscHpsOLUqvsEfRNfSDn72UgoDM6Iqoydcp6/KHH5uPy7uH0B9cwsDMaIK6xscRnfvAK6Ewmio86FhYQwNTYljoWgYe989CgAMzggAAzOiqpSxSq4OWP7IZoB1U6vSrt3DeGb7AC6MhrF4URCPPdqBTRtKc4Ev52PXir7BYbyw9yhiWmKrr9BUDJNngbgEGucnztHicfSeG2BgRgAYmBERudau3cN48utHEYkkLvojF8J48uuJ0ZfZBFC7dg/jG399HFcmpuvdleqxa01370AqKNNJCVwamQ7MAJYmomkMzIiIXOqZ7QOpoEwXicTxzPaBGQVPu3YP4+m/OoaJqwYbxs/ysaud2ejilZBxwKVl1XgOeH34Qf8e5p0RAzMiIre6MGp80R+5UPzoS/boW7HPWcuMRi6/8rXDOPL2JcxrCRoGZ17f9M8eIRDVYogko7VQNIzdA4fxlScP49owp5BrDctlEBG51OJF5gWgd+0eLuqxjEbfin3OWmX22u188QyWBBfB58281Hq9AtctTYyLNPiDUDzenP2KFR9wxy9OTyEX+/sk9zINzIQQXiHEfxVC/IkQYn3Wsf9e/q4REZGVxx41LwD9zPaBoh6rkJGwQMBj+Zy1yuq12/nDUWy+ZzXmNSQC2nkNQXzintvw2IcfwKN3PohPd96PqGY8dTwnuXJTn0Km2mA1lfk3AOoB7AfwLSHEa1LKLySPfRLAn5a7c0REZG7ThlZ85WuHDY8VO+W4eFHQcgp0bqOCx397FafUDFi9dhdGw1jT3oo17eavm9l+xdcuZz4O1Qarqcx1UspflVJ+A8BdAOYIIXYKIQIARGW6R0REVloWG08tFjvl+NijHQgEci8J8+b68D+euB2vPPcAgzITVqOIRr+H02PD+EH/Hmw/8Ap+0L8Hy+YugteT+drHokDvLuvHoepkNWLm13+QUqoAPiuE+CMAPwEwp9wdIyKi/B57tCMnaX8mU4560FWqumXhkUOYGtqFeOQyEt/lJTyBJtS1bUKwZe2MHtOpNm1oxZG3L2Hni2cy2o1+D6fHhrH33aPQ4sm6ZtEwTl08hxULluLMxChCkTCuXQEOvAL8rN/8cah6CSmzUw6TB4T4ewB/L6V8Jav9NwF8W0rpM7yjDbq6umRvb6/d3SAiskWhhWArVTA2PHIIoVM7gXgs96DHh4YVn6y64Awwfn2BzGB3zQMqrr8tN6eswR/EpzvvN30cjlZWFyHEQSlll+Exs8DMbkKIBwF8E4AXwN9KKZ80O5eBGRHVunwXc6NyGIGAB1/+wuqSX/QvvfW15EiZMU+gCfPveqKkz+kk+u/CKO/M6wPu+QSw/P2593v0zgcr0DtyAqvAzJHlMoQQXgB/DeAjAFYB+BUhxCp7e0VE5Ex60DVyIQwpjUssWBWjLTWroKyQ426W/rswosWA3h/ntjf4mUNGCY4MzACsA3BaSvkzKWUUwA8AbLa5T0REjmQWdH3jr4+nbput6ivHaj9PoGlWx92skHpwoay41OvxoGspc8gowamB2VIA6VmUZ5NtKUKIzwoheoUQvaOjoxXtHBGRnSbUMxgK78LpqecxFN6F991yzfC8KxOx1KiZ2aq+cqz2q2vbBHhM0pA9vsTxKlVIoNu80JcaIWvwB3HPjau5/RKl5N2SKVlctk9KGRJC/BqAtQC+KaV8t4z9MirHkZEMJ6V8FsCzQCLHrIx9oSo3oZ7BRfUYVDkFRdRhgbIKc5VldneLyNCEegajsT5IaAAAVU7h0d9JHHvztdyPdH1vy1Kt3iyEnthfK6sy0+WrBxcIePDbW2/Bpk4GYmSskL0yvw2gUwjRCeD3AGwH8D0A95WxX2cBpF8ZrwfA/Sio5IwucqOxPgBgcEaOdFE9lvp71fkDwC99RjUMzPQRnFKXw8gn2LK2qgMwM0YBsK5lMVdYUn6FBGaqlFIKITYjMVK2XQjxG2Xu1wEAK4QQNwE4B+DTAH61zM9JNcjoIieh4aJ6jIEZOZIqpwzbmxcan58+VblpQyuDgjKrdABM1aeQwOyqEOIJAL8G4EPJFZNlrWEmpVSFEL8NYBcS5TK+I6V8u5zPSbXJ7CJn1k5kN0XUGf59qlE/AgFPRaYqyRoDYJqNQgKzX0ZitOpRKeV5IcQNAJ4qb7cAKeXLAF4u9/NQbUu/yPnGRlF37j14olFIfwDhm26oyakYcrYFyqqM6XcAEPBiaeNt+PIXvBypsaDGhqDF+gE5CYh6eH2dUHxtdneLKINjC8wWgwVmaab0HDNl7Dwa3v0ZRDwzL0Qo9ahvf4gBGjlK9oIV7Wcajv7N/8bk+AXUNy9G55ataFu/0e5uOooaG4IW3Q9kpC544fWvY3BGFWdVYNZ0xEwIsVdKeY8Q4ioyV0QKAFJKObfE/SQqG7OVl3oeWeTctpygDACkOonQyR8idPKHNbGijNwh/W93qKcbB7f/JbRoBAAwOT6C/dsTkxoMzqZpsX4gK58U0KDF+hmYkaOYBmZSynuS/2+sXHfIzZw6TZBv5eVcZRnGkxc1K/HI5cT+fwCDM3KM/h3bUkGZTotGsO9v/icABmcpcrK4diKb5C0wK4R4wKCt3KsyyWVS0wT6h5ychBbdDzU2ZGu/APOVl2OhNxEeOQSgiErk8RimhnaVuotEMzY5fsGwXcbj2L/9KQz1dFe4Rw4l6k0POeFzikhXSOX/PxJCfFsI0SCEaBFCvATgoXJ3jNzFaprAbmYrLOM+H0KndiI8csi6Unn2/ap4nz9yj6GebrzwuS3Iqr2dQYtG0L9jW+U65WBeX6fpMSd8ThHpCgnM7gMwCKAPwF4A35dSfqqsvSL3cfA0gSLqDNs90UhqBCzYshYNKz4JeI3PzbhfFe/zR+4w1NON/dufwuT4SN5zzUbUao1lWoUDPqeIdIWUy5gP4C4kgrPrAdwohBCyGpZzUumIeuMPN1GfnOY8CCCabPTB6+8y/KAsR56aUXkBaBqCZ98DMD0CplcqD48cSttKJkuV7/NH7mCUV2amvnlxmXvjIhafU0ROUUhgtg/Ak1LK7wgh6gD8GYAeAB8sa8/IVYSnFVI7bXBkDrToWwDSVzzGoEX3Acj8FpuznD2Zp5Z9XrH01WtjoTcR9/ngiUYQPPseAhfHAeSOgKVvJZMepHFVJjlFoaNgXn8AnVu2lrk37uH1dRqXzLCY5iSqtEICsweklO8BgJRyCsDvCiE+VN5ukdvIuMlWpnIUxjkwMmeZer7l7EM93ejfsS1vraa+wWF09w7gSiiMeQ1BbOzqwJr2ZfCHRxE6shOIx6ZPzjMCVqv7/ZGz1TcvNpzG9M+ZByUQZD0zE/rnjRNXjxPp8gZmUsr3hBDzAawAEMx3PtUo0xwNixnv7PtY5KnpOTX5ajX1DQ7jhb1HEdMSI3RXQmG8sPcoAGBNeyLA4ggYuV3nlq0Z7wcgMTp2x6//DgOxPBRfG3a/7sfTf3UME1dVACcwb+4gPv9bt3CXBHKEvIGZEOI3AXwOifyyPgB3A3gTwIfL2zWyW1H5Xma5G4l6xOb3KeQxRL1prab+HdtSF6K+wWH80+uHkZ39GNPi6O4dwJr2Vo6AUVXQ/+YLGUGmTLt2D+NP//wwtLTB+SsTMfzPp44AAIMzsl0hU5mfA3AngH1Syl8QQtwM4Cvl7RbZrdh8L7PcDeG9CVL7GTJzzABA5OR1WOV/TI4/bdhPPddGHykzW5JyJRQ2PkDkUm3rN5YtEBsffx1XlPOJnMxYDPPUJWhuro4Mlme2D2QEZbqYKvHM9gEGZmS7QgKzsJQyLISAECIgpTwhhFhZ9p5RxWWMkBmOdJlvX2KVu6HGFhW0KtPqMcxyavQVZ929A6npSyPzGjgLT1SI8fHXcSkwCnj9AIC4349L3lFg/HVXB2d6jurIhUeQ+HzLdWGUX+DIfoUEZmeFEE0AngfQLYS4BMAk05vcKDE61gsgLSnebPrRot6P4mszDdoKTa41O9csp0ZfcWY1IubzerCxq6Og5yeqdVeU86mgLMXrxRXlPJrt6dKspeeoNnomcDU+z/C8xYv4BY7sV0jy/yeSP/6xEOLfAMwD8EpZe0UVkzNlmY9N9X7y5dTMawgaBmdCAJvvWY017ZyeICpE3Ge8A4ZZuxuk56h+YM4edE98DDLr8udTBB57lF/gyH6FjJilSClfK1dHqLIypy0LZW+9H6ucmpXLFmH/iTMZbT6vh0EZUZE8sRjifr9hu5ukl9dJnwFYWX8MAPDaxEZEUAdAYN5cH1dlkmMUFZhRdShulCyZa+bgej99g8P46alzOe3vX7GUQRlRkeapSxI5ZV7vdKOmYZ66xL5OFSm7vE62lfXHsLL+GOqbW7D5mzsq3DsiawzMapBxIVcjXnj96xwZjKUzS/w/eWbUht4QuVtz84cAl6/KLGTLKu6KQE7FwKwWFTR96YfXf4fjgzLAPPGfJTKIZqa5+UOuTfQH8m1ZJVj3jRyNgVktMi0GC0dPWZoxS/xvbHBvsjK5H/dZtY95eR1OXZbLeXUYg+oAIggjgCDalQ4sUZhKMhMMzGqQaSFXF0xbGtnY1YHn9x6Bqk0n+Hq8wA23x3BeHXb8hwMv4NUnPHIIoVPT+7LGI5cROvlDxK68i8aOT+S5NxUrOyi48T9+CgP/+29Ny+tQaZ1Xh3FMPZy6HUE4ddvpn79O5LG7A1R5iq8NXv+66dIXot61QRkArGlvxap1XgSS/5xAPXDzOqDlJmBQHbC3c3noF/B45DKA5AX81E6ERw7Z3DOajamhXamgLF30/D7+bkvsvDqME+pRRJAYNY8gjMvrmtDxn38T9c0tSExdtmDdo1/k1GWZnFSPFdVO1jhiVqOKKfrqBgtvUrHwptx2/cPaqQwv4PEYpoZ2cdTMxfRA2wh/t6U1qA4gnrXlWxxxhNYtxuYPcdqyEjSoRbWTNY6YUVUIwLhit1m7U5hdwK0u7OR8nkCT6TH+bkvL7MuX07+UEZlhYEZVoV3pgCfrz9kDD9oVZ1fyNruAW13Yyfnq2jaZHuPvtrTc+qWsmigwXmhl1k7WGJhRVViitOJmZXXqwziAIG5WVjs+8bSubRPgyfrw8vgsL+zkfMGWtfAvuTv3AH+3JVfqL2XhkUO49NbXMP76l3Dpra8xJ7AAHcotEFkbwwsIdCi32NQjd2OOGVWNJUqr4wOxbHqukb4q82zgJhzzvQ+T711Aw/k96FrageUL3fVvooTGjk8gPO9GrrgtsWvHd+Nyz3ehXR2Ft3ERmtY/gptXrC5JqYbwyCGEBn4EyMSK9XjkcuI2wN+bBf21ZrmM0hBSyvxnOVxXV5fs7e21uxtEs3J6bBh73z0KLT6dyOz1eHDPjasZnNWw9D0fa70w6rXju3Hx1W9AqtNlMIQSwIIHPo85t2yY9eNf/PevQKq5NR6FUo8FH/wfs358Ip0Q4qCUssvoGKcyiRyi99xARlAGAFo8jt5zzi75QeWj7/mYKJYqMTk+gv3bn8JQT7fdXbPFxX/7fzOCMgCQagSXe75bksc3Csqs2onKgYEZkUOEosaryMzaqfoZ7fmoRSPo37HNph7Z59rx3ZCRq4bHtKvcF5eqB3PMyJX6BofR3TuAK6Ew5jUEsbGrA2va3T3d1+APGgZhDf7SrS6rxtetmhltK2TVXs0u95gHo97GRaV5Em8doE0ZtxNVCEfMyHX6Bofxwt6jqf0xr4TCeGHvUfQNDtvcs9npWtoBrydrdVlcxW0iWpLHr9bXrZoJj/FHtFl7tVJjQ9CuXjQ93rT+kZI8T8Pyh5F7WfQk24kqgyNm5DrdvQOIaZm5WDEtju7eAVeP/ixf2IrI8FH0TUwg7G9EMHIV7UNvoPHyEN4GcET6EYqG0eAPzmi1ZrW+btVMZuUc5muvVlqsH545DYhfC+Uc8wTnliTxH8hdJc2VtGQHBmbkOvqIT6HtbnHt+G7M+cnXcY/MvOgOL1yJ41NRxD2J9lA0jL3vHgWAooKzan3dqll9c4vhtGViD8gaIicx5847MPFGD6Bq0+2KF/Pv/28lfapgy1oGYmSr2hoPp6owr8E858qt03J6GQDI3JGQwbZ7EfdkfoeayWpNs9fN6vUke3Vu2QqvP5DR5vUH0Lllq009somoR/2Kdsy9dz08cxoAAJ45DZj7oQ+XbLSMyCk4Ykaus7GrAz967bDhMbdOy13u+W5OGQBdONBo2F7sas2NXR14Ye/RjOlMn9eDjV0dGYsC6gM+SCkxFVW5QMBmer2yWq9j5vV1QovuR/2KdtSvaNdb4fWvs7VfROXAwIxcZ017q2lg5tZpOavl/sHoVYQDc3Pai12tqQdX3fuP4sqUhkYljHtbRqBeacC/HAmlArbJSCx1H32BQPr9qbLa1m+suUAsm+JrA5DINYOcBEQ9vL7OVDtRNWFgRq40ryFoGIS5dVrO27gI2tULuQeEB2vmNuFADDk7AnQtLX4vwJvnnMeyZa8D8eng62+PLkFMM3/dyrlAgOU7qFCKr42BGNUE5piRK23s6oDPm/nnq0/LuVHT+kcglMxcIqEE0Lzpi7j19l/EPTeuTo2QNfiDM96maWpoV0ZQBgBX1YDJ2dPKMRLJ8h1ERLk4YkaulJqWq5LRFj2BOXtzZr19+cLWjEDs2vHdOPv87xmeayUeuZzT1qiEcVW1LqBZjpFIs/Id//LmMdf+Hktp1+5hPLN9ABdGw1i8KIjHHu3Apg18XYiqHQMzcq017a1VdQGfc8uGgoKr7I2ctasXEis6gbz39wSacoKz9Qt+hldHb4YqvYb3KddIpNko3FRURd/gcFX9bou1a/cwnvz6UUQiicB15EIYT349kevnxOCs5523cXLsDCQAAWDlwmVYf9OtdneLyJUYmJGp8MghFlp0IKMVnPpGznpgdu34bsPRt7q2TQid2pkxnXlL0yUEW5vwb6diFV2VaZYnCGSurq3FPLRntg+kgjJdJBLHM9sHHBeY9bzzNk6MnUndlkB4W5psAAAgAElEQVTqNoMzouIxMHOZ8+owBtUBRBBGAEG0Kx1YopT+gzo8cgihgR8BMlHMMR65nLgNOCI46xscxsv7jqdWENb5FXzsA6uq/oINmK/g1K6O4trx3bi059uIhyfS2nNH1LID7q6Wteiq8K/VquyJHrDpeWj6lKeTV4meV4dxUj0GDSoAQIEPHcotM3p/Xhg1DljN2u10Mi0oy25nYEZUPAZmLnJeHcYJ9SjiSFykIgjjhJq4SJU6OJscfCkVlKVIDZODL9kemPUNDuO5N45Ai8tU21RUxc7XExd5p12wS81sBacIzMmY4kyXPqLmlMrma9pbM4LrdHpOm1u2kTqvDuOYmhlkqojhuHoEQPHvz8WLghi5kBuELV6Um+s3oZ7BRfUYVDkFRdRhgbIKc5VlRT3fbMgi24nIGgMzFxlUB1JBmS6OOAbVgZIHZlKdLKq9krp7BzKCMl1cJo7p51Tr1FfT+kdyAjChBCCEQNykSC1gXSvNLh+9+xbDorcrly3CUz/c45ptpAZV410YJKTl+9NsmvaxRzvwk/0/xSd+NYbmhcD4GPDc93348LrpXL8J9QzGYkcQx/Qm96qcwmisDwAqFpwJGAdhoiLPTlR9GJi5SATGFyOz9mpldVHWp7rcMPU1U2YrOMdf+XPL+3kbF1Wie0UxWl27ctki/PTUuZyRsnROq1dn9R40O2Y1TfuB+zTcdJcGT3I9xsLFwKO/o2FJMDGKPaGewWisDxJazuNKaLioHqtYYLZy4bKMHLP0diIqHgMzFwkgaPghH0AZLlLeOkCbMm63mVXSuBBwxdTXbBmt4EwEagZFapEYUWta/0glula07NW1T/1wj2VQ5sR6dWbvTf2YEatp2l9aGoHHm3nM442nAq6L6jHDoEynSoP3bpnoeWRclUlUGgzMXKRZLMKwzPxm6oEH7UrpL1INyx9G6OQ/AhlTpx40LH+45M+VT/Z0z8pli3Bw4GzOdKZHJKYzjeiBnBobqtptXYymOFO8/sp3aIasRkSdOjXdrnTk5JgBgIAwfX9aTdOq0viYKqcwoZ7JG3gporJfoNbfdCsDMaISYWDmEufVYZyX53Lal4ilZVmVqSeHl7NcRiFlEIyme3566hzu6LgeR985n7MqU3+8bPMagomgLLof0Eca5GTyNqoiOJtzywaEh99G6PA/5xyTkasF1zqzm9V2W1/85fsr36EC6O/BYlZlWv07FSFMg6/RWB888GfklqUT8GKBsmom/wwicgAGZi5hlPgPAOOyfAnd5Vy9ZxRw/ei1w3hv5BIe/uD0N2+z6Z6TZ0bx+//JOMAwSibf2NUBLXYAyJn+0RIjaAC06EEgdbHzwevvcl3AFn5nv+mx7FpnTrWxq8P0d+hkS5TWor4kWf07FyiaZQ4Z4IGAN+e4gA+LfLdXdFUmEZUWAzOXqLbEf6OACwD2nziDG1rmp0bOil2VZ7VVUyRksqJUTkKLvoXMadsYtOg+AO4aTcu38tKJKzOzVdt2W2YK+XdeiB00vK9EDIt9d9haJoOIyoOBmUtUNPG/AqzyiNIT9a2me8yYbtUk6hO5ZbkHAIPRSEBCi/W7KjAzq3GWftwNsoMWvQxKNQZnZv8mPcnfaEpTEXWYqyxjIEZUhRiYOVh6DlZbh4L3rRWAZzq7vVyJ/5VgtbLySiic8W/PNtNpLa+vMzPHLNGK3OnNNIaBnHNZLQBw8srMdH2Dw/iXN49hKqqm2qqx7EkhFiircqY0mUNGVN0YmJVAOSpvZ+dgDQ2oiMaAVXf6EFdiZd2OqRKstuOpD/hycm90s5nW0ke+sldlpm4bEfVFP4+dMmucXQCEB5BxeBsXp/bLdCKrQFznprInpdo6Tf8c4ZQlUe2wJTATQjwF4CEkMq0HATwipbycPPYEgEeRGMb4XSnlLjv6WKjsQo+lqrxtlIM1/A4QOq/hi7/y4Mw77BBr2lvx3sgl7D+RWf7D5/VASmkalM12VZ7iazOcmszNMQMAAa+vc1bPZwejGmdOlv0lxIrTKv4bMdo67bh6GFPaOG4K3Fb043HKkqh8KrX/dDHsGjHrBvCElFIVQvwZgCcAfEkIsQrApwHcCqAVwKtCiA4pszdtdA6jQo+lqLxtOs03pSE8cqhsqyWHerrRv2MbJscvoL55MTq3bEXb+o1lea6HP3grbmiZn5P8nG9j61JLjaRVwapMNzJbCGJkXkMwY3StPuCDlBJTURVzG3xYe3sMbW1hW0eWjFZQSwDvxc+iWW1ikEXkENl73EYQTt22MzizJTCTUv447eY+AJ9K/rwZwA+klBEA7wghTgNYB+DNCnexYGa1hoqtvH3t+O6MLXZWe+/GUbk845yVc87j3oWDCJ2MYmpoV8nrig31dGP/9qegRRP5SZPjI9i//SkAKFtwZpT8bFWLrFzMRtKqhZML6xYacOt7aKaPrqVvgD4RiuGN/RIaPGhvq/yekTqzldIaUNGtkojI2kn1mGm7nYGZx7ZnnvZfAPxr8uelANLnts4m23IIIT4rhOgVQvSOjtpXAsCswvbkpMB//84reOqHe9A3OGz5GNeO78bFV7+RXE0noV29gLuvvoIV0bdT56yccx4bF59Eo5IY0YlHLiN0aifCI4dK9m/p/d63UkGZTotG0L9jW8meoxAbuzrg8+b+aa5c5o4VhU6TKqyr59ElC+uqsSFb+6UrJOCuD/iw+Z7VOHlm1HJ0TdMEDvUnvm/qI9eVZrZS2gtZ0a2SiMiaXgy60PZKKVtgJoR4VQhx1OC/zWnn/AEAFcD/0ZsMHspwkx0p5bNSyi4pZdeiRfZdsBcoqyDgzWhTVeBAX6JNX01mFZxd7vluzio6oUVxT+x1NCpTACTuXTgInyfrghSPYWqoNCl4Qz3diIUmDI9NjpuXXyiHNe2teP+K3Hj8p6fO5Q1yKVeigK55YV27mQXiQCJo+9R9t+P3/9MGrGlvLWh0LTQ5/TFiRyDUrnTkfJAJKTEPasW3SiIi9ynbVKaU8gGr40KI3wDwHwBskFLqwddZAOnj/NcDcPSVWJ+WOD91BMIbRWgSONiv4J13p1/afKvJzIp+KuoUfvN9B4F4zPA4kBg5KwWrUbH65sUleY5inDyT+5q4aVWeE0xPj1+AZ04D5tx5B+pXtE+f4JBSIMUUlLUqs6JrqJ/+LmdHILREacWUNo734mehITFSNg8qGiFY5oLIIc6r5qGFAl8Fe2L0/DYQQjwI4EsA7pMy4+rwIoDvCyG+jkTy/woA5nvMOMTP3vXihb0KYpr5AKTVxcSsKKi3cTEaVnwytV+lEU+gqST5Q1ajYp1bthb1WKVQbMV/yqRPj+sjsfFrIUy80QMA08GZg0qBWBVaTbexqwPPvXEkZwN7ndcrsbYzMQ1hZ72vmwK3oVltKmuZi3KU6SGqBfrKaSMCAh3KLRXuUSa7VmX+FYAAgG4hBADsk1I+JqV8WwixA8AxJKY4f8vJKzJ1L+87nndVmVUejVFRUL0YqL5fZXjkEEKndmaOnnl8CCy7oyQbc/saGg2nMv1z5pUt8d9KnV/JKDCa3k75GU2PQ9Vw7cDBZGDmrWgpkOzFLbOpqTY9wJ5pelVm3BGBSjnLXJSrTA9RLTDbexoAblFuq81yGVJmLTfMPPZVAF+tYHdmpW9wOGNlmJF8leozi4IaX7j01Zf66Jkn0IS6tk0QjWeAnNhVy9hKyKgEBoBUm6+hEepUKKdfwuvFHb/+O/legrJIBuwFt1Mms+nx+LVQxVdlZo/eaVcv4OKr3wCAooOz7t4BGA2WlaLGnZuUq0wPzUx6CZdq3du1mljtMW13UAaw8v+s6Xv4mSn0TVpIUVB99CxdJHTS+OTkDLFRCYx9z34NQngQVxMBpVnSv9fnt2W0DIBpsJsvCKYEq+nxQP1mg3uUj9HonVQjuNzz3YICs0J2Bai1Ke5Slemh2csukHwlFMaPXjuMf3nzGD72gVUM0MpkNoVhnb73NAOzWbK6IHzqvtvL/6Y025g7mT/Uv2NbTgkMqWk537aNqOEpDPV02xKczWTzcspM+M9m116ZZqN3Zu3pCt0VoNb+LhRRZ7q5OVWWWYHkqahak/u7lkK+oMtodw09Z6yQ4Kxd6ci4P+CsvaedUMfMtaxKN9T5lYq8GRN5Qt7s1lT+0GxLXVS6hpnOqITCTDcvrxWZ9fAyeRsXY8EDn7dlqyZvo3E5G7P2dIXsClCLfxdGZXqAxIjZ6annMRTehQn1jME9qdQK2d+11p0eG8YP+vdg+4FX8IP+PTg9Zn7t1IMufURLD7rSV1Ea5YjFEcegWthrvURpxc3K6tQIWQBB3KysdsQ0JsARs1mxesN97AOVWQ1mtjG33l7fvBiT4yMzfvxK1zDTFVNCgRIME/6RCMqu/82/t6FHCVaLW/LJN0VZq38Xeh7ZaOwwJHKn96txMUB45FBOjm25tqYrRr4SLrU2zZ7t9Ngw9r57FFo8EUiFomG89s5hvPbOYTT4g+ha2oHlC6ffv1ZB1xKlFefVYdMcMavcsWxLlFbHBGLZGJjNgtUbrpIXCqvthDq3bM3IMQMSSf3pOWZW7Khhpiu0hAIlRsuMRsqAwqYMy6mQxS1mrKa0aynZ38hcZVmyXIbx+1hCw/5Tb+Onhwdd/+Xm6sBziJ7fl7qt73wCwPbgbGNXh+V0e61Ns2frPTeQCsqyhaJh7H03MQWpB2dWQdfr4d1QDb6I6JySIzZbDMxmwQ15UHp+mNWqzPrmxWhd8wG888a/ZgRwXn/AlhpmVBx9CtNMIVOG5VbI4hYjRhe9Wpy6NGOV7D845MG/75fQtMRnlL4LCeCunKfwyKGMoCwlufOJ3YGZ/lq+vO94zuIk/q0mgi8rWjyO3nMDqcDMLDEfgGVQ5qQcsdliYFak9BViPm9u6QYnvhHb1m80TODPblvUsTongLNrVWatmkm9L7MpTMC+hP9S4ZS2Mb24rJVD/Qo0LfMzyk27Z6RPXZop1c4ns6WP7rNsRq4GfzBvcJZ+vFkswrAsPj/SSTlis8XArAjZK8RiWm5BpfevWOraN6JZAEeVMdN6X1ZTlXYl/JcSp7QzZReXNZO+Z2g6N+Q8GRbUNuAJNFWoR4Xh32qurqUdGTlmRhr807NM47L41IsAglUTlAFclVmUQlaIGe3xSFQIq3pfVsxXPS52fVBGuYyKy05LBGOKqMPcBr/hGU5KtTAzNbQrb1AGAHVtmyrQG5qN5Qtbcc+NqzOCr3RejwddS6dnmYpJ4Nc1C/vTNUqJI2ZFKOSbphu+jZIzzbTe12xWPZL7WOWVLa+bLh78i125NeCcmGphpJApSv+Su23PLytUrU9xLl/YmsohOz02jN5zAwhFw4arMq1yzMycl+fQpM6vmlEzBmZFyLcsWj+HaCbMqvUDEme+/SlIKSEj1+AJNqZ+1vPQFjzw+ZLtRUnOVmhxWTfn53kCTabBmZNKZRTCaGcAo0UYtbIpfXqQZsSs+OsSsRTjctQwaEsvp1ENGJgVId+yaLd8GyVnMhr50sXDE4Y/63loCx74vK21yqhyFiircnLMBLxYoOTWTnRrzlNd26bcHDOPDw0rPumagEzX3TuA66+P4o5OFQ31QGgSONivZCzCmFDP4ELsEIBE3rIqp5K3q6cOXSH0iv/pQVl25f+fhF8xvO9MpkCdijlmRVjT3orN96xOjYrV+RXUB3wAEiNlm+9Z7coPQXKGObdswIIHPg9vY3G14wrJQ6PqMVdZhkW+NakRMkXUYZFvTVVdwIMta9Gw4pOp5H5PoMmVQRkALFh4DevXqZjTAAgBzGkA1q9TsWDhtdQ5Y7Ej0IOyaTLZXhuyK/4D0yUw0kfCzGqVVUsNM4AjZkVz6zdQcge93te7T29C7ge1ObuLyFLhZlISJdtcZVlVBWJGgi1rXRmIZbtzjQYl60qrKIl2XRxRw/uatVejfBX/dU7f57IUGJgROUT6BRtCALLwwMwJRWQpv5mWRCH3qqszfh+btdeqQrdZ0oM0q03O3Y6BGZEDZF+wiwnKuALTPaxKojAwq04+j/FiDZ9nerGGgM9wz1MBX1n75iRmqzGNpiidvM9lKTDHjMgBTKv3Cw8AAU9wLkSgMednb+PiqigiWytmWhKF3GuBsgoC3oy27MUai3y3Q69Bl35Wor02tCsd8GSFJNU2RVkojpgROYDphVlK3Pj4rsp2hsrGrCSK0VR0rZRPqHb678zqd1nIOdWuFqYoC8XAjMgBirlgk3sVWgw4e9slVU5hNNYHoLbKJ1SL9MUaesB9IXYQiVEymQrE2oK1vZNBtU9RFoqBGZEDsHp/bdCnnMfOvgq1cxUwZw48mgfxuo6METL9gp1OQsNF9RgDMxfL3ed0um4ZA2/SMTBzqZ533sbJsTOQSHyEr1y4DOtvutXubpVE3+AwXt53HJORRDJsnV/Bxz6wqqrLlOgXbFbvr37xFR3Q2iaB5MU5rshUMdHpYMx48YfVdkzkfFb7nDLwJh0DMxfqeedtnBg7k7otgdRttwdnfYPDeO6NI9Di0xemqaiKna8fBoCqD84YiFU/44tzYatws7ddInfJF1gz8CaAqzJd6WRaUFZIu5t09w5kBGW6uEwcI3K7mV58zbZdIvfIF1gz8CaAgZkrmX23roZyhVabxOfbQJ7IDYq7+IrUfapt26VaZFQ6Q8fAm3ScynSh3LTg6Xa3m9cQNA3A9D1KidwmPbHfAz9y38X6u1emtXgZjFWZ7LIY2asy+bsmgIGZK61cuCwjxyy93e02dnXk5JgBgEckjjnJUE83+ndsw+T4BdQ3L0bnlq1oW7/R7m6Rw2SvxEvsfyhS1d71izJQ23WsakUt7HNKs8PAzIX0BP9qXJWpJ/c7fVXmUE839m9/Clo0Ud5icnwE+7c/BQAMzijDWOyIYbK/VyhoC34so5UXbCISsog9+Zyqq6tL9vb22t0NqiEvfG4LJsdHctqFxwMZlxxBIwCJ0bJEIVFjy+s+XsHeENnrvDrMyv5JQoiDUsouo2NM/ieagcnx3Cr9ACDjcQASk+MjeHP7k9i155s4rw5XtnPkGBfVY6bHuAKPasl5dRgn1KOpjcojCOOEepSfjwYYmBHNQH3z4vwnRVVc3vkqP3xqmFVpDK7Ao1oyqA4gjnhGWxxxDKosg5SNgRnRDHRu2QqvP5D3vPjFCX741DCzUTEBH/PJqGacV4dTI2XZzNprGZP/iWZAzx3TV2UKj0hOY2byLJgLwD0fPmO7v4XQkZcBGQeEBw23fRQLN/yu3d1yrQXKqqy9EfUyGLfb2CuiytGnMM0EwDJI2RiYEc1Q2/qNqQAte5UmAMCvQLv3fvQ8D0QmgYMNe7Cxq8NRq0vTje3+FkKH/3m6QcZTtxmczUx23SqWwaBaYzSFqfPAg3bFWWWQnICBGVEJ6AHaoR3PIDI+Bs+CudDuvR8nJm9FPDlYciUUxgt7E98cnRichY68bNrOwGzmWLeKapnVbMHNyuqaXZVphYEZUYnoI2j6kvCfPB9OBWW6mBZHd++AIwMzSONvtabt5HrhkUOYGtqFeOQyPIEm1LVtQrBlrd3doiphtegpgCCDMhNM/icqsSVKK9YH70dk0vi4Y/f8FCYfB2bt5GrhkUMIndqJeOQyACAeuYzQqZ0IjxyyuWdUDaxyyziFaY2fuERlYra3p1P3/Gy47aNFtZN7hUcOIXRyBxCPZR6IxzA1tMueTlFVscot4xSmNU5lEpXJxq4OvLD3KGLa9IeTz+tx3J6fOj2PjKsyq5s+Upa5ifo0fQSNKB+jSv4AUm1mGJRZY2BGVCZ6Hll37wCuhMKY1xB09KpMIBGcMRCrbqHTL+aOlKXxBJoq2BtyK32qUh8ViyCM4+oRSJOAX8fyGPkxMCMqozXtrY4OxKi2hEcOAZr5bgTw+FDXtqlyHSLXMpqqzBeUMbesMAzMiIhqhHX+mEDDik9yVSYVpNii2bW+aXkxGJgREdUIq/yxhpVbGJRRwQIIFhycBRDE+uD95e1QFWFgRlQBfYPDrso1o+rkCTQZBmdCqWdQRkVpVzoycswAQEDkTGdy+rJ4DMyIyqxvcBjPvXEEWjzxgXUlFMZzbxwB4MwdAKi6pH8peH/zDfjQgmvwSHX6BI8P9e0P2ddBciV9StJqVSanL2eGgRlRmb2873gqKNNpcYmX9x1nYEZl1Tc4nFGy5afjzYjEOrDhujNQtKus9k+zskRpNQy6GIjNDgMzojKbjBiXJjBrJyqV7t6BjDp6AHBsogXntBvxxV++355OkasZ1S5jIFZaDMyIiKqU2fZfjt0WjBzNqHaZvu0Sg7PS4ZZMRGVW5zf+/mPWTlQqbtsWjJzNqHZZHHEcUw+jJ7zHctNyKhwDM6Iy+9gHVsEjMts8ItFOVE4buzrg82Z+zDt5WzByNqvyGProGYOz2eNXdqIyc+PWTFQd+LdHpZSvdlkccQyoxzmtOUtCSustFNygq6tL9vb22t0NIiKiqpWdY2ZmlXI7g7M8hBAHpZRdRsc4lUlEREQFEQWEDcfUw5zSnAVOZRIREZGlQkfLdFytOXMMzIjI9SbUM7ioHoMqp6CIOixQVmGusszublGZqLEhaLF+QE4Coh5eXycUX5vd3apqRisyrcQRx6A6wMBsBmydyhRC/N9CCCmEWJi8LYQQ3xJCnBZCHBZCsBw1EVmaUM9gNNYHVU4BAFQ5hdFYHybUMzb3jMpBjQ1Bi+5PBGUAICehRfdDjQ3Z2q9qV+iG5bO9D9k4YiaEWAZgI4D30po/AmBF8r+7AHw7+X8iIkMX1WOQ0DLaJDRcVI9V1ajZUE83+ndsw+T4BdQ3L0bnlq1oW7/R7m5VnBbrB7J+34AGLdbPUbMyMluR6YUCDarBPRL3oeLZOWL2NIDfAzK2ot8M4HsyYR+AJiHEdbb0johcQR8pK7TdjYZ6urF/+1OYHB8BIDE5PoL925/CUE+33V2rPH2krNB2Kol2pQOerJDBAw9WKquwSrnd8Ji+qTkVx5YRMyHEwwDOSSn7hciovLkUQPr8w9lk288NHuOzAD4LADfccEP5OktEjrNr9zCe2T6AC6NhNC8M4lOfieKD92fmvyiizqbelV7/jm3QopGMNi0aQe/3vlV7o2ii3iQI8yIy+QLzzspEzxWz2ieTe2iWRtkCMyHEqwCWGBz6AwC/D+AXje5m0GZYaE1K+SyAZ4FEHbMZdpOIXOb5Hx/BN755DnqcMjYKfOevfABiqeBMwIsFSvXsrDA5fsGwPRaaQCw0kTwnMYoGoKqDM+FphdROGxzRcvLOADA4K6ElSqtpsJV+TN/o/Jh6mEHaDJRtKlNK+YCUcnX2fwB+BuAmAP1CiCEA1wM4JIRYgsQIWXpSyPUAWAyFiAAkEv23f/cssgaPEI0I/Oh7fgCJkbJFvjVVlV9W37y4oPO0aAT9O7aVuTf2kvFCLwlaMh+NKkkvq6Hno3GrpuJVPMdMSnlESrlYStkmpWxDIhhbK6U8D+BFAJ9Jrs68G8AVKWXONCYR1aaL6jGMjxkfGx8Dltd9HG3BTVUVlAFA55at8PoDBZ1rNrpWNYrJJWPeWcWZbXQ+qA7Y1CP3cVods5cBfBTAaQCTAB6xtztE5CSqnELzQj/GR3OzHhYvqt4VYPrUpJ5PZpLhAaDw0TXXMs0xMzmXKsqsRAZLZxTO9i2ZkiNnY8mfpZTyt6SU7VLK26SU3ACTiFIUUYdf+owKfyAzMPEHgMcere4VYG3rN2LzN3fgV/5+D+qbW0zP69yytYK9qjyvrxPG6cg5ZybPpUqyKpHRE97DKc0C2B6YEREVaoGyCuvvF/gvvx1D86I4ICSaF0l8/nNLsWlD7SQXd27ZCo/iyz0gCglY3E3xtcHrvxtA+r/fD+FdPj1CJurh9a9j4r8NjMpq6JhvVhghpfsXNHZ1dcneXg6uEdUCbr+U8KP/+lBqRWa6+uYWbP7mDht6RJSgr8o0m74MIIj1wfsr2ymHEUIclFJ2GR1zWo4ZEZGlucqymgzEssVCVw3bqz75nxxPL53xk/ArhseZb2aNU5lERC5kluRf9cn/5Bpm+WbcqskaR8yIiFyoc8tW7N/+VMaOAF5/IG/yf3jkEEKnXwS0xJZVQqlHfftDCLasLWt/qfa0Kx04oR7NKJ/BrZryY2BGRFSEvsFhdPcO4EoojHkNQWzs6sCa9sovPMguoVHIlkzhkUMInfxHIO1CKdVJhAZ+BAAMzqiksrdx8kKBgMAx9TAG1QHuCGCCgRkRUYH6Bofxwt6jiGmJwOZKKIwX9h4FANuCs2K2X5oa2gVkFf8EAEgNU0O7GJhRyen5ZufVYRxXj0Ama/BFEMZx9UjqHJrGHDMiogJ19w6kgjJdTIuju9cdVc3jkcszOkY0WwPq8VRQppOQGFCP29Qj52JgRkRUoCsh49VkZu1O4wk0zegY0WypiBXVXssYmBERFWheg/FqMrN2p6lr2wTDj33hTR4jIrsxx4yIqEDvb4zg9asxxD3TVed9Xg82dpVnldlQT3dRyf356DlkXJVJleaFAg2qYTtl4itCRFSAoZ5uXPzRX+K6+e248L77EQvOhS9yFevb5pUl8X+opzujHMbk+Aj2b38KAGYdnDEIo0pbqazCMfWwYTtlYmBGRFSA/h3boEUjaBo5hqaRY6n20MkW4KOlnwY8+Hf/K6NGGQBo0Qj6d2ybVWBGZIfs0hkBBFkuwwQDMyKiAphtdVSOLZCGeroRvXalYs9HVAl66QyyxuR/IqI8hnq6AWF8rBxbIPXv2GZ6jFsuEVU3BmZERBaGerrx1rY/A6TMOeZRfHm3QJrJ802Oj5geL/XzEZGzMDAjIrLQv2Mb4qpxrSVvoK6k+V56wr8ZX8Nc5pcRVTnmmBERWbDK6YqFrpb0ud763jOIZyX867z+ALo+87slfT4ich6OmBERmRjq6YbwmCSXobT5Xl3koTEAABjESURBVLt2D0O7NmZ6fN2jX+RoGVENYGBGRGRAn1aUcYNNvwEIr7ek+V7PbB/AVW2u4bH65hYGZUQ1goEZEZEBvW6ZEV/DXNz92SdKGixdGA3j36/dj1g8M8MkFleY8E9UQ5hjRkRkwDy3TOBTf/NSyZ9v8aIgTl24FQDwwTl70OidwFVtLt72PIDPcLSMqGYwMCMiMlDfvNiwbEW56og99mgHnvz6UZwK34pT4USAFgh48OUvrC7L8xGRM3Eqk4jIQOeWrfD6AxltXn+gbNOKmza04stfWI2WxUEIAbQsDuLLX1iNTRtYKX0m1NgQIpMvIBL6B0QmX4AaG7K7S0QF4YgZEZEBPX+sf8c2TI5fQH3zYnRu2VrWJPxNG1oZiJWAGhuCFt0HIFkUWE4mbwOKr822fhEVgoEZEZGJtvUbuRrShbRoL1JBWYqEFu1lYEaOx6lMIiKqMsY7NZi3EzkHAzMiIiIih2BgRkREVcZfZDuRczDHjIhqxumxYfSeG0AoGkaDP4iupR1YvpDJ9tXG678DWvQtAOm7Nnjg9d9hV5eICsbAjIhqwumxYex99yi05BZLoWgYe989CgAMzqqMnuCvxfoBOQmIenh9nUz8J1dgYEZENaH33EAqKNNp8Th6zw0wMKtCiq+NgRi5EnPMiKgmhKLhotqJiOzAwIyIakK9KK6diMgODMyIqCa0D+2FR8usY+XRYmgf2mtTj4iIcjHHjIhqQsuZA4hPXcFg270IBxoRjFxF+9AbaBkbsLtrREQpDMyIqCZ4GxfhurGTuG7sZFb7Ypt6RESUi1OZRFQTmtY/AqEEMtqEEkDT+kds6hERUS6OmBFRTZhzywYAwOWe70K7Ogpv4yI0rX8k1V4JamyItbWIyBIDMyKqGXNu2VDRQCydGhuCFt0PQEs0yMnkbTA4I6IUTmUSEVWAFutHKiibbk22ExElcMSMiFwnPHIIU0O7EI9chifQhLq2TQi2rLW7W4aGerrRv2MbNn314xDCoGianKx8p4jIsRiYEZGrhEcOIXRqJxBP1CSLRy4nbgOOC86Gerqxf/tT0KIRTF68hobmxtyTRH3lO0ZEjsWpTCJyhdNjw/hB/x6MDjyfCspS4jFMDe2yp2MW+ndsgxaNAADefu4tqJGsfsMLr6+z8h0jIsfiiBkROd7psWHsffcotHgcdTJieE48crnCvcpvcnwk9fPZA6cBALd+4i7UL5gD4WngqkwiysHAjIjKrm9wGN29A7gSCsMfvYZFp3ajVR1H55ataFu/Me/9e88NQIvHAQBTIoB6g+DME2gqeb9nQ40NoW7BHExdvJZqO3vgNM4eOI365hZs/uYOG3tXW1imhNyEgRkRlVXf4DBe2HsUMS0RWEX9czB880eAE/+KyPanAABLljdbJvOHouHUz28r78P7YyehID79JB4f6to2VeYfVCB18i3c+vG78NO/fw1aVE21e/0KOrdstbFntSVRpmQfAJlokJPJ2yxTQs7EHDMiKqvu3oFUUKaTXj8uvO9+aNEIzv379xE6tTM1Fakn84dHDqXOb/AHUz+fU5bgp76VmBSB5KVWwL/4Dkcl/l87vhvwarjhrhV4/6/dh7oFcwAAdQvm4P2/dl9Bo4RUGlq0F6mgLEUm24mchyNmRFRWV0Jhw/ZYcC4A4MZV80yT+fVgq3OOD2+Nh6AJL4BEcHbeuwhrYiewTLuA6MgBjI/2A9qUI8pnXO75Lub/h/ugNM7BDXetwA13rZg+yFWYFZa94CJfO5G9OGJGRGU1ryFo2O4LTwAAgnP8hsfTk/mXjL2ONbETqItPAVKiLj6VCsoAAFIDtKnU/bJH3CpNuzqKa/t7EY+pGe3xmMpVmERkiSNmRFRWG7s6MnLMAEBoUSz+2R54/QFIUQeB3FE1odTj0ltfSwVoy4DpQCyfrBG3SjtxJoDX/s9hTFzrR1NLAz7y2/dgzb3XY/LIKSza+Ou29Kl2+QFETdqJnIcjZkRUVmvaW7H5ntWpkTN/9BpaT/wrWtVxrHv0i2hcuRnw+DLvJLyQanhWJTDsKp9x4KVX8MruS5i4lshrujwSwj9+ZRfe+OoO1F3vrAUKtcDrvwO5lzpPsp3IeThiRkRlt6a9FWvaW9NaPpVzTvqqzLgaSU1NzpRd5TNefPoZxLIKyaoqsLfPiwdt2kC9lukrL1kug9yCgRkR2S7YsjZj2nH89S9Zni+UekgpAW0q8bMaBhxSPuPSz0cM2y+PXalwT0in+NoYiJFrMDAjIsfxBJoMpyI9gSbMv+uJnHYnbWo+/7oWXBo+b9hORJSPbTlmQojfEUKcFEK8LYT487T2J4QQp5PHmJBBVIPq2jbl5p1ZjIIFW9Zi/l1PoPlDf4b5dz1ha6mMhx9/DL5g5kpUXzCIhx9/zKYeEZGb2DJiJoT4BQCbAdwupYwIIRYn21cB+DSAWwG0AnhVCNEhpdTs6CcR2UMPrNJHwZT5N2NqaBdCJ39o+6iYlTsfehBAItfs0s9HMP+6Fjz8+GOpdiIiK0LK7IrIFXhSIXYAeFZK+WpW+xMAIKX8WvL2LgB/LKV80+rxurq6ZG8vqzgTVavwyCGETu3MLETr8aFhxScdGZwREVkRQhyUUnYZHbNrKrMDwL1CiLeEEK8JIe5Mti8FcCbtvLPJthxCiM8KIXqFEL2jo6Nl7i4R2WlqaJfp7gBERNWkbFOZQohXASwxOPQHyeedD+BuAHcC2CGEeB8AYXC+4ZCelPJZAM8CiRGzUvSZiJzJrCaZXbXKnGBCPYOL6jGocgqKqMMCZRXmKsvs7hYRzVLZAjMp5QNmx4QQ/w3ATpmYR90vhIgDWIjECFn6J8v1AIbL1UcicgerVZq1aEI9g9FYHyQS6beqnMKF2EGMxg5jke92BmhELmbXVObzAD4MAEKIDiT2xhgD8CKATwshAkKImwCsALDfpj4SkUMUu0qz2l1Uj6WCsnQSMYzG+jChnjG4FxG5gV11zL4D4DtCiKNIbGL2G8nRs7eTCwOOAVAB/BZXZBKR0SpNp67KrARVmu+KIKHhonqMo2ZELmVLYCaljAL4NZNjXwXw1cr2iIicLnt3gFqmiDrL4MzqGBE5Gyv/E1FVOz02jN5zAwhFw2jwB9G1tAPLF7bmv6ODLVBWZeSYZVNEXYV7lKDGhrgnJdEsMTAjoqp1emwYr79zOLW0OxQN4/V3DgOAq4MzfZpyLHYEcUQzjgl4sUBZZXi/cm5dpcaGoEX3A3qwKCehRd9EXBuFP3in5X2JaBoDMyJyvJmWhnjzvWM59XZkst3NgRmQCM7mKsssX5v0QAzeOiAeBZJpu/HI5UTRXqAkwZkW6weMFiRop6HGFnHkjKhADMyIyNGMSkOMxvoAIG9wFtXUotrdSA/QsuXslqAZ5J0li/SWZNRMTpoe0mL9DMyICmTbJuZERIUwKg2hrzwkc4a7JRgoWZFeUW9+zCJoI6JMDMyIyNHMVhiq8UlEJl+AGhsyvW/A6yuqvZoUGnCVqkiv19dpftAqaCOiDAzMiMjRjFYY1sdVXCfDqQTzaPiA4X3vvuEWeETmTm8eIXD3DbeUpa9OUlDAVcIivYqvDcK73OCI1zpoK4IaG0Jk8gVEQv+QNygncisGZkTkaAuUVRDwpm7Xx1XMRywjQTaRYD6Uc9/lC1txb9ttaPAHAQAN/iDubbvN9Yn/hTDcLQEeCCUxeuUJNKFhxSdLWhvOH7wTXv8HpkfIRD28/nUlyS9LrfrUp0XlJLTofgZnVHWY/E9EjqYntl9Uj0GNT2IeYobfKM0SzJcvbK2JQCxb9m4JgAAQh/D6Ud/+UNmK9Sq+tlkHYkb10IxXfWpcWEBVhyNmROR4c5VlaAtuwjJ4zL9NMsE8R7BlbdrIWaJwiF4mIzxyyN7OmUiMjL2VNTL2lvnvV05y1IyqCgMzInINJpgXz3B1ZjyGycGX7OlQHlr0IIB4Vmv27ez7cEqTqgcDMyJyjUokmFcbs9WZUp106KhZ1OKY16Rdgxbdx+CMqgIDMyJylXImmFcjq9WZodMvVrAns+f1r7M4KqFF9yES+ieu2iRXY/I/EblOKRLMa0Vd2yaETv7Q+KA2hfDIobItBChGKuHflA+Kr216UYAhidSIW3LVJgD+rZCrcMSMiKiKBVvWJvbJNDE1tKuCvTGWUwojh4DX3wVAzzM0m9LMpuUJ9oich4EZEVGVa1j+sOmxeOSy7blmZhugA0hOVd+dGvVSfG3JKU1hfH42rtYll2FgRkRU5YIta1OFZY3YXj7DIngK1G/OmYpMBGd3o6CRM67WJZdhYEZEVAPq2x8y2AkgKR6zd0rTLHiyCKpSI2epc3zIvaRxtS65D5P/iYhqgJ7gb7YQoNBNz8vB6+tMJuqnT2fmD6qyF4EY7RjAxH9yGwZmREQ1ItiyNm2LpkwFbXpeJnrwNNugiqt1qRowMCMiqiF1bZsQOrUzczcAjy+xdZONGFQRJTAwIyKqIdmbm3sCTahr2+SIWmZExMCMiKjmBFvWMhAjcigGZkRUMgdeegUvPv0MLv18BPOva8HDjz+GOx960O5uERG5BgMzIiqJAy+9gu//4ZOIhcMAgEvD5/H9P3wSABicEREViIEZEc1KapRs+HzOsVg4jBeffoaBGRFRgRiYEdGMZY+SGbn085EK9oiIyN1Y+Z+IZuzFp5+xDMoAYP51LRXqDRGR+3HEjIhM5Uvmzzca5gsG8fDjj5W7m0REVUNIKe3uw6x1dXXJ3t5eu7tBVFWMpik9ioK6OQ0IXZnA/OtaEJ2cQujyFcP7z29dwlWZREQGhBAHpZRdRsc4YkZEhoymKeOqmgrELg2fh/B44PX5oMWmq8j7gkH86p98mQEZEdEMMMeMiAwVkrQv43F4FQXzW5cAQmB+6xIGZUREs8ARMyIyNP+6FsMSGNmiU1P4+k//rQI9IiKqfhwxIyJDDz/+GHzBoN3dICKqKRwxIyJD+nSkvioTkIDBWqH6prmV7RgRURVjYEZEpu586MFUgHbgpVfwd0/8KeKqmjruURT80h98wa7uERFVHQZmRFSQ7BE0blJORFR6DMyIqGDpI2hERFR6TP4nIiIicggGZkREREQOwcCMiIiIyCGYY0ZEeTcrJyKiymBgRlTjsjcrvzR8Ht//wycBgMEZEVGFcSqTqMYZbVYeC4fxj1/9uk09IiKqXQzMiGqc2Wblk5cncOClVyrcGyKi2sbAjKjGzb+uxfTY//fFP8YffvjjDNCIiCqEgRlRjXv48ccsj+s5ZwzOiIjKj4EZUY2786EH0dA0z/KcWDiMF59+pkI9IiKqXQzMiAhrP7Ih7zlmuWhERFQ6DMyICEdf+/e851jlohERUWkwMCOqcQdeegWXhs9bnuMLBvPmohER0eyxwCxRDdOLy1qZ37qEOwEQEVUIAzOiGmZUXFbnCwbxq3/yZQZkREQVxKlMohpmldDPoIyIqPJsCcyEEGuEEPuEEH1CiF4hxLpkuxBCfEsIcVoIcVgIsdaO/hHVCrOE/vmtSxiUERHZwK4Rsz8H8BUp5RoAf5S8DQAfAbAi+d9nAXzbnu4R1YaHH38MvmAwo42J/kRE9rErx0wCmJv8eR6A4eTPmwF8T0opAewTQjQJIa6TUv7cjk4SVTt9VOzFp5/BpZ+PYP51LUz0JyKykV2B2ecB7BJC/AUSo3YfTLYvBXAm7byzybacwEwI8VkkRtVwww03lLWzRNXszoceZCBGROQQZQvMhBCvAlhicOgPAGwA8LiU8p+EEFsAbAfwAABhcL40enwp5bMAngWArq4uw3OIiIiI3KRsgZmU8gGzY0KI7wH4XPLmPwL42+TPZwEsSzv1ekxPcxIRERFVNbuS/4cB3Jf8+cMATiV/fhHAZ5KrM+8GcIX5ZURERFQr7Mox2wrgm0IIBUAYyVwxAC8D+CiA0wAmATxiT/eIiIiIKs+WwExKuRfAHQbtEsBvVb5HRERERPZj5X8iIiIih2BgRkREROQQDMyIiIiIHIKBGREREZFDMDAjIiIicggGZkREREQOwcCMiIiIyCEYmBERERE5BAMzIiIiIodgYEZERETkEAzMiIiIiByCgRkRERGRQzAwIyIiInIIBmZEREREDsHAjIiIiMghGJgREREROQQDMyIiIiKHEFJKu/swa0KIUQDv2t2PClkIYMzuTrgAX6f8+BoVhq9TYfg6FYavU2Gq/XW6UUq5yOhAVQRmtUQI0Sul7LK7H07H1yk/vkaF4etUGL5OheHrVJhafp04lUlERETkEAzMiIiIiByCgZn7PGt3B1yCr1N+fI0Kw9epMHydCsPXqTA1+zoxx4yIiIjIIThiRkREROQQDMyIiIiIHIKBmQsIIX4ohOhL/jckhOhLtrcJIabSjj1jd1/tJIT4YyHEubTX46Npx54QQpwWQpwUQmyys592E0I8JYQ4IYQ4LIR4TgjRlGzn31MWIcSDyb+Z00KIL9vdH6cQQiwTQvybEOK4EOJtIcTnku2m78FalfzMPpJ8PXqTbQuEEN1CiFPJ/8+3u592EUKsTPt76RNCTAghPl/Lf0vMMXMZIcRfArgipfx/hBBtAP5ZSrna3l45gxDijwFck1L+RVb7KgD/AGAdgFYArwLokFJqFe+kAwghfhHAT6SUqhDizwBASvkl/j1lEkJ4AQwA2AjgLIADAH5FSnnM1o45gBDiOgDXSSkPCSEaARwE8HEAW2DwHqxlQoghAF1SyrG0tj8HcFFK+WQy4J8vpfySXX10iuR77hyAuwA8ghr9W+KImYsIIQQSH3z/YHdfXGYzgB9IKSNSyncAnEYiSKtJUsofSynV5M19AK63sz8Otg7AaSnlz6T8/9u7vxCpyjiM49+ntjSVgrBErMT+0V1qBYWoQSIKYlQIdlHSH1JQJOoiqLuiC4OCIOhCEyo2wihNguzPRRlEZbVimYEZVquLUgopgmI8XZx3aXZbW8XcOTvn+cAyZ95zzuxvDr8z85v3PTOvTwBvUuVS49nus/1tWT4C7AKmtDeqUeVO4NWy/CpVURtwB7DHdlNm8hlSCrPRZTZwwPbulrZpknokfSppdrsCq5FVZYhufcvwwBTgt5ZtesmbSL8Hgfdb7ief/pG8OQ2lp3UG8GVpGuocbDIDH0r6RtIjpW2S7T6oilzg8rZFVy9LGdjx0MhcSmFWE5I+lvT9EH+tn9DvZWDS9gFX2Z4BPAa8IenikYx7pA1znF4GrgGmUx2b5/t3G+KhOnoM/3TySdJTwEmguzQ1Lp+G0bi8OVOSJgBvA4/a/pNTn4NNNsv2TGAhsFLSnHYHVEeSLgQWA2+VpsbmUle7A4iK7Xn/tV5SF3A3cFPLPseB42X5G0l7gOuBr89hqG013HHqJ2kt8F652wtc2bL6CmD//xxarZxGPi0DFgF3uFxo2sR8Gkbj8uZMSLqAqijrtv0OgO0DLetbz8HGsr2/3B6UtJFqiPyApMm2+8r1egfbGmQ9LAS+7c+hJudSesxGj3nAj7Z7+xskXVYulkTS1cB1wM9tiq/tygtcv7uA78vyZmCppDGSplEdp69GOr66kLQAeAJYbPtYS3vyaaBtwHWSppVP80upcqnxyvWurwC7bL/Q0n6qc7CRJI0vX45A0nhgPtUx2QwsK5stA95tT4S1MmBEqMm5lB6z0WPw2DvAHOBpSSeBv4AVtg+NeGT18Zyk6VTDTXuB5QC2d0raAPxANXS3sqnfyCxeAsYAH1Xvr3xhewXJpwHKt1ZXAR8A5wPrbe9sc1h1MQu4D/hO5ed7gCeBe4c6BxtsErCxnGddwBu2t0jaBmyQ9BDwK7CkjTG2naRxVN9+bs2XIV/PmyA/lxERERFRExnKjIiIiKiJFGYRERERNZHCLCIiIqImUphFRERE1EQKs4iIiIiaSGEWETGIpM/PYNtVkn6SZEkTz2VcEdH58nMZERFnQdIM4DDwCXCz7d/bG1FEjGbpMYuIjidpU5lEemf/RNKSpkraLWmipPMkfSZpfll3tNxOlrRV0vYy1+i/Jna33WN774g+oYjoWOkxi4iOJ+lS24ckXUQ11dJc239IehhYAHwJXGt7edn+qO0Jkh4Hxtp+tkxXNc72kVP8j72kxywizlKmZIqIJlgt6a6yfCXVPKB/2F4naQmwApg+xH7bgPVlwu5NtrcPsU1ExP8mQ5kR0dEk3Q7MA26zfSPQA4wt68YBV5RNJwze1/ZWqjlE9wGvS7p/JGKOiOZKj1lEdLpLgMO2j0m6Abi1Zd0aoBv4BVgLLGrdUdJUYJ/ttZLGAzOB10Ym7IhoovSYRUSn2wJ0SdoBPAN8ASBpLnALsMZ2N3BC0gOD9r0d2C6pB7gHeHHwg0taLamXqudth6R15+yZRETHy8X/ERERETWRHrOIiIiImkhhFhEREVETKcwiIiIiaiKFWURERERNpDCLiIiIqIkUZhERERE1kcIsIiIioib+BqyGvcTWeGewAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "labels=torch.tensor(test_y)\n",
    "color_dict={0:'#6B2737',1:'#A65B3E',2:'#E08E45',3:'#ECC176',4:'#F8F4A6',5:'#DBF6AF',6:'#BDF7B7',7:'#9CCAB7',8:'#7B9DB7',9:'#3943B7'}\n",
    "fig=plt.figure(figsize=(10,10))\n",
    "rec=[]\n",
    "for i in range(X_emb.shape[0]):\n",
    "    if labels[i].item() not in rec:\n",
    "        rec.append(labels[i].item())\n",
    "        plt.scatter(X_emb[i][0],X_emb[i][1],color=color_dict[labels[i].item()],label=str(labels[i].item()))\n",
    "    else:\n",
    "        plt.scatter(X_emb[i][0],X_emb[i][1],color=color_dict[labels[i].item()])\n",
    "plt.xlabel(\"axis 1\")   \n",
    "plt.ylabel(\"axis 2\")\n",
    "plt.title(\"T-SNE plot\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad76651f",
   "metadata": {
    "id": "435d62c9"
   },
   "source": [
    "## Task II\n",
    "1. Having established a baseline with a linear model trained on a downsampled signal representation of the speech segment, this task aims to learn a classifier based on the full speech segment. To this end, you will implement a neural model that is suitable for sequential data such as recurrent DNN, convolutional DNN with 1-D temporal convolution, or an audio transformer. The model should take the acoustic sample as it is (i.e., the Mel spectrogram could have an arbitrary length) without the need to downsample the segment. You need to implement at least two of the aforementioned models. Do the neural models improve accuracy over the baseline model? Do you observe any signs of overfitting to the training data? How do the hyperparameters affect the model performance? Report and discuss your observations.        \n",
    "\n",
    "2. Evaluate your (best) neural models and compare to the baseline model using the same evalution process as in task I.4. \n",
    "\n",
    "3. Use a dimensionality reduction algorithm such as t-SNE \\[[1](https://en.wikipedia.org/wiki/T-distributed_stochastic_neighbor_embedding),[2](https://pypi.org/project/tsne-torch/),[3](https://scikit-learn.org/stable/modules/generated/sklearn.manifold.TSNE.html)\\] or [UMAP](https://umap-learn.readthedocs.io/en/latest/basic_usage.html) to analyze how the different models seperate the different classes (the last non-linear layer in your model). Compare to the downsampled representation you used in the baseline and report your observations.\n",
    "\n",
    "4. Are the differences between the different models statistically significant? To answer this question, you need to implement a statistical significance test based on bootstrapping method. To read more how to estiame p-values based on bootstrapping, we recommend the materials on this paper https://aclanthology.org/D12-1091.pdf. Include the baseline model in your evaluation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 602,
   "id": "c0251666",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import transforms\n",
    "from torchvision import datasets\n",
    "import torch.nn.functional as F\n",
    "from tqdm import tqdm\n",
    "from torchmetrics import F1Score\n",
    "from torch.utils.data import Dataset,DataLoader\n",
    "from tsne_torch import TorchTSNE as TSNE\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sn\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 430,
   "id": "5636ef41",
   "metadata": {},
   "outputs": [],
   "source": [
    "###Helper function\n",
    "#calculating loss over a dataset\n",
    "def test(model,test_loader):\n",
    "        loss_fn = nn.CrossEntropyLoss()\n",
    "        loss=0\n",
    "        for i,(xs,ys) in enumerate(test_loader):\n",
    "            xs=xs.to(device)\n",
    "            ys=ys.to(device)\n",
    "            pred = model.forward(xs.type(torch.FloatTensor).cuda())\n",
    "            loss+= loss_fn(pred,ys).item()\n",
    "        print(loss/len(test_loader))\n",
    "        return (loss/len(test_loader))\n",
    "##function to get accuracy:\n",
    "def get_accuracy(data,model):\n",
    "    accdata=data\n",
    "    train_acc=0\n",
    "    i=0\n",
    "    for X,Y in accdata:\n",
    "        i+=len(X)\n",
    "        X=X.to(device)\n",
    "        Y=Y.to(device)\n",
    "        ypred=model.forward(X.type(torch.FloatTensor).cuda())\n",
    "        train_acc += torch.sum(ypred.argmax(1) == Y)\n",
    "    accuracy = train_acc/i\n",
    "    \n",
    "    print(accuracy.item()*100,\"%\")\n",
    "    return (accuracy.item())\n",
    "#function to get the f1 score\n",
    "def get_f1(data,model):\n",
    "    accdata=data\n",
    "    F1=0\n",
    "    i=0\n",
    "    for X,Y in accdata:\n",
    "        i+=len(X)\n",
    "        X=X.to(device)\n",
    "        Y=Y.to(device)\n",
    "        f1= F1Score(task=\"multiclass\", num_classes=10).to(device)\n",
    "        ypred=model.forward(X.type(torch.FloatTensor).cuda())\n",
    "        f1 = f1(ypred.argmax(1),Y)\n",
    "        F1+=f1.item()\n",
    "    print(\"F1 score:\",F1/i)\n",
    "    return (f1.item())\n",
    "#function to plot the training loss and change in norm of weight's gradient\n",
    "def plot(lossrec,par):\n",
    "    fig, axs = plt.subplots(1,2,figsize=(20,7))\n",
    "    axs[0].set_title('epoch vs log loss')\n",
    "    axs[0].plot(range(len(lossrec)),lossrec,color='orange',label='Training loss')\n",
    "    axs[0].set_xlabel('epochs')\n",
    "    axs[0].set_ylabel('log loss')\n",
    "    axs[1].plot(range(len(par)),par,marker='o',color='violet',label='weight grad')\n",
    "    axs[1].set_ylabel('norm of weights grad')\n",
    "    axs[1].set_xlabel('epochs')\n",
    "    axs[1].set_title('change of weight grad over epochs ')\n",
    "    axs[1].legend()\n",
    "    plt.show()\n",
    "\n",
    "#function to get the embedding from the models \n",
    "def create_embedding(data,model):\n",
    "    accdata=data\n",
    "    train_acc=0\n",
    "    i=0\n",
    "    YP=torch.ones(1,10)\n",
    "    Ys=[]\n",
    "    for X,Y in accdata:\n",
    "        ypred=model.forward(X.type(torch.FloatTensor).cuda())\n",
    "        YP=torch.tensor(np.concatenate((YP,ypred.detach().cpu().numpy()),axis=0))\n",
    "        Ys+=Y\n",
    "    return YP[1:],Ys\n",
    "# function to visualise the data using tsne\n",
    "def tsne_map(testdl2,modellstm):\n",
    "    embeds,labels=create_embedding(testdl2,modellstm)\n",
    "    X_emb = tsne(n_components=2,init='random', perplexity=3).fit_transform(embeds.cpu().detach().numpy())\n",
    "    color_dict={0:'#6B2737',1:'#A65B3E',2:'#E08E45',3:'#ECC176',4:'#F8F4A6',5:'#DBF6AF',6:'#BDF7B7',7:'#9CCAB7',8:'#7B9DB7',9:'#3943B7'}\n",
    "    fig=plt.figure(figsize=(10,10))\n",
    "    rec=[]\n",
    "    for i in range(X_emb.shape[0]):\n",
    "        if labels[i].item() not in rec:\n",
    "            rec.append(labels[i].item())\n",
    "            plt.scatter(X_emb[i][0],X_emb[i][1],color=color_dict[labels[i].item()],label=str(labels[i].item()))\n",
    "        else:\n",
    "            plt.scatter(X_emb[i][0],X_emb[i][1],color=color_dict[labels[i].item()])\n",
    "    plt.xlabel(\"axis 1\")   \n",
    "    plt.ylabel(\"axis 2\")\n",
    "    plt.title(\"T-SNE plot\")\n",
    "    plt.legend()\n",
    "    \n",
    "# function to plot the confusion matrix\n",
    "def confusionplot(data,model):\n",
    "    accdata=data\n",
    "    \n",
    "    YP=[]\n",
    "    Ys=[]\n",
    "    for X,Y in accdata:\n",
    "        X=X.to(device)\n",
    "        y_pred=torch.argmax(model.forward(X.type(torch.FloatTensor).cuda()),dim=1)\n",
    "        YP+=y_pred.cpu()\n",
    "        Ys+=Y\n",
    "    cf_matrix = confusion_matrix(Ys, YP)\n",
    "    classes = (0,1,2,3,4,5,6,7,8,9)\n",
    "    df_cm = pd.DataFrame(cf_matrix / np.sum(cf_matrix, axis=1)[:, None], index = [i for i in classes],\n",
    "                         columns = [i for i in classes])\n",
    "    plt.figure(figsize = (12,10))\n",
    "    sn.heatmap(df_cm, annot=True)\n",
    "def classificationReport(data,model):\n",
    "    accdata=data\n",
    "    YP=[]\n",
    "    Ys=[]\n",
    "    for X,Y in accdata:\n",
    "        X=X.to(device)\n",
    "        y_pred=torch.argmax(model.forward(X.type(torch.FloatTensor).cuda()),dim=1)\n",
    "        YP+=y_pred.cpu()\n",
    "        Ys+=Y\n",
    "    print(classification_report(Ys, YP, labels=list(range(10))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fcd37966",
   "metadata": {},
   "outputs": [],
   "source": [
    "class customDataset(Dataset):\n",
    "    def __init__(self, datalist, labels):\n",
    "        self.labels = labels #contains the labels of the audio samples\n",
    "        self.datalist = datalist # contains the audio samples in a numpy array form\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.datalist.shape[0]\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        label = self.labels[idx]\n",
    "        data = self.datalist[idx]\n",
    "        return data, label\n",
    "\n",
    "\n",
    "class customDataLoader(DataLoader):\n",
    "    def __init__(self, customdata, batch_size, collate_fn=None):\n",
    "        self.customdata = customdata\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "    def loader(self):\n",
    "        return DataLoader(self.customdata, self.batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b3ae3c3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "229\n"
     ]
    }
   ],
   "source": [
    "## data processing\n",
    "\n",
    "# determining the longest sequence\n",
    "maxlength=0\n",
    "for path,split,label in zip(sdr_df['file'],sdr_df['split'],sdr_df['label']):\n",
    "        x, sr = librosa.load(path, sr=SAMPLING_RATE)\n",
    "        melspectrogram = extract_melspectrogram(x, sr, num_mels=13)\n",
    "        if maxlength < melspectrogram.shape[1]:\n",
    "            maxlength = melspectrogram.shape[1]\n",
    "print(maxlength)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9d3f3b27",
   "metadata": {},
   "outputs": [],
   "source": [
    "## finding the maximum value in the melspectrogram # used later for normalising the data\n",
    "max_val = -np.inf\n",
    "for path, split, label in zip(sdr_df['file'], sdr_df['split'], sdr_df['label']):\n",
    "    x, sr = librosa.load(path, sr=SAMPLING_RATE)\n",
    "    melspectrogram = extract_melspectrogram(x, sr, num_mels=13)\n",
    "    if np.max(melspectrogram) > max_val:\n",
    "        max_val = np.max(melspectrogram)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ed8c806",
   "metadata": {},
   "source": [
    "### Model 1: 1D CNN based"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a188918",
   "metadata": {},
   "source": [
    "The data for the CNN based model was prepared such that all the samples are of the size 13X256. The longest sequence from the dataset turned out to be 229 which was then padded by 27 so that a size which is a power of 2 is obtained. This is done so that the size can be tracked easily after downsampling from maxpooling layer occurs. And since CNN is translational equivarient so it does not affect the performance that much[4]. The data is also normalised.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f4cb6611",
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy=np.zeros((1,melspectrogram.shape[0],maxlength+27))\n",
    "datadict = {'TRAIN':dummy,'DEV':dummy,'TEST':dummy}\n",
    "labeldict = {'TRAIN':[],'DEV':[],'TEST':[]}\n",
    "for path,split,label in zip(sdr_df['file'],sdr_df['split'],sdr_df['label']):\n",
    "        x, sr = librosa.load(path, sr=SAMPLING_RATE)\n",
    "        melspectrogram = extract_melspectrogram(x, sr, num_mels=13)/max_val\n",
    "        data = torch.tensor(np.concatenate((melspectrogram,np.zeros((melspectrogram.shape[0],maxlength-melspectrogram.shape[1]+27))),axis = 1))## the dimension is made to be 256 so that it works with the maxpooling layers in the architecture.\n",
    "        data = data.view(1,melspectrogram.shape[0],-1) \n",
    "        datadict[split]=torch.tensor(np.concatenate((datadict[split],data),axis=0))\n",
    "        labeldict[split].append(label)\n",
    "train_data = datadict['TRAIN'][1:]\n",
    "test_data = datadict['TEST'][1:]\n",
    "val_data = datadict['DEV'][1:]\n",
    "train_y = labeldict['TRAIN'] \n",
    "test_y = labeldict['TEST']\n",
    "val_y = labeldict['DEV']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "6e02c961",
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_train_dataset = customDataset(train_data, train_y)\n",
    "custom_train_loader = customDataLoader(custom_train_dataset, batch_size=32)\n",
    "traindl = custom_train_loader.loader()\n",
    "\n",
    "custom_test_dataset = customDataset(test_data, test_y)\n",
    "custom_test_loader = customDataLoader(custom_test_dataset, batch_size=503)\n",
    "testdl = custom_test_loader.loader()\n",
    "\n",
    "custom_val_dataset = customDataset(val_data, val_y)\n",
    "custom_val_loader = customDataLoader(custom_val_dataset, batch_size=32)\n",
    "valdl = custom_val_loader.loader()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e4d5413",
   "metadata": {},
   "source": [
    "The CNN architecture is having 6 convolutional blocks and each of them is composed of two convolutional layers followed by Batch Normalisation, Relu Activation and Maxpooling layer. A dropout layer is applied after every convolutional layer. the dropout probability is determined later during hyperparameter tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "058055da",
   "metadata": {},
   "outputs": [],
   "source": [
    "class cnnModel(nn.Module):\n",
    "    def __init__(self, input_dim, kernel_size,d):\n",
    "        super(cnnModel, self).__init__() \n",
    "        self.input_dim = input_dim\n",
    "        self.k_size = kernel_size \n",
    "        self.d=d\n",
    "        layers = []\n",
    "        layers.append(nn.Conv1d(in_channels=self.input_dim, out_channels=26, kernel_size=self.k_size, padding='same',bias=False, stride=1))\n",
    "        layers.append(nn.Dropout(p=self.d))\n",
    "        layers.append(nn.Conv1d(in_channels=26, out_channels=26, kernel_size=self.k_size, padding='same',bias=False, stride=1))\n",
    "        layers.append(nn.Dropout(p=self.d))\n",
    "        layers.append(nn.BatchNorm1d(26))\n",
    "        layers.append(nn.ReLU())\n",
    "        layers.append(nn.MaxPool1d(kernel_size=2, stride=2))\n",
    "        \n",
    "        \n",
    "        layers.append(nn.Conv1d(in_channels=26, out_channels=52, kernel_size=self.k_size, padding='same',bias=False, stride=1))\n",
    "        layers.append(nn.Dropout(p=self.d))\n",
    "        layers.append(nn.Conv1d(in_channels=52, out_channels=52, kernel_size=self.k_size, padding='same',bias=False, stride=1))\n",
    "        layers.append(nn.Dropout(p=self.d))\n",
    "        layers.append(nn.BatchNorm1d(52))\n",
    "        layers.append(nn.ReLU())\n",
    "        layers.append(nn.MaxPool1d(kernel_size=2, stride=2))\n",
    "        \n",
    "        \n",
    "        layers.append(nn.Conv1d(in_channels=52, out_channels=104, kernel_size=self.k_size, padding='same',bias=False, stride=1))\n",
    "        layers.append(nn.Dropout(p=self.d))\n",
    "        layers.append(nn.Conv1d(in_channels=104, out_channels=104, kernel_size=self.k_size, padding='same',bias=False, stride=1))\n",
    "        layers.append(nn.Dropout(p=self.d))\n",
    "        layers.append(nn.BatchNorm1d(104))\n",
    "        layers.append(nn.ReLU())\n",
    "        layers.append(nn.MaxPool1d(kernel_size=2, stride=2))\n",
    "        \n",
    "        layers.append(nn.Conv1d(in_channels=104, out_channels=104, kernel_size=self.k_size, padding='same',bias=False, stride=1))\n",
    "        layers.append(nn.Dropout(p=self.d))\n",
    "        layers.append(nn.Conv1d(in_channels=104, out_channels=52, kernel_size=self.k_size, padding='same',bias=False, stride=1))\n",
    "        layers.append(nn.Dropout(p=self.d))\n",
    "        layers.append(nn.BatchNorm1d(52))\n",
    "        layers.append(nn.ReLU())\n",
    "        layers.append(nn.MaxPool1d(kernel_size=2, stride=2))\n",
    "        \n",
    "        \n",
    "        layers.append(nn.Conv1d(in_channels=52, out_channels=52, kernel_size=self.k_size, padding='same',bias=False, stride=1))\n",
    "        layers.append(nn.Dropout(p=self.d))\n",
    "        layers.append(nn.Conv1d(in_channels=52, out_channels=26, kernel_size=self.k_size, padding='same',bias=False, stride=1))\n",
    "        layers.append(nn.Dropout(p=self.d))\n",
    "        layers.append(nn.BatchNorm1d(26))\n",
    "        layers.append(nn.ReLU())\n",
    "        layers.append(nn.MaxPool1d(kernel_size=2, stride=2))\n",
    "        \n",
    "        layers.append(nn.Conv1d(in_channels=26, out_channels=26, kernel_size=self.k_size, padding='same',bias=False, stride=1))\n",
    "        layers.append(nn.Dropout(p=self.d))\n",
    "        layers.append(nn.Conv1d(in_channels=26, out_channels=26, kernel_size=self.k_size, padding='same',bias=False, stride=1))\n",
    "        layers.append(nn.Dropout(p=self.d))\n",
    "        layers.append(nn.BatchNorm1d(26))\n",
    "        layers.append(nn.ReLU())\n",
    "        layers.append(nn.MaxPool1d(kernel_size=2, stride=2))\n",
    "        \n",
    "        \n",
    "        self.conv_layers = nn.Sequential(*layers)\n",
    "        \n",
    "        self.fc_layers = nn.Sequential(\n",
    "            nn.Linear(26 * 4, 350, bias=True),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(350, 10, bias=True),\n",
    "            nn.Softmax(dim=1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Reshape input tensor to be compatible with convolutional layers\n",
    "        x = self.conv_layers(x.type(torch.FloatTensor).cuda())\n",
    "        x = x.view(x.size(0), -1)  # Flatten tensor\n",
    "        \n",
    "        # Feed flattened tensor through fully connected layers\n",
    "        x = self.fc_layers(x)\n",
    "        \n",
    "        return x\n",
    "    \n",
    "    def train(self,train_loader,learning_rate=0.01,epochs=5,lam=0.01,opti='adam'):\n",
    "        optidict={'adagrad':torch.optim.Adagrad(self.parameters(), lr=learning_rate),'adam':torch.optim.Adam(self.parameters(),lr=learning_rate),'sgd':torch.optim.SGD(self.parameters(), lr=learning_rate)}\n",
    "        loss_fn = nn.CrossEntropyLoss()\n",
    "        optimizer = optidict[opti]\n",
    "        optimizer.weight_decay = lam #torch.optim.Adam(self.parameters(),lr=learning_rate,weight_decay=lam)\n",
    "        lossrec=[]\n",
    "        par_grad=[]\n",
    "        for epoch in range(epochs):\n",
    "            tloss=0\n",
    "            total_grad=0\n",
    "            for i,(xs,ys) in enumerate(train_loader):\n",
    "                xs=xs.to(device)\n",
    "                ys=ys.to(device)\n",
    "                pred = self.forward(xs.type(torch.FloatTensor).cuda())                \n",
    "                loss = loss_fn(pred,ys) \n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                \n",
    "                grad=0\n",
    "                for p in self.parameters():\n",
    "                    grad+=torch.norm(p.grad).item()\n",
    "                    \n",
    "                total_grad+=grad\n",
    "                tloss+=loss\n",
    "            lossrec.append((tloss/len(train_loader)).log().item())\n",
    "            par_grad.append((total_grad/len(train_loader)))\n",
    "            print('epoch:',epoch,'loss:',(tloss/len(train_loader)).item(),'grad:',(total_grad/len(train_loader)))\n",
    "        return lossrec,par_grad"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f89a1914",
   "metadata": {},
   "source": [
    "#### Tuning the Hyperparameters\n",
    "The following script is for selecting the optimal values for the hyperparameter by training the model multiple times with the different set of hyperparameters and then evaluating them based on the validation loss obtained. The hyperparameter values that gives the lowest values for validation loss are reported."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 583,
   "id": "bbefc851",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0 loss: 2.2930805683135986 grad: 1.5850450685561916\n",
      "epoch: 1 loss: 2.240147829055786 grad: 1.427302191736147\n",
      "epoch: 2 loss: 2.22637677192688 grad: 1.2675270126681657\n",
      "epoch: 3 loss: 2.2212109565734863 grad: 1.214669512860137\n",
      "epoch: 4 loss: 2.2173714637756348 grad: 1.294983855655624\n",
      "epoch: 5 loss: 2.215639352798462 grad: 1.3666256525394846\n",
      "epoch: 6 loss: 2.211505651473999 grad: 1.4911880902243808\n",
      "epoch: 7 loss: 2.2052409648895264 grad: 1.6296624009467897\n",
      "epoch: 8 loss: 2.1931262016296387 grad: 1.9753857920803721\n",
      "epoch: 9 loss: 2.1798388957977295 grad: 2.4817684924059975\n",
      "epoch: 10 loss: 2.1689720153808594 grad: 2.6472616388447703\n",
      "epoch: 11 loss: 2.1603729724884033 grad: 3.02328000206589\n",
      "epoch: 12 loss: 2.153085708618164 grad: 3.1691630611284856\n",
      "epoch: 13 loss: 2.1430416107177734 grad: 3.515254119932208\n",
      "epoch: 14 loss: 2.136294364929199 grad: 3.6435443219167016\n",
      "epoch: 15 loss: 2.124990940093994 grad: 4.113669657022766\n",
      "epoch: 16 loss: 2.114968776702881 grad: 4.437692186373862\n",
      "epoch: 17 loss: 2.10304856300354 grad: 4.860149613588989\n",
      "epoch: 18 loss: 2.087614059448242 grad: 5.2363365780236935\n",
      "epoch: 19 loss: 2.075305223464966 grad: 5.299811499067656\n",
      "epoch: 20 loss: 2.0662729740142822 grad: 5.666140825029403\n",
      "epoch: 21 loss: 2.0536880493164062 grad: 5.741932281211669\n",
      "epoch: 22 loss: 2.0413386821746826 grad: 5.898859421419542\n",
      "epoch: 23 loss: 2.0322446823120117 grad: 6.17058598828162\n",
      "epoch: 24 loss: 2.0244438648223877 grad: 6.364828904440242\n",
      "epoch: 25 loss: 2.0117337703704834 grad: 6.335397683601412\n",
      "epoch: 26 loss: 2.000375747680664 grad: 7.020897404046818\n",
      "epoch: 27 loss: 1.9965745210647583 grad: 6.94940570023443\n",
      "epoch: 28 loss: 1.986276388168335 grad: 7.187000059167898\n",
      "epoch: 29 loss: 1.9699499607086182 grad: 6.916474223210816\n",
      "epoch: 30 loss: 1.9647736549377441 grad: 7.357626651635482\n",
      "epoch: 31 loss: 1.95683753490448 grad: 7.753623820870878\n",
      "epoch: 32 loss: 1.9481922388076782 grad: 7.686741957477929\n",
      "epoch: 33 loss: 1.9418089389801025 grad: 7.82555699038748\n",
      "epoch: 34 loss: 1.9360888004302979 grad: 7.914255412672425\n",
      "epoch: 35 loss: 1.9245390892028809 grad: 7.800284087687494\n",
      "epoch: 36 loss: 1.9200327396392822 grad: 8.050420811525472\n",
      "epoch: 37 loss: 1.914373517036438 grad: 8.464814936210002\n",
      "epoch: 38 loss: 1.9107728004455566 grad: 8.14287778093583\n",
      "epoch: 39 loss: 1.9057133197784424 grad: 8.159820489703662\n",
      "epoch: 40 loss: 1.8964316844940186 grad: 8.090024681658381\n",
      "epoch: 41 loss: 1.8888059854507446 grad: 9.054091508988114\n",
      "epoch: 42 loss: 1.8917138576507568 grad: 8.801125562040223\n",
      "epoch: 43 loss: 1.8820407390594482 grad: 8.605721873852113\n",
      "epoch: 44 loss: 1.8739213943481445 grad: 8.888785641529553\n",
      "epoch: 45 loss: 1.872238278388977 grad: 9.177319349484547\n",
      "epoch: 46 loss: 1.868104338645935 grad: 9.542793675000587\n",
      "epoch: 47 loss: 1.8589653968811035 grad: 9.362394230174166\n",
      "epoch: 48 loss: 1.860674262046814 grad: 10.024323657206777\n",
      "epoch: 49 loss: 1.8542543649673462 grad: 9.519313783621387\n",
      "epoch: 50 loss: 1.848645806312561 grad: 9.709500783729174\n",
      "epoch: 51 loss: 1.8522250652313232 grad: 9.498970318644766\n",
      "epoch: 52 loss: 1.8408210277557373 grad: 9.614022604086333\n",
      "epoch: 53 loss: 1.845260739326477 grad: 9.849038711926411\n",
      "epoch: 54 loss: 1.8421721458435059 grad: 9.99098188481811\n",
      "epoch: 55 loss: 1.830185055732727 grad: 9.78777763237142\n",
      "epoch: 56 loss: 1.8260256052017212 grad: 9.474689264367852\n",
      "epoch: 57 loss: 1.8303868770599365 grad: 9.75578234013584\n",
      "epoch: 58 loss: 1.826534390449524 grad: 9.856105280833113\n",
      "epoch: 59 loss: 1.823021411895752 grad: 9.759315554983914\n",
      "epoch: 60 loss: 1.8244704008102417 grad: 9.888375440708524\n",
      "epoch: 61 loss: 1.8161324262619019 grad: 9.955210053421084\n",
      "epoch: 62 loss: 1.8153661489486694 grad: 10.105094353697957\n",
      "epoch: 63 loss: 1.8203661441802979 grad: 9.924294070178082\n",
      "epoch: 64 loss: 1.8127024173736572 grad: 9.884336830818997\n",
      "epoch: 65 loss: 1.8065413236618042 grad: 9.853431253841826\n",
      "epoch: 66 loss: 1.8043386936187744 grad: 9.691385619844946\n",
      "epoch: 67 loss: 1.8003442287445068 grad: 10.09727795242465\n",
      "epoch: 68 loss: 1.8045425415039062 grad: 9.693000267060208\n",
      "epoch: 69 loss: 1.8040293455123901 grad: 9.98046456663204\n",
      "epoch: 70 loss: 1.800995945930481 grad: 10.19684327897128\n",
      "epoch: 71 loss: 1.7914514541625977 grad: 10.197695739981201\n",
      "epoch: 72 loss: 1.7947194576263428 grad: 9.981379175056068\n",
      "epoch: 73 loss: 1.7892690896987915 grad: 10.363138814870682\n",
      "epoch: 74 loss: 1.7883272171020508 grad: 9.969346004286928\n",
      "epoch: 75 loss: 1.7841702699661255 grad: 10.144486518576741\n",
      "epoch: 76 loss: 1.7886379957199097 grad: 10.415825821681036\n",
      "epoch: 77 loss: 1.7782303094863892 grad: 9.850858717447235\n",
      "epoch: 78 loss: 1.7851697206497192 grad: 10.507060059154082\n",
      "epoch: 79 loss: 1.7759413719177246 grad: 9.984090563634204\n",
      "epoch: 80 loss: 1.7790963649749756 grad: 10.167080416499326\n",
      "epoch: 81 loss: 1.7799729108810425 grad: 9.859674565760153\n",
      "epoch: 82 loss: 1.7773653268814087 grad: 10.228340881920996\n",
      "epoch: 83 loss: 1.7671353816986084 grad: 11.123978166796622\n",
      "epoch: 84 loss: 1.767535924911499 grad: 10.285897605771583\n",
      "epoch: 85 loss: 1.7732256650924683 grad: 10.350007249419356\n",
      "epoch: 86 loss: 1.768308401107788 grad: 10.210116639008952\n",
      "epoch: 87 loss: 1.771401047706604 grad: 10.807683678018668\n",
      "epoch: 88 loss: 1.7650970220565796 grad: 10.092765806885879\n",
      "epoch: 89 loss: 1.7658519744873047 grad: 10.837111527381081\n",
      "epoch: 90 loss: 1.766129732131958 grad: 10.680052194921743\n",
      "epoch: 91 loss: 1.7622215747833252 grad: 10.67861422665772\n",
      "epoch: 92 loss: 1.7624456882476807 grad: 10.797523558258064\n",
      "epoch: 93 loss: 1.75621497631073 grad: 10.565740769019438\n",
      "epoch: 94 loss: 1.7550069093704224 grad: 10.625756503570647\n",
      "epoch: 95 loss: 1.7508126497268677 grad: 10.709505407834454\n",
      "epoch: 96 loss: 1.7517873048782349 grad: 10.82305090014069\n",
      "epoch: 97 loss: 1.7525805234909058 grad: 11.267384591468034\n",
      "epoch: 98 loss: 1.755805253982544 grad: 11.075546042779314\n",
      "epoch: 99 loss: 1.7475826740264893 grad: 10.437791689254698\n",
      "epoch: 100 loss: 1.7439332008361816 grad: 10.925407670866994\n",
      "epoch: 101 loss: 1.74250066280365 grad: 10.73325251048756\n",
      "epoch: 102 loss: 1.744468331336975 grad: 11.78106154031342\n",
      "epoch: 103 loss: 1.7496522665023804 grad: 11.310986401912357\n",
      "epoch: 104 loss: 1.7417858839035034 grad: 11.603982079840664\n",
      "epoch: 105 loss: 1.7345566749572754 grad: 10.916084389911877\n",
      "epoch: 106 loss: 1.7427617311477661 grad: 11.818833688377506\n",
      "epoch: 107 loss: 1.7374697923660278 grad: 11.964138010620243\n",
      "epoch: 108 loss: 1.7318094968795776 grad: 10.934240054206125\n",
      "epoch: 109 loss: 1.728708267211914 grad: 11.042004696699598\n",
      "epoch: 110 loss: 1.7331299781799316 grad: 11.137996154822527\n",
      "epoch: 111 loss: 1.736659288406372 grad: 11.291024406603167\n",
      "epoch: 112 loss: 1.7304335832595825 grad: 11.43623863114044\n",
      "epoch: 113 loss: 1.7263094186782837 grad: 11.002918698115362\n",
      "epoch: 114 loss: 1.728798508644104 grad: 10.989644288776502\n",
      "epoch: 115 loss: 1.722739577293396 grad: 11.495532027800524\n",
      "epoch: 116 loss: 1.7276378870010376 grad: 11.333838449672811\n",
      "epoch: 117 loss: 1.7283728122711182 grad: 11.255987776066398\n",
      "epoch: 118 loss: 1.7232388257980347 grad: 11.509295228351322\n",
      "epoch: 119 loss: 1.7188187837600708 grad: 11.161582325311702\n",
      "epoch: 120 loss: 1.717463731765747 grad: 11.615970713522522\n",
      "epoch: 121 loss: 1.7200826406478882 grad: 12.052757121474734\n",
      "epoch: 122 loss: 1.722697377204895 grad: 12.125220515573073\n",
      "epoch: 123 loss: 1.7178795337677002 grad: 11.676459200081549\n",
      "epoch: 124 loss: 1.712303876876831 grad: 11.136705127049474\n",
      "epoch: 125 loss: 1.7156811952590942 grad: 10.963258561382572\n",
      "epoch: 126 loss: 1.7126060724258423 grad: 11.287449102213104\n",
      "epoch: 127 loss: 1.7092187404632568 grad: 11.13854145900982\n",
      "epoch: 128 loss: 1.7103385925292969 grad: 11.414914593388815\n",
      "epoch: 129 loss: 1.7143958806991577 grad: 11.645219697395252\n",
      "epoch: 130 loss: 1.7070876359939575 grad: 11.925738203487107\n",
      "epoch: 131 loss: 1.7061917781829834 grad: 11.148797131187859\n",
      "epoch: 132 loss: 1.6987969875335693 grad: 11.680145955873682\n",
      "epoch: 133 loss: 1.705875039100647 grad: 12.081673718759761\n",
      "epoch: 134 loss: 1.702686071395874 grad: 11.450874487499869\n",
      "epoch: 135 loss: 1.702052354812622 grad: 10.405445281900318\n",
      "epoch: 136 loss: 1.7042893171310425 grad: 11.567405182203013\n",
      "epoch: 137 loss: 1.6985522508621216 grad: 11.195738059002906\n",
      "epoch: 138 loss: 1.7057372331619263 grad: 11.103155727446493\n",
      "epoch: 139 loss: 1.7034082412719727 grad: 11.861160821480942\n",
      "epoch: 140 loss: 1.7030714750289917 grad: 12.001009065192193\n",
      "epoch: 141 loss: 1.6893792152404785 grad: 11.096450377122633\n",
      "epoch: 142 loss: 1.6921489238739014 grad: 11.26048371149227\n",
      "epoch: 143 loss: 1.6952685117721558 grad: 11.530652964598543\n",
      "epoch: 144 loss: 1.6956896781921387 grad: 11.660615239447603\n",
      "epoch: 145 loss: 1.6923534870147705 grad: 11.746274149547967\n",
      "epoch: 146 loss: 1.6927663087844849 grad: 11.355191250050824\n",
      "epoch: 147 loss: 1.6979409456253052 grad: 11.217018018003612\n",
      "epoch: 148 loss: 1.6907036304473877 grad: 11.023228630068756\n",
      "epoch: 149 loss: 1.6927019357681274 grad: 11.403233072853514\n",
      "epoch: 150 loss: 1.6882721185684204 grad: 11.774866869259212\n",
      "epoch: 151 loss: 1.6929669380187988 grad: 11.421543517113028\n",
      "epoch: 152 loss: 1.691362977027893 grad: 11.799639606515743\n",
      "epoch: 153 loss: 1.684303879737854 grad: 10.872584395184521\n",
      "epoch: 154 loss: 1.6904586553573608 grad: 11.490569065554096\n",
      "epoch: 155 loss: 1.6824657917022705 grad: 11.227560160888565\n",
      "epoch: 156 loss: 1.6861616373062134 grad: 11.146141739783896\n",
      "epoch: 157 loss: 1.6808953285217285 grad: 11.378465257851142\n",
      "epoch: 158 loss: 1.677656650543213 grad: 11.082359147117666\n",
      "epoch: 159 loss: 1.6857922077178955 grad: 11.505434149750583\n",
      "epoch: 160 loss: 1.6801714897155762 grad: 10.794866719253598\n",
      "epoch: 161 loss: 1.6812173128128052 grad: 11.073153409881458\n",
      "epoch: 162 loss: 1.6835527420043945 grad: 11.713177933675489\n",
      "epoch: 163 loss: 1.674944281578064 grad: 11.524478759616613\n",
      "epoch: 164 loss: 1.6717818975448608 grad: 11.63338339146197\n",
      "epoch: 165 loss: 1.6788064241409302 grad: 11.267740841962338\n",
      "epoch: 166 loss: 1.6755905151367188 grad: 11.473357250869629\n",
      "epoch: 167 loss: 1.6808910369873047 grad: 11.691891153912163\n",
      "epoch: 168 loss: 1.6733595132827759 grad: 11.023304062171114\n",
      "epoch: 169 loss: 1.676595687866211 grad: 11.265463217191162\n",
      "epoch: 170 loss: 1.677783727645874 grad: 11.12938061088974\n",
      "epoch: 171 loss: 1.6689101457595825 grad: 10.535308601667307\n",
      "epoch: 172 loss: 1.672951102256775 grad: 11.497719768353457\n",
      "epoch: 173 loss: 1.6755365133285522 grad: 10.983585239410223\n",
      "epoch: 174 loss: 1.6746196746826172 grad: 11.765112969972607\n",
      "epoch: 175 loss: 1.6709198951721191 grad: 11.428648152462547\n",
      "epoch: 176 loss: 1.6701090335845947 grad: 10.459115117795706\n",
      "epoch: 177 loss: 1.6736689805984497 grad: 11.237331915425049\n",
      "epoch: 178 loss: 1.666839599609375 grad: 11.005999177561275\n",
      "epoch: 179 loss: 1.6702947616577148 grad: 11.586970670880484\n",
      "epoch: 180 loss: 1.6664046049118042 grad: 11.106530033961116\n",
      "epoch: 181 loss: 1.6694546937942505 grad: 11.555370713014984\n",
      "epoch: 182 loss: 1.6703943014144897 grad: 11.337926525068248\n",
      "epoch: 183 loss: 1.668541431427002 grad: 11.358665548383243\n",
      "epoch: 184 loss: 1.6598951816558838 grad: 10.754010956933987\n",
      "epoch: 185 loss: 1.6692252159118652 grad: 11.054738809557868\n",
      "epoch: 186 loss: 1.6645424365997314 grad: 11.630104522937762\n",
      "epoch: 187 loss: 1.6651204824447632 grad: 11.303999556494611\n",
      "epoch: 188 loss: 1.6644361019134521 grad: 11.467232041748328\n",
      "epoch: 189 loss: 1.661044955253601 grad: 10.862341560120324\n",
      "epoch: 190 loss: 1.6598846912384033 grad: 11.05362705060739\n",
      "epoch: 191 loss: 1.6600911617279053 grad: 11.866776437217753\n",
      "epoch: 192 loss: 1.6605638265609741 grad: 11.935032332449087\n",
      "epoch: 193 loss: 1.653050184249878 grad: 11.830335709813331\n",
      "epoch: 194 loss: 1.651125192642212 grad: 11.893183151230453\n",
      "epoch: 195 loss: 1.649451732635498 grad: 11.671026881458976\n",
      "epoch: 196 loss: 1.6528691053390503 grad: 12.631807392403957\n",
      "epoch: 197 loss: 1.6528456211090088 grad: 12.000192812976561\n",
      "epoch: 198 loss: 1.6504822969436646 grad: 12.540121376270516\n",
      "epoch: 199 loss: 1.6492533683776855 grad: 11.437515684181736\n",
      "epoch: 200 loss: 1.6491643190383911 grad: 12.351384955864873\n",
      "epoch: 201 loss: 1.646127700805664 grad: 12.123270039269258\n",
      "epoch: 202 loss: 1.6412595510482788 grad: 12.000930127761666\n",
      "epoch: 203 loss: 1.6424744129180908 grad: 12.14129646246632\n",
      "epoch: 204 loss: 1.6431668996810913 grad: 13.033411631656309\n",
      "epoch: 205 loss: 1.643810749053955 grad: 12.568716853590947\n",
      "epoch: 206 loss: 1.6365361213684082 grad: 12.215564295390827\n",
      "epoch: 207 loss: 1.6439119577407837 grad: 13.191772980157227\n",
      "epoch: 208 loss: 1.6394598484039307 grad: 11.740263999240208\n",
      "epoch: 209 loss: 1.6359901428222656 grad: 12.712425579198651\n",
      "epoch: 210 loss: 1.6376615762710571 grad: 12.555999484844506\n",
      "epoch: 211 loss: 1.6348505020141602 grad: 12.845473799433204\n",
      "epoch: 212 loss: 1.635007381439209 grad: 12.821364906867819\n",
      "epoch: 213 loss: 1.639583706855774 grad: 13.208365460539916\n",
      "epoch: 214 loss: 1.6386120319366455 grad: 12.582183223897738\n",
      "epoch: 215 loss: 1.632198452949524 grad: 12.763649694932004\n",
      "epoch: 216 loss: 1.6222730875015259 grad: 13.113495109706289\n",
      "epoch: 217 loss: 1.6274218559265137 grad: 12.094665912482592\n",
      "epoch: 218 loss: 1.6310323476791382 grad: 12.659695639105012\n",
      "epoch: 219 loss: 1.6246628761291504 grad: 13.258618180506996\n",
      "epoch: 220 loss: 1.6215901374816895 grad: 13.187371702140403\n",
      "epoch: 221 loss: 1.6212478876113892 grad: 12.013439685073015\n",
      "epoch: 222 loss: 1.6298340559005737 grad: 13.524826418460599\n",
      "epoch: 223 loss: 1.6302062273025513 grad: 13.030311238501103\n",
      "epoch: 224 loss: 1.6216918230056763 grad: 13.48551033947262\n",
      "epoch: 225 loss: 1.6245534420013428 grad: 12.879359827657778\n",
      "epoch: 226 loss: 1.6221786737442017 grad: 13.14522352098443\n",
      "epoch: 227 loss: 1.6208008527755737 grad: 13.25709746914014\n",
      "epoch: 228 loss: 1.6277618408203125 grad: 13.058385663562351\n",
      "epoch: 229 loss: 1.6214230060577393 grad: 13.365571467058054\n",
      "epoch: 230 loss: 1.618193507194519 grad: 13.483156533956173\n",
      "epoch: 231 loss: 1.6148649454116821 grad: 12.1439800610958\n",
      "epoch: 232 loss: 1.6112308502197266 grad: 12.545211074045962\n",
      "epoch: 233 loss: 1.6135791540145874 grad: 12.818155761379453\n",
      "epoch: 234 loss: 1.61305832862854 grad: 13.004060362776121\n",
      "epoch: 235 loss: 1.6108033657073975 grad: 12.173164067080332\n",
      "epoch: 236 loss: 1.6133166551589966 grad: 13.900122970180025\n",
      "epoch: 237 loss: 1.611614465713501 grad: 12.807799405011806\n",
      "epoch: 238 loss: 1.611668586730957 grad: 12.791933159691297\n",
      "epoch: 239 loss: 1.6123976707458496 grad: 12.307780634316186\n",
      "epoch: 240 loss: 1.6108466386795044 grad: 13.234016966296448\n",
      "epoch: 241 loss: 1.6017332077026367 grad: 12.175755112291506\n",
      "epoch: 242 loss: 1.6076712608337402 grad: 13.220570513963818\n",
      "epoch: 243 loss: 1.5999131202697754 grad: 12.738553408060282\n",
      "epoch: 244 loss: 1.597853183746338 grad: 12.786089685375964\n",
      "epoch: 245 loss: 1.6016398668289185 grad: 12.805502499246764\n",
      "epoch: 246 loss: 1.6027939319610596 grad: 12.547134644167114\n",
      "epoch: 247 loss: 1.6026760339736938 grad: 12.7644405882096\n",
      "epoch: 248 loss: 1.5976910591125488 grad: 11.995840289925654\n",
      "epoch: 249 loss: 1.6004233360290527 grad: 12.28803559690566\n",
      "epoch: 250 loss: 1.595860242843628 grad: 13.27985127965757\n",
      "epoch: 251 loss: 1.5939961671829224 grad: 12.638125925213986\n",
      "epoch: 252 loss: 1.6068195104599 grad: 12.760291797315908\n",
      "epoch: 253 loss: 1.5931477546691895 grad: 12.09360071154873\n",
      "epoch: 254 loss: 1.600116491317749 grad: 12.344022552275824\n",
      "epoch: 255 loss: 1.5970563888549805 grad: 12.045077628359968\n",
      "epoch: 256 loss: 1.598280906677246 grad: 11.831125270575285\n",
      "epoch: 257 loss: 1.593252182006836 grad: 13.079424298035779\n",
      "epoch: 258 loss: 1.598368525505066 grad: 13.289767056274863\n",
      "epoch: 259 loss: 1.5964332818984985 grad: 12.811557181534313\n",
      "epoch: 260 loss: 1.5912883281707764 grad: 12.541105003406605\n",
      "epoch: 261 loss: 1.5894391536712646 grad: 12.808713430350291\n",
      "epoch: 262 loss: 1.5904138088226318 grad: 11.882903891253388\n",
      "epoch: 263 loss: 1.5858439207077026 grad: 12.706342323380152\n",
      "epoch: 264 loss: 1.5869238376617432 grad: 11.623117914319867\n",
      "epoch: 265 loss: 1.5864439010620117 grad: 11.534090967176276\n",
      "epoch: 266 loss: 1.584320306777954 grad: 12.371358784499563\n",
      "epoch: 267 loss: 1.5916703939437866 grad: 13.650820329400991\n",
      "epoch: 268 loss: 1.5937016010284424 grad: 13.149420034118174\n",
      "epoch: 269 loss: 1.5861033201217651 grad: 12.852005096581129\n",
      "epoch: 270 loss: 1.5890387296676636 grad: 12.492049413119695\n",
      "epoch: 271 loss: 1.5868240594863892 grad: 11.99027960893831\n",
      "epoch: 272 loss: 1.5883280038833618 grad: 12.34959398533055\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 273 loss: 1.5928117036819458 grad: 12.94690791644629\n",
      "epoch: 274 loss: 1.5875407457351685 grad: 12.657472598758186\n",
      "epoch: 275 loss: 1.5787863731384277 grad: 11.931470529701087\n",
      "epoch: 276 loss: 1.5878088474273682 grad: 13.120213040823323\n",
      "epoch: 277 loss: 1.5863579511642456 grad: 13.297351765867678\n",
      "epoch: 278 loss: 1.5789457559585571 grad: 12.595597066103466\n",
      "epoch: 279 loss: 1.5757815837860107 grad: 12.55801556926472\n",
      "epoch: 280 loss: 1.5783814191818237 grad: 12.516437652979105\n",
      "epoch: 281 loss: 1.5890586376190186 grad: 12.755204377230257\n",
      "epoch: 282 loss: 1.5783932209014893 grad: 12.429789298095756\n",
      "epoch: 283 loss: 1.57935631275177 grad: 12.04805052004725\n",
      "epoch: 284 loss: 1.5864462852478027 grad: 13.07054606435584\n",
      "epoch: 285 loss: 1.577509880065918 grad: 12.80815263945491\n",
      "epoch: 286 loss: 1.5759285688400269 grad: 12.384754111243796\n",
      "epoch: 287 loss: 1.5685598850250244 grad: 12.37966501110396\n",
      "epoch: 288 loss: 1.581834316253662 grad: 12.782997038111919\n",
      "epoch: 289 loss: 1.5770164728164673 grad: 12.779392863261616\n",
      "epoch: 290 loss: 1.5695717334747314 grad: 13.19222957593581\n",
      "epoch: 291 loss: 1.5695079565048218 grad: 12.168137742302543\n",
      "epoch: 292 loss: 1.5710629224777222 grad: 12.208127938824454\n",
      "epoch: 293 loss: 1.5711586475372314 grad: 12.807570498813654\n",
      "epoch: 294 loss: 1.5732685327529907 grad: 12.289619428874364\n",
      "epoch: 295 loss: 1.5729875564575195 grad: 11.876369030495722\n",
      "epoch: 296 loss: 1.5775517225265503 grad: 11.570004110453679\n",
      "epoch: 297 loss: 1.5718761682510376 grad: 12.099676303432457\n",
      "epoch: 298 loss: 1.5707255601882935 grad: 12.573349357161316\n",
      "epoch: 299 loss: 1.5772825479507446 grad: 13.555975325693865\n",
      "epoch: 300 loss: 1.5703414678573608 grad: 12.67169481594973\n",
      "epoch: 301 loss: 1.5714783668518066 grad: 13.022105847041876\n",
      "epoch: 302 loss: 1.5710350275039673 grad: 11.29272543160718\n",
      "epoch: 303 loss: 1.5744065046310425 grad: 12.311333957120835\n",
      "epoch: 304 loss: 1.571358561515808 grad: 12.18020806417224\n",
      "epoch: 305 loss: 1.5724022388458252 grad: 11.909667059143503\n",
      "epoch: 306 loss: 1.5665067434310913 grad: 12.13470906958664\n",
      "epoch: 307 loss: 1.571683645248413 grad: 12.377461165832798\n",
      "epoch: 308 loss: 1.5699598789215088 grad: 11.356486772438364\n",
      "epoch: 309 loss: 1.568250060081482 grad: 12.243862582858474\n",
      "epoch: 310 loss: 1.5671212673187256 grad: 12.007193022128565\n",
      "epoch: 311 loss: 1.5698024034500122 grad: 12.170250350579856\n",
      "epoch: 312 loss: 1.5722452402114868 grad: 11.82214833259405\n",
      "epoch: 313 loss: 1.5701261758804321 grad: 11.41593323944373\n",
      "epoch: 314 loss: 1.5698661804199219 grad: 11.686737811320373\n",
      "epoch: 315 loss: 1.5670666694641113 grad: 12.644999267234068\n",
      "epoch: 316 loss: 1.571367621421814 grad: 11.667525610997385\n",
      "epoch: 317 loss: 1.5653265714645386 grad: 12.560666347410352\n",
      "epoch: 318 loss: 1.5660690069198608 grad: 12.080121401830443\n",
      "epoch: 319 loss: 1.5695984363555908 grad: 11.950953654619672\n",
      "epoch: 320 loss: 1.5643922090530396 grad: 11.687549925564477\n",
      "epoch: 321 loss: 1.5666475296020508 grad: 11.258209931856346\n",
      "epoch: 322 loss: 1.5669004917144775 grad: 12.81655186161192\n",
      "epoch: 323 loss: 1.5644023418426514 grad: 11.998906580317351\n",
      "epoch: 324 loss: 1.5693315267562866 grad: 12.501207691395567\n",
      "epoch: 325 loss: 1.5720657110214233 grad: 12.707853464380143\n",
      "epoch: 326 loss: 1.5576974153518677 grad: 12.480239922491213\n",
      "epoch: 327 loss: 1.5639042854309082 grad: 11.393801804480423\n",
      "epoch: 328 loss: 1.558424472808838 grad: 12.140086451756014\n",
      "epoch: 329 loss: 1.5607757568359375 grad: 11.783885753502892\n",
      "epoch: 330 loss: 1.5612601041793823 grad: 11.78271141726642\n",
      "epoch: 331 loss: 1.5649282932281494 grad: 12.621710335802552\n",
      "epoch: 332 loss: 1.568423867225647 grad: 12.76549872325822\n",
      "epoch: 333 loss: 1.5552743673324585 grad: 11.939259757221278\n",
      "epoch: 334 loss: 1.5586408376693726 grad: 11.887481850664324\n",
      "epoch: 335 loss: 1.5620756149291992 grad: 11.84664499672455\n",
      "epoch: 336 loss: 1.5646525621414185 grad: 11.323890000363694\n",
      "epoch: 337 loss: 1.5605491399765015 grad: 10.854775646793849\n",
      "epoch: 338 loss: 1.5587817430496216 grad: 12.462215471687534\n",
      "epoch: 339 loss: 1.5635066032409668 grad: 11.456245536509428\n",
      "epoch: 340 loss: 1.5571256875991821 grad: 12.572355677447622\n",
      "epoch: 341 loss: 1.565280556678772 grad: 12.28749542693711\n",
      "epoch: 342 loss: 1.5575296878814697 grad: 11.774547937185696\n",
      "epoch: 343 loss: 1.5584787130355835 grad: 11.84705025718976\n",
      "epoch: 344 loss: 1.5527963638305664 grad: 11.525532328405433\n",
      "epoch: 345 loss: 1.560938835144043 grad: 12.57781059557705\n",
      "epoch: 346 loss: 1.567184329032898 grad: 11.549490061921201\n",
      "epoch: 347 loss: 1.5615042448043823 grad: 11.156026244817657\n",
      "epoch: 348 loss: 1.5536245107650757 grad: 11.425786399071859\n",
      "epoch: 349 loss: 1.5630896091461182 grad: 11.85699552970953\n",
      "epoch: 350 loss: 1.5599751472473145 grad: 11.893941874128013\n",
      "epoch: 351 loss: 1.558308720588684 grad: 11.461297381994507\n",
      "epoch: 352 loss: 1.5586439371109009 grad: 12.116340982158565\n",
      "epoch: 353 loss: 1.5502617359161377 grad: 10.791066934472866\n",
      "epoch: 354 loss: 1.5533465147018433 grad: 12.126203801050517\n",
      "epoch: 355 loss: 1.5607233047485352 grad: 12.50888761793751\n",
      "epoch: 356 loss: 1.5605138540267944 grad: 11.520136264211956\n",
      "epoch: 357 loss: 1.5525083541870117 grad: 11.707114567292766\n",
      "epoch: 358 loss: 1.5498566627502441 grad: 11.58071262173591\n",
      "epoch: 359 loss: 1.5638617277145386 grad: 12.786072999970722\n",
      "epoch: 360 loss: 1.5534942150115967 grad: 11.203971107349924\n",
      "epoch: 361 loss: 1.559547781944275 grad: 12.370160354611775\n",
      "epoch: 362 loss: 1.5571893453598022 grad: 11.137381992761105\n",
      "epoch: 363 loss: 1.5556681156158447 grad: 10.90907613611928\n",
      "epoch: 364 loss: 1.5516343116760254 grad: 10.656487516068395\n",
      "epoch: 365 loss: 1.5560575723648071 grad: 12.032857391938922\n",
      "epoch: 366 loss: 1.5497827529907227 grad: 11.311173702712127\n",
      "epoch: 367 loss: 1.5449378490447998 grad: 10.868920149654889\n",
      "epoch: 368 loss: 1.5527135133743286 grad: 12.007129962519107\n",
      "epoch: 369 loss: 1.5578913688659668 grad: 11.77169656222095\n",
      "epoch: 370 loss: 1.5502337217330933 grad: 11.029472495828356\n",
      "epoch: 371 loss: 1.5549280643463135 grad: 12.476834978132198\n",
      "epoch: 372 loss: 1.5553733110427856 grad: 11.396569830402436\n",
      "epoch: 373 loss: 1.5502938032150269 grad: 12.208785692621614\n",
      "epoch: 374 loss: 1.5531086921691895 grad: 10.718683317192786\n",
      "epoch: 375 loss: 1.5519888401031494 grad: 11.930716563130744\n",
      "epoch: 376 loss: 1.5539448261260986 grad: 11.942682897354224\n",
      "epoch: 377 loss: 1.5531047582626343 grad: 11.062699354165012\n",
      "epoch: 378 loss: 1.5478228330612183 grad: 11.16607360666736\n",
      "epoch: 379 loss: 1.5479165315628052 grad: 12.472584521664041\n",
      "epoch: 380 loss: 1.5531479120254517 grad: 11.847641372236438\n",
      "epoch: 381 loss: 1.5499368906021118 grad: 11.643851686690358\n",
      "epoch: 382 loss: 1.5557650327682495 grad: 11.308758553305996\n",
      "epoch: 383 loss: 1.5468953847885132 grad: 11.785039474703519\n",
      "epoch: 384 loss: 1.555457592010498 grad: 11.464061548201633\n",
      "epoch: 385 loss: 1.551439881324768 grad: 11.367591974207215\n",
      "epoch: 386 loss: 1.5568615198135376 grad: 11.26161116453272\n",
      "epoch: 387 loss: 1.548622965812683 grad: 11.770291367024626\n",
      "epoch: 388 loss: 1.5510715246200562 grad: 12.113625905448792\n",
      "epoch: 389 loss: 1.5479055643081665 grad: 11.135745126964702\n",
      "epoch: 390 loss: 1.5549837350845337 grad: 12.417244977886892\n",
      "epoch: 391 loss: 1.5519635677337646 grad: 10.976428292532791\n",
      "epoch: 392 loss: 1.5550053119659424 grad: 11.813575106188802\n",
      "epoch: 393 loss: 1.5476595163345337 grad: 12.368677927561784\n",
      "epoch: 394 loss: 1.5460195541381836 grad: 11.296402812506708\n",
      "epoch: 395 loss: 1.5506664514541626 grad: 10.95520658751521\n",
      "epoch: 396 loss: 1.5482839345932007 grad: 11.909240777373299\n",
      "epoch: 397 loss: 1.5487782955169678 grad: 10.895550591176347\n",
      "epoch: 398 loss: 1.54581618309021 grad: 10.656537372740873\n",
      "epoch: 399 loss: 1.5478346347808838 grad: 10.648794166965498\n",
      "epoch: 400 loss: 1.5547369718551636 grad: 11.632240827282196\n",
      "epoch: 401 loss: 1.545745611190796 grad: 11.068558260022352\n",
      "epoch: 402 loss: 1.5469450950622559 grad: 10.866957973289702\n",
      "epoch: 403 loss: 1.5477654933929443 grad: 11.590824472784464\n",
      "epoch: 404 loss: 1.5478193759918213 grad: 11.266848414748287\n",
      "epoch: 405 loss: 1.5488139390945435 grad: 12.038528376735659\n",
      "epoch: 406 loss: 1.5515257120132446 grad: 12.358550268173632\n",
      "epoch: 407 loss: 1.5481715202331543 grad: 12.45121687245629\n",
      "epoch: 408 loss: 1.5433045625686646 grad: 11.896063723331613\n",
      "epoch: 409 loss: 1.537881851196289 grad: 10.891329553406981\n",
      "epoch: 410 loss: 1.543689250946045 grad: 11.925089296506023\n",
      "epoch: 411 loss: 1.5479916334152222 grad: 11.723036721422677\n",
      "epoch: 412 loss: 1.5446304082870483 grad: 11.428678557136289\n",
      "epoch: 413 loss: 1.5511211156845093 grad: 11.331083188956928\n",
      "epoch: 414 loss: 1.5487037897109985 grad: 11.068823698749174\n",
      "epoch: 415 loss: 1.5496957302093506 grad: 12.044547442465074\n",
      "epoch: 416 loss: 1.5496457815170288 grad: 12.153381349239869\n",
      "epoch: 417 loss: 1.5536576509475708 grad: 11.742156751095392\n",
      "epoch: 418 loss: 1.5428398847579956 grad: 11.035776195681787\n",
      "epoch: 419 loss: 1.5415143966674805 grad: 10.614758907602953\n",
      "epoch: 420 loss: 1.551228404045105 grad: 11.544932115508894\n",
      "epoch: 421 loss: 1.544750690460205 grad: 11.385716624912762\n",
      "epoch: 422 loss: 1.5406298637390137 grad: 11.72964105211265\n",
      "epoch: 423 loss: 1.5487592220306396 grad: 11.416754013075241\n",
      "epoch: 424 loss: 1.543750286102295 grad: 12.22950016321533\n",
      "epoch: 425 loss: 1.5460597276687622 grad: 11.483217430692758\n",
      "epoch: 426 loss: 1.541725993156433 grad: 10.723415636317066\n",
      "epoch: 427 loss: 1.547813057899475 grad: 11.756872837668256\n",
      "epoch: 428 loss: 1.5444915294647217 grad: 11.258764812541711\n",
      "epoch: 429 loss: 1.5431036949157715 grad: 10.413120410031832\n",
      "epoch: 430 loss: 1.543666958808899 grad: 11.566517110123106\n",
      "epoch: 431 loss: 1.5425350666046143 grad: 11.033155255246951\n",
      "epoch: 432 loss: 1.5440583229064941 grad: 11.60584796922991\n",
      "epoch: 433 loss: 1.542203664779663 grad: 10.610839906544054\n",
      "epoch: 434 loss: 1.5419429540634155 grad: 12.317399494878446\n",
      "epoch: 435 loss: 1.5400586128234863 grad: 10.535891462878753\n",
      "epoch: 436 loss: 1.5429757833480835 grad: 11.27234059514936\n",
      "epoch: 437 loss: 1.5398093461990356 grad: 10.79460416060488\n",
      "epoch: 438 loss: 1.5397144556045532 grad: 11.556184839398142\n",
      "epoch: 439 loss: 1.5445406436920166 grad: 10.659227658336658\n",
      "epoch: 440 loss: 1.542251706123352 grad: 9.340504510535133\n",
      "epoch: 441 loss: 1.5464577674865723 grad: 12.28057754964065\n",
      "epoch: 442 loss: 1.5434496402740479 grad: 11.421006111417054\n",
      "epoch: 443 loss: 1.5416369438171387 grad: 12.049649405954701\n",
      "epoch: 444 loss: 1.54486882686615 grad: 12.298624871313454\n",
      "epoch: 445 loss: 1.5426784753799438 grad: 11.710429409241659\n",
      "epoch: 446 loss: 1.541141390800476 grad: 10.188171337635833\n",
      "epoch: 447 loss: 1.5382744073867798 grad: 10.396622109875482\n",
      "epoch: 448 loss: 1.5408514738082886 grad: 11.75081151083023\n",
      "epoch: 449 loss: 1.5412073135375977 grad: 10.419323471829383\n",
      "epoch: 450 loss: 1.5371782779693604 grad: 10.020659387422105\n",
      "epoch: 451 loss: 1.5371185541152954 grad: 11.467152787047246\n",
      "epoch: 452 loss: 1.5390396118164062 grad: 11.68436392103248\n",
      "epoch: 453 loss: 1.5364145040512085 grad: 11.872629941526121\n",
      "epoch: 454 loss: 1.537423849105835 grad: 10.981408413861775\n",
      "epoch: 455 loss: 1.5334336757659912 grad: 10.657058943994343\n",
      "epoch: 456 loss: 1.5315446853637695 grad: 10.261760067538402\n",
      "epoch: 457 loss: 1.5401902198791504 grad: 11.67308981136589\n",
      "epoch: 458 loss: 1.5366792678833008 grad: 11.225614145339009\n",
      "epoch: 459 loss: 1.5386590957641602 grad: 11.642360252590613\n",
      "epoch: 460 loss: 1.5397107601165771 grad: 11.615672792197161\n",
      "epoch: 461 loss: 1.5455825328826904 grad: 11.907829325040064\n",
      "epoch: 462 loss: 1.534511923789978 grad: 11.316778004369032\n",
      "epoch: 463 loss: 1.5346170663833618 grad: 11.661019050736083\n",
      "epoch: 464 loss: 1.538613200187683 grad: 10.830680870329074\n",
      "epoch: 465 loss: 1.537396788597107 grad: 11.603283434919643\n",
      "epoch: 466 loss: 1.5362659692764282 grad: 11.455437624450063\n",
      "epoch: 467 loss: 1.5375877618789673 grad: 10.296660417707503\n",
      "epoch: 468 loss: 1.5392251014709473 grad: 11.058063868181927\n",
      "epoch: 469 loss: 1.5375977754592896 grad: 10.786155472354343\n",
      "epoch: 470 loss: 1.533650279045105 grad: 11.04235348914055\n",
      "epoch: 471 loss: 1.5446631908416748 grad: 11.485891855961185\n",
      "epoch: 472 loss: 1.536598801612854 grad: 12.11666148216168\n",
      "epoch: 473 loss: 1.536871314048767 grad: 10.823965206269234\n",
      "epoch: 474 loss: 1.534764051437378 grad: 10.933703476788535\n",
      "epoch: 475 loss: 1.5339514017105103 grad: 10.036844773373256\n",
      "epoch: 476 loss: 1.5370936393737793 grad: 11.336523916601898\n",
      "epoch: 477 loss: 1.5328999757766724 grad: 10.801444310901893\n",
      "epoch: 478 loss: 1.5359914302825928 grad: 11.625921589307605\n",
      "epoch: 479 loss: 1.53578782081604 grad: 10.820175643356162\n",
      "epoch: 480 loss: 1.5381020307540894 grad: 10.819411318508967\n",
      "epoch: 481 loss: 1.5307589769363403 grad: 10.275464978773103\n",
      "epoch: 482 loss: 1.5392731428146362 grad: 10.373826501780146\n",
      "epoch: 483 loss: 1.5308775901794434 grad: 11.370244661556734\n",
      "epoch: 484 loss: 1.5383938550949097 grad: 11.837263461243037\n",
      "epoch: 485 loss: 1.531886339187622 grad: 11.825540771050054\n",
      "epoch: 486 loss: 1.5358047485351562 grad: 10.954643973622412\n",
      "epoch: 487 loss: 1.542141079902649 grad: 12.297963072985617\n",
      "epoch: 488 loss: 1.5400798320770264 grad: 11.111566904887912\n",
      "epoch: 489 loss: 1.5376695394515991 grad: 10.57557438903429\n",
      "epoch: 490 loss: 1.5349857807159424 grad: 10.780678811376832\n",
      "epoch: 491 loss: 1.538045048713684 grad: 10.963271098248365\n",
      "epoch: 492 loss: 1.5357626676559448 grad: 10.947142886528228\n",
      "epoch: 493 loss: 1.532359004020691 grad: 10.347205109550574\n",
      "epoch: 494 loss: 1.5347967147827148 grad: 10.312518094163684\n",
      "epoch: 495 loss: 1.5368543863296509 grad: 10.732348183140395\n",
      "epoch: 496 loss: 1.5332214832305908 grad: 11.138781219273659\n",
      "epoch: 497 loss: 1.5329339504241943 grad: 11.343252010562177\n",
      "epoch: 498 loss: 1.5365997552871704 grad: 11.729336450247848\n",
      "epoch: 499 loss: 1.5337008237838745 grad: 10.391341560490666\n",
      "1.7846455574035645\n",
      "1.8056424856185913\n",
      "1.8056424856185913\n",
      "epoch: 0 loss: 2.2711846828460693 grad: 1.6541374966581648\n",
      "epoch: 1 loss: 2.1627328395843506 grad: 1.8535584402363008\n",
      "epoch: 2 loss: 2.1098737716674805 grad: 3.158674134761982\n",
      "epoch: 3 loss: 2.0603065490722656 grad: 3.259832231145877\n",
      "epoch: 4 loss: 2.0070297718048096 grad: 4.219617348377748\n",
      "epoch: 5 loss: 1.9648970365524292 grad: 5.36364578534775\n",
      "epoch: 6 loss: 1.920840859413147 grad: 5.184416738141971\n",
      "epoch: 7 loss: 1.8766109943389893 grad: 5.56808499223645\n",
      "epoch: 8 loss: 1.8320738077163696 grad: 6.434867861810037\n",
      "epoch: 9 loss: 1.815870761871338 grad: 7.226569613169265\n",
      "epoch: 10 loss: 1.790511965751648 grad: 6.939221282698406\n",
      "epoch: 11 loss: 1.7558656930923462 grad: 6.0215654626159765\n",
      "epoch: 12 loss: 1.7189232110977173 grad: 6.060703630186341\n",
      "epoch: 13 loss: 1.714525818824768 grad: 6.404350574701629\n",
      "epoch: 14 loss: 1.7122204303741455 grad: 6.875525584087304\n",
      "epoch: 15 loss: 1.7086212635040283 grad: 6.631403680441306\n",
      "epoch: 16 loss: 1.7026556730270386 grad: 6.470554992736739\n",
      "epoch: 17 loss: 1.680906057357788 grad: 6.963677533108571\n",
      "epoch: 18 loss: 1.686834454536438 grad: 6.790908209433491\n",
      "epoch: 19 loss: 1.6721091270446777 grad: 7.306309106510034\n",
      "epoch: 20 loss: 1.6441855430603027 grad: 5.90028648279593\n",
      "epoch: 21 loss: 1.6583938598632812 grad: 6.688905741080701\n",
      "epoch: 22 loss: 1.6393712759017944 grad: 7.332149080170129\n",
      "epoch: 23 loss: 1.6331895589828491 grad: 7.53337814850827\n",
      "epoch: 24 loss: 1.6327930688858032 grad: 6.134598296662882\n",
      "epoch: 25 loss: 1.6293580532073975 grad: 6.755067134775071\n",
      "epoch: 26 loss: 1.6199902296066284 grad: 7.2005716017914\n",
      "epoch: 27 loss: 1.6006431579589844 grad: 6.569892396162946\n",
      "epoch: 28 loss: 1.599975347518921 grad: 5.6355031175366355\n",
      "epoch: 29 loss: 1.6168806552886963 grad: 6.0356422005619\n",
      "epoch: 30 loss: 1.604479193687439 grad: 5.028513500761792\n",
      "epoch: 31 loss: 1.5787280797958374 grad: 5.013387616603578\n",
      "epoch: 32 loss: 1.5924715995788574 grad: 5.717882779473416\n",
      "epoch: 33 loss: 1.593083143234253 grad: 6.0933411221502904\n",
      "epoch: 34 loss: 1.5842818021774292 grad: 5.488717200605029\n",
      "epoch: 35 loss: 1.5779255628585815 grad: 6.259966592351818\n",
      "epoch: 36 loss: 1.5776281356811523 grad: 6.0581206822387195\n",
      "epoch: 37 loss: 1.5948748588562012 grad: 6.156424581205058\n",
      "epoch: 38 loss: 1.5984728336334229 grad: 5.921368724789881\n",
      "epoch: 39 loss: 1.5820348262786865 grad: 5.379231660662054\n",
      "epoch: 40 loss: 1.5755234956741333 grad: 5.536342716359564\n",
      "epoch: 41 loss: 1.5673868656158447 grad: 4.8727429340757595\n",
      "epoch: 42 loss: 1.5782655477523804 grad: 6.0691545707284975\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 43 loss: 1.599351167678833 grad: 6.400820044397228\n",
      "epoch: 44 loss: 1.5762724876403809 grad: 5.42666734858531\n",
      "epoch: 45 loss: 1.5474992990493774 grad: 4.58220737812172\n",
      "epoch: 46 loss: 1.56564462184906 grad: 5.617485897874996\n",
      "epoch: 47 loss: 1.563116192817688 grad: 4.868974728767288\n",
      "epoch: 48 loss: 1.5748023986816406 grad: 5.700690776416671\n",
      "epoch: 49 loss: 1.5642521381378174 grad: 5.083966845912322\n",
      "epoch: 50 loss: 1.575982928276062 grad: 5.558300637641965\n",
      "epoch: 51 loss: 1.5705410242080688 grad: 4.784823198645845\n",
      "epoch: 52 loss: 1.5705052614212036 grad: 5.185697816783814\n",
      "epoch: 53 loss: 1.5648044347763062 grad: 5.394676554928887\n",
      "epoch: 54 loss: 1.5656358003616333 grad: 4.749142314244593\n",
      "epoch: 55 loss: 1.5752038955688477 grad: 6.342319727507423\n",
      "epoch: 56 loss: 1.57538902759552 grad: 6.295640248458947\n",
      "epoch: 57 loss: 1.5615038871765137 grad: 4.376180237707399\n",
      "epoch: 58 loss: 1.5539402961730957 grad: 5.091849935661346\n",
      "epoch: 59 loss: 1.5657848119735718 grad: 4.72040641216781\n",
      "epoch: 60 loss: 1.5588135719299316 grad: 5.443538365888171\n",
      "epoch: 61 loss: 1.5879921913146973 grad: 5.5921248191184745\n",
      "epoch: 62 loss: 1.5540426969528198 grad: 4.960625765510067\n",
      "epoch: 63 loss: 1.5662394762039185 grad: 5.271879195747441\n",
      "epoch: 64 loss: 1.5608189105987549 grad: 5.368711189608716\n",
      "epoch: 65 loss: 1.5512531995773315 grad: 4.3831843088458955\n",
      "epoch: 66 loss: 1.5566197633743286 grad: 5.5281186429056\n",
      "epoch: 67 loss: 1.5453579425811768 grad: 5.051829978996953\n",
      "epoch: 68 loss: 1.547703742980957 grad: 4.58575581427727\n",
      "epoch: 69 loss: 1.5472946166992188 grad: 4.9585713906012785\n",
      "epoch: 70 loss: 1.5505996942520142 grad: 4.8304020252105415\n",
      "epoch: 71 loss: 1.5525864362716675 grad: 5.0336086452145565\n",
      "epoch: 72 loss: 1.5515422821044922 grad: 4.482597722797985\n",
      "epoch: 73 loss: 1.5551975965499878 grad: 4.584630366019209\n",
      "epoch: 74 loss: 1.5483133792877197 grad: 3.079841284074949\n",
      "epoch: 75 loss: 1.5420504808425903 grad: 4.026055548978101\n",
      "epoch: 76 loss: 1.5542792081832886 grad: 4.60903679242314\n",
      "epoch: 77 loss: 1.5461987257003784 grad: 4.822053829489514\n",
      "epoch: 78 loss: 1.5472025871276855 grad: 4.2837395057296295\n",
      "epoch: 79 loss: 1.549111008644104 grad: 4.50875351768118\n",
      "epoch: 80 loss: 1.5435166358947754 grad: 3.611234190338008\n",
      "epoch: 81 loss: 1.5448634624481201 grad: 4.685625208345657\n",
      "epoch: 82 loss: 1.5611227750778198 grad: 5.909421079206065\n",
      "epoch: 83 loss: 1.5554900169372559 grad: 3.8153623012813274\n",
      "epoch: 84 loss: 1.5514678955078125 grad: 4.356575626638532\n",
      "epoch: 85 loss: 1.545833706855774 grad: 4.956679969317466\n",
      "epoch: 86 loss: 1.5583759546279907 grad: 4.738825027884572\n",
      "epoch: 87 loss: 1.5509387254714966 grad: 5.347788222034387\n",
      "epoch: 88 loss: 1.5403705835342407 grad: 4.336644047881715\n",
      "epoch: 89 loss: 1.5380069017410278 grad: 3.588307311617735\n",
      "epoch: 90 loss: 1.5399240255355835 grad: 3.7955066530764197\n",
      "epoch: 91 loss: 1.5436301231384277 grad: 3.7966006548120674\n",
      "epoch: 92 loss: 1.54635751247406 grad: 4.59013430758846\n",
      "epoch: 93 loss: 1.545009732246399 grad: 5.044678490389598\n",
      "epoch: 94 loss: 1.5557185411453247 grad: 4.353171619966743\n",
      "epoch: 95 loss: 1.5333836078643799 grad: 3.145012958522139\n",
      "epoch: 96 loss: 1.5304877758026123 grad: 4.482476091325218\n",
      "epoch: 97 loss: 1.5575534105300903 grad: 4.695323038410447\n",
      "epoch: 98 loss: 1.5488718748092651 grad: 4.643613246714599\n",
      "epoch: 99 loss: 1.5414975881576538 grad: 4.37810796910718\n",
      "epoch: 100 loss: 1.5322299003601074 grad: 4.1173665843456195\n",
      "epoch: 101 loss: 1.536012887954712 grad: 4.08176808529463\n",
      "epoch: 102 loss: 1.5422672033309937 grad: 5.2572313706305955\n",
      "epoch: 103 loss: 1.5460104942321777 grad: 4.247313337269639\n",
      "epoch: 104 loss: 1.5525258779525757 grad: 5.031013098354214\n",
      "epoch: 105 loss: 1.5499874353408813 grad: 4.931324685994905\n",
      "epoch: 106 loss: 1.5304011106491089 grad: 3.315001799691105\n",
      "epoch: 107 loss: 1.5324347019195557 grad: 3.67197082925756\n",
      "epoch: 108 loss: 1.553946614265442 grad: 5.673507045874525\n",
      "epoch: 109 loss: 1.539567470550537 grad: 3.9695059604913014\n",
      "epoch: 110 loss: 1.5560534000396729 grad: 4.491157584964813\n",
      "epoch: 111 loss: 1.5506260395050049 grad: 4.040509158127576\n",
      "epoch: 112 loss: 1.5386768579483032 grad: 4.1337288454810075\n",
      "epoch: 113 loss: 1.5356104373931885 grad: 3.5891901652208578\n",
      "epoch: 114 loss: 1.546735167503357 grad: 3.906987107722594\n",
      "epoch: 115 loss: 1.5324991941452026 grad: 4.192784549513887\n",
      "epoch: 116 loss: 1.539704442024231 grad: 5.834867327656473\n",
      "epoch: 117 loss: 1.545833706855774 grad: 4.740624822707893\n",
      "epoch: 118 loss: 1.5389728546142578 grad: 4.524594175962804\n",
      "epoch: 119 loss: 1.5514411926269531 grad: 4.65797942879364\n",
      "epoch: 120 loss: 1.5372917652130127 grad: 4.018593815616269\n",
      "epoch: 121 loss: 1.5310051441192627 grad: 3.6360993346667914\n",
      "epoch: 122 loss: 1.524200439453125 grad: 3.368585869595007\n",
      "epoch: 123 loss: 1.5312458276748657 grad: 3.130034919630113\n",
      "epoch: 124 loss: 1.5285561084747314 grad: 2.6532358485047\n",
      "epoch: 125 loss: 1.5221531391143799 grad: 3.05971809928796\n",
      "epoch: 126 loss: 1.5219826698303223 grad: 3.2753251276999156\n",
      "epoch: 127 loss: 1.5346400737762451 grad: 3.523019809394053\n",
      "epoch: 128 loss: 1.525176763534546 grad: 3.44439424557385\n",
      "epoch: 129 loss: 1.5290558338165283 grad: 4.457096287651785\n",
      "epoch: 130 loss: 1.528178095817566 grad: 3.8188240784264584\n",
      "epoch: 131 loss: 1.5316070318222046 grad: 3.8516560347005\n",
      "epoch: 132 loss: 1.5420098304748535 grad: 4.4848019887186785\n",
      "epoch: 133 loss: 1.5194026231765747 grad: 3.47853880355309\n",
      "epoch: 134 loss: 1.5339373350143433 grad: 3.0455450852610935\n",
      "epoch: 135 loss: 1.5281097888946533 grad: 4.050668151931788\n",
      "epoch: 136 loss: 1.5387537479400635 grad: 4.062630726160227\n",
      "epoch: 137 loss: 1.5339851379394531 grad: 4.183202708923803\n",
      "epoch: 138 loss: 1.543765664100647 grad: 3.2009042895465956\n",
      "epoch: 139 loss: 1.5254138708114624 grad: 2.9242696755389246\n",
      "epoch: 140 loss: 1.522849202156067 grad: 2.34796469040553\n",
      "epoch: 141 loss: 1.5243252515792847 grad: 2.794820189267137\n",
      "epoch: 142 loss: 1.5377187728881836 grad: 3.2209740893571674\n",
      "epoch: 143 loss: 1.532700777053833 grad: 3.765444130366008\n",
      "epoch: 144 loss: 1.5352720022201538 grad: 3.1439082148805735\n",
      "epoch: 145 loss: 1.5309813022613525 grad: 2.2629946870072\n",
      "epoch: 146 loss: 1.521336555480957 grad: 2.41132289047931\n",
      "epoch: 147 loss: 1.5333025455474854 grad: 3.6981698990806398\n",
      "epoch: 148 loss: 1.5333253145217896 grad: 4.057780952101063\n",
      "epoch: 149 loss: 1.5366020202636719 grad: 4.627143523959957\n",
      "epoch: 150 loss: 1.5392407178878784 grad: 3.4967044817723716\n",
      "epoch: 151 loss: 1.5257991552352905 grad: 4.605576092205538\n",
      "epoch: 152 loss: 1.5171642303466797 grad: 3.563120415569583\n",
      "epoch: 153 loss: 1.514953851699829 grad: 3.1794189136801387\n",
      "epoch: 154 loss: 1.5197973251342773 grad: 3.6968552728383193\n",
      "epoch: 155 loss: 1.5291067361831665 grad: 4.349189324360726\n",
      "epoch: 156 loss: 1.532153844833374 grad: 3.983926511300489\n",
      "epoch: 157 loss: 1.5256375074386597 grad: 3.061378385155277\n",
      "epoch: 158 loss: 1.5162583589553833 grad: 3.184080664802371\n",
      "epoch: 159 loss: 1.5142722129821777 grad: 2.7980587040565474\n",
      "epoch: 160 loss: 1.5223708152770996 grad: 3.5587938645186923\n",
      "epoch: 161 loss: 1.53962242603302 grad: 3.020780441711829\n",
      "epoch: 162 loss: 1.522283673286438 grad: 2.9522367158556047\n",
      "epoch: 163 loss: 1.5177457332611084 grad: 3.012700580376804\n",
      "epoch: 164 loss: 1.530211091041565 grad: 4.0357082011192205\n",
      "epoch: 165 loss: 1.5340170860290527 grad: 3.07112800739664\n",
      "epoch: 166 loss: 1.5344111919403076 grad: 4.04598625556425\n",
      "epoch: 167 loss: 1.5322374105453491 grad: 3.8353267205381085\n",
      "epoch: 168 loss: 1.5130681991577148 grad: 2.3851533910668063\n",
      "epoch: 169 loss: 1.514687180519104 grad: 2.2410947865141915\n",
      "epoch: 170 loss: 1.5258654356002808 grad: 3.8147582868101764\n",
      "epoch: 171 loss: 1.515622615814209 grad: 3.1070854930841842\n",
      "epoch: 172 loss: 1.5256776809692383 grad: 2.9089008406431915\n",
      "epoch: 173 loss: 1.5157310962677002 grad: 2.191313990417855\n",
      "epoch: 174 loss: 1.5107589960098267 grad: 3.297664354075846\n",
      "epoch: 175 loss: 1.5262936353683472 grad: 4.653908214838514\n",
      "epoch: 176 loss: 1.52774977684021 grad: 4.018795152574507\n",
      "epoch: 177 loss: 1.5270583629608154 grad: 3.8031964058662684\n",
      "epoch: 178 loss: 1.5501530170440674 grad: 4.126468019166029\n",
      "epoch: 179 loss: 1.5180243253707886 grad: 2.4555206493920627\n",
      "epoch: 180 loss: 1.5100314617156982 grad: 2.4475345726957136\n",
      "epoch: 181 loss: 1.5163944959640503 grad: 4.21945349169359\n",
      "epoch: 182 loss: 1.5210225582122803 grad: 3.88564139438259\n",
      "epoch: 183 loss: 1.523167371749878 grad: 2.786102047536649\n",
      "epoch: 184 loss: 1.5452226400375366 grad: 4.347742153720224\n",
      "epoch: 185 loss: 1.5281305313110352 grad: 4.054101080322259\n",
      "epoch: 186 loss: 1.5308988094329834 grad: 4.528887631094404\n",
      "epoch: 187 loss: 1.5223934650421143 grad: 4.397782314736747\n",
      "epoch: 188 loss: 1.532820701599121 grad: 3.1170971001314096\n",
      "epoch: 189 loss: 1.5181663036346436 grad: 2.369248724698451\n",
      "epoch: 190 loss: 1.516419529914856 grad: 2.410424587783565\n",
      "epoch: 191 loss: 1.5206377506256104 grad: 3.0770714960297036\n",
      "epoch: 192 loss: 1.5161505937576294 grad: 3.949526794560327\n",
      "epoch: 193 loss: 1.5092402696609497 grad: 2.3874331625415492\n",
      "epoch: 194 loss: 1.5171202421188354 grad: 2.89163237890917\n",
      "epoch: 195 loss: 1.5228064060211182 grad: 3.7403506679995155\n",
      "epoch: 196 loss: 1.509840488433838 grad: 2.535709491991967\n",
      "epoch: 197 loss: 1.5074061155319214 grad: 2.570622551067785\n",
      "epoch: 198 loss: 1.5238761901855469 grad: 3.7396641068624548\n",
      "epoch: 199 loss: 1.518810749053955 grad: 2.8817989216931608\n",
      "epoch: 200 loss: 1.5123711824417114 grad: 2.4358952140795784\n",
      "epoch: 201 loss: 1.5287584066390991 grad: 3.9119005637678312\n",
      "epoch: 202 loss: 1.5171998739242554 grad: 3.525068822586084\n",
      "epoch: 203 loss: 1.510308861732483 grad: 3.2238232257266124\n",
      "epoch: 204 loss: 1.517207384109497 grad: 2.600418538476597\n",
      "epoch: 205 loss: 1.5065792798995972 grad: 2.242272114020305\n",
      "epoch: 206 loss: 1.5056272745132446 grad: 1.974942991531149\n",
      "epoch: 207 loss: 1.5173463821411133 grad: 4.077856245393572\n",
      "epoch: 208 loss: 1.5130025148391724 grad: 3.4896733285459303\n",
      "epoch: 209 loss: 1.5161887407302856 grad: 2.7748603622693353\n",
      "epoch: 210 loss: 1.5188195705413818 grad: 3.303870041666958\n",
      "epoch: 211 loss: 1.5452351570129395 grad: 3.573655306056479\n",
      "epoch: 212 loss: 1.5365760326385498 grad: 3.695618477756884\n",
      "epoch: 213 loss: 1.5191940069198608 grad: 2.7164534535513214\n",
      "epoch: 214 loss: 1.52430260181427 grad: 3.2807777024099023\n",
      "epoch: 215 loss: 1.5200709104537964 grad: 3.434998565850931\n",
      "epoch: 216 loss: 1.5077428817749023 grad: 2.3942050623984925\n",
      "epoch: 217 loss: 1.5004117488861084 grad: 2.3980052351363152\n",
      "epoch: 218 loss: 1.5104851722717285 grad: 3.106313268647434\n",
      "epoch: 219 loss: 1.5099265575408936 grad: 2.780375123546509\n",
      "epoch: 220 loss: 1.4970943927764893 grad: 1.7686817860828123\n",
      "epoch: 221 loss: 1.5262137651443481 grad: 3.181089271688402\n",
      "epoch: 222 loss: 1.5145293474197388 grad: 2.93074987344087\n",
      "epoch: 223 loss: 1.5016992092132568 grad: 2.1509846367630963\n",
      "epoch: 224 loss: 1.504489779472351 grad: 3.093134032410252\n",
      "epoch: 225 loss: 1.527492880821228 grad: 3.562302058663064\n",
      "epoch: 226 loss: 1.514116644859314 grad: 2.332751330158764\n",
      "epoch: 227 loss: 1.5030303001403809 grad: 3.1608239086403453\n",
      "epoch: 228 loss: 1.5096545219421387 grad: 3.001222967092483\n",
      "epoch: 229 loss: 1.516603946685791 grad: 2.5722272105553694\n",
      "epoch: 230 loss: 1.509128451347351 grad: 3.1966163473306235\n",
      "epoch: 231 loss: 1.509031891822815 grad: 3.1041757865962207\n",
      "epoch: 232 loss: 1.5071841478347778 grad: 2.785392833552489\n",
      "epoch: 233 loss: 1.509068489074707 grad: 3.3231380782044324\n",
      "epoch: 234 loss: 1.540846586227417 grad: 2.5137617105078287\n",
      "epoch: 235 loss: 1.508505940437317 grad: 3.6708091847086566\n",
      "epoch: 236 loss: 1.567482352256775 grad: 4.1102138664641314\n",
      "epoch: 237 loss: 1.5267298221588135 grad: 3.7784635640792033\n",
      "epoch: 238 loss: 1.527009129524231 grad: 2.9239386911456164\n",
      "epoch: 239 loss: 1.5170819759368896 grad: 4.105518976933108\n",
      "epoch: 240 loss: 1.5276082754135132 grad: 3.6659779819958973\n",
      "epoch: 241 loss: 1.5199346542358398 grad: 2.6215552716496466\n",
      "epoch: 242 loss: 1.5017023086547852 grad: 3.067096484926945\n",
      "epoch: 243 loss: 1.509796380996704 grad: 2.8759410929270026\n",
      "epoch: 244 loss: 1.516638994216919 grad: 3.2554920252588992\n",
      "epoch: 245 loss: 1.5152052640914917 grad: 3.693686845569952\n",
      "epoch: 246 loss: 1.516051173210144 grad: 2.8887202133078946\n",
      "epoch: 247 loss: 1.5080509185791016 grad: 2.082874465940182\n",
      "epoch: 248 loss: 1.4965604543685913 grad: 2.0911595824781664\n",
      "epoch: 249 loss: 1.5094480514526367 grad: 3.331255811601502\n",
      "epoch: 250 loss: 1.5110570192337036 grad: 3.3489870648014795\n",
      "epoch: 251 loss: 1.4972139596939087 grad: 2.0692434556904633\n",
      "epoch: 252 loss: 1.5041825771331787 grad: 2.002662401443731\n",
      "epoch: 253 loss: 1.5081689357757568 grad: 3.642893046885479\n",
      "epoch: 254 loss: 1.5106587409973145 grad: 2.027283239432562\n",
      "epoch: 255 loss: 1.5076414346694946 grad: 2.617213422922406\n",
      "epoch: 256 loss: 1.5094497203826904 grad: 2.478036852122855\n",
      "epoch: 257 loss: 1.5263808965682983 grad: 2.7863536424551922\n",
      "epoch: 258 loss: 1.5187016725540161 grad: 2.9026413031708356\n",
      "epoch: 259 loss: 1.5134233236312866 grad: 2.8273745657526943\n",
      "epoch: 260 loss: 1.5092326402664185 grad: 2.7738919253907857\n",
      "epoch: 261 loss: 1.5154426097869873 grad: 2.293834110263516\n",
      "epoch: 262 loss: 1.5111802816390991 grad: 2.1601203564754465\n",
      "epoch: 263 loss: 1.500852346420288 grad: 2.4171488392921416\n",
      "epoch: 264 loss: 1.5213264226913452 grad: 3.1154981887438002\n",
      "epoch: 265 loss: 1.4984241724014282 grad: 2.210284937319195\n",
      "epoch: 266 loss: 1.5004570484161377 grad: 1.551959778634765\n",
      "epoch: 267 loss: 1.4962799549102783 grad: 2.07198491043175\n",
      "epoch: 268 loss: 1.4953413009643555 grad: 2.19231141247676\n",
      "epoch: 269 loss: 1.497377634048462 grad: 2.1202740228433403\n",
      "epoch: 270 loss: 1.5064948797225952 grad: 2.6432484242232044\n",
      "epoch: 271 loss: 1.4997080564498901 grad: 2.5906998348607764\n",
      "epoch: 272 loss: 1.538033366203308 grad: 4.702588051765273\n",
      "epoch: 273 loss: 1.5375676155090332 grad: 2.471356751065438\n",
      "epoch: 274 loss: 1.508538007736206 grad: 2.743271096909304\n",
      "epoch: 275 loss: 1.525069236755371 grad: 3.2549588132966685\n",
      "epoch: 276 loss: 1.5144635438919067 grad: 2.794079857667447\n",
      "epoch: 277 loss: 1.5237646102905273 grad: 5.050504711177144\n",
      "epoch: 278 loss: 1.511199712753296 grad: 3.315114481446629\n",
      "epoch: 279 loss: 1.4978405237197876 grad: 2.3801821736045015\n",
      "epoch: 280 loss: 1.4992300271987915 grad: 1.5231443952023327\n",
      "epoch: 281 loss: 1.5075312852859497 grad: 2.2689571004347373\n",
      "epoch: 282 loss: 1.503334403038025 grad: 2.292192469335406\n",
      "epoch: 283 loss: 1.5026980638504028 grad: 1.8474385898163936\n",
      "epoch: 284 loss: 1.505033016204834 grad: 2.5579243838147345\n",
      "epoch: 285 loss: 1.5284552574157715 grad: 4.097385444314303\n",
      "epoch: 286 loss: 1.5321286916732788 grad: 2.96875796521324\n",
      "epoch: 287 loss: 1.5211224555969238 grad: 3.2229071555228455\n",
      "epoch: 288 loss: 1.500048041343689 grad: 2.6326671694537453\n",
      "epoch: 289 loss: 1.5061441659927368 grad: 3.0472419147087266\n",
      "epoch: 290 loss: 1.5037236213684082 grad: 2.1112807398074493\n",
      "epoch: 291 loss: 1.4996914863586426 grad: 2.126578521359379\n",
      "epoch: 292 loss: 1.4902433156967163 grad: 1.5175799266259424\n",
      "epoch: 293 loss: 1.5028184652328491 grad: 2.569665836973241\n",
      "epoch: 294 loss: 1.5059179067611694 grad: 1.8139021603540173\n",
      "epoch: 295 loss: 1.5040327310562134 grad: 2.779391671217826\n",
      "epoch: 296 loss: 1.504647135734558 grad: 2.2174433411091425\n",
      "epoch: 297 loss: 1.5295828580856323 grad: 4.233070190165469\n",
      "epoch: 298 loss: 1.5180697441101074 grad: 4.775903941619012\n",
      "epoch: 299 loss: 1.5165531635284424 grad: 3.2711365074924426\n",
      "epoch: 300 loss: 1.5180394649505615 grad: 3.1963330870958386\n",
      "epoch: 301 loss: 1.5072380304336548 grad: 2.424326210982525\n",
      "epoch: 302 loss: 1.5129307508468628 grad: 2.81352941066835\n",
      "epoch: 303 loss: 1.5109779834747314 grad: 3.287616651792532\n",
      "epoch: 304 loss: 1.4965077638626099 grad: 2.2948015496723118\n",
      "epoch: 305 loss: 1.5043025016784668 grad: 1.9817824836475932\n",
      "epoch: 306 loss: 1.495420217514038 grad: 2.445114273677709\n",
      "epoch: 307 loss: 1.506465196609497 grad: 3.460973980489275\n",
      "epoch: 308 loss: 1.5221019983291626 grad: 3.38058138194403\n",
      "epoch: 309 loss: 1.5108914375305176 grad: 3.2484083244153594\n",
      "epoch: 310 loss: 1.4950847625732422 grad: 1.7659803485543906\n",
      "epoch: 311 loss: 1.5005019903182983 grad: 2.597238760148378\n",
      "epoch: 312 loss: 1.5027848482131958 grad: 2.282086835431267\n",
      "epoch: 313 loss: 1.502579927444458 grad: 2.1741441134644246\n",
      "epoch: 314 loss: 1.4923819303512573 grad: 2.0059885033838487\n",
      "epoch: 315 loss: 1.4923447370529175 grad: 2.125628757107897\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 316 loss: 1.5077182054519653 grad: 3.7920677489925274\n",
      "epoch: 317 loss: 1.5029776096343994 grad: 2.430120952841146\n",
      "epoch: 318 loss: 1.4998291730880737 grad: 2.675488773213607\n",
      "epoch: 319 loss: 1.493503451347351 grad: 1.6235137526238628\n",
      "epoch: 320 loss: 1.512334942817688 grad: 2.641348240744091\n",
      "epoch: 321 loss: 1.4998362064361572 grad: 1.9088459932382813\n",
      "epoch: 322 loss: 1.5074483156204224 grad: 2.9799234050639174\n",
      "epoch: 323 loss: 1.5016560554504395 grad: 1.1088363660822425\n",
      "epoch: 324 loss: 1.499989628791809 grad: 2.696858078402449\n",
      "epoch: 325 loss: 1.507567048072815 grad: 2.815922259023575\n",
      "epoch: 326 loss: 1.5102472305297852 grad: 2.2643079573440854\n",
      "epoch: 327 loss: 1.4973043203353882 grad: 2.0248681964645128\n",
      "epoch: 328 loss: 1.5401523113250732 grad: 2.900291541594777\n",
      "epoch: 329 loss: 1.5103963613510132 grad: 2.0513898172798197\n",
      "epoch: 330 loss: 1.5007542371749878 grad: 2.4464096706978755\n",
      "epoch: 331 loss: 1.5047271251678467 grad: 2.987615454334247\n",
      "epoch: 332 loss: 1.505662202835083 grad: 2.515705218241363\n",
      "epoch: 333 loss: 1.502137541770935 grad: 3.0214035995726554\n",
      "epoch: 334 loss: 1.4898418188095093 grad: 0.9725798355933396\n",
      "epoch: 335 loss: 1.4891722202301025 grad: 1.4450653255952497\n",
      "epoch: 336 loss: 1.4996461868286133 grad: 2.262450343257409\n",
      "epoch: 337 loss: 1.5005334615707397 grad: 2.3955497151761347\n",
      "epoch: 338 loss: 1.4879841804504395 grad: 1.121699592343891\n",
      "epoch: 339 loss: 1.4929009675979614 grad: 2.094191894983355\n",
      "epoch: 340 loss: 1.4993817806243896 grad: 1.835242848493883\n",
      "epoch: 341 loss: 1.50457763671875 grad: 2.091867785424815\n",
      "epoch: 342 loss: 1.4992445707321167 grad: 1.1899500149501636\n",
      "epoch: 343 loss: 1.5072550773620605 grad: 3.5484421282712875\n",
      "epoch: 344 loss: 1.4969877004623413 grad: 2.0810656393601366\n",
      "epoch: 345 loss: 1.4890649318695068 grad: 1.8937424516934918\n",
      "epoch: 346 loss: 1.4990863800048828 grad: 1.3640926710183068\n",
      "epoch: 347 loss: 1.4918807744979858 grad: 1.615734487031136\n",
      "epoch: 348 loss: 1.501630425453186 grad: 2.576877372581705\n",
      "epoch: 349 loss: 1.527349829673767 grad: 3.9056970187420634\n",
      "epoch: 350 loss: 1.531157374382019 grad: 3.3675735127532107\n",
      "epoch: 351 loss: 1.522367238998413 grad: 3.416580901771022\n",
      "epoch: 352 loss: 1.5049785375595093 grad: 2.323245760407723\n",
      "epoch: 353 loss: 1.5014185905456543 grad: 1.5089287779181422\n",
      "epoch: 354 loss: 1.4989228248596191 grad: 1.5162315725953532\n",
      "epoch: 355 loss: 1.5103111267089844 grad: 3.045495366077269\n",
      "epoch: 356 loss: 1.5031780004501343 grad: 1.3049861717016094\n",
      "epoch: 357 loss: 1.5072649717330933 grad: 3.550378714017007\n",
      "epoch: 358 loss: 1.5023980140686035 grad: 2.2089223736474977\n",
      "epoch: 359 loss: 1.502049446105957 grad: 2.2655620455825107\n",
      "epoch: 360 loss: 1.4996869564056396 grad: 3.3763075510118608\n",
      "epoch: 361 loss: 1.5207500457763672 grad: 2.274183258156103\n",
      "epoch: 362 loss: 1.5048162937164307 grad: 1.9468673376688284\n",
      "epoch: 363 loss: 1.5075370073318481 grad: 2.826496815752657\n",
      "epoch: 364 loss: 1.493744969367981 grad: 2.834985766052392\n",
      "epoch: 365 loss: 1.504335641860962 grad: 3.871945506046826\n",
      "epoch: 366 loss: 1.5127952098846436 grad: 2.149827876403402\n",
      "epoch: 367 loss: 1.5001569986343384 grad: 2.7463137328443072\n",
      "epoch: 368 loss: 1.5130395889282227 grad: 2.003941266756084\n",
      "epoch: 369 loss: 1.4993778467178345 grad: 1.8330470832995434\n",
      "epoch: 370 loss: 1.5011519193649292 grad: 2.312987416146562\n",
      "epoch: 371 loss: 1.5024325847625732 grad: 2.6210212444765277\n",
      "epoch: 372 loss: 1.4982105493545532 grad: 1.5950075988056744\n",
      "epoch: 373 loss: 1.4933147430419922 grad: 1.5809367010089106\n",
      "epoch: 374 loss: 1.490468978881836 grad: 1.539671352547815\n",
      "epoch: 375 loss: 1.4946365356445312 grad: 1.1812876671666956\n",
      "epoch: 376 loss: 1.491167426109314 grad: 1.172322599626322\n",
      "epoch: 377 loss: 1.4874835014343262 grad: 1.466884452028339\n",
      "epoch: 378 loss: 1.5002979040145874 grad: 3.3621025304875674\n",
      "epoch: 379 loss: 1.5044548511505127 grad: 2.555640975251982\n",
      "epoch: 380 loss: 1.4938199520111084 grad: 1.1233262083980013\n",
      "epoch: 381 loss: 1.4922168254852295 grad: 1.7484576516401968\n",
      "epoch: 382 loss: 1.508530855178833 grad: 2.947351070993051\n",
      "epoch: 383 loss: 1.5044728517532349 grad: 2.854989841072906\n",
      "epoch: 384 loss: 1.4986706972122192 grad: 1.9692351801753758\n",
      "epoch: 385 loss: 1.4925711154937744 grad: 1.2037348094129146\n",
      "epoch: 386 loss: 1.4925481081008911 grad: 2.264658412985893\n",
      "epoch: 387 loss: 1.5285688638687134 grad: 2.710992962888167\n",
      "epoch: 388 loss: 1.4989240169525146 grad: 1.3818840669708168\n",
      "epoch: 389 loss: 1.5044894218444824 grad: 2.4908573334101898\n",
      "epoch: 390 loss: 1.5030736923217773 grad: 2.5074275303761913\n",
      "epoch: 391 loss: 1.4995036125183105 grad: 2.6134188832759744\n",
      "epoch: 392 loss: 1.510853886604309 grad: 2.5050055020326565\n",
      "epoch: 393 loss: 1.5076473951339722 grad: 2.105331214836139\n",
      "epoch: 394 loss: 1.497185468673706 grad: 1.5448189727397188\n",
      "epoch: 395 loss: 1.4938603639602661 grad: 1.9465892598959398\n",
      "epoch: 396 loss: 1.4974528551101685 grad: 1.8405004173006434\n",
      "epoch: 397 loss: 1.4984558820724487 grad: 1.66103160130597\n",
      "epoch: 398 loss: 1.4852321147918701 grad: 1.143538392333438\n",
      "epoch: 399 loss: 1.4979687929153442 grad: 1.7139126531071436\n",
      "epoch: 400 loss: 1.4941293001174927 grad: 1.9146462328293972\n",
      "epoch: 401 loss: 1.4971354007720947 grad: 2.3381118294992187\n",
      "epoch: 402 loss: 1.5128992795944214 grad: 2.8113907832068703\n",
      "epoch: 403 loss: 1.4896968603134155 grad: 1.8140395309225767\n",
      "epoch: 404 loss: 1.4920231103897095 grad: 2.1715531318056045\n",
      "epoch: 405 loss: 1.5163260698318481 grad: 3.1059622237190303\n",
      "epoch: 406 loss: 1.5025122165679932 grad: 3.025633312718892\n",
      "epoch: 407 loss: 1.4998365640640259 grad: 2.4986236241909565\n",
      "epoch: 408 loss: 1.5025203227996826 grad: 3.222772570138762\n",
      "epoch: 409 loss: 1.5291426181793213 grad: 3.2556820507114455\n",
      "epoch: 410 loss: 1.51116144657135 grad: 2.3533247155610106\n",
      "epoch: 411 loss: 1.4936943054199219 grad: 2.376870938198188\n",
      "epoch: 412 loss: 1.5159406661987305 grad: 2.627225020539638\n",
      "epoch: 413 loss: 1.484541654586792 grad: 0.8943440998779797\n",
      "epoch: 414 loss: 1.4966684579849243 grad: 2.382794042610696\n",
      "epoch: 415 loss: 1.4982901811599731 grad: 1.5578537715488103\n",
      "epoch: 416 loss: 1.485131859779358 grad: 1.5024668392002414\n",
      "epoch: 417 loss: 1.483039140701294 grad: 1.7719326465730336\n",
      "epoch: 418 loss: 1.4977874755859375 grad: 3.0989667354306163\n",
      "epoch: 419 loss: 1.5007739067077637 grad: 2.252891620083928\n",
      "epoch: 420 loss: 1.497969150543213 grad: 2.0292574984355656\n",
      "epoch: 421 loss: 1.5220967531204224 grad: 2.5859709015141683\n",
      "epoch: 422 loss: 1.4943649768829346 grad: 2.4810686758242566\n",
      "epoch: 423 loss: 1.4973435401916504 grad: 1.9605644083742053\n",
      "epoch: 424 loss: 1.4945952892303467 grad: 1.35147027862558\n",
      "epoch: 425 loss: 1.5090011358261108 grad: 3.1971631150591637\n",
      "epoch: 426 loss: 1.511094093322754 grad: 2.2236744066077683\n",
      "epoch: 427 loss: 1.493707299232483 grad: 1.8924648907253887\n",
      "epoch: 428 loss: 1.4950000047683716 grad: 2.062616250897333\n",
      "epoch: 429 loss: 1.4995391368865967 grad: 2.829493918600287\n",
      "epoch: 430 loss: 1.5178416967391968 grad: 2.178842626669022\n",
      "epoch: 431 loss: 1.4958442449569702 grad: 1.8839262653982958\n",
      "epoch: 432 loss: 1.481722116470337 grad: 0.9696738362948831\n",
      "epoch: 433 loss: 1.486192226409912 grad: 1.5218420726168091\n",
      "epoch: 434 loss: 1.504974603652954 grad: 3.1694768415028647\n",
      "epoch: 435 loss: 1.505323886871338 grad: 1.2248307213226568\n",
      "epoch: 436 loss: 1.5220266580581665 grad: 2.800487336291926\n",
      "epoch: 437 loss: 1.517167091369629 grad: 2.8530755315701506\n",
      "epoch: 438 loss: 1.5051554441452026 grad: 2.9790371703805514\n",
      "epoch: 439 loss: 1.4952971935272217 grad: 2.0326434144910346\n",
      "epoch: 440 loss: 1.493653655052185 grad: 1.4256446987323528\n",
      "epoch: 441 loss: 1.4928739070892334 grad: 1.7274027552847464\n",
      "epoch: 442 loss: 1.5112910270690918 grad: 2.7442530422909215\n",
      "epoch: 443 loss: 1.48928701877594 grad: 2.0852347262955644\n",
      "epoch: 444 loss: 1.4994810819625854 grad: 2.4975576668077695\n",
      "epoch: 445 loss: 1.4939823150634766 grad: 1.0303790299945874\n",
      "epoch: 446 loss: 1.493394374847412 grad: 1.2658160386316337\n",
      "epoch: 447 loss: 1.4865626096725464 grad: 1.3623912014646613\n",
      "epoch: 448 loss: 1.4921704530715942 grad: 1.548986792201989\n",
      "epoch: 449 loss: 1.4924687147140503 grad: 2.2472871151626466\n",
      "epoch: 450 loss: 1.5159623622894287 grad: 1.678275853130942\n",
      "epoch: 451 loss: 1.5089799165725708 grad: 1.5745471179274402\n",
      "epoch: 452 loss: 1.5187474489212036 grad: 3.618645669960615\n",
      "epoch: 453 loss: 1.5026601552963257 grad: 3.864232471267065\n",
      "epoch: 454 loss: 1.5060958862304688 grad: 2.31202304296393\n",
      "epoch: 455 loss: 1.491039514541626 grad: 2.0888885249747156\n",
      "epoch: 456 loss: 1.5030198097229004 grad: 2.495508944294998\n",
      "epoch: 457 loss: 1.4988329410552979 grad: 1.2600260122685034\n",
      "epoch: 458 loss: 1.4913536310195923 grad: 1.3273763000950007\n",
      "epoch: 459 loss: 1.4910565614700317 grad: 2.697918184731835\n",
      "epoch: 460 loss: 1.5057621002197266 grad: 1.66371647670182\n",
      "epoch: 461 loss: 1.4991028308868408 grad: 1.13529581010823\n",
      "epoch: 462 loss: 1.490990161895752 grad: 1.2720690421383352\n",
      "epoch: 463 loss: 1.4911150932312012 grad: 2.6570507235110714\n",
      "epoch: 464 loss: 1.5027942657470703 grad: 2.2704089649221877\n",
      "epoch: 465 loss: 1.4863601922988892 grad: 1.6749088569816792\n",
      "epoch: 466 loss: 1.4872533082962036 grad: 0.7793306812860757\n",
      "epoch: 467 loss: 1.4832782745361328 grad: 1.190123350711694\n",
      "epoch: 468 loss: 1.4845963716506958 grad: 1.462236123711012\n",
      "epoch: 469 loss: 1.482722282409668 grad: 1.3780689045813883\n",
      "epoch: 470 loss: 1.4886682033538818 grad: 2.2770711187389865\n",
      "epoch: 471 loss: 1.4989583492279053 grad: 1.458781078817418\n",
      "epoch: 472 loss: 1.4987257719039917 grad: 1.942506403082051\n",
      "epoch: 473 loss: 1.4912729263305664 grad: 1.6816553469887052\n",
      "epoch: 474 loss: 1.491084337234497 grad: 2.0561767717674537\n",
      "epoch: 475 loss: 1.4866664409637451 grad: 1.8362988922193744\n",
      "epoch: 476 loss: 1.4886276721954346 grad: 1.2069322161077913\n",
      "epoch: 477 loss: 1.4842277765274048 grad: 1.554789224175221\n",
      "epoch: 478 loss: 1.4918441772460938 grad: 1.0783098669793891\n",
      "epoch: 479 loss: 1.5007539987564087 grad: 1.8228269087296118\n",
      "epoch: 480 loss: 1.5053101778030396 grad: 1.6558420498288626\n",
      "epoch: 481 loss: 1.4986114501953125 grad: 2.0002194350278404\n",
      "epoch: 482 loss: 1.530713438987732 grad: 2.2757276853120936\n",
      "epoch: 483 loss: 1.5108319520950317 grad: 2.3827317225879443\n",
      "epoch: 484 loss: 1.522309422492981 grad: 2.6441107574035128\n",
      "epoch: 485 loss: 1.5085922479629517 grad: 2.618829805858185\n",
      "epoch: 486 loss: 1.5020934343338013 grad: 1.910420771323218\n",
      "epoch: 487 loss: 1.4897044897079468 grad: 1.0150449112500264\n",
      "epoch: 488 loss: 1.4807783365249634 grad: 0.9819370846830828\n",
      "epoch: 489 loss: 1.4808108806610107 grad: 1.0884214457096482\n",
      "epoch: 490 loss: 1.4888956546783447 grad: 1.023158817007701\n",
      "epoch: 491 loss: 1.4874879121780396 grad: 1.679822446944021\n",
      "epoch: 492 loss: 1.4851105213165283 grad: 1.6233009886515055\n",
      "epoch: 493 loss: 1.492942452430725 grad: 1.857804500128269\n",
      "epoch: 494 loss: 1.5008212327957153 grad: 1.583103486413032\n",
      "epoch: 495 loss: 1.4898184537887573 grad: 1.0896047064308316\n",
      "epoch: 496 loss: 1.491966724395752 grad: 1.5601409193797706\n",
      "epoch: 497 loss: 1.493133544921875 grad: 2.398602323185044\n",
      "epoch: 498 loss: 1.5036344528198242 grad: 2.5519957780113334\n",
      "epoch: 499 loss: 1.4960936307907104 grad: 1.6214620967825828\n",
      "1.800662249326706\n",
      "1.8013098537921906\n",
      "1.8013098537921906\n",
      "epoch: 0 loss: 2.3026585578918457 grad: 1.5263684966364905\n",
      "epoch: 1 loss: 2.302168607711792 grad: 1.5265998745869314\n",
      "epoch: 2 loss: 2.3028247356414795 grad: 1.5235969517176735\n",
      "epoch: 3 loss: 2.302497625350952 grad: 1.5305220626982017\n",
      "epoch: 4 loss: 2.302201986312866 grad: 1.5260698537320077\n",
      "epoch: 5 loss: 2.302711009979248 grad: 1.5310288760515431\n",
      "epoch: 6 loss: 2.303036689758301 grad: 1.5174615901917041\n",
      "epoch: 7 loss: 2.302236318588257 grad: 1.5279039205643274\n",
      "epoch: 8 loss: 2.3025755882263184 grad: 1.5219576607388074\n",
      "epoch: 9 loss: 2.303117275238037 grad: 1.5253596309653765\n",
      "epoch: 10 loss: 2.302931547164917 grad: 1.5281833538172087\n",
      "epoch: 11 loss: 2.302907705307007 grad: 1.5133788004399291\n",
      "epoch: 12 loss: 2.3026747703552246 grad: 1.520176036294461\n",
      "epoch: 13 loss: 2.3026764392852783 grad: 1.5285471974824008\n",
      "epoch: 14 loss: 2.3029091358184814 grad: 1.509740248374227\n",
      "epoch: 15 loss: 2.302398443222046 grad: 1.5363021658452611\n",
      "epoch: 16 loss: 2.3029720783233643 grad: 1.5102176715394422\n",
      "epoch: 17 loss: 2.302150011062622 grad: 1.5331157801399333\n",
      "epoch: 18 loss: 2.30218243598938 grad: 1.5386498115701779\n",
      "epoch: 19 loss: 2.3021976947784424 grad: 1.527534288527917\n",
      "epoch: 20 loss: 2.3027396202087402 grad: 1.5200569902506051\n",
      "epoch: 21 loss: 2.3024919033050537 grad: 1.5204817456219137\n",
      "epoch: 22 loss: 2.302865982055664 grad: 1.5101945950494458\n",
      "epoch: 23 loss: 2.303225040435791 grad: 1.5128820208769793\n",
      "epoch: 24 loss: 2.3028807640075684 grad: 1.5220349239968947\n",
      "epoch: 25 loss: 2.3021719455718994 grad: 1.5329900956989841\n",
      "epoch: 26 loss: 2.302173376083374 grad: 1.5358004203132753\n",
      "epoch: 27 loss: 2.3022632598876953 grad: 1.5216720201267255\n",
      "epoch: 28 loss: 2.302713394165039 grad: 1.5146095847141825\n",
      "epoch: 29 loss: 2.302119016647339 grad: 1.5261738644469351\n",
      "epoch: 30 loss: 2.3022422790527344 grad: 1.5295988528837732\n",
      "epoch: 31 loss: 2.3022689819335938 grad: 1.5220266218807192\n",
      "epoch: 32 loss: 2.3028693199157715 grad: 1.5185956535121752\n",
      "epoch: 33 loss: 2.3020389080047607 grad: 1.5268077732263399\n",
      "epoch: 34 loss: 2.3019278049468994 grad: 1.5392220724847108\n",
      "epoch: 35 loss: 2.3024516105651855 grad: 1.51626083433872\n",
      "epoch: 36 loss: 2.301743268966675 grad: 1.5347948257944413\n",
      "epoch: 37 loss: 2.301882028579712 grad: 1.528338665227657\n",
      "epoch: 38 loss: 2.3024661540985107 grad: 1.5109279449578257\n",
      "epoch: 39 loss: 2.3023488521575928 grad: 1.5169173852902733\n",
      "epoch: 40 loss: 2.302295207977295 grad: 1.5198829128085414\n",
      "epoch: 41 loss: 2.3015990257263184 grad: 1.534159545328409\n",
      "epoch: 42 loss: 2.3020644187927246 grad: 1.5257610605090917\n",
      "epoch: 43 loss: 2.3026745319366455 grad: 1.5108803508651725\n",
      "epoch: 44 loss: 2.302816152572632 grad: 1.5138528726196714\n",
      "epoch: 45 loss: 2.3017420768737793 grad: 1.5367288310006852\n",
      "epoch: 46 loss: 2.301931619644165 grad: 1.5338748285790818\n",
      "epoch: 47 loss: 2.301753282546997 grad: 1.5320020573535225\n",
      "epoch: 48 loss: 2.3022878170013428 grad: 1.5122608939603355\n",
      "epoch: 49 loss: 2.3017752170562744 grad: 1.5272124771320719\n",
      "epoch: 50 loss: 2.3023524284362793 grad: 1.522643589107911\n",
      "epoch: 51 loss: 2.301976442337036 grad: 1.5197508849743162\n",
      "epoch: 52 loss: 2.3022427558898926 grad: 1.5184045025435764\n",
      "epoch: 53 loss: 2.3015341758728027 grad: 1.537071581083601\n",
      "epoch: 54 loss: 2.302081823348999 grad: 1.5266078447346532\n",
      "epoch: 55 loss: 2.3019304275512695 grad: 1.522619540298668\n",
      "epoch: 56 loss: 2.302673101425171 grad: 1.511655899147237\n",
      "epoch: 57 loss: 2.3022310733795166 grad: 1.5163407955791741\n",
      "epoch: 58 loss: 2.301386594772339 grad: 1.5363296671837037\n",
      "epoch: 59 loss: 2.3019111156463623 grad: 1.5238746672107408\n",
      "epoch: 60 loss: 2.3016517162323 grad: 1.537084359367053\n",
      "epoch: 61 loss: 2.3018674850463867 grad: 1.530914280899904\n",
      "epoch: 62 loss: 2.301547050476074 grad: 1.533839082284387\n",
      "epoch: 63 loss: 2.3015685081481934 grad: 1.533032743332331\n",
      "epoch: 64 loss: 2.302022933959961 grad: 1.5139281478348292\n",
      "epoch: 65 loss: 2.3013391494750977 grad: 1.548437790558969\n",
      "epoch: 66 loss: 2.3018805980682373 grad: 1.5190928115616626\n",
      "epoch: 67 loss: 2.302109479904175 grad: 1.5132806620427541\n",
      "epoch: 68 loss: 2.302075147628784 grad: 1.5289069966538735\n",
      "epoch: 69 loss: 2.301804542541504 grad: 1.5120750965424887\n",
      "epoch: 70 loss: 2.301384925842285 grad: 1.5430411897832528\n",
      "epoch: 71 loss: 2.3016648292541504 grad: 1.5302007250739114\n",
      "epoch: 72 loss: 2.3019378185272217 grad: 1.5119697308511517\n",
      "epoch: 73 loss: 2.3013834953308105 grad: 1.5318882749452891\n",
      "epoch: 74 loss: 2.3019607067108154 grad: 1.5271411163155877\n",
      "epoch: 75 loss: 2.301429510116577 grad: 1.5378850266902842\n",
      "epoch: 76 loss: 2.3016934394836426 grad: 1.5186683014848283\n",
      "epoch: 77 loss: 2.3015291690826416 grad: 1.521993914863006\n",
      "epoch: 78 loss: 2.302011251449585 grad: 1.5231076965463304\n",
      "epoch: 79 loss: 2.301506519317627 grad: 1.5149837559059498\n",
      "epoch: 80 loss: 2.3014273643493652 grad: 1.5100628604543291\n",
      "epoch: 81 loss: 2.3017289638519287 grad: 1.5204916956191439\n",
      "epoch: 82 loss: 2.301636219024658 grad: 1.5103640319439509\n",
      "epoch: 83 loss: 2.3016436100006104 grad: 1.5170895042977044\n",
      "epoch: 84 loss: 2.301133394241333 grad: 1.5284543085089397\n",
      "epoch: 85 loss: 2.30117130279541 grad: 1.531635982838149\n",
      "epoch: 86 loss: 2.3010833263397217 grad: 1.5374981138323034\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 87 loss: 2.301201820373535 grad: 1.5279387116232621\n",
      "epoch: 88 loss: 2.3010616302490234 grad: 1.5229398180834122\n",
      "epoch: 89 loss: 2.3009276390075684 grad: 1.5301522645334313\n",
      "epoch: 90 loss: 2.3017771244049072 grad: 1.5175319907148295\n",
      "epoch: 91 loss: 2.3008036613464355 grad: 1.5407615230743965\n",
      "epoch: 92 loss: 2.3008265495300293 grad: 1.5285852972015237\n",
      "epoch: 93 loss: 2.301095485687256 grad: 1.5274479548550315\n",
      "epoch: 94 loss: 2.300771474838257 grad: 1.5330784062222977\n",
      "epoch: 95 loss: 2.301344871520996 grad: 1.5227380555403967\n",
      "epoch: 96 loss: 2.300814628601074 grad: 1.5335654183475684\n",
      "epoch: 97 loss: 2.3009350299835205 grad: 1.532312415719461\n",
      "epoch: 98 loss: 2.300408124923706 grad: 1.5416976912612361\n",
      "epoch: 99 loss: 2.3009049892425537 grad: 1.5381169028668886\n",
      "epoch: 100 loss: 2.3009586334228516 grad: 1.5192196661299686\n",
      "epoch: 101 loss: 2.3004491329193115 grad: 1.5394820104194213\n",
      "epoch: 102 loss: 2.300675392150879 grad: 1.5366607013820035\n",
      "epoch: 103 loss: 2.3004863262176514 grad: 1.5302133477396436\n",
      "epoch: 104 loss: 2.300363302230835 grad: 1.5204268483156782\n",
      "epoch: 105 loss: 2.301144599914551 grad: 1.507986424790163\n",
      "epoch: 106 loss: 2.301015853881836 grad: 1.5142109107710273\n",
      "epoch: 107 loss: 2.3004910945892334 grad: 1.534815337374023\n",
      "epoch: 108 loss: 2.3002777099609375 grad: 1.5407107214458169\n",
      "epoch: 109 loss: 2.3004353046417236 grad: 1.5269596347334011\n",
      "epoch: 110 loss: 2.3009307384490967 grad: 1.5242209907266355\n",
      "epoch: 111 loss: 2.299772262573242 grad: 1.5429454232059745\n",
      "epoch: 112 loss: 2.300670623779297 grad: 1.520872628453025\n",
      "epoch: 113 loss: 2.3004918098449707 grad: 1.518668434456996\n",
      "epoch: 114 loss: 2.3010013103485107 grad: 1.5187182333135594\n",
      "epoch: 115 loss: 2.3003406524658203 grad: 1.543745645155598\n",
      "epoch: 116 loss: 2.300899028778076 grad: 1.5213938030868857\n",
      "epoch: 117 loss: 2.3003926277160645 grad: 1.5254826224704703\n",
      "epoch: 118 loss: 2.3001434803009033 grad: 1.5378949235448436\n",
      "epoch: 119 loss: 2.3004097938537598 grad: 1.525520367074817\n",
      "epoch: 120 loss: 2.299917697906494 grad: 1.528993885040224\n",
      "epoch: 121 loss: 2.2997782230377197 grad: 1.5348516196855122\n",
      "epoch: 122 loss: 2.30025315284729 grad: 1.5364616005053182\n",
      "epoch: 123 loss: 2.299551010131836 grad: 1.540368988893793\n",
      "epoch: 124 loss: 2.2998809814453125 grad: 1.5434060250815478\n",
      "epoch: 125 loss: 2.299651861190796 grad: 1.5407799824532713\n",
      "epoch: 126 loss: 2.298877000808716 grad: 1.535188779386411\n",
      "epoch: 127 loss: 2.299380302429199 grad: 1.546050287823799\n",
      "epoch: 128 loss: 2.2997899055480957 grad: 1.5246004272965596\n",
      "epoch: 129 loss: 2.299424648284912 grad: 1.5388037679968254\n",
      "epoch: 130 loss: 2.299408435821533 grad: 1.526175181547712\n",
      "epoch: 131 loss: 2.2995879650115967 grad: 1.5328744597056703\n",
      "epoch: 132 loss: 2.299494743347168 grad: 1.5212514068809382\n",
      "epoch: 133 loss: 2.29959774017334 grad: 1.533315559917514\n",
      "epoch: 134 loss: 2.29996919631958 grad: 1.5241087162368265\n",
      "epoch: 135 loss: 2.2995975017547607 grad: 1.535929831142153\n",
      "epoch: 136 loss: 2.2999556064605713 grad: 1.528797622877247\n",
      "epoch: 137 loss: 2.2994725704193115 grad: 1.5357484975940592\n",
      "epoch: 138 loss: 2.298874855041504 grad: 1.5441120902024623\n",
      "epoch: 139 loss: 2.299288272857666 grad: 1.5474487667116115\n",
      "epoch: 140 loss: 2.2994470596313477 grad: 1.5270611326901302\n",
      "epoch: 141 loss: 2.299478530883789 grad: 1.534797617404293\n",
      "epoch: 142 loss: 2.298884153366089 grad: 1.528485648067934\n",
      "epoch: 143 loss: 2.298771381378174 grad: 1.5568005111851981\n",
      "epoch: 144 loss: 2.29903244972229 grad: 1.5376881778513687\n",
      "epoch: 145 loss: 2.298738718032837 grad: 1.5461164072695528\n",
      "epoch: 146 loss: 2.2989437580108643 grad: 1.5289759235770723\n",
      "epoch: 147 loss: 2.2987749576568604 grad: 1.5429213957654104\n",
      "epoch: 148 loss: 2.2982563972473145 grad: 1.5614715622782351\n",
      "epoch: 149 loss: 2.2982847690582275 grad: 1.560443077543159\n",
      "epoch: 150 loss: 2.298964262008667 grad: 1.5372456884425547\n",
      "epoch: 151 loss: 2.298598289489746 grad: 1.5418299984663637\n",
      "epoch: 152 loss: 2.298973321914673 grad: 1.535984192577575\n",
      "epoch: 153 loss: 2.2989234924316406 grad: 1.5480403819210118\n",
      "epoch: 154 loss: 2.2990286350250244 grad: 1.5224932995717233\n",
      "epoch: 155 loss: 2.2982394695281982 grad: 1.559777392246317\n",
      "epoch: 156 loss: 2.2983806133270264 grad: 1.5417318403099973\n",
      "epoch: 157 loss: 2.297950029373169 grad: 1.5415915545419834\n",
      "epoch: 158 loss: 2.297891616821289 grad: 1.5670021488959531\n",
      "epoch: 159 loss: 2.2978336811065674 grad: 1.5556645963178386\n",
      "epoch: 160 loss: 2.2979512214660645 grad: 1.555644675764063\n",
      "epoch: 161 loss: 2.297633171081543 grad: 1.5576891248883118\n",
      "epoch: 162 loss: 2.297725200653076 grad: 1.555926682689922\n",
      "epoch: 163 loss: 2.29788875579834 grad: 1.577978975342823\n",
      "epoch: 164 loss: 2.297346830368042 grad: 1.5742481002872366\n",
      "epoch: 165 loss: 2.298121452331543 grad: 1.552627556763279\n",
      "epoch: 166 loss: 2.2975962162017822 grad: 1.5756382963431643\n",
      "epoch: 167 loss: 2.2973406314849854 grad: 1.581724210671844\n",
      "epoch: 168 loss: 2.2965197563171387 grad: 1.5879830934147956\n",
      "epoch: 169 loss: 2.2970821857452393 grad: 1.5776323541972994\n",
      "epoch: 170 loss: 2.297442674636841 grad: 1.574543789892073\n",
      "epoch: 171 loss: 2.296804428100586 grad: 1.6024462269094315\n",
      "epoch: 172 loss: 2.2969090938568115 grad: 1.5786637534472412\n",
      "epoch: 173 loss: 2.2974116802215576 grad: 1.5845124137085227\n",
      "epoch: 174 loss: 2.296746015548706 grad: 1.5997932603017293\n",
      "epoch: 175 loss: 2.296081304550171 grad: 1.5884432094023815\n",
      "epoch: 176 loss: 2.2969794273376465 grad: 1.6014777370266586\n",
      "epoch: 177 loss: 2.2968623638153076 grad: 1.5989172100939506\n",
      "epoch: 178 loss: 2.296687126159668 grad: 1.6056853246390967\n",
      "epoch: 179 loss: 2.2962520122528076 grad: 1.6159602052103432\n",
      "epoch: 180 loss: 2.2955236434936523 grad: 1.6298616204543837\n",
      "epoch: 181 loss: 2.2967140674591064 grad: 1.5934259423520416\n",
      "epoch: 182 loss: 2.2969422340393066 grad: 1.5933537519692134\n",
      "epoch: 183 loss: 2.296358823776245 grad: 1.6089091073344683\n",
      "epoch: 184 loss: 2.2962608337402344 grad: 1.6102325097003596\n",
      "epoch: 185 loss: 2.2953007221221924 grad: 1.6283629335618268\n",
      "epoch: 186 loss: 2.295795440673828 grad: 1.6403308814310187\n",
      "epoch: 187 loss: 2.296370506286621 grad: 1.6182569034345862\n",
      "epoch: 188 loss: 2.295581102371216 grad: 1.6481354848004965\n",
      "epoch: 189 loss: 2.2959909439086914 grad: 1.6314450572836139\n",
      "epoch: 190 loss: 2.295189380645752 grad: 1.634459847233273\n",
      "epoch: 191 loss: 2.294893503189087 grad: 1.6497969164675663\n",
      "epoch: 192 loss: 2.2944490909576416 grad: 1.6714728909345078\n",
      "epoch: 193 loss: 2.294895887374878 grad: 1.6543081454407897\n",
      "epoch: 194 loss: 2.295078992843628 grad: 1.651998329031769\n",
      "epoch: 195 loss: 2.294199228286743 grad: 1.671782977442952\n",
      "epoch: 196 loss: 2.295283079147339 grad: 1.6747717444252754\n",
      "epoch: 197 loss: 2.295511484146118 grad: 1.654666389822812\n",
      "epoch: 198 loss: 2.2945640087127686 grad: 1.6515137203229917\n",
      "epoch: 199 loss: 2.2949790954589844 grad: 1.6635558135208808\n",
      "epoch: 200 loss: 2.2944064140319824 grad: 1.6865680953487754\n",
      "epoch: 201 loss: 2.294036388397217 grad: 1.6783637720149098\n",
      "epoch: 202 loss: 2.2936649322509766 grad: 1.6883847991093284\n",
      "epoch: 203 loss: 2.2939977645874023 grad: 1.6910554666001911\n",
      "epoch: 204 loss: 2.293095350265503 grad: 1.7046723183732302\n",
      "epoch: 205 loss: 2.293543577194214 grad: 1.7089572544690104\n",
      "epoch: 206 loss: 2.2945921421051025 grad: 1.6880060537008656\n",
      "epoch: 207 loss: 2.2942724227905273 grad: 1.7025252777957431\n",
      "epoch: 208 loss: 2.2929959297180176 grad: 1.7232368807197505\n",
      "epoch: 209 loss: 2.2920470237731934 grad: 1.7264346826344816\n",
      "epoch: 210 loss: 2.2941949367523193 grad: 1.7001714893905002\n",
      "epoch: 211 loss: 2.293241500854492 grad: 1.7307550991693186\n",
      "epoch: 212 loss: 2.292269229888916 grad: 1.7646158574100967\n",
      "epoch: 213 loss: 2.2932472229003906 grad: 1.7301537542537386\n",
      "epoch: 214 loss: 2.29315447807312 grad: 1.719725798907882\n",
      "epoch: 215 loss: 2.2939374446868896 grad: 1.7346136861125983\n",
      "epoch: 216 loss: 2.291558027267456 grad: 1.7649118943169477\n",
      "epoch: 217 loss: 2.2921175956726074 grad: 1.7575680910875755\n",
      "epoch: 218 loss: 2.293186664581299 grad: 1.754470773809959\n",
      "epoch: 219 loss: 2.2920477390289307 grad: 1.769703443838461\n",
      "epoch: 220 loss: 2.291322708129883 grad: 1.7774651254331397\n",
      "epoch: 221 loss: 2.292266607284546 grad: 1.7482794241587971\n",
      "epoch: 222 loss: 2.292189598083496 grad: 1.765775244379978\n",
      "epoch: 223 loss: 2.291329860687256 grad: 1.7944650143968859\n",
      "epoch: 224 loss: 2.292215347290039 grad: 1.7862828120086638\n",
      "epoch: 225 loss: 2.2918155193328857 grad: 1.7917116298857663\n",
      "epoch: 226 loss: 2.291741371154785 grad: 1.794559983806389\n",
      "epoch: 227 loss: 2.2907400131225586 grad: 1.7958530255053784\n",
      "epoch: 228 loss: 2.2909889221191406 grad: 1.7954694834918463\n",
      "epoch: 229 loss: 2.291253089904785 grad: 1.796675729112596\n",
      "epoch: 230 loss: 2.291469097137451 grad: 1.7910117299096393\n",
      "epoch: 231 loss: 2.292222261428833 grad: 1.7980319278255579\n",
      "epoch: 232 loss: 2.290451765060425 grad: 1.8170444182164611\n",
      "epoch: 233 loss: 2.290952205657959 grad: 1.812261090074326\n",
      "epoch: 234 loss: 2.29142165184021 grad: 1.8137373200632514\n",
      "epoch: 235 loss: 2.290245532989502 grad: 1.8186161613298788\n",
      "epoch: 236 loss: 2.290739059448242 grad: 1.801944079162139\n",
      "epoch: 237 loss: 2.2924633026123047 grad: 1.806960586292137\n",
      "epoch: 238 loss: 2.290879011154175 grad: 1.803941347547585\n",
      "epoch: 239 loss: 2.2919280529022217 grad: 1.7880798539106129\n",
      "epoch: 240 loss: 2.2899296283721924 grad: 1.8346400001189775\n",
      "epoch: 241 loss: 2.2903060913085938 grad: 1.8148685282092571\n",
      "epoch: 242 loss: 2.2916624546051025 grad: 1.8032693868347753\n",
      "epoch: 243 loss: 2.2915804386138916 grad: 1.7991569896989932\n",
      "epoch: 244 loss: 2.2908105850219727 grad: 1.817052151542157\n",
      "epoch: 245 loss: 2.2900373935699463 grad: 1.8231272426810825\n",
      "epoch: 246 loss: 2.291043996810913 grad: 1.7933631239843273\n",
      "epoch: 247 loss: 2.2893199920654297 grad: 1.8344681104608176\n",
      "epoch: 248 loss: 2.2890126705169678 grad: 1.8359333084386198\n",
      "epoch: 249 loss: 2.2893261909484863 grad: 1.8516244122810248\n",
      "epoch: 250 loss: 2.2896475791931152 grad: 1.8003367579538405\n",
      "epoch: 251 loss: 2.2894041538238525 grad: 1.8565948894616986\n",
      "epoch: 252 loss: 2.289933919906616 grad: 1.8190037174083824\n",
      "epoch: 253 loss: 2.2888989448547363 grad: 1.8504183253140323\n",
      "epoch: 254 loss: 2.289809226989746 grad: 1.829779692494961\n",
      "epoch: 255 loss: 2.288709878921509 grad: 1.86210549525207\n",
      "epoch: 256 loss: 2.2885265350341797 grad: 1.837114042218124\n",
      "epoch: 257 loss: 2.288729190826416 grad: 1.8098326063648398\n",
      "epoch: 258 loss: 2.28826642036438 grad: 1.848625589849516\n",
      "epoch: 259 loss: 2.288949966430664 grad: 1.8404275693465024\n",
      "epoch: 260 loss: 2.287950277328491 grad: 1.8537055828224218\n",
      "epoch: 261 loss: 2.2872672080993652 grad: 1.863499544243077\n",
      "epoch: 262 loss: 2.286231756210327 grad: 1.8842572939086941\n",
      "epoch: 263 loss: 2.2891690731048584 grad: 1.8483251283732465\n",
      "epoch: 264 loss: 2.287600040435791 grad: 1.8732827230400981\n",
      "epoch: 265 loss: 2.2878830432891846 grad: 1.8550717248655264\n",
      "epoch: 266 loss: 2.288705348968506 grad: 1.8554828433201662\n",
      "epoch: 267 loss: 2.2878451347351074 grad: 1.8337032374268072\n",
      "epoch: 268 loss: 2.286806583404541 grad: 1.8503814082858818\n",
      "epoch: 269 loss: 2.2874057292938232 grad: 1.8217201494567452\n",
      "epoch: 270 loss: 2.2866671085357666 grad: 1.885708726410355\n",
      "epoch: 271 loss: 2.285930633544922 grad: 1.8645186145191215\n",
      "epoch: 272 loss: 2.2866389751434326 grad: 1.8932754599936454\n",
      "epoch: 273 loss: 2.2871811389923096 grad: 1.8660031979208782\n",
      "epoch: 274 loss: 2.2876222133636475 grad: 1.8848187665469827\n",
      "epoch: 275 loss: 2.285653829574585 grad: 1.8949784169986195\n",
      "epoch: 276 loss: 2.2853708267211914 grad: 1.8867299938426605\n",
      "epoch: 277 loss: 2.2855303287506104 grad: 1.8904145463214566\n",
      "epoch: 278 loss: 2.2864010334014893 grad: 1.858040909996138\n",
      "epoch: 279 loss: 2.2856316566467285 grad: 1.8575553711215478\n",
      "epoch: 280 loss: 2.287287473678589 grad: 1.8728699336874313\n",
      "epoch: 281 loss: 2.2855875492095947 grad: 1.8674685271966847\n",
      "epoch: 282 loss: 2.284611463546753 grad: 1.9110955242492584\n",
      "epoch: 283 loss: 2.2853455543518066 grad: 1.8932321301166204\n",
      "epoch: 284 loss: 2.2850377559661865 grad: 1.8794285665184909\n",
      "epoch: 285 loss: 2.2853336334228516 grad: 1.9013874005186298\n",
      "epoch: 286 loss: 2.2851181030273438 grad: 1.9289932795061124\n",
      "epoch: 287 loss: 2.283834934234619 grad: 1.9265538986646644\n",
      "epoch: 288 loss: 2.2837417125701904 grad: 1.922026670844634\n",
      "epoch: 289 loss: 2.284371852874756 grad: 1.925376293012902\n",
      "epoch: 290 loss: 2.2858920097351074 grad: 1.9024017526812496\n",
      "epoch: 291 loss: 2.283726930618286 grad: 1.9218798110867659\n",
      "epoch: 292 loss: 2.285477638244629 grad: 1.9196427988871518\n",
      "epoch: 293 loss: 2.284257411956787 grad: 1.9065620929727123\n",
      "epoch: 294 loss: 2.28485369682312 grad: 1.9405354204705902\n",
      "epoch: 295 loss: 2.2832953929901123 grad: 1.9140016428889737\n",
      "epoch: 296 loss: 2.283391237258911 grad: 1.9690975068831846\n",
      "epoch: 297 loss: 2.28298282623291 grad: 1.9291954085097782\n",
      "epoch: 298 loss: 2.282768726348877 grad: 1.9454079448884827\n",
      "epoch: 299 loss: 2.2831218242645264 grad: 1.9257740787903055\n",
      "epoch: 300 loss: 2.28218936920166 grad: 1.9261636929253914\n",
      "epoch: 301 loss: 2.2835841178894043 grad: 1.930034544137824\n",
      "epoch: 302 loss: 2.284745693206787 grad: 1.9233509234840138\n",
      "epoch: 303 loss: 2.2811503410339355 grad: 1.9371663103109256\n",
      "epoch: 304 loss: 2.2821836471557617 grad: 1.9395718011665084\n",
      "epoch: 305 loss: 2.2813141345977783 grad: 1.9688621891130293\n",
      "epoch: 306 loss: 2.2820029258728027 grad: 1.9484055107015938\n",
      "epoch: 307 loss: 2.2810049057006836 grad: 1.994623133960727\n",
      "epoch: 308 loss: 2.283348321914673 grad: 1.9556224212116962\n",
      "epoch: 309 loss: 2.2828128337860107 grad: 1.966052181547552\n",
      "epoch: 310 loss: 2.28377366065979 grad: 1.9748666827485615\n",
      "epoch: 311 loss: 2.2814536094665527 grad: 2.0067320766910495\n",
      "epoch: 312 loss: 2.2815945148468018 grad: 1.970452668289432\n",
      "epoch: 313 loss: 2.281856060028076 grad: 1.959749804240548\n",
      "epoch: 314 loss: 2.2793052196502686 grad: 1.9939094833874453\n",
      "epoch: 315 loss: 2.2818822860717773 grad: 1.9994206532451606\n",
      "epoch: 316 loss: 2.2797887325286865 grad: 1.9656327163120584\n",
      "epoch: 317 loss: 2.280907154083252 grad: 2.0173994993535977\n",
      "epoch: 318 loss: 2.2801122665405273 grad: 1.9648691750212854\n",
      "epoch: 319 loss: 2.279590129852295 grad: 2.010044901587424\n",
      "epoch: 320 loss: 2.2794179916381836 grad: 2.0226541673247187\n",
      "epoch: 321 loss: 2.2797791957855225 grad: 2.0275713981384236\n",
      "epoch: 322 loss: 2.2800240516662598 grad: 1.9884823910219387\n",
      "epoch: 323 loss: 2.2797939777374268 grad: 2.0657546138316984\n",
      "epoch: 324 loss: 2.278628349304199 grad: 2.010449498801285\n",
      "epoch: 325 loss: 2.2786238193511963 grad: 2.026420346106447\n",
      "epoch: 326 loss: 2.2779250144958496 grad: 2.068442576906703\n",
      "epoch: 327 loss: 2.279581069946289 grad: 2.051193449733084\n",
      "epoch: 328 loss: 2.279559850692749 grad: 2.014054021631767\n",
      "epoch: 329 loss: 2.278113603591919 grad: 2.025319473570331\n",
      "epoch: 330 loss: 2.2784762382507324 grad: 2.0583169605501648\n",
      "epoch: 331 loss: 2.2770416736602783 grad: 2.095790263339286\n",
      "epoch: 332 loss: 2.2769904136657715 grad: 2.083263188630106\n",
      "epoch: 333 loss: 2.2771120071411133 grad: 2.1402149614249724\n",
      "epoch: 334 loss: 2.277866840362549 grad: 2.102194438810416\n",
      "epoch: 335 loss: 2.277918577194214 grad: 2.1302088378403807\n",
      "epoch: 336 loss: 2.2774245738983154 grad: 2.1087785170871824\n",
      "epoch: 337 loss: 2.2751662731170654 grad: 2.1269323166481975\n",
      "epoch: 338 loss: 2.276073932647705 grad: 2.1531332177516544\n",
      "epoch: 339 loss: 2.2761363983154297 grad: 2.1575183903517585\n",
      "epoch: 340 loss: 2.2757811546325684 grad: 2.181380160127042\n",
      "epoch: 341 loss: 2.273642063140869 grad: 2.148085306234111\n",
      "epoch: 342 loss: 2.275207281112671 grad: 2.182949798950364\n",
      "epoch: 343 loss: 2.2748470306396484 grad: 2.2158040203050606\n",
      "epoch: 344 loss: 2.2739827632904053 grad: 2.218975240239016\n",
      "epoch: 345 loss: 2.274592638015747 grad: 2.228222890387452\n",
      "epoch: 346 loss: 2.2740397453308105 grad: 2.2142716129901747\n",
      "epoch: 347 loss: 2.274458169937134 grad: 2.2782552407921424\n",
      "epoch: 348 loss: 2.273668050765991 grad: 2.24262452899434\n",
      "epoch: 349 loss: 2.2723307609558105 grad: 2.261289524324682\n",
      "epoch: 350 loss: 2.270909070968628 grad: 2.305611672489682\n",
      "epoch: 351 loss: 2.2733399868011475 grad: 2.2972402298593866\n",
      "epoch: 352 loss: 2.2703802585601807 grad: 2.28621785899639\n",
      "epoch: 353 loss: 2.2717902660369873 grad: 2.325291342009598\n",
      "epoch: 354 loss: 2.2708513736724854 grad: 2.390325085311714\n",
      "epoch: 355 loss: 2.269582748413086 grad: 2.400031942770713\n",
      "epoch: 356 loss: 2.269658327102661 grad: 2.392039496056174\n",
      "epoch: 357 loss: 2.269810438156128 grad: 2.4440302404737664\n",
      "epoch: 358 loss: 2.267939805984497 grad: 2.4537996701038782\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 359 loss: 2.2670416831970215 grad: 2.4582494497299194\n",
      "epoch: 360 loss: 2.2647664546966553 grad: 2.546633932236878\n",
      "epoch: 361 loss: 2.267204761505127 grad: 2.5434748846778854\n",
      "epoch: 362 loss: 2.2690701484680176 grad: 2.5999013430084146\n",
      "epoch: 363 loss: 2.265957832336426 grad: 2.580254005955621\n",
      "epoch: 364 loss: 2.263889789581299 grad: 2.6243934790448598\n",
      "epoch: 365 loss: 2.263291120529175 grad: 2.6729671121353196\n",
      "epoch: 366 loss: 2.2639284133911133 grad: 2.6592189924835803\n",
      "epoch: 367 loss: 2.261939764022827 grad: 2.7158800385862825\n",
      "epoch: 368 loss: 2.261488676071167 grad: 2.743188621498467\n",
      "epoch: 369 loss: 2.25821852684021 grad: 2.80503869543059\n",
      "epoch: 370 loss: 2.2591733932495117 grad: 2.8912792692796163\n",
      "epoch: 371 loss: 2.258540391921997 grad: 2.8427407327625485\n",
      "epoch: 372 loss: 2.2577147483825684 grad: 2.9290745283277437\n",
      "epoch: 373 loss: 2.254122734069824 grad: 2.963291515141637\n",
      "epoch: 374 loss: 2.2525339126586914 grad: 2.940809825612676\n",
      "epoch: 375 loss: 2.2514045238494873 grad: 2.9078974679947667\n",
      "epoch: 376 loss: 2.2487268447875977 grad: 3.021467208869696\n",
      "epoch: 377 loss: 2.2492763996124268 grad: 3.037847763600035\n",
      "epoch: 378 loss: 2.2463343143463135 grad: 3.021261653700282\n",
      "epoch: 379 loss: 2.2463438510894775 grad: 3.08857908491267\n",
      "epoch: 380 loss: 2.2408652305603027 grad: 3.0301108199378683\n",
      "epoch: 381 loss: 2.2398407459259033 grad: 2.9814826907065237\n",
      "epoch: 382 loss: 2.241795063018799 grad: 2.8753272954130633\n",
      "epoch: 383 loss: 2.2369258403778076 grad: 2.969194055645771\n",
      "epoch: 384 loss: 2.2375006675720215 grad: 3.041967711392938\n",
      "epoch: 385 loss: 2.23583722114563 grad: 2.8349592658720675\n",
      "epoch: 386 loss: 2.235152244567871 grad: 2.91635436692556\n",
      "epoch: 387 loss: 2.236057996749878 grad: 2.8808552413801882\n",
      "epoch: 388 loss: 2.2324767112731934 grad: 2.898957681989977\n",
      "epoch: 389 loss: 2.2308077812194824 grad: 2.923615829098881\n",
      "epoch: 390 loss: 2.228990077972412 grad: 3.027345610261407\n",
      "epoch: 391 loss: 2.229950428009033 grad: 2.8819633657001846\n",
      "epoch: 392 loss: 2.228039026260376 grad: 2.89010299240712\n",
      "epoch: 393 loss: 2.2274703979492188 grad: 2.8468207383476614\n",
      "epoch: 394 loss: 2.225632905960083 grad: 2.9297277139100646\n",
      "epoch: 395 loss: 2.2267353534698486 grad: 2.9081219541138066\n",
      "epoch: 396 loss: 2.2240512371063232 grad: 2.833465437748514\n",
      "epoch: 397 loss: 2.2223236560821533 grad: 2.9436467050700377\n",
      "epoch: 398 loss: 2.226044178009033 grad: 2.9677498439504277\n",
      "epoch: 399 loss: 2.2218918800354004 grad: 2.954867724174013\n",
      "epoch: 400 loss: 2.223611354827881 grad: 2.964915975852544\n",
      "epoch: 401 loss: 2.22153902053833 grad: 2.9284577694802825\n",
      "epoch: 402 loss: 2.2218525409698486 grad: 2.990342267027627\n",
      "epoch: 403 loss: 2.217434883117676 grad: 2.913639279038069\n",
      "epoch: 404 loss: 2.2170493602752686 grad: 2.9673199179131418\n",
      "epoch: 405 loss: 2.219268798828125 grad: 3.0434992900746507\n",
      "epoch: 406 loss: 2.217026948928833 grad: 2.9948716822527497\n",
      "epoch: 407 loss: 2.212587594985962 grad: 2.975890194195219\n",
      "epoch: 408 loss: 2.213810682296753 grad: 3.039026573226447\n",
      "epoch: 409 loss: 2.2155425548553467 grad: 3.1366233588381123\n",
      "epoch: 410 loss: 2.2145509719848633 grad: 3.1589549604308096\n",
      "epoch: 411 loss: 2.213022470474243 grad: 3.0989139044679526\n",
      "epoch: 412 loss: 2.2098259925842285 grad: 3.2113435622193807\n",
      "epoch: 413 loss: 2.2089176177978516 grad: 3.0210915755975756\n",
      "epoch: 414 loss: 2.2087864875793457 grad: 3.0372746620172015\n",
      "epoch: 415 loss: 2.2088825702667236 grad: 3.031573303649941\n",
      "epoch: 416 loss: 2.2061378955841064 grad: 3.0791698629849606\n",
      "epoch: 417 loss: 2.208681106567383 grad: 3.173726924260827\n",
      "epoch: 418 loss: 2.2056522369384766 grad: 3.1396577059187822\n",
      "epoch: 419 loss: 2.2079966068267822 grad: 3.1706333252867416\n",
      "epoch: 420 loss: 2.207699775695801 grad: 3.2101344341256968\n",
      "epoch: 421 loss: 2.2038631439208984 grad: 3.1352534556007456\n",
      "epoch: 422 loss: 2.2015445232391357 grad: 3.122793790884316\n",
      "epoch: 423 loss: 2.202549457550049 grad: 3.2437643029557037\n",
      "epoch: 424 loss: 2.1990623474121094 grad: 3.102155073993056\n",
      "epoch: 425 loss: 2.2009692192077637 grad: 3.169632137747526\n",
      "epoch: 426 loss: 2.2040343284606934 grad: 3.152943756623519\n",
      "epoch: 427 loss: 2.2000746726989746 grad: 3.2028174300434156\n",
      "epoch: 428 loss: 2.1994781494140625 grad: 3.2241583348414493\n",
      "epoch: 429 loss: 2.200347661972046 grad: 3.2461454239045637\n",
      "epoch: 430 loss: 2.199885845184326 grad: 3.255603729850716\n",
      "epoch: 431 loss: 2.196469306945801 grad: 3.273756286942415\n",
      "epoch: 432 loss: 2.195359945297241 grad: 3.1308891338311016\n",
      "epoch: 433 loss: 2.194870948791504 grad: 3.260892794644904\n",
      "epoch: 434 loss: 2.194796085357666 grad: 3.2022768032020106\n",
      "epoch: 435 loss: 2.1941819190979004 grad: 3.3055341228443598\n",
      "epoch: 436 loss: 2.1932473182678223 grad: 3.1588845824201903\n",
      "epoch: 437 loss: 2.194247007369995 grad: 3.3035670811964555\n",
      "epoch: 438 loss: 2.191096305847168 grad: 3.2650920238109333\n",
      "epoch: 439 loss: 2.189678430557251 grad: 3.190085731723922\n",
      "epoch: 440 loss: 2.192481756210327 grad: 3.3368780525356887\n",
      "epoch: 441 loss: 2.188673496246338 grad: 3.1289929718588523\n",
      "epoch: 442 loss: 2.1897737979888916 grad: 3.2942561720024854\n",
      "epoch: 443 loss: 2.1885249614715576 grad: 3.1894536369687154\n",
      "epoch: 444 loss: 2.190979242324829 grad: 3.346028015856439\n",
      "epoch: 445 loss: 2.1877691745758057 grad: 3.244831897455105\n",
      "epoch: 446 loss: 2.1880807876586914 grad: 3.2579697335641535\n",
      "epoch: 447 loss: 2.1862423419952393 grad: 3.1344639791123985\n",
      "epoch: 448 loss: 2.184495210647583 grad: 3.0902305321087913\n",
      "epoch: 449 loss: 2.1873867511749268 grad: 3.364790904934385\n",
      "epoch: 450 loss: 2.1856606006622314 grad: 3.1023208456121325\n",
      "epoch: 451 loss: 2.187091827392578 grad: 3.3519525276386135\n",
      "epoch: 452 loss: 2.184772491455078 grad: 3.3012614685761195\n",
      "epoch: 453 loss: 2.184234142303467 grad: 3.179171857671694\n",
      "epoch: 454 loss: 2.1818857192993164 grad: 3.1823099232500507\n",
      "epoch: 455 loss: 2.1842992305755615 grad: 3.2659737175434\n",
      "epoch: 456 loss: 2.180363655090332 grad: 3.16253418664241\n",
      "epoch: 457 loss: 2.1804213523864746 grad: 3.1140747367652013\n",
      "epoch: 458 loss: 2.1838107109069824 grad: 3.4128524547328225\n",
      "epoch: 459 loss: 2.1804587841033936 grad: 3.273264321123457\n",
      "epoch: 460 loss: 2.182317018508911 grad: 3.143361593079236\n",
      "epoch: 461 loss: 2.1779887676239014 grad: 3.137582592980286\n",
      "epoch: 462 loss: 2.180004835128784 grad: 3.241822549175205\n",
      "epoch: 463 loss: 2.1777613162994385 grad: 3.1335468692852864\n",
      "epoch: 464 loss: 2.176827907562256 grad: 3.2810951999780382\n",
      "epoch: 465 loss: 2.1764092445373535 grad: 3.04352098115949\n",
      "epoch: 466 loss: 2.179981231689453 grad: 3.2377228960801387\n",
      "epoch: 467 loss: 2.1769917011260986 grad: 3.178324200486439\n",
      "epoch: 468 loss: 2.1739673614501953 grad: 3.0596848964535943\n",
      "epoch: 469 loss: 2.1751065254211426 grad: 3.1574316068870267\n",
      "epoch: 470 loss: 2.174906015396118 grad: 3.1499924059728133\n",
      "epoch: 471 loss: 2.1744377613067627 grad: 3.0755400045715744\n",
      "epoch: 472 loss: 2.172818422317505 grad: 3.1948866967632923\n",
      "epoch: 473 loss: 2.1727852821350098 grad: 3.1082804205879153\n",
      "epoch: 474 loss: 2.1728527545928955 grad: 3.0497444898318795\n",
      "epoch: 475 loss: 2.1764323711395264 grad: 3.2309021718489626\n",
      "epoch: 476 loss: 2.172205924987793 grad: 3.1874345847172663\n",
      "epoch: 477 loss: 2.172773599624634 grad: 3.09645266819834\n",
      "epoch: 478 loss: 2.1717288494110107 grad: 3.2422846937127088\n",
      "epoch: 479 loss: 2.170163631439209 grad: 3.309321831446141\n",
      "epoch: 480 loss: 2.17101788520813 grad: 3.147652247296055\n",
      "epoch: 481 loss: 2.169610023498535 grad: 3.154640678031784\n",
      "epoch: 482 loss: 2.168452024459839 grad: 3.1512521670998206\n",
      "epoch: 483 loss: 2.1676323413848877 grad: 3.141145920876177\n",
      "epoch: 484 loss: 2.168219566345215 grad: 3.08040380556809\n",
      "epoch: 485 loss: 2.1706066131591797 grad: 3.166329666074099\n",
      "epoch: 486 loss: 2.1691012382507324 grad: 3.2667616883159747\n",
      "epoch: 487 loss: 2.1693480014801025 grad: 2.937110774183927\n",
      "epoch: 488 loss: 2.166379451751709 grad: 3.159247460935841\n",
      "epoch: 489 loss: 2.1670939922332764 grad: 3.1117145075270582\n",
      "epoch: 490 loss: 2.163743495941162 grad: 2.9734590235794527\n",
      "epoch: 491 loss: 2.164433002471924 grad: 3.184705341412198\n",
      "epoch: 492 loss: 2.1668248176574707 grad: 3.160355122678632\n",
      "epoch: 493 loss: 2.16587495803833 grad: 3.0465219657542923\n",
      "epoch: 494 loss: 2.163182258605957 grad: 3.0467992836206648\n",
      "epoch: 495 loss: 2.1635582447052 grad: 3.041632637137636\n",
      "epoch: 496 loss: 2.163322925567627 grad: 3.227133444702578\n",
      "epoch: 497 loss: 2.1625468730926514 grad: 3.163269681992778\n",
      "epoch: 498 loss: 2.161391258239746 grad: 3.0296582532750946\n",
      "epoch: 499 loss: 2.1614913940429688 grad: 2.903797154194705\n",
      "2.2417069524526596\n",
      "epoch: 0 loss: 2.302366256713867 grad: 1.3314618673729932\n",
      "epoch: 1 loss: 2.3004627227783203 grad: 1.3366498764426935\n",
      "epoch: 2 loss: 2.294761896133423 grad: 1.48937185463636\n",
      "epoch: 3 loss: 2.2781925201416016 grad: 1.9575094250141687\n",
      "epoch: 4 loss: 2.246030807495117 grad: 2.409864349176161\n",
      "epoch: 5 loss: 2.2184884548187256 grad: 2.987412321872802\n",
      "epoch: 6 loss: 2.1786389350891113 grad: 3.264093439087331\n",
      "epoch: 7 loss: 2.1480612754821777 grad: 3.173892927640635\n",
      "epoch: 8 loss: 2.135878562927246 grad: 2.983951627969786\n",
      "epoch: 9 loss: 2.1259520053863525 grad: 2.9684813915241866\n",
      "epoch: 10 loss: 2.1170332431793213 grad: 2.9505573141588166\n",
      "epoch: 11 loss: 2.113168954849243 grad: 2.900528087947769\n",
      "epoch: 12 loss: 2.10981822013855 grad: 2.9726553973538565\n",
      "epoch: 13 loss: 2.103372812271118 grad: 2.9238877480864405\n",
      "epoch: 14 loss: 2.1003479957580566 grad: 3.219728303995604\n",
      "epoch: 15 loss: 2.0950841903686523 grad: 3.2437326702814078\n",
      "epoch: 16 loss: 2.0897862911224365 grad: 3.2967075808454185\n",
      "epoch: 17 loss: 2.0846455097198486 grad: 3.7263106017351326\n",
      "epoch: 18 loss: 2.08178973197937 grad: 3.5656089247278278\n",
      "epoch: 19 loss: 2.072479486465454 grad: 3.818734043588241\n",
      "epoch: 20 loss: 2.0700623989105225 grad: 3.788742956964092\n",
      "epoch: 21 loss: 2.067744493484497 grad: 4.13255499387973\n",
      "epoch: 22 loss: 2.062880754470825 grad: 4.230647012894411\n",
      "epoch: 23 loss: 2.058643102645874 grad: 4.781669027700517\n",
      "epoch: 24 loss: 2.054797887802124 grad: 4.925009793372795\n",
      "epoch: 25 loss: 2.051102876663208 grad: 5.228675414556785\n",
      "epoch: 26 loss: 2.0378992557525635 grad: 5.4592199259703715\n",
      "epoch: 27 loss: 2.0317647457122803 grad: 5.699326748353621\n",
      "epoch: 28 loss: 2.022451162338257 grad: 6.15088731824376\n",
      "epoch: 29 loss: 2.013322591781616 grad: 6.626876532935375\n",
      "epoch: 30 loss: 2.006749391555786 grad: 7.004853668363972\n",
      "epoch: 31 loss: 1.9987198114395142 grad: 6.303931362845654\n",
      "epoch: 32 loss: 1.992588996887207 grad: 6.884457992921982\n",
      "epoch: 33 loss: 1.9893410205841064 grad: 7.276145984854786\n",
      "epoch: 34 loss: 1.9762139320373535 grad: 7.154346892573235\n",
      "epoch: 35 loss: 1.9650473594665527 grad: 6.841338021170703\n",
      "epoch: 36 loss: 1.9618390798568726 grad: 7.634529877454042\n",
      "epoch: 37 loss: 1.956068754196167 grad: 7.386579504864852\n",
      "epoch: 38 loss: 1.9488956928253174 grad: 7.623393199155255\n",
      "epoch: 39 loss: 1.9450644254684448 grad: 7.5919880419895645\n",
      "epoch: 40 loss: 1.9353152513504028 grad: 7.498706912340981\n",
      "epoch: 41 loss: 1.926857829093933 grad: 7.963981143442825\n",
      "epoch: 42 loss: 1.9301891326904297 grad: 8.227097863819273\n",
      "epoch: 43 loss: 1.9239060878753662 grad: 7.845674841029067\n",
      "epoch: 44 loss: 1.9122223854064941 grad: 8.045293246809807\n",
      "epoch: 45 loss: 1.9138802289962769 grad: 8.413320378562997\n",
      "epoch: 46 loss: 1.901241660118103 grad: 8.158951407283663\n",
      "epoch: 47 loss: 1.898527979850769 grad: 8.976291635044156\n",
      "epoch: 48 loss: 1.8888696432113647 grad: 8.441582894581\n",
      "epoch: 49 loss: 1.8842308521270752 grad: 9.275277784715096\n",
      "epoch: 50 loss: 1.8799453973770142 grad: 9.364067846997862\n",
      "epoch: 51 loss: 1.8779382705688477 grad: 9.3872195092429\n",
      "epoch: 52 loss: 1.8588032722473145 grad: 9.44496163904726\n",
      "epoch: 53 loss: 1.8603202104568481 grad: 10.171549187381826\n",
      "epoch: 54 loss: 1.8584812879562378 grad: 9.563495696670124\n",
      "epoch: 55 loss: 1.844576358795166 grad: 10.353189889977257\n",
      "epoch: 56 loss: 1.8423011302947998 grad: 10.52383994339921\n",
      "epoch: 57 loss: 1.8387107849121094 grad: 10.19773826887092\n",
      "epoch: 58 loss: 1.8368606567382812 grad: 10.393521419519352\n",
      "epoch: 59 loss: 1.8224902153015137 grad: 10.263708797815655\n",
      "epoch: 60 loss: 1.8172520399093628 grad: 10.479774843339646\n",
      "epoch: 61 loss: 1.8230963945388794 grad: 10.472850183616318\n",
      "epoch: 62 loss: 1.8050190210342407 grad: 10.555754805323742\n",
      "epoch: 63 loss: 1.8124403953552246 grad: 10.891263751919189\n",
      "epoch: 64 loss: 1.793290138244629 grad: 10.743589996301111\n",
      "epoch: 65 loss: 1.8018590211868286 grad: 11.044428083853472\n",
      "epoch: 66 loss: 1.791986346244812 grad: 10.981809651893046\n",
      "epoch: 67 loss: 1.7862175703048706 grad: 11.29259678181852\n",
      "epoch: 68 loss: 1.7832895517349243 grad: 11.476751277755413\n",
      "epoch: 69 loss: 1.7778329849243164 grad: 11.482282362227876\n",
      "epoch: 70 loss: 1.7730786800384521 grad: 10.952468866438029\n",
      "epoch: 71 loss: 1.7792649269104004 grad: 12.068962358825264\n",
      "epoch: 72 loss: 1.7719701528549194 grad: 11.558704633132688\n",
      "epoch: 73 loss: 1.7676366567611694 grad: 11.20755313651725\n",
      "epoch: 74 loss: 1.7618714570999146 grad: 11.562454444784967\n",
      "epoch: 75 loss: 1.7658066749572754 grad: 11.572484542113093\n",
      "epoch: 76 loss: 1.7572441101074219 grad: 11.708047465110818\n",
      "epoch: 77 loss: 1.7640188932418823 grad: 11.400367723482232\n",
      "epoch: 78 loss: 1.7437793016433716 grad: 11.40859246171183\n",
      "epoch: 79 loss: 1.7542431354522705 grad: 11.64222949249522\n",
      "epoch: 80 loss: 1.74699866771698 grad: 10.94617584338116\n",
      "epoch: 81 loss: 1.7447808980941772 grad: 11.163048158207584\n",
      "epoch: 82 loss: 1.7398812770843506 grad: 10.823809648050911\n",
      "epoch: 83 loss: 1.7447600364685059 grad: 11.557970114392303\n",
      "epoch: 84 loss: 1.7387235164642334 grad: 11.36392467687764\n",
      "epoch: 85 loss: 1.7359504699707031 grad: 11.22001788856846\n",
      "epoch: 86 loss: 1.7314602136611938 grad: 11.08383460005834\n",
      "epoch: 87 loss: 1.7285499572753906 grad: 10.998020433465994\n",
      "epoch: 88 loss: 1.7261922359466553 grad: 11.326379203237593\n",
      "epoch: 89 loss: 1.728035569190979 grad: 11.256844726428094\n",
      "epoch: 90 loss: 1.727845311164856 grad: 11.888839336267361\n",
      "epoch: 91 loss: 1.7251031398773193 grad: 11.424256471118756\n",
      "epoch: 92 loss: 1.7201261520385742 grad: 11.332372331282212\n",
      "epoch: 93 loss: 1.7219024896621704 grad: 11.2975095794684\n",
      "epoch: 94 loss: 1.7236971855163574 grad: 12.013453441568547\n",
      "epoch: 95 loss: 1.722249150276184 grad: 10.984057555625599\n",
      "epoch: 96 loss: 1.7140026092529297 grad: 11.443121163780608\n",
      "epoch: 97 loss: 1.7032033205032349 grad: 11.41117053512957\n",
      "epoch: 98 loss: 1.7064094543457031 grad: 11.840312474717697\n",
      "epoch: 99 loss: 1.7142294645309448 grad: 11.866094569136049\n",
      "epoch: 100 loss: 1.7090697288513184 grad: 11.86809785844433\n",
      "epoch: 101 loss: 1.7126290798187256 grad: 11.476173926810068\n",
      "epoch: 102 loss: 1.7032066583633423 grad: 11.671121876901163\n",
      "epoch: 103 loss: 1.7048907279968262 grad: 11.569166953143265\n",
      "epoch: 104 loss: 1.701592206954956 grad: 11.888917963131375\n",
      "epoch: 105 loss: 1.7000761032104492 grad: 10.943440021991375\n",
      "epoch: 106 loss: 1.7028969526290894 grad: 11.6002005496698\n",
      "epoch: 107 loss: 1.6964716911315918 grad: 11.332730654479256\n",
      "epoch: 108 loss: 1.692800760269165 grad: 11.331355547037212\n",
      "epoch: 109 loss: 1.6950048208236694 grad: 11.363451154695618\n",
      "epoch: 110 loss: 1.6945866346359253 grad: 11.757724038813086\n",
      "epoch: 111 loss: 1.6922610998153687 grad: 11.275751303194003\n",
      "epoch: 112 loss: 1.7008856534957886 grad: 12.271837424767751\n",
      "epoch: 113 loss: 1.6969259977340698 grad: 11.208499758859121\n",
      "epoch: 114 loss: 1.691924810409546 grad: 11.429368255940814\n",
      "epoch: 115 loss: 1.6852048635482788 grad: 11.19325970351282\n",
      "epoch: 116 loss: 1.6942042112350464 grad: 11.087284930131679\n",
      "epoch: 117 loss: 1.6965798139572144 grad: 12.015826999268953\n",
      "epoch: 118 loss: 1.6864715814590454 grad: 11.679741707475236\n",
      "epoch: 119 loss: 1.692955493927002 grad: 11.058395714632102\n",
      "epoch: 120 loss: 1.6830679178237915 grad: 11.150113843588365\n",
      "epoch: 121 loss: 1.6883119344711304 grad: 11.456390389111927\n",
      "epoch: 122 loss: 1.6898298263549805 grad: 12.358635865151882\n",
      "epoch: 123 loss: 1.6866596937179565 grad: 10.792072380833801\n",
      "epoch: 124 loss: 1.6812382936477661 grad: 11.049896115969334\n",
      "epoch: 125 loss: 1.6811459064483643 grad: 11.112641991374808\n",
      "epoch: 126 loss: 1.6884311437606812 grad: 11.124582585642143\n",
      "epoch: 127 loss: 1.686397910118103 grad: 11.718790161992526\n",
      "epoch: 128 loss: 1.6831799745559692 grad: 10.926136987121215\n",
      "epoch: 129 loss: 1.6828893423080444 grad: 11.846886186106573\n",
      "epoch: 130 loss: 1.6814007759094238 grad: 12.061500187859767\n",
      "epoch: 131 loss: 1.678253412246704 grad: 11.485906454727113\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 132 loss: 1.6683872938156128 grad: 11.207667439229905\n",
      "epoch: 133 loss: 1.6817480325698853 grad: 11.837802822095535\n",
      "epoch: 134 loss: 1.6732252836227417 grad: 10.363514271875223\n",
      "epoch: 135 loss: 1.681817889213562 grad: 11.710762376172674\n",
      "epoch: 136 loss: 1.6746857166290283 grad: 11.669900666013183\n",
      "epoch: 137 loss: 1.672948956489563 grad: 11.608433217416325\n",
      "epoch: 138 loss: 1.6767101287841797 grad: 11.761718867974917\n",
      "epoch: 139 loss: 1.669561743736267 grad: 10.902147856511412\n",
      "epoch: 140 loss: 1.6661088466644287 grad: 10.705006586609496\n",
      "epoch: 141 loss: 1.6707255840301514 grad: 12.461996726122582\n",
      "epoch: 142 loss: 1.6655502319335938 grad: 11.03874643102643\n",
      "epoch: 143 loss: 1.671895146369934 grad: 10.932943417686998\n",
      "epoch: 144 loss: 1.6600170135498047 grad: 11.154792878392433\n",
      "epoch: 145 loss: 1.670245885848999 grad: 12.023290196086265\n",
      "epoch: 146 loss: 1.6632194519042969 grad: 11.305983431119886\n",
      "epoch: 147 loss: 1.6664484739303589 grad: 11.095670279714145\n",
      "epoch: 148 loss: 1.6662709712982178 grad: 11.47976238225838\n",
      "epoch: 149 loss: 1.664963722229004 grad: 11.138172528056044\n",
      "epoch: 150 loss: 1.669334053993225 grad: 11.82539665228909\n",
      "epoch: 151 loss: 1.6652973890304565 grad: 11.200596497645455\n",
      "epoch: 152 loss: 1.6674177646636963 grad: 12.119224645566964\n",
      "epoch: 153 loss: 1.6583764553070068 grad: 10.61152519837081\n",
      "epoch: 154 loss: 1.6557493209838867 grad: 11.151711483722524\n",
      "epoch: 155 loss: 1.6520487070083618 grad: 11.37836843115529\n",
      "epoch: 156 loss: 1.663671851158142 grad: 12.27822233358812\n",
      "epoch: 157 loss: 1.6642996072769165 grad: 11.331963045862578\n",
      "epoch: 158 loss: 1.6559265851974487 grad: 11.2885396516261\n",
      "epoch: 159 loss: 1.6498130559921265 grad: 12.044634946991527\n",
      "epoch: 160 loss: 1.6508002281188965 grad: 11.461851706558337\n",
      "epoch: 161 loss: 1.6485106945037842 grad: 11.504733603070711\n",
      "epoch: 162 loss: 1.6533652544021606 grad: 11.327687316053058\n",
      "epoch: 163 loss: 1.652270793914795 grad: 12.310310578055029\n",
      "epoch: 164 loss: 1.6518807411193848 grad: 11.720352550717218\n",
      "epoch: 165 loss: 1.649071455001831 grad: 11.169547601056005\n",
      "epoch: 166 loss: 1.648911476135254 grad: 10.913353853482043\n",
      "epoch: 167 loss: 1.644037127494812 grad: 11.946043943868034\n",
      "epoch: 168 loss: 1.6351732015609741 grad: 11.71241993870261\n",
      "epoch: 169 loss: 1.6545203924179077 grad: 11.727679302945496\n",
      "epoch: 170 loss: 1.6481428146362305 grad: 12.426371121646039\n",
      "epoch: 171 loss: 1.641438364982605 grad: 12.172953341688428\n",
      "epoch: 172 loss: 1.6491371393203735 grad: 11.705665790180246\n",
      "epoch: 173 loss: 1.639809012413025 grad: 11.40331202267211\n",
      "epoch: 174 loss: 1.6434513330459595 grad: 12.177647591457658\n",
      "epoch: 175 loss: 1.641876459121704 grad: 11.784564040564296\n",
      "epoch: 176 loss: 1.6363879442214966 grad: 11.957698058654806\n",
      "epoch: 177 loss: 1.6476305723190308 grad: 12.203672386136734\n",
      "epoch: 178 loss: 1.6460392475128174 grad: 12.44115715783592\n",
      "epoch: 179 loss: 1.634687900543213 grad: 11.685907144018168\n",
      "epoch: 180 loss: 1.634350061416626 grad: 12.07837159892485\n",
      "epoch: 181 loss: 1.6372846364974976 grad: 11.7563626531822\n",
      "epoch: 182 loss: 1.6330070495605469 grad: 12.072194676964529\n",
      "epoch: 183 loss: 1.6366500854492188 grad: 12.099392283279153\n",
      "epoch: 184 loss: 1.6339036226272583 grad: 11.66132071969055\n",
      "epoch: 185 loss: 1.6327097415924072 grad: 11.889072439263737\n",
      "epoch: 186 loss: 1.6319125890731812 grad: 12.433302460120075\n",
      "epoch: 187 loss: 1.6346224546432495 grad: 12.957393033030842\n",
      "epoch: 188 loss: 1.6402873992919922 grad: 12.342885535032977\n",
      "epoch: 189 loss: 1.6393804550170898 grad: 11.867148115003983\n",
      "epoch: 190 loss: 1.6317003965377808 grad: 11.887468097051459\n",
      "epoch: 191 loss: 1.62613046169281 grad: 12.53273658835817\n",
      "epoch: 192 loss: 1.6327614784240723 grad: 11.847901028226174\n",
      "epoch: 193 loss: 1.6164391040802002 grad: 11.841957375732443\n",
      "epoch: 194 loss: 1.6279926300048828 grad: 13.076986842951367\n",
      "epoch: 195 loss: 1.6277393102645874 grad: 12.882020873963715\n",
      "epoch: 196 loss: 1.6222528219223022 grad: 11.996557844425773\n",
      "epoch: 197 loss: 1.6146817207336426 grad: 12.254475069764469\n",
      "epoch: 198 loss: 1.6216448545455933 grad: 12.247520126601946\n",
      "epoch: 199 loss: 1.6231334209442139 grad: 12.964312852818578\n",
      "epoch: 200 loss: 1.6223621368408203 grad: 12.37934346165922\n",
      "epoch: 201 loss: 1.628868579864502 grad: 12.833917250605447\n",
      "epoch: 202 loss: 1.620101809501648 grad: 12.480459550528654\n",
      "epoch: 203 loss: 1.6199910640716553 grad: 12.922679244038013\n",
      "epoch: 204 loss: 1.6143501996994019 grad: 12.128331802526695\n",
      "epoch: 205 loss: 1.62265944480896 grad: 12.019944067837464\n",
      "epoch: 206 loss: 1.6168503761291504 grad: 13.145942664941744\n",
      "epoch: 207 loss: 1.6210811138153076 grad: 12.48701210239429\n",
      "epoch: 208 loss: 1.6111788749694824 grad: 13.323244925684458\n",
      "epoch: 209 loss: 1.6241720914840698 grad: 11.926856767578375\n",
      "epoch: 210 loss: 1.6161396503448486 grad: 11.678046514597973\n",
      "epoch: 211 loss: 1.615601897239685 grad: 12.41395870905133\n",
      "epoch: 212 loss: 1.6213176250457764 grad: 12.892845448298704\n",
      "epoch: 213 loss: 1.6131318807601929 grad: 12.217100015907947\n",
      "epoch: 214 loss: 1.6088299751281738 grad: 12.14771796669811\n",
      "epoch: 215 loss: 1.6108770370483398 grad: 11.959163106068791\n",
      "epoch: 216 loss: 1.6099683046340942 grad: 13.561569414774162\n",
      "epoch: 217 loss: 1.6059765815734863 grad: 12.746519425159526\n",
      "epoch: 218 loss: 1.6175702810287476 grad: 13.00250531452161\n",
      "epoch: 219 loss: 1.6044573783874512 grad: 12.651859590820672\n",
      "epoch: 220 loss: 1.6106665134429932 grad: 12.784860714604813\n",
      "epoch: 221 loss: 1.604857325553894 grad: 11.507094394334311\n",
      "epoch: 222 loss: 1.6106375455856323 grad: 12.281513219314908\n",
      "epoch: 223 loss: 1.6081584692001343 grad: 13.000242141770228\n",
      "epoch: 224 loss: 1.6064574718475342 grad: 12.40665471036401\n",
      "epoch: 225 loss: 1.6089600324630737 grad: 12.212295647185769\n",
      "epoch: 226 loss: 1.6000593900680542 grad: 12.978857657369522\n",
      "epoch: 227 loss: 1.6067614555358887 grad: 12.465325683917081\n",
      "epoch: 228 loss: 1.5982954502105713 grad: 11.661528222491993\n",
      "epoch: 229 loss: 1.6062015295028687 grad: 12.081570428360017\n",
      "epoch: 230 loss: 1.6017979383468628 grad: 12.391779327875978\n",
      "epoch: 231 loss: 1.602688193321228 grad: 12.868480518726367\n",
      "epoch: 232 loss: 1.6082420349121094 grad: 12.647261096135018\n",
      "epoch: 233 loss: 1.5978550910949707 grad: 12.594139086444759\n",
      "epoch: 234 loss: 1.6052296161651611 grad: 12.969727621820297\n",
      "epoch: 235 loss: 1.601918339729309 grad: 13.019578172455704\n",
      "epoch: 236 loss: 1.59440279006958 grad: 12.719483107941905\n",
      "epoch: 237 loss: 1.5961947441101074 grad: 12.483118243855499\n",
      "epoch: 238 loss: 1.6009666919708252 grad: 13.009746128693223\n",
      "epoch: 239 loss: 1.6045031547546387 grad: 13.317743547748597\n",
      "epoch: 240 loss: 1.5902892351150513 grad: 13.005944834674693\n",
      "epoch: 241 loss: 1.5853497982025146 grad: 11.998326794846752\n",
      "epoch: 242 loss: 1.5938918590545654 grad: 12.526125517888142\n",
      "epoch: 243 loss: 1.5971306562423706 grad: 13.14388983496391\n",
      "epoch: 244 loss: 1.5962389707565308 grad: 12.898351568514334\n",
      "epoch: 245 loss: 1.5924437046051025 grad: 12.687608351250963\n",
      "epoch: 246 loss: 1.5985380411148071 grad: 13.491222929697306\n",
      "epoch: 247 loss: 1.5921293497085571 grad: 12.50225375844757\n",
      "epoch: 248 loss: 1.5984944105148315 grad: 12.75868419400372\n",
      "epoch: 249 loss: 1.5970919132232666 grad: 12.550963947091192\n",
      "epoch: 250 loss: 1.5928114652633667 grad: 12.668114660012106\n",
      "epoch: 251 loss: 1.5865706205368042 grad: 12.755075903195474\n",
      "epoch: 252 loss: 1.5865867137908936 grad: 12.579189723453647\n",
      "epoch: 253 loss: 1.596848487854004 grad: 12.26376742326344\n",
      "epoch: 254 loss: 1.589361310005188 grad: 12.354959015490575\n",
      "epoch: 255 loss: 1.58861243724823 grad: 11.724598023301315\n",
      "epoch: 256 loss: 1.5944421291351318 grad: 13.330464502190432\n",
      "epoch: 257 loss: 1.5927226543426514 grad: 12.126940352901343\n",
      "epoch: 258 loss: 1.591772437095642 grad: 12.525905527181864\n",
      "epoch: 259 loss: 1.5880236625671387 grad: 12.055230130692797\n",
      "epoch: 260 loss: 1.5914841890335083 grad: 11.670857811073166\n",
      "epoch: 261 loss: 1.592603325843811 grad: 12.58904474501365\n",
      "epoch: 262 loss: 1.5932608842849731 grad: 12.70935568615188\n",
      "epoch: 263 loss: 1.5878725051879883 grad: 12.65907414072001\n",
      "epoch: 264 loss: 1.5825690031051636 grad: 13.080761234837746\n",
      "epoch: 265 loss: 1.5842751264572144 grad: 12.774476009605836\n",
      "epoch: 266 loss: 1.5908465385437012 grad: 12.321406263251982\n",
      "epoch: 267 loss: 1.5867737531661987 grad: 12.863044977483769\n",
      "epoch: 268 loss: 1.5834765434265137 grad: 11.857220437835961\n",
      "epoch: 269 loss: 1.5814385414123535 grad: 12.01290419821938\n",
      "epoch: 270 loss: 1.5804855823516846 grad: 12.576918688713617\n",
      "epoch: 271 loss: 1.5855337381362915 grad: 12.161558589580217\n",
      "epoch: 272 loss: 1.5763803720474243 grad: 12.232153120857205\n",
      "epoch: 273 loss: 1.5862667560577393 grad: 12.787839373374092\n",
      "epoch: 274 loss: 1.5784695148468018 grad: 12.324065731801388\n",
      "epoch: 275 loss: 1.579417109489441 grad: 11.380364301762292\n",
      "epoch: 276 loss: 1.5776360034942627 grad: 12.135395400965262\n",
      "epoch: 277 loss: 1.5767450332641602 grad: 11.385452517020028\n",
      "epoch: 278 loss: 1.585559606552124 grad: 12.582424737860464\n",
      "epoch: 279 loss: 1.5795246362686157 grad: 12.107669965903614\n",
      "epoch: 280 loss: 1.5754656791687012 grad: 12.247513168454466\n",
      "epoch: 281 loss: 1.586287021636963 grad: 12.520355635100888\n",
      "epoch: 282 loss: 1.5755435228347778 grad: 12.734259451554705\n",
      "epoch: 283 loss: 1.5777889490127563 grad: 11.686059266062719\n",
      "epoch: 284 loss: 1.5745640993118286 grad: 11.563511030083257\n",
      "epoch: 285 loss: 1.5796430110931396 grad: 12.945105784916363\n",
      "epoch: 286 loss: 1.572588324546814 grad: 11.844162132790578\n",
      "epoch: 287 loss: 1.5744667053222656 grad: 11.989569705397274\n",
      "epoch: 288 loss: 1.5813466310501099 grad: 11.770574913811057\n",
      "epoch: 289 loss: 1.5732618570327759 grad: 12.22223038573764\n",
      "epoch: 290 loss: 1.5794304609298706 grad: 13.280801098379824\n",
      "epoch: 291 loss: 1.5751502513885498 grad: 11.614368271903091\n",
      "epoch: 292 loss: 1.5820153951644897 grad: 12.395269207146374\n",
      "epoch: 293 loss: 1.5721542835235596 grad: 11.927265095177091\n",
      "epoch: 294 loss: 1.573928952217102 grad: 12.264524354507023\n",
      "epoch: 295 loss: 1.575378179550171 grad: 11.5643097313254\n",
      "epoch: 296 loss: 1.5742533206939697 grad: 11.490318202058829\n",
      "epoch: 297 loss: 1.5749636888504028 grad: 12.194250447549932\n",
      "epoch: 298 loss: 1.5707367658615112 grad: 12.387495276163376\n",
      "epoch: 299 loss: 1.5740342140197754 grad: 12.761313367642403\n",
      "epoch: 300 loss: 1.5740394592285156 grad: 12.891563021234193\n",
      "epoch: 301 loss: 1.5711135864257812 grad: 11.976173221144737\n",
      "epoch: 302 loss: 1.5765166282653809 grad: 12.825859571104898\n",
      "epoch: 303 loss: 1.5724624395370483 grad: 12.167396688530783\n",
      "epoch: 304 loss: 1.578635811805725 grad: 13.362546926172126\n",
      "epoch: 305 loss: 1.5775444507598877 grad: 13.060769223438074\n",
      "epoch: 306 loss: 1.570798397064209 grad: 12.452975757057882\n",
      "epoch: 307 loss: 1.577834129333496 grad: 12.064336618889005\n",
      "epoch: 308 loss: 1.5755219459533691 grad: 12.200661552419502\n",
      "epoch: 309 loss: 1.565911889076233 grad: 12.537358032221654\n",
      "epoch: 310 loss: 1.5724143981933594 grad: 11.977895184257438\n",
      "epoch: 311 loss: 1.5712945461273193 grad: 12.525946611279828\n",
      "epoch: 312 loss: 1.5695778131484985 grad: 12.519238212848053\n",
      "epoch: 313 loss: 1.5722864866256714 grad: 12.335829161070583\n",
      "epoch: 314 loss: 1.570087194442749 grad: 12.068722295027877\n",
      "epoch: 315 loss: 1.5709927082061768 grad: 11.923704860561957\n",
      "epoch: 316 loss: 1.5648332834243774 grad: 11.049071573349277\n",
      "epoch: 317 loss: 1.575927734375 grad: 13.34111909095257\n",
      "epoch: 318 loss: 1.559409737586975 grad: 11.462894447406548\n",
      "epoch: 319 loss: 1.5714795589447021 grad: 13.062098682924573\n",
      "epoch: 320 loss: 1.5633050203323364 grad: 11.74335805722882\n",
      "epoch: 321 loss: 1.5667939186096191 grad: 11.526866376518257\n",
      "epoch: 322 loss: 1.5642396211624146 grad: 12.022297986908741\n",
      "epoch: 323 loss: 1.569663166999817 grad: 12.29324564559474\n",
      "epoch: 324 loss: 1.5674737691879272 grad: 12.837205983469234\n",
      "epoch: 325 loss: 1.570324420928955 grad: 12.246472081576016\n",
      "epoch: 326 loss: 1.564112663269043 grad: 12.359898557531691\n",
      "epoch: 327 loss: 1.56436288356781 grad: 12.00865496783\n",
      "epoch: 328 loss: 1.56842839717865 grad: 12.995318951469566\n",
      "epoch: 329 loss: 1.566796898841858 grad: 11.626739911528098\n",
      "epoch: 330 loss: 1.5625255107879639 grad: 12.266254751898703\n",
      "epoch: 331 loss: 1.5667532682418823 grad: 12.131129559827968\n",
      "epoch: 332 loss: 1.5654691457748413 grad: 12.180910764129035\n",
      "epoch: 333 loss: 1.5635178089141846 grad: 12.725101496396025\n",
      "epoch: 334 loss: 1.5644782781600952 grad: 12.265395678587199\n",
      "epoch: 335 loss: 1.5580673217773438 grad: 11.994277459513839\n",
      "epoch: 336 loss: 1.5626736879348755 grad: 11.178960712781796\n",
      "epoch: 337 loss: 1.5599474906921387 grad: 12.598987875787158\n",
      "epoch: 338 loss: 1.563547134399414 grad: 12.530135682052267\n",
      "epoch: 339 loss: 1.5599476099014282 grad: 12.323925968133919\n",
      "epoch: 340 loss: 1.5620942115783691 grad: 11.055765304337477\n",
      "epoch: 341 loss: 1.5651445388793945 grad: 11.833058536067487\n",
      "epoch: 342 loss: 1.5646902322769165 grad: 12.758505831775626\n",
      "epoch: 343 loss: 1.5610333681106567 grad: 12.077848051903798\n",
      "epoch: 344 loss: 1.555260419845581 grad: 11.21327878844126\n",
      "epoch: 345 loss: 1.5622568130493164 grad: 11.8737237873295\n",
      "epoch: 346 loss: 1.562809944152832 grad: 11.633093395662154\n",
      "epoch: 347 loss: 1.5619947910308838 grad: 13.000963146510045\n",
      "epoch: 348 loss: 1.5633260011672974 grad: 12.408062491018976\n",
      "epoch: 349 loss: 1.5607353448867798 grad: 12.44803052664631\n",
      "epoch: 350 loss: 1.5666438341140747 grad: 11.46734963426189\n",
      "epoch: 351 loss: 1.5605977773666382 grad: 12.383499664498405\n",
      "epoch: 352 loss: 1.5633761882781982 grad: 11.990028435645241\n",
      "epoch: 353 loss: 1.5679516792297363 grad: 12.215660064296413\n",
      "epoch: 354 loss: 1.5639100074768066 grad: 11.82943200677382\n",
      "epoch: 355 loss: 1.5562444925308228 grad: 11.970173344223035\n",
      "epoch: 356 loss: 1.5619381666183472 grad: 11.445245315997107\n",
      "epoch: 357 loss: 1.5546928644180298 grad: 11.886069071153917\n",
      "epoch: 358 loss: 1.5550892353057861 grad: 11.919329848495268\n",
      "epoch: 359 loss: 1.56155526638031 grad: 11.438398802989266\n",
      "epoch: 360 loss: 1.5611573457717896 grad: 11.931722241283824\n",
      "epoch: 361 loss: 1.5595358610153198 grad: 11.103683826532068\n",
      "epoch: 362 loss: 1.5569871664047241 grad: 12.554169976644012\n",
      "epoch: 363 loss: 1.5553029775619507 grad: 11.598237912458856\n",
      "epoch: 364 loss: 1.5663702487945557 grad: 12.387982100152248\n",
      "epoch: 365 loss: 1.5589255094528198 grad: 11.801219701279132\n",
      "epoch: 366 loss: 1.561031699180603 grad: 11.91323852291449\n",
      "epoch: 367 loss: 1.5547540187835693 grad: 11.944457421833206\n",
      "epoch: 368 loss: 1.560402512550354 grad: 12.726970059054327\n",
      "epoch: 369 loss: 1.5545730590820312 grad: 11.618177684136695\n",
      "epoch: 370 loss: 1.5595875978469849 grad: 12.319572463705544\n",
      "epoch: 371 loss: 1.5526610612869263 grad: 11.846699749378281\n",
      "epoch: 372 loss: 1.5622241497039795 grad: 11.346064964871085\n",
      "epoch: 373 loss: 1.5575850009918213 grad: 12.589738694843762\n",
      "epoch: 374 loss: 1.5607868432998657 grad: 12.015994404749353\n",
      "epoch: 375 loss: 1.55589759349823 grad: 11.7094183915206\n",
      "epoch: 376 loss: 1.552467703819275 grad: 11.320236361034894\n",
      "epoch: 377 loss: 1.5625640153884888 grad: 12.754386413140251\n",
      "epoch: 378 loss: 1.5533268451690674 grad: 11.405458821515952\n",
      "epoch: 379 loss: 1.5526586771011353 grad: 12.239623667949456\n",
      "epoch: 380 loss: 1.5556824207305908 grad: 12.142765663460725\n",
      "epoch: 381 loss: 1.5584537982940674 grad: 11.494506279612699\n",
      "epoch: 382 loss: 1.5600178241729736 grad: 11.113190464405639\n",
      "epoch: 383 loss: 1.5545963048934937 grad: 11.294650557007463\n",
      "epoch: 384 loss: 1.553359866142273 grad: 11.110307459131858\n",
      "epoch: 385 loss: 1.5534921884536743 grad: 10.938096477310099\n",
      "epoch: 386 loss: 1.5542292594909668 grad: 11.870470356000292\n",
      "epoch: 387 loss: 1.5542654991149902 grad: 11.676570650962521\n",
      "epoch: 388 loss: 1.5502039194107056 grad: 11.764356117917313\n",
      "epoch: 389 loss: 1.5533860921859741 grad: 11.890514659444017\n",
      "epoch: 390 loss: 1.5577596426010132 grad: 11.852465659250608\n",
      "epoch: 391 loss: 1.5511484146118164 grad: 11.8050703570498\n",
      "epoch: 392 loss: 1.55070161819458 grad: 11.726601683039455\n",
      "epoch: 393 loss: 1.5556588172912598 grad: 12.330184559500406\n",
      "epoch: 394 loss: 1.5551080703735352 grad: 12.289933933126223\n",
      "epoch: 395 loss: 1.5554534196853638 grad: 11.770777231614504\n",
      "epoch: 396 loss: 1.552121639251709 grad: 11.577611109138363\n",
      "epoch: 397 loss: 1.5494271516799927 grad: 11.142832408101105\n",
      "epoch: 398 loss: 1.5558713674545288 grad: 11.631175793184426\n",
      "epoch: 399 loss: 1.5559005737304688 grad: 11.887097671753653\n",
      "epoch: 400 loss: 1.5475250482559204 grad: 10.974790785627972\n",
      "epoch: 401 loss: 1.5447635650634766 grad: 10.57814590080035\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 402 loss: 1.5500348806381226 grad: 12.343130655472152\n",
      "epoch: 403 loss: 1.5555033683776855 grad: 12.470974453490243\n",
      "epoch: 404 loss: 1.5516986846923828 grad: 11.502057754678564\n",
      "epoch: 405 loss: 1.5477900505065918 grad: 12.234796667190652\n",
      "epoch: 406 loss: 1.5498942136764526 grad: 11.85323823750433\n",
      "epoch: 407 loss: 1.5460866689682007 grad: 10.785382113855569\n",
      "epoch: 408 loss: 1.5534342527389526 grad: 11.657043452489205\n",
      "epoch: 409 loss: 1.550368309020996 grad: 12.246219610104278\n",
      "epoch: 410 loss: 1.5498230457305908 grad: 11.130193057045016\n",
      "epoch: 411 loss: 1.5485363006591797 grad: 10.987125598677686\n",
      "epoch: 412 loss: 1.5507785081863403 grad: 11.475731454050493\n",
      "epoch: 413 loss: 1.5490727424621582 grad: 11.660106593048171\n",
      "epoch: 414 loss: 1.545487880706787 grad: 11.099891232407932\n",
      "epoch: 415 loss: 1.5467199087142944 grad: 11.477215831894206\n",
      "epoch: 416 loss: 1.5426318645477295 grad: 11.951705430771062\n",
      "epoch: 417 loss: 1.5519404411315918 grad: 12.856594745376487\n",
      "epoch: 418 loss: 1.550722599029541 grad: 11.365875146601216\n",
      "epoch: 419 loss: 1.5456724166870117 grad: 10.860046190679045\n",
      "epoch: 420 loss: 1.5496187210083008 grad: 11.589963803075195\n",
      "epoch: 421 loss: 1.5510914325714111 grad: 11.5541676245445\n",
      "epoch: 422 loss: 1.5486280918121338 grad: 11.69915138907169\n",
      "epoch: 423 loss: 1.5573194026947021 grad: 11.284923498467025\n",
      "epoch: 424 loss: 1.5484991073608398 grad: 11.652239076859717\n",
      "epoch: 425 loss: 1.5476024150848389 grad: 11.55401028647265\n",
      "epoch: 426 loss: 1.548201084136963 grad: 11.210649805694139\n",
      "epoch: 427 loss: 1.5482498407363892 grad: 10.611477421448818\n",
      "epoch: 428 loss: 1.5589860677719116 grad: 11.63445276907453\n",
      "epoch: 429 loss: 1.5387886762619019 grad: 11.132232705563572\n",
      "epoch: 430 loss: 1.5509971380233765 grad: 11.949950955135542\n",
      "epoch: 431 loss: 1.5400091409683228 grad: 10.377814959801201\n",
      "epoch: 432 loss: 1.5521042346954346 grad: 12.860452754423022\n",
      "epoch: 433 loss: 1.5445326566696167 grad: 10.859191501433665\n",
      "epoch: 434 loss: 1.5516067743301392 grad: 11.425935426738025\n",
      "epoch: 435 loss: 1.5434963703155518 grad: 11.170939229288331\n",
      "epoch: 436 loss: 1.5425046682357788 grad: 11.02203800004079\n",
      "epoch: 437 loss: 1.5447115898132324 grad: 11.163961629981973\n",
      "epoch: 438 loss: 1.545576810836792 grad: 11.828965779353258\n",
      "epoch: 439 loss: 1.549557089805603 grad: 11.459700453623627\n",
      "epoch: 440 loss: 1.5476093292236328 grad: 11.239431691344915\n",
      "epoch: 441 loss: 1.5463030338287354 grad: 11.475831508163422\n",
      "epoch: 442 loss: 1.5490070581436157 grad: 11.439615288623683\n",
      "epoch: 443 loss: 1.537493109703064 grad: 10.458168146496137\n",
      "epoch: 444 loss: 1.5399374961853027 grad: 10.647946719176298\n",
      "epoch: 445 loss: 1.5407918691635132 grad: 11.043974145404285\n",
      "epoch: 446 loss: 1.5500468015670776 grad: 12.456430110322785\n",
      "epoch: 447 loss: 1.5437331199645996 grad: 11.011036999287112\n",
      "epoch: 448 loss: 1.5419161319732666 grad: 11.426037492452277\n",
      "epoch: 449 loss: 1.544442057609558 grad: 11.772601984411715\n",
      "epoch: 450 loss: 1.5505163669586182 grad: 11.948333801882756\n",
      "epoch: 451 loss: 1.546644687652588 grad: 10.634669744963979\n",
      "epoch: 452 loss: 1.542341709136963 grad: 11.022944777780804\n",
      "epoch: 453 loss: 1.5477533340454102 grad: 11.547176118932724\n",
      "epoch: 454 loss: 1.5493355989456177 grad: 11.860306383395153\n",
      "epoch: 455 loss: 1.542483925819397 grad: 11.463148495629577\n",
      "epoch: 456 loss: 1.5479443073272705 grad: 12.104060856924791\n",
      "epoch: 457 loss: 1.5359622240066528 grad: 10.763092733468742\n",
      "epoch: 458 loss: 1.544519305229187 grad: 11.23779324292841\n",
      "epoch: 459 loss: 1.539942741394043 grad: 12.041587762667664\n",
      "epoch: 460 loss: 1.5450493097305298 grad: 12.055165317212602\n",
      "epoch: 461 loss: 1.5413776636123657 grad: 11.21871795299064\n",
      "epoch: 462 loss: 1.5348037481307983 grad: 10.425972470329956\n",
      "epoch: 463 loss: 1.541319489479065 grad: 11.433463905117518\n",
      "epoch: 464 loss: 1.5424073934555054 grad: 11.478466204790738\n",
      "epoch: 465 loss: 1.5416259765625 grad: 11.589024926180995\n",
      "epoch: 466 loss: 1.5434937477111816 grad: 11.205324083073286\n",
      "epoch: 467 loss: 1.540553331375122 grad: 11.66427387664878\n",
      "epoch: 468 loss: 1.5457937717437744 grad: 11.927788833200577\n",
      "epoch: 469 loss: 1.5420979261398315 grad: 11.146521431297833\n",
      "epoch: 470 loss: 1.5494145154953003 grad: 11.138832244231173\n",
      "epoch: 471 loss: 1.54058837890625 grad: 11.766317707346014\n",
      "epoch: 472 loss: 1.5397496223449707 grad: 11.390293897953741\n",
      "epoch: 473 loss: 1.5474075078964233 grad: 11.359537121614382\n",
      "epoch: 474 loss: 1.5466842651367188 grad: 11.593616915973909\n",
      "epoch: 475 loss: 1.548677921295166 grad: 11.91819977301306\n",
      "epoch: 476 loss: 1.5361077785491943 grad: 10.041393700724704\n",
      "epoch: 477 loss: 1.5405374765396118 grad: 10.940145496275305\n",
      "epoch: 478 loss: 1.5444327592849731 grad: 11.245110940955032\n",
      "epoch: 479 loss: 1.5407921075820923 grad: 12.040462040652832\n",
      "epoch: 480 loss: 1.5402867794036865 grad: 10.911273376099647\n",
      "epoch: 481 loss: 1.5367902517318726 grad: 12.372914823385635\n",
      "epoch: 482 loss: 1.5442471504211426 grad: 12.487518353129012\n",
      "epoch: 483 loss: 1.5315929651260376 grad: 10.737192210356985\n",
      "epoch: 484 loss: 1.5411016941070557 grad: 10.94002398967536\n",
      "epoch: 485 loss: 1.5410689115524292 grad: 11.431361698272031\n",
      "epoch: 486 loss: 1.5446490049362183 grad: 11.07185997880463\n",
      "epoch: 487 loss: 1.5427950620651245 grad: 12.129905393993896\n",
      "epoch: 488 loss: 1.5345337390899658 grad: 10.077381885969006\n",
      "epoch: 489 loss: 1.5311063528060913 grad: 10.928542542108705\n",
      "epoch: 490 loss: 1.5360937118530273 grad: 11.101576504497123\n",
      "epoch: 491 loss: 1.5337316989898682 grad: 10.658179556470483\n",
      "epoch: 492 loss: 1.5345561504364014 grad: 11.189162533689615\n",
      "epoch: 493 loss: 1.5442736148834229 grad: 13.028027001834873\n",
      "epoch: 494 loss: 1.5319870710372925 grad: 10.39779085616973\n",
      "epoch: 495 loss: 1.5364253520965576 grad: 12.584299137080384\n",
      "epoch: 496 loss: 1.5387760400772095 grad: 10.68788241527398\n",
      "epoch: 497 loss: 1.5375726222991943 grad: 11.239496782665984\n",
      "epoch: 498 loss: 1.5338280200958252 grad: 10.48298446108247\n",
      "epoch: 499 loss: 1.5372484922409058 grad: 11.002119207869299\n",
      "1.8677145466208458\n",
      "epoch: 0 loss: 2.281981945037842 grad: 1.4007567613041916\n",
      "epoch: 1 loss: 2.175569772720337 grad: 2.592995114521944\n",
      "epoch: 2 loss: 2.0534827709198 grad: 3.2291400054172197\n",
      "epoch: 3 loss: 1.9832876920700073 grad: 4.735768592848058\n",
      "epoch: 4 loss: 1.9301095008850098 grad: 5.770058979056702\n",
      "epoch: 5 loss: 1.8465980291366577 grad: 6.487435469806697\n",
      "epoch: 6 loss: 1.8191556930541992 grad: 6.959260165047396\n",
      "epoch: 7 loss: 1.7535866498947144 grad: 6.493216679351116\n",
      "epoch: 8 loss: 1.7208055257797241 grad: 7.0193363514457205\n",
      "epoch: 9 loss: 1.6978248357772827 grad: 7.121987473354527\n",
      "epoch: 10 loss: 1.6769131422042847 grad: 7.111690105660633\n",
      "epoch: 11 loss: 1.691064476966858 grad: 6.9651282183042476\n",
      "epoch: 12 loss: 1.6509183645248413 grad: 6.552075512737723\n",
      "epoch: 13 loss: 1.6383901834487915 grad: 6.554997316132935\n",
      "epoch: 14 loss: 1.6542792320251465 grad: 6.499830933464095\n",
      "epoch: 15 loss: 1.6291823387145996 grad: 6.617477036826867\n",
      "epoch: 16 loss: 1.6261053085327148 grad: 6.437003085507997\n",
      "epoch: 17 loss: 1.6262154579162598 grad: 6.877474119199351\n",
      "epoch: 18 loss: 1.6044822931289673 grad: 5.408764819996866\n",
      "epoch: 19 loss: 1.6150643825531006 grad: 5.935153508362996\n",
      "epoch: 20 loss: 1.589348316192627 grad: 5.469687020037045\n",
      "epoch: 21 loss: 1.6164791584014893 grad: 6.222271821101747\n",
      "epoch: 22 loss: 1.604961633682251 grad: 6.229400257395658\n",
      "epoch: 23 loss: 1.6159065961837769 grad: 6.186183572043471\n",
      "epoch: 24 loss: 1.6031289100646973 grad: 6.5848107041091435\n",
      "epoch: 25 loss: 1.6119881868362427 grad: 5.626801558646202\n",
      "epoch: 26 loss: 1.609804391860962 grad: 6.674687102381584\n",
      "epoch: 27 loss: 1.5937203168869019 grad: 6.314283967583515\n",
      "epoch: 28 loss: 1.5874319076538086 grad: 5.879741168979756\n",
      "epoch: 29 loss: 1.5819475650787354 grad: 5.576980977012436\n",
      "epoch: 30 loss: 1.5858079195022583 grad: 5.729603633771163\n",
      "epoch: 31 loss: 1.5814111232757568 grad: 6.478182516213911\n",
      "epoch: 32 loss: 1.6079280376434326 grad: 6.558302503801228\n",
      "epoch: 33 loss: 1.5766171216964722 grad: 4.797067210927043\n",
      "epoch: 34 loss: 1.577561616897583 grad: 4.943390631880397\n",
      "epoch: 35 loss: 1.564612627029419 grad: 4.932561597203237\n",
      "epoch: 36 loss: 1.5674124956130981 grad: 5.672977802820357\n",
      "epoch: 37 loss: 1.5703755617141724 grad: 5.99153122387638\n",
      "epoch: 38 loss: 1.5720056295394897 grad: 5.424545841500904\n",
      "epoch: 39 loss: 1.5763130187988281 grad: 5.515221785898099\n",
      "epoch: 40 loss: 1.5666019916534424 grad: 5.425438555463701\n",
      "epoch: 41 loss: 1.5624014139175415 grad: 5.043895820939118\n",
      "epoch: 42 loss: 1.5508359670639038 grad: 4.77677236645382\n",
      "epoch: 43 loss: 1.563283085823059 grad: 5.099237353096142\n",
      "epoch: 44 loss: 1.5445486307144165 grad: 4.548113155026566\n",
      "epoch: 45 loss: 1.5512666702270508 grad: 5.139317154953142\n",
      "epoch: 46 loss: 1.563489556312561 grad: 4.694121036210639\n",
      "epoch: 47 loss: 1.5526176691055298 grad: 4.517087083983265\n",
      "epoch: 48 loss: 1.5604898929595947 grad: 4.7170566581432745\n",
      "epoch: 49 loss: 1.5459895133972168 grad: 3.827581756224419\n",
      "epoch: 50 loss: 1.550948143005371 grad: 4.601350189640799\n",
      "epoch: 51 loss: 1.5508508682250977 grad: 4.646092876325892\n",
      "epoch: 52 loss: 1.5792616605758667 grad: 6.742985244504318\n",
      "epoch: 53 loss: 1.5634973049163818 grad: 4.722893671604789\n",
      "epoch: 54 loss: 1.5584533214569092 grad: 4.836947346657495\n",
      "epoch: 55 loss: 1.5621387958526611 grad: 4.9221555467467555\n",
      "epoch: 56 loss: 1.554850697517395 grad: 4.726698641046712\n",
      "epoch: 57 loss: 1.6016405820846558 grad: 5.980824649354353\n",
      "epoch: 58 loss: 1.5468393564224243 grad: 4.720897639407819\n",
      "epoch: 59 loss: 1.5548523664474487 grad: 5.550633408097693\n",
      "epoch: 60 loss: 1.5410385131835938 grad: 3.923756605168624\n",
      "epoch: 61 loss: 1.542752981185913 grad: 4.7438446905362435\n",
      "epoch: 62 loss: 1.5440869331359863 grad: 4.99699575657992\n",
      "epoch: 63 loss: 1.5422495603561401 grad: 4.420890344951539\n",
      "epoch: 64 loss: 1.5535871982574463 grad: 5.018890479837345\n",
      "epoch: 65 loss: 1.533974289894104 grad: 3.5796166172779036\n",
      "epoch: 66 loss: 1.5420540571212769 grad: 4.47512858967516\n",
      "epoch: 67 loss: 1.5269999504089355 grad: 3.460812552960999\n",
      "epoch: 68 loss: 1.5386509895324707 grad: 4.811890620858839\n",
      "epoch: 69 loss: 1.5471763610839844 grad: 4.572663862071746\n",
      "epoch: 70 loss: 1.5402494668960571 grad: 4.6293944838266725\n",
      "epoch: 71 loss: 1.5426063537597656 grad: 4.108969451509287\n",
      "epoch: 72 loss: 1.5353220701217651 grad: 4.355709699745712\n",
      "epoch: 73 loss: 1.5409200191497803 grad: 4.15115884690319\n",
      "epoch: 74 loss: 1.5468930006027222 grad: 4.85798361581012\n",
      "epoch: 75 loss: 1.5341241359710693 grad: 4.578814895808809\n",
      "epoch: 76 loss: 1.5577046871185303 grad: 5.60791705744065\n",
      "epoch: 77 loss: 1.5475443601608276 grad: 5.021839199703823\n",
      "epoch: 78 loss: 1.5576622486114502 grad: 4.798530078880422\n",
      "epoch: 79 loss: 1.5598217248916626 grad: 5.0640784905948975\n",
      "epoch: 80 loss: 1.537523627281189 grad: 3.684420836708009\n",
      "epoch: 81 loss: 1.5264631509780884 grad: 3.1951436358624288\n",
      "epoch: 82 loss: 1.5361855030059814 grad: 3.8905524621320455\n",
      "epoch: 83 loss: 1.5401370525360107 grad: 4.389864612649211\n",
      "epoch: 84 loss: 1.5395941734313965 grad: 3.8585956966853554\n",
      "epoch: 85 loss: 1.5374871492385864 grad: 4.1033343523937935\n",
      "epoch: 86 loss: 1.527034044265747 grad: 3.4445419611008736\n",
      "epoch: 87 loss: 1.541361927986145 grad: 4.260800086739433\n",
      "epoch: 88 loss: 1.535911202430725 grad: 4.071670792560741\n",
      "epoch: 89 loss: 1.5264147520065308 grad: 4.00613140307997\n",
      "epoch: 90 loss: 1.523874044418335 grad: 4.249986014945762\n",
      "epoch: 91 loss: 1.5302773714065552 grad: 3.825337289962352\n",
      "epoch: 92 loss: 1.5351454019546509 grad: 3.8878191106695366\n",
      "epoch: 93 loss: 1.5381783246994019 grad: 3.961397780048648\n",
      "epoch: 94 loss: 1.5280412435531616 grad: 4.85134876784791\n",
      "epoch: 95 loss: 1.564271330833435 grad: 5.331253656262766\n",
      "epoch: 96 loss: 1.5465761423110962 grad: 4.639976099220816\n",
      "epoch: 97 loss: 1.548523187637329 grad: 4.4239516426184124\n",
      "epoch: 98 loss: 1.538346767425537 grad: 4.69189912958388\n",
      "epoch: 99 loss: 1.5344395637512207 grad: 4.711194495358921\n",
      "epoch: 100 loss: 1.5277676582336426 grad: 3.396126130205879\n",
      "epoch: 101 loss: 1.5177620649337769 grad: 3.54559376850686\n",
      "epoch: 102 loss: 1.535151720046997 grad: 3.9577344796447442\n",
      "epoch: 103 loss: 1.5236870050430298 grad: 3.914758310018664\n",
      "epoch: 104 loss: 1.522678017616272 grad: 3.695314075759991\n",
      "epoch: 105 loss: 1.5399624109268188 grad: 3.6645246064644503\n",
      "epoch: 106 loss: 1.5140414237976074 grad: 3.2416291099294\n",
      "epoch: 107 loss: 1.5441161394119263 grad: 4.688509119089605\n",
      "epoch: 108 loss: 1.5465221405029297 grad: 5.323943082398296\n",
      "epoch: 109 loss: 1.55064857006073 grad: 4.345376795077394\n",
      "epoch: 110 loss: 1.5314362049102783 grad: 5.08529814544783\n",
      "epoch: 111 loss: 1.5377236604690552 grad: 4.832398775174704\n",
      "epoch: 112 loss: 1.5248621702194214 grad: 4.148157124528321\n",
      "epoch: 113 loss: 1.519919514656067 grad: 3.0765787065526045\n",
      "epoch: 114 loss: 1.5184979438781738 grad: 3.3583457484211974\n",
      "epoch: 115 loss: 1.521045207977295 grad: 4.141596311998909\n",
      "epoch: 116 loss: 1.5334570407867432 grad: 4.501135194105678\n",
      "epoch: 117 loss: 1.5415726900100708 grad: 4.288789993212101\n",
      "epoch: 118 loss: 1.5207240581512451 grad: 3.557547606134852\n",
      "epoch: 119 loss: 1.5211987495422363 grad: 3.409334811775603\n",
      "epoch: 120 loss: 1.5293262004852295 grad: 3.857974992986788\n",
      "epoch: 121 loss: 1.5285847187042236 grad: 3.9161335753509485\n",
      "epoch: 122 loss: 1.5217393636703491 grad: 4.060107506928993\n",
      "epoch: 123 loss: 1.5183041095733643 grad: 3.5448941250851984\n",
      "epoch: 124 loss: 1.523638367652893 grad: 3.688173908264804\n",
      "epoch: 125 loss: 1.5205079317092896 grad: 3.65248312160593\n",
      "epoch: 126 loss: 1.523730754852295 grad: 2.9092832812538068\n",
      "epoch: 127 loss: 1.5296920537948608 grad: 3.8148117378664517\n",
      "epoch: 128 loss: 1.5385445356369019 grad: 4.956315483323784\n",
      "epoch: 129 loss: 1.5375010967254639 grad: 3.315595275515569\n",
      "epoch: 130 loss: 1.5365861654281616 grad: 3.6310476585095657\n",
      "epoch: 131 loss: 1.5149586200714111 grad: 2.992789889451552\n",
      "epoch: 132 loss: 1.5174144506454468 grad: 2.644661403000759\n",
      "epoch: 133 loss: 1.5180193185806274 grad: 4.1420639828328065\n",
      "epoch: 134 loss: 1.5320751667022705 grad: 3.9273200373925103\n",
      "epoch: 135 loss: 1.52705979347229 grad: 3.871073357863421\n",
      "epoch: 136 loss: 1.529475212097168 grad: 3.9957364111156104\n",
      "epoch: 137 loss: 1.5384265184402466 grad: 4.685720535888972\n",
      "epoch: 138 loss: 1.5236890316009521 grad: 4.03460168021131\n",
      "epoch: 139 loss: 1.5207854509353638 grad: 3.410205389720098\n",
      "epoch: 140 loss: 1.515689492225647 grad: 2.7944151576355223\n",
      "epoch: 141 loss: 1.5171780586242676 grad: 3.630524149739055\n",
      "epoch: 142 loss: 1.528709053993225 grad: 3.06824996882631\n",
      "epoch: 143 loss: 1.523362636566162 grad: 3.31797787316216\n",
      "epoch: 144 loss: 1.5136306285858154 grad: 3.94507120858827\n",
      "epoch: 145 loss: 1.5150359869003296 grad: 3.5821143368896573\n",
      "epoch: 146 loss: 1.5442649126052856 grad: 6.068137803068451\n",
      "epoch: 147 loss: 1.5417373180389404 grad: 3.1230866857789286\n",
      "epoch: 148 loss: 1.514705777168274 grad: 2.6498339682354097\n",
      "epoch: 149 loss: 1.5051707029342651 grad: 2.125546381999325\n",
      "epoch: 150 loss: 1.524718999862671 grad: 3.3709733454383035\n",
      "epoch: 151 loss: 1.524501919746399 grad: 4.04956863368313\n",
      "epoch: 152 loss: 1.5098750591278076 grad: 2.578597949168125\n",
      "epoch: 153 loss: 1.508724570274353 grad: 2.373632034809927\n",
      "epoch: 154 loss: 1.5162668228149414 grad: 3.5435917213849724\n",
      "epoch: 155 loss: 1.5179932117462158 grad: 3.9088357717171323\n",
      "epoch: 156 loss: 1.5227724313735962 grad: 3.803796043428189\n",
      "epoch: 157 loss: 1.5315190553665161 grad: 4.425748120680024\n",
      "epoch: 158 loss: 1.539048433303833 grad: 3.9252293055323784\n",
      "epoch: 159 loss: 1.5260049104690552 grad: 3.9851576838898506\n",
      "epoch: 160 loss: 1.5208765268325806 grad: 4.038587687409627\n",
      "epoch: 161 loss: 1.5169110298156738 grad: 3.7623382616803838\n",
      "epoch: 162 loss: 1.5305795669555664 grad: 4.71331666185244\n",
      "epoch: 163 loss: 1.518171787261963 grad: 4.008708226350595\n",
      "epoch: 164 loss: 1.5482982397079468 grad: 4.25383873238926\n",
      "epoch: 165 loss: 1.50537109375 grad: 3.0675032690764468\n",
      "epoch: 166 loss: 1.5130844116210938 grad: 2.686288870515767\n",
      "epoch: 167 loss: 1.5116243362426758 grad: 2.4894774714506376\n",
      "epoch: 168 loss: 1.5045095682144165 grad: 2.6939425029169195\n",
      "epoch: 169 loss: 1.511168122291565 grad: 2.4062945676998955\n",
      "epoch: 170 loss: 1.5150631666183472 grad: 3.249322774353858\n",
      "epoch: 171 loss: 1.5211385488510132 grad: 3.246828847723611\n",
      "epoch: 172 loss: 1.5040006637573242 grad: 2.748621901212375\n",
      "epoch: 173 loss: 1.5167675018310547 grad: 3.2365528045889707\n",
      "epoch: 174 loss: 1.5293583869934082 grad: 4.12127653843353\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 175 loss: 1.5250561237335205 grad: 4.331941203539602\n",
      "epoch: 176 loss: 1.519188642501831 grad: 2.3339511512595355\n",
      "epoch: 177 loss: 1.5142806768417358 grad: 2.324693840607272\n",
      "epoch: 178 loss: 1.5095572471618652 grad: 2.197158758960149\n",
      "epoch: 179 loss: 1.5211974382400513 grad: 2.968113400744191\n",
      "epoch: 180 loss: 1.510475993156433 grad: 2.553490041709419\n",
      "epoch: 181 loss: 1.5156124830245972 grad: 3.963123481111855\n",
      "epoch: 182 loss: 1.5302150249481201 grad: 3.2789711572675873\n",
      "epoch: 183 loss: 1.5150123834609985 grad: 3.707062680729723\n",
      "epoch: 184 loss: 1.5160280466079712 grad: 3.329274545039459\n",
      "epoch: 185 loss: 1.522995948791504 grad: 3.6755793555831406\n",
      "epoch: 186 loss: 1.5131906270980835 grad: 3.5895887527226575\n",
      "epoch: 187 loss: 1.5094720125198364 grad: 2.8778583358355982\n",
      "epoch: 188 loss: 1.5409013032913208 grad: 4.074593964276272\n",
      "epoch: 189 loss: 1.5194607973098755 grad: 3.404243497668528\n",
      "epoch: 190 loss: 1.5256866216659546 grad: 3.464597461234128\n",
      "epoch: 191 loss: 1.5283305644989014 grad: 4.539005157160628\n",
      "epoch: 192 loss: 1.5134477615356445 grad: 2.9321034492910854\n",
      "epoch: 193 loss: 1.5330473184585571 grad: 3.471251170992581\n",
      "epoch: 194 loss: 1.5336408615112305 grad: 3.245093705930261\n",
      "epoch: 195 loss: 1.5254944562911987 grad: 3.1397037647281985\n",
      "epoch: 196 loss: 1.5039148330688477 grad: 2.1020127815707266\n",
      "epoch: 197 loss: 1.5317403078079224 grad: 2.9309382894501024\n",
      "epoch: 198 loss: 1.5054389238357544 grad: 2.9347668812637875\n",
      "epoch: 199 loss: 1.5078258514404297 grad: 2.710818566596697\n",
      "epoch: 200 loss: 1.5170905590057373 grad: 2.875489476746857\n",
      "epoch: 201 loss: 1.520526647567749 grad: 2.8944501480885765\n",
      "epoch: 202 loss: 1.5110390186309814 grad: 3.0861149821581693\n",
      "epoch: 203 loss: 1.5209760665893555 grad: 2.8930404843830413\n",
      "epoch: 204 loss: 1.5089296102523804 grad: 2.503307794717655\n",
      "epoch: 205 loss: 1.5041301250457764 grad: 3.0089042988026735\n",
      "epoch: 206 loss: 1.5107781887054443 grad: 2.8629575280556203\n",
      "epoch: 207 loss: 1.5186131000518799 grad: 3.2930364757782375\n",
      "epoch: 208 loss: 1.5058866739273071 grad: 2.6452190527111488\n",
      "epoch: 209 loss: 1.509587049484253 grad: 3.5291817647351333\n",
      "epoch: 210 loss: 1.5189504623413086 grad: 2.8840690400154085\n",
      "epoch: 211 loss: 1.5115952491760254 grad: 2.97786683137743\n",
      "epoch: 212 loss: 1.5215215682983398 grad: 2.8946213843747985\n",
      "epoch: 213 loss: 1.496350884437561 grad: 1.9227816687137196\n",
      "epoch: 214 loss: 1.5114843845367432 grad: 2.836454816950087\n",
      "epoch: 215 loss: 1.5090718269348145 grad: 3.8018739686196077\n",
      "epoch: 216 loss: 1.5451828241348267 grad: 4.331955322186526\n",
      "epoch: 217 loss: 1.499015212059021 grad: 3.1341599411493153\n",
      "epoch: 218 loss: 1.5020487308502197 grad: 2.4347229501119854\n",
      "epoch: 219 loss: 1.503764271736145 grad: 1.7432120327721923\n",
      "epoch: 220 loss: 1.5080229043960571 grad: 3.041545766747227\n",
      "epoch: 221 loss: 1.5223904848098755 grad: 2.692723664904195\n",
      "epoch: 222 loss: 1.5027945041656494 grad: 2.963818548346632\n",
      "epoch: 223 loss: 1.5146713256835938 grad: 3.2260591544810273\n",
      "epoch: 224 loss: 1.5220990180969238 grad: 3.031274209074708\n",
      "epoch: 225 loss: 1.4991395473480225 grad: 3.066964660819792\n",
      "epoch: 226 loss: 1.5152959823608398 grad: 2.2338611703912887\n",
      "epoch: 227 loss: 1.506116271018982 grad: 1.926903510887694\n",
      "epoch: 228 loss: 1.5007489919662476 grad: 2.1125601560271106\n",
      "epoch: 229 loss: 1.5000120401382446 grad: 2.4076670700246607\n",
      "epoch: 230 loss: 1.505124568939209 grad: 2.240634855834463\n",
      "epoch: 231 loss: 1.505031943321228 grad: 2.9291875088846004\n",
      "epoch: 232 loss: 1.5123307704925537 grad: 2.8301218773257983\n",
      "epoch: 233 loss: 1.5036743879318237 grad: 2.348331761286792\n",
      "epoch: 234 loss: 1.5293047428131104 grad: 2.821815512030808\n",
      "epoch: 235 loss: 1.5081279277801514 grad: 2.711437190084579\n",
      "epoch: 236 loss: 1.5256892442703247 grad: 3.228826328120177\n",
      "epoch: 237 loss: 1.5178263187408447 grad: 2.329196900881091\n",
      "epoch: 238 loss: 1.5042275190353394 grad: 2.8876830715353075\n",
      "epoch: 239 loss: 1.5076590776443481 grad: 2.349642426762289\n",
      "epoch: 240 loss: 1.51205575466156 grad: 2.585500825943678\n",
      "epoch: 241 loss: 1.514661192893982 grad: 3.6004289610061595\n",
      "epoch: 242 loss: 1.5042812824249268 grad: 2.372304356787459\n",
      "epoch: 243 loss: 1.5046091079711914 grad: 2.588646674125133\n",
      "epoch: 244 loss: 1.5181573629379272 grad: 3.0980595379846654\n",
      "epoch: 245 loss: 1.516749620437622 grad: 2.9435732743780276\n",
      "epoch: 246 loss: 1.5074843168258667 grad: 2.8964082532903794\n",
      "epoch: 247 loss: 1.5039196014404297 grad: 2.7469376501731295\n",
      "epoch: 248 loss: 1.5022356510162354 grad: 3.000913278831726\n",
      "epoch: 249 loss: 1.5114730596542358 grad: 2.6823810908766315\n",
      "epoch: 250 loss: 1.5038807392120361 grad: 1.4458005162431742\n",
      "epoch: 251 loss: 1.50802481174469 grad: 2.637442674041151\n",
      "epoch: 252 loss: 1.5068373680114746 grad: 2.829402087364496\n",
      "epoch: 253 loss: 1.5230777263641357 grad: 3.090935276152674\n",
      "epoch: 254 loss: 1.5136730670928955 grad: 2.786579020383936\n",
      "epoch: 255 loss: 1.5108543634414673 grad: 2.9207779243107934\n",
      "epoch: 256 loss: 1.5162922143936157 grad: 3.988244890400542\n",
      "epoch: 257 loss: 1.5027023553848267 grad: 1.5952947724814084\n",
      "epoch: 258 loss: 1.4989091157913208 grad: 1.7226907502983833\n",
      "epoch: 259 loss: 1.4964625835418701 grad: 1.2672663082714875\n",
      "epoch: 260 loss: 1.500996708869934 grad: 2.7324266300896\n",
      "epoch: 261 loss: 1.4996033906936646 grad: 3.0911918673060375\n",
      "epoch: 262 loss: 1.5091395378112793 grad: 3.2692062971107303\n",
      "epoch: 263 loss: 1.5092400312423706 grad: 2.7237712766428106\n",
      "epoch: 264 loss: 1.5014785528182983 grad: 2.247471199481117\n",
      "epoch: 265 loss: 1.5091960430145264 grad: 3.0984799453011087\n",
      "epoch: 266 loss: 1.5106172561645508 grad: 3.7726618955985614\n",
      "epoch: 267 loss: 1.5241456031799316 grad: 2.975464224524426\n",
      "epoch: 268 loss: 1.5099506378173828 grad: 2.2991564517682956\n",
      "epoch: 269 loss: 1.497108817100525 grad: 1.8134802030174941\n",
      "epoch: 270 loss: 1.5104823112487793 grad: 3.510251752407283\n",
      "epoch: 271 loss: 1.5051002502441406 grad: 2.308282234770047\n",
      "epoch: 272 loss: 1.5032206773757935 grad: 2.791616202549049\n",
      "epoch: 273 loss: 1.5108914375305176 grad: 2.660389461062808\n",
      "epoch: 274 loss: 1.4965510368347168 grad: 2.109743131582117\n",
      "epoch: 275 loss: 1.5007975101470947 grad: 2.1472541139848547\n",
      "epoch: 276 loss: 1.5055747032165527 grad: 1.6694638374704347\n",
      "epoch: 277 loss: 1.5149048566818237 grad: 2.2289250560084706\n",
      "epoch: 278 loss: 1.5106737613677979 grad: 2.59661794013462\n",
      "epoch: 279 loss: 1.5019577741622925 grad: 1.3610693633895692\n",
      "epoch: 280 loss: 1.5075769424438477 grad: 3.638596842454788\n",
      "epoch: 281 loss: 1.4926605224609375 grad: 2.0097403717522657\n",
      "epoch: 282 loss: 1.4995614290237427 grad: 2.1745710168236307\n",
      "epoch: 283 loss: 1.4939968585968018 grad: 1.8221008882553384\n",
      "epoch: 284 loss: 1.5009599924087524 grad: 2.027434092731942\n",
      "epoch: 285 loss: 1.5088223218917847 grad: 2.6472499608527946\n",
      "epoch: 286 loss: 1.507625937461853 grad: 2.4251181676354263\n",
      "epoch: 287 loss: 1.5223228931427002 grad: 3.342497125745111\n",
      "epoch: 288 loss: 1.525635838508606 grad: 3.0315601477860454\n",
      "epoch: 289 loss: 1.5053658485412598 grad: 1.8573785306486457\n",
      "epoch: 290 loss: 1.5068897008895874 grad: 2.2771307982599125\n",
      "epoch: 291 loss: 1.5092413425445557 grad: 2.4515828235135038\n",
      "epoch: 292 loss: 1.5106905698776245 grad: 2.4870152037778306\n",
      "epoch: 293 loss: 1.5014855861663818 grad: 2.4290902632999964\n",
      "epoch: 294 loss: 1.512817144393921 grad: 3.664342749115888\n",
      "epoch: 295 loss: 1.5172666311264038 grad: 3.737730486041468\n",
      "epoch: 296 loss: 1.5251541137695312 grad: 3.763291923245459\n",
      "epoch: 297 loss: 1.4934186935424805 grad: 1.787127055388175\n",
      "epoch: 298 loss: 1.5094023942947388 grad: 3.9700956531401315\n",
      "epoch: 299 loss: 1.5034477710723877 grad: 3.1184900433127987\n",
      "epoch: 300 loss: 1.5039464235305786 grad: 3.1248635963369304\n",
      "epoch: 301 loss: 1.5230185985565186 grad: 3.228425462985955\n",
      "epoch: 302 loss: 1.5023248195648193 grad: 2.5115722372220746\n",
      "epoch: 303 loss: 1.5006641149520874 grad: 2.165748233344237\n",
      "epoch: 304 loss: 1.4996672868728638 grad: 1.834155097992218\n",
      "epoch: 305 loss: 1.5017849206924438 grad: 1.819467592111052\n",
      "epoch: 306 loss: 1.4946253299713135 grad: 2.004701109636696\n",
      "epoch: 307 loss: 1.5066672563552856 grad: 2.2924168296633867\n",
      "epoch: 308 loss: 1.5032284259796143 grad: 2.7925928512873006\n",
      "epoch: 309 loss: 1.5057392120361328 grad: 1.8268492173807735\n",
      "epoch: 310 loss: 1.4946072101593018 grad: 1.9612953828470847\n",
      "epoch: 311 loss: 1.5108885765075684 grad: 3.5392208630302764\n",
      "epoch: 312 loss: 1.515049695968628 grad: 3.3554107503951336\n",
      "epoch: 313 loss: 1.5164481401443481 grad: 2.215853250297043\n",
      "epoch: 314 loss: 1.5022988319396973 grad: 1.5687756260571544\n",
      "epoch: 315 loss: 1.4996119737625122 grad: 2.414054945066765\n",
      "epoch: 316 loss: 1.5073376893997192 grad: 3.2307476906958628\n",
      "epoch: 317 loss: 1.5019944906234741 grad: 2.5753025357817942\n",
      "epoch: 318 loss: 1.49704110622406 grad: 2.0564219255722733\n",
      "epoch: 319 loss: 1.5065298080444336 grad: 1.6997607100912235\n",
      "epoch: 320 loss: 1.5101442337036133 grad: 3.3039604784645444\n",
      "epoch: 321 loss: 1.4984023571014404 grad: 2.8454333779325927\n",
      "epoch: 322 loss: 1.5001407861709595 grad: 1.7700771405850702\n",
      "epoch: 323 loss: 1.5039925575256348 grad: 3.365127112877908\n",
      "epoch: 324 loss: 1.5054106712341309 grad: 2.4629435289705857\n",
      "epoch: 325 loss: 1.4954551458358765 grad: 1.5212282477759715\n",
      "epoch: 326 loss: 1.5050724744796753 grad: 2.4563721308855335\n",
      "epoch: 327 loss: 1.5009509325027466 grad: 2.2285110358169433\n",
      "epoch: 328 loss: 1.4939583539962769 grad: 1.761142706014449\n",
      "epoch: 329 loss: 1.499300241470337 grad: 2.0325740854177936\n",
      "epoch: 330 loss: 1.4940584897994995 grad: 2.8318508556176356\n",
      "epoch: 331 loss: 1.513975739479065 grad: 2.437701670632852\n",
      "epoch: 332 loss: 1.4934003353118896 grad: 2.08772470266699\n",
      "epoch: 333 loss: 1.497210144996643 grad: 1.1872051497893061\n",
      "epoch: 334 loss: 1.5017483234405518 grad: 2.6278767661573315\n",
      "epoch: 335 loss: 1.497004747390747 grad: 1.7919137257736883\n",
      "epoch: 336 loss: 1.4924322366714478 grad: 1.2224047794245056\n",
      "epoch: 337 loss: 1.4913972616195679 grad: 1.8046576213999859\n",
      "epoch: 338 loss: 1.5073586702346802 grad: 2.0490431371820668\n",
      "epoch: 339 loss: 1.506645917892456 grad: 2.613312975871257\n",
      "epoch: 340 loss: 1.5082584619522095 grad: 2.76941683739657\n",
      "epoch: 341 loss: 1.4952304363250732 grad: 2.3160854211310684\n",
      "epoch: 342 loss: 1.496692180633545 grad: 1.424133211956533\n",
      "epoch: 343 loss: 1.5072957277297974 grad: 2.903752014779063\n",
      "epoch: 344 loss: 1.514835000038147 grad: 2.7831262068765135\n",
      "epoch: 345 loss: 1.4989874362945557 grad: 1.5907200251007942\n",
      "epoch: 346 loss: 1.506131649017334 grad: 1.5317624245969703\n",
      "epoch: 347 loss: 1.5057547092437744 grad: 1.970138012673753\n",
      "epoch: 348 loss: 1.4969112873077393 grad: 1.7752525260664371\n",
      "epoch: 349 loss: 1.4959412813186646 grad: 2.3501935152374855\n",
      "epoch: 350 loss: 1.4974510669708252 grad: 1.9132851993414697\n",
      "epoch: 351 loss: 1.5109859704971313 grad: 3.1706323538140033\n",
      "epoch: 352 loss: 1.511522889137268 grad: 1.9015402784988376\n",
      "epoch: 353 loss: 1.510151743888855 grad: 2.875278377677113\n",
      "epoch: 354 loss: 1.5072304010391235 grad: 3.278024273841198\n",
      "epoch: 355 loss: 1.5226149559020996 grad: 2.7272815204304734\n",
      "epoch: 356 loss: 1.5119508504867554 grad: 3.0922703715263054\n",
      "epoch: 357 loss: 1.5045011043548584 grad: 2.3374865957402275\n",
      "epoch: 358 loss: 1.5200462341308594 grad: 2.0429617724420845\n",
      "epoch: 359 loss: 1.5085641145706177 grad: 1.6331740531342538\n",
      "epoch: 360 loss: 1.4962732791900635 grad: 2.724932639843619\n",
      "epoch: 361 loss: 1.5048032999038696 grad: 3.335588328327273\n",
      "epoch: 362 loss: 1.520572304725647 grad: 2.1896351476943585\n",
      "epoch: 363 loss: 1.5016324520111084 grad: 2.0371388330271034\n",
      "epoch: 364 loss: 1.4985705614089966 grad: 2.3589126114941066\n",
      "epoch: 365 loss: 1.4977576732635498 grad: 1.6270202347085385\n",
      "epoch: 366 loss: 1.4935040473937988 grad: 2.299367417500456\n",
      "epoch: 367 loss: 1.4934600591659546 grad: 1.9777432222045945\n",
      "epoch: 368 loss: 1.4984976053237915 grad: 2.500775353165312\n",
      "epoch: 369 loss: 1.5098625421524048 grad: 2.4244067986069138\n",
      "epoch: 370 loss: 1.495773434638977 grad: 2.390151754256455\n",
      "epoch: 371 loss: 1.4943221807479858 grad: 2.060710840463566\n",
      "epoch: 372 loss: 1.5116822719573975 grad: 3.1538066252128174\n",
      "epoch: 373 loss: 1.5050519704818726 grad: 3.3650267117787376\n",
      "epoch: 374 loss: 1.505180835723877 grad: 3.3823883713564267\n",
      "epoch: 375 loss: 1.5152945518493652 grad: 2.487034113608578\n",
      "epoch: 376 loss: 1.4954863786697388 grad: 1.4354290515096653\n",
      "epoch: 377 loss: 1.5106029510498047 grad: 3.0240705898463536\n",
      "epoch: 378 loss: 1.4917620420455933 grad: 1.6416904947309967\n",
      "epoch: 379 loss: 1.496612787246704 grad: 1.499365249774256\n",
      "epoch: 380 loss: 1.5041441917419434 grad: 1.901000501897599\n",
      "epoch: 381 loss: 1.5016299486160278 grad: 2.416027746898848\n",
      "epoch: 382 loss: 1.5013298988342285 grad: 2.9865257094404503\n",
      "epoch: 383 loss: 1.5118792057037354 grad: 3.0387222905290026\n",
      "epoch: 384 loss: 1.4964604377746582 grad: 2.748982310204163\n",
      "epoch: 385 loss: 1.4938312768936157 grad: 2.4374265405010105\n",
      "epoch: 386 loss: 1.4903080463409424 grad: 1.5373496850044162\n",
      "epoch: 387 loss: 1.4953744411468506 grad: 2.17869124680487\n",
      "epoch: 388 loss: 1.493208885192871 grad: 1.4070017880148906\n",
      "epoch: 389 loss: 1.5046513080596924 grad: 2.1203505561232516\n",
      "epoch: 390 loss: 1.492472529411316 grad: 1.1940473168952621\n",
      "epoch: 391 loss: 1.495427131652832 grad: 2.139209772373038\n",
      "epoch: 392 loss: 1.5020610094070435 grad: 2.2530556379942093\n",
      "epoch: 393 loss: 1.4946260452270508 grad: 1.7987371805423837\n",
      "epoch: 394 loss: 1.5007882118225098 grad: 2.5088365481984685\n",
      "epoch: 395 loss: 1.5403803586959839 grad: 3.3883275656339555\n",
      "epoch: 396 loss: 1.5228697061538696 grad: 2.2408316894230125\n",
      "epoch: 397 loss: 1.4959461688995361 grad: 1.5754093730116838\n",
      "epoch: 398 loss: 1.4948463439941406 grad: 2.244748850460907\n",
      "epoch: 399 loss: 1.5067919492721558 grad: 2.643966299903735\n",
      "epoch: 400 loss: 1.5107582807540894 grad: 2.736300862725999\n",
      "epoch: 401 loss: 1.5111163854599 grad: 3.37981459287698\n",
      "epoch: 402 loss: 1.4958287477493286 grad: 1.9781171249366998\n",
      "epoch: 403 loss: 1.4911580085754395 grad: 0.4512062324396104\n",
      "epoch: 404 loss: 1.4924906492233276 grad: 1.9001254487682158\n",
      "epoch: 405 loss: 1.4983165264129639 grad: 2.0333903195415166\n",
      "epoch: 406 loss: 1.511641025543213 grad: 2.2558460719358955\n",
      "epoch: 407 loss: 1.4895703792572021 grad: 1.244044852085466\n",
      "epoch: 408 loss: 1.4917830228805542 grad: 1.8223009606009224\n",
      "epoch: 409 loss: 1.4903372526168823 grad: 1.5591603549196154\n",
      "epoch: 410 loss: 1.4891562461853027 grad: 1.150371452369648\n",
      "epoch: 411 loss: 1.4829797744750977 grad: 0.6846875824234461\n",
      "epoch: 412 loss: 1.4795236587524414 grad: 1.4795545890153043\n",
      "epoch: 413 loss: 1.5061650276184082 grad: 1.3422308652249573\n",
      "epoch: 414 loss: 1.5005168914794922 grad: 1.3197175446274663\n",
      "epoch: 415 loss: 1.4950751066207886 grad: 1.9756894468659245\n",
      "epoch: 416 loss: 1.4920861721038818 grad: 2.024290311073717\n",
      "epoch: 417 loss: 1.4936306476593018 grad: 2.008124204660809\n",
      "epoch: 418 loss: 1.5139538049697876 grad: 3.0996054768735744\n",
      "epoch: 419 loss: 1.499251365661621 grad: 2.568531469644694\n",
      "epoch: 420 loss: 1.5017727613449097 grad: 2.2980157483960277\n",
      "epoch: 421 loss: 1.4984458684921265 grad: 1.0957909614756163\n",
      "epoch: 422 loss: 1.4872137308120728 grad: 1.866006933716359\n",
      "epoch: 423 loss: 1.4881318807601929 grad: 1.7899274595812764\n",
      "epoch: 424 loss: 1.4970619678497314 grad: 1.368851217351726\n",
      "epoch: 425 loss: 1.4988290071487427 grad: 1.7551404698501751\n",
      "epoch: 426 loss: 1.4887380599975586 grad: 1.0484296190863542\n",
      "epoch: 427 loss: 1.492448329925537 grad: 1.2736539345751052\n",
      "epoch: 428 loss: 1.4920895099639893 grad: 1.9176144729556222\n",
      "epoch: 429 loss: 1.4982043504714966 grad: 2.1794432360360756\n",
      "epoch: 430 loss: 1.5195252895355225 grad: 2.9366980886593823\n",
      "epoch: 431 loss: 1.516171932220459 grad: 2.1193390881549723\n",
      "epoch: 432 loss: 1.498247742652893 grad: 2.139148822546587\n",
      "epoch: 433 loss: 1.5114026069641113 grad: 3.527119697965607\n",
      "epoch: 434 loss: 1.5133841037750244 grad: 2.558895393954367\n",
      "epoch: 435 loss: 1.4994179010391235 grad: 1.9101785734874646\n",
      "epoch: 436 loss: 1.4957276582717896 grad: 1.9103266465544844\n",
      "epoch: 437 loss: 1.5025277137756348 grad: 2.191831868576105\n",
      "epoch: 438 loss: 1.4881418943405151 grad: 2.397618133209724\n",
      "epoch: 439 loss: 1.5196400880813599 grad: 1.412060890064822\n",
      "epoch: 440 loss: 1.4902679920196533 grad: 0.9154624072290579\n",
      "epoch: 441 loss: 1.4932971000671387 grad: 1.9228282361108435\n",
      "epoch: 442 loss: 1.5032975673675537 grad: 1.7839310214992594\n",
      "epoch: 443 loss: 1.4943690299987793 grad: 1.5636827564581441\n",
      "epoch: 444 loss: 1.4944080114364624 grad: 2.256973109629559\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 445 loss: 1.4998071193695068 grad: 2.119086554859631\n",
      "epoch: 446 loss: 1.5006814002990723 grad: 3.110711134146517\n",
      "epoch: 447 loss: 1.4994468688964844 grad: 2.110218951468867\n",
      "epoch: 448 loss: 1.492106556892395 grad: 1.5070332474718395\n",
      "epoch: 449 loss: 1.496382713317871 grad: 1.3367802114946035\n",
      "epoch: 450 loss: 1.5097113847732544 grad: 2.5021951563432774\n",
      "epoch: 451 loss: 1.4982552528381348 grad: 2.543609401920156\n",
      "epoch: 452 loss: 1.4937511682510376 grad: 1.8750620766144903\n",
      "epoch: 453 loss: 1.4930189847946167 grad: 2.5460510832878627\n",
      "epoch: 454 loss: 1.498647689819336 grad: 2.8257505920697232\n",
      "epoch: 455 loss: 1.4903838634490967 grad: 1.305831836451303\n",
      "epoch: 456 loss: 1.485292673110962 grad: 1.1962881067367086\n",
      "epoch: 457 loss: 1.4980072975158691 grad: 2.6009093105609975\n",
      "epoch: 458 loss: 1.4935718774795532 grad: 1.862499498264393\n",
      "epoch: 459 loss: 1.4954036474227905 grad: 1.5029233286543655\n",
      "epoch: 460 loss: 1.4979290962219238 grad: 1.8282669857167866\n",
      "epoch: 461 loss: 1.4805960655212402 grad: 1.8766660431614122\n",
      "epoch: 462 loss: 1.5066295862197876 grad: 2.3289374429096124\n",
      "epoch: 463 loss: 1.5107719898223877 grad: 3.4195455112802216\n",
      "epoch: 464 loss: 1.502328634262085 grad: 1.9067696002969379\n",
      "epoch: 465 loss: 1.4976749420166016 grad: 1.455827392559431\n",
      "epoch: 466 loss: 1.4996070861816406 grad: 2.3695017163247476\n",
      "epoch: 467 loss: 1.4972922801971436 grad: 2.046168892763712\n",
      "epoch: 468 loss: 1.494233250617981 grad: 1.8629647981632524\n",
      "epoch: 469 loss: 1.486322283744812 grad: 1.820852016359787\n",
      "epoch: 470 loss: 1.4928107261657715 grad: 1.478606825847449\n",
      "epoch: 471 loss: 1.496153473854065 grad: 1.6466225706630415\n",
      "epoch: 472 loss: 1.511081337928772 grad: 2.040744243841111\n",
      "epoch: 473 loss: 1.5069538354873657 grad: 1.7851976423899054\n",
      "epoch: 474 loss: 1.4900085926055908 grad: 1.1899186243277893\n",
      "epoch: 475 loss: 1.4930689334869385 grad: 1.2306728576457096\n",
      "epoch: 476 loss: 1.4853876829147339 grad: 1.6666372157401446\n",
      "epoch: 477 loss: 1.4877159595489502 grad: 1.48803277201435\n",
      "epoch: 478 loss: 1.4924979209899902 grad: 1.9280624527441415\n",
      "epoch: 479 loss: 1.4864890575408936 grad: 2.5991609755836653\n",
      "epoch: 480 loss: 1.4905754327774048 grad: 2.295856545589993\n",
      "epoch: 481 loss: 1.5096824169158936 grad: 2.3007617124737547\n",
      "epoch: 482 loss: 1.501717209815979 grad: 2.264877766529528\n",
      "epoch: 483 loss: 1.5052183866500854 grad: 3.2342774779207164\n",
      "epoch: 484 loss: 1.5002998113632202 grad: 2.0572424457720646\n",
      "epoch: 485 loss: 1.4964643716812134 grad: 1.7368814546781792\n",
      "epoch: 486 loss: 1.5016705989837646 grad: 1.0614894444468952\n",
      "epoch: 487 loss: 1.4888103008270264 grad: 1.1444618297051408\n",
      "epoch: 488 loss: 1.490570306777954 grad: 1.4590706515943554\n",
      "epoch: 489 loss: 1.5059170722961426 grad: 2.021440184588174\n",
      "epoch: 490 loss: 1.4902658462524414 grad: 1.3802130843661309\n",
      "epoch: 491 loss: 1.4832698106765747 grad: 1.5364842920112611\n",
      "epoch: 492 loss: 1.4846569299697876 grad: 2.2916193399296403\n",
      "epoch: 493 loss: 1.4958276748657227 grad: 1.33080675341429\n",
      "epoch: 494 loss: 1.4924732446670532 grad: 1.537444722945886\n",
      "epoch: 495 loss: 1.4939029216766357 grad: 1.421734831553024\n",
      "epoch: 496 loss: 1.4852229356765747 grad: 1.0797679305152694\n",
      "epoch: 497 loss: 1.489817500114441 grad: 1.6252029775335521\n",
      "epoch: 498 loss: 1.5010427236557007 grad: 2.2021872714195783\n",
      "epoch: 499 loss: 1.4973118305206299 grad: 1.794681845989425\n",
      "1.8354103937745094\n",
      "epoch: 0 loss: 2.303215265274048 grad: 1.5379158289131103\n",
      "epoch: 1 loss: 2.302424430847168 grad: 1.545787921105142\n",
      "epoch: 2 loss: 2.302474021911621 grad: 1.5447752063554372\n",
      "epoch: 3 loss: 2.3027751445770264 grad: 1.5311592645067278\n",
      "epoch: 4 loss: 2.302804470062256 grad: 1.5392760742743987\n",
      "epoch: 5 loss: 2.302778959274292 grad: 1.5383350455131943\n",
      "epoch: 6 loss: 2.3025081157684326 grad: 1.5394756770932987\n",
      "epoch: 7 loss: 2.3026657104492188 grad: 1.5338462749958068\n",
      "epoch: 8 loss: 2.303682327270508 grad: 1.5193240577946343\n",
      "epoch: 9 loss: 2.3026087284088135 grad: 1.5437003747404863\n",
      "epoch: 10 loss: 2.3032398223876953 grad: 1.52309137319089\n",
      "epoch: 11 loss: 2.3028476238250732 grad: 1.5359455939042308\n",
      "epoch: 12 loss: 2.3026669025421143 grad: 1.5376596075615712\n",
      "epoch: 13 loss: 2.3024039268493652 grad: 1.5338311360609378\n",
      "epoch: 14 loss: 2.3029496669769287 grad: 1.5329093477274809\n",
      "epoch: 15 loss: 2.302678346633911 grad: 1.5357209397830986\n",
      "epoch: 16 loss: 2.302799701690674 grad: 1.5284309533945772\n",
      "epoch: 17 loss: 2.3032147884368896 grad: 1.5135840490138868\n",
      "epoch: 18 loss: 2.3025262355804443 grad: 1.524783066278028\n",
      "epoch: 19 loss: 2.30310320854187 grad: 1.5337742428103136\n",
      "epoch: 20 loss: 2.3033854961395264 grad: 1.5199146377096426\n",
      "epoch: 21 loss: 2.30277419090271 grad: 1.538715992331697\n",
      "epoch: 22 loss: 2.302884101867676 grad: 1.5273264219766365\n",
      "epoch: 23 loss: 2.302554130554199 grad: 1.544214067150957\n",
      "epoch: 24 loss: 2.303116798400879 grad: 1.5192058774576123\n",
      "epoch: 25 loss: 2.302656650543213 grad: 1.5293478746048457\n",
      "epoch: 26 loss: 2.302623987197876 grad: 1.5352878663319325\n",
      "epoch: 27 loss: 2.302618980407715 grad: 1.5253699128996463\n",
      "epoch: 28 loss: 2.3028500080108643 grad: 1.5252364150466515\n",
      "epoch: 29 loss: 2.302980422973633 grad: 1.5218778384612903\n",
      "epoch: 30 loss: 2.302783966064453 grad: 1.5283669933421715\n",
      "epoch: 31 loss: 2.302760362625122 grad: 1.5374108403403726\n",
      "epoch: 32 loss: 2.302429437637329 grad: 1.5342777582358509\n",
      "epoch: 33 loss: 2.302483558654785 grad: 1.529742463693274\n",
      "epoch: 34 loss: 2.302762031555176 grad: 1.5315335782518285\n",
      "epoch: 35 loss: 2.302290678024292 grad: 1.5360145173423614\n",
      "epoch: 36 loss: 2.30255126953125 grad: 1.5251562216241534\n",
      "epoch: 37 loss: 2.302760362625122 grad: 1.5169292677707586\n",
      "epoch: 38 loss: 2.30248761177063 grad: 1.5390865349428846\n",
      "epoch: 39 loss: 2.302570343017578 grad: 1.5261424328348348\n",
      "epoch: 40 loss: 2.3026559352874756 grad: 1.5243945620115107\n",
      "epoch: 41 loss: 2.303391218185425 grad: 1.5144119131959057\n",
      "epoch: 42 loss: 2.303149461746216 grad: 1.5182315103565565\n",
      "epoch: 43 loss: 2.3024983406066895 grad: 1.5359270247032069\n",
      "epoch: 44 loss: 2.3028416633605957 grad: 1.534761520814047\n",
      "epoch: 45 loss: 2.3024096488952637 grad: 1.528633073960904\n",
      "epoch: 46 loss: 2.3024258613586426 grad: 1.5344414954066337\n",
      "epoch: 47 loss: 2.3023109436035156 grad: 1.5333249872007098\n",
      "epoch: 48 loss: 2.3029592037200928 grad: 1.5460036070370633\n",
      "epoch: 49 loss: 2.3023390769958496 grad: 1.5282795394083397\n",
      "epoch: 50 loss: 2.302640199661255 grad: 1.531728649153448\n",
      "epoch: 51 loss: 2.3027892112731934 grad: 1.523659151895637\n",
      "epoch: 52 loss: 2.3022048473358154 grad: 1.5260301177271656\n",
      "epoch: 53 loss: 2.3023440837860107 grad: 1.5396469031785807\n",
      "epoch: 54 loss: 2.3029961585998535 grad: 1.5236938197021594\n",
      "epoch: 55 loss: 2.3028171062469482 grad: 1.5306659576165238\n",
      "epoch: 56 loss: 2.3025357723236084 grad: 1.5387852722778916\n",
      "epoch: 57 loss: 2.3023815155029297 grad: 1.5155859402628498\n",
      "epoch: 58 loss: 2.3019065856933594 grad: 1.5459822914045718\n",
      "epoch: 59 loss: 2.3024816513061523 grad: 1.5424998697384984\n",
      "epoch: 60 loss: 2.301635980606079 grad: 1.5359617025805785\n",
      "epoch: 61 loss: 2.301957368850708 grad: 1.5360350416925188\n",
      "epoch: 62 loss: 2.3029286861419678 grad: 1.5196792067930338\n",
      "epoch: 63 loss: 2.3024914264678955 grad: 1.5261652286234682\n",
      "epoch: 64 loss: 2.3023250102996826 grad: 1.539761913652044\n",
      "epoch: 65 loss: 2.302443265914917 grad: 1.5296040255472891\n",
      "epoch: 66 loss: 2.302302122116089 grad: 1.5331628609555847\n",
      "epoch: 67 loss: 2.3023884296417236 grad: 1.533723852665548\n",
      "epoch: 68 loss: 2.3022427558898926 grad: 1.5405453967507041\n",
      "epoch: 69 loss: 2.302490472793579 grad: 1.5253079001152414\n",
      "epoch: 70 loss: 2.302163600921631 grad: 1.5268902148190324\n",
      "epoch: 71 loss: 2.302621603012085 grad: 1.5392380548929352\n",
      "epoch: 72 loss: 2.302215814590454 grad: 1.5305826118796146\n",
      "epoch: 73 loss: 2.3019323348999023 grad: 1.5367832079969554\n",
      "epoch: 74 loss: 2.3028934001922607 grad: 1.531443865515203\n",
      "epoch: 75 loss: 2.3019566535949707 grad: 1.5315381077798231\n",
      "epoch: 76 loss: 2.3016722202301025 grad: 1.545175050121052\n",
      "epoch: 77 loss: 2.301629066467285 grad: 1.5447952134224276\n",
      "epoch: 78 loss: 2.30263614654541 grad: 1.5257585157902676\n",
      "epoch: 79 loss: 2.3022730350494385 grad: 1.5295105310626298\n",
      "epoch: 80 loss: 2.3018174171447754 grad: 1.5388937509666745\n",
      "epoch: 81 loss: 2.3025572299957275 grad: 1.5330247831963268\n",
      "epoch: 82 loss: 2.3018290996551514 grad: 1.538807568205003\n",
      "epoch: 83 loss: 2.3018248081207275 grad: 1.535725682286457\n",
      "epoch: 84 loss: 2.301332473754883 grad: 1.5417658972576083\n",
      "epoch: 85 loss: 2.30250883102417 grad: 1.5241878141006011\n",
      "epoch: 86 loss: 2.3018362522125244 grad: 1.5399514971696402\n",
      "epoch: 87 loss: 2.301813840866089 grad: 1.540260640654846\n",
      "epoch: 88 loss: 2.3019802570343018 grad: 1.5333277205068117\n",
      "epoch: 89 loss: 2.302312135696411 grad: 1.540028626230427\n",
      "epoch: 90 loss: 2.302386522293091 grad: 1.527107676454184\n",
      "epoch: 91 loss: 2.301969051361084 grad: 1.549345815585675\n",
      "epoch: 92 loss: 2.3022472858428955 grad: 1.5396028721948998\n",
      "epoch: 93 loss: 2.302149772644043 grad: 1.5406660759906536\n",
      "epoch: 94 loss: 2.302058219909668 grad: 1.5312360527108437\n",
      "epoch: 95 loss: 2.301515817642212 grad: 1.5433393448132962\n",
      "epoch: 96 loss: 2.301748275756836 grad: 1.5355633239036366\n",
      "epoch: 97 loss: 2.3021316528320312 grad: 1.5370195640716702\n",
      "epoch: 98 loss: 2.3014962673187256 grad: 1.5584268734276678\n",
      "epoch: 99 loss: 2.3017513751983643 grad: 1.545858760101957\n",
      "epoch: 100 loss: 2.302117347717285 grad: 1.5504215876424006\n",
      "epoch: 101 loss: 2.301762819290161 grad: 1.5400277665938207\n",
      "epoch: 102 loss: 2.302000045776367 grad: 1.5417318614994338\n",
      "epoch: 103 loss: 2.3015847206115723 grad: 1.5488288020049887\n",
      "epoch: 104 loss: 2.301497459411621 grad: 1.559769550061208\n",
      "epoch: 105 loss: 2.301619291305542 grad: 1.5511281762017115\n",
      "epoch: 106 loss: 2.301658868789673 grad: 1.5496275759623608\n",
      "epoch: 107 loss: 2.3020496368408203 grad: 1.5389738808485813\n",
      "epoch: 108 loss: 2.3017325401306152 grad: 1.5476765758487292\n",
      "epoch: 109 loss: 2.3016107082366943 grad: 1.5532617559453237\n",
      "epoch: 110 loss: 2.301356792449951 grad: 1.5547096546654338\n",
      "epoch: 111 loss: 2.3016254901885986 grad: 1.5427992454848238\n",
      "epoch: 112 loss: 2.3014185428619385 grad: 1.5508013151194309\n",
      "epoch: 113 loss: 2.3012425899505615 grad: 1.5540129748590674\n",
      "epoch: 114 loss: 2.3016762733459473 grad: 1.5394798561187817\n",
      "epoch: 115 loss: 2.3014135360717773 grad: 1.550812394919968\n",
      "epoch: 116 loss: 2.3023884296417236 grad: 1.5413030711860056\n",
      "epoch: 117 loss: 2.3012633323669434 grad: 1.5557469138062545\n",
      "epoch: 118 loss: 2.301565647125244 grad: 1.5461194616250902\n",
      "epoch: 119 loss: 2.3008861541748047 grad: 1.5612542496325212\n",
      "epoch: 120 loss: 2.30202054977417 grad: 1.5457796879216201\n",
      "epoch: 121 loss: 2.301436424255371 grad: 1.5600090133643427\n",
      "epoch: 122 loss: 2.301380157470703 grad: 1.5602759546988334\n",
      "epoch: 123 loss: 2.301436185836792 grad: 1.5649421412113405\n",
      "epoch: 124 loss: 2.301332473754883 grad: 1.5607445796171853\n",
      "epoch: 125 loss: 2.301054000854492 grad: 1.5574255812735784\n",
      "epoch: 126 loss: 2.301072835922241 grad: 1.5540191772013223\n",
      "epoch: 127 loss: 2.3015942573547363 grad: 1.5510352679070025\n",
      "epoch: 128 loss: 2.3011505603790283 grad: 1.5655196245726464\n",
      "epoch: 129 loss: 2.3012747764587402 grad: 1.56213772164229\n",
      "epoch: 130 loss: 2.3010222911834717 grad: 1.5707829272603646\n",
      "epoch: 131 loss: 2.3018903732299805 grad: 1.5597375380466618\n",
      "epoch: 132 loss: 2.301150321960449 grad: 1.573138363670469\n",
      "epoch: 133 loss: 2.3005409240722656 grad: 1.5817811433669358\n",
      "epoch: 134 loss: 2.3013856410980225 grad: 1.56627816125004\n",
      "epoch: 135 loss: 2.301356315612793 grad: 1.566543133618931\n",
      "epoch: 136 loss: 2.300938606262207 grad: 1.575818663777133\n",
      "epoch: 137 loss: 2.3012988567352295 grad: 1.5606452842235625\n",
      "epoch: 138 loss: 2.301365852355957 grad: 1.5733122732749\n",
      "epoch: 139 loss: 2.3017168045043945 grad: 1.5541544925488\n",
      "epoch: 140 loss: 2.301103115081787 grad: 1.5783627592378282\n",
      "epoch: 141 loss: 2.3011953830718994 grad: 1.5818386180307864\n",
      "epoch: 142 loss: 2.301154613494873 grad: 1.5864801674818856\n",
      "epoch: 143 loss: 2.3010947704315186 grad: 1.581651719647371\n",
      "epoch: 144 loss: 2.300130844116211 grad: 1.5939748561848694\n",
      "epoch: 145 loss: 2.300527334213257 grad: 1.5908222826205134\n",
      "epoch: 146 loss: 2.3003926277160645 grad: 1.579142666512376\n",
      "epoch: 147 loss: 2.3003032207489014 grad: 1.6043945908978847\n",
      "epoch: 148 loss: 2.2998509407043457 grad: 1.5984449978115864\n",
      "epoch: 149 loss: 2.3002936840057373 grad: 1.6051532989774373\n",
      "epoch: 150 loss: 2.3004374504089355 grad: 1.5944909355935775\n",
      "epoch: 151 loss: 2.300236701965332 grad: 1.602759566577521\n",
      "epoch: 152 loss: 2.299550771713257 grad: 1.6184796643635584\n",
      "epoch: 153 loss: 2.300452470779419 grad: 1.598951003408902\n",
      "epoch: 154 loss: 2.300572395324707 grad: 1.6074845591035214\n",
      "epoch: 155 loss: 2.3001604080200195 grad: 1.606192747306537\n",
      "epoch: 156 loss: 2.3004350662231445 grad: 1.5881543398117794\n",
      "epoch: 157 loss: 2.299856424331665 grad: 1.62317033406044\n",
      "epoch: 158 loss: 2.3002824783325195 grad: 1.619696997726957\n",
      "epoch: 159 loss: 2.3004496097564697 grad: 1.6093866684426006\n",
      "epoch: 160 loss: 2.3000192642211914 grad: 1.6228477502027379\n",
      "epoch: 161 loss: 2.299532413482666 grad: 1.6243924618798442\n",
      "epoch: 162 loss: 2.30002760887146 grad: 1.6365578557689866\n",
      "epoch: 163 loss: 2.2995898723602295 grad: 1.6283293474310387\n",
      "epoch: 164 loss: 2.2998695373535156 grad: 1.6245964258162688\n",
      "epoch: 165 loss: 2.2993381023406982 grad: 1.6216224157288375\n",
      "epoch: 166 loss: 2.2992191314697266 grad: 1.6508167836342067\n",
      "epoch: 167 loss: 2.2994163036346436 grad: 1.6555136284303098\n",
      "epoch: 168 loss: 2.2990665435791016 grad: 1.660772100837517\n",
      "epoch: 169 loss: 2.2995150089263916 grad: 1.6526027913057497\n",
      "epoch: 170 loss: 2.2989578247070312 grad: 1.6669276581803663\n",
      "epoch: 171 loss: 2.2995223999023438 grad: 1.6686135318873094\n",
      "epoch: 172 loss: 2.2992355823516846 grad: 1.6659627786323812\n",
      "epoch: 173 loss: 2.2988264560699463 grad: 1.6910494097604578\n",
      "epoch: 174 loss: 2.2991013526916504 grad: 1.6938316054172844\n",
      "epoch: 175 loss: 2.2984120845794678 grad: 1.7119637092848914\n",
      "epoch: 176 loss: 2.297520637512207 grad: 1.7151073769958216\n",
      "epoch: 177 loss: 2.2986061573028564 grad: 1.6978380832163291\n",
      "epoch: 178 loss: 2.2981936931610107 grad: 1.7205101650518675\n",
      "epoch: 179 loss: 2.2981109619140625 grad: 1.727554696157486\n",
      "epoch: 180 loss: 2.2979979515075684 grad: 1.742478503472364\n",
      "epoch: 181 loss: 2.29771089553833 grad: 1.7529161823931934\n",
      "epoch: 182 loss: 2.2985894680023193 grad: 1.7350102802738547\n",
      "epoch: 183 loss: 2.2971267700195312 grad: 1.7775242504153757\n",
      "epoch: 184 loss: 2.2972934246063232 grad: 1.775821149962703\n",
      "epoch: 185 loss: 2.2963829040527344 grad: 1.8151738968260203\n",
      "epoch: 186 loss: 2.2965047359466553 grad: 1.8285050829798575\n",
      "epoch: 187 loss: 2.295685052871704 grad: 1.8301964774690864\n",
      "epoch: 188 loss: 2.296074867248535 grad: 1.8482542345854676\n",
      "epoch: 189 loss: 2.295703411102295 grad: 1.8718715627263818\n",
      "epoch: 190 loss: 2.295602321624756 grad: 1.8804384639804503\n",
      "epoch: 191 loss: 2.293431282043457 grad: 1.9758841376326652\n",
      "epoch: 192 loss: 2.2952513694763184 grad: 1.9331686914573232\n",
      "epoch: 193 loss: 2.293692111968994 grad: 2.0156912820336097\n",
      "epoch: 194 loss: 2.293522834777832 grad: 2.019004512794449\n",
      "epoch: 195 loss: 2.292238473892212 grad: 2.0800718850796183\n",
      "epoch: 196 loss: 2.29267954826355 grad: 2.083767906406022\n",
      "epoch: 197 loss: 2.2908763885498047 grad: 2.150570812378271\n",
      "epoch: 198 loss: 2.289062738418579 grad: 2.189829470079747\n",
      "epoch: 199 loss: 2.2895967960357666 grad: 2.22235875336882\n",
      "epoch: 200 loss: 2.289400100708008 grad: 2.254924089211734\n",
      "epoch: 201 loss: 2.2888896465301514 grad: 2.2939894738910156\n",
      "epoch: 202 loss: 2.2862844467163086 grad: 2.359481670036321\n",
      "epoch: 203 loss: 2.285311222076416 grad: 2.390708921643506\n",
      "epoch: 204 loss: 2.2842020988464355 grad: 2.482585561206742\n",
      "epoch: 205 loss: 2.2823803424835205 grad: 2.479864525316756\n",
      "epoch: 206 loss: 2.2809157371520996 grad: 2.5565099853039204\n",
      "epoch: 207 loss: 2.279214859008789 grad: 2.528764044381826\n",
      "epoch: 208 loss: 2.275722026824951 grad: 2.5452502413453266\n",
      "epoch: 209 loss: 2.2744107246398926 grad: 2.5174197825152307\n",
      "epoch: 210 loss: 2.27217698097229 grad: 2.4434012910868557\n",
      "epoch: 211 loss: 2.2709267139434814 grad: 2.5021008394052466\n",
      "epoch: 212 loss: 2.2691915035247803 grad: 2.4969933613920436\n",
      "epoch: 213 loss: 2.268699884414673 grad: 2.4439046030073235\n",
      "epoch: 214 loss: 2.264899492263794 grad: 2.3669443739142033\n",
      "epoch: 215 loss: 2.263296365737915 grad: 2.3701395592023986\n",
      "epoch: 216 loss: 2.2601475715637207 grad: 2.2973479450059435\n",
      "epoch: 217 loss: 2.2610762119293213 grad: 2.2729822020693167\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 218 loss: 2.258265972137451 grad: 2.294876620299109\n",
      "epoch: 219 loss: 2.25773549079895 grad: 2.195196610271177\n",
      "epoch: 220 loss: 2.2556941509246826 grad: 2.1279625071707877\n",
      "epoch: 221 loss: 2.2542576789855957 grad: 2.0796599165344287\n",
      "epoch: 222 loss: 2.252755641937256 grad: 2.0516240674640156\n",
      "epoch: 223 loss: 2.2537624835968018 grad: 2.047844059724686\n",
      "epoch: 224 loss: 2.251457929611206 grad: 1.9833010414519185\n",
      "epoch: 225 loss: 2.250713586807251 grad: 1.9635783981103154\n",
      "epoch: 226 loss: 2.2515904903411865 grad: 1.9726802144358526\n",
      "epoch: 227 loss: 2.248377561569214 grad: 1.8926262236255709\n",
      "epoch: 228 loss: 2.2498178482055664 grad: 1.9097113530742862\n",
      "epoch: 229 loss: 2.247657537460327 grad: 1.8504144923192345\n",
      "epoch: 230 loss: 2.2482237815856934 grad: 1.901328616376434\n",
      "epoch: 231 loss: 2.247603416442871 grad: 1.8426657189238107\n",
      "epoch: 232 loss: 2.2460310459136963 grad: 1.8210642763805236\n",
      "epoch: 233 loss: 2.2447705268859863 grad: 1.7811255755738193\n",
      "epoch: 234 loss: 2.244868755340576 grad: 1.786242370440122\n",
      "epoch: 235 loss: 2.245565891265869 grad: 1.760875693304346\n",
      "epoch: 236 loss: 2.244842767715454 grad: 1.72915630546465\n",
      "epoch: 237 loss: 2.2429745197296143 grad: 1.718502248452592\n",
      "epoch: 238 loss: 2.2423672676086426 grad: 1.7329128054136942\n",
      "epoch: 239 loss: 2.2416329383850098 grad: 1.6844797508609999\n",
      "epoch: 240 loss: 2.2424707412719727 grad: 1.6920695827150392\n",
      "epoch: 241 loss: 2.241424798965454 grad: 1.657688154883328\n",
      "epoch: 242 loss: 2.2409608364105225 grad: 1.6586455380071015\n",
      "epoch: 243 loss: 2.2408297061920166 grad: 1.6283454686968721\n",
      "epoch: 244 loss: 2.240833044052124 grad: 1.637068533155668\n",
      "epoch: 245 loss: 2.240480661392212 grad: 1.6587363961337518\n",
      "epoch: 246 loss: 2.239504814147949 grad: 1.587761452434481\n",
      "epoch: 247 loss: 2.2384965419769287 grad: 1.5519860546540705\n",
      "epoch: 248 loss: 2.2388200759887695 grad: 1.5865928622439416\n",
      "epoch: 249 loss: 2.239565134048462 grad: 1.584120285676955\n",
      "epoch: 250 loss: 2.2385661602020264 grad: 1.5794281514568462\n",
      "epoch: 251 loss: 2.2391669750213623 grad: 1.6482111497039331\n",
      "epoch: 252 loss: 2.237602710723877 grad: 1.5786466831803352\n",
      "epoch: 253 loss: 2.238140344619751 grad: 1.5685620285858888\n",
      "epoch: 254 loss: 2.2376534938812256 grad: 1.5678489125418729\n",
      "epoch: 255 loss: 2.2349436283111572 grad: 1.4897861086970403\n",
      "epoch: 256 loss: 2.236048460006714 grad: 1.5619318982168648\n",
      "epoch: 257 loss: 2.2363460063934326 grad: 1.5482495515810561\n",
      "epoch: 258 loss: 2.2351181507110596 grad: 1.530407303354762\n",
      "epoch: 259 loss: 2.2354817390441895 grad: 1.5716100558028778\n",
      "epoch: 260 loss: 2.2357687950134277 grad: 1.523052621019324\n",
      "epoch: 261 loss: 2.2364046573638916 grad: 1.5718078234247745\n",
      "epoch: 262 loss: 2.235450506210327 grad: 1.5089547307570539\n",
      "epoch: 263 loss: 2.234994411468506 grad: 1.5276671076001274\n",
      "epoch: 264 loss: 2.234626293182373 grad: 1.4739354216837368\n",
      "epoch: 265 loss: 2.232525587081909 grad: 1.4174752779996083\n",
      "epoch: 266 loss: 2.2345428466796875 grad: 1.5268330009273505\n",
      "epoch: 267 loss: 2.2343811988830566 grad: 1.5106276255821631\n",
      "epoch: 268 loss: 2.234544515609741 grad: 1.522977351469712\n",
      "epoch: 269 loss: 2.2338359355926514 grad: 1.5223117235046442\n",
      "epoch: 270 loss: 2.2335941791534424 grad: 1.554920379791246\n",
      "epoch: 271 loss: 2.232863187789917 grad: 1.4834840152475481\n",
      "epoch: 272 loss: 2.2331430912017822 grad: 1.4878649900571281\n",
      "epoch: 273 loss: 2.2316958904266357 grad: 1.4314141369550415\n",
      "epoch: 274 loss: 2.2318613529205322 grad: 1.4812512285915012\n",
      "epoch: 275 loss: 2.231931209564209 grad: 1.4353022986601682\n",
      "epoch: 276 loss: 2.2329049110412598 grad: 1.5257031949872653\n",
      "epoch: 277 loss: 2.231576919555664 grad: 1.476274996873967\n",
      "epoch: 278 loss: 2.231553792953491 grad: 1.4695916273353977\n",
      "epoch: 279 loss: 2.2317543029785156 grad: 1.4819416413434767\n",
      "epoch: 280 loss: 2.2323758602142334 grad: 1.5554904312963436\n",
      "epoch: 281 loss: 2.2301430702209473 grad: 1.416962006308567\n",
      "epoch: 282 loss: 2.2302589416503906 grad: 1.4405635766951101\n",
      "epoch: 283 loss: 2.230607032775879 grad: 1.4412259757130716\n",
      "epoch: 284 loss: 2.231325149536133 grad: 1.4673142430339274\n",
      "epoch: 285 loss: 2.2302680015563965 grad: 1.4326975754155438\n",
      "epoch: 286 loss: 2.228987693786621 grad: 1.444834555950134\n",
      "epoch: 287 loss: 2.23036527633667 grad: 1.4034438592710694\n",
      "epoch: 288 loss: 2.2288007736206055 grad: 1.3869856252955894\n",
      "epoch: 289 loss: 2.22975754737854 grad: 1.4427447911935845\n",
      "epoch: 290 loss: 2.229539632797241 grad: 1.489920902651705\n",
      "epoch: 291 loss: 2.228689670562744 grad: 1.406055903818\n",
      "epoch: 292 loss: 2.228929042816162 grad: 1.4048537925635982\n",
      "epoch: 293 loss: 2.2300453186035156 grad: 1.4952952410962934\n",
      "epoch: 294 loss: 2.228881597518921 grad: 1.4040184761896464\n",
      "epoch: 295 loss: 2.2288591861724854 grad: 1.4444779735908562\n",
      "epoch: 296 loss: 2.2291219234466553 grad: 1.4566435472936266\n",
      "epoch: 297 loss: 2.2282299995422363 grad: 1.3877237025881186\n",
      "epoch: 298 loss: 2.226022958755493 grad: 1.3370561742478804\n",
      "epoch: 299 loss: 2.2286956310272217 grad: 1.435781569953727\n",
      "epoch: 300 loss: 2.228066921234131 grad: 1.4494204790468166\n",
      "epoch: 301 loss: 2.2281455993652344 grad: 1.5188144557787815\n",
      "epoch: 302 loss: 2.2270987033843994 grad: 1.3764993304346083\n",
      "epoch: 303 loss: 2.2273590564727783 grad: 1.4275330420332177\n",
      "epoch: 304 loss: 2.22739315032959 grad: 1.4139137665800277\n",
      "epoch: 305 loss: 2.2266123294830322 grad: 1.3451684994571325\n",
      "epoch: 306 loss: 2.2270302772521973 grad: 1.398807951720387\n",
      "epoch: 307 loss: 2.2261781692504883 grad: 1.4156964313560387\n",
      "epoch: 308 loss: 2.2260243892669678 grad: 1.4248440242889855\n",
      "epoch: 309 loss: 2.2262187004089355 grad: 1.424153724286173\n",
      "epoch: 310 loss: 2.226255416870117 grad: 1.3503805847435688\n",
      "epoch: 311 loss: 2.2252795696258545 grad: 1.3436784903807122\n",
      "epoch: 312 loss: 2.225714683532715 grad: 1.4013830006643686\n",
      "epoch: 313 loss: 2.225855827331543 grad: 1.4167881662391923\n",
      "epoch: 314 loss: 2.226539134979248 grad: 1.473567196227137\n",
      "epoch: 315 loss: 2.225867986679077 grad: 1.4444671419563717\n",
      "epoch: 316 loss: 2.225616216659546 grad: 1.4049055225766516\n",
      "epoch: 317 loss: 2.2260007858276367 grad: 1.4877501693221606\n",
      "epoch: 318 loss: 2.22501540184021 grad: 1.397833046719565\n",
      "epoch: 319 loss: 2.2259387969970703 grad: 1.46979690736921\n",
      "epoch: 320 loss: 2.2250313758850098 grad: 1.3876463278983941\n",
      "epoch: 321 loss: 2.224095344543457 grad: 1.3803948268076287\n",
      "epoch: 322 loss: 2.2248594760894775 grad: 1.4436855510594175\n",
      "epoch: 323 loss: 2.2246620655059814 grad: 1.4764454701216891\n",
      "epoch: 324 loss: 2.2240381240844727 grad: 1.4157927543689897\n",
      "epoch: 325 loss: 2.22501540184021 grad: 1.3788698680148208\n",
      "epoch: 326 loss: 2.224133253097534 grad: 1.4574911380630164\n",
      "epoch: 327 loss: 2.223936080932617 grad: 1.3789389549074547\n",
      "epoch: 328 loss: 2.2239861488342285 grad: 1.4500808015628348\n",
      "epoch: 329 loss: 2.2250888347625732 grad: 1.4861184625816162\n",
      "epoch: 330 loss: 2.223395586013794 grad: 1.4256764170565894\n",
      "epoch: 331 loss: 2.2235701084136963 grad: 1.4127955510491683\n",
      "epoch: 332 loss: 2.2222297191619873 grad: 1.3519316459673323\n",
      "epoch: 333 loss: 2.224015474319458 grad: 1.424466507827183\n",
      "epoch: 334 loss: 2.2226343154907227 grad: 1.3806215851708123\n",
      "epoch: 335 loss: 2.223055362701416 grad: 1.4098620856668622\n",
      "epoch: 336 loss: 2.222914695739746 grad: 1.4346250264798217\n",
      "epoch: 337 loss: 2.223416566848755 grad: 1.5203522639940419\n",
      "epoch: 338 loss: 2.2231061458587646 grad: 1.464447581804254\n",
      "epoch: 339 loss: 2.222360372543335 grad: 1.4267470626389638\n",
      "epoch: 340 loss: 2.2215046882629395 grad: 1.3661917585358467\n",
      "epoch: 341 loss: 2.2213549613952637 grad: 1.4094173088854562\n",
      "epoch: 342 loss: 2.2213239669799805 grad: 1.3734423708436745\n",
      "epoch: 343 loss: 2.222135305404663 grad: 1.4498474518066302\n",
      "epoch: 344 loss: 2.22123384475708 grad: 1.3822169565736124\n",
      "epoch: 345 loss: 2.221057176589966 grad: 1.4604536311161365\n",
      "epoch: 346 loss: 2.222057342529297 grad: 1.436977422016392\n",
      "epoch: 347 loss: 2.221088409423828 grad: 1.3785399626071995\n",
      "epoch: 348 loss: 2.2216949462890625 grad: 1.4547302146157663\n",
      "epoch: 349 loss: 2.2217869758605957 grad: 1.4406716244845903\n",
      "epoch: 350 loss: 2.220982074737549 grad: 1.4349786622065401\n",
      "epoch: 351 loss: 2.221191644668579 grad: 1.4069922071390062\n",
      "epoch: 352 loss: 2.2202935218811035 grad: 1.369475389309671\n",
      "epoch: 353 loss: 2.2208163738250732 grad: 1.414581253285712\n",
      "epoch: 354 loss: 2.2212677001953125 grad: 1.4323714467297708\n",
      "epoch: 355 loss: 2.2208428382873535 grad: 1.4437307299942606\n",
      "epoch: 356 loss: 2.2199180126190186 grad: 1.4589209534072627\n",
      "epoch: 357 loss: 2.2208619117736816 grad: 1.4200723049423052\n",
      "epoch: 358 loss: 2.2206857204437256 grad: 1.4906201410561888\n",
      "epoch: 359 loss: 2.220365524291992 grad: 1.5287246527390494\n",
      "epoch: 360 loss: 2.219625234603882 grad: 1.4506327685741116\n",
      "epoch: 361 loss: 2.219839334487915 grad: 1.4422701274558518\n",
      "epoch: 362 loss: 2.2193992137908936 grad: 1.4718696563153542\n",
      "epoch: 363 loss: 2.2192840576171875 grad: 1.4935541979669194\n",
      "epoch: 364 loss: 2.2189793586730957 grad: 1.505990402340623\n",
      "epoch: 365 loss: 2.2197206020355225 grad: 1.5276161287818844\n",
      "epoch: 366 loss: 2.2198657989501953 grad: 1.5273148911997736\n",
      "epoch: 367 loss: 2.219024896621704 grad: 1.473245923205959\n",
      "epoch: 368 loss: 2.218043565750122 grad: 1.4777483383788623\n",
      "epoch: 369 loss: 2.2186119556427 grad: 1.525065506039749\n",
      "epoch: 370 loss: 2.217745780944824 grad: 1.4767215363533488\n",
      "epoch: 371 loss: 2.2173430919647217 grad: 1.4362372882083976\n",
      "epoch: 372 loss: 2.2175400257110596 grad: 1.6120309468953766\n",
      "epoch: 373 loss: 2.2180161476135254 grad: 1.5374961955350868\n",
      "epoch: 374 loss: 2.217329502105713 grad: 1.4774526042830465\n",
      "epoch: 375 loss: 2.217988967895508 grad: 1.572436371749814\n",
      "epoch: 376 loss: 2.216622829437256 grad: 1.4953213009876125\n",
      "epoch: 377 loss: 2.2168493270874023 grad: 1.5062015811184657\n",
      "epoch: 378 loss: 2.216146469116211 grad: 1.5234901745275164\n",
      "epoch: 379 loss: 2.2165608406066895 grad: 1.476005786416372\n",
      "epoch: 380 loss: 2.216177225112915 grad: 1.5145391622421494\n",
      "epoch: 381 loss: 2.216918706893921 grad: 1.601529379842788\n",
      "epoch: 382 loss: 2.216477870941162 grad: 1.5187912987848182\n",
      "epoch: 383 loss: 2.215179681777954 grad: 1.567606510313612\n",
      "epoch: 384 loss: 2.215547800064087 grad: 1.5584026675279592\n",
      "epoch: 385 loss: 2.2150607109069824 grad: 1.5867429926995158\n",
      "epoch: 386 loss: 2.215221643447876 grad: 1.52665403248587\n",
      "epoch: 387 loss: 2.215181350708008 grad: 1.6077899213728777\n",
      "epoch: 388 loss: 2.2145020961761475 grad: 1.554989431306557\n",
      "epoch: 389 loss: 2.2163469791412354 grad: 1.64976820890193\n",
      "epoch: 390 loss: 2.215223550796509 grad: 1.5996046311994423\n",
      "epoch: 391 loss: 2.21466064453125 grad: 1.5450570472693514\n",
      "epoch: 392 loss: 2.2130119800567627 grad: 1.5965543715689805\n",
      "epoch: 393 loss: 2.2139759063720703 grad: 1.7082474599943482\n",
      "epoch: 394 loss: 2.213756799697876 grad: 1.6091296569691853\n",
      "epoch: 395 loss: 2.2131505012512207 grad: 1.6327052045768748\n",
      "epoch: 396 loss: 2.2137157917022705 grad: 1.6495222671138536\n",
      "epoch: 397 loss: 2.2117886543273926 grad: 1.6622184331044703\n",
      "epoch: 398 loss: 2.2130887508392334 grad: 1.6605165448623695\n",
      "epoch: 399 loss: 2.213020086288452 grad: 1.6873983980474314\n",
      "epoch: 400 loss: 2.211057186126709 grad: 1.6853242658636725\n",
      "epoch: 401 loss: 2.211970090866089 grad: 1.7329802897385513\n",
      "epoch: 402 loss: 2.211280345916748 grad: 1.666486477756518\n",
      "epoch: 403 loss: 2.2110328674316406 grad: 1.7833558082809702\n",
      "epoch: 404 loss: 2.2112038135528564 grad: 1.7798109752761702\n",
      "epoch: 405 loss: 2.2111339569091797 grad: 1.7075006488899125\n",
      "epoch: 406 loss: 2.2093329429626465 grad: 1.6719626312380627\n",
      "epoch: 407 loss: 2.209049701690674 grad: 1.7658240801695408\n",
      "epoch: 408 loss: 2.2098796367645264 grad: 1.8347040656344256\n",
      "epoch: 409 loss: 2.208649158477783 grad: 1.8366959084394492\n",
      "epoch: 410 loss: 2.2084457874298096 grad: 1.7059346130117774\n",
      "epoch: 411 loss: 2.2082419395446777 grad: 1.7586499386123338\n",
      "epoch: 412 loss: 2.2089662551879883 grad: 1.8115179782256572\n",
      "epoch: 413 loss: 2.2083518505096436 grad: 1.8500105822458863\n",
      "epoch: 414 loss: 2.2079756259918213 grad: 1.8725057385643826\n",
      "epoch: 415 loss: 2.208620309829712 grad: 1.7740249787993168\n",
      "epoch: 416 loss: 2.208500385284424 grad: 1.8430848761409935\n",
      "epoch: 417 loss: 2.2064707279205322 grad: 1.8669302982540565\n",
      "epoch: 418 loss: 2.2076923847198486 grad: 1.8909475553618182\n",
      "epoch: 419 loss: 2.2066140174865723 grad: 1.9336023742632409\n",
      "epoch: 420 loss: 2.2058517932891846 grad: 1.8840708954311494\n",
      "epoch: 421 loss: 2.2050631046295166 grad: 1.978261842205751\n",
      "epoch: 422 loss: 2.204561471939087 grad: 1.9257025692781935\n",
      "epoch: 423 loss: 2.204578399658203 grad: 1.9793904775084692\n",
      "epoch: 424 loss: 2.2031450271606445 grad: 1.9672611730343232\n",
      "epoch: 425 loss: 2.202324628829956 grad: 2.001254420021608\n",
      "epoch: 426 loss: 2.2025411128997803 grad: 1.9584003372546581\n",
      "epoch: 427 loss: 2.203462839126587 grad: 1.9119542438614492\n",
      "epoch: 428 loss: 2.2021560668945312 grad: 1.9841213427310336\n",
      "epoch: 429 loss: 2.2000982761383057 grad: 1.97272833921237\n",
      "epoch: 430 loss: 2.2000274658203125 grad: 1.996567322778338\n",
      "epoch: 431 loss: 2.1992361545562744 grad: 2.0027497050792187\n",
      "epoch: 432 loss: 2.19966983795166 grad: 2.0272331085843254\n",
      "epoch: 433 loss: 2.2000677585601807 grad: 2.1059647369538506\n",
      "epoch: 434 loss: 2.1993825435638428 grad: 2.0658747065601695\n",
      "epoch: 435 loss: 2.198737621307373 grad: 2.0158397474304017\n",
      "epoch: 436 loss: 2.197402238845825 grad: 2.0554115053040847\n",
      "epoch: 437 loss: 2.1999635696411133 grad: 2.0899033037971497\n",
      "epoch: 438 loss: 2.1977224349975586 grad: 2.0591228966811848\n",
      "epoch: 439 loss: 2.197162389755249 grad: 2.155919662002282\n",
      "epoch: 440 loss: 2.1975836753845215 grad: 2.088017406069585\n",
      "epoch: 441 loss: 2.1953017711639404 grad: 2.108664685071239\n",
      "epoch: 442 loss: 2.1954119205474854 grad: 2.0304336229520334\n",
      "epoch: 443 loss: 2.1939492225646973 grad: 2.066384287746919\n",
      "epoch: 444 loss: 2.19528865814209 grad: 2.1682355004299936\n",
      "epoch: 445 loss: 2.1955950260162354 grad: 2.086991107072829\n",
      "epoch: 446 loss: 2.1933813095092773 grad: 2.14458986932397\n",
      "epoch: 447 loss: 2.1938629150390625 grad: 2.136370177589549\n",
      "epoch: 448 loss: 2.1928744316101074 grad: 2.127425895661988\n",
      "epoch: 449 loss: 2.1932857036590576 grad: 2.075479064532186\n",
      "epoch: 450 loss: 2.194404125213623 grad: 2.13869788674342\n",
      "epoch: 451 loss: 2.1902542114257812 grad: 2.1118595376887934\n",
      "epoch: 452 loss: 2.1928067207336426 grad: 2.1606221675396053\n",
      "epoch: 453 loss: 2.190361738204956 grad: 2.0910390784246995\n",
      "epoch: 454 loss: 2.1883041858673096 grad: 2.161667427785384\n",
      "epoch: 455 loss: 2.1903042793273926 grad: 2.18227229347556\n",
      "epoch: 456 loss: 2.189181089401245 grad: 2.132392883555786\n",
      "epoch: 457 loss: 2.189497709274292 grad: 2.219127057994243\n",
      "epoch: 458 loss: 2.1886024475097656 grad: 2.2069138766502934\n",
      "epoch: 459 loss: 2.188511610031128 grad: 2.168915103461283\n",
      "epoch: 460 loss: 2.187668561935425 grad: 2.1433633363247657\n",
      "epoch: 461 loss: 2.187912702560425 grad: 2.119305396818423\n",
      "epoch: 462 loss: 2.1879923343658447 grad: 2.100568523894744\n",
      "epoch: 463 loss: 2.1874964237213135 grad: 2.179013375488539\n",
      "epoch: 464 loss: 2.1856801509857178 grad: 2.2278573486625053\n",
      "epoch: 465 loss: 2.186107635498047 grad: 2.2138027780271683\n",
      "epoch: 466 loss: 2.185068368911743 grad: 2.116154858426723\n",
      "epoch: 467 loss: 2.1839616298675537 grad: 2.1047947609405373\n",
      "epoch: 468 loss: 2.1858887672424316 grad: 2.115327577666557\n",
      "epoch: 469 loss: 2.1831958293914795 grad: 2.141429803834947\n",
      "epoch: 470 loss: 2.184842109680176 grad: 2.21849411416481\n",
      "epoch: 471 loss: 2.1851909160614014 grad: 2.1973911667693526\n",
      "epoch: 472 loss: 2.182683229446411 grad: 2.145186435941252\n",
      "epoch: 473 loss: 2.183213949203491 grad: 2.2424483677475817\n",
      "epoch: 474 loss: 2.182100296020508 grad: 2.198021647418731\n",
      "epoch: 475 loss: 2.183385133743286 grad: 2.2430817441153708\n",
      "epoch: 476 loss: 2.1815245151519775 grad: 2.2677126067287716\n",
      "epoch: 477 loss: 2.1800248622894287 grad: 2.2885288635900776\n",
      "epoch: 478 loss: 2.179938793182373 grad: 2.249350068377449\n",
      "epoch: 479 loss: 2.1797597408294678 grad: 2.2169188556560715\n",
      "epoch: 480 loss: 2.1799514293670654 grad: 2.1696851835271995\n",
      "epoch: 481 loss: 2.180579900741577 grad: 2.302762612633939\n",
      "epoch: 482 loss: 2.1779367923736572 grad: 2.2855134531042522\n",
      "epoch: 483 loss: 2.179831027984619 grad: 2.269486876483637\n",
      "epoch: 484 loss: 2.176377534866333 grad: 2.24571911450882\n",
      "epoch: 485 loss: 2.1792640686035156 grad: 2.2191360406448237\n",
      "epoch: 486 loss: 2.1786763668060303 grad: 2.295688828758319\n",
      "epoch: 487 loss: 2.176445960998535 grad: 2.3092449229295617\n",
      "epoch: 488 loss: 2.1752874851226807 grad: 2.342910968617255\n",
      "epoch: 489 loss: 2.1777124404907227 grad: 2.3409382989888803\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 490 loss: 2.173626184463501 grad: 2.197178065588343\n",
      "epoch: 491 loss: 2.175212860107422 grad: 2.3801750898886\n",
      "epoch: 492 loss: 2.175781488418579 grad: 2.3494127567742935\n",
      "epoch: 493 loss: 2.1748368740081787 grad: 2.279024456762561\n",
      "epoch: 494 loss: 2.1740028858184814 grad: 2.290554709671553\n",
      "epoch: 495 loss: 2.1758296489715576 grad: 2.3916785196024213\n",
      "epoch: 496 loss: 2.173600196838379 grad: 2.4012635589802698\n",
      "epoch: 497 loss: 2.1723647117614746 grad: 2.4093578052725495\n",
      "epoch: 498 loss: 2.173295259475708 grad: 2.342843115071042\n",
      "epoch: 499 loss: 2.171808958053589 grad: 2.419130266721671\n",
      "2.2303716093301773\n",
      "epoch: 0 loss: 2.290409803390503 grad: 1.742264002053407\n",
      "epoch: 1 loss: 2.2398643493652344 grad: 2.2140455541555726\n",
      "epoch: 2 loss: 2.2008745670318604 grad: 2.072609248231091\n",
      "epoch: 3 loss: 2.185945987701416 grad: 2.1401665803000687\n",
      "epoch: 4 loss: 2.1777851581573486 grad: 2.129654939199561\n",
      "epoch: 5 loss: 2.171133279800415 grad: 2.1946045387562156\n",
      "epoch: 6 loss: 2.162231683731079 grad: 2.353989350300888\n",
      "epoch: 7 loss: 2.159890651702881 grad: 2.4424853086977873\n",
      "epoch: 8 loss: 2.151521682739258 grad: 2.3979313819972234\n",
      "epoch: 9 loss: 2.1507630348205566 grad: 2.7828868802392943\n",
      "epoch: 10 loss: 2.141946315765381 grad: 2.967593400813048\n",
      "epoch: 11 loss: 2.1342880725860596 grad: 3.060019762635911\n",
      "epoch: 12 loss: 2.1290202140808105 grad: 3.3715248735444177\n",
      "epoch: 13 loss: 2.1226232051849365 grad: 3.647600876189591\n",
      "epoch: 14 loss: 2.1085615158081055 grad: 3.7126839846956528\n",
      "epoch: 15 loss: 2.1060879230499268 grad: 4.059298742429486\n",
      "epoch: 16 loss: 2.097304582595825 grad: 4.151355128528343\n",
      "epoch: 17 loss: 2.0885183811187744 grad: 4.404353663462052\n",
      "epoch: 18 loss: 2.082218885421753 grad: 4.477739230870077\n",
      "epoch: 19 loss: 2.08027720451355 grad: 4.731779160443693\n",
      "epoch: 20 loss: 2.0675785541534424 grad: 5.032318208322284\n",
      "epoch: 21 loss: 2.059882640838623 grad: 4.970523640498637\n",
      "epoch: 22 loss: 2.0571060180664062 grad: 5.124470182664929\n",
      "epoch: 23 loss: 2.0508077144622803 grad: 5.408149589414871\n",
      "epoch: 24 loss: 2.0419631004333496 grad: 5.441724701030624\n",
      "epoch: 25 loss: 2.0433549880981445 grad: 5.681732498020644\n",
      "epoch: 26 loss: 2.0338218212127686 grad: 5.959375801836214\n",
      "epoch: 27 loss: 2.029562473297119 grad: 5.969929841694436\n",
      "epoch: 28 loss: 2.0270068645477295 grad: 6.104405727030502\n",
      "epoch: 29 loss: 2.021697759628296 grad: 6.427164139773046\n",
      "epoch: 30 loss: 2.0116748809814453 grad: 6.388616235586741\n",
      "epoch: 31 loss: 2.0115230083465576 grad: 6.463284723608504\n",
      "epoch: 32 loss: 1.999088168144226 grad: 6.371079630632368\n",
      "epoch: 33 loss: 2.0047521591186523 grad: 6.636100213021217\n",
      "epoch: 34 loss: 1.9997639656066895 grad: 6.830071275698996\n",
      "epoch: 35 loss: 1.9904793500900269 grad: 7.033631059969406\n",
      "epoch: 36 loss: 1.9881983995437622 grad: 7.33661371665371\n",
      "epoch: 37 loss: 1.981781005859375 grad: 7.190338331910353\n",
      "epoch: 38 loss: 1.9826505184173584 grad: 7.196971458094638\n",
      "epoch: 39 loss: 1.9724986553192139 grad: 7.450325900873554\n",
      "epoch: 40 loss: 1.9715991020202637 grad: 7.2555013099936625\n",
      "epoch: 41 loss: 1.9597140550613403 grad: 7.6847367404427915\n",
      "epoch: 42 loss: 1.9609596729278564 grad: 7.510657471190724\n",
      "epoch: 43 loss: 1.9601913690567017 grad: 7.8816394774938034\n",
      "epoch: 44 loss: 1.952609658241272 grad: 8.321395115631203\n",
      "epoch: 45 loss: 1.948347806930542 grad: 8.112377752298636\n",
      "epoch: 46 loss: 1.946812629699707 grad: 8.271665025472878\n",
      "epoch: 47 loss: 1.9432704448699951 grad: 8.222562685002766\n",
      "epoch: 48 loss: 1.9361319541931152 grad: 8.486551550823071\n",
      "epoch: 49 loss: 1.9303832054138184 grad: 7.921776094163458\n",
      "epoch: 50 loss: 1.9219483137130737 grad: 8.133388283544235\n",
      "epoch: 51 loss: 1.9187167882919312 grad: 8.085250051721694\n",
      "epoch: 52 loss: 1.9178977012634277 grad: 8.041349584000214\n",
      "epoch: 53 loss: 1.9138884544372559 grad: 8.462830605798416\n",
      "epoch: 54 loss: 1.9046202898025513 grad: 8.700242394115776\n",
      "epoch: 55 loss: 1.9041998386383057 grad: 8.399876386148943\n",
      "epoch: 56 loss: 1.9011900424957275 grad: 8.94654676983399\n",
      "epoch: 57 loss: 1.9020622968673706 grad: 8.929082650306915\n",
      "epoch: 58 loss: 1.8920342922210693 grad: 8.715965535935192\n",
      "epoch: 59 loss: 1.8926444053649902 grad: 8.657364810122148\n",
      "epoch: 60 loss: 1.889835000038147 grad: 8.542770759786464\n",
      "epoch: 61 loss: 1.8865317106246948 grad: 8.60084799847137\n",
      "epoch: 62 loss: 1.884570837020874 grad: 8.995938360838899\n",
      "epoch: 63 loss: 1.8773008584976196 grad: 8.321595062605208\n",
      "epoch: 64 loss: 1.8728892803192139 grad: 8.843498309830292\n",
      "epoch: 65 loss: 1.8711739778518677 grad: 9.235745823498638\n",
      "epoch: 66 loss: 1.8671140670776367 grad: 8.983749182148289\n",
      "epoch: 67 loss: 1.8649613857269287 grad: 8.806714962207018\n",
      "epoch: 68 loss: 1.8620374202728271 grad: 9.155067654563085\n",
      "epoch: 69 loss: 1.8599731922149658 grad: 9.437242840734562\n",
      "epoch: 70 loss: 1.8534729480743408 grad: 9.087223596190887\n",
      "epoch: 71 loss: 1.8519797325134277 grad: 9.175123712240111\n",
      "epoch: 72 loss: 1.848076581954956 grad: 9.563506085248221\n",
      "epoch: 73 loss: 1.852022409439087 grad: 9.53777887994453\n",
      "epoch: 74 loss: 1.8418604135513306 grad: 9.238023221019715\n",
      "epoch: 75 loss: 1.8375989198684692 grad: 9.637800507454408\n",
      "epoch: 76 loss: 1.8360995054244995 grad: 9.504250907915688\n",
      "epoch: 77 loss: 1.8403388261795044 grad: 9.92685857673161\n",
      "epoch: 78 loss: 1.8314212560653687 grad: 10.088749920424547\n",
      "epoch: 79 loss: 1.8235403299331665 grad: 9.65099217964425\n",
      "epoch: 80 loss: 1.8309074640274048 grad: 9.3300012689276\n",
      "epoch: 81 loss: 1.8243834972381592 grad: 10.293785007552259\n",
      "epoch: 82 loss: 1.825024127960205 grad: 10.42039695324465\n",
      "epoch: 83 loss: 1.8179303407669067 grad: 9.55649119458117\n",
      "epoch: 84 loss: 1.813429832458496 grad: 10.053329044672113\n",
      "epoch: 85 loss: 1.8066003322601318 grad: 10.16261253464553\n",
      "epoch: 86 loss: 1.8027408123016357 grad: 10.044087555377729\n",
      "epoch: 87 loss: 1.8028919696807861 grad: 10.668147328427978\n",
      "epoch: 88 loss: 1.8084412813186646 grad: 10.227457813231187\n",
      "epoch: 89 loss: 1.8035234212875366 grad: 10.482118880065778\n",
      "epoch: 90 loss: 1.7960373163223267 grad: 10.864437874850063\n",
      "epoch: 91 loss: 1.7956748008728027 grad: 9.511363135369878\n",
      "epoch: 92 loss: 1.7932103872299194 grad: 10.616649988136949\n",
      "epoch: 93 loss: 1.7968581914901733 grad: 10.537058766280849\n",
      "epoch: 94 loss: 1.7837985754013062 grad: 9.907100242274325\n",
      "epoch: 95 loss: 1.7878409624099731 grad: 10.315206767946837\n",
      "epoch: 96 loss: 1.7803025245666504 grad: 10.46930239346647\n",
      "epoch: 97 loss: 1.7785414457321167 grad: 10.658702877217106\n",
      "epoch: 98 loss: 1.784902572631836 grad: 10.38951410910499\n",
      "epoch: 99 loss: 1.7777894735336304 grad: 10.294429666207483\n",
      "epoch: 100 loss: 1.7698636054992676 grad: 10.382114814949178\n",
      "epoch: 101 loss: 1.7756081819534302 grad: 10.601963555691617\n",
      "epoch: 102 loss: 1.7628945112228394 grad: 10.457148361167619\n",
      "epoch: 103 loss: 1.7748000621795654 grad: 10.124011996083908\n",
      "epoch: 104 loss: 1.7676056623458862 grad: 10.964170332266283\n",
      "epoch: 105 loss: 1.7606050968170166 grad: 10.364203552915049\n",
      "epoch: 106 loss: 1.7596101760864258 grad: 10.669501066104406\n",
      "epoch: 107 loss: 1.76262366771698 grad: 10.98982522285558\n",
      "epoch: 108 loss: 1.7651177644729614 grad: 10.21441739602458\n",
      "epoch: 109 loss: 1.753543734550476 grad: 10.344282195666834\n",
      "epoch: 110 loss: 1.7567862272262573 grad: 10.91448987367016\n",
      "epoch: 111 loss: 1.7553439140319824 grad: 10.577775458923526\n",
      "epoch: 112 loss: 1.7435743808746338 grad: 10.517557252686293\n",
      "epoch: 113 loss: 1.7532410621643066 grad: 10.49880061039908\n",
      "epoch: 114 loss: 1.749330759048462 grad: 11.046119829506747\n",
      "epoch: 115 loss: 1.7480082511901855 grad: 10.609962200509413\n",
      "epoch: 116 loss: 1.749045968055725 grad: 10.384348168614364\n",
      "epoch: 117 loss: 1.7403651475906372 grad: 11.046198774454377\n",
      "epoch: 118 loss: 1.7393579483032227 grad: 10.423234655203977\n",
      "epoch: 119 loss: 1.7404603958129883 grad: 10.804643558382633\n",
      "epoch: 120 loss: 1.74590265750885 grad: 11.006479240007817\n",
      "epoch: 121 loss: 1.7427537441253662 grad: 10.990703218527848\n",
      "epoch: 122 loss: 1.7394472360610962 grad: 10.998981988412284\n",
      "epoch: 123 loss: 1.7404727935791016 grad: 11.304223837005713\n",
      "epoch: 124 loss: 1.7295831441879272 grad: 10.84122725671512\n",
      "epoch: 125 loss: 1.7333329916000366 grad: 10.842858741547735\n",
      "epoch: 126 loss: 1.7219371795654297 grad: 10.982043944897928\n",
      "epoch: 127 loss: 1.72845458984375 grad: 11.226164325679992\n",
      "epoch: 128 loss: 1.721351146697998 grad: 11.207816841760797\n",
      "epoch: 129 loss: 1.7263747453689575 grad: 11.421764471922957\n",
      "epoch: 130 loss: 1.724184513092041 grad: 10.861963504171442\n",
      "epoch: 131 loss: 1.7285693883895874 grad: 9.863265183806005\n",
      "epoch: 132 loss: 1.724389672279358 grad: 10.06848837472942\n",
      "epoch: 133 loss: 1.7246928215026855 grad: 10.885428250989033\n",
      "epoch: 134 loss: 1.7233918905258179 grad: 11.564450131374455\n",
      "epoch: 135 loss: 1.7189443111419678 grad: 11.147850229818788\n",
      "epoch: 136 loss: 1.721935749053955 grad: 11.313156801224169\n",
      "epoch: 137 loss: 1.7163941860198975 grad: 11.377259532595792\n",
      "epoch: 138 loss: 1.7200868129730225 grad: 11.657993422436808\n",
      "epoch: 139 loss: 1.711683750152588 grad: 11.012240280190277\n",
      "epoch: 140 loss: 1.7133442163467407 grad: 10.618617782310125\n",
      "epoch: 141 loss: 1.7155985832214355 grad: 10.800674936623269\n",
      "epoch: 142 loss: 1.7163076400756836 grad: 11.703973957211785\n",
      "epoch: 143 loss: 1.7134300470352173 grad: 10.870680623584324\n",
      "epoch: 144 loss: 1.7117503881454468 grad: 11.404757575871098\n",
      "epoch: 145 loss: 1.7099379301071167 grad: 11.793648501052447\n",
      "epoch: 146 loss: 1.7108628749847412 grad: 10.512015659561646\n",
      "epoch: 147 loss: 1.7113683223724365 grad: 11.323352272252714\n",
      "epoch: 148 loss: 1.7111520767211914 grad: 11.732054166554931\n",
      "epoch: 149 loss: 1.7068854570388794 grad: 10.836625019428395\n",
      "epoch: 150 loss: 1.708803415298462 grad: 11.192636918010455\n",
      "epoch: 151 loss: 1.7031629085540771 grad: 11.081513571035531\n",
      "epoch: 152 loss: 1.7032910585403442 grad: 11.393749544456128\n",
      "epoch: 153 loss: 1.6976462602615356 grad: 11.522689918928322\n",
      "epoch: 154 loss: 1.6999505758285522 grad: 11.017930024318279\n",
      "epoch: 155 loss: 1.708380937576294 grad: 11.328836430048954\n",
      "epoch: 156 loss: 1.7000192403793335 grad: 11.431047199486148\n",
      "epoch: 157 loss: 1.7052412033081055 grad: 11.989837497398849\n",
      "epoch: 158 loss: 1.699309229850769 grad: 11.396545860923768\n",
      "epoch: 159 loss: 1.7027552127838135 grad: 11.616586564374822\n",
      "epoch: 160 loss: 1.6989139318466187 grad: 11.773726649212813\n",
      "epoch: 161 loss: 1.693394422531128 grad: 11.700543459327449\n",
      "epoch: 162 loss: 1.6913695335388184 grad: 11.304169093554338\n",
      "epoch: 163 loss: 1.6997264623641968 grad: 12.18656985559279\n",
      "epoch: 164 loss: 1.6928167343139648 grad: 12.168458278453539\n",
      "epoch: 165 loss: 1.698061466217041 grad: 12.112254263574464\n",
      "epoch: 166 loss: 1.6901062726974487 grad: 12.106978125855445\n",
      "epoch: 167 loss: 1.6926236152648926 grad: 11.716871256230487\n",
      "epoch: 168 loss: 1.695862054824829 grad: 11.558696543812633\n",
      "epoch: 169 loss: 1.6927077770233154 grad: 11.994942408025501\n",
      "epoch: 170 loss: 1.6884489059448242 grad: 11.929036642602156\n",
      "epoch: 171 loss: 1.6885449886322021 grad: 12.28582005538342\n",
      "epoch: 172 loss: 1.6856920719146729 grad: 11.84021774182717\n",
      "epoch: 173 loss: 1.693032145500183 grad: 12.726533324620316\n",
      "epoch: 174 loss: 1.6823039054870605 grad: 12.76965908067567\n",
      "epoch: 175 loss: 1.681845784187317 grad: 12.004730874687315\n",
      "epoch: 176 loss: 1.6740609407424927 grad: 12.97844099620032\n",
      "epoch: 177 loss: 1.6793335676193237 grad: 12.374024997007043\n",
      "epoch: 178 loss: 1.6802477836608887 grad: 12.907131610985195\n",
      "epoch: 179 loss: 1.6679948568344116 grad: 11.819863286918945\n",
      "epoch: 180 loss: 1.669575810432434 grad: 12.37157381962364\n",
      "epoch: 181 loss: 1.663902997970581 grad: 12.927040728222993\n",
      "epoch: 182 loss: 1.674698829650879 grad: 13.189594252138502\n",
      "epoch: 183 loss: 1.6641439199447632 grad: 12.2444220140192\n",
      "epoch: 184 loss: 1.6662089824676514 grad: 12.872990014822415\n",
      "epoch: 185 loss: 1.6696600914001465 grad: 12.94061660105806\n",
      "epoch: 186 loss: 1.6593514680862427 grad: 12.671533419373667\n",
      "epoch: 187 loss: 1.6663296222686768 grad: 13.026572566272485\n",
      "epoch: 188 loss: 1.6623070240020752 grad: 13.323112714562624\n",
      "epoch: 189 loss: 1.6584786176681519 grad: 13.277987429266057\n",
      "epoch: 190 loss: 1.662934422492981 grad: 13.098621221288802\n",
      "epoch: 191 loss: 1.6673089265823364 grad: 12.492325457892129\n",
      "epoch: 192 loss: 1.6623181104660034 grad: 12.780727106678698\n",
      "epoch: 193 loss: 1.6637837886810303 grad: 13.086730481775861\n",
      "epoch: 194 loss: 1.6524276733398438 grad: 12.630195109158873\n",
      "epoch: 195 loss: 1.655590295791626 grad: 13.281959081467773\n",
      "epoch: 196 loss: 1.6509212255477905 grad: 12.795087597887253\n",
      "epoch: 197 loss: 1.6504536867141724 grad: 12.350915366000244\n",
      "epoch: 198 loss: 1.6524142026901245 grad: 13.096206032449292\n",
      "epoch: 199 loss: 1.6547545194625854 grad: 12.939520548822152\n",
      "epoch: 200 loss: 1.6490044593811035 grad: 12.69255182977825\n",
      "epoch: 201 loss: 1.6466747522354126 grad: 12.870170207413297\n",
      "epoch: 202 loss: 1.6592696905136108 grad: 12.647753303959256\n",
      "epoch: 203 loss: 1.6487030982971191 grad: 12.513168937149679\n",
      "epoch: 204 loss: 1.6534769535064697 grad: 13.487401563082896\n",
      "epoch: 205 loss: 1.6402615308761597 grad: 13.104287797104686\n",
      "epoch: 206 loss: 1.644856333732605 grad: 12.717557851735148\n",
      "epoch: 207 loss: 1.6468591690063477 grad: 13.060949573699858\n",
      "epoch: 208 loss: 1.643236756324768 grad: 13.119066450441817\n",
      "epoch: 209 loss: 1.6422042846679688 grad: 12.880897823625082\n",
      "epoch: 210 loss: 1.646936058998108 grad: 12.419372006230766\n",
      "epoch: 211 loss: 1.6392512321472168 grad: 12.8019748593991\n",
      "epoch: 212 loss: 1.6323975324630737 grad: 12.315424526339426\n",
      "epoch: 213 loss: 1.6311882734298706 grad: 12.631502423864154\n",
      "epoch: 214 loss: 1.6350311040878296 grad: 13.055025078881059\n",
      "epoch: 215 loss: 1.641862154006958 grad: 13.338256855620928\n",
      "epoch: 216 loss: 1.6272555589675903 grad: 12.56189258903679\n",
      "epoch: 217 loss: 1.6331521272659302 grad: 12.379150476203197\n",
      "epoch: 218 loss: 1.6307716369628906 grad: 13.258191777821926\n",
      "epoch: 219 loss: 1.6391668319702148 grad: 13.53073789740336\n",
      "epoch: 220 loss: 1.629388689994812 grad: 13.00299394962984\n",
      "epoch: 221 loss: 1.6279914379119873 grad: 13.02459982098154\n",
      "epoch: 222 loss: 1.637018084526062 grad: 12.711021902786184\n",
      "epoch: 223 loss: 1.6248366832733154 grad: 12.666576280613386\n",
      "epoch: 224 loss: 1.6248111724853516 grad: 12.67021520032237\n",
      "epoch: 225 loss: 1.624582052230835 grad: 13.468833501339846\n",
      "epoch: 226 loss: 1.629757285118103 grad: 13.014130526007937\n",
      "epoch: 227 loss: 1.6285189390182495 grad: 13.31052420969816\n",
      "epoch: 228 loss: 1.6294527053833008 grad: 13.21225977230758\n",
      "epoch: 229 loss: 1.625012993812561 grad: 12.809229792879215\n",
      "epoch: 230 loss: 1.615676999092102 grad: 12.483013657978661\n",
      "epoch: 231 loss: 1.6213185787200928 grad: 13.531674885715816\n",
      "epoch: 232 loss: 1.6220314502716064 grad: 13.174797209807569\n",
      "epoch: 233 loss: 1.620723009109497 grad: 12.521533756768184\n",
      "epoch: 234 loss: 1.621590495109558 grad: 12.452065926688235\n",
      "epoch: 235 loss: 1.6177163124084473 grad: 12.573251563553063\n",
      "epoch: 236 loss: 1.6145451068878174 grad: 12.687781343029606\n",
      "epoch: 237 loss: 1.6160318851470947 grad: 12.887885400884977\n",
      "epoch: 238 loss: 1.623611330986023 grad: 12.714345080962788\n",
      "epoch: 239 loss: 1.614964246749878 grad: 12.254625358456185\n",
      "epoch: 240 loss: 1.6184756755828857 grad: 13.428215488806249\n",
      "epoch: 241 loss: 1.623039722442627 grad: 12.9194733049824\n",
      "epoch: 242 loss: 1.616943120956421 grad: 12.603887176207666\n",
      "epoch: 243 loss: 1.611587643623352 grad: 12.529168049220942\n",
      "epoch: 244 loss: 1.6183470487594604 grad: 12.527216564716092\n",
      "epoch: 245 loss: 1.608282446861267 grad: 12.414521115713768\n",
      "epoch: 246 loss: 1.6092162132263184 grad: 12.109103267975447\n",
      "epoch: 247 loss: 1.612546443939209 grad: 12.917552512198213\n",
      "epoch: 248 loss: 1.611916422843933 grad: 12.477786749342663\n",
      "epoch: 249 loss: 1.6074234247207642 grad: 13.273713067210915\n",
      "epoch: 250 loss: 1.6216843128204346 grad: 13.432209784889388\n",
      "epoch: 251 loss: 1.613561749458313 grad: 12.725394393790454\n",
      "epoch: 252 loss: 1.608865737915039 grad: 12.661560818944718\n",
      "epoch: 253 loss: 1.6089062690734863 grad: 12.577136523563356\n",
      "epoch: 254 loss: 1.608454704284668 grad: 13.498377018829895\n",
      "epoch: 255 loss: 1.6024200916290283 grad: 12.20646435649149\n",
      "epoch: 256 loss: 1.604490876197815 grad: 12.859070707600386\n",
      "epoch: 257 loss: 1.5963987112045288 grad: 12.97680124906557\n",
      "epoch: 258 loss: 1.6052508354187012 grad: 12.43772875580434\n",
      "epoch: 259 loss: 1.6104304790496826 grad: 12.909524476746954\n",
      "epoch: 260 loss: 1.6018624305725098 grad: 13.364181835925029\n",
      "epoch: 261 loss: 1.602383017539978 grad: 12.636425002603717\n",
      "epoch: 262 loss: 1.6006567478179932 grad: 12.385353340464274\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 263 loss: 1.6020523309707642 grad: 12.78325109426967\n",
      "epoch: 264 loss: 1.601541519165039 grad: 12.08682209568187\n",
      "epoch: 265 loss: 1.597174048423767 grad: 12.394308279128007\n",
      "epoch: 266 loss: 1.602845311164856 grad: 11.987406848767211\n",
      "epoch: 267 loss: 1.5981202125549316 grad: 12.300810154261333\n",
      "epoch: 268 loss: 1.6034234762191772 grad: 12.4861013897739\n",
      "epoch: 269 loss: 1.6017892360687256 grad: 12.678882669480075\n",
      "epoch: 270 loss: 1.5976064205169678 grad: 12.894438176608038\n",
      "epoch: 271 loss: 1.595649003982544 grad: 12.934068076260802\n",
      "epoch: 272 loss: 1.5925904512405396 grad: 11.771185993534765\n",
      "epoch: 273 loss: 1.5976849794387817 grad: 12.213296373034753\n",
      "epoch: 274 loss: 1.6110504865646362 grad: 13.369162073721075\n",
      "epoch: 275 loss: 1.5975059270858765 grad: 12.979874502047009\n",
      "epoch: 276 loss: 1.600878119468689 grad: 12.49882570611653\n",
      "epoch: 277 loss: 1.5899348258972168 grad: 12.487816364999624\n",
      "epoch: 278 loss: 1.5863099098205566 grad: 12.177751062962685\n",
      "epoch: 279 loss: 1.5966784954071045 grad: 13.300090024949954\n",
      "epoch: 280 loss: 1.5995029211044312 grad: 12.843720356468111\n",
      "epoch: 281 loss: 1.5979098081588745 grad: 12.190081953248452\n",
      "epoch: 282 loss: 1.5903462171554565 grad: 12.957995916191962\n",
      "epoch: 283 loss: 1.5910894870758057 grad: 13.065386535392868\n",
      "epoch: 284 loss: 1.5963413715362549 grad: 13.010347338452462\n",
      "epoch: 285 loss: 1.589667797088623 grad: 12.780191601446223\n",
      "epoch: 286 loss: 1.5985254049301147 grad: 13.23679295947243\n",
      "epoch: 287 loss: 1.5907750129699707 grad: 12.584703928591418\n",
      "epoch: 288 loss: 1.586448073387146 grad: 12.185516162368927\n",
      "epoch: 289 loss: 1.5928826332092285 grad: 12.331264192053665\n",
      "epoch: 290 loss: 1.593718409538269 grad: 12.689785410154848\n",
      "epoch: 291 loss: 1.59067964553833 grad: 12.366168371985651\n",
      "epoch: 292 loss: 1.5878994464874268 grad: 12.863926781356216\n",
      "epoch: 293 loss: 1.5942624807357788 grad: 12.716779207596408\n",
      "epoch: 294 loss: 1.591979742050171 grad: 12.553628160159976\n",
      "epoch: 295 loss: 1.5823251008987427 grad: 11.90810946321174\n",
      "epoch: 296 loss: 1.5853025913238525 grad: 12.749957512942187\n",
      "epoch: 297 loss: 1.5843799114227295 grad: 11.921903734361488\n",
      "epoch: 298 loss: 1.585677981376648 grad: 11.884011957872039\n",
      "epoch: 299 loss: 1.579177737236023 grad: 11.773207381774213\n",
      "epoch: 300 loss: 1.5875614881515503 grad: 12.609101290445006\n",
      "epoch: 301 loss: 1.5883328914642334 grad: 12.25650112052995\n",
      "epoch: 302 loss: 1.5852460861206055 grad: 13.103193617995\n",
      "epoch: 303 loss: 1.589255452156067 grad: 12.482902894269616\n",
      "epoch: 304 loss: 1.5847971439361572 grad: 11.959165043563448\n",
      "epoch: 305 loss: 1.5843194723129272 grad: 13.20575536183259\n",
      "epoch: 306 loss: 1.5808638334274292 grad: 11.707171932705457\n",
      "epoch: 307 loss: 1.5838322639465332 grad: 11.623069758549155\n",
      "epoch: 308 loss: 1.584991455078125 grad: 12.413808106304339\n",
      "epoch: 309 loss: 1.5877357721328735 grad: 12.62025687911932\n",
      "epoch: 310 loss: 1.5805875062942505 grad: 11.720120592138892\n",
      "epoch: 311 loss: 1.5801831483840942 grad: 12.881192830842107\n",
      "epoch: 312 loss: 1.5793958902359009 grad: 12.704388912696952\n",
      "epoch: 313 loss: 1.5786446332931519 grad: 12.131863934882281\n",
      "epoch: 314 loss: 1.5790904760360718 grad: 11.7052370097806\n",
      "epoch: 315 loss: 1.580859899520874 grad: 12.577994642572271\n",
      "epoch: 316 loss: 1.5796103477478027 grad: 13.20567767778855\n",
      "epoch: 317 loss: 1.5776925086975098 grad: 11.764880071224143\n",
      "epoch: 318 loss: 1.581377625465393 grad: 13.100213390168927\n",
      "epoch: 319 loss: 1.5789294242858887 grad: 11.890192978793667\n",
      "epoch: 320 loss: 1.5850448608398438 grad: 12.1956832580091\n",
      "epoch: 321 loss: 1.5792737007141113 grad: 11.878526100290141\n",
      "epoch: 322 loss: 1.5880872011184692 grad: 12.89749725775734\n",
      "epoch: 323 loss: 1.576875925064087 grad: 12.495929301132463\n",
      "epoch: 324 loss: 1.5854259729385376 grad: 13.688237677779167\n",
      "epoch: 325 loss: 1.5769858360290527 grad: 11.648488050829323\n",
      "epoch: 326 loss: 1.5824437141418457 grad: 11.699560917492601\n",
      "epoch: 327 loss: 1.5796279907226562 grad: 12.449745247997935\n",
      "epoch: 328 loss: 1.5822794437408447 grad: 11.987994957870493\n",
      "epoch: 329 loss: 1.5800631046295166 grad: 12.160203585659879\n",
      "epoch: 330 loss: 1.5768650770187378 grad: 12.639871034941207\n",
      "epoch: 331 loss: 1.5805984735488892 grad: 12.818732682393776\n",
      "epoch: 332 loss: 1.5830662250518799 grad: 12.506737752056251\n",
      "epoch: 333 loss: 1.5745748281478882 grad: 12.614988661408129\n",
      "epoch: 334 loss: 1.571808934211731 grad: 11.334588127203345\n",
      "epoch: 335 loss: 1.578748345375061 grad: 12.229044849755214\n",
      "epoch: 336 loss: 1.572945475578308 grad: 12.555004916575161\n",
      "epoch: 337 loss: 1.5788590908050537 grad: 11.879466737768361\n",
      "epoch: 338 loss: 1.574586033821106 grad: 12.092381481813002\n",
      "epoch: 339 loss: 1.5766769647598267 grad: 12.78048191391789\n",
      "epoch: 340 loss: 1.5738486051559448 grad: 12.979360069961302\n",
      "epoch: 341 loss: 1.5760889053344727 grad: 12.43060205060072\n",
      "epoch: 342 loss: 1.566024899482727 grad: 11.71462643065948\n",
      "epoch: 343 loss: 1.5769137144088745 grad: 11.932095337429987\n",
      "epoch: 344 loss: 1.5781521797180176 grad: 12.197231677667578\n",
      "epoch: 345 loss: 1.5740845203399658 grad: 11.711093896707993\n",
      "epoch: 346 loss: 1.566006064414978 grad: 11.94214682440303\n",
      "epoch: 347 loss: 1.5664033889770508 grad: 12.142897989514047\n",
      "epoch: 348 loss: 1.5680358409881592 grad: 11.786289181308968\n",
      "epoch: 349 loss: 1.5694140195846558 grad: 11.872381966088026\n",
      "epoch: 350 loss: 1.5722421407699585 grad: 12.955261612758187\n",
      "epoch: 351 loss: 1.571915626525879 grad: 11.413076819641338\n",
      "epoch: 352 loss: 1.5762652158737183 grad: 11.959054499894144\n",
      "epoch: 353 loss: 1.5733747482299805 grad: 11.579312013462186\n",
      "epoch: 354 loss: 1.5658541917800903 grad: 11.49710185408947\n",
      "epoch: 355 loss: 1.5753577947616577 grad: 11.963879999017255\n",
      "epoch: 356 loss: 1.5692840814590454 grad: 11.247941006159794\n",
      "epoch: 357 loss: 1.5723949670791626 grad: 12.034994470214265\n",
      "epoch: 358 loss: 1.5673755407333374 grad: 12.733111493001203\n",
      "epoch: 359 loss: 1.5692490339279175 grad: 12.284517179701536\n",
      "epoch: 360 loss: 1.56704580783844 grad: 12.251251372852407\n",
      "epoch: 361 loss: 1.5701512098312378 grad: 12.823862837058389\n",
      "epoch: 362 loss: 1.5735241174697876 grad: 11.248616101316339\n",
      "epoch: 363 loss: 1.565528392791748 grad: 11.618797700682153\n",
      "epoch: 364 loss: 1.5691014528274536 grad: 11.889238674699936\n",
      "epoch: 365 loss: 1.5671883821487427 grad: 12.564434218567811\n",
      "epoch: 366 loss: 1.565597414970398 grad: 12.470464669611482\n",
      "epoch: 367 loss: 1.5682833194732666 grad: 11.48747027656507\n",
      "epoch: 368 loss: 1.5645207166671753 grad: 11.330843106322433\n",
      "epoch: 369 loss: 1.560314655303955 grad: 11.57751829767718\n",
      "epoch: 370 loss: 1.56414794921875 grad: 12.14041713155466\n",
      "epoch: 371 loss: 1.5690956115722656 grad: 11.721685467317464\n",
      "epoch: 372 loss: 1.568239688873291 grad: 11.930435178860549\n",
      "epoch: 373 loss: 1.5692239999771118 grad: 11.986019473655947\n",
      "epoch: 374 loss: 1.565982460975647 grad: 11.397823070693347\n",
      "epoch: 375 loss: 1.5621644258499146 grad: 12.111654391667495\n",
      "epoch: 376 loss: 1.560274600982666 grad: 11.300207978277097\n",
      "epoch: 377 loss: 1.563454270362854 grad: 11.560985364851408\n",
      "epoch: 378 loss: 1.5624470710754395 grad: 11.349048343564695\n",
      "epoch: 379 loss: 1.5689657926559448 grad: 11.464417683433682\n",
      "epoch: 380 loss: 1.5675362348556519 grad: 11.126208151941972\n",
      "epoch: 381 loss: 1.564498782157898 grad: 12.549333093063314\n",
      "epoch: 382 loss: 1.5635040998458862 grad: 10.837695024841066\n",
      "epoch: 383 loss: 1.5676939487457275 grad: 10.940684645329528\n",
      "epoch: 384 loss: 1.5627487897872925 grad: 11.71263105707938\n",
      "epoch: 385 loss: 1.563225507736206 grad: 11.806772302688351\n",
      "epoch: 386 loss: 1.560433030128479 grad: 10.553209287812933\n",
      "epoch: 387 loss: 1.5659456253051758 grad: 12.231649861138846\n",
      "epoch: 388 loss: 1.5582679510116577 grad: 11.814883158305689\n",
      "epoch: 389 loss: 1.5598374605178833 grad: 11.418930572490874\n",
      "epoch: 390 loss: 1.572411298751831 grad: 12.168234486495042\n",
      "epoch: 391 loss: 1.561469554901123 grad: 11.43745007610599\n",
      "epoch: 392 loss: 1.5561344623565674 grad: 12.37314720611487\n",
      "epoch: 393 loss: 1.5612632036209106 grad: 11.66387285735266\n",
      "epoch: 394 loss: 1.5643653869628906 grad: 12.259671657431191\n",
      "epoch: 395 loss: 1.5633597373962402 grad: 12.074651814841976\n",
      "epoch: 396 loss: 1.5613605976104736 grad: 11.838793447760436\n",
      "epoch: 397 loss: 1.5576341152191162 grad: 12.269905409480016\n",
      "epoch: 398 loss: 1.56169855594635 grad: 11.412871790116668\n",
      "epoch: 399 loss: 1.5622951984405518 grad: 11.43469760889217\n",
      "epoch: 400 loss: 1.5552332401275635 grad: 10.279166159512002\n",
      "epoch: 401 loss: 1.5584313869476318 grad: 11.562136939985471\n",
      "epoch: 402 loss: 1.5563864707946777 grad: 10.57582322991867\n",
      "epoch: 403 loss: 1.55718195438385 grad: 11.800429572395625\n",
      "epoch: 404 loss: 1.5569736957550049 grad: 11.777324874367979\n",
      "epoch: 405 loss: 1.5591681003570557 grad: 11.901856616065498\n",
      "epoch: 406 loss: 1.558310866355896 grad: 11.89132440909152\n",
      "epoch: 407 loss: 1.5637638568878174 grad: 12.056219131767099\n",
      "epoch: 408 loss: 1.5524042844772339 grad: 11.652959845620133\n",
      "epoch: 409 loss: 1.5609031915664673 grad: 10.64090864811211\n",
      "epoch: 410 loss: 1.5630848407745361 grad: 12.280011996486417\n",
      "epoch: 411 loss: 1.5579116344451904 grad: 11.598396065578397\n",
      "epoch: 412 loss: 1.5547682046890259 grad: 11.397884623605817\n",
      "epoch: 413 loss: 1.5634422302246094 grad: 11.314512011454633\n",
      "epoch: 414 loss: 1.5572601556777954 grad: 11.612115508348252\n",
      "epoch: 415 loss: 1.5525150299072266 grad: 11.430328933832547\n",
      "epoch: 416 loss: 1.5622221231460571 grad: 11.969276177452965\n",
      "epoch: 417 loss: 1.5573577880859375 grad: 11.668273351221744\n",
      "epoch: 418 loss: 1.5596626996994019 grad: 12.150343540451667\n",
      "epoch: 419 loss: 1.5554213523864746 grad: 12.435530899495388\n",
      "epoch: 420 loss: 1.555119514465332 grad: 11.00444098846573\n",
      "epoch: 421 loss: 1.563254714012146 grad: 12.400635087873699\n",
      "epoch: 422 loss: 1.5576092004776 grad: 12.535580729718305\n",
      "epoch: 423 loss: 1.5594608783721924 grad: 11.82637790737245\n",
      "epoch: 424 loss: 1.5555578470230103 grad: 12.164598847399391\n",
      "epoch: 425 loss: 1.5627000331878662 grad: 12.834528804206037\n",
      "epoch: 426 loss: 1.5624703168869019 grad: 12.033509480153462\n",
      "epoch: 427 loss: 1.5615442991256714 grad: 11.70733268120851\n",
      "epoch: 428 loss: 1.5544604063034058 grad: 11.81220915419833\n",
      "epoch: 429 loss: 1.555623173713684 grad: 11.544777792948668\n",
      "epoch: 430 loss: 1.55061936378479 grad: 11.004237092669225\n",
      "epoch: 431 loss: 1.5565423965454102 grad: 11.230966454586161\n",
      "epoch: 432 loss: 1.5587852001190186 grad: 11.658375512664428\n",
      "epoch: 433 loss: 1.5497809648513794 grad: 11.184852916765811\n",
      "epoch: 434 loss: 1.5629175901412964 grad: 12.642374945937522\n",
      "epoch: 435 loss: 1.552003264427185 grad: 12.049113888518944\n",
      "epoch: 436 loss: 1.5618577003479004 grad: 11.226857738436333\n",
      "epoch: 437 loss: 1.5497536659240723 grad: 10.792486596645581\n",
      "epoch: 438 loss: 1.5575274229049683 grad: 11.945784603981005\n",
      "epoch: 439 loss: 1.555458426475525 grad: 11.466318968461739\n",
      "epoch: 440 loss: 1.5562763214111328 grad: 11.880369601678842\n",
      "epoch: 441 loss: 1.5526680946350098 grad: 12.218587855342776\n",
      "epoch: 442 loss: 1.5534148216247559 grad: 11.913963446659702\n",
      "epoch: 443 loss: 1.5550856590270996 grad: 11.89751208172409\n",
      "epoch: 444 loss: 1.555745244026184 grad: 11.911988025483128\n",
      "epoch: 445 loss: 1.5482279062271118 grad: 11.466734128409168\n",
      "epoch: 446 loss: 1.5524834394454956 grad: 11.017372673994581\n",
      "epoch: 447 loss: 1.550882339477539 grad: 11.04263342316595\n",
      "epoch: 448 loss: 1.5526756048202515 grad: 11.75929382063877\n",
      "epoch: 449 loss: 1.5508545637130737 grad: 11.932984905679607\n",
      "epoch: 450 loss: 1.5561318397521973 grad: 11.46320164730654\n",
      "epoch: 451 loss: 1.550362467765808 grad: 11.206474025427024\n",
      "epoch: 452 loss: 1.5508509874343872 grad: 11.34134242792673\n",
      "epoch: 453 loss: 1.5474933385849 grad: 10.5356067579502\n",
      "epoch: 454 loss: 1.5574721097946167 grad: 11.782081287023464\n",
      "epoch: 455 loss: 1.5555223226547241 grad: 11.866686124768522\n",
      "epoch: 456 loss: 1.5513001680374146 grad: 11.480889458837549\n",
      "epoch: 457 loss: 1.5494751930236816 grad: 11.996568123279657\n",
      "epoch: 458 loss: 1.5567740201950073 grad: 11.829672792142937\n",
      "epoch: 459 loss: 1.5503828525543213 grad: 11.94776650270935\n",
      "epoch: 460 loss: 1.547013282775879 grad: 11.252712946876677\n",
      "epoch: 461 loss: 1.549052357673645 grad: 11.364465941955883\n",
      "epoch: 462 loss: 1.5469532012939453 grad: 11.621452573779232\n",
      "epoch: 463 loss: 1.555607557296753 grad: 11.176847647531845\n",
      "epoch: 464 loss: 1.5476632118225098 grad: 11.024768864443999\n",
      "epoch: 465 loss: 1.5468108654022217 grad: 11.606502415124504\n",
      "epoch: 466 loss: 1.5574795007705688 grad: 12.13863845426397\n",
      "epoch: 467 loss: 1.5513569116592407 grad: 11.870549842785483\n",
      "epoch: 468 loss: 1.543565273284912 grad: 11.600929525834212\n",
      "epoch: 469 loss: 1.5531560182571411 grad: 11.181824466080538\n",
      "epoch: 470 loss: 1.5486137866973877 grad: 11.82657953496239\n",
      "epoch: 471 loss: 1.5510178804397583 grad: 10.85438342516621\n",
      "epoch: 472 loss: 1.5516024827957153 grad: 12.184958147528093\n",
      "epoch: 473 loss: 1.5501035451889038 grad: 11.246991396720876\n",
      "epoch: 474 loss: 1.5538151264190674 grad: 12.50797958260343\n",
      "epoch: 475 loss: 1.5443705320358276 grad: 11.366982668028434\n",
      "epoch: 476 loss: 1.5517007112503052 grad: 12.134752758139271\n",
      "epoch: 477 loss: 1.5441746711730957 grad: 11.758005583795557\n",
      "epoch: 478 loss: 1.5507594347000122 grad: 11.315216433478607\n",
      "epoch: 479 loss: 1.5514235496520996 grad: 12.057892516381033\n",
      "epoch: 480 loss: 1.5437551736831665 grad: 11.649379769114718\n",
      "epoch: 481 loss: 1.54595947265625 grad: 10.25536719935074\n",
      "epoch: 482 loss: 1.5514143705368042 grad: 11.761808637437218\n",
      "epoch: 483 loss: 1.5549837350845337 grad: 12.565648534039537\n",
      "epoch: 484 loss: 1.5482829809188843 grad: 11.400002353055964\n",
      "epoch: 485 loss: 1.548740267753601 grad: 11.904681588938859\n",
      "epoch: 486 loss: 1.5477017164230347 grad: 11.483589009980538\n",
      "epoch: 487 loss: 1.5431041717529297 grad: 11.650863026054429\n",
      "epoch: 488 loss: 1.5473061800003052 grad: 11.303515602605389\n",
      "epoch: 489 loss: 1.5525431632995605 grad: 11.885565848516611\n",
      "epoch: 490 loss: 1.5468195676803589 grad: 10.912096618719044\n",
      "epoch: 491 loss: 1.5467454195022583 grad: 11.573908580962332\n",
      "epoch: 492 loss: 1.5427336692810059 grad: 10.363733500144297\n",
      "epoch: 493 loss: 1.5481579303741455 grad: 10.933560259855494\n",
      "epoch: 494 loss: 1.5488450527191162 grad: 11.183358608589819\n",
      "epoch: 495 loss: 1.543601632118225 grad: 10.788961907811759\n",
      "epoch: 496 loss: 1.5494496822357178 grad: 11.921927481183841\n",
      "epoch: 497 loss: 1.5468928813934326 grad: 11.254492457882161\n",
      "epoch: 498 loss: 1.5568746328353882 grad: 11.873812292665539\n",
      "epoch: 499 loss: 1.5501103401184082 grad: 11.029193995147205\n",
      "1.8621762245893478\n",
      "epoch: 0 loss: 2.3019609451293945 grad: 1.1930945292170647\n",
      "epoch: 1 loss: 2.1896848678588867 grad: 1.8135032968638125\n",
      "epoch: 2 loss: 2.1282479763031006 grad: 2.415147497051669\n",
      "epoch: 3 loss: 2.023556709289551 grad: 4.022551359070118\n",
      "epoch: 4 loss: 1.9728177785873413 grad: 5.388525304856659\n",
      "epoch: 5 loss: 1.9630616903305054 grad: 4.924603498563455\n",
      "epoch: 6 loss: 1.9076470136642456 grad: 5.029949930123245\n",
      "epoch: 7 loss: 1.896087884902954 grad: 5.145394933331454\n",
      "epoch: 8 loss: 1.8795626163482666 grad: 5.949830708470443\n",
      "epoch: 9 loss: 1.8755240440368652 grad: 5.601815962175365\n",
      "epoch: 10 loss: 1.8284507989883423 grad: 5.262413068885623\n",
      "epoch: 11 loss: 1.8360155820846558 grad: 5.818698932078116\n",
      "epoch: 12 loss: 1.7963378429412842 grad: 5.589141059908018\n",
      "epoch: 13 loss: 1.7840172052383423 grad: 6.754979767724834\n",
      "epoch: 14 loss: 1.795619249343872 grad: 6.819158534496738\n",
      "epoch: 15 loss: 1.7627167701721191 grad: 6.953099792889718\n",
      "epoch: 16 loss: 1.7348488569259644 grad: 6.463700660049827\n",
      "epoch: 17 loss: 1.7254421710968018 grad: 7.231341867915554\n",
      "epoch: 18 loss: 1.7091078758239746 grad: 7.825380033111691\n",
      "epoch: 19 loss: 1.702620506286621 grad: 6.72074346914601\n",
      "epoch: 20 loss: 1.685173511505127 grad: 7.899911986646383\n",
      "epoch: 21 loss: 1.6806145906448364 grad: 7.012198644816794\n",
      "epoch: 22 loss: 1.6828317642211914 grad: 7.5519028407404205\n",
      "epoch: 23 loss: 1.6413072347640991 grad: 6.3684153511250825\n",
      "epoch: 24 loss: 1.664939522743225 grad: 6.4327410268768235\n",
      "epoch: 25 loss: 1.6411083936691284 grad: 7.439714228765557\n",
      "epoch: 26 loss: 1.654147982597351 grad: 6.680255548942128\n",
      "epoch: 27 loss: 1.6180082559585571 grad: 6.133354201821873\n",
      "epoch: 28 loss: 1.6379570960998535 grad: 6.645469857448627\n",
      "epoch: 29 loss: 1.6438565254211426 grad: 7.0372074322704785\n",
      "epoch: 30 loss: 1.6244162321090698 grad: 6.463099347415823\n",
      "epoch: 31 loss: 1.6392126083374023 grad: 6.856587246180482\n",
      "epoch: 32 loss: 1.6187468767166138 grad: 6.187711396392611\n",
      "epoch: 33 loss: 1.6306617259979248 grad: 7.085011115036029\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 34 loss: 1.6063016653060913 grad: 6.118090392853663\n",
      "epoch: 35 loss: 1.6160072088241577 grad: 6.48392538545863\n",
      "epoch: 36 loss: 1.5984313488006592 grad: 5.913014768875337\n",
      "epoch: 37 loss: 1.5987005233764648 grad: 7.832699138897638\n",
      "epoch: 38 loss: 1.6124656200408936 grad: 6.118363355457635\n",
      "epoch: 39 loss: 1.5803303718566895 grad: 5.789141745078629\n",
      "epoch: 40 loss: 1.5967351198196411 grad: 6.521418322728081\n",
      "epoch: 41 loss: 1.58103346824646 grad: 5.356973634377288\n",
      "epoch: 42 loss: 1.6023669242858887 grad: 5.794090027779309\n",
      "epoch: 43 loss: 1.620063066482544 grad: 7.8629932652863594\n",
      "epoch: 44 loss: 1.6037358045578003 grad: 6.476878418964055\n",
      "epoch: 45 loss: 1.5948843955993652 grad: 6.452696831532641\n",
      "epoch: 46 loss: 1.5840691328048706 grad: 5.21232243297605\n",
      "epoch: 47 loss: 1.5683002471923828 grad: 5.148507261971804\n",
      "epoch: 48 loss: 1.5691877603530884 grad: 5.2119871205425925\n",
      "epoch: 49 loss: 1.599223017692566 grad: 6.192165338179678\n",
      "epoch: 50 loss: 1.5786982774734497 grad: 5.053869121955638\n",
      "epoch: 51 loss: 1.5624234676361084 grad: 6.119991435309145\n",
      "epoch: 52 loss: 1.5737104415893555 grad: 5.742029718169342\n",
      "epoch: 53 loss: 1.5855903625488281 grad: 6.301210125993676\n",
      "epoch: 54 loss: 1.5822739601135254 grad: 6.001124116019351\n",
      "epoch: 55 loss: 1.5948340892791748 grad: 6.5983016097520055\n",
      "epoch: 56 loss: 1.5885586738586426 grad: 6.140516246739502\n",
      "epoch: 57 loss: 1.571097731590271 grad: 4.903373909374706\n",
      "epoch: 58 loss: 1.57096529006958 grad: 6.213154868337261\n",
      "epoch: 59 loss: 1.578679084777832 grad: 6.38035909128456\n",
      "epoch: 60 loss: 1.5755462646484375 grad: 6.502608902325948\n",
      "epoch: 61 loss: 1.5557868480682373 grad: 5.6723536486612955\n",
      "epoch: 62 loss: 1.5555996894836426 grad: 5.217743211294354\n",
      "epoch: 63 loss: 1.5507864952087402 grad: 5.537185154086008\n",
      "epoch: 64 loss: 1.5724200010299683 grad: 6.84936116668264\n",
      "epoch: 65 loss: 1.5656650066375732 grad: 5.220522531169586\n",
      "epoch: 66 loss: 1.5497584342956543 grad: 4.7788244710610766\n",
      "epoch: 67 loss: 1.5484449863433838 grad: 6.037204113518877\n",
      "epoch: 68 loss: 1.5607404708862305 grad: 5.70572699771968\n",
      "epoch: 69 loss: 1.5561127662658691 grad: 6.191133446514608\n",
      "epoch: 70 loss: 1.5508302450180054 grad: 5.465159903040825\n",
      "epoch: 71 loss: 1.539468765258789 grad: 4.905216438475274\n",
      "epoch: 72 loss: 1.5505748987197876 grad: 4.985548510779703\n",
      "epoch: 73 loss: 1.5448575019836426 grad: 4.995255659140242\n",
      "epoch: 74 loss: 1.5529117584228516 grad: 4.868385972880672\n",
      "epoch: 75 loss: 1.5297263860702515 grad: 3.551428070633063\n",
      "epoch: 76 loss: 1.551966905593872 grad: 5.291166946083028\n",
      "epoch: 77 loss: 1.554197907447815 grad: 4.971724292548879\n",
      "epoch: 78 loss: 1.5613224506378174 grad: 5.4809406073156195\n",
      "epoch: 79 loss: 1.562369465827942 grad: 5.162941700433535\n",
      "epoch: 80 loss: 1.544426441192627 grad: 4.916909117699144\n",
      "epoch: 81 loss: 1.5580352544784546 grad: 4.942449810379129\n",
      "epoch: 82 loss: 1.5413271188735962 grad: 4.29452570308778\n",
      "epoch: 83 loss: 1.561923861503601 grad: 5.254767056964593\n",
      "epoch: 84 loss: 1.548633337020874 grad: 4.159691014522563\n",
      "epoch: 85 loss: 1.5387613773345947 grad: 4.448750315854319\n",
      "epoch: 86 loss: 1.555705189704895 grad: 5.48716740904568\n",
      "epoch: 87 loss: 1.538063645362854 grad: 4.081574647375633\n",
      "epoch: 88 loss: 1.5310972929000854 grad: 5.2636030073395625\n",
      "epoch: 89 loss: 1.58194100856781 grad: 6.987429615007834\n",
      "epoch: 90 loss: 1.558268427848816 grad: 5.352091579395771\n",
      "epoch: 91 loss: 1.5478616952896118 grad: 5.375514320091478\n",
      "epoch: 92 loss: 1.5396649837493896 grad: 4.205493330655495\n",
      "epoch: 93 loss: 1.5448024272918701 grad: 4.869784173337273\n",
      "epoch: 94 loss: 1.5404994487762451 grad: 4.442944691677169\n",
      "epoch: 95 loss: 1.5397624969482422 grad: 4.347607668775156\n",
      "epoch: 96 loss: 1.562299132347107 grad: 5.713353202329311\n",
      "epoch: 97 loss: 1.541297435760498 grad: 3.5507303320205823\n",
      "epoch: 98 loss: 1.5393778085708618 grad: 3.8233081612183906\n",
      "epoch: 99 loss: 1.5256187915802002 grad: 3.366711531594265\n",
      "epoch: 100 loss: 1.5280944108963013 grad: 3.9087832130993316\n",
      "epoch: 101 loss: 1.5563064813613892 grad: 4.947267524927497\n",
      "epoch: 102 loss: 1.529699683189392 grad: 3.995974324610819\n",
      "epoch: 103 loss: 1.5403298139572144 grad: 4.143616499261001\n",
      "epoch: 104 loss: 1.532686471939087 grad: 4.1845200438818955\n",
      "epoch: 105 loss: 1.5375937223434448 grad: 3.5240311195571445\n",
      "epoch: 106 loss: 1.5318560600280762 grad: 4.4140742731453955\n",
      "epoch: 107 loss: 1.5220725536346436 grad: 2.8738684611961274\n",
      "epoch: 108 loss: 1.5276480913162231 grad: 3.4088024328138546\n",
      "epoch: 109 loss: 1.5273184776306152 grad: 4.3345173314085566\n",
      "epoch: 110 loss: 1.5281685590744019 grad: 3.775264165977004\n",
      "epoch: 111 loss: 1.5285202264785767 grad: 3.9926158899344233\n",
      "epoch: 112 loss: 1.5423444509506226 grad: 4.880827103666407\n",
      "epoch: 113 loss: 1.5475726127624512 grad: 4.397297323051299\n",
      "epoch: 114 loss: 1.544676661491394 grad: 5.038324152204716\n",
      "epoch: 115 loss: 1.5561128854751587 grad: 5.357335108369116\n",
      "epoch: 116 loss: 1.5409986972808838 grad: 3.7906523765462006\n",
      "epoch: 117 loss: 1.5570486783981323 grad: 4.310570972595371\n",
      "epoch: 118 loss: 1.5424805879592896 grad: 4.161640985465593\n",
      "epoch: 119 loss: 1.5300827026367188 grad: 3.8268990738206674\n",
      "epoch: 120 loss: 1.534540057182312 grad: 3.629722048487491\n",
      "epoch: 121 loss: 1.529477834701538 grad: 4.497738057994261\n",
      "epoch: 122 loss: 1.5331966876983643 grad: 4.373461491383658\n",
      "epoch: 123 loss: 1.53360116481781 grad: 4.1209113221673865\n",
      "epoch: 124 loss: 1.5427848100662231 grad: 4.850010133526876\n",
      "epoch: 125 loss: 1.5286439657211304 grad: 4.495346836282122\n",
      "epoch: 126 loss: 1.538855791091919 grad: 4.997890565966767\n",
      "epoch: 127 loss: 1.5374234914779663 grad: 4.347619131915804\n",
      "epoch: 128 loss: 1.52919602394104 grad: 3.6307023130923235\n",
      "epoch: 129 loss: 1.5258172750473022 grad: 4.322053862392798\n",
      "epoch: 130 loss: 1.5340564250946045 grad: 3.592601826475475\n",
      "epoch: 131 loss: 1.5243008136749268 grad: 3.805982322467592\n",
      "epoch: 132 loss: 1.5362197160720825 grad: 4.203523344479402\n",
      "epoch: 133 loss: 1.5285643339157104 grad: 4.550744102692291\n",
      "epoch: 134 loss: 1.5358811616897583 grad: 5.4225384981326155\n",
      "epoch: 135 loss: 1.5327425003051758 grad: 4.618925121630921\n",
      "epoch: 136 loss: 1.5294201374053955 grad: 4.501145250062612\n",
      "epoch: 137 loss: 1.5126335620880127 grad: 2.4718144207183235\n",
      "epoch: 138 loss: 1.526127576828003 grad: 3.3196330470991273\n",
      "epoch: 139 loss: 1.5325275659561157 grad: 4.376854385158906\n",
      "epoch: 140 loss: 1.5366692543029785 grad: 3.4089247049023794\n",
      "epoch: 141 loss: 1.530601978302002 grad: 3.538169864357015\n",
      "epoch: 142 loss: 1.5244139432907104 grad: 3.315507501415717\n",
      "epoch: 143 loss: 1.541761875152588 grad: 3.482560846200587\n",
      "epoch: 144 loss: 1.5354571342468262 grad: 4.140152844114117\n",
      "epoch: 145 loss: 1.534785509109497 grad: 4.081429253785408\n",
      "epoch: 146 loss: 1.5535691976547241 grad: 4.841402406437406\n",
      "epoch: 147 loss: 1.5342015027999878 grad: 4.340182277798192\n",
      "epoch: 148 loss: 1.5591299533843994 grad: 4.849015443254612\n",
      "epoch: 149 loss: 1.5469626188278198 grad: 4.322664145674396\n",
      "epoch: 150 loss: 1.550945520401001 grad: 3.89642639965311\n",
      "epoch: 151 loss: 1.5510144233703613 grad: 5.15606930989101\n",
      "epoch: 152 loss: 1.5461995601654053 grad: 4.679153014411595\n",
      "epoch: 153 loss: 1.527446985244751 grad: 4.243890049851912\n",
      "epoch: 154 loss: 1.544999599456787 grad: 4.564516479045353\n",
      "epoch: 155 loss: 1.5203227996826172 grad: 3.8299934064496957\n",
      "epoch: 156 loss: 1.5225906372070312 grad: 3.6753239758054015\n",
      "epoch: 157 loss: 1.5212857723236084 grad: 4.020944688378862\n",
      "epoch: 158 loss: 1.525409460067749 grad: 2.346858353969005\n",
      "epoch: 159 loss: 1.518068790435791 grad: 3.373591284762782\n",
      "epoch: 160 loss: 1.5196207761764526 grad: 2.796492845454817\n",
      "epoch: 161 loss: 1.529002070426941 grad: 4.179974250108083\n",
      "epoch: 162 loss: 1.5228012800216675 grad: 2.9028451977689786\n",
      "epoch: 163 loss: 1.522969126701355 grad: 4.063389123844917\n",
      "epoch: 164 loss: 1.5242204666137695 grad: 4.571815809567834\n",
      "epoch: 165 loss: 1.5509270429611206 grad: 3.4881498034269094\n",
      "epoch: 166 loss: 1.5367786884307861 grad: 3.0731409425731027\n",
      "epoch: 167 loss: 1.5359994173049927 grad: 4.926479082044545\n",
      "epoch: 168 loss: 1.5543406009674072 grad: 6.417700702305182\n",
      "epoch: 169 loss: 1.538358449935913 grad: 3.947599547267783\n",
      "epoch: 170 loss: 1.5210566520690918 grad: 2.353873729739376\n",
      "epoch: 171 loss: 1.5307852029800415 grad: 3.6428943800784954\n",
      "epoch: 172 loss: 1.5267517566680908 grad: 3.3819622334524295\n",
      "epoch: 173 loss: 1.5130869150161743 grad: 2.8434775215694206\n",
      "epoch: 174 loss: 1.5089259147644043 grad: 3.002825442646593\n",
      "epoch: 175 loss: 1.5231826305389404 grad: 2.320529821994173\n",
      "epoch: 176 loss: 1.519942283630371 grad: 3.962703127700601\n",
      "epoch: 177 loss: 1.5164471864700317 grad: 3.351315668953038\n",
      "epoch: 178 loss: 1.5165740251541138 grad: 2.7435672014523838\n",
      "epoch: 179 loss: 1.5086866617202759 grad: 3.977796300545351\n",
      "epoch: 180 loss: 1.5239790678024292 grad: 3.5431663233972683\n",
      "epoch: 181 loss: 1.5295675992965698 grad: 5.177583418262406\n",
      "epoch: 182 loss: 1.540642261505127 grad: 4.040216844754691\n",
      "epoch: 183 loss: 1.5385581254959106 grad: 3.6452079213467057\n",
      "epoch: 184 loss: 1.508863091468811 grad: 2.5984428921242504\n",
      "epoch: 185 loss: 1.5170352458953857 grad: 2.9876953173297593\n",
      "epoch: 186 loss: 1.5403794050216675 grad: 4.292618755830054\n",
      "epoch: 187 loss: 1.53449547290802 grad: 4.42023367343517\n",
      "epoch: 188 loss: 1.5206960439682007 grad: 4.0151588774079885\n",
      "epoch: 189 loss: 1.524633765220642 grad: 2.8858314967737377\n",
      "epoch: 190 loss: 1.5040431022644043 grad: 2.588086456903339\n",
      "epoch: 191 loss: 1.5035730600357056 grad: 2.113875241888601\n",
      "epoch: 192 loss: 1.5077627897262573 grad: 3.937180342585055\n",
      "epoch: 193 loss: 1.5360151529312134 grad: 4.294198151943267\n",
      "epoch: 194 loss: 1.5107157230377197 grad: 3.4145074949879874\n",
      "epoch: 195 loss: 1.5332120656967163 grad: 3.6937936760632932\n",
      "epoch: 196 loss: 1.5096009969711304 grad: 2.5578012159941923\n",
      "epoch: 197 loss: 1.5075788497924805 grad: 2.519027391424696\n",
      "epoch: 198 loss: 1.5157381296157837 grad: 2.7567003792159714\n",
      "epoch: 199 loss: 1.5151569843292236 grad: 3.4425049971211217\n",
      "epoch: 200 loss: 1.5152034759521484 grad: 2.932792849464937\n",
      "epoch: 201 loss: 1.5114471912384033 grad: 3.462591718788513\n",
      "epoch: 202 loss: 1.5252635478973389 grad: 2.4584761142624876\n",
      "epoch: 203 loss: 1.5095843076705933 grad: 3.011860800119305\n",
      "epoch: 204 loss: 1.500299096107483 grad: 2.8604224243135015\n",
      "epoch: 205 loss: 1.5110927820205688 grad: 2.5360951085545733\n",
      "epoch: 206 loss: 1.514285683631897 grad: 3.97333461663519\n",
      "epoch: 207 loss: 1.5265638828277588 grad: 4.4112809550125105\n",
      "epoch: 208 loss: 1.5307525396347046 grad: 4.312730935382068\n",
      "epoch: 209 loss: 1.5179574489593506 grad: 3.443711937544962\n",
      "epoch: 210 loss: 1.5080533027648926 grad: 2.688467020552209\n",
      "epoch: 211 loss: 1.5229928493499756 grad: 3.6371245159528582\n",
      "epoch: 212 loss: 1.5146236419677734 grad: 2.862719824016864\n",
      "epoch: 213 loss: 1.5124434232711792 grad: 3.1033184652158132\n",
      "epoch: 214 loss: 1.5069620609283447 grad: 2.289848105080383\n",
      "epoch: 215 loss: 1.5186443328857422 grad: 3.1008099446266773\n",
      "epoch: 216 loss: 1.5146750211715698 grad: 3.7120081086403505\n",
      "epoch: 217 loss: 1.5153499841690063 grad: 3.836451694380934\n",
      "epoch: 218 loss: 1.568735957145691 grad: 6.819377512947752\n",
      "epoch: 219 loss: 1.549788236618042 grad: 4.857906563631907\n",
      "epoch: 220 loss: 1.5167629718780518 grad: 2.6919373300657035\n",
      "epoch: 221 loss: 1.514611005783081 grad: 3.184582524904924\n",
      "epoch: 222 loss: 1.5192784070968628 grad: 2.7300605635755155\n",
      "epoch: 223 loss: 1.5104445219039917 grad: 3.472165868219962\n",
      "epoch: 224 loss: 1.5122156143188477 grad: 2.463183736245812\n",
      "epoch: 225 loss: 1.5078672170639038 grad: 2.2226259851353896\n",
      "epoch: 226 loss: 1.5215013027191162 grad: 3.713502583842877\n",
      "epoch: 227 loss: 1.516498327255249 grad: 2.7014585900049077\n",
      "epoch: 228 loss: 1.515721321105957 grad: 2.9881149930696655\n",
      "epoch: 229 loss: 1.5200446844100952 grad: 3.4647199885411295\n",
      "epoch: 230 loss: 1.5201791524887085 grad: 3.7156840084627007\n",
      "epoch: 231 loss: 1.5002464056015015 grad: 1.942125723098287\n",
      "epoch: 232 loss: 1.5351157188415527 grad: 4.025001984082127\n",
      "epoch: 233 loss: 1.5151715278625488 grad: 2.560067945026104\n",
      "epoch: 234 loss: 1.5176836252212524 grad: 4.109424870454648\n",
      "epoch: 235 loss: 1.516275405883789 grad: 3.213799021899792\n",
      "epoch: 236 loss: 1.5249677896499634 grad: 3.470410050205817\n",
      "epoch: 237 loss: 1.5402034521102905 grad: 3.7030113814464487\n",
      "epoch: 238 loss: 1.4999809265136719 grad: 1.6741330132050085\n",
      "epoch: 239 loss: 1.5135537385940552 grad: 3.1003560620460466\n",
      "epoch: 240 loss: 1.5214890241622925 grad: 3.4823308089446203\n",
      "epoch: 241 loss: 1.5576119422912598 grad: 4.184810085390132\n",
      "epoch: 242 loss: 1.5092447996139526 grad: 2.1384238116742216\n",
      "epoch: 243 loss: 1.5067824125289917 grad: 1.7666317719556335\n",
      "epoch: 244 loss: 1.5062124729156494 grad: 2.2033490918601046\n",
      "epoch: 245 loss: 1.4973623752593994 grad: 1.7242386580133064\n",
      "epoch: 246 loss: 1.5075170993804932 grad: 3.05371112729966\n",
      "epoch: 247 loss: 1.513056993484497 grad: 2.6737013388548854\n",
      "epoch: 248 loss: 1.5144861936569214 grad: 3.3600267731064433\n",
      "epoch: 249 loss: 1.504250168800354 grad: 2.7110067115980097\n",
      "epoch: 250 loss: 1.5012290477752686 grad: 2.164502369455422\n",
      "epoch: 251 loss: 1.5028780698776245 grad: 2.536698240871356\n",
      "epoch: 252 loss: 1.5133637189865112 grad: 2.9963396308101955\n",
      "epoch: 253 loss: 1.5167245864868164 grad: 4.335821696583757\n",
      "epoch: 254 loss: 1.52474844455719 grad: 2.6708345696012725\n",
      "epoch: 255 loss: 1.5158480405807495 grad: 2.5049003680823794\n",
      "epoch: 256 loss: 1.5480408668518066 grad: 4.547010857885304\n",
      "epoch: 257 loss: 1.5339175462722778 grad: 3.677123891677301\n",
      "epoch: 258 loss: 1.5136821269989014 grad: 2.8679572614645266\n",
      "epoch: 259 loss: 1.5130798816680908 grad: 2.4361445057032003\n",
      "epoch: 260 loss: 1.5106074810028076 grad: 2.382582990244551\n",
      "epoch: 261 loss: 1.5045766830444336 grad: 3.9625861294196545\n",
      "epoch: 262 loss: 1.513944149017334 grad: 2.599571968873857\n",
      "epoch: 263 loss: 1.513696312904358 grad: 2.6388698181220365\n",
      "epoch: 264 loss: 1.5097968578338623 grad: 2.803495864297144\n",
      "epoch: 265 loss: 1.5113332271575928 grad: 1.962667826645165\n",
      "epoch: 266 loss: 1.500219464302063 grad: 1.9033626352709017\n",
      "epoch: 267 loss: 1.5054771900177002 grad: 3.451785976375715\n",
      "epoch: 268 loss: 1.5163401365280151 grad: 3.475109004273294\n",
      "epoch: 269 loss: 1.5096662044525146 grad: 2.441453685802795\n",
      "epoch: 270 loss: 1.5064828395843506 grad: 1.9596360887717068\n",
      "epoch: 271 loss: 1.4924485683441162 grad: 2.0257366014716545\n",
      "epoch: 272 loss: 1.495224952697754 grad: 1.8652305856259088\n",
      "epoch: 273 loss: 1.5132185220718384 grad: 3.0966946641682482\n",
      "epoch: 274 loss: 1.5111825466156006 grad: 3.7874998731070932\n",
      "epoch: 275 loss: 1.5047812461853027 grad: 2.5155509632407766\n",
      "epoch: 276 loss: 1.5045018196105957 grad: 3.477614661818313\n",
      "epoch: 277 loss: 1.5071296691894531 grad: 3.1918487945555554\n",
      "epoch: 278 loss: 1.509600043296814 grad: 3.000774525708562\n",
      "epoch: 279 loss: 1.5016562938690186 grad: 2.175229874993065\n",
      "epoch: 280 loss: 1.5116060972213745 grad: 3.3811128586838266\n",
      "epoch: 281 loss: 1.5283266305923462 grad: 2.959064151786543\n",
      "epoch: 282 loss: 1.5000312328338623 grad: 2.229958778152944\n",
      "epoch: 283 loss: 1.5188677310943604 grad: 4.132539843438757\n",
      "epoch: 284 loss: 1.5476466417312622 grad: 5.0920615564436496\n",
      "epoch: 285 loss: 1.531214952468872 grad: 3.9343137293638097\n",
      "epoch: 286 loss: 1.5188932418823242 grad: 3.7105237704020695\n",
      "epoch: 287 loss: 1.5102208852767944 grad: 2.582759474741119\n",
      "epoch: 288 loss: 1.5033191442489624 grad: 2.3802427586646107\n",
      "epoch: 289 loss: 1.50372314453125 grad: 1.7206790101450478\n",
      "epoch: 290 loss: 1.5070736408233643 grad: 2.4084027084918698\n",
      "epoch: 291 loss: 1.5147690773010254 grad: 3.716133832393511\n",
      "epoch: 292 loss: 1.5212146043777466 grad: 2.192840398875083\n",
      "epoch: 293 loss: 1.5044829845428467 grad: 1.6523875588300276\n",
      "epoch: 294 loss: 1.5021698474884033 grad: 2.169607785107984\n",
      "epoch: 295 loss: 1.4996225833892822 grad: 2.6218148633835456\n",
      "epoch: 296 loss: 1.5138494968414307 grad: 3.1915658773428928\n",
      "epoch: 297 loss: 1.5047085285186768 grad: 2.536525652241219\n",
      "epoch: 298 loss: 1.4967738389968872 grad: 1.6471797761999496\n",
      "epoch: 299 loss: 1.491578221321106 grad: 1.3956709842503918\n",
      "epoch: 300 loss: 1.4976780414581299 grad: 2.4313913592795644\n",
      "epoch: 301 loss: 1.4916471242904663 grad: 1.3451079060833884\n",
      "epoch: 302 loss: 1.4906396865844727 grad: 1.7396282071135396\n",
      "epoch: 303 loss: 1.4931910037994385 grad: 1.8541808924675165\n",
      "epoch: 304 loss: 1.505812406539917 grad: 3.4815435201918756\n",
      "epoch: 305 loss: 1.5295790433883667 grad: 3.073420394870881\n",
      "epoch: 306 loss: 1.5276485681533813 grad: 3.982982412292008\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 307 loss: 1.5113800764083862 grad: 1.4933631190976275\n",
      "epoch: 308 loss: 1.5159190893173218 grad: 3.701297549247792\n",
      "epoch: 309 loss: 1.519187569618225 grad: 2.8650193959838224\n",
      "epoch: 310 loss: 1.509589433670044 grad: 2.477565083400619\n",
      "epoch: 311 loss: 1.499950647354126 grad: 2.3139139912553643\n",
      "epoch: 312 loss: 1.4943217039108276 grad: 1.9417242978328793\n",
      "epoch: 313 loss: 1.499916434288025 grad: 2.7415029953864503\n",
      "epoch: 314 loss: 1.5151629447937012 grad: 2.5619694213395197\n",
      "epoch: 315 loss: 1.521702766418457 grad: 3.615077993613581\n",
      "epoch: 316 loss: 1.5060899257659912 grad: 2.9724818805069817\n",
      "epoch: 317 loss: 1.513778567314148 grad: 2.2642501651125526\n",
      "epoch: 318 loss: 1.4978071451187134 grad: 2.3513929641765334\n",
      "epoch: 319 loss: 1.532547950744629 grad: 3.2892787663417886\n",
      "epoch: 320 loss: 1.505248785018921 grad: 1.799235790647739\n",
      "epoch: 321 loss: 1.5028722286224365 grad: 2.486006705305049\n",
      "epoch: 322 loss: 1.5135369300842285 grad: 4.034887507889455\n",
      "epoch: 323 loss: 1.513380765914917 grad: 3.0961091115348593\n",
      "epoch: 324 loss: 1.5076223611831665 grad: 2.264342533493561\n",
      "epoch: 325 loss: 1.5079894065856934 grad: 2.3430939117353455\n",
      "epoch: 326 loss: 1.501865267753601 grad: 2.088906987839676\n",
      "epoch: 327 loss: 1.5006417036056519 grad: 2.1345768901958038\n",
      "epoch: 328 loss: 1.5010464191436768 grad: 1.8010875956941688\n",
      "epoch: 329 loss: 1.5055994987487793 grad: 2.6125114229488515\n",
      "epoch: 330 loss: 1.5236867666244507 grad: 2.7965380173551346\n",
      "epoch: 331 loss: 1.4982224702835083 grad: 2.136220085795336\n",
      "epoch: 332 loss: 1.5187900066375732 grad: 3.8764741726167093\n",
      "epoch: 333 loss: 1.5245121717453003 grad: 3.260259309051765\n",
      "epoch: 334 loss: 1.5000606775283813 grad: 2.042565754156886\n",
      "epoch: 335 loss: 1.498005986213684 grad: 2.5289468016028676\n",
      "epoch: 336 loss: 1.5080822706222534 grad: 1.8650877696205341\n",
      "epoch: 337 loss: 1.519129991531372 grad: 1.7074372664696114\n",
      "epoch: 338 loss: 1.5136100053787231 grad: 2.2902851380636817\n",
      "epoch: 339 loss: 1.5039970874786377 grad: 2.364214880890784\n",
      "epoch: 340 loss: 1.5038188695907593 grad: 2.6097286918125073\n",
      "epoch: 341 loss: 1.4978042840957642 grad: 2.9982647447846777\n",
      "epoch: 342 loss: 1.5125895738601685 grad: 2.75300406667531\n",
      "epoch: 343 loss: 1.5090292692184448 grad: 2.164301091586444\n",
      "epoch: 344 loss: 1.5073362588882446 grad: 2.22740579051739\n",
      "epoch: 345 loss: 1.5091521739959717 grad: 3.2995048703428114\n",
      "epoch: 346 loss: 1.4939219951629639 grad: 1.747289762354879\n",
      "epoch: 347 loss: 1.4989362955093384 grad: 2.7780810470958595\n",
      "epoch: 348 loss: 1.5092629194259644 grad: 3.090982112730179\n",
      "epoch: 349 loss: 1.5062371492385864 grad: 2.44458048669031\n",
      "epoch: 350 loss: 1.4961122274398804 grad: 2.2436486052431435\n",
      "epoch: 351 loss: 1.5083738565444946 grad: 2.2138340241453784\n",
      "epoch: 352 loss: 1.4928808212280273 grad: 2.5749837015617643\n",
      "epoch: 353 loss: 1.5162711143493652 grad: 3.1678637018969305\n",
      "epoch: 354 loss: 1.51244056224823 grad: 1.8373186157968573\n",
      "epoch: 355 loss: 1.4898492097854614 grad: 1.0951398748968648\n",
      "epoch: 356 loss: 1.5039479732513428 grad: 2.3888623722450086\n",
      "epoch: 357 loss: 1.504899024963379 grad: 3.1298755153194775\n",
      "epoch: 358 loss: 1.4961811304092407 grad: 1.5164756699948199\n",
      "epoch: 359 loss: 1.515359878540039 grad: 4.193188423157971\n",
      "epoch: 360 loss: 1.5068812370300293 grad: 1.9657822245102579\n",
      "epoch: 361 loss: 1.5016875267028809 grad: 3.4739368186034407\n",
      "epoch: 362 loss: 1.5265138149261475 grad: 3.4327322793820403\n",
      "epoch: 363 loss: 1.504633903503418 grad: 1.6976804375511563\n",
      "epoch: 364 loss: 1.500370979309082 grad: 1.1186354211488823\n",
      "epoch: 365 loss: 1.5002135038375854 grad: 2.1954521473848607\n",
      "epoch: 366 loss: 1.4940611124038696 grad: 3.1436192539041072\n",
      "epoch: 367 loss: 1.519831895828247 grad: 3.393119073808754\n",
      "epoch: 368 loss: 1.4986830949783325 grad: 1.857649879845641\n",
      "epoch: 369 loss: 1.493925929069519 grad: 1.0337456377308876\n",
      "epoch: 370 loss: 1.4991291761398315 grad: 3.0703562467442915\n",
      "epoch: 371 loss: 1.5283111333847046 grad: 3.273411663005021\n",
      "epoch: 372 loss: 1.4993159770965576 grad: 3.1941300668309434\n",
      "epoch: 373 loss: 1.4998618364334106 grad: 1.6206608725042149\n",
      "epoch: 374 loss: 1.4963632822036743 grad: 1.7746990896795707\n",
      "epoch: 375 loss: 1.4938604831695557 grad: 1.4436226697979246\n",
      "epoch: 376 loss: 1.4906336069107056 grad: 1.349457455658395\n",
      "epoch: 377 loss: 1.4999172687530518 grad: 3.1692641467477545\n",
      "epoch: 378 loss: 1.4869046211242676 grad: 1.421675118056468\n",
      "epoch: 379 loss: 1.4912959337234497 grad: 1.3244157036964601\n",
      "epoch: 380 loss: 1.4950884580612183 grad: 2.939539907246981\n",
      "epoch: 381 loss: 1.508910059928894 grad: 2.578332481391734\n",
      "epoch: 382 loss: 1.5025501251220703 grad: 2.027882354125064\n",
      "epoch: 383 loss: 1.4935803413391113 grad: 1.8398121112132477\n",
      "epoch: 384 loss: 1.4935258626937866 grad: 1.9478062907253784\n",
      "epoch: 385 loss: 1.4861027002334595 grad: 1.798285967891956\n",
      "epoch: 386 loss: 1.4965091943740845 grad: 1.2173829973747305\n",
      "epoch: 387 loss: 1.4929354190826416 grad: 2.3010180126248536\n",
      "epoch: 388 loss: 1.5078368186950684 grad: 3.354464965917185\n",
      "epoch: 389 loss: 1.5282976627349854 grad: 3.2735132954108472\n",
      "epoch: 390 loss: 1.5154691934585571 grad: 2.7539213603863577\n",
      "epoch: 391 loss: 1.4923045635223389 grad: 1.952631142429597\n",
      "epoch: 392 loss: 1.4892066717147827 grad: 1.1160066903168098\n",
      "epoch: 393 loss: 1.4836034774780273 grad: 1.082637827563426\n",
      "epoch: 394 loss: 1.4901622533798218 grad: 2.020833224238895\n",
      "epoch: 395 loss: 1.4930552244186401 grad: 2.0748142120833517\n",
      "epoch: 396 loss: 1.4954652786254883 grad: 2.0133355672385336\n",
      "epoch: 397 loss: 1.5106770992279053 grad: 2.569598354989502\n",
      "epoch: 398 loss: 1.4955098628997803 grad: 1.4887744616429874\n",
      "epoch: 399 loss: 1.5089335441589355 grad: 1.652490164656369\n",
      "epoch: 400 loss: 1.5110318660736084 grad: 1.7406126968198343\n",
      "epoch: 401 loss: 1.5027810335159302 grad: 2.1074415478628254\n",
      "epoch: 402 loss: 1.4975125789642334 grad: 1.8230227008582613\n",
      "epoch: 403 loss: 1.496938705444336 grad: 1.7642849343462892\n",
      "epoch: 404 loss: 1.4928150177001953 grad: 3.157928189068637\n",
      "epoch: 405 loss: 1.5169862508773804 grad: 2.228970413543958\n",
      "epoch: 406 loss: 1.5032120943069458 grad: 3.2918824987538993\n",
      "epoch: 407 loss: 1.5113561153411865 grad: 2.191317224409432\n",
      "epoch: 408 loss: 1.5010722875595093 grad: 1.392145973282795\n",
      "epoch: 409 loss: 1.5169062614440918 grad: 2.8988732946787428\n",
      "epoch: 410 loss: 1.5050034523010254 grad: 2.0574861336284513\n",
      "epoch: 411 loss: 1.4966468811035156 grad: 1.509896237214886\n",
      "epoch: 412 loss: 1.5089250802993774 grad: 2.3858074839672816\n",
      "epoch: 413 loss: 1.4892197847366333 grad: 1.6928926569843692\n",
      "epoch: 414 loss: 1.485196590423584 grad: 1.25315106093895\n",
      "epoch: 415 loss: 1.4949854612350464 grad: 1.7563241643236036\n",
      "epoch: 416 loss: 1.4965637922286987 grad: 1.4111690170086926\n",
      "epoch: 417 loss: 1.501909613609314 grad: 3.3510659386819994\n",
      "epoch: 418 loss: 1.5050549507141113 grad: 1.5851576332820834\n",
      "epoch: 419 loss: 1.4979989528656006 grad: 1.5342504758834123\n",
      "epoch: 420 loss: 1.495385766029358 grad: 0.897725632764829\n",
      "epoch: 421 loss: 1.5066715478897095 grad: 1.5979368402800866\n",
      "epoch: 422 loss: 1.5069568157196045 grad: 2.9352601821189417\n",
      "epoch: 423 loss: 1.5365824699401855 grad: 2.3980719325742244\n",
      "epoch: 424 loss: 1.5049763917922974 grad: 2.7454046440429214\n",
      "epoch: 425 loss: 1.4926702976226807 grad: 1.9448621588816974\n",
      "epoch: 426 loss: 1.4947096109390259 grad: 2.4038801847366504\n",
      "epoch: 427 loss: 1.5013587474822998 grad: 2.531327779538601\n",
      "epoch: 428 loss: 1.5080245733261108 grad: 3.1763761524251715\n",
      "epoch: 429 loss: 1.5301555395126343 grad: 2.5245060387780645\n",
      "epoch: 430 loss: 1.5053200721740723 grad: 2.960389185265095\n",
      "epoch: 431 loss: 1.501358985900879 grad: 2.1732396109803545\n",
      "epoch: 432 loss: 1.5190078020095825 grad: 1.913327677857396\n",
      "epoch: 433 loss: 1.5038037300109863 grad: 1.6716819280392585\n",
      "epoch: 434 loss: 1.5081720352172852 grad: 3.1422215225739727\n",
      "epoch: 435 loss: 1.4975709915161133 grad: 1.7310565124089419\n",
      "epoch: 436 loss: 1.5015614032745361 grad: 1.891320817399666\n",
      "epoch: 437 loss: 1.503585696220398 grad: 2.1949865641061437\n",
      "epoch: 438 loss: 1.492254614830017 grad: 2.0530729883574113\n",
      "epoch: 439 loss: 1.4992601871490479 grad: 2.1573092100074454\n",
      "epoch: 440 loss: 1.4950026273727417 grad: 2.3341006835823883\n",
      "epoch: 441 loss: 1.4915560483932495 grad: 1.3293361881873966\n",
      "epoch: 442 loss: 1.495152473449707 grad: 2.926847416053942\n",
      "epoch: 443 loss: 1.5073555707931519 grad: 3.285445281140587\n",
      "epoch: 444 loss: 1.515012502670288 grad: 3.352102961270948\n",
      "epoch: 445 loss: 1.4888856410980225 grad: 1.6752999326330988\n",
      "epoch: 446 loss: 1.4888629913330078 grad: 2.091230915846869\n",
      "epoch: 447 loss: 1.4897806644439697 grad: 1.155854506226087\n",
      "epoch: 448 loss: 1.5011494159698486 grad: 2.522388759968757\n",
      "epoch: 449 loss: 1.4980108737945557 grad: 3.1766390702371607\n",
      "epoch: 450 loss: 1.516759991645813 grad: 2.371028426451111\n",
      "epoch: 451 loss: 1.4927223920822144 grad: 1.6197209332343765\n",
      "epoch: 452 loss: 1.4978948831558228 grad: 2.328475490720971\n",
      "epoch: 453 loss: 1.5055712461471558 grad: 3.0700592970391267\n",
      "epoch: 454 loss: 1.4952082633972168 grad: 1.9902185993624326\n",
      "epoch: 455 loss: 1.4989737272262573 grad: 2.162467624806131\n",
      "epoch: 456 loss: 1.495989441871643 grad: 1.7611431563432691\n",
      "epoch: 457 loss: 1.4897431135177612 grad: 1.798071028837844\n",
      "epoch: 458 loss: 1.4853675365447998 grad: 1.0856201619318562\n",
      "epoch: 459 loss: 1.4927978515625 grad: 1.5299399357310421\n",
      "epoch: 460 loss: 1.499182939529419 grad: 2.3737183027989692\n",
      "epoch: 461 loss: 1.5037816762924194 grad: 2.352244614427223\n",
      "epoch: 462 loss: 1.5005180835723877 grad: 1.511520068045269\n",
      "epoch: 463 loss: 1.4902901649475098 grad: 1.4365565844261403\n",
      "epoch: 464 loss: 1.490958333015442 grad: 1.507055002735863\n",
      "epoch: 465 loss: 1.5072156190872192 grad: 1.5646313459752812\n",
      "epoch: 466 loss: 1.503550410270691 grad: 1.5633856763064702\n",
      "epoch: 467 loss: 1.5073752403259277 grad: 1.8305661889580376\n",
      "epoch: 468 loss: 1.4890096187591553 grad: 1.5189614609913575\n",
      "epoch: 469 loss: 1.4985932111740112 grad: 2.3014014274411334\n",
      "epoch: 470 loss: 1.5023736953735352 grad: 2.052361322325693\n",
      "epoch: 471 loss: 1.4908249378204346 grad: 1.8325570081507006\n",
      "epoch: 472 loss: 1.4992833137512207 grad: 1.918736494797262\n",
      "epoch: 473 loss: 1.493788480758667 grad: 1.8363767645208147\n",
      "epoch: 474 loss: 1.483332633972168 grad: 1.8677254140019721\n",
      "epoch: 475 loss: 1.5129332542419434 grad: 1.823203853048781\n",
      "epoch: 476 loss: 1.4940837621688843 grad: 1.9901489614715817\n",
      "epoch: 477 loss: 1.4960196018218994 grad: 1.2030130727850838\n",
      "epoch: 478 loss: 1.4822466373443604 grad: 1.2543709239987784\n",
      "epoch: 479 loss: 1.499842643737793 grad: 1.2026112556174433\n",
      "epoch: 480 loss: 1.4946284294128418 grad: 2.587842816933942\n",
      "epoch: 481 loss: 1.5348354578018188 grad: 3.1967530280431\n",
      "epoch: 482 loss: 1.5004881620407104 grad: 1.9569231592073664\n",
      "epoch: 483 loss: 1.4929111003875732 grad: 2.226220245565655\n",
      "epoch: 484 loss: 1.4964040517807007 grad: 2.3862764103021097\n",
      "epoch: 485 loss: 1.4878736734390259 grad: 1.0988819458190802\n",
      "epoch: 486 loss: 1.486249327659607 grad: 0.8193553366495308\n",
      "epoch: 487 loss: 1.4922218322753906 grad: 1.4306781373811635\n",
      "epoch: 488 loss: 1.4886232614517212 grad: 1.2450364302100572\n",
      "epoch: 489 loss: 1.4875595569610596 grad: 2.5813825718075565\n",
      "epoch: 490 loss: 1.4854512214660645 grad: 2.405003985645718\n",
      "epoch: 491 loss: 1.4908326864242554 grad: 1.9725027798576729\n",
      "epoch: 492 loss: 1.4955077171325684 grad: 2.1488210375870738\n",
      "epoch: 493 loss: 1.493005394935608 grad: 2.5109461520888248\n",
      "epoch: 494 loss: 1.495689868927002 grad: 1.2421652595986103\n",
      "epoch: 495 loss: 1.4976011514663696 grad: 1.7699523543650966\n",
      "epoch: 496 loss: 1.4863163232803345 grad: 0.8513367042160331\n",
      "epoch: 497 loss: 1.4946894645690918 grad: 1.7840445787365065\n",
      "epoch: 498 loss: 1.4902398586273193 grad: 2.977733918426406\n",
      "epoch: 499 loss: 1.4949097633361816 grad: 1.305372462984885\n",
      "1.8240186721086502\n",
      "epoch: 0 loss: 2.302560329437256 grad: 1.6235420847522273\n",
      "epoch: 1 loss: 2.3020806312561035 grad: 1.6137204534625487\n",
      "epoch: 2 loss: 2.3020856380462646 grad: 1.6288725823637038\n",
      "epoch: 3 loss: 2.3021719455718994 grad: 1.6249855577147432\n",
      "epoch: 4 loss: 2.302445650100708 grad: 1.6305912693589186\n",
      "epoch: 5 loss: 2.302647590637207 grad: 1.6218872033170468\n",
      "epoch: 6 loss: 2.3022124767303467 grad: 1.6263632839360822\n",
      "epoch: 7 loss: 2.302314281463623 grad: 1.6157277599051003\n",
      "epoch: 8 loss: 2.3029520511627197 grad: 1.6189122256833972\n",
      "epoch: 9 loss: 2.302332878112793 grad: 1.617257627887681\n",
      "epoch: 10 loss: 2.3022730350494385 grad: 1.6322492532476427\n",
      "epoch: 11 loss: 2.3022549152374268 grad: 1.6289044814590838\n",
      "epoch: 12 loss: 2.3018853664398193 grad: 1.633348845789904\n",
      "epoch: 13 loss: 2.302164077758789 grad: 1.6257684413705848\n",
      "epoch: 14 loss: 2.3029162883758545 grad: 1.6121308145848738\n",
      "epoch: 15 loss: 2.3021280765533447 grad: 1.62167994397515\n",
      "epoch: 16 loss: 2.3021087646484375 grad: 1.6234674516451797\n",
      "epoch: 17 loss: 2.3017337322235107 grad: 1.640485856105529\n",
      "epoch: 18 loss: 2.302582025527954 grad: 1.6227312853286369\n",
      "epoch: 19 loss: 2.3020308017730713 grad: 1.628164530794565\n",
      "epoch: 20 loss: 2.3025197982788086 grad: 1.6121482617048073\n",
      "epoch: 21 loss: 2.302510976791382 grad: 1.6217072493644313\n",
      "epoch: 22 loss: 2.3025684356689453 grad: 1.6151799809313305\n",
      "epoch: 23 loss: 2.302130699157715 grad: 1.623891987904374\n",
      "epoch: 24 loss: 2.302556037902832 grad: 1.6076749841431304\n",
      "epoch: 25 loss: 2.3020052909851074 grad: 1.6294651415479917\n",
      "epoch: 26 loss: 2.3020429611206055 grad: 1.62729925095355\n",
      "epoch: 27 loss: 2.3019566535949707 grad: 1.6251564130283123\n",
      "epoch: 28 loss: 2.3022241592407227 grad: 1.6046075538643414\n",
      "epoch: 29 loss: 2.302234649658203 grad: 1.6277650221554\n",
      "epoch: 30 loss: 2.30208683013916 grad: 1.6290579098221358\n",
      "epoch: 31 loss: 2.302394390106201 grad: 1.6177170931043783\n",
      "epoch: 32 loss: 2.3018758296966553 grad: 1.6307168761711746\n",
      "epoch: 33 loss: 2.302091360092163 grad: 1.634412437791951\n",
      "epoch: 34 loss: 2.3021371364593506 grad: 1.6248406621827078\n",
      "epoch: 35 loss: 2.301806926727295 grad: 1.6235660970421686\n",
      "epoch: 36 loss: 2.301516532897949 grad: 1.6394819706652521\n",
      "epoch: 37 loss: 2.3017380237579346 grad: 1.6420978293975903\n",
      "epoch: 38 loss: 2.3024327754974365 grad: 1.6297726857342891\n",
      "epoch: 39 loss: 2.302109956741333 grad: 1.628061540783309\n",
      "epoch: 40 loss: 2.3021178245544434 grad: 1.6274010816529867\n",
      "epoch: 41 loss: 2.302668571472168 grad: 1.6191532716214183\n",
      "epoch: 42 loss: 2.3018271923065186 grad: 1.6364067641755802\n",
      "epoch: 43 loss: 2.3013789653778076 grad: 1.635345706095298\n",
      "epoch: 44 loss: 2.3023016452789307 grad: 1.635524003056898\n",
      "epoch: 45 loss: 2.301898717880249 grad: 1.6307717409827525\n",
      "epoch: 46 loss: 2.301189422607422 grad: 1.6555287389857103\n",
      "epoch: 47 loss: 2.3018715381622314 grad: 1.6348978663380775\n",
      "epoch: 48 loss: 2.30214786529541 grad: 1.6250234572290783\n",
      "epoch: 49 loss: 2.301880121231079 grad: 1.6406419678750108\n",
      "epoch: 50 loss: 2.301009178161621 grad: 1.6502349770125297\n",
      "epoch: 51 loss: 2.3014094829559326 grad: 1.6438817053604575\n",
      "epoch: 52 loss: 2.301832437515259 grad: 1.637880716811023\n",
      "epoch: 53 loss: 2.3017914295196533 grad: 1.6368755924585645\n",
      "epoch: 54 loss: 2.302233934402466 grad: 1.6160216920136932\n",
      "epoch: 55 loss: 2.300975799560547 grad: 1.6461696992665233\n",
      "epoch: 56 loss: 2.3018860816955566 grad: 1.6413663964966194\n",
      "epoch: 57 loss: 2.3016679286956787 grad: 1.6396820414774416\n",
      "epoch: 58 loss: 2.301837205886841 grad: 1.628932245862892\n",
      "epoch: 59 loss: 2.3017969131469727 grad: 1.6312645129556398\n",
      "epoch: 60 loss: 2.301724672317505 grad: 1.6381689801937827\n",
      "epoch: 61 loss: 2.301823616027832 grad: 1.6336772572470917\n",
      "epoch: 62 loss: 2.301861524581909 grad: 1.6351676651125124\n",
      "epoch: 63 loss: 2.3022286891937256 grad: 1.6305290598547943\n",
      "epoch: 64 loss: 2.301754951477051 grad: 1.643681922040525\n",
      "epoch: 65 loss: 2.3017001152038574 grad: 1.6344581697568563\n",
      "epoch: 66 loss: 2.3016700744628906 grad: 1.6431766394451852\n",
      "epoch: 67 loss: 2.3019020557403564 grad: 1.6410764230577837\n",
      "epoch: 68 loss: 2.3022468090057373 grad: 1.6315321500804867\n",
      "epoch: 69 loss: 2.300652265548706 grad: 1.6638208693152086\n",
      "epoch: 70 loss: 2.3016674518585205 grad: 1.6338772634654084\n",
      "epoch: 71 loss: 2.3014822006225586 grad: 1.6567502518457966\n",
      "epoch: 72 loss: 2.3018691539764404 grad: 1.6517573545967776\n",
      "epoch: 73 loss: 2.3008899688720703 grad: 1.6357176173182706\n",
      "epoch: 74 loss: 2.301361560821533 grad: 1.644255686209478\n",
      "epoch: 75 loss: 2.301058769226074 grad: 1.6463791235010066\n",
      "epoch: 76 loss: 2.3014180660247803 grad: 1.63934119236249\n",
      "epoch: 77 loss: 2.3019394874572754 grad: 1.6505452868314312\n",
      "epoch: 78 loss: 2.301204204559326 grad: 1.6548139031880373\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 79 loss: 2.3011534214019775 grad: 1.6534727838237784\n",
      "epoch: 80 loss: 2.3010528087615967 grad: 1.6582193774455745\n",
      "epoch: 81 loss: 2.3010432720184326 grad: 1.6589082851895087\n",
      "epoch: 82 loss: 2.301077127456665 grad: 1.662388843790968\n",
      "epoch: 83 loss: 2.301009178161621 grad: 1.6654880161744556\n",
      "epoch: 84 loss: 2.301180839538574 grad: 1.645524248961241\n",
      "epoch: 85 loss: 2.300567865371704 grad: 1.6672459320527397\n",
      "epoch: 86 loss: 2.301227569580078 grad: 1.658738358129215\n",
      "epoch: 87 loss: 2.3011677265167236 grad: 1.6575597179573147\n",
      "epoch: 88 loss: 2.301320791244507 grad: 1.6706640912212491\n",
      "epoch: 89 loss: 2.3006386756896973 grad: 1.662129311633873\n",
      "epoch: 90 loss: 2.300227642059326 grad: 1.6825083776502796\n",
      "epoch: 91 loss: 2.3008177280426025 grad: 1.6659528619909127\n",
      "epoch: 92 loss: 2.3005847930908203 grad: 1.666390021834227\n",
      "epoch: 93 loss: 2.3003594875335693 grad: 1.6915941561945522\n",
      "epoch: 94 loss: 2.301086664199829 grad: 1.6811838018678364\n",
      "epoch: 95 loss: 2.300527811050415 grad: 1.6895980636130958\n",
      "epoch: 96 loss: 2.3012349605560303 grad: 1.6762871020917027\n",
      "epoch: 97 loss: 2.2999587059020996 grad: 1.6950290260489085\n",
      "epoch: 98 loss: 2.3003437519073486 grad: 1.694909526837162\n",
      "epoch: 99 loss: 2.3005123138427734 grad: 1.6887740392001376\n",
      "epoch: 100 loss: 2.300720691680908 grad: 1.6728570768720514\n",
      "epoch: 101 loss: 2.3009238243103027 grad: 1.6899896357245447\n",
      "epoch: 102 loss: 2.3001811504364014 grad: 1.6987221990822858\n",
      "epoch: 103 loss: 2.2999672889709473 grad: 1.7159645067720068\n",
      "epoch: 104 loss: 2.3000104427337646 grad: 1.7098655319210911\n",
      "epoch: 105 loss: 2.2998595237731934 grad: 1.708243677259556\n",
      "epoch: 106 loss: 2.299893617630005 grad: 1.7167959999817881\n",
      "epoch: 107 loss: 2.29974365234375 grad: 1.7163566105540782\n",
      "epoch: 108 loss: 2.2998287677764893 grad: 1.7071253431717022\n",
      "epoch: 109 loss: 2.299679756164551 grad: 1.7308232752044523\n",
      "epoch: 110 loss: 2.2995383739471436 grad: 1.7256699540219935\n",
      "epoch: 111 loss: 2.299823522567749 grad: 1.732423401487592\n",
      "epoch: 112 loss: 2.2993295192718506 grad: 1.7326297611922086\n",
      "epoch: 113 loss: 2.2990567684173584 grad: 1.7544335327942722\n",
      "epoch: 114 loss: 2.298969268798828 grad: 1.7487966378869872\n",
      "epoch: 115 loss: 2.2993712425231934 grad: 1.7564052514074044\n",
      "epoch: 116 loss: 2.2993247509002686 grad: 1.7547972945326438\n",
      "epoch: 117 loss: 2.299468994140625 grad: 1.759195471082681\n",
      "epoch: 118 loss: 2.2991700172424316 grad: 1.7558688732669763\n",
      "epoch: 119 loss: 2.298827886581421 grad: 1.7822187755271675\n",
      "epoch: 120 loss: 2.299084424972534 grad: 1.784007915957195\n",
      "epoch: 121 loss: 2.298360586166382 grad: 1.799305571296755\n",
      "epoch: 122 loss: 2.2979986667633057 grad: 1.8178858685506774\n",
      "epoch: 123 loss: 2.298768997192383 grad: 1.7921648715171845\n",
      "epoch: 124 loss: 2.2976739406585693 grad: 1.8319500219298614\n",
      "epoch: 125 loss: 2.297940969467163 grad: 1.8352412176651083\n",
      "epoch: 126 loss: 2.298159122467041 grad: 1.8393746939421232\n",
      "epoch: 127 loss: 2.297656297683716 grad: 1.8374288084044579\n",
      "epoch: 128 loss: 2.297936201095581 grad: 1.838981106954937\n",
      "epoch: 129 loss: 2.2972445487976074 grad: 1.8530841561566507\n",
      "epoch: 130 loss: 2.297241449356079 grad: 1.8840855571204826\n",
      "epoch: 131 loss: 2.2975192070007324 grad: 1.8862978186243997\n",
      "epoch: 132 loss: 2.2970964908599854 grad: 1.9084066727183877\n",
      "epoch: 133 loss: 2.296353578567505 grad: 1.9176914513310683\n",
      "epoch: 134 loss: 2.295771598815918 grad: 1.9769855118097945\n",
      "epoch: 135 loss: 2.2967257499694824 grad: 1.9414496351798465\n",
      "epoch: 136 loss: 2.295386791229248 grad: 1.9899761726089296\n",
      "epoch: 137 loss: 2.2948989868164062 grad: 2.0094189960287796\n",
      "epoch: 138 loss: 2.2946176528930664 grad: 2.021826336766401\n",
      "epoch: 139 loss: 2.2953453063964844 grad: 2.0213711814962267\n",
      "epoch: 140 loss: 2.294684410095215 grad: 2.0369878908626675\n",
      "epoch: 141 loss: 2.293193817138672 grad: 2.1094289859276385\n",
      "epoch: 142 loss: 2.293797731399536 grad: 2.108168094873517\n",
      "epoch: 143 loss: 2.2922544479370117 grad: 2.144181622827928\n",
      "epoch: 144 loss: 2.2927536964416504 grad: 2.162834728251226\n",
      "epoch: 145 loss: 2.2928740978240967 grad: 2.1765658372998358\n",
      "epoch: 146 loss: 2.2921671867370605 grad: 2.202329996359786\n",
      "epoch: 147 loss: 2.2906973361968994 grad: 2.230105456885039\n",
      "epoch: 148 loss: 2.2894670963287354 grad: 2.2697165049427737\n",
      "epoch: 149 loss: 2.2907958030700684 grad: 2.3045920651842144\n",
      "epoch: 150 loss: 2.29095196723938 grad: 2.2474827551142504\n",
      "epoch: 151 loss: 2.2885079383850098 grad: 2.3299409528521613\n",
      "epoch: 152 loss: 2.28762149810791 grad: 2.4109710870155445\n",
      "epoch: 153 loss: 2.286661386489868 grad: 2.37224006956251\n",
      "epoch: 154 loss: 2.285642147064209 grad: 2.44288838707975\n",
      "epoch: 155 loss: 2.285283088684082 grad: 2.3756648671244167\n",
      "epoch: 156 loss: 2.284982919692993 grad: 2.466170998364096\n",
      "epoch: 157 loss: 2.2833547592163086 grad: 2.4510853886493438\n",
      "epoch: 158 loss: 2.282792329788208 grad: 2.4468051397152957\n",
      "epoch: 159 loss: 2.2825121879577637 grad: 2.4118726375911916\n",
      "epoch: 160 loss: 2.2811930179595947 grad: 2.4697586330806924\n",
      "epoch: 161 loss: 2.2820606231689453 grad: 2.444933786522597\n",
      "epoch: 162 loss: 2.279419183731079 grad: 2.4581491947617558\n",
      "epoch: 163 loss: 2.2798421382904053 grad: 2.4530804767051624\n",
      "epoch: 164 loss: 2.280174493789673 grad: 2.4456816088844326\n",
      "epoch: 165 loss: 2.277984380722046 grad: 2.4314009646463783\n",
      "epoch: 166 loss: 2.277578115463257 grad: 2.427656657169647\n",
      "epoch: 167 loss: 2.2763493061065674 grad: 2.4245082928673436\n",
      "epoch: 168 loss: 2.277576208114624 grad: 2.3878973082062744\n",
      "epoch: 169 loss: 2.2747013568878174 grad: 2.4361663292095597\n",
      "epoch: 170 loss: 2.2757043838500977 grad: 2.419912447062661\n",
      "epoch: 171 loss: 2.2755789756774902 grad: 2.3688304108338403\n",
      "epoch: 172 loss: 2.2739548683166504 grad: 2.390581970561355\n",
      "epoch: 173 loss: 2.2746684551239014 grad: 2.4424690087510657\n",
      "epoch: 174 loss: 2.2728323936462402 grad: 2.34210542933498\n",
      "epoch: 175 loss: 2.273266553878784 grad: 2.4473458831050685\n",
      "epoch: 176 loss: 2.27268123626709 grad: 2.3782696679552338\n",
      "epoch: 177 loss: 2.2734873294830322 grad: 2.43837592175733\n",
      "epoch: 178 loss: 2.271182060241699 grad: 2.3844121637114783\n",
      "epoch: 179 loss: 2.272552728652954 grad: 2.3642734871172006\n",
      "epoch: 180 loss: 2.27099347114563 grad: 2.370559752220288\n",
      "epoch: 181 loss: 2.271716833114624 grad: 2.4192819869227056\n",
      "epoch: 182 loss: 2.2699177265167236 grad: 2.3583573778566445\n",
      "epoch: 183 loss: 2.2701542377471924 grad: 2.4279706887013854\n",
      "epoch: 184 loss: 2.268686532974243 grad: 2.4058229382637712\n",
      "epoch: 185 loss: 2.2702291011810303 grad: 2.4319808735504806\n",
      "epoch: 186 loss: 2.2687315940856934 grad: 2.384071379574755\n",
      "epoch: 187 loss: 2.269749402999878 grad: 2.3356502245823365\n",
      "epoch: 188 loss: 2.2690749168395996 grad: 2.366004538064497\n",
      "epoch: 189 loss: 2.266319751739502 grad: 2.397693949378288\n",
      "epoch: 190 loss: 2.2681193351745605 grad: 2.4102815693126076\n",
      "epoch: 191 loss: 2.267462968826294 grad: 2.4541910265254536\n",
      "epoch: 192 loss: 2.2650668621063232 grad: 2.388780127756209\n",
      "epoch: 193 loss: 2.267280101776123 grad: 2.3846741137686114\n",
      "epoch: 194 loss: 2.265683174133301 grad: 2.4746577472810354\n",
      "epoch: 195 loss: 2.2658045291900635 grad: 2.4027158349035456\n",
      "epoch: 196 loss: 2.2639057636260986 grad: 2.4662083992291066\n",
      "epoch: 197 loss: 2.263744592666626 grad: 2.4256039278411734\n",
      "epoch: 198 loss: 2.2645750045776367 grad: 2.4447519811173337\n",
      "epoch: 199 loss: 2.2624459266662598 grad: 2.422947545109006\n",
      "epoch: 200 loss: 2.261719226837158 grad: 2.454578000959748\n",
      "epoch: 201 loss: 2.261657238006592 grad: 2.4444593004734507\n",
      "epoch: 202 loss: 2.262206554412842 grad: 2.430590155870757\n",
      "epoch: 203 loss: 2.2626564502716064 grad: 2.436977224457743\n",
      "epoch: 204 loss: 2.2626163959503174 grad: 2.5385969705798384\n",
      "epoch: 205 loss: 2.2622127532958984 grad: 2.5330699609245158\n",
      "epoch: 206 loss: 2.2604970932006836 grad: 2.510571608704234\n",
      "epoch: 207 loss: 2.2601542472839355 grad: 2.500852769455089\n",
      "epoch: 208 loss: 2.259655714035034 grad: 2.5564537285050997\n",
      "epoch: 209 loss: 2.2592761516571045 grad: 2.5728661206085235\n",
      "epoch: 210 loss: 2.260385513305664 grad: 2.712299555118772\n",
      "epoch: 211 loss: 2.25887131690979 grad: 2.6711822029254915\n",
      "epoch: 212 loss: 2.258100986480713 grad: 2.6397984489125923\n",
      "epoch: 213 loss: 2.2553305625915527 grad: 2.6860417774028424\n",
      "epoch: 214 loss: 2.2562358379364014 grad: 2.7295915243023683\n",
      "epoch: 215 loss: 2.2571933269500732 grad: 2.73381292012461\n",
      "epoch: 216 loss: 2.2553606033325195 grad: 2.741746648425414\n",
      "epoch: 217 loss: 2.2541706562042236 grad: 2.8720300564143275\n",
      "epoch: 218 loss: 2.2537686824798584 grad: 2.8442119666086954\n",
      "epoch: 219 loss: 2.2531237602233887 grad: 2.866739167857708\n",
      "epoch: 220 loss: 2.2539827823638916 grad: 2.913703732942748\n",
      "epoch: 221 loss: 2.249580144882202 grad: 2.988709180431056\n",
      "epoch: 222 loss: 2.2507736682891846 grad: 3.024926670043478\n",
      "epoch: 223 loss: 2.247889280319214 grad: 3.105095258973066\n",
      "epoch: 224 loss: 2.2468183040618896 grad: 3.304738971633866\n",
      "epoch: 225 loss: 2.2457900047302246 grad: 3.3527672485788425\n",
      "epoch: 226 loss: 2.2438201904296875 grad: 3.2392184400287944\n",
      "epoch: 227 loss: 2.2379355430603027 grad: 3.2762090712342236\n",
      "epoch: 228 loss: 2.238197088241577 grad: 3.4752882714531133\n",
      "epoch: 229 loss: 2.235715866088867 grad: 3.370812024917483\n",
      "epoch: 230 loss: 2.2347636222839355 grad: 3.5577342177977758\n",
      "epoch: 231 loss: 2.2304673194885254 grad: 3.315721034090818\n",
      "epoch: 232 loss: 2.22603178024292 grad: 3.4246362679164917\n",
      "epoch: 233 loss: 2.2236149311065674 grad: 3.4397515441911914\n",
      "epoch: 234 loss: 2.2231056690216064 grad: 3.396032388070746\n",
      "epoch: 235 loss: 2.219637155532837 grad: 3.4868929445566166\n",
      "epoch: 236 loss: 2.2161452770233154 grad: 3.294334502399175\n",
      "epoch: 237 loss: 2.2145392894744873 grad: 3.2895388269227825\n",
      "epoch: 238 loss: 2.213515520095825 grad: 3.2219101139492103\n",
      "epoch: 239 loss: 2.2123844623565674 grad: 3.193063779892991\n",
      "epoch: 240 loss: 2.21097993850708 grad: 3.2887942187362422\n",
      "epoch: 241 loss: 2.2073075771331787 grad: 3.092121078943213\n",
      "epoch: 242 loss: 2.208693265914917 grad: 3.109650838536225\n",
      "epoch: 243 loss: 2.2064459323883057 grad: 3.0003768691297856\n",
      "epoch: 244 loss: 2.204280138015747 grad: 3.1061961103992033\n",
      "epoch: 245 loss: 2.204822301864624 grad: 3.0508158967187184\n",
      "epoch: 246 loss: 2.2039620876312256 grad: 2.9660871019402135\n",
      "epoch: 247 loss: 2.2029354572296143 grad: 2.8078365560125795\n",
      "epoch: 248 loss: 2.2007174491882324 grad: 2.8390293431834186\n",
      "epoch: 249 loss: 2.199631452560425 grad: 2.876017550634782\n",
      "epoch: 250 loss: 2.1993601322174072 grad: 2.8570974016162967\n",
      "epoch: 251 loss: 2.2002124786376953 grad: 2.7507812685392325\n",
      "epoch: 252 loss: 2.197845220565796 grad: 2.9206490151950026\n",
      "epoch: 253 loss: 2.1988942623138428 grad: 2.74271459236098\n",
      "epoch: 254 loss: 2.1960289478302 grad: 2.7842926550915257\n",
      "epoch: 255 loss: 2.198486328125 grad: 2.948002568963501\n",
      "epoch: 256 loss: 2.1961262226104736 grad: 2.7392372958332536\n",
      "epoch: 257 loss: 2.1943275928497314 grad: 2.827734824510232\n",
      "epoch: 258 loss: 2.1961443424224854 grad: 2.794944597822097\n",
      "epoch: 259 loss: 2.1919026374816895 grad: 2.759704614353795\n",
      "epoch: 260 loss: 2.1937196254730225 grad: 2.6933369559295004\n",
      "epoch: 261 loss: 2.190217971801758 grad: 2.5580734471857016\n",
      "epoch: 262 loss: 2.193488121032715 grad: 2.6528390981755883\n",
      "epoch: 263 loss: 2.1902592182159424 grad: 2.6604511386655743\n",
      "epoch: 264 loss: 2.191495418548584 grad: 2.6163668327591574\n",
      "epoch: 265 loss: 2.189486503601074 grad: 2.475819718977806\n",
      "epoch: 266 loss: 2.189236640930176 grad: 2.5461742048658107\n",
      "epoch: 267 loss: 2.1900062561035156 grad: 2.4529330584494073\n",
      "epoch: 268 loss: 2.189586639404297 grad: 2.486556712752356\n",
      "epoch: 269 loss: 2.1898441314697266 grad: 2.6440025434112324\n",
      "epoch: 270 loss: 2.1868302822113037 grad: 2.5505399758768608\n",
      "epoch: 271 loss: 2.1878914833068848 grad: 2.655284039761191\n",
      "epoch: 272 loss: 2.1869194507598877 grad: 2.5570112008837955\n",
      "epoch: 273 loss: 2.1880149841308594 grad: 2.537357815369476\n",
      "epoch: 274 loss: 2.186067819595337 grad: 2.51367930007825\n",
      "epoch: 275 loss: 2.185028314590454 grad: 2.365753798594048\n",
      "epoch: 276 loss: 2.1858901977539062 grad: 2.4515386490421074\n",
      "epoch: 277 loss: 2.185554265975952 grad: 2.555576525678459\n",
      "epoch: 278 loss: 2.184748888015747 grad: 2.3782279331492084\n",
      "epoch: 279 loss: 2.1847126483917236 grad: 2.5533319632984726\n",
      "epoch: 280 loss: 2.184715986251831 grad: 2.4806903200445785\n",
      "epoch: 281 loss: 2.1844286918640137 grad: 2.551034927650887\n",
      "epoch: 282 loss: 2.182729482650757 grad: 2.4084292087955252\n",
      "epoch: 283 loss: 2.1832263469696045 grad: 2.506700748483473\n",
      "epoch: 284 loss: 2.182497978210449 grad: 2.360948756505321\n",
      "epoch: 285 loss: 2.1818044185638428 grad: 2.5306850073282563\n",
      "epoch: 286 loss: 2.182178258895874 grad: 2.409137566023255\n",
      "epoch: 287 loss: 2.1825079917907715 grad: 2.4040164234918646\n",
      "epoch: 288 loss: 2.180279016494751 grad: 2.448386715124509\n",
      "epoch: 289 loss: 2.1821155548095703 grad: 2.461518045971244\n",
      "epoch: 290 loss: 2.1782851219177246 grad: 2.381434145969309\n",
      "epoch: 291 loss: 2.1802167892456055 grad: 2.3069322812869877\n",
      "epoch: 292 loss: 2.1794028282165527 grad: 2.3612141032289298\n",
      "epoch: 293 loss: 2.179980754852295 grad: 2.4657293262370374\n",
      "epoch: 294 loss: 2.1794934272766113 grad: 2.38000047867859\n",
      "epoch: 295 loss: 2.1804471015930176 grad: 2.462324298306605\n",
      "epoch: 296 loss: 2.182755947113037 grad: 2.5253942901608606\n",
      "epoch: 297 loss: 2.1800944805145264 grad: 2.5259528958002133\n",
      "epoch: 298 loss: 2.1768383979797363 grad: 2.4186488212888233\n",
      "epoch: 299 loss: 2.1783981323242188 grad: 2.4562400497093293\n",
      "epoch: 300 loss: 2.1778783798217773 grad: 2.4376790561521102\n",
      "epoch: 301 loss: 2.1790904998779297 grad: 2.6211275845795634\n",
      "epoch: 302 loss: 2.178257703781128 grad: 2.386525447885062\n",
      "epoch: 303 loss: 2.177149772644043 grad: 2.351780989573204\n",
      "epoch: 304 loss: 2.17714262008667 grad: 2.4614960017617764\n",
      "epoch: 305 loss: 2.1754088401794434 grad: 2.486803162892881\n",
      "epoch: 306 loss: 2.1768388748168945 grad: 2.3532317359562196\n",
      "epoch: 307 loss: 2.1788949966430664 grad: 2.3224457420098283\n",
      "epoch: 308 loss: 2.1771252155303955 grad: 2.530070677667575\n",
      "epoch: 309 loss: 2.174407482147217 grad: 2.415588023364618\n",
      "epoch: 310 loss: 2.175267219543457 grad: 2.386666646077564\n",
      "epoch: 311 loss: 2.1749424934387207 grad: 2.509123102857894\n",
      "epoch: 312 loss: 2.1755411624908447 grad: 2.419818955551212\n",
      "epoch: 313 loss: 2.175360679626465 grad: 2.437031837274498\n",
      "epoch: 314 loss: 2.173494577407837 grad: 2.388795450769572\n",
      "epoch: 315 loss: 2.1738359928131104 grad: 2.5232271175232848\n",
      "epoch: 316 loss: 2.1747069358825684 grad: 2.386791376565169\n",
      "epoch: 317 loss: 2.174520492553711 grad: 2.435407296739637\n",
      "epoch: 318 loss: 2.1734068393707275 grad: 2.4063738184862786\n",
      "epoch: 319 loss: 2.172495126724243 grad: 2.3743206058769295\n",
      "epoch: 320 loss: 2.174428701400757 grad: 2.4353976759427627\n",
      "epoch: 321 loss: 2.172880172729492 grad: 2.3894947719582844\n",
      "epoch: 322 loss: 2.1716413497924805 grad: 2.2872804787641923\n",
      "epoch: 323 loss: 2.1718246936798096 grad: 2.4296834487431047\n",
      "epoch: 324 loss: 2.172123432159424 grad: 2.321994228896478\n",
      "epoch: 325 loss: 2.170949935913086 grad: 2.5200747339173204\n",
      "epoch: 326 loss: 2.17183780670166 grad: 2.310215803057266\n",
      "epoch: 327 loss: 2.1716556549072266 grad: 2.501597441566576\n",
      "epoch: 328 loss: 2.171046733856201 grad: 2.4627676415866953\n",
      "epoch: 329 loss: 2.169919490814209 grad: 2.355609765705017\n",
      "epoch: 330 loss: 2.1694395542144775 grad: 2.4192670677633337\n",
      "epoch: 331 loss: 2.1703460216522217 grad: 2.3136375359414765\n",
      "epoch: 332 loss: 2.169126033782959 grad: 2.4012792757342734\n",
      "epoch: 333 loss: 2.170545816421509 grad: 2.491181931103624\n",
      "epoch: 334 loss: 2.1689178943634033 grad: 2.549593926187501\n",
      "epoch: 335 loss: 2.1730329990386963 grad: 2.5703696060134837\n",
      "epoch: 336 loss: 2.170421838760376 grad: 2.499645808314358\n",
      "epoch: 337 loss: 2.168454170227051 grad: 2.4231234408660036\n",
      "epoch: 338 loss: 2.1694443225860596 grad: 2.4651716889163096\n",
      "epoch: 339 loss: 2.168379545211792 grad: 2.5650741115493316\n",
      "epoch: 340 loss: 2.1688876152038574 grad: 2.4023709046148087\n",
      "epoch: 341 loss: 2.1695542335510254 grad: 2.4847605104007506\n",
      "epoch: 342 loss: 2.1679022312164307 grad: 2.5276009723015633\n",
      "epoch: 343 loss: 2.167466163635254 grad: 2.2619508719311967\n",
      "epoch: 344 loss: 2.16618275642395 grad: 2.4614269537130546\n",
      "epoch: 345 loss: 2.1677141189575195 grad: 2.406759962291708\n",
      "epoch: 346 loss: 2.166034460067749 grad: 2.4603178949143354\n",
      "epoch: 347 loss: 2.165947437286377 grad: 2.5055702442454826\n",
      "epoch: 348 loss: 2.1658458709716797 grad: 2.4607195266418986\n",
      "epoch: 349 loss: 2.1673264503479004 grad: 2.3777112236638214\n",
      "epoch: 350 loss: 2.1657233238220215 grad: 2.3347900967937822\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 351 loss: 2.1662869453430176 grad: 2.5624635679913417\n",
      "epoch: 352 loss: 2.163923978805542 grad: 2.3309590174033055\n",
      "epoch: 353 loss: 2.1670913696289062 grad: 2.5618411163071406\n",
      "epoch: 354 loss: 2.1636855602264404 grad: 2.465608689120956\n",
      "epoch: 355 loss: 2.16520094871521 grad: 2.5343290106670575\n",
      "epoch: 356 loss: 2.165828227996826 grad: 2.5106684470564007\n",
      "epoch: 357 loss: 2.1637656688690186 grad: 2.4839646876216794\n",
      "epoch: 358 loss: 2.1644954681396484 grad: 2.4597208892449824\n",
      "epoch: 359 loss: 2.1627471446990967 grad: 2.4377554283747154\n",
      "epoch: 360 loss: 2.164215326309204 grad: 2.5516228737043485\n",
      "epoch: 361 loss: 2.1639108657836914 grad: 2.567239992364886\n",
      "epoch: 362 loss: 2.164907455444336 grad: 2.5516466854236253\n",
      "epoch: 363 loss: 2.1632752418518066 grad: 2.479700064920406\n",
      "epoch: 364 loss: 2.162715196609497 grad: 2.508605919575082\n",
      "epoch: 365 loss: 2.162285566329956 grad: 2.4853017765119496\n",
      "epoch: 366 loss: 2.1628811359405518 grad: 2.596110205685291\n",
      "epoch: 367 loss: 2.1626791954040527 grad: 2.5705088810803045\n",
      "epoch: 368 loss: 2.16577410697937 grad: 2.7576676249903227\n",
      "epoch: 369 loss: 2.1622979640960693 grad: 2.416455901717575\n",
      "epoch: 370 loss: 2.162956953048706 grad: 2.6185593331502455\n",
      "epoch: 371 loss: 2.1649093627929688 grad: 2.6871275749105576\n",
      "epoch: 372 loss: 2.1613035202026367 grad: 2.5595351946965184\n",
      "epoch: 373 loss: 2.162747859954834 grad: 2.5985433014926484\n",
      "epoch: 374 loss: 2.1601154804229736 grad: 2.4650683192654497\n",
      "epoch: 375 loss: 2.1614201068878174 grad: 2.586693242266183\n",
      "epoch: 376 loss: 2.1617636680603027 grad: 2.56229661731419\n",
      "epoch: 377 loss: 2.1607820987701416 grad: 2.5530635873484058\n",
      "epoch: 378 loss: 2.1613080501556396 grad: 2.5677769673001465\n",
      "epoch: 379 loss: 2.15982985496521 grad: 2.5481277970331058\n",
      "epoch: 380 loss: 2.158118486404419 grad: 2.3929737189984217\n",
      "epoch: 381 loss: 2.1584677696228027 grad: 2.438086900795396\n",
      "epoch: 382 loss: 2.160935401916504 grad: 2.615453665190938\n",
      "epoch: 383 loss: 2.159771203994751 grad: 2.5908987118459734\n",
      "epoch: 384 loss: 2.1593756675720215 grad: 2.6325966973922084\n",
      "epoch: 385 loss: 2.158595323562622 grad: 2.513627454882399\n",
      "epoch: 386 loss: 2.1587395668029785 grad: 2.5805388138045573\n",
      "epoch: 387 loss: 2.1584644317626953 grad: 2.446356134568637\n",
      "epoch: 388 loss: 2.157912015914917 grad: 2.462346219178659\n",
      "epoch: 389 loss: 2.1592869758605957 grad: 2.578876762194485\n",
      "epoch: 390 loss: 2.1583032608032227 grad: 2.446042900666639\n",
      "epoch: 391 loss: 2.156984329223633 grad: 2.546196060050057\n",
      "epoch: 392 loss: 2.1571524143218994 grad: 2.603359696396168\n",
      "epoch: 393 loss: 2.15602445602417 grad: 2.384607044107739\n",
      "epoch: 394 loss: 2.1595637798309326 grad: 2.647424032525455\n",
      "epoch: 395 loss: 2.1578474044799805 grad: 2.64099412000302\n",
      "epoch: 396 loss: 2.1561970710754395 grad: 2.522256524209672\n",
      "epoch: 397 loss: 2.155916690826416 grad: 2.545417654263373\n",
      "epoch: 398 loss: 2.158587694168091 grad: 2.7174338439353813\n",
      "epoch: 399 loss: 2.1578152179718018 grad: 2.641508289341194\n",
      "epoch: 400 loss: 2.1557106971740723 grad: 2.5885921307942934\n",
      "epoch: 401 loss: 2.158177137374878 grad: 2.528304295828714\n",
      "epoch: 402 loss: 2.155442476272583 grad: 2.470822877343005\n",
      "epoch: 403 loss: 2.156498908996582 grad: 2.6675571343318247\n",
      "epoch: 404 loss: 2.156162977218628 grad: 2.710900844011958\n",
      "epoch: 405 loss: 2.1568498611450195 grad: 2.5443326967938376\n",
      "epoch: 406 loss: 2.1539437770843506 grad: 2.5154244632955405\n",
      "epoch: 407 loss: 2.1584861278533936 grad: 2.649078185775406\n",
      "epoch: 408 loss: 2.1584575176239014 grad: 2.873276741591297\n",
      "epoch: 409 loss: 2.1558234691619873 grad: 2.653526693203723\n",
      "epoch: 410 loss: 2.154592275619507 grad: 2.708828081290001\n",
      "epoch: 411 loss: 2.154208183288574 grad: 2.4923333367573037\n",
      "epoch: 412 loss: 2.1558139324188232 grad: 2.685800439914659\n",
      "epoch: 413 loss: 2.152890920639038 grad: 2.650628481520384\n",
      "epoch: 414 loss: 2.155611276626587 grad: 2.809886073320365\n",
      "epoch: 415 loss: 2.1526949405670166 grad: 2.492593599533263\n",
      "epoch: 416 loss: 2.1524012088775635 grad: 2.6321283754918516\n",
      "epoch: 417 loss: 2.1556754112243652 grad: 2.7803360072042174\n",
      "epoch: 418 loss: 2.1557254791259766 grad: 2.6275501580528235\n",
      "epoch: 419 loss: 2.152869462966919 grad: 2.567575926454516\n",
      "epoch: 420 loss: 2.1531825065612793 grad: 2.618709403707365\n",
      "epoch: 421 loss: 2.1537926197052 grad: 2.6565105850763975\n",
      "epoch: 422 loss: 2.1542012691497803 grad: 2.779821870575053\n",
      "epoch: 423 loss: 2.1514945030212402 grad: 2.474318026916109\n",
      "epoch: 424 loss: 2.1517257690429688 grad: 2.634398850377664\n",
      "epoch: 425 loss: 2.153430461883545 grad: 2.743885924043651\n",
      "epoch: 426 loss: 2.152501344680786 grad: 2.605051838504594\n",
      "epoch: 427 loss: 2.1519510746002197 grad: 2.6459636561672335\n",
      "epoch: 428 loss: 2.1514244079589844 grad: 2.607923613567393\n",
      "epoch: 429 loss: 2.152444839477539 grad: 2.6307891182941456\n",
      "epoch: 430 loss: 2.1507723331451416 grad: 2.6071578162881206\n",
      "epoch: 431 loss: 2.151665687561035 grad: 2.7900144784334335\n",
      "epoch: 432 loss: 2.1514155864715576 grad: 2.7088396319018173\n",
      "epoch: 433 loss: 2.1540701389312744 grad: 2.7004368633904035\n",
      "epoch: 434 loss: 2.148808240890503 grad: 2.5044201274664837\n",
      "epoch: 435 loss: 2.149996757507324 grad: 2.712758285457283\n",
      "epoch: 436 loss: 2.1504292488098145 grad: 2.5248141648554583\n",
      "epoch: 437 loss: 2.149580955505371 grad: 2.7025773049746125\n",
      "epoch: 438 loss: 2.1513476371765137 grad: 2.67839089200078\n",
      "epoch: 439 loss: 2.1499242782592773 grad: 2.66165424035936\n",
      "epoch: 440 loss: 2.147679090499878 grad: 2.714461734191337\n",
      "epoch: 441 loss: 2.148730993270874 grad: 2.6080105904146054\n",
      "epoch: 442 loss: 2.1496524810791016 grad: 2.932194236614224\n",
      "epoch: 443 loss: 2.1480274200439453 grad: 2.697463702053822\n",
      "epoch: 444 loss: 2.1483471393585205 grad: 2.5365029066867595\n",
      "epoch: 445 loss: 2.148555040359497 grad: 2.6045239838117378\n",
      "epoch: 446 loss: 2.1493947505950928 grad: 2.684796876519815\n",
      "epoch: 447 loss: 2.148427724838257 grad: 2.6699620362164245\n",
      "epoch: 448 loss: 2.1495468616485596 grad: 2.8126815908961738\n",
      "epoch: 449 loss: 2.150975465774536 grad: 2.7240775486598503\n",
      "epoch: 450 loss: 2.1471445560455322 grad: 2.7373545165728066\n",
      "epoch: 451 loss: 2.1487538814544678 grad: 2.858237472137377\n",
      "epoch: 452 loss: 2.148362398147583 grad: 2.746234713090835\n",
      "epoch: 453 loss: 2.1495468616485596 grad: 2.943726492487633\n",
      "epoch: 454 loss: 2.1475002765655518 grad: 2.651056181412146\n",
      "epoch: 455 loss: 2.1477088928222656 grad: 2.76502358216408\n",
      "epoch: 456 loss: 2.1458353996276855 grad: 2.7339430008423586\n",
      "epoch: 457 loss: 2.145242214202881 grad: 2.555845037952716\n",
      "epoch: 458 loss: 2.1464247703552246 grad: 2.706668780551159\n",
      "epoch: 459 loss: 2.1478610038757324 grad: 2.6882580177311506\n",
      "epoch: 460 loss: 2.145695447921753 grad: 2.7640063828448693\n",
      "epoch: 461 loss: 2.146404504776001 grad: 2.7274228126376068\n",
      "epoch: 462 loss: 2.1447739601135254 grad: 2.7062127546126407\n",
      "epoch: 463 loss: 2.1435012817382812 grad: 2.5705224163885716\n",
      "epoch: 464 loss: 2.146057605743408 grad: 2.6052793395790523\n",
      "epoch: 465 loss: 2.144824504852295 grad: 2.7981328745076937\n",
      "epoch: 466 loss: 2.1447620391845703 grad: 2.5798224907678864\n",
      "epoch: 467 loss: 2.1459240913391113 grad: 2.643366759169906\n",
      "epoch: 468 loss: 2.1442923545837402 grad: 2.5876257961305478\n",
      "epoch: 469 loss: 2.1444432735443115 grad: 2.664608076286857\n",
      "epoch: 470 loss: 2.144806146621704 grad: 3.055000992883588\n",
      "epoch: 471 loss: 2.1431961059570312 grad: 2.6924632892626086\n",
      "epoch: 472 loss: 2.144026517868042 grad: 2.8720074665921165\n",
      "epoch: 473 loss: 2.1406044960021973 grad: 2.647287415041189\n",
      "epoch: 474 loss: 2.1457695960998535 grad: 2.926319679252744\n",
      "epoch: 475 loss: 2.144174337387085 grad: 2.7473144298936756\n",
      "epoch: 476 loss: 2.143346071243286 grad: 2.7765043642212976\n",
      "epoch: 477 loss: 2.142911911010742 grad: 2.7563525447326285\n",
      "epoch: 478 loss: 2.1436073780059814 grad: 2.651777800418333\n",
      "epoch: 479 loss: 2.1438236236572266 grad: 2.766884042399137\n",
      "epoch: 480 loss: 2.1445600986480713 grad: 2.7996854490364\n",
      "epoch: 481 loss: 2.1440176963806152 grad: 2.7990342324363096\n",
      "epoch: 482 loss: 2.1417791843414307 grad: 2.8095669633974985\n",
      "epoch: 483 loss: 2.1429905891418457 grad: 2.839803975990175\n",
      "epoch: 484 loss: 2.1421289443969727 grad: 2.8021489338901278\n",
      "epoch: 485 loss: 2.141817569732666 grad: 2.8439479281734084\n",
      "epoch: 486 loss: 2.1414058208465576 grad: 2.6825885876462543\n",
      "epoch: 487 loss: 2.1421046257019043 grad: 2.8745775836527288\n",
      "epoch: 488 loss: 2.1391780376434326 grad: 2.738113599441325\n",
      "epoch: 489 loss: 2.1418251991271973 grad: 2.605238375593982\n",
      "epoch: 490 loss: 2.1418752670288086 grad: 2.9070821118371057\n",
      "epoch: 491 loss: 2.139338493347168 grad: 2.630773842567578\n",
      "epoch: 492 loss: 2.141878128051758 grad: 2.925226632112061\n",
      "epoch: 493 loss: 2.1405770778656006 grad: 2.646505180480225\n",
      "epoch: 494 loss: 2.139890432357788 grad: 2.7023344207961584\n",
      "epoch: 495 loss: 2.139334201812744 grad: 2.84682514155764\n",
      "epoch: 496 loss: 2.1373374462127686 grad: 2.7518256841807642\n",
      "epoch: 497 loss: 2.1384143829345703 grad: 2.5939237841641503\n",
      "epoch: 498 loss: 2.1396470069885254 grad: 2.7774033861693055\n",
      "epoch: 499 loss: 2.1412882804870605 grad: 2.917238406748289\n",
      "2.21461720764637\n",
      "epoch: 0 loss: 2.302656412124634 grad: 1.3440058289635335\n",
      "epoch: 1 loss: 2.2774786949157715 grad: 1.678191263845841\n",
      "epoch: 2 loss: 2.232725143432617 grad: 1.2915374395577977\n",
      "epoch: 3 loss: 2.225646734237671 grad: 1.1529377769597524\n",
      "epoch: 4 loss: 2.2224180698394775 grad: 1.1412722014245533\n",
      "epoch: 5 loss: 2.219510078430176 grad: 1.19593027610487\n",
      "epoch: 6 loss: 2.2182583808898926 grad: 1.202429815716598\n",
      "epoch: 7 loss: 2.2153573036193848 grad: 1.2730515315566981\n",
      "epoch: 8 loss: 2.2133607864379883 grad: 1.355318712770924\n",
      "epoch: 9 loss: 2.212578535079956 grad: 1.4524288208977807\n",
      "epoch: 10 loss: 2.2095072269439697 grad: 1.628661356663095\n",
      "epoch: 11 loss: 2.201441764831543 grad: 2.060770076002911\n",
      "epoch: 12 loss: 2.1945557594299316 grad: 2.326295577307483\n",
      "epoch: 13 loss: 2.1846320629119873 grad: 2.541336271762183\n",
      "epoch: 14 loss: 2.1750869750976562 grad: 2.69220140410055\n",
      "epoch: 15 loss: 2.16853928565979 grad: 3.029849230577903\n",
      "epoch: 16 loss: 2.152728796005249 grad: 3.2773533600219893\n",
      "epoch: 17 loss: 2.140420436859131 grad: 3.431564276620361\n",
      "epoch: 18 loss: 2.1322391033172607 grad: 3.4728700331050075\n",
      "epoch: 19 loss: 2.1227710247039795 grad: 3.4962210091060055\n",
      "epoch: 20 loss: 2.11531138420105 grad: 3.9533169480698507\n",
      "epoch: 21 loss: 2.1065878868103027 grad: 4.243832005328307\n",
      "epoch: 22 loss: 2.097628355026245 grad: 4.60707639080901\n",
      "epoch: 23 loss: 2.0886435508728027 grad: 4.720037909091583\n",
      "epoch: 24 loss: 2.0827722549438477 grad: 5.0946971486573895\n",
      "epoch: 25 loss: 2.0715105533599854 grad: 5.242138710464277\n",
      "epoch: 26 loss: 2.063408613204956 grad: 5.063342749325943\n",
      "epoch: 27 loss: 2.0594167709350586 grad: 5.451906979128363\n",
      "epoch: 28 loss: 2.053711414337158 grad: 5.688032272892694\n",
      "epoch: 29 loss: 2.0450551509857178 grad: 5.522096777678511\n",
      "epoch: 30 loss: 2.030266523361206 grad: 5.580438504756857\n",
      "epoch: 31 loss: 2.0256364345550537 grad: 6.015767509782953\n",
      "epoch: 32 loss: 2.01711368560791 grad: 6.1024818255285185\n",
      "epoch: 33 loss: 2.014949321746826 grad: 6.2954826555436565\n",
      "epoch: 34 loss: 2.008136034011841 grad: 6.312951955168198\n",
      "epoch: 35 loss: 2.001229763031006 grad: 6.580130472261873\n",
      "epoch: 36 loss: 1.9950263500213623 grad: 6.824183549820667\n",
      "epoch: 37 loss: 1.9875723123550415 grad: 7.095086556349305\n",
      "epoch: 38 loss: 1.983709692955017 grad: 7.090329762577774\n",
      "epoch: 39 loss: 1.9802736043930054 grad: 6.83688676911628\n",
      "epoch: 40 loss: 1.9765806198120117 grad: 7.216870526627948\n",
      "epoch: 41 loss: 1.965658187866211 grad: 7.1019995118018295\n",
      "epoch: 42 loss: 1.9617769718170166 grad: 7.222787330429705\n",
      "epoch: 43 loss: 1.9645274877548218 grad: 7.293715052107083\n",
      "epoch: 44 loss: 1.9571031332015991 grad: 7.535721609782842\n",
      "epoch: 45 loss: 1.950637698173523 grad: 6.942012796378029\n",
      "epoch: 46 loss: 1.9490330219268799 grad: 7.545322013811933\n",
      "epoch: 47 loss: 1.9398671388626099 grad: 7.055488366278864\n",
      "epoch: 48 loss: 1.938589334487915 grad: 7.566340249031782\n",
      "epoch: 49 loss: 1.9284515380859375 grad: 7.305472373400653\n",
      "epoch: 50 loss: 1.9342141151428223 grad: 7.534897088383635\n",
      "epoch: 51 loss: 1.9256969690322876 grad: 7.594407378991563\n",
      "epoch: 52 loss: 1.9184815883636475 grad: 7.681861342662679\n",
      "epoch: 53 loss: 1.9199198484420776 grad: 7.484616997873499\n",
      "epoch: 54 loss: 1.9183319807052612 grad: 7.40252918960704\n",
      "epoch: 55 loss: 1.9160066843032837 grad: 7.467564580784667\n",
      "epoch: 56 loss: 1.9081028699874878 grad: 7.807544876466549\n",
      "epoch: 57 loss: 1.914990782737732 grad: 7.9750922119451895\n",
      "epoch: 58 loss: 1.9085835218429565 grad: 8.179872826429172\n",
      "epoch: 59 loss: 1.9058315753936768 grad: 7.841455982251477\n",
      "epoch: 60 loss: 1.9021419286727905 grad: 8.06900621147915\n",
      "epoch: 61 loss: 1.9041529893875122 grad: 8.29290288935105\n",
      "epoch: 62 loss: 1.8883392810821533 grad: 7.749071993229408\n",
      "epoch: 63 loss: 1.8872321844100952 grad: 8.13597819668847\n",
      "epoch: 64 loss: 1.8860934972763062 grad: 8.051632668069075\n",
      "epoch: 65 loss: 1.886817455291748 grad: 8.630599308345053\n",
      "epoch: 66 loss: 1.8818542957305908 grad: 8.371419516672928\n",
      "epoch: 67 loss: 1.8818914890289307 grad: 8.98460070358678\n",
      "epoch: 68 loss: 1.8818891048431396 grad: 8.936071448116785\n",
      "epoch: 69 loss: 1.8765653371810913 grad: 8.106184886081056\n",
      "epoch: 70 loss: 1.8694723844528198 grad: 8.26501939052509\n",
      "epoch: 71 loss: 1.8691729307174683 grad: 8.207786910465016\n",
      "epoch: 72 loss: 1.8679524660110474 grad: 8.787252397209938\n",
      "epoch: 73 loss: 1.8623650074005127 grad: 9.013890714488095\n",
      "epoch: 74 loss: 1.865978717803955 grad: 9.283142383018184\n",
      "epoch: 75 loss: 1.8581371307373047 grad: 9.241159489097457\n",
      "epoch: 76 loss: 1.8623214960098267 grad: 8.735269226991232\n",
      "epoch: 77 loss: 1.8609709739685059 grad: 8.855137462505983\n",
      "epoch: 78 loss: 1.8566621541976929 grad: 8.863748326749793\n",
      "epoch: 79 loss: 1.8505938053131104 grad: 9.065296148999579\n",
      "epoch: 80 loss: 1.8543682098388672 grad: 9.00856754146812\n",
      "epoch: 81 loss: 1.8439955711364746 grad: 8.805064635380866\n",
      "epoch: 82 loss: 1.8452017307281494 grad: 9.188649114871781\n",
      "epoch: 83 loss: 1.8430075645446777 grad: 9.169297652489076\n",
      "epoch: 84 loss: 1.8406357765197754 grad: 9.345066416942116\n",
      "epoch: 85 loss: 1.840395450592041 grad: 9.273851615554165\n",
      "epoch: 86 loss: 1.8395531177520752 grad: 9.561138766758617\n",
      "epoch: 87 loss: 1.834693193435669 grad: 9.472503264434636\n",
      "epoch: 88 loss: 1.8313038349151611 grad: 9.228363481808513\n",
      "epoch: 89 loss: 1.828474760055542 grad: 8.853787268393688\n",
      "epoch: 90 loss: 1.8317214250564575 grad: 9.504493597214895\n",
      "epoch: 91 loss: 1.824324131011963 grad: 9.183244323180546\n",
      "epoch: 92 loss: 1.8247426748275757 grad: 9.33919842873833\n",
      "epoch: 93 loss: 1.820435881614685 grad: 10.131196956623286\n",
      "epoch: 94 loss: 1.8162248134613037 grad: 9.756674886001127\n",
      "epoch: 95 loss: 1.8137860298156738 grad: 9.654981890124166\n",
      "epoch: 96 loss: 1.8156054019927979 grad: 9.811959535578294\n",
      "epoch: 97 loss: 1.8117846250534058 grad: 9.30264903705508\n",
      "epoch: 98 loss: 1.80488920211792 grad: 9.724347986162655\n",
      "epoch: 99 loss: 1.8052581548690796 grad: 9.934162901418786\n",
      "epoch: 100 loss: 1.8102948665618896 grad: 10.331712240146267\n",
      "epoch: 101 loss: 1.8055009841918945 grad: 9.90034741949704\n",
      "epoch: 102 loss: 1.8013242483139038 grad: 10.345150835723395\n",
      "epoch: 103 loss: 1.803300380706787 grad: 10.824669758109229\n",
      "epoch: 104 loss: 1.7913072109222412 grad: 9.976195522184883\n",
      "epoch: 105 loss: 1.7960307598114014 grad: 10.339594938082708\n",
      "epoch: 106 loss: 1.7938164472579956 grad: 10.726991977187849\n",
      "epoch: 107 loss: 1.7875548601150513 grad: 10.109339389624813\n",
      "epoch: 108 loss: 1.7874665260314941 grad: 10.854395477056858\n",
      "epoch: 109 loss: 1.783661127090454 grad: 10.149278062632279\n",
      "epoch: 110 loss: 1.7863643169403076 grad: 10.659092466006912\n",
      "epoch: 111 loss: 1.7774525880813599 grad: 11.101901644160824\n",
      "epoch: 112 loss: 1.7829303741455078 grad: 10.955514470337047\n",
      "epoch: 113 loss: 1.767608642578125 grad: 10.798819545804271\n",
      "epoch: 114 loss: 1.7712469100952148 grad: 11.293901662652692\n",
      "epoch: 115 loss: 1.769291639328003 grad: 11.045731843242216\n",
      "epoch: 116 loss: 1.7627307176589966 grad: 10.954279038522925\n",
      "epoch: 117 loss: 1.7600232362747192 grad: 11.116484854784277\n",
      "epoch: 118 loss: 1.7485896348953247 grad: 11.234580335695119\n",
      "epoch: 119 loss: 1.7530003786087036 grad: 11.30859420383497\n",
      "epoch: 120 loss: 1.7603365182876587 grad: 12.079278767508056\n",
      "epoch: 121 loss: 1.7526711225509644 grad: 12.181522296652908\n",
      "epoch: 122 loss: 1.7564358711242676 grad: 11.717180764420874\n",
      "epoch: 123 loss: 1.742480754852295 grad: 11.714980809698028\n",
      "epoch: 124 loss: 1.7386033535003662 grad: 11.665428720252027\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 125 loss: 1.734775424003601 grad: 12.353490587545647\n",
      "epoch: 126 loss: 1.740657925605774 grad: 12.126420236503085\n",
      "epoch: 127 loss: 1.7358042001724243 grad: 12.452789857998372\n",
      "epoch: 128 loss: 1.7381539344787598 grad: 11.92343184386661\n",
      "epoch: 129 loss: 1.7316125631332397 grad: 12.199815320013652\n",
      "epoch: 130 loss: 1.7357851266860962 grad: 11.871528144467563\n",
      "epoch: 131 loss: 1.7317079305648804 grad: 11.929566789891512\n",
      "epoch: 132 loss: 1.7276721000671387 grad: 12.435174414873241\n",
      "epoch: 133 loss: 1.7229721546173096 grad: 12.02958546164963\n",
      "epoch: 134 loss: 1.7214492559432983 grad: 11.902495215602574\n",
      "epoch: 135 loss: 1.71578049659729 grad: 12.513980548547964\n",
      "epoch: 136 loss: 1.7177808284759521 grad: 12.275731257251685\n",
      "epoch: 137 loss: 1.7215806245803833 grad: 12.4103972812198\n",
      "epoch: 138 loss: 1.7136940956115723 grad: 12.542370876386052\n",
      "epoch: 139 loss: 1.7084317207336426 grad: 12.351741095605705\n",
      "epoch: 140 loss: 1.7075977325439453 grad: 12.117870223309312\n",
      "epoch: 141 loss: 1.7060285806655884 grad: 12.510012132337405\n",
      "epoch: 142 loss: 1.7051100730895996 grad: 12.520646431172887\n",
      "epoch: 143 loss: 1.6979866027832031 grad: 12.858474656998638\n",
      "epoch: 144 loss: 1.699686050415039 grad: 12.162937364378383\n",
      "epoch: 145 loss: 1.7045292854309082 grad: 12.931076106866675\n",
      "epoch: 146 loss: 1.6944153308868408 grad: 12.564794409177487\n",
      "epoch: 147 loss: 1.7061958312988281 grad: 12.41987192330675\n",
      "epoch: 148 loss: 1.6980736255645752 grad: 12.231173239500514\n",
      "epoch: 149 loss: 1.6848148107528687 grad: 12.189793532699465\n",
      "epoch: 150 loss: 1.6865228414535522 grad: 11.975792894154669\n",
      "epoch: 151 loss: 1.688650369644165 grad: 12.54288779120774\n",
      "epoch: 152 loss: 1.6951874494552612 grad: 12.63013783647191\n",
      "epoch: 153 loss: 1.682456374168396 grad: 12.715475127544432\n",
      "epoch: 154 loss: 1.6820523738861084 grad: 12.47893444522624\n",
      "epoch: 155 loss: 1.6834152936935425 grad: 12.683736509480884\n",
      "epoch: 156 loss: 1.6908683776855469 grad: 12.962216309419581\n",
      "epoch: 157 loss: 1.6852202415466309 grad: 12.823500666412569\n",
      "epoch: 158 loss: 1.675770878791809 grad: 12.646418554530968\n",
      "epoch: 159 loss: 1.679339051246643 grad: 12.63133225428118\n",
      "epoch: 160 loss: 1.679041862487793 grad: 12.492788450408076\n",
      "epoch: 161 loss: 1.6719245910644531 grad: 12.2241722458737\n",
      "epoch: 162 loss: 1.6734342575073242 grad: 12.294475916078285\n",
      "epoch: 163 loss: 1.6709035634994507 grad: 12.75972574059334\n",
      "epoch: 164 loss: 1.6773399114608765 grad: 13.6730520450584\n",
      "epoch: 165 loss: 1.6724666357040405 grad: 13.06195298712405\n",
      "epoch: 166 loss: 1.6677428483963013 grad: 13.039959728614324\n",
      "epoch: 167 loss: 1.6672903299331665 grad: 12.75664961877619\n",
      "epoch: 168 loss: 1.6612906455993652 grad: 12.637992745132319\n",
      "epoch: 169 loss: 1.6589164733886719 grad: 13.127284382499518\n",
      "epoch: 170 loss: 1.6548274755477905 grad: 12.806076334138949\n",
      "epoch: 171 loss: 1.6587262153625488 grad: 12.543325877763213\n",
      "epoch: 172 loss: 1.6646993160247803 grad: 12.892389194655513\n",
      "epoch: 173 loss: 1.6542550325393677 grad: 13.365478763593332\n",
      "epoch: 174 loss: 1.662304162979126 grad: 13.319558076043096\n",
      "epoch: 175 loss: 1.6527020931243896 grad: 12.874973583449092\n",
      "epoch: 176 loss: 1.654684066772461 grad: 12.160107037215123\n",
      "epoch: 177 loss: 1.6533403396606445 grad: 12.690977826041895\n",
      "epoch: 178 loss: 1.6553939580917358 grad: 13.250924645154367\n",
      "epoch: 179 loss: 1.6386120319366455 grad: 12.818516697268933\n",
      "epoch: 180 loss: 1.6535826921463013 grad: 12.78302738513975\n",
      "epoch: 181 loss: 1.6454627513885498 grad: 12.933053553119183\n",
      "epoch: 182 loss: 1.645846962928772 grad: 12.861243867507529\n",
      "epoch: 183 loss: 1.6444480419158936 grad: 12.180265082282917\n",
      "epoch: 184 loss: 1.6485488414764404 grad: 12.275018023001769\n",
      "epoch: 185 loss: 1.6476256847381592 grad: 13.462069837760831\n",
      "epoch: 186 loss: 1.6358765363693237 grad: 12.456166000948066\n",
      "epoch: 187 loss: 1.647647738456726 grad: 12.288672303396558\n",
      "epoch: 188 loss: 1.6392154693603516 grad: 12.443590700057232\n",
      "epoch: 189 loss: 1.6320971250534058 grad: 12.513363060970155\n",
      "epoch: 190 loss: 1.6442140340805054 grad: 12.87225427045413\n",
      "epoch: 191 loss: 1.6447420120239258 grad: 13.037798274581927\n",
      "epoch: 192 loss: 1.6385213136672974 grad: 12.955392922511296\n",
      "epoch: 193 loss: 1.6389999389648438 grad: 12.860452342482786\n",
      "epoch: 194 loss: 1.6342577934265137 grad: 12.213673769429858\n",
      "epoch: 195 loss: 1.6390362977981567 grad: 12.495119134126792\n",
      "epoch: 196 loss: 1.6288520097732544 grad: 12.97818687133905\n",
      "epoch: 197 loss: 1.6274818181991577 grad: 12.817515341631536\n",
      "epoch: 198 loss: 1.623405933380127 grad: 12.07303484693347\n",
      "epoch: 199 loss: 1.62717866897583 grad: 12.06023034565742\n",
      "epoch: 200 loss: 1.6287001371383667 grad: 11.915054411908228\n",
      "epoch: 201 loss: 1.6321438550949097 grad: 12.434364880730827\n",
      "epoch: 202 loss: 1.623618245124817 grad: 12.875784891672314\n",
      "epoch: 203 loss: 1.6261883974075317 grad: 12.241639540634221\n",
      "epoch: 204 loss: 1.623518943786621 grad: 12.204508523937196\n",
      "epoch: 205 loss: 1.6261584758758545 grad: 11.787990333748953\n",
      "epoch: 206 loss: 1.6275427341461182 grad: 13.166641303892469\n",
      "epoch: 207 loss: 1.6304603815078735 grad: 13.221708990042172\n",
      "epoch: 208 loss: 1.624255895614624 grad: 12.257512013753137\n",
      "epoch: 209 loss: 1.621014952659607 grad: 13.056859307079797\n",
      "epoch: 210 loss: 1.6200947761535645 grad: 12.487963251710411\n",
      "epoch: 211 loss: 1.6150833368301392 grad: 12.310292384254613\n",
      "epoch: 212 loss: 1.6142253875732422 grad: 12.038020977565635\n",
      "epoch: 213 loss: 1.6232975721359253 grad: 12.662022730468639\n",
      "epoch: 214 loss: 1.6161855459213257 grad: 13.171083657839706\n",
      "epoch: 215 loss: 1.616411805152893 grad: 12.175207790497335\n",
      "epoch: 216 loss: 1.621598482131958 grad: 12.66461910739068\n",
      "epoch: 217 loss: 1.6192964315414429 grad: 11.925737564851131\n",
      "epoch: 218 loss: 1.6205943822860718 grad: 12.267826040127567\n",
      "epoch: 219 loss: 1.610625147819519 grad: 12.041154474256532\n",
      "epoch: 220 loss: 1.6141085624694824 grad: 12.198667922855488\n",
      "epoch: 221 loss: 1.6185412406921387 grad: 12.712033791208846\n",
      "epoch: 222 loss: 1.6131181716918945 grad: 12.47044179805865\n",
      "epoch: 223 loss: 1.6156600713729858 grad: 12.57565387854323\n",
      "epoch: 224 loss: 1.6108638048171997 grad: 12.240220743127995\n",
      "epoch: 225 loss: 1.612012267112732 grad: 13.204117951293787\n",
      "epoch: 226 loss: 1.6103087663650513 grad: 11.815904222325319\n",
      "epoch: 227 loss: 1.6063255071640015 grad: 11.904449475049558\n",
      "epoch: 228 loss: 1.6117029190063477 grad: 13.118766761177945\n",
      "epoch: 229 loss: 1.6085561513900757 grad: 11.951939746663566\n",
      "epoch: 230 loss: 1.606582522392273 grad: 12.597038764469621\n",
      "epoch: 231 loss: 1.609149694442749 grad: 12.280942507753414\n",
      "epoch: 232 loss: 1.6027402877807617 grad: 11.756682693174788\n",
      "epoch: 233 loss: 1.603723168373108 grad: 12.006597471852151\n",
      "epoch: 234 loss: 1.6077537536621094 grad: 12.405476139998802\n",
      "epoch: 235 loss: 1.6098780632019043 grad: 11.959673295743645\n",
      "epoch: 236 loss: 1.6041419506072998 grad: 11.909016993961163\n",
      "epoch: 237 loss: 1.6082531213760376 grad: 12.75149514980703\n",
      "epoch: 238 loss: 1.6104825735092163 grad: 11.873430027537758\n",
      "epoch: 239 loss: 1.6112539768218994 grad: 12.256121702824853\n",
      "epoch: 240 loss: 1.6011669635772705 grad: 12.035561851440145\n",
      "epoch: 241 loss: 1.6065419912338257 grad: 13.21875762178873\n",
      "epoch: 242 loss: 1.5985089540481567 grad: 11.765412694648914\n",
      "epoch: 243 loss: 1.5946259498596191 grad: 12.053670653770308\n",
      "epoch: 244 loss: 1.602203607559204 grad: 12.161897437602637\n",
      "epoch: 245 loss: 1.605626106262207 grad: 13.118535492199635\n",
      "epoch: 246 loss: 1.6049553155899048 grad: 12.729823987783185\n",
      "epoch: 247 loss: 1.6009955406188965 grad: 12.627814031767821\n",
      "epoch: 248 loss: 1.6004841327667236 grad: 12.448031795314616\n",
      "epoch: 249 loss: 1.5998846292495728 grad: 12.232096474795114\n",
      "epoch: 250 loss: 1.6055957078933716 grad: 12.667045899422927\n",
      "epoch: 251 loss: 1.5945100784301758 grad: 12.152636120191938\n",
      "epoch: 252 loss: 1.5950427055358887 grad: 11.983767456323323\n",
      "epoch: 253 loss: 1.5997987985610962 grad: 13.16690467349771\n",
      "epoch: 254 loss: 1.5997369289398193 grad: 12.434674317859823\n",
      "epoch: 255 loss: 1.5911513566970825 grad: 11.866909253041422\n",
      "epoch: 256 loss: 1.608582854270935 grad: 12.563877490393462\n",
      "epoch: 257 loss: 1.5953586101531982 grad: 12.493084074160645\n",
      "epoch: 258 loss: 1.594435453414917 grad: 12.051731954387847\n",
      "epoch: 259 loss: 1.6017932891845703 grad: 12.49833178812904\n",
      "epoch: 260 loss: 1.5901292562484741 grad: 11.988936880174728\n",
      "epoch: 261 loss: 1.5891600847244263 grad: 11.982655074510221\n",
      "epoch: 262 loss: 1.5985851287841797 grad: 12.94227828006334\n",
      "epoch: 263 loss: 1.606981873512268 grad: 12.75802298970077\n",
      "epoch: 264 loss: 1.5954793691635132 grad: 12.121745236284498\n",
      "epoch: 265 loss: 1.5946518182754517 grad: 12.544861375960329\n",
      "epoch: 266 loss: 1.5826356410980225 grad: 11.84702791457641\n",
      "epoch: 267 loss: 1.5996133089065552 grad: 12.079658158581763\n",
      "epoch: 268 loss: 1.5879734754562378 grad: 11.615136586040968\n",
      "epoch: 269 loss: 1.5953221321105957 grad: 11.475568756690278\n",
      "epoch: 270 loss: 1.588518500328064 grad: 12.092955365673536\n",
      "epoch: 271 loss: 1.5907201766967773 grad: 12.171945060211574\n",
      "epoch: 272 loss: 1.595503568649292 grad: 12.316619326648791\n",
      "epoch: 273 loss: 1.5863227844238281 grad: 11.510912883594367\n",
      "epoch: 274 loss: 1.5850300788879395 grad: 11.897886841742705\n",
      "epoch: 275 loss: 1.5858581066131592 grad: 12.618176446000616\n",
      "epoch: 276 loss: 1.5830702781677246 grad: 11.936450345382568\n",
      "epoch: 277 loss: 1.5866209268569946 grad: 11.246339904983335\n",
      "epoch: 278 loss: 1.5887829065322876 grad: 11.673032420687377\n",
      "epoch: 279 loss: 1.589407205581665 grad: 12.952818953014527\n",
      "epoch: 280 loss: 1.5868747234344482 grad: 11.742992476878008\n",
      "epoch: 281 loss: 1.5859465599060059 grad: 11.676438377438378\n",
      "epoch: 282 loss: 1.5882325172424316 grad: 12.148643097064147\n",
      "epoch: 283 loss: 1.5913912057876587 grad: 12.636212607993492\n",
      "epoch: 284 loss: 1.5858917236328125 grad: 11.983670190889535\n",
      "epoch: 285 loss: 1.585253357887268 grad: 11.9839789928011\n",
      "epoch: 286 loss: 1.585599422454834 grad: 12.454199790762413\n",
      "epoch: 287 loss: 1.580985426902771 grad: 11.763963274650335\n",
      "epoch: 288 loss: 1.581060528755188 grad: 11.404745726121796\n",
      "epoch: 289 loss: 1.5844125747680664 grad: 12.477945224500246\n",
      "epoch: 290 loss: 1.5879958868026733 grad: 12.564171756359023\n",
      "epoch: 291 loss: 1.5775662660598755 grad: 11.623721952106626\n",
      "epoch: 292 loss: 1.5866788625717163 grad: 11.6677803894771\n",
      "epoch: 293 loss: 1.5818620920181274 grad: 12.978217418446013\n",
      "epoch: 294 loss: 1.5785150527954102 grad: 11.737388072102997\n",
      "epoch: 295 loss: 1.5810675621032715 grad: 11.869577554121081\n",
      "epoch: 296 loss: 1.5718700885772705 grad: 12.318882765994955\n",
      "epoch: 297 loss: 1.5844604969024658 grad: 11.944796009957495\n",
      "epoch: 298 loss: 1.5855145454406738 grad: 12.114205461110004\n",
      "epoch: 299 loss: 1.5845112800598145 grad: 12.957502091554778\n",
      "epoch: 300 loss: 1.5775668621063232 grad: 11.368713986572056\n",
      "epoch: 301 loss: 1.5792173147201538 grad: 12.007686798216863\n",
      "epoch: 302 loss: 1.5788127183914185 grad: 11.04086116280052\n",
      "epoch: 303 loss: 1.5842407941818237 grad: 12.506174938694116\n",
      "epoch: 304 loss: 1.5818943977355957 grad: 12.975143551722997\n",
      "epoch: 305 loss: 1.577808141708374 grad: 11.779328632234995\n",
      "epoch: 306 loss: 1.580277919769287 grad: 10.98987870987889\n",
      "epoch: 307 loss: 1.5761138200759888 grad: 12.22166417729819\n",
      "epoch: 308 loss: 1.580741286277771 grad: 12.018425423141924\n",
      "epoch: 309 loss: 1.5810950994491577 grad: 12.357948101851868\n",
      "epoch: 310 loss: 1.5863102674484253 grad: 12.23754349222318\n",
      "epoch: 311 loss: 1.576858401298523 grad: 11.856318951407005\n",
      "epoch: 312 loss: 1.5729804039001465 grad: 11.341624875763609\n",
      "epoch: 313 loss: 1.5786769390106201 grad: 11.38417787395329\n",
      "epoch: 314 loss: 1.5781077146530151 grad: 11.523568535977532\n",
      "epoch: 315 loss: 1.5820579528808594 grad: 12.897712512784416\n",
      "epoch: 316 loss: 1.580152153968811 grad: 11.872994047463946\n",
      "epoch: 317 loss: 1.5753920078277588 grad: 12.34471769314555\n",
      "epoch: 318 loss: 1.5689477920532227 grad: 11.869398793390404\n",
      "epoch: 319 loss: 1.5706522464752197 grad: 11.733709006836373\n",
      "epoch: 320 loss: 1.5737603902816772 grad: 11.559320823991643\n",
      "epoch: 321 loss: 1.5767343044281006 grad: 11.399058287187168\n",
      "epoch: 322 loss: 1.5756386518478394 grad: 11.947922326735265\n",
      "epoch: 323 loss: 1.5751316547393799 grad: 11.509700663062551\n",
      "epoch: 324 loss: 1.5768401622772217 grad: 10.89636875580745\n",
      "epoch: 325 loss: 1.5713847875595093 grad: 11.660834761659821\n",
      "epoch: 326 loss: 1.5766195058822632 grad: 11.53708553031486\n",
      "epoch: 327 loss: 1.572907567024231 grad: 11.406453127019285\n",
      "epoch: 328 loss: 1.5689035654067993 grad: 11.976141290975706\n",
      "epoch: 329 loss: 1.568383812904358 grad: 11.734111429155169\n",
      "epoch: 330 loss: 1.5723556280136108 grad: 11.66871981667946\n",
      "epoch: 331 loss: 1.577520489692688 grad: 12.020429742108616\n",
      "epoch: 332 loss: 1.5729148387908936 grad: 12.402196159046735\n",
      "epoch: 333 loss: 1.5700809955596924 grad: 12.017855170168101\n",
      "epoch: 334 loss: 1.564597487449646 grad: 10.733643551904057\n",
      "epoch: 335 loss: 1.564988136291504 grad: 10.701924345918028\n",
      "epoch: 336 loss: 1.565688967704773 grad: 11.256333410096843\n",
      "epoch: 337 loss: 1.5670942068099976 grad: 11.369876139449872\n",
      "epoch: 338 loss: 1.5767852067947388 grad: 11.33176384208029\n",
      "epoch: 339 loss: 1.572235345840454 grad: 11.765050645267207\n",
      "epoch: 340 loss: 1.5645716190338135 grad: 11.644093989956355\n",
      "epoch: 341 loss: 1.5750079154968262 grad: 12.776046211528222\n",
      "epoch: 342 loss: 1.5682517290115356 grad: 11.177411384015743\n",
      "epoch: 343 loss: 1.56557035446167 grad: 11.09322726685879\n",
      "epoch: 344 loss: 1.5697439908981323 grad: 11.793480781224808\n",
      "epoch: 345 loss: 1.5675548315048218 grad: 11.591765506832402\n",
      "epoch: 346 loss: 1.570314884185791 grad: 11.502852329407775\n",
      "epoch: 347 loss: 1.5619581937789917 grad: 11.830393999364109\n",
      "epoch: 348 loss: 1.572280764579773 grad: 11.756601296476132\n",
      "epoch: 349 loss: 1.5723867416381836 grad: 11.330685912062311\n",
      "epoch: 350 loss: 1.5706336498260498 grad: 12.28837864452027\n",
      "epoch: 351 loss: 1.5710690021514893 grad: 11.713740564151001\n",
      "epoch: 352 loss: 1.5667263269424438 grad: 11.902881316700212\n",
      "epoch: 353 loss: 1.5630131959915161 grad: 10.901447218857587\n",
      "epoch: 354 loss: 1.5611512660980225 grad: 11.415163423326458\n",
      "epoch: 355 loss: 1.5632107257843018 grad: 11.313960725278964\n",
      "epoch: 356 loss: 1.5659403800964355 grad: 11.079789433820498\n",
      "epoch: 357 loss: 1.5630416870117188 grad: 11.819380136605885\n",
      "epoch: 358 loss: 1.565326452255249 grad: 11.328476980313777\n",
      "epoch: 359 loss: 1.5620949268341064 grad: 12.286360062097037\n",
      "epoch: 360 loss: 1.566379189491272 grad: 11.220968250458736\n",
      "epoch: 361 loss: 1.564158320426941 grad: 11.906345151039579\n",
      "epoch: 362 loss: 1.5632482767105103 grad: 11.465695672978958\n",
      "epoch: 363 loss: 1.5655428171157837 grad: 10.973706930690993\n",
      "epoch: 364 loss: 1.5659549236297607 grad: 11.152224027666279\n",
      "epoch: 365 loss: 1.569513201713562 grad: 12.202694015133948\n",
      "epoch: 366 loss: 1.5649898052215576 grad: 11.93279089224303\n",
      "epoch: 367 loss: 1.5600813627243042 grad: 11.469451940274753\n",
      "epoch: 368 loss: 1.5666682720184326 grad: 12.562993676102321\n",
      "epoch: 369 loss: 1.561789631843567 grad: 10.449997658371954\n",
      "epoch: 370 loss: 1.5570212602615356 grad: 11.384572606223324\n",
      "epoch: 371 loss: 1.5576746463775635 grad: 11.279311437041514\n",
      "epoch: 372 loss: 1.5549794435501099 grad: 11.969413107079971\n",
      "epoch: 373 loss: 1.5628620386123657 grad: 11.340487020807194\n",
      "epoch: 374 loss: 1.55828857421875 grad: 11.754448255764261\n",
      "epoch: 375 loss: 1.5645538568496704 grad: 11.752478186041117\n",
      "epoch: 376 loss: 1.5639758110046387 grad: 12.050717135769359\n",
      "epoch: 377 loss: 1.558560848236084 grad: 10.816619167621765\n",
      "epoch: 378 loss: 1.5621356964111328 grad: 11.344552882344624\n",
      "epoch: 379 loss: 1.566123366355896 grad: 11.658283914143722\n",
      "epoch: 380 loss: 1.5647372007369995 grad: 12.333443121991992\n",
      "epoch: 381 loss: 1.5587095022201538 grad: 10.338186076636212\n",
      "epoch: 382 loss: 1.5569634437561035 grad: 11.740607988399764\n",
      "epoch: 383 loss: 1.5671263933181763 grad: 11.214342214041464\n",
      "epoch: 384 loss: 1.560667872428894 grad: 11.979885726557335\n",
      "epoch: 385 loss: 1.5601400136947632 grad: 11.889304590145391\n",
      "epoch: 386 loss: 1.5572444200515747 grad: 11.014204816634042\n",
      "epoch: 387 loss: 1.5609031915664673 grad: 11.52763086479778\n",
      "epoch: 388 loss: 1.566108226776123 grad: 11.701389707757958\n",
      "epoch: 389 loss: 1.5560195446014404 grad: 11.595521652945392\n",
      "epoch: 390 loss: 1.5590155124664307 grad: 11.471899944560839\n",
      "epoch: 391 loss: 1.5552799701690674 grad: 10.806509650785417\n",
      "epoch: 392 loss: 1.5633996725082397 grad: 11.39383985070763\n",
      "epoch: 393 loss: 1.559138298034668 grad: 10.952039200879101\n",
      "epoch: 394 loss: 1.5610806941986084 grad: 11.60538283950605\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 395 loss: 1.5603207349777222 grad: 10.58739236551189\n",
      "epoch: 396 loss: 1.5576356649398804 grad: 11.174202740255241\n",
      "epoch: 397 loss: 1.5567858219146729 grad: 10.592725790290546\n",
      "epoch: 398 loss: 1.556788444519043 grad: 11.935733504693157\n",
      "epoch: 399 loss: 1.5586210489273071 grad: 11.721297461498853\n",
      "epoch: 400 loss: 1.5562851428985596 grad: 11.702600416128657\n",
      "epoch: 401 loss: 1.556424856185913 grad: 10.249004161916673\n",
      "epoch: 402 loss: 1.564408302307129 grad: 12.121700055882453\n",
      "epoch: 403 loss: 1.5597668886184692 grad: 11.114363998071187\n",
      "epoch: 404 loss: 1.5561970472335815 grad: 10.935467255708303\n",
      "epoch: 405 loss: 1.5594993829727173 grad: 11.249805597422112\n",
      "epoch: 406 loss: 1.5667598247528076 grad: 11.14689892001583\n",
      "epoch: 407 loss: 1.5561343431472778 grad: 11.649314620495138\n",
      "epoch: 408 loss: 1.5561553239822388 grad: 11.326132179812587\n",
      "epoch: 409 loss: 1.5578902959823608 grad: 11.35950070689802\n",
      "epoch: 410 loss: 1.5522871017456055 grad: 12.17431709590915\n",
      "epoch: 411 loss: 1.551567554473877 grad: 11.493337282885072\n",
      "epoch: 412 loss: 1.5562677383422852 grad: 10.992114286810633\n",
      "epoch: 413 loss: 1.56075918674469 grad: 12.37995968039872\n",
      "epoch: 414 loss: 1.5566843748092651 grad: 11.463277967646718\n",
      "epoch: 415 loss: 1.5588736534118652 grad: 11.901352289472781\n",
      "epoch: 416 loss: 1.5573124885559082 grad: 11.66981190156066\n",
      "epoch: 417 loss: 1.5544726848602295 grad: 11.27507921915117\n",
      "epoch: 418 loss: 1.5525619983673096 grad: 10.923894095751974\n",
      "epoch: 419 loss: 1.557374358177185 grad: 11.563476804983877\n",
      "epoch: 420 loss: 1.5520662069320679 grad: 11.396318288540305\n",
      "epoch: 421 loss: 1.5534453392028809 grad: 11.115678762551397\n",
      "epoch: 422 loss: 1.5550899505615234 grad: 11.702968257139363\n",
      "epoch: 423 loss: 1.5590745210647583 grad: 11.30760997119138\n",
      "epoch: 424 loss: 1.5490621328353882 grad: 10.54225545054272\n",
      "epoch: 425 loss: 1.5529121160507202 grad: 11.188449686788584\n",
      "epoch: 426 loss: 1.5492675304412842 grad: 10.361584560372792\n",
      "epoch: 427 loss: 1.561631202697754 grad: 11.376155612081112\n",
      "epoch: 428 loss: 1.5566599369049072 grad: 11.879451511006447\n",
      "epoch: 429 loss: 1.5568690299987793 grad: 11.307300776797568\n",
      "epoch: 430 loss: 1.551537275314331 grad: 11.360076411564405\n",
      "epoch: 431 loss: 1.5516631603240967 grad: 10.47999570640691\n",
      "epoch: 432 loss: 1.5512726306915283 grad: 11.061596200866108\n",
      "epoch: 433 loss: 1.5519636869430542 grad: 10.30453094700721\n",
      "epoch: 434 loss: 1.5532140731811523 grad: 11.236935351694386\n",
      "epoch: 435 loss: 1.554610252380371 grad: 11.022956241738967\n",
      "epoch: 436 loss: 1.5479750633239746 grad: 11.45551558685792\n",
      "epoch: 437 loss: 1.5556033849716187 grad: 12.02798382876744\n",
      "epoch: 438 loss: 1.5484333038330078 grad: 10.658998469265903\n",
      "epoch: 439 loss: 1.5506454706192017 grad: 11.014406257105755\n",
      "epoch: 440 loss: 1.5493664741516113 grad: 10.659894405505694\n",
      "epoch: 441 loss: 1.556822419166565 grad: 11.683715408353786\n",
      "epoch: 442 loss: 1.5585609674453735 grad: 11.13848060066442\n",
      "epoch: 443 loss: 1.5543255805969238 grad: 11.898051209171259\n",
      "epoch: 444 loss: 1.555667757987976 grad: 10.4283903891642\n",
      "epoch: 445 loss: 1.5523830652236938 grad: 10.877882990298705\n",
      "epoch: 446 loss: 1.552946925163269 grad: 10.698261655767315\n",
      "epoch: 447 loss: 1.5522053241729736 grad: 10.498658131379338\n",
      "epoch: 448 loss: 1.5532299280166626 grad: 11.74628341128488\n",
      "epoch: 449 loss: 1.5494349002838135 grad: 11.249426575817374\n",
      "epoch: 450 loss: 1.5510711669921875 grad: 11.16381532373646\n",
      "epoch: 451 loss: 1.5521901845932007 grad: 11.17741417198161\n",
      "epoch: 452 loss: 1.5453579425811768 grad: 12.385541115089186\n",
      "epoch: 453 loss: 1.5465574264526367 grad: 12.036881061034306\n",
      "epoch: 454 loss: 1.551590085029602 grad: 10.813174441859628\n",
      "epoch: 455 loss: 1.5405821800231934 grad: 11.360959989602662\n",
      "epoch: 456 loss: 1.5471047163009644 grad: 11.71276353463708\n",
      "epoch: 457 loss: 1.5500602722167969 grad: 11.390945071535599\n",
      "epoch: 458 loss: 1.5471991300582886 grad: 10.939636724040149\n",
      "epoch: 459 loss: 1.5498363971710205 grad: 10.806912939254534\n",
      "epoch: 460 loss: 1.5475982427597046 grad: 12.056156602928356\n",
      "epoch: 461 loss: 1.553449273109436 grad: 11.267053123101563\n",
      "epoch: 462 loss: 1.5482639074325562 grad: 11.891080464195785\n",
      "epoch: 463 loss: 1.5458042621612549 grad: 10.882703983956683\n",
      "epoch: 464 loss: 1.5478545427322388 grad: 10.337896798401037\n",
      "epoch: 465 loss: 1.5508064031600952 grad: 12.288643708374972\n",
      "epoch: 466 loss: 1.5562900304794312 grad: 11.08903134577272\n",
      "epoch: 467 loss: 1.5495657920837402 grad: 10.893561516548433\n",
      "epoch: 468 loss: 1.543963074684143 grad: 10.50507743482197\n",
      "epoch: 469 loss: 1.5496742725372314 grad: 11.378746059300038\n",
      "epoch: 470 loss: 1.546595573425293 grad: 10.887085032418355\n",
      "epoch: 471 loss: 1.550370454788208 grad: 10.007878645629962\n",
      "epoch: 472 loss: 1.5531600713729858 grad: 11.228491620508038\n",
      "epoch: 473 loss: 1.5472803115844727 grad: 9.762515400697122\n",
      "epoch: 474 loss: 1.5507463216781616 grad: 11.232903993677436\n",
      "epoch: 475 loss: 1.5428619384765625 grad: 11.10221920038263\n",
      "epoch: 476 loss: 1.5511808395385742 grad: 10.598293820214975\n",
      "epoch: 477 loss: 1.5462710857391357 grad: 11.214367932871\n",
      "epoch: 478 loss: 1.5470268726348877 grad: 11.001212587055292\n",
      "epoch: 479 loss: 1.5402692556381226 grad: 11.096335971046106\n",
      "epoch: 480 loss: 1.546273112297058 grad: 11.000676315959677\n",
      "epoch: 481 loss: 1.5491786003112793 grad: 10.571728548315901\n",
      "epoch: 482 loss: 1.5508944988250732 grad: 10.478922823488357\n",
      "epoch: 483 loss: 1.551101565361023 grad: 11.500681090615837\n",
      "epoch: 484 loss: 1.5425668954849243 grad: 11.132915723130166\n",
      "epoch: 485 loss: 1.5466160774230957 grad: 10.799788727062857\n",
      "epoch: 486 loss: 1.5474125146865845 grad: 10.48195888879635\n",
      "epoch: 487 loss: 1.5468288660049438 grad: 10.818465005898375\n",
      "epoch: 488 loss: 1.5486931800842285 grad: 11.648895465484303\n",
      "epoch: 489 loss: 1.5415290594100952 grad: 10.211291391313786\n",
      "epoch: 490 loss: 1.5489842891693115 grad: 11.175849878620948\n",
      "epoch: 491 loss: 1.5450557470321655 grad: 9.728385040957836\n",
      "epoch: 492 loss: 1.5466581583023071 grad: 10.99102474413886\n",
      "epoch: 493 loss: 1.5418976545333862 grad: 10.640324457688996\n",
      "epoch: 494 loss: 1.5456198453903198 grad: 11.788765309696338\n",
      "epoch: 495 loss: 1.5452255010604858 grad: 9.678260375863857\n",
      "epoch: 496 loss: 1.5424829721450806 grad: 10.474860042274472\n",
      "epoch: 497 loss: 1.5467946529388428 grad: 10.418945354054726\n",
      "epoch: 498 loss: 1.5398972034454346 grad: 11.109085211814898\n",
      "epoch: 499 loss: 1.5458862781524658 grad: 10.850928268506236\n",
      "1.847690686583519\n",
      "epoch: 0 loss: 2.296316146850586 grad: 1.2546926953345685\n",
      "epoch: 1 loss: 2.164330005645752 grad: 2.673676821111243\n",
      "epoch: 2 loss: 2.053762912750244 grad: 3.7768279607638733\n",
      "epoch: 3 loss: 1.9595446586608887 grad: 5.1376336264490545\n",
      "epoch: 4 loss: 1.9034463167190552 grad: 6.745070811542165\n",
      "epoch: 5 loss: 1.8382508754730225 grad: 7.3613248308233565\n",
      "epoch: 6 loss: 1.7471294403076172 grad: 7.485731928842142\n",
      "epoch: 7 loss: 1.7297956943511963 grad: 7.934909643629374\n",
      "epoch: 8 loss: 1.6909669637680054 grad: 7.760659804604652\n",
      "epoch: 9 loss: 1.6673208475112915 grad: 7.486536532723611\n",
      "epoch: 10 loss: 1.7027982473373413 grad: 8.312246896989924\n",
      "epoch: 11 loss: 1.662439227104187 grad: 7.3845462788169876\n",
      "epoch: 12 loss: 1.6526858806610107 grad: 7.434695018178669\n",
      "epoch: 13 loss: 1.6463261842727661 grad: 7.302930671725393\n",
      "epoch: 14 loss: 1.6359105110168457 grad: 7.177421703141475\n",
      "epoch: 15 loss: 1.6211739778518677 grad: 6.892728549987725\n",
      "epoch: 16 loss: 1.618001103401184 grad: 7.885927706820121\n",
      "epoch: 17 loss: 1.6053745746612549 grad: 7.1301117385631345\n",
      "epoch: 18 loss: 1.6101232767105103 grad: 6.982469075883273\n",
      "epoch: 19 loss: 1.6164554357528687 grad: 6.51141205217388\n",
      "epoch: 20 loss: 1.6112180948257446 grad: 6.367944627820555\n",
      "epoch: 21 loss: 1.5830867290496826 grad: 5.794502612820546\n",
      "epoch: 22 loss: 1.5864633321762085 grad: 5.239886026054765\n",
      "epoch: 23 loss: 1.5761934518814087 grad: 5.819226959872703\n",
      "epoch: 24 loss: 1.585976481437683 grad: 5.824637087985355\n",
      "epoch: 25 loss: 1.5877525806427002 grad: 6.108550362817902\n",
      "epoch: 26 loss: 1.5718672275543213 grad: 5.425583405679462\n",
      "epoch: 27 loss: 1.579863429069519 grad: 5.670459105670849\n",
      "epoch: 28 loss: 1.5777181386947632 grad: 6.395132197370797\n",
      "epoch: 29 loss: 1.5730066299438477 grad: 5.9706436842199535\n",
      "epoch: 30 loss: 1.564919352531433 grad: 5.345771217644344\n",
      "epoch: 31 loss: 1.5706745386123657 grad: 5.669981193968967\n",
      "epoch: 32 loss: 1.565226435661316 grad: 5.116734223758382\n",
      "epoch: 33 loss: 1.5689224004745483 grad: 5.243403822817426\n",
      "epoch: 34 loss: 1.5711015462875366 grad: 6.141013794774139\n",
      "epoch: 35 loss: 1.5776870250701904 grad: 6.091418391343845\n",
      "epoch: 36 loss: 1.5553834438323975 grad: 5.4547941207923625\n",
      "epoch: 37 loss: 1.5508239269256592 grad: 4.133580194460621\n",
      "epoch: 38 loss: 1.5660271644592285 grad: 4.740562698040963\n",
      "epoch: 39 loss: 1.5647947788238525 grad: 6.134684612766294\n",
      "epoch: 40 loss: 1.561318039894104 grad: 5.416793643140727\n",
      "epoch: 41 loss: 1.559403896331787 grad: 4.584283687133552\n",
      "epoch: 42 loss: 1.560378074645996 grad: 5.880351489749598\n",
      "epoch: 43 loss: 1.5597162246704102 grad: 5.069306467681101\n",
      "epoch: 44 loss: 1.5630604028701782 grad: 5.48407806145498\n",
      "epoch: 45 loss: 1.55319344997406 grad: 5.388332074953636\n",
      "epoch: 46 loss: 1.5507047176361084 grad: 5.255937672446923\n",
      "epoch: 47 loss: 1.5572744607925415 grad: 5.958973446050362\n",
      "epoch: 48 loss: 1.569602608680725 grad: 6.038858395008599\n",
      "epoch: 49 loss: 1.5495506525039673 grad: 4.41791714395206\n",
      "epoch: 50 loss: 1.5515985488891602 grad: 3.9721855049766233\n",
      "epoch: 51 loss: 1.5548677444458008 grad: 4.432185206674815\n",
      "epoch: 52 loss: 1.5574710369110107 grad: 5.665181775402743\n",
      "epoch: 53 loss: 1.5627233982086182 grad: 5.621517640682532\n",
      "epoch: 54 loss: 1.5479562282562256 grad: 4.433470540633917\n",
      "epoch: 55 loss: 1.5445820093154907 grad: 5.3149493765796425\n",
      "epoch: 56 loss: 1.5524165630340576 grad: 5.323169165681917\n",
      "epoch: 57 loss: 1.5414962768554688 grad: 4.38146214284119\n",
      "epoch: 58 loss: 1.548282265663147 grad: 5.1055397183447475\n",
      "epoch: 59 loss: 1.5435492992401123 grad: 4.19135701039785\n",
      "epoch: 60 loss: 1.5495160818099976 grad: 5.437275083155973\n",
      "epoch: 61 loss: 1.5447205305099487 grad: 4.920809685999836\n",
      "epoch: 62 loss: 1.5365023612976074 grad: 4.762157483777123\n",
      "epoch: 63 loss: 1.5484791994094849 grad: 4.00798564240595\n",
      "epoch: 64 loss: 1.535377860069275 grad: 4.353832551121842\n",
      "epoch: 65 loss: 1.5347071886062622 grad: 3.5123502390490646\n",
      "epoch: 66 loss: 1.5325627326965332 grad: 3.2490135182040656\n",
      "epoch: 67 loss: 1.537566065788269 grad: 4.080973696576384\n",
      "epoch: 68 loss: 1.5241715908050537 grad: 3.9806812295917857\n",
      "epoch: 69 loss: 1.5521987676620483 grad: 5.102539145298308\n",
      "epoch: 70 loss: 1.5336148738861084 grad: 4.266516247771102\n",
      "epoch: 71 loss: 1.534306526184082 grad: 3.842538107999045\n",
      "epoch: 72 loss: 1.5302743911743164 grad: 4.298244696656011\n",
      "epoch: 73 loss: 1.5492016077041626 grad: 4.7674617036183395\n",
      "epoch: 74 loss: 1.526045322418213 grad: 3.3486426033925656\n",
      "epoch: 75 loss: 1.5325661897659302 grad: 4.283405259196418\n",
      "epoch: 76 loss: 1.5355522632598877 grad: 5.085346048072104\n",
      "epoch: 77 loss: 1.5616220235824585 grad: 6.326852824478465\n",
      "epoch: 78 loss: 1.5439939498901367 grad: 3.6086893780426137\n",
      "epoch: 79 loss: 1.5459110736846924 grad: 4.756472509948339\n",
      "epoch: 80 loss: 1.5489615201950073 grad: 4.315870165967266\n",
      "epoch: 81 loss: 1.5462908744812012 grad: 4.362240750090172\n",
      "epoch: 82 loss: 1.5338115692138672 grad: 4.965873912052577\n",
      "epoch: 83 loss: 1.5920674800872803 grad: 6.247005638848336\n",
      "epoch: 84 loss: 1.5365848541259766 grad: 3.442348761761145\n",
      "epoch: 85 loss: 1.5306594371795654 grad: 2.7662410709408123\n",
      "epoch: 86 loss: 1.5331186056137085 grad: 4.44526458920365\n",
      "epoch: 87 loss: 1.5284039974212646 grad: 3.5290936439397815\n",
      "epoch: 88 loss: 1.5253400802612305 grad: 3.4620838650667145\n",
      "epoch: 89 loss: 1.5380805730819702 grad: 5.219679773836312\n",
      "epoch: 90 loss: 1.5295236110687256 grad: 3.9201627165647306\n",
      "epoch: 91 loss: 1.531951904296875 grad: 3.53358464171997\n",
      "epoch: 92 loss: 1.537712574005127 grad: 3.6906669540040595\n",
      "epoch: 93 loss: 1.5343571901321411 grad: 3.4884510359699066\n",
      "epoch: 94 loss: 1.5258220434188843 grad: 3.269388137051906\n",
      "epoch: 95 loss: 1.5241436958312988 grad: 3.270643837700258\n",
      "epoch: 96 loss: 1.5273116827011108 grad: 3.8648128085393227\n",
      "epoch: 97 loss: 1.5292922258377075 grad: 2.82459224988879\n",
      "epoch: 98 loss: 1.528807282447815 grad: 3.816230210797046\n",
      "epoch: 99 loss: 1.5522791147232056 grad: 3.770772450477012\n",
      "epoch: 100 loss: 1.5302824974060059 grad: 3.9679489928401344\n",
      "epoch: 101 loss: 1.5281306505203247 grad: 2.8922264597449474\n",
      "epoch: 102 loss: 1.5379441976547241 grad: 4.065813879268142\n",
      "epoch: 103 loss: 1.5300918817520142 grad: 4.334876430197168\n",
      "epoch: 104 loss: 1.5260016918182373 grad: 3.1542890313287337\n",
      "epoch: 105 loss: 1.5253111124038696 grad: 3.641098259536267\n",
      "epoch: 106 loss: 1.5244128704071045 grad: 4.654099764749031\n",
      "epoch: 107 loss: 1.5249353647232056 grad: 4.393115386247478\n",
      "epoch: 108 loss: 1.5183500051498413 grad: 3.9341840538613693\n",
      "epoch: 109 loss: 1.5331487655639648 grad: 4.963971823605937\n",
      "epoch: 110 loss: 1.5194340944290161 grad: 2.743500436785092\n",
      "epoch: 111 loss: 1.5351685285568237 grad: 3.5687715416480974\n",
      "epoch: 112 loss: 1.5174424648284912 grad: 3.2077596292957553\n",
      "epoch: 113 loss: 1.5441867113113403 grad: 4.223837534898733\n",
      "epoch: 114 loss: 1.5218899250030518 grad: 3.4927337134839602\n",
      "epoch: 115 loss: 1.5218273401260376 grad: 4.541073054211954\n",
      "epoch: 116 loss: 1.5397318601608276 grad: 3.4241164015951013\n",
      "epoch: 117 loss: 1.5297576189041138 grad: 3.5782190024025358\n",
      "epoch: 118 loss: 1.530318021774292 grad: 4.215580734934962\n",
      "epoch: 119 loss: 1.5235129594802856 grad: 3.3514182289051675\n",
      "epoch: 120 loss: 1.541052222251892 grad: 5.021840024975494\n",
      "epoch: 121 loss: 1.53600013256073 grad: 3.7522967297147916\n",
      "epoch: 122 loss: 1.5185743570327759 grad: 3.7297082352483795\n",
      "epoch: 123 loss: 1.5384432077407837 grad: 3.862649958358548\n",
      "epoch: 124 loss: 1.5067813396453857 grad: 3.1967102193222567\n",
      "epoch: 125 loss: 1.5155186653137207 grad: 3.879745974588779\n",
      "epoch: 126 loss: 1.5193791389465332 grad: 3.212337194220455\n",
      "epoch: 127 loss: 1.5392556190490723 grad: 3.8422324841108124\n",
      "epoch: 128 loss: 1.5275524854660034 grad: 4.185119150047747\n",
      "epoch: 129 loss: 1.5265311002731323 grad: 3.720201452070567\n",
      "epoch: 130 loss: 1.5338225364685059 grad: 3.3677322358893655\n",
      "epoch: 131 loss: 1.5209460258483887 grad: 3.228434031881922\n",
      "epoch: 132 loss: 1.5176000595092773 grad: 2.274221203450433\n",
      "epoch: 133 loss: 1.5101650953292847 grad: 2.727110107678564\n",
      "epoch: 134 loss: 1.5171082019805908 grad: 3.6722893591645303\n",
      "epoch: 135 loss: 1.5259002447128296 grad: 3.433917926576325\n",
      "epoch: 136 loss: 1.5395305156707764 grad: 3.3753879816454804\n",
      "epoch: 137 loss: 1.5451686382293701 grad: 4.45637856637733\n",
      "epoch: 138 loss: 1.5267653465270996 grad: 3.629963164499998\n",
      "epoch: 139 loss: 1.5236839056015015 grad: 4.404681827804541\n",
      "epoch: 140 loss: 1.5394235849380493 grad: 4.074497237820558\n",
      "epoch: 141 loss: 1.5393264293670654 grad: 3.508435892740678\n",
      "epoch: 142 loss: 1.5145232677459717 grad: 3.170480791477404\n",
      "epoch: 143 loss: 1.5319386720657349 grad: 4.0169272225691515\n",
      "epoch: 144 loss: 1.5198230743408203 grad: 3.854737489528545\n",
      "epoch: 145 loss: 1.5473992824554443 grad: 4.91407913626736\n",
      "epoch: 146 loss: 1.5335192680358887 grad: 4.57255916887197\n",
      "epoch: 147 loss: 1.5105512142181396 grad: 2.6079637905394457\n",
      "epoch: 148 loss: 1.5171300172805786 grad: 3.11830289368613\n",
      "epoch: 149 loss: 1.5128406286239624 grad: 2.0462842533788126\n",
      "epoch: 150 loss: 1.514119029045105 grad: 2.7516179836450663\n",
      "epoch: 151 loss: 1.5110145807266235 grad: 3.215041767658606\n",
      "epoch: 152 loss: 1.5341235399246216 grad: 4.560721464789774\n",
      "epoch: 153 loss: 1.5130736827850342 grad: 3.0981735047310157\n",
      "epoch: 154 loss: 1.5068273544311523 grad: 2.956746970477275\n",
      "epoch: 155 loss: 1.5361086130142212 grad: 4.225928625469022\n",
      "epoch: 156 loss: 1.5112814903259277 grad: 1.9590669845704676\n",
      "epoch: 157 loss: 1.5086190700531006 grad: 3.11994351870747\n",
      "epoch: 158 loss: 1.517664909362793 grad: 3.0483067114394196\n",
      "epoch: 159 loss: 1.5294040441513062 grad: 2.5418704323909433\n",
      "epoch: 160 loss: 1.5304383039474487 grad: 3.22111452224684\n",
      "epoch: 161 loss: 1.535649299621582 grad: 3.6804417064940544\n",
      "epoch: 162 loss: 1.5156586170196533 grad: 3.1449404947669346\n",
      "epoch: 163 loss: 1.5175789594650269 grad: 3.031423530052255\n",
      "epoch: 164 loss: 1.5130715370178223 grad: 3.3643291774665927\n",
      "epoch: 165 loss: 1.5130923986434937 grad: 4.273514736919912\n",
      "epoch: 166 loss: 1.5366172790527344 grad: 4.548031924495416\n",
      "epoch: 167 loss: 1.5228826999664307 grad: 2.815358968959712\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 168 loss: 1.5226246118545532 grad: 4.144913043379132\n",
      "epoch: 169 loss: 1.5125459432601929 grad: 2.43284684357205\n",
      "epoch: 170 loss: 1.5170153379440308 grad: 3.2341157936200893\n",
      "epoch: 171 loss: 1.508777379989624 grad: 2.8167018215229653\n",
      "epoch: 172 loss: 1.5203304290771484 grad: 3.9102474702193706\n",
      "epoch: 173 loss: 1.5068708658218384 grad: 2.453108350900843\n",
      "epoch: 174 loss: 1.5134304761886597 grad: 2.9978510030621903\n",
      "epoch: 175 loss: 1.5077509880065918 grad: 2.501512569749213\n",
      "epoch: 176 loss: 1.5059384107589722 grad: 1.733953433419486\n",
      "epoch: 177 loss: 1.5148800611495972 grad: 2.431412050375065\n",
      "epoch: 178 loss: 1.506728172302246 grad: 3.1574692998011846\n",
      "epoch: 179 loss: 1.5093255043029785 grad: 2.9267190833765313\n",
      "epoch: 180 loss: 1.505867838859558 grad: 2.128883301271161\n",
      "epoch: 181 loss: 1.512125015258789 grad: 2.9836092960221516\n",
      "epoch: 182 loss: 1.5258097648620605 grad: 3.000673152076554\n",
      "epoch: 183 loss: 1.5073909759521484 grad: 2.7358046421921367\n",
      "epoch: 184 loss: 1.5170248746871948 grad: 2.504043472793867\n",
      "epoch: 185 loss: 1.5084362030029297 grad: 3.191335818665886\n",
      "epoch: 186 loss: 1.5142319202423096 grad: 2.917295355516872\n",
      "epoch: 187 loss: 1.5133310556411743 grad: 3.490842991474619\n",
      "epoch: 188 loss: 1.511285424232483 grad: 2.5005222163729766\n",
      "epoch: 189 loss: 1.5128387212753296 grad: 2.713298461494891\n",
      "epoch: 190 loss: 1.5073497295379639 grad: 2.125399353421554\n",
      "epoch: 191 loss: 1.5199652910232544 grad: 3.558828025399659\n",
      "epoch: 192 loss: 1.5220891237258911 grad: 3.732077441681705\n",
      "epoch: 193 loss: 1.513802409172058 grad: 3.3170635715121626\n",
      "epoch: 194 loss: 1.5207377672195435 grad: 2.271947447624625\n",
      "epoch: 195 loss: 1.5252928733825684 grad: 3.9876564570977537\n",
      "epoch: 196 loss: 1.5128812789916992 grad: 3.2954443777705333\n",
      "epoch: 197 loss: 1.5062750577926636 grad: 1.6038016259869663\n",
      "epoch: 198 loss: 1.501965880393982 grad: 1.7904031372529556\n",
      "epoch: 199 loss: 1.5042215585708618 grad: 2.314792939576804\n",
      "epoch: 200 loss: 1.5090829133987427 grad: 3.0063124772078296\n",
      "epoch: 201 loss: 1.5122010707855225 grad: 2.2514788358335585\n",
      "epoch: 202 loss: 1.5035723447799683 grad: 2.531452849045244\n",
      "epoch: 203 loss: 1.5023239850997925 grad: 2.582831173096797\n",
      "epoch: 204 loss: 1.521955966949463 grad: 3.432406373882553\n",
      "epoch: 205 loss: 1.508320689201355 grad: 2.166380284575511\n",
      "epoch: 206 loss: 1.5122554302215576 grad: 2.5299729511077143\n",
      "epoch: 207 loss: 1.5215497016906738 grad: 2.497401349032662\n",
      "epoch: 208 loss: 1.5017942190170288 grad: 2.0611442527358648\n",
      "epoch: 209 loss: 1.5141937732696533 grad: 3.4129290983920906\n",
      "epoch: 210 loss: 1.530622959136963 grad: 3.8935549265781524\n",
      "epoch: 211 loss: 1.5375261306762695 grad: 4.015278357699576\n",
      "epoch: 212 loss: 1.5183935165405273 grad: 3.4798981814143426\n",
      "epoch: 213 loss: 1.5108305215835571 grad: 3.007118477712737\n",
      "epoch: 214 loss: 1.5148084163665771 grad: 2.9715506010687798\n",
      "epoch: 215 loss: 1.512899398803711 grad: 2.8602470751286515\n",
      "epoch: 216 loss: 1.5098522901535034 grad: 2.3781272173524175\n",
      "epoch: 217 loss: 1.50108003616333 grad: 2.6378065902514254\n",
      "epoch: 218 loss: 1.5074512958526611 grad: 2.039342075914032\n",
      "epoch: 219 loss: 1.503969430923462 grad: 2.7409313171508614\n",
      "epoch: 220 loss: 1.5046976804733276 grad: 2.054802023103092\n",
      "epoch: 221 loss: 1.516830563545227 grad: 2.6423711229548803\n",
      "epoch: 222 loss: 1.5025545358657837 grad: 2.413539816080049\n",
      "epoch: 223 loss: 1.5022482872009277 grad: 1.7269024287694295\n",
      "epoch: 224 loss: 1.5083751678466797 grad: 2.5878524716356437\n",
      "epoch: 225 loss: 1.5233732461929321 grad: 2.0703827885550843\n",
      "epoch: 226 loss: 1.523105502128601 grad: 4.018615199349841\n",
      "epoch: 227 loss: 1.5254225730895996 grad: 2.014566124356865\n",
      "epoch: 228 loss: 1.5180736780166626 grad: 3.755941940162496\n",
      "epoch: 229 loss: 1.5110080242156982 grad: 2.226254883505277\n",
      "epoch: 230 loss: 1.5046724081039429 grad: 2.274894887551115\n",
      "epoch: 231 loss: 1.5144540071487427 grad: 3.878253362276236\n",
      "epoch: 232 loss: 1.5156038999557495 grad: 2.369720877228112\n",
      "epoch: 233 loss: 1.5073057413101196 grad: 2.1613097058176325\n",
      "epoch: 234 loss: 1.5021438598632812 grad: 2.4853688009998485\n",
      "epoch: 235 loss: 1.5093029737472534 grad: 3.1423902010555893\n",
      "epoch: 236 loss: 1.522445797920227 grad: 2.042315913117749\n",
      "epoch: 237 loss: 1.4934967756271362 grad: 1.4477096644477008\n",
      "epoch: 238 loss: 1.5052930116653442 grad: 2.4599459357851226\n",
      "epoch: 239 loss: 1.5027196407318115 grad: 2.5133562332860535\n",
      "epoch: 240 loss: 1.5092307329177856 grad: 3.8441764781946253\n",
      "epoch: 241 loss: 1.5167455673217773 grad: 3.516242966500138\n",
      "epoch: 242 loss: 1.5161041021347046 grad: 2.6165856885555567\n",
      "epoch: 243 loss: 1.4928860664367676 grad: 2.212667713338456\n",
      "epoch: 244 loss: 1.4992791414260864 grad: 2.3930410861433704\n",
      "epoch: 245 loss: 1.4911537170410156 grad: 1.8035085985330765\n",
      "epoch: 246 loss: 1.5066450834274292 grad: 2.3793801090631472\n",
      "epoch: 247 loss: 1.5097808837890625 grad: 2.560405079634\n",
      "epoch: 248 loss: 1.5029245615005493 grad: 2.0271663938631805\n",
      "epoch: 249 loss: 1.5086326599121094 grad: 2.6762745595834674\n",
      "epoch: 250 loss: 1.5079841613769531 grad: 2.6310044098033605\n",
      "epoch: 251 loss: 1.5025949478149414 grad: 2.5984158868805722\n",
      "epoch: 252 loss: 1.5085597038269043 grad: 1.8873373977669399\n",
      "epoch: 253 loss: 1.5145143270492554 grad: 2.8843125597555255\n",
      "epoch: 254 loss: 1.507135033607483 grad: 2.25795984349522\n",
      "epoch: 255 loss: 1.5095051527023315 grad: 2.1402747439863505\n",
      "epoch: 256 loss: 1.5024185180664062 grad: 2.21533837670701\n",
      "epoch: 257 loss: 1.5125725269317627 grad: 2.907107223673858\n",
      "epoch: 258 loss: 1.5351223945617676 grad: 4.304416181789439\n",
      "epoch: 259 loss: 1.5240321159362793 grad: 4.624457981479934\n",
      "epoch: 260 loss: 1.5629446506500244 grad: 3.96850927685533\n",
      "epoch: 261 loss: 1.5290504693984985 grad: 3.0555009917394447\n",
      "epoch: 262 loss: 1.500423789024353 grad: 1.8328568638931038\n",
      "epoch: 263 loss: 1.5014528036117554 grad: 1.319322588559621\n",
      "epoch: 264 loss: 1.507513403892517 grad: 2.2738424850666834\n",
      "epoch: 265 loss: 1.5157538652420044 grad: 2.310429996961928\n",
      "epoch: 266 loss: 1.5067602396011353 grad: 2.9160786931689437\n",
      "epoch: 267 loss: 1.508863925933838 grad: 2.472147956673535\n",
      "epoch: 268 loss: 1.5087964534759521 grad: 2.5770538355502164\n",
      "epoch: 269 loss: 1.5239230394363403 grad: 3.258335702598029\n",
      "epoch: 270 loss: 1.4994285106658936 grad: 2.4562183879778354\n",
      "epoch: 271 loss: 1.505515694618225 grad: 2.2574078078428537\n",
      "epoch: 272 loss: 1.5168476104736328 grad: 3.6441458536909894\n",
      "epoch: 273 loss: 1.5201902389526367 grad: 2.7430670089944647\n",
      "epoch: 274 loss: 1.5123950242996216 grad: 3.378199202775127\n",
      "epoch: 275 loss: 1.502657413482666 grad: 1.6469625492690008\n",
      "epoch: 276 loss: 1.5119233131408691 grad: 3.426001054722235\n",
      "epoch: 277 loss: 1.509456992149353 grad: 3.825201165370012\n",
      "epoch: 278 loss: 1.5073306560516357 grad: 1.6342399703001458\n",
      "epoch: 279 loss: 1.501172423362732 grad: 1.3563727607819944\n",
      "epoch: 280 loss: 1.5073200464248657 grad: 2.773990568419863\n",
      "epoch: 281 loss: 1.5093882083892822 grad: 2.874900921957067\n",
      "epoch: 282 loss: 1.5120841264724731 grad: 2.3954142001685717\n",
      "epoch: 283 loss: 1.498431921005249 grad: 2.7203514356348397\n",
      "epoch: 284 loss: 1.5026524066925049 grad: 3.5473572939685245\n",
      "epoch: 285 loss: 1.5017039775848389 grad: 2.7368887600140077\n",
      "epoch: 286 loss: 1.5011303424835205 grad: 3.088725008281616\n",
      "epoch: 287 loss: 1.4946209192276 grad: 2.3027680736727705\n",
      "epoch: 288 loss: 1.5076762437820435 grad: 2.624078571495859\n",
      "epoch: 289 loss: 1.516042709350586 grad: 2.6297922293765152\n",
      "epoch: 290 loss: 1.497469425201416 grad: 2.7751177873033157\n",
      "epoch: 291 loss: 1.5077662467956543 grad: 3.217599047695995\n",
      "epoch: 292 loss: 1.5015922784805298 grad: 2.685365752756223\n",
      "epoch: 293 loss: 1.5004091262817383 grad: 2.336225605758784\n",
      "epoch: 294 loss: 1.4959661960601807 grad: 2.3394234117188635\n",
      "epoch: 295 loss: 1.4887930154800415 grad: 1.8785117764488182\n",
      "epoch: 296 loss: 1.493668556213379 grad: 1.4594759433252091\n",
      "epoch: 297 loss: 1.5107332468032837 grad: 3.4262782688403446\n",
      "epoch: 298 loss: 1.5127774477005005 grad: 2.756337110273052\n",
      "epoch: 299 loss: 1.5010164976119995 grad: 2.14124560826376\n",
      "epoch: 300 loss: 1.5093178749084473 grad: 2.594518665690457\n",
      "epoch: 301 loss: 1.5272669792175293 grad: 3.8175830673548297\n",
      "epoch: 302 loss: 1.5123810768127441 grad: 3.064788480909056\n",
      "epoch: 303 loss: 1.5176550149917603 grad: 3.2973042247835243\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 304 loss: 1.4994237422943115 grad: 2.57191735720224\n",
      "epoch: 305 loss: 1.5093281269073486 grad: 3.1938224046583215\n",
      "epoch: 306 loss: 1.5125195980072021 grad: 2.4068621872837914\n",
      "epoch: 307 loss: 1.494893193244934 grad: 1.879315033057754\n",
      "epoch: 308 loss: 1.5026007890701294 grad: 2.3655486480103045\n",
      "epoch: 309 loss: 1.5075640678405762 grad: 1.4474256923953335\n",
      "epoch: 310 loss: 1.4940760135650635 grad: 1.3652044714622413\n",
      "epoch: 311 loss: 1.5030381679534912 grad: 3.0480191704506785\n",
      "epoch: 312 loss: 1.4988752603530884 grad: 2.1853304860176705\n",
      "epoch: 313 loss: 1.4945660829544067 grad: 1.312800086997353\n",
      "epoch: 314 loss: 1.4899412393569946 grad: 1.7959434605107123\n",
      "epoch: 315 loss: 1.4978070259094238 grad: 2.8444953642615745\n",
      "epoch: 316 loss: 1.4902338981628418 grad: 1.5622925734004642\n",
      "epoch: 317 loss: 1.4873985052108765 grad: 1.2809082831715068\n",
      "epoch: 318 loss: 1.5212262868881226 grad: 4.830429618243873\n",
      "epoch: 319 loss: 1.5317308902740479 grad: 3.661020362216141\n",
      "epoch: 320 loss: 1.5157532691955566 grad: 2.6965278790895586\n",
      "epoch: 321 loss: 1.5097386837005615 grad: 1.5535184948273588\n",
      "epoch: 322 loss: 1.5022122859954834 grad: 3.177285435540157\n",
      "epoch: 323 loss: 1.5080639123916626 grad: 2.113744936977325\n",
      "epoch: 324 loss: 1.4893639087677002 grad: 1.992121679877994\n",
      "epoch: 325 loss: 1.4968528747558594 grad: 2.355600228562052\n",
      "epoch: 326 loss: 1.508558988571167 grad: 1.7377711014443626\n",
      "epoch: 327 loss: 1.505151629447937 grad: 2.7081326875418523\n",
      "epoch: 328 loss: 1.499226450920105 grad: 1.4890626250190044\n",
      "epoch: 329 loss: 1.487197995185852 grad: 1.1208208166139724\n",
      "epoch: 330 loss: 1.4890652894973755 grad: 1.9921848226825438\n",
      "epoch: 331 loss: 1.5098880529403687 grad: 2.4708031399909696\n",
      "epoch: 332 loss: 1.5061317682266235 grad: 2.282285220441593\n",
      "epoch: 333 loss: 1.500399112701416 grad: 2.381477950660526\n",
      "epoch: 334 loss: 1.503270149230957 grad: 3.026720047419801\n",
      "epoch: 335 loss: 1.4920748472213745 grad: 2.4562072175395406\n",
      "epoch: 336 loss: 1.4930179119110107 grad: 2.2267065669823456\n",
      "epoch: 337 loss: 1.4972041845321655 grad: 2.193378917114789\n",
      "epoch: 338 loss: 1.4914178848266602 grad: 1.9779759284175076\n",
      "epoch: 339 loss: 1.49212646484375 grad: 2.0476254744181115\n",
      "epoch: 340 loss: 1.4983693361282349 grad: 1.963278636085026\n",
      "epoch: 341 loss: 1.4919120073318481 grad: 1.6097407620277497\n",
      "epoch: 342 loss: 1.4868488311767578 grad: 1.9928646412518318\n",
      "epoch: 343 loss: 1.4880367517471313 grad: 1.479794464398838\n",
      "epoch: 344 loss: 1.4995760917663574 grad: 2.692639696180513\n",
      "epoch: 345 loss: 1.5012881755828857 grad: 1.8442398859905103\n",
      "epoch: 346 loss: 1.5063068866729736 grad: 2.4530069142539674\n",
      "epoch: 347 loss: 1.5013477802276611 grad: 1.6779293286888477\n",
      "epoch: 348 loss: 1.4932754039764404 grad: 1.5890013292203609\n",
      "epoch: 349 loss: 1.4941775798797607 grad: 1.7768088041398193\n",
      "epoch: 350 loss: 1.50273597240448 grad: 1.8370260041675968\n",
      "epoch: 351 loss: 1.5101021528244019 grad: 2.6610181243342153\n",
      "epoch: 352 loss: 1.5117089748382568 grad: 3.9472587739770644\n",
      "epoch: 353 loss: 1.5054247379302979 grad: 2.326915814715174\n",
      "epoch: 354 loss: 1.5047613382339478 grad: 2.295582042496704\n",
      "epoch: 355 loss: 1.5123299360275269 grad: 1.7580898246880203\n",
      "epoch: 356 loss: 1.4985154867172241 grad: 2.0834375308487623\n",
      "epoch: 357 loss: 1.4959615468978882 grad: 1.9038125462494626\n",
      "epoch: 358 loss: 1.4988666772842407 grad: 2.2673970386188467\n",
      "epoch: 359 loss: 1.5089619159698486 grad: 2.7689143225616686\n",
      "epoch: 360 loss: 1.497235894203186 grad: 2.070243075730022\n",
      "epoch: 361 loss: 1.4867892265319824 grad: 1.4681475416823448\n",
      "epoch: 362 loss: 1.5073703527450562 grad: 2.3481028650708304\n",
      "epoch: 363 loss: 1.521447777748108 grad: 3.229946868819808\n",
      "epoch: 364 loss: 1.504454255104065 grad: 2.5605111690688145\n",
      "epoch: 365 loss: 1.5005375146865845 grad: 2.2737066665731858\n",
      "epoch: 366 loss: 1.4964854717254639 grad: 2.3263467282249097\n",
      "epoch: 367 loss: 1.492689609527588 grad: 2.0934979071414896\n",
      "epoch: 368 loss: 1.514684796333313 grad: 2.490119365690405\n",
      "epoch: 369 loss: 1.504184603691101 grad: 1.6438149088655523\n",
      "epoch: 370 loss: 1.4978224039077759 grad: 2.1759380942979094\n",
      "epoch: 371 loss: 1.5071516036987305 grad: 1.2239929555808928\n",
      "epoch: 372 loss: 1.5072489976882935 grad: 2.5333363193131793\n",
      "epoch: 373 loss: 1.4942728281021118 grad: 2.709654072859881\n",
      "epoch: 374 loss: 1.5004688501358032 grad: 2.0021360215098793\n",
      "epoch: 375 loss: 1.501939296722412 grad: 2.42796915700023\n",
      "epoch: 376 loss: 1.5053702592849731 grad: 2.523603959543846\n",
      "epoch: 377 loss: 1.5205166339874268 grad: 1.9009552713393616\n",
      "epoch: 378 loss: 1.5106451511383057 grad: 4.160101941843539\n",
      "epoch: 379 loss: 1.505474328994751 grad: 3.0579886324407295\n",
      "epoch: 380 loss: 1.5070244073867798 grad: 1.6405996490101993\n",
      "epoch: 381 loss: 1.5023466348648071 grad: 3.303312010968905\n",
      "epoch: 382 loss: 1.5014220476150513 grad: 2.4875319155492277\n",
      "epoch: 383 loss: 1.4987117052078247 grad: 2.1020404202577136\n",
      "epoch: 384 loss: 1.5014255046844482 grad: 2.9239037068195577\n",
      "epoch: 385 loss: 1.5042322874069214 grad: 2.1487753254985438\n",
      "epoch: 386 loss: 1.5124292373657227 grad: 3.302315418501764\n",
      "epoch: 387 loss: 1.5071029663085938 grad: 2.7573893004947783\n",
      "epoch: 388 loss: 1.4971859455108643 grad: 2.5200281392057318\n",
      "epoch: 389 loss: 1.5069143772125244 grad: 2.4855610067184437\n",
      "epoch: 390 loss: 1.5000739097595215 grad: 1.9753814152245308\n",
      "epoch: 391 loss: 1.488537073135376 grad: 1.329583723800119\n",
      "epoch: 392 loss: 1.4904594421386719 grad: 1.7177782159210322\n",
      "epoch: 393 loss: 1.4860256910324097 grad: 1.041118587415273\n",
      "epoch: 394 loss: 1.481967806816101 grad: 0.9370059549705626\n",
      "epoch: 395 loss: 1.4886962175369263 grad: 1.4264032847231165\n",
      "epoch: 396 loss: 1.4844510555267334 grad: 2.30008466572796\n",
      "epoch: 397 loss: 1.4878933429718018 grad: 0.6779787806751048\n",
      "epoch: 398 loss: 1.4897356033325195 grad: 1.8152755879934928\n",
      "epoch: 399 loss: 1.4943652153015137 grad: 2.5414831676046727\n",
      "epoch: 400 loss: 1.5173667669296265 grad: 2.1318627957377845\n",
      "epoch: 401 loss: 1.4972411394119263 grad: 2.3902874358799866\n",
      "epoch: 402 loss: 1.493870735168457 grad: 1.7156193250212786\n",
      "epoch: 403 loss: 1.4910147190093994 grad: 1.5438770636578882\n",
      "epoch: 404 loss: 1.501384973526001 grad: 2.1935539650991753\n",
      "epoch: 405 loss: 1.4913148880004883 grad: 1.1756752379848103\n",
      "epoch: 406 loss: 1.499353051185608 grad: 2.530168233141507\n",
      "epoch: 407 loss: 1.5052846670150757 grad: 2.780156876796923\n",
      "epoch: 408 loss: 1.4986048936843872 grad: 1.9262756748713665\n",
      "epoch: 409 loss: 1.5056114196777344 grad: 3.083257633520522\n",
      "epoch: 410 loss: 1.4992550611495972 grad: 1.9089565940739126\n",
      "epoch: 411 loss: 1.4979767799377441 grad: 1.673201574744682\n",
      "epoch: 412 loss: 1.4925211668014526 grad: 1.9535451195194522\n",
      "epoch: 413 loss: 1.4877861738204956 grad: 1.12169388623443\n",
      "epoch: 414 loss: 1.500887155532837 grad: 2.814356820968259\n",
      "epoch: 415 loss: 1.5068224668502808 grad: 3.1150181694481276\n",
      "epoch: 416 loss: 1.495096206665039 grad: 1.6068741990668305\n",
      "epoch: 417 loss: 1.4948289394378662 grad: 2.067593400328726\n",
      "epoch: 418 loss: 1.4911829233169556 grad: 2.044562009934817\n",
      "epoch: 419 loss: 1.4976656436920166 grad: 1.8225916652114318\n",
      "epoch: 420 loss: 1.4946587085723877 grad: 2.1538734225982243\n",
      "epoch: 421 loss: 1.5063490867614746 grad: 3.7150232858956618\n",
      "epoch: 422 loss: 1.4987761974334717 grad: 1.7432236596660633\n",
      "epoch: 423 loss: 1.4973187446594238 grad: 1.694670893897056\n",
      "epoch: 424 loss: 1.5143896341323853 grad: 3.7326290802840765\n",
      "epoch: 425 loss: 1.518381118774414 grad: 2.5287180975818044\n",
      "epoch: 426 loss: 1.4979541301727295 grad: 2.158274742247027\n",
      "epoch: 427 loss: 1.4896888732910156 grad: 1.3694672413296933\n",
      "epoch: 428 loss: 1.4897043704986572 grad: 1.4497431419060849\n",
      "epoch: 429 loss: 1.4872366189956665 grad: 1.405653622002162\n",
      "epoch: 430 loss: 1.5006473064422607 grad: 2.2845934136337354\n",
      "epoch: 431 loss: 1.5099382400512695 grad: 2.0768674597564583\n",
      "epoch: 432 loss: 1.5105061531066895 grad: 2.4858480002341534\n",
      "epoch: 433 loss: 1.5116519927978516 grad: 2.213787296128277\n",
      "epoch: 434 loss: 1.4895856380462646 grad: 1.3456657611698268\n",
      "epoch: 435 loss: 1.4899559020996094 grad: 0.6908448901286832\n",
      "epoch: 436 loss: 1.489139199256897 grad: 1.7003488518877734\n",
      "epoch: 437 loss: 1.4867945909500122 grad: 1.702620619923862\n",
      "epoch: 438 loss: 1.5006178617477417 grad: 2.066372770279234\n",
      "epoch: 439 loss: 1.509971022605896 grad: 2.917607283865739\n",
      "epoch: 440 loss: 1.4996328353881836 grad: 1.3337693251946943\n",
      "epoch: 441 loss: 1.4879244565963745 grad: 1.4579469522399526\n",
      "epoch: 442 loss: 1.488750696182251 grad: 1.1816664695872656\n",
      "epoch: 443 loss: 1.4904886484146118 grad: 1.7079418723584219\n",
      "epoch: 444 loss: 1.5025367736816406 grad: 1.6722871215659285\n",
      "epoch: 445 loss: 1.4926917552947998 grad: 2.245539130783094\n",
      "epoch: 446 loss: 1.5024433135986328 grad: 2.630504511958663\n",
      "epoch: 447 loss: 1.490269660949707 grad: 1.2323958070863892\n",
      "epoch: 448 loss: 1.497280240058899 grad: 2.82052448471966\n",
      "epoch: 449 loss: 1.5088651180267334 grad: 2.6257586926709213\n",
      "epoch: 450 loss: 1.4977844953536987 grad: 1.2716194784629198\n",
      "epoch: 451 loss: 1.4952008724212646 grad: 2.4300654449521994\n",
      "epoch: 452 loss: 1.503747820854187 grad: 2.2594487689351332\n",
      "epoch: 453 loss: 1.4895316362380981 grad: 1.5755958288378025\n",
      "epoch: 454 loss: 1.484723448753357 grad: 1.0027132868281112\n",
      "epoch: 455 loss: 1.4879536628723145 grad: 1.2652739159717084\n",
      "epoch: 456 loss: 1.484445333480835 grad: 1.3618407102450099\n",
      "epoch: 457 loss: 1.486655354499817 grad: 1.275974143682545\n",
      "epoch: 458 loss: 1.495267391204834 grad: 2.656813225522386\n",
      "epoch: 459 loss: 1.4910935163497925 grad: 1.3670264633543956\n",
      "epoch: 460 loss: 1.4927150011062622 grad: 2.0381842909966053\n",
      "epoch: 461 loss: 1.4997429847717285 grad: 1.751925624175564\n",
      "epoch: 462 loss: 1.4904602766036987 grad: 1.0077192069491199\n",
      "epoch: 463 loss: 1.4945850372314453 grad: 2.0449021388696953\n",
      "epoch: 464 loss: 1.5139799118041992 grad: 2.988758901428259\n",
      "epoch: 465 loss: 1.5185030698776245 grad: 2.463807414022381\n",
      "epoch: 466 loss: 1.522316336631775 grad: 2.958861840043005\n",
      "epoch: 467 loss: 1.5039243698120117 grad: 2.0238466028675632\n",
      "epoch: 468 loss: 1.4986743927001953 grad: 1.1911650218917675\n",
      "epoch: 469 loss: 1.4986257553100586 grad: 1.6059099813747428\n",
      "epoch: 470 loss: 1.4936989545822144 grad: 1.9242347976947818\n",
      "epoch: 471 loss: 1.4914979934692383 grad: 1.3723852152624691\n",
      "epoch: 472 loss: 1.4817144870758057 grad: 0.9597193585781322\n",
      "epoch: 473 loss: 1.4939789772033691 grad: 1.4811281857929421\n",
      "epoch: 474 loss: 1.4864869117736816 grad: 1.1014138154406046\n",
      "epoch: 475 loss: 1.4913086891174316 grad: 1.2595842208934027\n",
      "epoch: 476 loss: 1.5002250671386719 grad: 2.347960053563512\n",
      "epoch: 477 loss: 1.5278804302215576 grad: 2.482729601024224\n",
      "epoch: 478 loss: 1.500298261642456 grad: 1.9298726759459355\n",
      "epoch: 479 loss: 1.4958686828613281 grad: 1.9321250403470185\n",
      "epoch: 480 loss: 1.5080194473266602 grad: 3.2024710981411477\n",
      "epoch: 481 loss: 1.4926730394363403 grad: 2.600284865692322\n",
      "epoch: 482 loss: 1.4993263483047485 grad: 2.063392525507456\n",
      "epoch: 483 loss: 1.5036022663116455 grad: 2.310610387115714\n",
      "epoch: 484 loss: 1.4956718683242798 grad: 1.0556249547097616\n",
      "epoch: 485 loss: 1.4897736310958862 grad: 0.8195686679155085\n",
      "epoch: 486 loss: 1.486230731010437 grad: 1.0449679952171638\n",
      "epoch: 487 loss: 1.4803403615951538 grad: 0.9897663540847751\n",
      "epoch: 488 loss: 1.481377363204956 grad: 1.4339985661719614\n",
      "epoch: 489 loss: 1.5023090839385986 grad: 2.145344326574086\n",
      "epoch: 490 loss: 1.5036598443984985 grad: 1.9797428055828976\n",
      "epoch: 491 loss: 1.5182286500930786 grad: 2.2799876178078176\n",
      "epoch: 492 loss: 1.5043494701385498 grad: 1.7917610238509067\n",
      "epoch: 493 loss: 1.4961382150650024 grad: 2.1867651599138607\n",
      "epoch: 494 loss: 1.5272377729415894 grad: 3.5493697823151735\n",
      "epoch: 495 loss: 1.5185333490371704 grad: 4.143449928638501\n",
      "epoch: 496 loss: 1.4991111755371094 grad: 1.4070907062508393\n",
      "epoch: 497 loss: 1.4907400608062744 grad: 2.004549865650206\n",
      "epoch: 498 loss: 1.4850304126739502 grad: 1.7142387185168961\n",
      "epoch: 499 loss: 1.4938713312149048 grad: 1.9485045101841119\n",
      "1.8226224556565285\n",
      "epoch: 0 loss: 2.3034186363220215 grad: 1.620871587649047\n",
      "epoch: 1 loss: 2.3034842014312744 grad: 1.6082861879581793\n",
      "epoch: 2 loss: 2.303389072418213 grad: 1.6151474356144992\n",
      "epoch: 3 loss: 2.303544044494629 grad: 1.6194542115665085\n",
      "epoch: 4 loss: 2.303239583969116 grad: 1.6087652753155295\n",
      "epoch: 5 loss: 2.3026111125946045 grad: 1.6215652866466415\n",
      "epoch: 6 loss: 2.3033394813537598 grad: 1.6137374622104246\n",
      "epoch: 7 loss: 2.303797483444214 grad: 1.6227949910708481\n",
      "epoch: 8 loss: 2.302515745162964 grad: 1.6234407555866277\n",
      "epoch: 9 loss: 2.302863836288452 grad: 1.6154185457391634\n",
      "epoch: 10 loss: 2.3030688762664795 grad: 1.6091101605275144\n",
      "epoch: 11 loss: 2.3029043674468994 grad: 1.619702030852851\n",
      "epoch: 12 loss: 2.3029446601867676 grad: 1.6151630342531476\n",
      "epoch: 13 loss: 2.302640676498413 grad: 1.62141518848246\n",
      "epoch: 14 loss: 2.3030483722686768 grad: 1.6144323119864104\n",
      "epoch: 15 loss: 2.3031022548675537 grad: 1.6197414286212908\n",
      "epoch: 16 loss: 2.3028006553649902 grad: 1.621875315679178\n",
      "epoch: 17 loss: 2.3036766052246094 grad: 1.6081257058189264\n",
      "epoch: 18 loss: 2.3027212619781494 grad: 1.6085861874855167\n",
      "epoch: 19 loss: 2.3037116527557373 grad: 1.5966884417030665\n",
      "epoch: 20 loss: 2.303075075149536 grad: 1.613311263884137\n",
      "epoch: 21 loss: 2.3033065795898438 grad: 1.6071336986903575\n",
      "epoch: 22 loss: 2.3027427196502686 grad: 1.6178001551593224\n",
      "epoch: 23 loss: 2.3031275272369385 grad: 1.6130902076746145\n",
      "epoch: 24 loss: 2.3033430576324463 grad: 1.5985973651099594\n",
      "epoch: 25 loss: 2.303095817565918 grad: 1.609135939880082\n",
      "epoch: 26 loss: 2.302786111831665 grad: 1.615539376779149\n",
      "epoch: 27 loss: 2.3035075664520264 grad: 1.5942445087527473\n",
      "epoch: 28 loss: 2.303004026412964 grad: 1.5922064862864476\n",
      "epoch: 29 loss: 2.302748680114746 grad: 1.6154670853570605\n",
      "epoch: 30 loss: 2.303352117538452 grad: 1.585654039120686\n",
      "epoch: 31 loss: 2.303248643875122 grad: 1.5951443141407615\n",
      "epoch: 32 loss: 2.303074836730957 grad: 1.6040578637187117\n",
      "epoch: 33 loss: 2.3022987842559814 grad: 1.6213232713551926\n",
      "epoch: 34 loss: 2.303457736968994 grad: 1.598283590172373\n",
      "epoch: 35 loss: 2.3032736778259277 grad: 1.6014514949934056\n",
      "epoch: 36 loss: 2.302603244781494 grad: 1.6131112195943142\n",
      "epoch: 37 loss: 2.3032515048980713 grad: 1.5966128620415156\n",
      "epoch: 38 loss: 2.3026282787323 grad: 1.6217560057254834\n",
      "epoch: 39 loss: 2.303183078765869 grad: 1.6021146286936803\n",
      "epoch: 40 loss: 2.302422523498535 grad: 1.61787688083178\n",
      "epoch: 41 loss: 2.3031628131866455 grad: 1.607363672753323\n",
      "epoch: 42 loss: 2.3023974895477295 grad: 1.6102098615522245\n",
      "epoch: 43 loss: 2.3033182621002197 grad: 1.5964952270751671\n",
      "epoch: 44 loss: 2.3031206130981445 grad: 1.6079442373122133\n",
      "epoch: 45 loss: 2.302947998046875 grad: 1.5991410551710972\n",
      "epoch: 46 loss: 2.3030848503112793 grad: 1.60573293214723\n",
      "epoch: 47 loss: 2.3028564453125 grad: 1.5994234985620197\n",
      "epoch: 48 loss: 2.30230975151062 grad: 1.61560678861237\n",
      "epoch: 49 loss: 2.3024866580963135 grad: 1.612639244056366\n",
      "epoch: 50 loss: 2.3023548126220703 grad: 1.5990476352236573\n",
      "epoch: 51 loss: 2.302546739578247 grad: 1.5998851975485209\n",
      "epoch: 52 loss: 2.3032009601593018 grad: 1.6002096713720155\n",
      "epoch: 53 loss: 2.303007125854492 grad: 1.5877826595771318\n",
      "epoch: 54 loss: 2.302539825439453 grad: 1.6095120195439825\n",
      "epoch: 55 loss: 2.3028059005737305 grad: 1.5957267028150253\n",
      "epoch: 56 loss: 2.302844285964966 grad: 1.5910189444095724\n",
      "epoch: 57 loss: 2.3023452758789062 grad: 1.604160803216805\n",
      "epoch: 58 loss: 2.302795886993408 grad: 1.5954248714593373\n",
      "epoch: 59 loss: 2.302708864212036 grad: 1.5849612413476857\n",
      "epoch: 60 loss: 2.3023667335510254 grad: 1.5914114656477487\n",
      "epoch: 61 loss: 2.3031296730041504 grad: 1.5834064531354382\n",
      "epoch: 62 loss: 2.3026187419891357 grad: 1.6037475010195363\n",
      "epoch: 63 loss: 2.3023018836975098 grad: 1.6234993734507865\n",
      "epoch: 64 loss: 2.3028440475463867 grad: 1.5952755682806055\n",
      "epoch: 65 loss: 2.302854299545288 grad: 1.5845969775488364\n",
      "epoch: 66 loss: 2.302443504333496 grad: 1.6054784772429793\n",
      "epoch: 67 loss: 2.3023953437805176 grad: 1.6007583090972657\n",
      "epoch: 68 loss: 2.3025729656219482 grad: 1.59461234334398\n",
      "epoch: 69 loss: 2.3026387691497803 grad: 1.5994159017785614\n",
      "epoch: 70 loss: 2.3030738830566406 grad: 1.5765334490653393\n",
      "epoch: 71 loss: 2.302790880203247 grad: 1.594633628089454\n",
      "epoch: 72 loss: 2.302441358566284 grad: 1.5949645735146034\n",
      "epoch: 73 loss: 2.302401542663574 grad: 1.5968031196463262\n",
      "epoch: 74 loss: 2.3023080825805664 grad: 1.6003603070146508\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 75 loss: 2.303009510040283 grad: 1.591791807988008\n",
      "epoch: 76 loss: 2.30214524269104 grad: 1.6144148375846386\n",
      "epoch: 77 loss: 2.3027284145355225 grad: 1.5924838941640382\n",
      "epoch: 78 loss: 2.3028008937835693 grad: 1.591077196323091\n",
      "epoch: 79 loss: 2.3026795387268066 grad: 1.5954809248103716\n",
      "epoch: 80 loss: 2.302518606185913 grad: 1.5931896675352215\n",
      "epoch: 81 loss: 2.303088665008545 grad: 1.579107377395433\n",
      "epoch: 82 loss: 2.302924394607544 grad: 1.5871981165412488\n",
      "epoch: 83 loss: 2.3024840354919434 grad: 1.6057570006731632\n",
      "epoch: 84 loss: 2.3021256923675537 grad: 1.5889526652246122\n",
      "epoch: 85 loss: 2.3026533126831055 grad: 1.5860870925354815\n",
      "epoch: 86 loss: 2.30238676071167 grad: 1.6037006350455894\n",
      "epoch: 87 loss: 2.3027255535125732 grad: 1.5892638544448547\n",
      "epoch: 88 loss: 2.302241802215576 grad: 1.601133087775596\n",
      "epoch: 89 loss: 2.302570343017578 grad: 1.598629546778587\n",
      "epoch: 90 loss: 2.3029353618621826 grad: 1.5828439882745788\n",
      "epoch: 91 loss: 2.302471876144409 grad: 1.5967447584539296\n",
      "epoch: 92 loss: 2.302586078643799 grad: 1.5867298582498546\n",
      "epoch: 93 loss: 2.302565574645996 grad: 1.6000203921474399\n",
      "epoch: 94 loss: 2.30220627784729 grad: 1.594832035749855\n",
      "epoch: 95 loss: 2.302459955215454 grad: 1.5987943980735653\n",
      "epoch: 96 loss: 2.302555799484253 grad: 1.5856980160322218\n",
      "epoch: 97 loss: 2.3026742935180664 grad: 1.5790657977192915\n",
      "epoch: 98 loss: 2.301987409591675 grad: 1.5865840576995638\n",
      "epoch: 99 loss: 2.302520990371704 grad: 1.5899897749214211\n",
      "epoch: 100 loss: 2.3024256229400635 grad: 1.5985300329343846\n",
      "epoch: 101 loss: 2.3027172088623047 grad: 1.5922171832579706\n",
      "epoch: 102 loss: 2.302452564239502 grad: 1.5990747359529551\n",
      "epoch: 103 loss: 2.302999258041382 grad: 1.5891565669398193\n",
      "epoch: 104 loss: 2.3022093772888184 grad: 1.5988425222218097\n",
      "epoch: 105 loss: 2.3027119636535645 grad: 1.5908350044055768\n",
      "epoch: 106 loss: 2.3025388717651367 grad: 1.5886831833807278\n",
      "epoch: 107 loss: 2.302194595336914 grad: 1.5945296647943674\n",
      "epoch: 108 loss: 2.3025612831115723 grad: 1.5913382393736688\n",
      "epoch: 109 loss: 2.3030099868774414 grad: 1.5805424780821398\n",
      "epoch: 110 loss: 2.3025388717651367 grad: 1.589959792968344\n",
      "epoch: 111 loss: 2.3028109073638916 grad: 1.5840854320438609\n",
      "epoch: 112 loss: 2.3022961616516113 grad: 1.5946601244975769\n",
      "epoch: 113 loss: 2.302103281021118 grad: 1.5983958139993428\n",
      "epoch: 114 loss: 2.3025732040405273 grad: 1.5879867753597894\n",
      "epoch: 115 loss: 2.30251407623291 grad: 1.5900071624644279\n",
      "epoch: 116 loss: 2.302610397338867 grad: 1.583882463896381\n",
      "epoch: 117 loss: 2.3026723861694336 grad: 1.5926038115045116\n",
      "epoch: 118 loss: 2.302590847015381 grad: 1.5902932588277119\n",
      "epoch: 119 loss: 2.302258014678955 grad: 1.5897517461507094\n",
      "epoch: 120 loss: 2.302574634552002 grad: 1.5846143663336065\n",
      "epoch: 121 loss: 2.3018860816955566 grad: 1.595920077003982\n",
      "epoch: 122 loss: 2.3022875785827637 grad: 1.592752046779626\n",
      "epoch: 123 loss: 2.3023648262023926 grad: 1.5766743699879577\n",
      "epoch: 124 loss: 2.302501916885376 grad: 1.5775343093407592\n",
      "epoch: 125 loss: 2.30260968208313 grad: 1.5847921307098918\n",
      "epoch: 126 loss: 2.302912712097168 grad: 1.5787264778822039\n",
      "epoch: 127 loss: 2.302884340286255 grad: 1.585512255117046\n",
      "epoch: 128 loss: 2.301785469055176 grad: 1.6015080787825384\n",
      "epoch: 129 loss: 2.3029637336730957 grad: 1.571510644651772\n",
      "epoch: 130 loss: 2.302212715148926 grad: 1.5835826608189751\n",
      "epoch: 131 loss: 2.30242919921875 grad: 1.5913667617779639\n",
      "epoch: 132 loss: 2.302351713180542 grad: 1.5831899252195385\n",
      "epoch: 133 loss: 2.302189826965332 grad: 1.5957750620667837\n",
      "epoch: 134 loss: 2.3021485805511475 grad: 1.5891852677348883\n",
      "epoch: 135 loss: 2.302130937576294 grad: 1.6060634915280851\n",
      "epoch: 136 loss: 2.302720785140991 grad: 1.5645517524228327\n",
      "epoch: 137 loss: 2.3023056983947754 grad: 1.5806161562158239\n",
      "epoch: 138 loss: 2.302234649658203 grad: 1.5776713633584598\n",
      "epoch: 139 loss: 2.3021628856658936 grad: 1.5892242916068802\n",
      "epoch: 140 loss: 2.3022172451019287 grad: 1.5792861561335267\n",
      "epoch: 141 loss: 2.3015334606170654 grad: 1.581372215305381\n",
      "epoch: 142 loss: 2.3016164302825928 grad: 1.5908707380183928\n",
      "epoch: 143 loss: 2.301726818084717 grad: 1.5885095515709726\n",
      "epoch: 144 loss: 2.301950216293335 grad: 1.5777123780710445\n",
      "epoch: 145 loss: 2.302506446838379 grad: 1.5787481790157183\n",
      "epoch: 146 loss: 2.3024158477783203 grad: 1.580656916285599\n",
      "epoch: 147 loss: 2.302375555038452 grad: 1.575783559932403\n",
      "epoch: 148 loss: 2.3018062114715576 grad: 1.5857561210388436\n",
      "epoch: 149 loss: 2.30222749710083 grad: 1.5880126288781564\n",
      "epoch: 150 loss: 2.302481174468994 grad: 1.5765586307989286\n",
      "epoch: 151 loss: 2.302088499069214 grad: 1.5802310470672738\n",
      "epoch: 152 loss: 2.302288770675659 grad: 1.5771112238566967\n",
      "epoch: 153 loss: 2.302358865737915 grad: 1.581494868677553\n",
      "epoch: 154 loss: 2.301690101623535 grad: 1.580219079786542\n",
      "epoch: 155 loss: 2.3019802570343018 grad: 1.5791865765793427\n",
      "epoch: 156 loss: 2.3020966053009033 grad: 1.5858685760906646\n",
      "epoch: 157 loss: 2.3022027015686035 grad: 1.58879008391569\n",
      "epoch: 158 loss: 2.3019659519195557 grad: 1.5833602539256275\n",
      "epoch: 159 loss: 2.301257610321045 grad: 1.5960722827585414\n",
      "epoch: 160 loss: 2.301443099975586 grad: 1.5977285245529538\n",
      "epoch: 161 loss: 2.302109479904175 grad: 1.5771412439237806\n",
      "epoch: 162 loss: 2.3016276359558105 grad: 1.5931822042376365\n",
      "epoch: 163 loss: 2.3017616271972656 grad: 1.5804087430005893\n",
      "epoch: 164 loss: 2.3012444972991943 grad: 1.5932546567249422\n",
      "epoch: 165 loss: 2.3012611865997314 grad: 1.5830127780883765\n",
      "epoch: 166 loss: 2.301708221435547 grad: 1.5862934084568499\n",
      "epoch: 167 loss: 2.301558017730713 grad: 1.5878104800136672\n",
      "epoch: 168 loss: 2.301710844039917 grad: 1.587144125550468\n",
      "epoch: 169 loss: 2.301361560821533 grad: 1.5834276374828602\n",
      "epoch: 170 loss: 2.3020355701446533 grad: 1.5797030536627898\n",
      "epoch: 171 loss: 2.3015778064727783 grad: 1.5880096684439138\n",
      "epoch: 172 loss: 2.302280902862549 grad: 1.5790229439661498\n",
      "epoch: 173 loss: 2.301820993423462 grad: 1.5942575619777752\n",
      "epoch: 174 loss: 2.30256724357605 grad: 1.5706459649335889\n",
      "epoch: 175 loss: 2.301297664642334 grad: 1.588756590749004\n",
      "epoch: 176 loss: 2.301954746246338 grad: 1.5809114608721482\n",
      "epoch: 177 loss: 2.301276206970215 grad: 1.5814912496356381\n",
      "epoch: 178 loss: 2.3016140460968018 grad: 1.5841073045314895\n",
      "epoch: 179 loss: 2.3017091751098633 grad: 1.5848297280839658\n",
      "epoch: 180 loss: 2.301786184310913 grad: 1.5842617326674775\n",
      "epoch: 181 loss: 2.3013956546783447 grad: 1.5921753087184496\n",
      "epoch: 182 loss: 2.301715850830078 grad: 1.5756131212951408\n",
      "epoch: 183 loss: 2.3018510341644287 grad: 1.5759179559739542\n",
      "epoch: 184 loss: 2.3018581867218018 grad: 1.5830519724570746\n",
      "epoch: 185 loss: 2.3013429641723633 grad: 1.5918077684362375\n",
      "epoch: 186 loss: 2.30159854888916 grad: 1.5814560973233291\n",
      "epoch: 187 loss: 2.3014936447143555 grad: 1.593508066311996\n",
      "epoch: 188 loss: 2.302036762237549 grad: 1.5798671789714949\n",
      "epoch: 189 loss: 2.301093578338623 grad: 1.5897725421587923\n",
      "epoch: 190 loss: 2.3012070655822754 grad: 1.582621109294927\n",
      "epoch: 191 loss: 2.301377773284912 grad: 1.5908944206570999\n",
      "epoch: 192 loss: 2.3018317222595215 grad: 1.5873575004202032\n",
      "epoch: 193 loss: 2.3016421794891357 grad: 1.5872145606323131\n",
      "epoch: 194 loss: 2.3019282817840576 grad: 1.5781480225601368\n",
      "epoch: 195 loss: 2.302053689956665 grad: 1.57474114522264\n",
      "epoch: 196 loss: 2.301243305206299 grad: 1.58921456096753\n",
      "epoch: 197 loss: 2.3019039630889893 grad: 1.564262819552188\n",
      "epoch: 198 loss: 2.3017334938049316 grad: 1.5691350678828293\n",
      "epoch: 199 loss: 2.3009777069091797 grad: 1.5773830627043184\n",
      "epoch: 200 loss: 2.3010504245758057 grad: 1.5843901413433727\n",
      "epoch: 201 loss: 2.301449775695801 grad: 1.5868197876501768\n",
      "epoch: 202 loss: 2.3014819622039795 grad: 1.5761678336679728\n",
      "epoch: 203 loss: 2.3008387088775635 grad: 1.5963437628677293\n",
      "epoch: 204 loss: 2.301330089569092 grad: 1.5891663365893893\n",
      "epoch: 205 loss: 2.3011035919189453 grad: 1.583854316726386\n",
      "epoch: 206 loss: 2.3009438514709473 grad: 1.5882062244465545\n",
      "epoch: 207 loss: 2.300859212875366 grad: 1.5882162819764325\n",
      "epoch: 208 loss: 2.3013622760772705 grad: 1.5850306682783875\n",
      "epoch: 209 loss: 2.300977945327759 grad: 1.5771421807973336\n",
      "epoch: 210 loss: 2.3015902042388916 grad: 1.5775134230498224\n",
      "epoch: 211 loss: 2.301503896713257 grad: 1.5877540610464556\n",
      "epoch: 212 loss: 2.300708293914795 grad: 1.5916087413927362\n",
      "epoch: 213 loss: 2.3016743659973145 grad: 1.5797509486594843\n",
      "epoch: 214 loss: 2.3011245727539062 grad: 1.5762849466354099\n",
      "epoch: 215 loss: 2.301542282104492 grad: 1.5800492512727422\n",
      "epoch: 216 loss: 2.301150321960449 grad: 1.587998799116735\n",
      "epoch: 217 loss: 2.3008599281311035 grad: 1.5937942987241382\n",
      "epoch: 218 loss: 2.3012351989746094 grad: 1.5918963115887776\n",
      "epoch: 219 loss: 2.3012657165527344 grad: 1.583040587212299\n",
      "epoch: 220 loss: 2.3014140129089355 grad: 1.5762211536851873\n",
      "epoch: 221 loss: 2.3011796474456787 grad: 1.5750111247087637\n",
      "epoch: 222 loss: 2.301527261734009 grad: 1.579179564764398\n",
      "epoch: 223 loss: 2.3010172843933105 grad: 1.5921192805389948\n",
      "epoch: 224 loss: 2.3015196323394775 grad: 1.5788229496683925\n",
      "epoch: 225 loss: 2.301816463470459 grad: 1.5620709282072587\n",
      "epoch: 226 loss: 2.3008856773376465 grad: 1.5889804334387123\n",
      "epoch: 227 loss: 2.3009352684020996 grad: 1.5816936867001157\n",
      "epoch: 228 loss: 2.301442861557007 grad: 1.5813082244509595\n",
      "epoch: 229 loss: 2.3011815547943115 grad: 1.5857767930128686\n",
      "epoch: 230 loss: 2.3009722232818604 grad: 1.5764918792272165\n",
      "epoch: 231 loss: 2.3013176918029785 grad: 1.57351737822746\n",
      "epoch: 232 loss: 2.3010475635528564 grad: 1.5872642305413527\n",
      "epoch: 233 loss: 2.301439046859741 grad: 1.5806637190371042\n",
      "epoch: 234 loss: 2.3012118339538574 grad: 1.5843673404564873\n",
      "epoch: 235 loss: 2.300523281097412 grad: 1.5929421591424635\n",
      "epoch: 236 loss: 2.3012237548828125 grad: 1.5818296323848209\n",
      "epoch: 237 loss: 2.3004636764526367 grad: 1.5864696484835197\n",
      "epoch: 238 loss: 2.3000314235687256 grad: 1.5986556798323162\n",
      "epoch: 239 loss: 2.3008601665496826 grad: 1.593245787126574\n",
      "epoch: 240 loss: 2.301116704940796 grad: 1.574846957193037\n",
      "epoch: 241 loss: 2.3004958629608154 grad: 1.5937234271772294\n",
      "epoch: 242 loss: 2.300748586654663 grad: 1.587874908131429\n",
      "epoch: 243 loss: 2.3002169132232666 grad: 1.583539069667163\n",
      "epoch: 244 loss: 2.3006248474121094 grad: 1.5822403102943172\n",
      "epoch: 245 loss: 2.300309181213379 grad: 1.5972100044064785\n",
      "epoch: 246 loss: 2.3001136779785156 grad: 1.5945637239815875\n",
      "epoch: 247 loss: 2.3002657890319824 grad: 1.5899050596044473\n",
      "epoch: 248 loss: 2.3003077507019043 grad: 1.590794805803203\n",
      "epoch: 249 loss: 2.300507068634033 grad: 1.5903057037272477\n",
      "epoch: 250 loss: 2.300346612930298 grad: 1.5963090950408803\n",
      "epoch: 251 loss: 2.300062894821167 grad: 1.6004520151061967\n",
      "epoch: 252 loss: 2.3003389835357666 grad: 1.5901520773121673\n",
      "epoch: 253 loss: 2.2997989654541016 grad: 1.592427724344094\n",
      "epoch: 254 loss: 2.3000478744506836 grad: 1.60054323292293\n",
      "epoch: 255 loss: 2.2998223304748535 grad: 1.6105521748226785\n",
      "epoch: 256 loss: 2.300179958343506 grad: 1.5990986370865905\n",
      "epoch: 257 loss: 2.2999653816223145 grad: 1.609874328760992\n",
      "epoch: 258 loss: 2.299577474594116 grad: 1.6069028957133433\n",
      "epoch: 259 loss: 2.3002641201019287 grad: 1.605266872257556\n",
      "epoch: 260 loss: 2.299854278564453 grad: 1.6056702501170101\n",
      "epoch: 261 loss: 2.299360990524292 grad: 1.6169472684647652\n",
      "epoch: 262 loss: 2.2996323108673096 grad: 1.6233453775963023\n",
      "epoch: 263 loss: 2.299856424331665 grad: 1.6065935174720214\n",
      "epoch: 264 loss: 2.3001718521118164 grad: 1.6108292897364922\n",
      "epoch: 265 loss: 2.2996742725372314 grad: 1.6097109366895719\n",
      "epoch: 266 loss: 2.29892897605896 grad: 1.6304242948905403\n",
      "epoch: 267 loss: 2.2998766899108887 grad: 1.6108578347586213\n",
      "epoch: 268 loss: 2.2996511459350586 grad: 1.6203721250307612\n",
      "epoch: 269 loss: 2.2991926670074463 grad: 1.6245364757025584\n",
      "epoch: 270 loss: 2.2995033264160156 grad: 1.6195167693908192\n",
      "epoch: 271 loss: 2.2990431785583496 grad: 1.631986719487782\n",
      "epoch: 272 loss: 2.2998108863830566 grad: 1.6111639767611725\n",
      "epoch: 273 loss: 2.299325704574585 grad: 1.6252960493300288\n",
      "epoch: 274 loss: 2.2990829944610596 grad: 1.6268651136566723\n",
      "epoch: 275 loss: 2.2996785640716553 grad: 1.6143658133186696\n",
      "epoch: 276 loss: 2.2992746829986572 grad: 1.635548306462754\n",
      "epoch: 277 loss: 2.2993342876434326 grad: 1.6327794168591647\n",
      "epoch: 278 loss: 2.2978577613830566 grad: 1.6485188002383986\n",
      "epoch: 279 loss: 2.29872465133667 grad: 1.6374397224336419\n",
      "epoch: 280 loss: 2.2988977432250977 grad: 1.6228701271623047\n",
      "epoch: 281 loss: 2.298793315887451 grad: 1.6439283277972467\n",
      "epoch: 282 loss: 2.2981789112091064 grad: 1.6571704676071743\n",
      "epoch: 283 loss: 2.2984180450439453 grad: 1.6373425548792713\n",
      "epoch: 284 loss: 2.2976090908050537 grad: 1.6659785245271725\n",
      "epoch: 285 loss: 2.298220634460449 grad: 1.6620793225953268\n",
      "epoch: 286 loss: 2.2979044914245605 grad: 1.6756484492234738\n",
      "epoch: 287 loss: 2.2977449893951416 grad: 1.6758909482704771\n",
      "epoch: 288 loss: 2.297224283218384 grad: 1.6931405775655535\n",
      "epoch: 289 loss: 2.2978806495666504 grad: 1.6844906125010715\n",
      "epoch: 290 loss: 2.2972044944763184 grad: 1.701443645655961\n",
      "epoch: 291 loss: 2.2976996898651123 grad: 1.7079679062054123\n",
      "epoch: 292 loss: 2.2972090244293213 grad: 1.7055717938956583\n",
      "epoch: 293 loss: 2.297062397003174 grad: 1.7121853138068839\n",
      "epoch: 294 loss: 2.2970991134643555 grad: 1.7250401176002232\n",
      "epoch: 295 loss: 2.296149492263794 grad: 1.7496605018183353\n",
      "epoch: 296 loss: 2.2959718704223633 grad: 1.7758172237469505\n",
      "epoch: 297 loss: 2.296288251876831 grad: 1.7693172686027423\n",
      "epoch: 298 loss: 2.2961535453796387 grad: 1.7684639366232746\n",
      "epoch: 299 loss: 2.295914888381958 grad: 1.7851100580190264\n",
      "epoch: 300 loss: 2.296107530593872 grad: 1.7958216059006868\n",
      "epoch: 301 loss: 2.2951183319091797 grad: 1.8200116801881305\n",
      "epoch: 302 loss: 2.2959675788879395 grad: 1.8192617200085863\n",
      "epoch: 303 loss: 2.294769763946533 grad: 1.824878170476517\n",
      "epoch: 304 loss: 2.2950708866119385 grad: 1.8683865460648483\n",
      "epoch: 305 loss: 2.2936007976531982 grad: 1.9047807560464929\n",
      "epoch: 306 loss: 2.2942895889282227 grad: 1.9154099847434\n",
      "epoch: 307 loss: 2.2923803329467773 grad: 1.9720496593952357\n",
      "epoch: 308 loss: 2.292888641357422 grad: 1.9636075454431452\n",
      "epoch: 309 loss: 2.2929797172546387 grad: 2.024208286451915\n",
      "epoch: 310 loss: 2.2924845218658447 grad: 2.044076834790527\n",
      "epoch: 311 loss: 2.2909505367279053 grad: 2.068149208482946\n",
      "epoch: 312 loss: 2.289005994796753 grad: 2.1284589736633714\n",
      "epoch: 313 loss: 2.2891507148742676 grad: 2.169247962530732\n",
      "epoch: 314 loss: 2.2885630130767822 grad: 2.204737674659266\n",
      "epoch: 315 loss: 2.2852394580841064 grad: 2.3051330154236878\n",
      "epoch: 316 loss: 2.2859928607940674 grad: 2.292247826946781\n",
      "epoch: 317 loss: 2.2839791774749756 grad: 2.34635906211204\n",
      "epoch: 318 loss: 2.2827937602996826 grad: 2.4121454302147622\n",
      "epoch: 319 loss: 2.281730890274048 grad: 2.421883945005931\n",
      "epoch: 320 loss: 2.27949857711792 grad: 2.4727018029828156\n",
      "epoch: 321 loss: 2.2767791748046875 grad: 2.532830922121537\n",
      "epoch: 322 loss: 2.2767786979675293 grad: 2.5775187758558857\n",
      "epoch: 323 loss: 2.272563934326172 grad: 2.570091314772735\n",
      "epoch: 324 loss: 2.2695181369781494 grad: 2.481259543374772\n",
      "epoch: 325 loss: 2.2688536643981934 grad: 2.4781955274465006\n",
      "epoch: 326 loss: 2.265918016433716 grad: 2.45365174891915\n",
      "epoch: 327 loss: 2.2652339935302734 grad: 2.497436981954952\n",
      "epoch: 328 loss: 2.264072895050049 grad: 2.4414403021542563\n",
      "epoch: 329 loss: 2.260166883468628 grad: 2.3980185641641065\n",
      "epoch: 330 loss: 2.259614944458008 grad: 2.404032434351624\n",
      "epoch: 331 loss: 2.258711338043213 grad: 2.381566480338012\n",
      "epoch: 332 loss: 2.2544538974761963 grad: 2.262317853022574\n",
      "epoch: 333 loss: 2.2540109157562256 grad: 2.2408949381908374\n",
      "epoch: 334 loss: 2.254290819168091 grad: 2.2666557210031897\n",
      "epoch: 335 loss: 2.254544973373413 grad: 2.242352544899202\n",
      "epoch: 336 loss: 2.2517149448394775 grad: 2.1564952992050657\n",
      "epoch: 337 loss: 2.2506051063537598 grad: 2.1466155804154123\n",
      "epoch: 338 loss: 2.2511253356933594 grad: 2.0844138207409295\n",
      "epoch: 339 loss: 2.248427152633667 grad: 2.0741070539187936\n",
      "epoch: 340 loss: 2.2481634616851807 grad: 2.133301917517129\n",
      "epoch: 341 loss: 2.2468690872192383 grad: 1.9990328422097106\n",
      "epoch: 342 loss: 2.247377634048462 grad: 2.1116544494316694\n",
      "epoch: 343 loss: 2.246915340423584 grad: 2.031051460150925\n",
      "epoch: 344 loss: 2.2451179027557373 grad: 1.9715962966660125\n",
      "epoch: 345 loss: 2.243971347808838 grad: 1.9789860158168253\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 346 loss: 2.242856502532959 grad: 1.8988884397143024\n",
      "epoch: 347 loss: 2.243131399154663 grad: 1.8981186159043795\n",
      "epoch: 348 loss: 2.2418887615203857 grad: 1.8692985593363465\n",
      "epoch: 349 loss: 2.242844820022583 grad: 1.8903939234617624\n",
      "epoch: 350 loss: 2.24222469329834 grad: 1.936745691582531\n",
      "epoch: 351 loss: 2.239478826522827 grad: 1.832450107970674\n",
      "epoch: 352 loss: 2.240593194961548 grad: 1.8905518025913763\n",
      "epoch: 353 loss: 2.2392306327819824 grad: 1.803659125048268\n",
      "epoch: 354 loss: 2.238477945327759 grad: 1.8503822105666918\n",
      "epoch: 355 loss: 2.23830246925354 grad: 1.8353179324684399\n",
      "epoch: 356 loss: 2.2382125854492188 grad: 1.845394285521396\n",
      "epoch: 357 loss: 2.2378430366516113 grad: 1.7685107431958416\n",
      "epoch: 358 loss: 2.2371621131896973 grad: 1.7937033355073442\n",
      "epoch: 359 loss: 2.2356138229370117 grad: 1.7774270312151028\n",
      "epoch: 360 loss: 2.23606014251709 grad: 1.7801425472744519\n",
      "epoch: 361 loss: 2.236351490020752 grad: 1.8086242572116178\n",
      "epoch: 362 loss: 2.2342660427093506 grad: 1.7589051361520966\n",
      "epoch: 363 loss: 2.233168363571167 grad: 1.6762851703956367\n",
      "epoch: 364 loss: 2.2328217029571533 grad: 1.7507297340115267\n",
      "epoch: 365 loss: 2.2351267337799072 grad: 1.8235298948425298\n",
      "epoch: 366 loss: 2.2333884239196777 grad: 1.7513404438819087\n",
      "epoch: 367 loss: 2.2322793006896973 grad: 1.666455474016922\n",
      "epoch: 368 loss: 2.234334945678711 grad: 1.7296612184764522\n",
      "epoch: 369 loss: 2.2323899269104004 grad: 1.7475465161796098\n",
      "epoch: 370 loss: 2.2315385341644287 grad: 1.6993499836341168\n",
      "epoch: 371 loss: 2.2341866493225098 grad: 1.811524138822856\n",
      "epoch: 372 loss: 2.232029914855957 grad: 1.769683518890469\n",
      "epoch: 373 loss: 2.231502056121826 grad: 1.7537975643377102\n",
      "epoch: 374 loss: 2.231426954269409 grad: 1.7209707050610126\n",
      "epoch: 375 loss: 2.2300209999084473 grad: 1.6565799413060414\n",
      "epoch: 376 loss: 2.229891777038574 grad: 1.6671870963514916\n",
      "epoch: 377 loss: 2.2299630641937256 grad: 1.7475304500281161\n",
      "epoch: 378 loss: 2.230189085006714 grad: 1.725602738666422\n",
      "epoch: 379 loss: 2.2299280166625977 grad: 1.7191150266425832\n",
      "epoch: 380 loss: 2.228414297103882 grad: 1.6485551062099162\n",
      "epoch: 381 loss: 2.2294998168945312 grad: 1.7358508649880864\n",
      "epoch: 382 loss: 2.22807240486145 grad: 1.6715292452357797\n",
      "epoch: 383 loss: 2.228520154953003 grad: 1.691081259471719\n",
      "epoch: 384 loss: 2.22666335105896 grad: 1.6642830083627136\n",
      "epoch: 385 loss: 2.2268567085266113 grad: 1.7225363969300238\n",
      "epoch: 386 loss: 2.2273077964782715 grad: 1.634927679477851\n",
      "epoch: 387 loss: 2.2267091274261475 grad: 1.6893923143349914\n",
      "epoch: 388 loss: 2.2270002365112305 grad: 1.7723909867613294\n",
      "epoch: 389 loss: 2.226862907409668 grad: 1.6984525732067783\n",
      "epoch: 390 loss: 2.226205587387085 grad: 1.7040135842888424\n",
      "epoch: 391 loss: 2.2262837886810303 grad: 1.6576765450290478\n",
      "epoch: 392 loss: 2.226280927658081 grad: 1.7336293329643677\n",
      "epoch: 393 loss: 2.2242372035980225 grad: 1.586975656970892\n",
      "epoch: 394 loss: 2.2251620292663574 grad: 1.6865806444658942\n",
      "epoch: 395 loss: 2.2253947257995605 grad: 1.7208598506108428\n",
      "epoch: 396 loss: 2.226154327392578 grad: 1.7411332823472867\n",
      "epoch: 397 loss: 2.2240610122680664 grad: 1.7223031468308783\n",
      "epoch: 398 loss: 2.223430871963501 grad: 1.721940068504034\n",
      "epoch: 399 loss: 2.2226271629333496 grad: 1.7009043301241324\n",
      "epoch: 400 loss: 2.222404956817627 grad: 1.737049611362939\n",
      "epoch: 401 loss: 2.2228331565856934 grad: 1.7362599201123452\n",
      "epoch: 402 loss: 2.223121166229248 grad: 1.7743899932718792\n",
      "epoch: 403 loss: 2.223674774169922 grad: 1.828612787708167\n",
      "epoch: 404 loss: 2.2222518920898438 grad: 1.7138410431133317\n",
      "epoch: 405 loss: 2.220759630203247 grad: 1.635270413528714\n",
      "epoch: 406 loss: 2.2224173545837402 grad: 1.760677890216429\n",
      "epoch: 407 loss: 2.2217061519622803 grad: 1.749487905182861\n",
      "epoch: 408 loss: 2.2204978466033936 grad: 1.6920873500584137\n",
      "epoch: 409 loss: 2.221275806427002 grad: 1.7728272044517484\n",
      "epoch: 410 loss: 2.218738317489624 grad: 1.6739087087760074\n",
      "epoch: 411 loss: 2.219571352005005 grad: 1.7769114105345032\n",
      "epoch: 412 loss: 2.2201077938079834 grad: 1.7794167914904566\n",
      "epoch: 413 loss: 2.2175042629241943 grad: 1.6804217738339617\n",
      "epoch: 414 loss: 2.2197868824005127 grad: 1.7819979808437416\n",
      "epoch: 415 loss: 2.2182908058166504 grad: 1.7444797971670234\n",
      "epoch: 416 loss: 2.218435049057007 grad: 1.741061497350327\n",
      "epoch: 417 loss: 2.218491792678833 grad: 1.7816717072042623\n",
      "epoch: 418 loss: 2.21779465675354 grad: 1.8169014213388668\n",
      "epoch: 419 loss: 2.2175023555755615 grad: 1.814901482119846\n",
      "epoch: 420 loss: 2.2173550128936768 grad: 1.9230800743218481\n",
      "epoch: 421 loss: 2.2165191173553467 grad: 1.8517155586612515\n",
      "epoch: 422 loss: 2.2171480655670166 grad: 1.8565698150039045\n",
      "epoch: 423 loss: 2.2172129154205322 grad: 1.9097511209602955\n",
      "epoch: 424 loss: 2.2180936336517334 grad: 1.9230344297811537\n",
      "epoch: 425 loss: 2.2165300846099854 grad: 1.9099603740790385\n",
      "epoch: 426 loss: 2.2178702354431152 grad: 1.9171263783013388\n",
      "epoch: 427 loss: 2.214421033859253 grad: 1.9108904894027445\n",
      "epoch: 428 loss: 2.214909315109253 grad: 1.9157870868387232\n",
      "epoch: 429 loss: 2.214423179626465 grad: 1.886383175923829\n",
      "epoch: 430 loss: 2.215515613555908 grad: 1.9861532349087712\n",
      "epoch: 431 loss: 2.213991641998291 grad: 1.9860096370158273\n",
      "epoch: 432 loss: 2.212564468383789 grad: 1.9482272735368165\n",
      "epoch: 433 loss: 2.212942600250244 grad: 1.9854191606476281\n",
      "epoch: 434 loss: 2.212183952331543 grad: 1.9940532764516001\n",
      "epoch: 435 loss: 2.212338447570801 grad: 1.9156749441476895\n",
      "epoch: 436 loss: 2.2130227088928223 grad: 1.9686176452715511\n",
      "epoch: 437 loss: 2.211508274078369 grad: 2.089892191823483\n",
      "epoch: 438 loss: 2.212646722793579 grad: 1.956469702637858\n",
      "epoch: 439 loss: 2.2119648456573486 grad: 2.0248542830665848\n",
      "epoch: 440 loss: 2.2098779678344727 grad: 2.051382590850283\n",
      "epoch: 441 loss: 2.210598945617676 grad: 2.0535571436002287\n",
      "epoch: 442 loss: 2.209965944290161 grad: 2.0156867111837196\n",
      "epoch: 443 loss: 2.2095634937286377 grad: 2.034699851275599\n",
      "epoch: 444 loss: 2.210714817047119 grad: 2.1175324243349243\n",
      "epoch: 445 loss: 2.206868886947632 grad: 2.0582137746340963\n",
      "epoch: 446 loss: 2.2071163654327393 grad: 2.0470968548445003\n",
      "epoch: 447 loss: 2.2088255882263184 grad: 2.187592511669555\n",
      "epoch: 448 loss: 2.2075283527374268 grad: 2.08854618561565\n",
      "epoch: 449 loss: 2.2072763442993164 grad: 2.131735196263189\n",
      "epoch: 450 loss: 2.2058496475219727 grad: 2.1524327757180712\n",
      "epoch: 451 loss: 2.206429958343506 grad: 2.1671199181767564\n",
      "epoch: 452 loss: 2.2093966007232666 grad: 2.2503903525574724\n",
      "epoch: 453 loss: 2.2037596702575684 grad: 2.1614440340541363\n",
      "epoch: 454 loss: 2.2029707431793213 grad: 2.1576338743842722\n",
      "epoch: 455 loss: 2.2040765285491943 grad: 2.194673061295087\n",
      "epoch: 456 loss: 2.203273057937622 grad: 2.1930852600314195\n",
      "epoch: 457 loss: 2.20394229888916 grad: 2.2155453998092858\n",
      "epoch: 458 loss: 2.2028090953826904 grad: 2.303056673431355\n",
      "epoch: 459 loss: 2.2011327743530273 grad: 2.197590290278655\n",
      "epoch: 460 loss: 2.202094793319702 grad: 2.2792329786323187\n",
      "epoch: 461 loss: 2.2016239166259766 grad: 2.2276268774691586\n",
      "epoch: 462 loss: 2.1997499465942383 grad: 2.2536113182219513\n",
      "epoch: 463 loss: 2.200665235519409 grad: 2.160610528551929\n",
      "epoch: 464 loss: 2.199280261993408 grad: 2.2268206378785034\n",
      "epoch: 465 loss: 2.1994810104370117 grad: 2.2292974225858906\n",
      "epoch: 466 loss: 2.198021411895752 grad: 2.2520588588760426\n",
      "epoch: 467 loss: 2.199037551879883 grad: 2.2708266013013643\n",
      "epoch: 468 loss: 2.19716215133667 grad: 2.20256571838307\n",
      "epoch: 469 loss: 2.1971871852874756 grad: 2.269133093072072\n",
      "epoch: 470 loss: 2.196927785873413 grad: 2.2019252988143956\n",
      "epoch: 471 loss: 2.1975598335266113 grad: 2.3196487107724395\n",
      "epoch: 472 loss: 2.1954376697540283 grad: 2.151674621971324\n",
      "epoch: 473 loss: 2.1952908039093018 grad: 2.1847967516782414\n",
      "epoch: 474 loss: 2.1949164867401123 grad: 2.1655135023876997\n",
      "epoch: 475 loss: 2.1953799724578857 grad: 2.152651897409842\n",
      "epoch: 476 loss: 2.1953506469726562 grad: 2.2649517982222496\n",
      "epoch: 477 loss: 2.1941018104553223 grad: 2.212867548125648\n",
      "epoch: 478 loss: 2.193253517150879 grad: 2.408249341032749\n",
      "epoch: 479 loss: 2.1933093070983887 grad: 2.305255774179444\n",
      "epoch: 480 loss: 2.1936142444610596 grad: 2.2636834017060226\n",
      "epoch: 481 loss: 2.192929267883301 grad: 2.2941409198970106\n",
      "epoch: 482 loss: 2.1914656162261963 grad: 2.204757162643271\n",
      "epoch: 483 loss: 2.191746473312378 grad: 2.285545998326843\n",
      "epoch: 484 loss: 2.190504312515259 grad: 2.256050492173046\n",
      "epoch: 485 loss: 2.1909093856811523 grad: 2.2315401838157354\n",
      "epoch: 486 loss: 2.1914448738098145 grad: 2.223806762095866\n",
      "epoch: 487 loss: 2.189129590988159 grad: 2.2012758389935785\n",
      "epoch: 488 loss: 2.1890358924865723 grad: 2.216614520071917\n",
      "epoch: 489 loss: 2.1854660511016846 grad: 2.2225082384585035\n",
      "epoch: 490 loss: 2.189986228942871 grad: 2.199511686733569\n",
      "epoch: 491 loss: 2.188931703567505 grad: 2.222871599763277\n",
      "epoch: 492 loss: 2.1879494190216064 grad: 2.2502517044000947\n",
      "epoch: 493 loss: 2.187553644180298 grad: 2.35068847471109\n",
      "epoch: 494 loss: 2.1877620220184326 grad: 2.2298477909801204\n",
      "epoch: 495 loss: 2.186917543411255 grad: 2.314687489494977\n",
      "epoch: 496 loss: 2.187417984008789 grad: 2.265506009885391\n",
      "epoch: 497 loss: 2.1872806549072266 grad: 2.1976271296134366\n",
      "epoch: 498 loss: 2.1855571269989014 grad: 2.1854276900024465\n",
      "epoch: 499 loss: 2.1867637634277344 grad: 2.310002180917691\n",
      "2.229303926229477\n",
      "epoch: 0 loss: 2.3034234046936035 grad: 1.3553724520939536\n",
      "epoch: 1 loss: 2.3026063442230225 grad: 1.328068979417107\n",
      "epoch: 2 loss: 2.301021099090576 grad: 1.354486099144976\n",
      "epoch: 3 loss: 2.2971019744873047 grad: 1.4578093356038961\n",
      "epoch: 4 loss: 2.2906932830810547 grad: 1.66362190649416\n",
      "epoch: 5 loss: 2.2821285724639893 grad: 1.8456397879562\n",
      "epoch: 6 loss: 2.2729523181915283 grad: 2.074502151550001\n",
      "epoch: 7 loss: 2.266989231109619 grad: 2.2068587652673677\n",
      "epoch: 8 loss: 2.2555229663848877 grad: 2.3847761721098943\n",
      "epoch: 9 loss: 2.2515413761138916 grad: 2.541489390778311\n",
      "epoch: 10 loss: 2.2508389949798584 grad: 2.690083919226059\n",
      "epoch: 11 loss: 2.2398476600646973 grad: 2.8159773670347583\n",
      "epoch: 12 loss: 2.2364747524261475 grad: 3.0006246180624685\n",
      "epoch: 13 loss: 2.233520746231079 grad: 3.1561601596222895\n",
      "epoch: 14 loss: 2.225816249847412 grad: 3.3889267841050965\n",
      "epoch: 15 loss: 2.2211971282958984 grad: 3.372963470037258\n",
      "epoch: 16 loss: 2.218111515045166 grad: 3.630802243378841\n",
      "epoch: 17 loss: 2.218212366104126 grad: 3.4601559468604153\n",
      "epoch: 18 loss: 2.214620590209961 grad: 3.8412788174787744\n",
      "epoch: 19 loss: 2.208685874938965 grad: 3.637064010067473\n",
      "epoch: 20 loss: 2.204686164855957 grad: 3.899370751036922\n",
      "epoch: 21 loss: 2.2012362480163574 grad: 3.8649575262153077\n",
      "epoch: 22 loss: 2.194026231765747 grad: 3.718935653245786\n",
      "epoch: 23 loss: 2.190167188644409 grad: 4.007944131617449\n",
      "epoch: 24 loss: 2.1800479888916016 grad: 4.4451563977119\n",
      "epoch: 25 loss: 2.165414571762085 grad: 4.222655256064461\n",
      "epoch: 26 loss: 2.158486843109131 grad: 4.0908869835141575\n",
      "epoch: 27 loss: 2.1580278873443604 grad: 3.9977985093192685\n",
      "epoch: 28 loss: 2.1520392894744873 grad: 4.044044511950767\n",
      "epoch: 29 loss: 2.145932197570801 grad: 4.393070654304225\n",
      "epoch: 30 loss: 2.141287088394165 grad: 3.898246886814752\n",
      "epoch: 31 loss: 2.1360299587249756 grad: 3.852294753224308\n",
      "epoch: 32 loss: 2.1342616081237793 grad: 4.276639331638488\n",
      "epoch: 33 loss: 2.131610870361328 grad: 4.316894937162509\n",
      "epoch: 34 loss: 2.128349542617798 grad: 4.171810965338308\n",
      "epoch: 35 loss: 2.128183603286743 grad: 4.284255701364831\n",
      "epoch: 36 loss: 2.1224448680877686 grad: 4.4107681061880335\n",
      "epoch: 37 loss: 2.1197919845581055 grad: 4.42544294439537\n",
      "epoch: 38 loss: 2.1211183071136475 grad: 4.388903483700392\n",
      "epoch: 39 loss: 2.1160786151885986 grad: 4.3573211803662755\n",
      "epoch: 40 loss: 2.112316846847534 grad: 4.361511424424068\n",
      "epoch: 41 loss: 2.112424612045288 grad: 4.51743853063367\n",
      "epoch: 42 loss: 2.106678009033203 grad: 4.42850685201674\n",
      "epoch: 43 loss: 2.1118950843811035 grad: 4.776754945036142\n",
      "epoch: 44 loss: 2.1043455600738525 grad: 4.938428629914092\n",
      "epoch: 45 loss: 2.1069743633270264 grad: 4.813649594635954\n",
      "epoch: 46 loss: 2.1001908779144287 grad: 4.801971945309242\n",
      "epoch: 47 loss: 2.0989537239074707 grad: 4.6870453344613665\n",
      "epoch: 48 loss: 2.095957040786743 grad: 4.843329391449631\n",
      "epoch: 49 loss: 2.0969555377960205 grad: 5.110912741228406\n",
      "epoch: 50 loss: 2.093966245651245 grad: 5.089420834541439\n",
      "epoch: 51 loss: 2.0925984382629395 grad: 5.243219179027374\n",
      "epoch: 52 loss: 2.084876775741577 grad: 5.502350109237586\n",
      "epoch: 53 loss: 2.085057258605957 grad: 5.465386315433693\n",
      "epoch: 54 loss: 2.085594415664673 grad: 5.295046989236855\n",
      "epoch: 55 loss: 2.0802714824676514 grad: 5.113801351467532\n",
      "epoch: 56 loss: 2.0812249183654785 grad: 5.567258442434231\n",
      "epoch: 57 loss: 2.0780885219573975 grad: 5.2573256635713195\n",
      "epoch: 58 loss: 2.078953981399536 grad: 5.887979804020789\n",
      "epoch: 59 loss: 2.072861671447754 grad: 5.712165134064557\n",
      "epoch: 60 loss: 2.0677125453948975 grad: 6.161656360274979\n",
      "epoch: 61 loss: 2.0770890712738037 grad: 5.602445734605666\n",
      "epoch: 62 loss: 2.062934398651123 grad: 5.860370214769824\n",
      "epoch: 63 loss: 2.0638461112976074 grad: 6.060610706104883\n",
      "epoch: 64 loss: 2.0606014728546143 grad: 5.821821792361637\n",
      "epoch: 65 loss: 2.0625295639038086 grad: 6.401663583185938\n",
      "epoch: 66 loss: 2.060823917388916 grad: 6.349543161719801\n",
      "epoch: 67 loss: 2.059810161590576 grad: 6.754080184129259\n",
      "epoch: 68 loss: 2.058647632598877 grad: 6.3213947125680985\n",
      "epoch: 69 loss: 2.0606863498687744 grad: 6.649092258301578\n",
      "epoch: 70 loss: 2.0564684867858887 grad: 6.518509425873321\n",
      "epoch: 71 loss: 2.0524845123291016 grad: 6.40331244366687\n",
      "epoch: 72 loss: 2.0480892658233643 grad: 6.16846563682581\n",
      "epoch: 73 loss: 2.0429184436798096 grad: 6.288714819617333\n",
      "epoch: 74 loss: 2.047553062438965 grad: 6.576792253720914\n",
      "epoch: 75 loss: 2.0464768409729004 grad: 6.666041034672942\n",
      "epoch: 76 loss: 2.045413017272949 grad: 6.846807988264436\n",
      "epoch: 77 loss: 2.0363245010375977 grad: 6.514282709593693\n",
      "epoch: 78 loss: 2.0423901081085205 grad: 6.538837818680183\n",
      "epoch: 79 loss: 2.0340631008148193 grad: 6.352107373044072\n",
      "epoch: 80 loss: 2.040933132171631 grad: 6.728316277553815\n",
      "epoch: 81 loss: 2.0314035415649414 grad: 6.5619211725166275\n",
      "epoch: 82 loss: 2.031172275543213 grad: 6.0142609742544\n",
      "epoch: 83 loss: 2.031050205230713 grad: 6.222473300136034\n",
      "epoch: 84 loss: 2.0222830772399902 grad: 6.556502610518937\n",
      "epoch: 85 loss: 2.0291452407836914 grad: 6.783361107739251\n",
      "epoch: 86 loss: 2.022202730178833 grad: 6.523752749742319\n",
      "epoch: 87 loss: 2.0250911712646484 grad: 6.77203625641645\n",
      "epoch: 88 loss: 2.0205626487731934 grad: 6.395246459511182\n",
      "epoch: 89 loss: 2.02188777923584 grad: 6.990818675252653\n",
      "epoch: 90 loss: 2.0211782455444336 grad: 6.516854724048504\n",
      "epoch: 91 loss: 2.0173168182373047 grad: 6.654465895286569\n",
      "epoch: 92 loss: 2.02089786529541 grad: 6.37359961579066\n",
      "epoch: 93 loss: 2.0179967880249023 grad: 6.411647356987473\n",
      "epoch: 94 loss: 2.017237424850464 grad: 6.662141717430796\n",
      "epoch: 95 loss: 2.0095274448394775 grad: 5.919970793509116\n",
      "epoch: 96 loss: 2.010124683380127 grad: 6.404403244840011\n",
      "epoch: 97 loss: 2.0148377418518066 grad: 6.993049280666229\n",
      "epoch: 98 loss: 2.0076942443847656 grad: 6.5503205994203215\n",
      "epoch: 99 loss: 2.008814573287964 grad: 6.952469351974922\n",
      "epoch: 100 loss: 2.007133960723877 grad: 6.97283421279419\n",
      "epoch: 101 loss: 2.0077149868011475 grad: 6.697743202337906\n",
      "epoch: 102 loss: 2.005967855453491 grad: 6.502633440456102\n",
      "epoch: 103 loss: 2.0044379234313965 grad: 6.39938271459606\n",
      "epoch: 104 loss: 2.003979444503784 grad: 6.827717636364498\n",
      "epoch: 105 loss: 2.002387762069702 grad: 6.238031950757085\n",
      "epoch: 106 loss: 1.9998379945755005 grad: 7.070875020439012\n",
      "epoch: 107 loss: 1.9975274801254272 grad: 6.5560373079903895\n",
      "epoch: 108 loss: 1.9944465160369873 grad: 6.835937393348782\n",
      "epoch: 109 loss: 1.9954586029052734 grad: 6.5983303478652875\n",
      "epoch: 110 loss: 1.9932076930999756 grad: 6.730298980205719\n",
      "epoch: 111 loss: 1.9873135089874268 grad: 7.281131265359739\n",
      "epoch: 112 loss: 1.9895075559616089 grad: 7.211704507706657\n",
      "epoch: 113 loss: 1.9871793985366821 grad: 6.714741177620396\n",
      "epoch: 114 loss: 1.983889102935791 grad: 6.9556039233603295\n",
      "epoch: 115 loss: 1.9905933141708374 grad: 7.331071840747009\n",
      "epoch: 116 loss: 1.9825924634933472 grad: 7.299182297824513\n",
      "epoch: 117 loss: 1.9811569452285767 grad: 7.055145180739817\n",
      "epoch: 118 loss: 1.9780350923538208 grad: 7.152831537397726\n",
      "epoch: 119 loss: 1.9756646156311035 grad: 7.215448203659247\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 120 loss: 1.9740849733352661 grad: 6.883413162496355\n",
      "epoch: 121 loss: 1.9739288091659546 grad: 7.2446212032662025\n",
      "epoch: 122 loss: 1.9770711660385132 grad: 7.532549057288894\n",
      "epoch: 123 loss: 1.9799548387527466 grad: 7.624834679865411\n",
      "epoch: 124 loss: 1.9754170179367065 grad: 7.692575943988881\n",
      "epoch: 125 loss: 1.972841501235962 grad: 7.30644813410583\n",
      "epoch: 126 loss: 1.9721640348434448 grad: 7.218748716327052\n",
      "epoch: 127 loss: 1.9606295824050903 grad: 7.305507719694149\n",
      "epoch: 128 loss: 1.9695594310760498 grad: 7.565867537706499\n",
      "epoch: 129 loss: 1.9613298177719116 grad: 7.727003323372513\n",
      "epoch: 130 loss: 1.9558029174804688 grad: 8.204251011759634\n",
      "epoch: 131 loss: 1.9562262296676636 grad: 7.7832228813083875\n",
      "epoch: 132 loss: 1.961621642112732 grad: 8.327464905050066\n",
      "epoch: 133 loss: 1.9588145017623901 grad: 8.105819639579822\n",
      "epoch: 134 loss: 1.9563508033752441 grad: 8.02832518915631\n",
      "epoch: 135 loss: 1.9539927244186401 grad: 8.027765622776416\n",
      "epoch: 136 loss: 1.9493573904037476 grad: 8.261438177181555\n",
      "epoch: 137 loss: 1.9526004791259766 grad: 8.07204095846308\n",
      "epoch: 138 loss: 1.9470001459121704 grad: 8.532864482275077\n",
      "epoch: 139 loss: 1.9509105682373047 grad: 8.126569247257615\n",
      "epoch: 140 loss: 1.9453506469726562 grad: 8.350013994582234\n",
      "epoch: 141 loss: 1.9437285661697388 grad: 8.280896634602595\n",
      "epoch: 142 loss: 1.9418003559112549 grad: 9.002728695315975\n",
      "epoch: 143 loss: 1.940212607383728 grad: 8.889031076907283\n",
      "epoch: 144 loss: 1.9391674995422363 grad: 8.52969303600017\n",
      "epoch: 145 loss: 1.9395254850387573 grad: 8.878690529052937\n",
      "epoch: 146 loss: 1.9339027404785156 grad: 9.191432980524878\n",
      "epoch: 147 loss: 1.9320474863052368 grad: 8.770456211523168\n",
      "epoch: 148 loss: 1.9297093152999878 grad: 8.868065742494922\n",
      "epoch: 149 loss: 1.9292492866516113 grad: 8.84843822987011\n",
      "epoch: 150 loss: 1.929599404335022 grad: 8.971202177793852\n",
      "epoch: 151 loss: 1.9307271242141724 grad: 8.611551707640054\n",
      "epoch: 152 loss: 1.9199141263961792 grad: 8.773854142173178\n",
      "epoch: 153 loss: 1.920933485031128 grad: 9.194077228964677\n",
      "epoch: 154 loss: 1.9242503643035889 grad: 9.040476167766702\n",
      "epoch: 155 loss: 1.917656421661377 grad: 8.906591119008167\n",
      "epoch: 156 loss: 1.9132672548294067 grad: 9.8609514480368\n",
      "epoch: 157 loss: 1.9116166830062866 grad: 9.365396241317429\n",
      "epoch: 158 loss: 1.9109019041061401 grad: 9.287545093453474\n",
      "epoch: 159 loss: 1.9106076955795288 grad: 9.236455940611897\n",
      "epoch: 160 loss: 1.9015493392944336 grad: 9.422307760868636\n",
      "epoch: 161 loss: 1.919177770614624 grad: 9.345780697429465\n",
      "epoch: 162 loss: 1.9094395637512207 grad: 9.93854394989709\n",
      "epoch: 163 loss: 1.9122086763381958 grad: 9.973615409333318\n",
      "epoch: 164 loss: 1.9028509855270386 grad: 9.29774983870309\n",
      "epoch: 165 loss: 1.8966022729873657 grad: 9.453566900631856\n",
      "epoch: 166 loss: 1.9009122848510742 grad: 10.231312329526103\n",
      "epoch: 167 loss: 1.9028452634811401 grad: 9.938529854684713\n",
      "epoch: 168 loss: 1.9043701887130737 grad: 9.451572127181977\n",
      "epoch: 169 loss: 1.8957065343856812 grad: 9.80764607505666\n",
      "epoch: 170 loss: 1.8908271789550781 grad: 10.162984562756877\n",
      "epoch: 171 loss: 1.8863874673843384 grad: 10.236269740905199\n",
      "epoch: 172 loss: 1.8894920349121094 grad: 9.64990980327425\n",
      "epoch: 173 loss: 1.8916921615600586 grad: 9.744939346635153\n",
      "epoch: 174 loss: 1.894575595855713 grad: 9.869145907979044\n",
      "epoch: 175 loss: 1.8850637674331665 grad: 10.03644966458281\n",
      "epoch: 176 loss: 1.8906896114349365 grad: 10.035554627222675\n",
      "epoch: 177 loss: 1.883385181427002 grad: 10.353289908138178\n",
      "epoch: 178 loss: 1.8870196342468262 grad: 10.074953730218112\n",
      "epoch: 179 loss: 1.8803454637527466 grad: 10.225485394827075\n",
      "epoch: 180 loss: 1.8822661638259888 grad: 10.251056965203984\n",
      "epoch: 181 loss: 1.8782625198364258 grad: 9.891714585368478\n",
      "epoch: 182 loss: 1.8752920627593994 grad: 10.69290982114358\n",
      "epoch: 183 loss: 1.872252106666565 grad: 10.522151128625469\n",
      "epoch: 184 loss: 1.8796069622039795 grad: 10.6792493311777\n",
      "epoch: 185 loss: 1.8688955307006836 grad: 10.275035671461078\n",
      "epoch: 186 loss: 1.8765439987182617 grad: 10.761103705754357\n",
      "epoch: 187 loss: 1.865868330001831 grad: 10.538517160296795\n",
      "epoch: 188 loss: 1.8884960412979126 grad: 10.536250221380403\n",
      "epoch: 189 loss: 1.8728106021881104 grad: 10.778020409601075\n",
      "epoch: 190 loss: 1.877333164215088 grad: 10.70209546985903\n",
      "epoch: 191 loss: 1.8650410175323486 grad: 10.216442963167552\n",
      "epoch: 192 loss: 1.8635523319244385 grad: 10.798344236857716\n",
      "epoch: 193 loss: 1.8709255456924438 grad: 11.067129160055803\n",
      "epoch: 194 loss: 1.8702888488769531 grad: 10.986919426344453\n",
      "epoch: 195 loss: 1.862554907798767 grad: 10.638211429059979\n",
      "epoch: 196 loss: 1.8596065044403076 grad: 10.799743922353382\n",
      "epoch: 197 loss: 1.8716379404067993 grad: 11.306979712764067\n",
      "epoch: 198 loss: 1.851881742477417 grad: 10.254904932416384\n",
      "epoch: 199 loss: 1.867815613746643 grad: 10.2412867343408\n",
      "epoch: 200 loss: 1.85738205909729 grad: 10.996784640313496\n",
      "epoch: 201 loss: 1.8630831241607666 grad: 11.132664241768893\n",
      "epoch: 202 loss: 1.8635125160217285 grad: 11.373553790462514\n",
      "epoch: 203 loss: 1.8495997190475464 grad: 10.950774641559711\n",
      "epoch: 204 loss: 1.851288080215454 grad: 10.969749033007593\n",
      "epoch: 205 loss: 1.8542851209640503 grad: 11.335742650361407\n",
      "epoch: 206 loss: 1.8531583547592163 grad: 11.117261978383693\n",
      "epoch: 207 loss: 1.8422160148620605 grad: 11.428352111181805\n",
      "epoch: 208 loss: 1.849400281906128 grad: 10.982909865825185\n",
      "epoch: 209 loss: 1.8450676202774048 grad: 11.077021317467803\n",
      "epoch: 210 loss: 1.8478121757507324 grad: 11.72587060026588\n",
      "epoch: 211 loss: 1.8387943506240845 grad: 11.170405634294545\n",
      "epoch: 212 loss: 1.8416988849639893 grad: 11.611238945940775\n",
      "epoch: 213 loss: 1.841825246810913 grad: 11.115415230023837\n",
      "epoch: 214 loss: 1.8381508588790894 grad: 11.018247604665776\n",
      "epoch: 215 loss: 1.834372878074646 grad: 11.307970168438578\n",
      "epoch: 216 loss: 1.842761516571045 grad: 11.350903395563364\n",
      "epoch: 217 loss: 1.8383824825286865 grad: 11.583676425355767\n",
      "epoch: 218 loss: 1.8385868072509766 grad: 12.095607966228965\n",
      "epoch: 219 loss: 1.8362681865692139 grad: 11.518892374007947\n",
      "epoch: 220 loss: 1.8400956392288208 grad: 11.993216015856772\n",
      "epoch: 221 loss: 1.833024501800537 grad: 11.445429222126092\n",
      "epoch: 222 loss: 1.8283900022506714 grad: 11.875831418759411\n",
      "epoch: 223 loss: 1.834309697151184 grad: 11.6977646773208\n",
      "epoch: 224 loss: 1.8314075469970703 grad: 11.987677495157907\n",
      "epoch: 225 loss: 1.8278090953826904 grad: 11.580228751244407\n",
      "epoch: 226 loss: 1.834462285041809 grad: 11.537727067424427\n",
      "epoch: 227 loss: 1.825896978378296 grad: 11.923148478928303\n",
      "epoch: 228 loss: 1.831764817237854 grad: 11.50247732245378\n",
      "epoch: 229 loss: 1.8260806798934937 grad: 11.708323516823825\n",
      "epoch: 230 loss: 1.8268805742263794 grad: 11.625745667203788\n",
      "epoch: 231 loss: 1.8270142078399658 grad: 12.063481102209716\n",
      "epoch: 232 loss: 1.8249027729034424 grad: 11.805497293168354\n",
      "epoch: 233 loss: 1.8201245069503784 grad: 11.679603183937688\n",
      "epoch: 234 loss: 1.8212742805480957 grad: 12.239759226226145\n",
      "epoch: 235 loss: 1.8165080547332764 grad: 12.024770342419663\n",
      "epoch: 236 loss: 1.8230712413787842 grad: 11.598959533970744\n",
      "epoch: 237 loss: 1.8109663724899292 grad: 11.626192407608624\n",
      "epoch: 238 loss: 1.8197648525238037 grad: 11.889929674477095\n",
      "epoch: 239 loss: 1.8133856058120728 grad: 12.496366061166757\n",
      "epoch: 240 loss: 1.8112071752548218 grad: 11.460199903090677\n",
      "epoch: 241 loss: 1.8129279613494873 grad: 11.83529034858599\n",
      "epoch: 242 loss: 1.800079584121704 grad: 11.832223670305831\n",
      "epoch: 243 loss: 1.8102009296417236 grad: 12.734523251017054\n",
      "epoch: 244 loss: 1.8132479190826416 grad: 11.98136027056783\n",
      "epoch: 245 loss: 1.8132710456848145 grad: 12.171129429905069\n",
      "epoch: 246 loss: 1.813867211341858 grad: 12.036922648829956\n",
      "epoch: 247 loss: 1.8111099004745483 grad: 12.476375177073928\n",
      "epoch: 248 loss: 1.8140827417373657 grad: 12.578639206180851\n",
      "epoch: 249 loss: 1.808692455291748 grad: 12.665171582044827\n",
      "epoch: 250 loss: 1.8080010414123535 grad: 12.441584261237747\n",
      "epoch: 251 loss: 1.8099285364151 grad: 12.827107001214273\n",
      "epoch: 252 loss: 1.8134962320327759 grad: 12.880136045390769\n",
      "epoch: 253 loss: 1.7960729598999023 grad: 12.591254332975026\n",
      "epoch: 254 loss: 1.8003424406051636 grad: 12.34232398580819\n",
      "epoch: 255 loss: 1.8061522245407104 grad: 12.867477277382498\n",
      "epoch: 256 loss: 1.7905124425888062 grad: 12.410164240112026\n",
      "epoch: 257 loss: 1.8005486726760864 grad: 13.334705159230719\n",
      "epoch: 258 loss: 1.7977935075759888 grad: 12.816341780273923\n",
      "epoch: 259 loss: 1.7999439239501953 grad: 12.160506325936506\n",
      "epoch: 260 loss: 1.7840943336486816 grad: 12.182767085361457\n",
      "epoch: 261 loss: 1.8015555143356323 grad: 13.590445258285081\n",
      "epoch: 262 loss: 1.7913397550582886 grad: 12.02820595339059\n",
      "epoch: 263 loss: 1.7876139879226685 grad: 12.872197655665259\n",
      "epoch: 264 loss: 1.7854493856430054 grad: 12.460932602292843\n",
      "epoch: 265 loss: 1.8023027181625366 grad: 12.893014005680998\n",
      "epoch: 266 loss: 1.7913576364517212 grad: 12.437225801663267\n",
      "epoch: 267 loss: 1.7786448001861572 grad: 12.368406626528927\n",
      "epoch: 268 loss: 1.79238760471344 grad: 12.653014714711361\n",
      "epoch: 269 loss: 1.7913005352020264 grad: 12.318767044574969\n",
      "epoch: 270 loss: 1.7851977348327637 grad: 12.393434609715191\n",
      "epoch: 271 loss: 1.7919659614562988 grad: 12.90644986232713\n",
      "epoch: 272 loss: 1.785693883895874 grad: 12.863650760894258\n",
      "epoch: 273 loss: 1.7903354167938232 grad: 12.709339317776973\n",
      "epoch: 274 loss: 1.7790638208389282 grad: 13.26523593792485\n",
      "epoch: 275 loss: 1.795921802520752 grad: 12.832828361378422\n",
      "epoch: 276 loss: 1.7861047983169556 grad: 12.845390708976618\n",
      "epoch: 277 loss: 1.7878258228302002 grad: 13.20967454266631\n",
      "epoch: 278 loss: 1.7879389524459839 grad: 13.21885949361419\n",
      "epoch: 279 loss: 1.7852991819381714 grad: 12.949142683770448\n",
      "epoch: 280 loss: 1.7844518423080444 grad: 12.519051995483183\n",
      "epoch: 281 loss: 1.7846028804779053 grad: 12.892218814320152\n",
      "epoch: 282 loss: 1.7716290950775146 grad: 12.135183183698071\n",
      "epoch: 283 loss: 1.7786318063735962 grad: 12.647266781253238\n",
      "epoch: 284 loss: 1.7880555391311646 grad: 13.39656001308726\n",
      "epoch: 285 loss: 1.77970552444458 grad: 12.39522353762258\n",
      "epoch: 286 loss: 1.7695128917694092 grad: 13.147504866197114\n",
      "epoch: 287 loss: 1.7721939086914062 grad: 13.481316162347202\n",
      "epoch: 288 loss: 1.767626404762268 grad: 13.35146461449386\n",
      "epoch: 289 loss: 1.7711939811706543 grad: 13.582176223160728\n",
      "epoch: 290 loss: 1.7778207063674927 grad: 13.438006287366743\n",
      "epoch: 291 loss: 1.7781012058258057 grad: 13.130161039531231\n",
      "epoch: 292 loss: 1.7666735649108887 grad: 13.042121235414275\n",
      "epoch: 293 loss: 1.7739226818084717 grad: 13.31047186055886\n",
      "epoch: 294 loss: 1.7616195678710938 grad: 12.627340647347626\n",
      "epoch: 295 loss: 1.7670135498046875 grad: 13.232277371684118\n",
      "epoch: 296 loss: 1.764365315437317 grad: 13.030786384207508\n",
      "epoch: 297 loss: 1.767043948173523 grad: 13.78083771192247\n",
      "epoch: 298 loss: 1.7635701894760132 grad: 13.31758510393815\n",
      "epoch: 299 loss: 1.7669590711593628 grad: 13.707592076178463\n",
      "epoch: 300 loss: 1.7667028903961182 grad: 13.240295670039597\n",
      "epoch: 301 loss: 1.7682727575302124 grad: 12.993434706643697\n",
      "epoch: 302 loss: 1.758840799331665 grad: 12.961707404504219\n",
      "epoch: 303 loss: 1.760627269744873 grad: 13.031995474538277\n",
      "epoch: 304 loss: 1.7687456607818604 grad: 13.369322121764222\n",
      "epoch: 305 loss: 1.7645241022109985 grad: 13.28673391789198\n",
      "epoch: 306 loss: 1.7595911026000977 grad: 13.712337361264323\n",
      "epoch: 307 loss: 1.757590651512146 grad: 13.60154913846285\n",
      "epoch: 308 loss: 1.7599998712539673 grad: 13.190803678588026\n",
      "epoch: 309 loss: 1.7559109926223755 grad: 13.534079308311144\n",
      "epoch: 310 loss: 1.7641127109527588 grad: 13.895121108297081\n",
      "epoch: 311 loss: 1.7533832788467407 grad: 13.318479245247703\n",
      "epoch: 312 loss: 1.7574130296707153 grad: 13.986270869653376\n",
      "epoch: 313 loss: 1.7536320686340332 grad: 13.45003076858582\n",
      "epoch: 314 loss: 1.7624199390411377 grad: 13.682746331089191\n",
      "epoch: 315 loss: 1.7624715566635132 grad: 13.9219601982761\n",
      "epoch: 316 loss: 1.756588339805603 grad: 13.27893695947788\n",
      "epoch: 317 loss: 1.7592252492904663 grad: 13.992251094312422\n",
      "epoch: 318 loss: 1.7518596649169922 grad: 14.011989767027517\n",
      "epoch: 319 loss: 1.7605705261230469 grad: 13.264876411222513\n",
      "epoch: 320 loss: 1.7436492443084717 grad: 13.681700198999827\n",
      "epoch: 321 loss: 1.7464041709899902 grad: 13.955636186421746\n",
      "epoch: 322 loss: 1.7525463104248047 grad: 13.246590919556125\n",
      "epoch: 323 loss: 1.7556054592132568 grad: 13.938006937222939\n",
      "epoch: 324 loss: 1.7411216497421265 grad: 13.968423810151835\n",
      "epoch: 325 loss: 1.7480653524398804 grad: 14.000008657840747\n",
      "epoch: 326 loss: 1.74769926071167 grad: 14.629891701929626\n",
      "epoch: 327 loss: 1.7439907789230347 grad: 14.118610728059023\n",
      "epoch: 328 loss: 1.7420809268951416 grad: 13.00903874277211\n",
      "epoch: 329 loss: 1.7480534315109253 grad: 13.426171405506986\n",
      "epoch: 330 loss: 1.7422184944152832 grad: 13.725213436587225\n",
      "epoch: 331 loss: 1.7443714141845703 grad: 13.186084062393222\n",
      "epoch: 332 loss: 1.7471985816955566 grad: 13.288958055994636\n",
      "epoch: 333 loss: 1.741064190864563 grad: 14.20932540668559\n",
      "epoch: 334 loss: 1.7266932725906372 grad: 13.092638877028275\n",
      "epoch: 335 loss: 1.7410520315170288 grad: 13.392007979667849\n",
      "epoch: 336 loss: 1.7407325506210327 grad: 13.74393414345289\n",
      "epoch: 337 loss: 1.738431453704834 grad: 13.108993611106325\n",
      "epoch: 338 loss: 1.7337815761566162 grad: 13.178336393923336\n",
      "epoch: 339 loss: 1.7415709495544434 grad: 13.061716600469062\n",
      "epoch: 340 loss: 1.7330931425094604 grad: 13.837542135608457\n",
      "epoch: 341 loss: 1.7451645135879517 grad: 14.190609923600855\n",
      "epoch: 342 loss: 1.7394777536392212 grad: 13.274842095516977\n",
      "epoch: 343 loss: 1.7457454204559326 grad: 13.467268136714305\n",
      "epoch: 344 loss: 1.7340561151504517 grad: 13.5489282369658\n",
      "epoch: 345 loss: 1.730428695678711 grad: 13.212493271892152\n",
      "epoch: 346 loss: 1.7390284538269043 grad: 14.851305377270494\n",
      "epoch: 347 loss: 1.7358394861221313 grad: 13.970016261769665\n",
      "epoch: 348 loss: 1.7410218715667725 grad: 13.881603995707655\n",
      "epoch: 349 loss: 1.7355822324752808 grad: 13.614115783057752\n",
      "epoch: 350 loss: 1.7248256206512451 grad: 13.79118006317211\n",
      "epoch: 351 loss: 1.731762170791626 grad: 13.993751869034318\n",
      "epoch: 352 loss: 1.7314249277114868 grad: 13.457138583729309\n",
      "epoch: 353 loss: 1.7363059520721436 grad: 13.41019776592859\n",
      "epoch: 354 loss: 1.7328015565872192 grad: 13.640240873003172\n",
      "epoch: 355 loss: 1.7390316724777222 grad: 13.954896883950347\n",
      "epoch: 356 loss: 1.7414395809173584 grad: 13.922017989901914\n",
      "epoch: 357 loss: 1.7402212619781494 grad: 14.182582372193417\n",
      "epoch: 358 loss: 1.7232329845428467 grad: 13.115061265933845\n",
      "epoch: 359 loss: 1.7259429693222046 grad: 13.748534569073291\n",
      "epoch: 360 loss: 1.7258647680282593 grad: 13.088855914756774\n",
      "epoch: 361 loss: 1.7342588901519775 grad: 14.03249076234975\n",
      "epoch: 362 loss: 1.732248067855835 grad: 14.237947884725319\n",
      "epoch: 363 loss: 1.7325005531311035 grad: 13.91426564954103\n",
      "epoch: 364 loss: 1.7228516340255737 grad: 13.649541499950583\n",
      "epoch: 365 loss: 1.7324516773223877 grad: 13.591908817445594\n",
      "epoch: 366 loss: 1.7204762697219849 grad: 14.08079960726438\n",
      "epoch: 367 loss: 1.7313765287399292 grad: 13.607899123787998\n",
      "epoch: 368 loss: 1.7218362092971802 grad: 14.074390277828252\n",
      "epoch: 369 loss: 1.7268701791763306 grad: 13.532918802787743\n",
      "epoch: 370 loss: 1.7287225723266602 grad: 13.803627179595567\n",
      "epoch: 371 loss: 1.7241743803024292 grad: 13.175761873464262\n",
      "epoch: 372 loss: 1.725148320198059 grad: 14.051093706979401\n",
      "epoch: 373 loss: 1.7227957248687744 grad: 13.830144656866434\n",
      "epoch: 374 loss: 1.7242969274520874 grad: 13.919208827872007\n",
      "epoch: 375 loss: 1.7313014268875122 grad: 13.556997482975325\n",
      "epoch: 376 loss: 1.7341517210006714 grad: 14.27185282739441\n",
      "epoch: 377 loss: 1.7245762348175049 grad: 14.957634666298945\n",
      "epoch: 378 loss: 1.719253420829773 grad: 14.32420611974325\n",
      "epoch: 379 loss: 1.7201142311096191 grad: 14.039800598197395\n",
      "epoch: 380 loss: 1.7238833904266357 grad: 14.159649198800917\n",
      "epoch: 381 loss: 1.7201217412948608 grad: 13.639241863322992\n",
      "epoch: 382 loss: 1.7258968353271484 grad: 14.500177233199041\n",
      "epoch: 383 loss: 1.7232469320297241 grad: 14.095469230815532\n",
      "epoch: 384 loss: 1.725246787071228 grad: 14.121120936532934\n",
      "epoch: 385 loss: 1.7143996953964233 grad: 14.254185143030352\n",
      "epoch: 386 loss: 1.7194621562957764 grad: 13.730615863576531\n",
      "epoch: 387 loss: 1.711943507194519 grad: 13.52859641060174\n",
      "epoch: 388 loss: 1.7275358438491821 grad: 13.570489449086525\n",
      "epoch: 389 loss: 1.7121952772140503 grad: 14.6828818446587\n",
      "epoch: 390 loss: 1.7141389846801758 grad: 13.13461851954667\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 391 loss: 1.713897943496704 grad: 13.541331967531097\n",
      "epoch: 392 loss: 1.700379729270935 grad: 14.076859042447593\n",
      "epoch: 393 loss: 1.7236981391906738 grad: 14.412826767442601\n",
      "epoch: 394 loss: 1.718788743019104 grad: 14.054789154095547\n",
      "epoch: 395 loss: 1.7073609828948975 grad: 14.149076377884263\n",
      "epoch: 396 loss: 1.7073956727981567 grad: 13.635918202026495\n",
      "epoch: 397 loss: 1.704722285270691 grad: 13.781393207447042\n",
      "epoch: 398 loss: 1.7227139472961426 grad: 14.51950088282308\n",
      "epoch: 399 loss: 1.7157379388809204 grad: 14.341243825978525\n",
      "epoch: 400 loss: 1.7088350057601929 grad: 14.077195510016901\n",
      "epoch: 401 loss: 1.7036830186843872 grad: 13.887503026334185\n",
      "epoch: 402 loss: 1.7137389183044434 grad: 13.997213646828655\n",
      "epoch: 403 loss: 1.7155132293701172 grad: 13.998832848336962\n",
      "epoch: 404 loss: 1.702887773513794 grad: 13.681762123761315\n",
      "epoch: 405 loss: 1.7092161178588867 grad: 14.036323581038722\n",
      "epoch: 406 loss: 1.7186558246612549 grad: 14.360884347139665\n",
      "epoch: 407 loss: 1.7132797241210938 grad: 13.659204549200478\n",
      "epoch: 408 loss: 1.700027346611023 grad: 14.165124489171873\n",
      "epoch: 409 loss: 1.707516074180603 grad: 13.978514512498228\n",
      "epoch: 410 loss: 1.7097142934799194 grad: 14.344755700996352\n",
      "epoch: 411 loss: 1.7012486457824707 grad: 13.982122401012079\n",
      "epoch: 412 loss: 1.7112945318222046 grad: 14.606181225857682\n",
      "epoch: 413 loss: 1.6970428228378296 grad: 13.885217145233163\n",
      "epoch: 414 loss: 1.7059533596038818 grad: 14.156423697455061\n",
      "epoch: 415 loss: 1.7114113569259644 grad: 13.558669490902314\n",
      "epoch: 416 loss: 1.7046715021133423 grad: 14.314050198650904\n",
      "epoch: 417 loss: 1.7026889324188232 grad: 13.493970053965255\n",
      "epoch: 418 loss: 1.7098333835601807 grad: 13.974608609689371\n",
      "epoch: 419 loss: 1.6961597204208374 grad: 13.938466484214933\n",
      "epoch: 420 loss: 1.7060424089431763 grad: 13.04677670839287\n",
      "epoch: 421 loss: 1.707200527191162 grad: 14.446699393218355\n",
      "epoch: 422 loss: 1.7117724418640137 grad: 14.312259124946737\n",
      "epoch: 423 loss: 1.69833505153656 grad: 14.123748429326547\n",
      "epoch: 424 loss: 1.70176100730896 grad: 14.655605397955885\n",
      "epoch: 425 loss: 1.710037350654602 grad: 13.897907164139998\n",
      "epoch: 426 loss: 1.706970453262329 grad: 13.852395419016599\n",
      "epoch: 427 loss: 1.7068754434585571 grad: 13.41163576605715\n",
      "epoch: 428 loss: 1.7004543542861938 grad: 14.258093197963067\n",
      "epoch: 429 loss: 1.7020303010940552 grad: 14.288351181628448\n",
      "epoch: 430 loss: 1.6971567869186401 grad: 13.458451470670601\n",
      "epoch: 431 loss: 1.6928541660308838 grad: 13.541560324485458\n",
      "epoch: 432 loss: 1.687076210975647 grad: 13.929485473205292\n",
      "epoch: 433 loss: 1.6921547651290894 grad: 14.40729025729178\n",
      "epoch: 434 loss: 1.702993392944336 grad: 14.31442028198332\n",
      "epoch: 435 loss: 1.6987130641937256 grad: 14.331214203743176\n",
      "epoch: 436 loss: 1.6981136798858643 grad: 14.24974453795169\n",
      "epoch: 437 loss: 1.7040073871612549 grad: 14.416759217084046\n",
      "epoch: 438 loss: 1.6948094367980957 grad: 14.154053112314571\n",
      "epoch: 439 loss: 1.6937705278396606 grad: 13.93011036229926\n",
      "epoch: 440 loss: 1.699364185333252 grad: 13.731983565437119\n",
      "epoch: 441 loss: 1.7030984163284302 grad: 13.488582321501795\n",
      "epoch: 442 loss: 1.6855578422546387 grad: 13.795457789142217\n",
      "epoch: 443 loss: 1.7012747526168823 grad: 14.228436520604033\n",
      "epoch: 444 loss: 1.6908748149871826 grad: 14.293428049999333\n",
      "epoch: 445 loss: 1.6938331127166748 grad: 14.62440923938439\n",
      "epoch: 446 loss: 1.6953449249267578 grad: 13.928931334750756\n",
      "epoch: 447 loss: 1.6963169574737549 grad: 14.185376901105638\n",
      "epoch: 448 loss: 1.6964472532272339 grad: 13.553132636398669\n",
      "epoch: 449 loss: 1.6958236694335938 grad: 14.388680239503701\n",
      "epoch: 450 loss: 1.6811779737472534 grad: 13.405333911453093\n",
      "epoch: 451 loss: 1.6936054229736328 grad: 14.465485892465544\n",
      "epoch: 452 loss: 1.6924140453338623 grad: 14.826150103531305\n",
      "epoch: 453 loss: 1.698570728302002 grad: 14.189188922918031\n",
      "epoch: 454 loss: 1.6894885301589966 grad: 14.545038800716164\n",
      "epoch: 455 loss: 1.6766408681869507 grad: 12.960892467116494\n",
      "epoch: 456 loss: 1.6982356309890747 grad: 14.266368920988743\n",
      "epoch: 457 loss: 1.6917784214019775 grad: 14.45606588206387\n",
      "epoch: 458 loss: 1.6953200101852417 grad: 13.664777099140107\n",
      "epoch: 459 loss: 1.6841411590576172 grad: 13.420181684122081\n",
      "epoch: 460 loss: 1.695899486541748 grad: 14.7544930299064\n",
      "epoch: 461 loss: 1.6933234930038452 grad: 14.039274301409485\n",
      "epoch: 462 loss: 1.679097294807434 grad: 14.857724554112387\n",
      "epoch: 463 loss: 1.6864320039749146 grad: 14.359648602467681\n",
      "epoch: 464 loss: 1.6767469644546509 grad: 14.081589244232173\n",
      "epoch: 465 loss: 1.6867623329162598 grad: 14.284277743926006\n",
      "epoch: 466 loss: 1.6848810911178589 grad: 14.373657312140697\n",
      "epoch: 467 loss: 1.6781152486801147 grad: 14.28072675598401\n",
      "epoch: 468 loss: 1.6767500638961792 grad: 14.74756181210516\n",
      "epoch: 469 loss: 1.6857246160507202 grad: 14.108940394550917\n",
      "epoch: 470 loss: 1.6839792728424072 grad: 13.701630283642324\n",
      "epoch: 471 loss: 1.6854376792907715 grad: 13.98170416787385\n",
      "epoch: 472 loss: 1.6827170848846436 grad: 14.537689524480985\n",
      "epoch: 473 loss: 1.693402886390686 grad: 14.582797534216846\n",
      "epoch: 474 loss: 1.6777340173721313 grad: 13.740912537474836\n",
      "epoch: 475 loss: 1.6831836700439453 grad: 14.661213933009773\n",
      "epoch: 476 loss: 1.690456509590149 grad: 15.402077547097136\n",
      "epoch: 477 loss: 1.6802749633789062 grad: 14.350054354776466\n",
      "epoch: 478 loss: 1.68972647190094 grad: 14.79464605852725\n",
      "epoch: 479 loss: 1.6813665628433228 grad: 13.948345712371289\n",
      "epoch: 480 loss: 1.6776043176651 grad: 13.503061182198248\n",
      "epoch: 481 loss: 1.6809437274932861 grad: 14.62029063652846\n",
      "epoch: 482 loss: 1.682769536972046 grad: 14.083967861202028\n",
      "epoch: 483 loss: 1.6844085454940796 grad: 14.191998135682846\n",
      "epoch: 484 loss: 1.671384572982788 grad: 13.473975524823699\n",
      "epoch: 485 loss: 1.6735270023345947 grad: 14.866644945505652\n",
      "epoch: 486 loss: 1.687515139579773 grad: 14.59026049251949\n",
      "epoch: 487 loss: 1.6779102087020874 grad: 14.001980784866545\n",
      "epoch: 488 loss: 1.676657795906067 grad: 13.452620988889109\n",
      "epoch: 489 loss: 1.6727181673049927 grad: 14.912810095305007\n",
      "epoch: 490 loss: 1.6785807609558105 grad: 14.45423648787278\n",
      "epoch: 491 loss: 1.678359866142273 grad: 13.511229059718076\n",
      "epoch: 492 loss: 1.6743767261505127 grad: 13.513889575524935\n",
      "epoch: 493 loss: 1.6809667348861694 grad: 13.68979595419729\n",
      "epoch: 494 loss: 1.682361364364624 grad: 13.778668210235617\n",
      "epoch: 495 loss: 1.6769384145736694 grad: 14.229348550417594\n",
      "epoch: 496 loss: 1.680133581161499 grad: 14.050013853695303\n",
      "epoch: 497 loss: 1.6690917015075684 grad: 13.591662973926832\n",
      "epoch: 498 loss: 1.6776063442230225 grad: 13.43688485972465\n",
      "epoch: 499 loss: 1.6757111549377441 grad: 13.676685687819761\n",
      "1.9693664535880089\n",
      "epoch: 0 loss: 2.304899215698242 grad: 0.9488776320829944\n",
      "epoch: 1 loss: 2.2811827659606934 grad: 1.303382936963952\n",
      "epoch: 2 loss: 2.2142488956451416 grad: 2.3723286747681125\n",
      "epoch: 3 loss: 2.155163526535034 grad: 3.214370996498185\n",
      "epoch: 4 loss: 2.062680244445801 grad: 3.767265586038342\n",
      "epoch: 5 loss: 1.9873645305633545 grad: 4.635712579526524\n",
      "epoch: 6 loss: 1.9325039386749268 grad: 5.774264568524871\n",
      "epoch: 7 loss: 1.8940622806549072 grad: 5.794440541101346\n",
      "epoch: 8 loss: 1.8869550228118896 grad: 6.7400509808508176\n",
      "epoch: 9 loss: 1.8349599838256836 grad: 5.906892488477752\n",
      "epoch: 10 loss: 1.8266650438308716 grad: 7.073128431829409\n",
      "epoch: 11 loss: 1.7898274660110474 grad: 6.594835715005285\n",
      "epoch: 12 loss: 1.7831960916519165 grad: 7.080088844715012\n",
      "epoch: 13 loss: 1.764705777168274 grad: 6.601707063685079\n",
      "epoch: 14 loss: 1.7648781538009644 grad: 6.832298713641302\n",
      "epoch: 15 loss: 1.7601408958435059 grad: 6.074684913110104\n",
      "epoch: 16 loss: 1.7489418983459473 grad: 6.55382157023257\n",
      "epoch: 17 loss: 1.7414562702178955 grad: 6.064078238637497\n",
      "epoch: 18 loss: 1.7256438732147217 grad: 6.008092589419527\n",
      "epoch: 19 loss: 1.7401678562164307 grad: 6.924167493346244\n",
      "epoch: 20 loss: 1.725380778312683 grad: 6.291131979542404\n",
      "epoch: 21 loss: 1.7018080949783325 grad: 6.146631256484109\n",
      "epoch: 22 loss: 1.6802363395690918 grad: 6.75079072600541\n",
      "epoch: 23 loss: 1.6769896745681763 grad: 6.941644543931553\n",
      "epoch: 24 loss: 1.665523648262024 grad: 6.280931607941128\n",
      "epoch: 25 loss: 1.6688750982284546 grad: 7.1609146185844095\n",
      "epoch: 26 loss: 1.6650996208190918 grad: 7.336843020481331\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 27 loss: 1.6611344814300537 grad: 6.373418115167638\n",
      "epoch: 28 loss: 1.6634654998779297 grad: 6.829760536341512\n",
      "epoch: 29 loss: 1.6508491039276123 grad: 7.227521982769903\n",
      "epoch: 30 loss: 1.6440759897232056 grad: 6.943717076726783\n",
      "epoch: 31 loss: 1.6257359981536865 grad: 6.450760593651221\n",
      "epoch: 32 loss: 1.6261160373687744 grad: 6.921142443204723\n",
      "epoch: 33 loss: 1.629729151725769 grad: 6.91238727187068\n",
      "epoch: 34 loss: 1.6486698389053345 grad: 6.83946810207618\n",
      "epoch: 35 loss: 1.6468846797943115 grad: 6.548317362891837\n",
      "epoch: 36 loss: 1.636650562286377 grad: 6.993042767840038\n",
      "epoch: 37 loss: 1.6208211183547974 grad: 6.666039537492907\n",
      "epoch: 38 loss: 1.6269783973693848 grad: 6.768704019831762\n",
      "epoch: 39 loss: 1.6239688396453857 grad: 6.694878306222981\n",
      "epoch: 40 loss: 1.6149706840515137 grad: 6.800161338056482\n",
      "epoch: 41 loss: 1.632836103439331 grad: 6.911270761107777\n",
      "epoch: 42 loss: 1.6271916627883911 grad: 5.349956599715427\n",
      "epoch: 43 loss: 1.599394679069519 grad: 5.439555728836456\n",
      "epoch: 44 loss: 1.5938876867294312 grad: 5.8769331185985285\n",
      "epoch: 45 loss: 1.6192082166671753 grad: 5.969621020517754\n",
      "epoch: 46 loss: 1.6140263080596924 grad: 6.722310112227985\n",
      "epoch: 47 loss: 1.6310352087020874 grad: 7.085762267217057\n",
      "epoch: 48 loss: 1.6048613786697388 grad: 6.041988719225686\n",
      "epoch: 49 loss: 1.6143410205841064 grad: 6.242216917927018\n",
      "epoch: 50 loss: 1.6212109327316284 grad: 6.607426161264836\n",
      "epoch: 51 loss: 1.6099493503570557 grad: 6.25375650055676\n",
      "epoch: 52 loss: 1.6121541261672974 grad: 7.025869939739601\n",
      "epoch: 53 loss: 1.6194602251052856 grad: 6.766194505605358\n",
      "epoch: 54 loss: 1.6111409664154053 grad: 6.60118013749496\n",
      "epoch: 55 loss: 1.6240878105163574 grad: 6.788627362264494\n",
      "epoch: 56 loss: 1.603519320487976 grad: 5.398045290209276\n",
      "epoch: 57 loss: 1.6023859977722168 grad: 5.568697220983953\n",
      "epoch: 58 loss: 1.5925019979476929 grad: 5.977140086442338\n",
      "epoch: 59 loss: 1.599565029144287 grad: 5.51483541662476\n",
      "epoch: 60 loss: 1.5935174226760864 grad: 5.964709299981656\n",
      "epoch: 61 loss: 1.5956592559814453 grad: 5.460415368976981\n",
      "epoch: 62 loss: 1.587607741355896 grad: 6.271220786555897\n",
      "epoch: 63 loss: 1.5956000089645386 grad: 5.772046896458281\n",
      "epoch: 64 loss: 1.5930683612823486 grad: 5.970276483657515\n",
      "epoch: 65 loss: 1.5813239812850952 grad: 4.713935594415849\n",
      "epoch: 66 loss: 1.5930479764938354 grad: 5.547342536508199\n",
      "epoch: 67 loss: 1.5865596532821655 grad: 5.649413948170237\n",
      "epoch: 68 loss: 1.5865075588226318 grad: 5.701324062426191\n",
      "epoch: 69 loss: 1.577405333518982 grad: 4.374636425958988\n",
      "epoch: 70 loss: 1.5834547281265259 grad: 5.988061412104034\n",
      "epoch: 71 loss: 1.5899291038513184 grad: 5.42104701976074\n",
      "epoch: 72 loss: 1.5886121988296509 grad: 5.85345734751022\n",
      "epoch: 73 loss: 1.588901162147522 grad: 5.189286387005932\n",
      "epoch: 74 loss: 1.5765409469604492 grad: 5.119104320484721\n",
      "epoch: 75 loss: 1.6062211990356445 grad: 5.77889968461428\n",
      "epoch: 76 loss: 1.5909193754196167 grad: 6.283840465926063\n",
      "epoch: 77 loss: 1.5803319215774536 grad: 5.781196703388956\n",
      "epoch: 78 loss: 1.6052165031433105 grad: 6.012796759872944\n",
      "epoch: 79 loss: 1.6048694849014282 grad: 6.1095164714590195\n",
      "epoch: 80 loss: 1.582842469215393 grad: 5.536925731239629\n",
      "epoch: 81 loss: 1.573677659034729 grad: 5.353315693899229\n",
      "epoch: 82 loss: 1.5732437372207642 grad: 4.990549868660483\n",
      "epoch: 83 loss: 1.5905956029891968 grad: 6.428998654895911\n",
      "epoch: 84 loss: 1.595276951789856 grad: 7.033557242161069\n",
      "epoch: 85 loss: 1.5911805629730225 grad: 5.470239094712537\n",
      "epoch: 86 loss: 1.568921685218811 grad: 4.712141895675846\n",
      "epoch: 87 loss: 1.5841022729873657 grad: 6.429561066997906\n",
      "epoch: 88 loss: 1.584195613861084 grad: 6.5435474268813865\n",
      "epoch: 89 loss: 1.5842636823654175 grad: 5.38523388562505\n",
      "epoch: 90 loss: 1.5799119472503662 grad: 5.466657751300827\n",
      "epoch: 91 loss: 1.5871195793151855 grad: 6.472498026190131\n",
      "epoch: 92 loss: 1.5893478393554688 grad: 5.6026662974493355\n",
      "epoch: 93 loss: 1.5872530937194824 grad: 5.46006774890085\n",
      "epoch: 94 loss: 1.574684739112854 grad: 6.0490304804456\n",
      "epoch: 95 loss: 1.5911651849746704 grad: 6.22053511491983\n",
      "epoch: 96 loss: 1.576476812362671 grad: 5.269112213347442\n",
      "epoch: 97 loss: 1.582625150680542 grad: 6.5513565296362986\n",
      "epoch: 98 loss: 1.5882036685943604 grad: 5.331463621074396\n",
      "epoch: 99 loss: 1.5791218280792236 grad: 5.88394637111492\n",
      "epoch: 100 loss: 1.5782793760299683 grad: 5.192727958492527\n",
      "epoch: 101 loss: 1.5837990045547485 grad: 4.670374894567553\n",
      "epoch: 102 loss: 1.5835102796554565 grad: 4.839305645602436\n",
      "epoch: 103 loss: 1.58256196975708 grad: 5.571549929622932\n",
      "epoch: 104 loss: 1.5602803230285645 grad: 3.724870278749955\n",
      "epoch: 105 loss: 1.5587607622146606 grad: 5.105899592648013\n",
      "epoch: 106 loss: 1.5560029745101929 grad: 4.110579689915887\n",
      "epoch: 107 loss: 1.5685837268829346 grad: 4.80225857690909\n",
      "epoch: 108 loss: 1.558398962020874 grad: 5.444153814525895\n",
      "epoch: 109 loss: 1.5608183145523071 grad: 5.001150449759871\n",
      "epoch: 110 loss: 1.572876214981079 grad: 5.88921640264151\n",
      "epoch: 111 loss: 1.560359239578247 grad: 4.113010962361353\n",
      "epoch: 112 loss: 1.5733994245529175 grad: 5.5461387089329355\n",
      "epoch: 113 loss: 1.5638916492462158 grad: 5.3695988010243\n",
      "epoch: 114 loss: 1.5682636499404907 grad: 3.457760108776812\n",
      "epoch: 115 loss: 1.5618525743484497 grad: 4.516781824575331\n",
      "epoch: 116 loss: 1.5701444149017334 grad: 6.219297358585512\n",
      "epoch: 117 loss: 1.5691043138504028 grad: 5.101445274714298\n",
      "epoch: 118 loss: 1.5701971054077148 grad: 5.528525670787952\n",
      "epoch: 119 loss: 1.5847573280334473 grad: 5.096603927293364\n",
      "epoch: 120 loss: 1.5722991228103638 grad: 5.878527349869439\n",
      "epoch: 121 loss: 1.5728076696395874 grad: 5.191905986030439\n",
      "epoch: 122 loss: 1.5712624788284302 grad: 5.514927297944144\n",
      "epoch: 123 loss: 1.5749366283416748 grad: 4.84404659424205\n",
      "epoch: 124 loss: 1.5681486129760742 grad: 4.3684967454626795\n",
      "epoch: 125 loss: 1.5725899934768677 grad: 5.174537456305957\n",
      "epoch: 126 loss: 1.5609806776046753 grad: 4.165582312828589\n",
      "epoch: 127 loss: 1.5708647966384888 grad: 4.9039224542429025\n",
      "epoch: 128 loss: 1.5620248317718506 grad: 5.077783504284555\n",
      "epoch: 129 loss: 1.5740240812301636 grad: 5.068483982577166\n",
      "epoch: 130 loss: 1.5705840587615967 grad: 6.190940754646426\n",
      "epoch: 131 loss: 1.5724170207977295 grad: 4.931428300378663\n",
      "epoch: 132 loss: 1.5758063793182373 grad: 4.490344385193653\n",
      "epoch: 133 loss: 1.5579754114151 grad: 4.0462666355022225\n",
      "epoch: 134 loss: 1.5682705640792847 grad: 5.040093156448027\n",
      "epoch: 135 loss: 1.5644633769989014 grad: 4.307185774129546\n",
      "epoch: 136 loss: 1.5723298788070679 grad: 5.295204147362429\n",
      "epoch: 137 loss: 1.5686947107315063 grad: 4.08603315006128\n",
      "epoch: 138 loss: 1.5564861297607422 grad: 4.689066293260372\n",
      "epoch: 139 loss: 1.5734107494354248 grad: 5.589384367070364\n",
      "epoch: 140 loss: 1.578427791595459 grad: 4.111477033401603\n",
      "epoch: 141 loss: 1.558802843093872 grad: 4.071865531305462\n",
      "epoch: 142 loss: 1.5876920223236084 grad: 5.564407347435347\n",
      "epoch: 143 loss: 1.5564488172531128 grad: 4.000970950362147\n",
      "epoch: 144 loss: 1.5600305795669556 grad: 4.639231188818214\n",
      "epoch: 145 loss: 1.5595678091049194 grad: 5.1460003055462895\n",
      "epoch: 146 loss: 1.5899361371994019 grad: 5.814830878850709\n",
      "epoch: 147 loss: 1.5691627264022827 grad: 4.404120419575676\n",
      "epoch: 148 loss: 1.5659034252166748 grad: 5.060582692523884\n",
      "epoch: 149 loss: 1.5669159889221191 grad: 5.644444997799758\n",
      "epoch: 150 loss: 1.563651204109192 grad: 5.669707020805425\n",
      "epoch: 151 loss: 1.568767786026001 grad: 4.579212388709161\n",
      "epoch: 152 loss: 1.5723062753677368 grad: 5.488987039356877\n",
      "epoch: 153 loss: 1.5603063106536865 grad: 5.257827540075996\n",
      "epoch: 154 loss: 1.5680688619613647 grad: 4.05843161888138\n",
      "epoch: 155 loss: 1.5535422563552856 grad: 3.935907297083322\n",
      "epoch: 156 loss: 1.5590767860412598 grad: 5.12657027128256\n",
      "epoch: 157 loss: 1.5638389587402344 grad: 5.180783194093761\n",
      "epoch: 158 loss: 1.5531243085861206 grad: 4.38185965343354\n",
      "epoch: 159 loss: 1.5570968389511108 grad: 4.792169718507904\n",
      "epoch: 160 loss: 1.561964750289917 grad: 5.387598672709048\n",
      "epoch: 161 loss: 1.576328158378601 grad: 4.726589907568441\n",
      "epoch: 162 loss: 1.5542019605636597 grad: 3.7931276791360524\n",
      "epoch: 163 loss: 1.5507755279541016 grad: 3.418894196203523\n",
      "epoch: 164 loss: 1.5552003383636475 grad: 4.502100456863579\n",
      "epoch: 165 loss: 1.5674262046813965 grad: 4.209689990425738\n",
      "epoch: 166 loss: 1.5567740201950073 grad: 5.03833598952244\n",
      "epoch: 167 loss: 1.5631322860717773 grad: 5.3538851418131195\n",
      "epoch: 168 loss: 1.5586694478988647 grad: 5.270424034412755\n",
      "epoch: 169 loss: 1.539029836654663 grad: 4.305915474816169\n",
      "epoch: 170 loss: 1.5652135610580444 grad: 4.0801322690455875\n",
      "epoch: 171 loss: 1.5498319864273071 grad: 4.058418538390954\n",
      "epoch: 172 loss: 1.5446088314056396 grad: 4.150049472565445\n",
      "epoch: 173 loss: 1.5487016439437866 grad: 4.148895482359382\n",
      "epoch: 174 loss: 1.559043526649475 grad: 4.2941550204969525\n",
      "epoch: 175 loss: 1.5722650289535522 grad: 4.6936393497952915\n",
      "epoch: 176 loss: 1.5527218580245972 grad: 4.1974084284534054\n",
      "epoch: 177 loss: 1.553054690361023 grad: 3.7864942175663345\n",
      "epoch: 178 loss: 1.5474833250045776 grad: 3.695890861820707\n",
      "epoch: 179 loss: 1.5472370386123657 grad: 3.8989866468946506\n",
      "epoch: 180 loss: 1.5858476161956787 grad: 7.087477415424857\n",
      "epoch: 181 loss: 1.5640498399734497 grad: 4.08741714635495\n",
      "epoch: 182 loss: 1.5507862567901611 grad: 4.737710689743933\n",
      "epoch: 183 loss: 1.5626029968261719 grad: 4.531047301805114\n",
      "epoch: 184 loss: 1.5583736896514893 grad: 5.216084098021328\n",
      "epoch: 185 loss: 1.5553566217422485 grad: 4.382583215644548\n",
      "epoch: 186 loss: 1.5563808679580688 grad: 4.2143716810245015\n",
      "epoch: 187 loss: 1.5501713752746582 grad: 4.228443452112252\n",
      "epoch: 188 loss: 1.540283441543579 grad: 4.301065520641449\n",
      "epoch: 189 loss: 1.5541932582855225 grad: 4.833901714024979\n",
      "epoch: 190 loss: 1.5560649633407593 grad: 3.47196113970606\n",
      "epoch: 191 loss: 1.5437941551208496 grad: 3.892456318249037\n",
      "epoch: 192 loss: 1.5573360919952393 grad: 3.7618472722584295\n",
      "epoch: 193 loss: 1.5559101104736328 grad: 6.198856774199663\n",
      "epoch: 194 loss: 1.544298529624939 grad: 4.393473581983785\n",
      "epoch: 195 loss: 1.56354820728302 grad: 4.343689688586575\n",
      "epoch: 196 loss: 1.5563445091247559 grad: 4.185673801767685\n",
      "epoch: 197 loss: 1.5499650239944458 grad: 4.248066847303848\n",
      "epoch: 198 loss: 1.5610476732254028 grad: 4.447618007214763\n",
      "epoch: 199 loss: 1.5617314577102661 grad: 3.672986214818971\n",
      "epoch: 200 loss: 1.5506662130355835 grad: 3.859132886844822\n",
      "epoch: 201 loss: 1.5542100667953491 grad: 4.177527896375445\n",
      "epoch: 202 loss: 1.5546756982803345 grad: 3.974236051691075\n",
      "epoch: 203 loss: 1.539868712425232 grad: 3.53049080828253\n",
      "epoch: 204 loss: 1.5414929389953613 grad: 3.341336043753278\n",
      "epoch: 205 loss: 1.5481492280960083 grad: 3.104077334731203\n",
      "epoch: 206 loss: 1.5392693281173706 grad: 3.3289949797802945\n",
      "epoch: 207 loss: 1.5466078519821167 grad: 2.851193122001328\n",
      "epoch: 208 loss: 1.5504660606384277 grad: 3.019978110286921\n",
      "epoch: 209 loss: 1.541634202003479 grad: 3.15362400760525\n",
      "epoch: 210 loss: 1.5465672016143799 grad: 3.7266383099588243\n",
      "epoch: 211 loss: 1.5508804321289062 grad: 4.053598355711028\n",
      "epoch: 212 loss: 1.5402723550796509 grad: 4.399529184496136\n",
      "epoch: 213 loss: 1.5758233070373535 grad: 5.068717142413572\n",
      "epoch: 214 loss: 1.563712477684021 grad: 4.597915609684007\n",
      "epoch: 215 loss: 1.5643799304962158 grad: 5.234091310383407\n",
      "epoch: 216 loss: 1.5378007888793945 grad: 3.6464875432688526\n",
      "epoch: 217 loss: 1.5567126274108887 grad: 3.5339168631253917\n",
      "epoch: 218 loss: 1.5593317747116089 grad: 4.621067899892894\n",
      "epoch: 219 loss: 1.5577746629714966 grad: 5.531447262953809\n",
      "epoch: 220 loss: 1.5751700401306152 grad: 4.552068023871104\n",
      "epoch: 221 loss: 1.5458766222000122 grad: 3.7249525412106963\n",
      "epoch: 222 loss: 1.5433319807052612 grad: 3.2182215623337185\n",
      "epoch: 223 loss: 1.5476781129837036 grad: 4.661626040487655\n",
      "epoch: 224 loss: 1.5477612018585205 grad: 3.0978100846376124\n",
      "epoch: 225 loss: 1.5364102125167847 grad: 2.9605020786561407\n",
      "epoch: 226 loss: 1.5413082838058472 grad: 3.8260636874667333\n",
      "epoch: 227 loss: 1.542148232460022 grad: 3.101835605157343\n",
      "epoch: 228 loss: 1.5656042098999023 grad: 3.9024512245389036\n",
      "epoch: 229 loss: 1.5570513010025024 grad: 4.157524850145557\n",
      "epoch: 230 loss: 1.553602933883667 grad: 5.376217956892834\n",
      "epoch: 231 loss: 1.5597985982894897 grad: 4.971431281266336\n",
      "epoch: 232 loss: 1.5679562091827393 grad: 5.654696726031722\n",
      "epoch: 233 loss: 1.569277286529541 grad: 4.626192997438072\n",
      "epoch: 234 loss: 1.5561543703079224 grad: 4.009926926940518\n",
      "epoch: 235 loss: 1.5428059101104736 grad: 3.274413783753444\n",
      "epoch: 236 loss: 1.5579862594604492 grad: 3.766120528630021\n",
      "epoch: 237 loss: 1.5620299577713013 grad: 5.631119531916486\n",
      "epoch: 238 loss: 1.5503703355789185 grad: 4.2209622961732\n",
      "epoch: 239 loss: 1.554249882698059 grad: 4.177265597314823\n",
      "epoch: 240 loss: 1.5484637022018433 grad: 4.429222961714931\n",
      "epoch: 241 loss: 1.5444059371948242 grad: 4.143939777675847\n",
      "epoch: 242 loss: 1.547239899635315 grad: 3.8222665206103845\n",
      "epoch: 243 loss: 1.534318208694458 grad: 3.221959799551963\n",
      "epoch: 244 loss: 1.5372265577316284 grad: 4.136714822920454\n",
      "epoch: 245 loss: 1.5376248359680176 grad: 3.5810552210562587\n",
      "epoch: 246 loss: 1.5546658039093018 grad: 4.570357426114308\n",
      "epoch: 247 loss: 1.5374445915222168 grad: 4.15026275295592\n",
      "epoch: 248 loss: 1.5632054805755615 grad: 5.099477132805281\n",
      "epoch: 249 loss: 1.5635786056518555 grad: 5.0596368099201685\n",
      "epoch: 250 loss: 1.5610785484313965 grad: 3.8329805783128506\n",
      "epoch: 251 loss: 1.5494167804718018 grad: 4.307403848585304\n",
      "epoch: 252 loss: 1.543332576751709 grad: 4.103042281886124\n",
      "epoch: 253 loss: 1.5537028312683105 grad: 5.168938899297768\n",
      "epoch: 254 loss: 1.550644040107727 grad: 4.219473641182166\n",
      "epoch: 255 loss: 1.5419373512268066 grad: 3.5833561692989626\n",
      "epoch: 256 loss: 1.5586776733398438 grad: 4.180887344965411\n",
      "epoch: 257 loss: 1.5392450094223022 grad: 3.9710516359618446\n",
      "epoch: 258 loss: 1.5385667085647583 grad: 3.304510389043518\n",
      "epoch: 259 loss: 1.5317872762680054 grad: 3.870410218178347\n",
      "epoch: 260 loss: 1.5511817932128906 grad: 4.947847991786508\n",
      "epoch: 261 loss: 1.5464932918548584 grad: 4.879286881290534\n",
      "epoch: 262 loss: 1.5387285947799683 grad: 3.460031797923347\n",
      "epoch: 263 loss: 1.529863953590393 grad: 2.700722833307364\n",
      "epoch: 264 loss: 1.53240168094635 grad: 3.860676660976805\n",
      "epoch: 265 loss: 1.538285255432129 grad: 3.6648545507750625\n",
      "epoch: 266 loss: 1.5309733152389526 grad: 4.478558879545921\n",
      "epoch: 267 loss: 1.5458455085754395 grad: 2.9230151468465424\n",
      "epoch: 268 loss: 1.5511738061904907 grad: 4.355457695373345\n",
      "epoch: 269 loss: 1.5374191999435425 grad: 4.473041956010916\n",
      "epoch: 270 loss: 1.5425690412521362 grad: 2.521710111248245\n",
      "epoch: 271 loss: 1.5295488834381104 grad: 3.7217541986020004\n",
      "epoch: 272 loss: 1.530967354774475 grad: 3.4198901657989715\n",
      "epoch: 273 loss: 1.537541389465332 grad: 3.5441294753425256\n",
      "epoch: 274 loss: 1.5318659543991089 grad: 3.5261643470831556\n",
      "epoch: 275 loss: 1.5515758991241455 grad: 4.357623845635519\n",
      "epoch: 276 loss: 1.5447933673858643 grad: 4.1687935719598554\n",
      "epoch: 277 loss: 1.5327180624008179 grad: 3.9797121138956393\n",
      "epoch: 278 loss: 1.5587553977966309 grad: 5.206467634953546\n",
      "epoch: 279 loss: 1.5557811260223389 grad: 4.72389850726516\n",
      "epoch: 280 loss: 1.5339105129241943 grad: 3.6088963139402743\n",
      "epoch: 281 loss: 1.5425301790237427 grad: 3.416302522096609\n",
      "epoch: 282 loss: 1.536481261253357 grad: 3.488485686426065\n",
      "epoch: 283 loss: 1.528612494468689 grad: 3.8454830872719605\n",
      "epoch: 284 loss: 1.537308692932129 grad: 3.667535965041188\n",
      "epoch: 285 loss: 1.5291589498519897 grad: 2.696680264863877\n",
      "epoch: 286 loss: 1.5284125804901123 grad: 2.5967007394151036\n",
      "epoch: 287 loss: 1.532325267791748 grad: 3.5236528758043666\n",
      "epoch: 288 loss: 1.5311723947525024 grad: 2.822566067489148\n",
      "epoch: 289 loss: 1.5366612672805786 grad: 3.6802910847133927\n",
      "epoch: 290 loss: 1.5433498620986938 grad: 3.9889608927568405\n",
      "epoch: 291 loss: 1.5431125164031982 grad: 3.2614069375471164\n",
      "epoch: 292 loss: 1.5462325811386108 grad: 5.843313505173082\n",
      "epoch: 293 loss: 1.5573850870132446 grad: 5.063668742590728\n",
      "epoch: 294 loss: 1.5817843675613403 grad: 6.050069669537743\n",
      "epoch: 295 loss: 1.5640404224395752 grad: 4.387246695209023\n",
      "epoch: 296 loss: 1.5531288385391235 grad: 4.148892389811081\n",
      "epoch: 297 loss: 1.5346488952636719 grad: 2.1514537612808673\n",
      "epoch: 298 loss: 1.5334131717681885 grad: 3.686213302584811\n",
      "epoch: 299 loss: 1.538055419921875 grad: 3.762117946242873\n",
      "epoch: 300 loss: 1.5383192300796509 grad: 2.2508857410970426\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 301 loss: 1.5311211347579956 grad: 2.2443539407676334\n",
      "epoch: 302 loss: 1.5213184356689453 grad: 2.4142609348639192\n",
      "epoch: 303 loss: 1.5391360521316528 grad: 4.5083807073863165\n",
      "epoch: 304 loss: 1.5445868968963623 grad: 3.5859779820804807\n",
      "epoch: 305 loss: 1.5358268022537231 grad: 3.4145226660304457\n",
      "epoch: 306 loss: 1.5399137735366821 grad: 4.465428267810145\n",
      "epoch: 307 loss: 1.5345406532287598 grad: 3.5975272729705776\n",
      "epoch: 308 loss: 1.538428783416748 grad: 3.730242577396471\n",
      "epoch: 309 loss: 1.5344595909118652 grad: 3.560721157031224\n",
      "epoch: 310 loss: 1.5273679494857788 grad: 3.765917879741069\n",
      "epoch: 311 loss: 1.5229448080062866 grad: 2.702142803575773\n",
      "epoch: 312 loss: 1.5402400493621826 grad: 3.122023541372763\n",
      "epoch: 313 loss: 1.5326975584030151 grad: 2.7082959786606984\n",
      "epoch: 314 loss: 1.5284403562545776 grad: 2.7946256357355415\n",
      "epoch: 315 loss: 1.5375714302062988 grad: 3.820323683878081\n",
      "epoch: 316 loss: 1.567663311958313 grad: 4.2022018807039325\n",
      "epoch: 317 loss: 1.5376380681991577 grad: 2.5771214890842\n",
      "epoch: 318 loss: 1.5307161808013916 grad: 3.2851039852501924\n",
      "epoch: 319 loss: 1.5330212116241455 grad: 4.355608538830041\n",
      "epoch: 320 loss: 1.5327179431915283 grad: 3.0973229290501942\n",
      "epoch: 321 loss: 1.5408580303192139 grad: 3.239858948010084\n",
      "epoch: 322 loss: 1.5246013402938843 grad: 1.8218556003651378\n",
      "epoch: 323 loss: 1.54135000705719 grad: 5.213609122727497\n",
      "epoch: 324 loss: 1.537336826324463 grad: 3.1152218354309493\n",
      "epoch: 325 loss: 1.5334621667861938 grad: 1.797209520643943\n",
      "epoch: 326 loss: 1.5326600074768066 grad: 2.195688044439432\n",
      "epoch: 327 loss: 1.5235215425491333 grad: 2.8604337154621047\n",
      "epoch: 328 loss: 1.547189712524414 grad: 4.910573523428138\n",
      "epoch: 329 loss: 1.5431486368179321 grad: 3.880934369966222\n",
      "epoch: 330 loss: 1.5357919931411743 grad: 2.6510577238343926\n",
      "epoch: 331 loss: 1.5237966775894165 grad: 3.120340104707083\n",
      "epoch: 332 loss: 1.5600014925003052 grad: 4.068997486869932\n",
      "epoch: 333 loss: 1.5433645248413086 grad: 3.5351317109850333\n",
      "epoch: 334 loss: 1.5496283769607544 grad: 3.3252844095411196\n",
      "epoch: 335 loss: 1.5499682426452637 grad: 3.40425866535973\n",
      "epoch: 336 loss: 1.5362613201141357 grad: 3.333773564152547\n",
      "epoch: 337 loss: 1.543054461479187 grad: 3.5819092842114295\n",
      "epoch: 338 loss: 1.537023901939392 grad: 2.530469439286918\n",
      "epoch: 339 loss: 1.541080117225647 grad: 4.230203654235297\n",
      "epoch: 340 loss: 1.5367931127548218 grad: 3.374421317432274\n",
      "epoch: 341 loss: 1.524475336074829 grad: 1.872254211736846\n",
      "epoch: 342 loss: 1.525255560874939 grad: 3.2271187441311517\n",
      "epoch: 343 loss: 1.53543221950531 grad: 2.956970211132096\n",
      "epoch: 344 loss: 1.5329725742340088 grad: 3.240299153678172\n",
      "epoch: 345 loss: 1.539084553718567 grad: 5.608501983547956\n",
      "epoch: 346 loss: 1.5444529056549072 grad: 2.9444241534184554\n",
      "epoch: 347 loss: 1.5324273109436035 grad: 4.195573467070517\n",
      "epoch: 348 loss: 1.537642478942871 grad: 2.768670977974612\n",
      "epoch: 349 loss: 1.5256168842315674 grad: 4.000196575828708\n",
      "epoch: 350 loss: 1.5523759126663208 grad: 4.089382946639103\n",
      "epoch: 351 loss: 1.540470004081726 grad: 3.7120034034390583\n",
      "epoch: 352 loss: 1.5475492477416992 grad: 3.659240831706402\n",
      "epoch: 353 loss: 1.5356115102767944 grad: 2.004284482079519\n",
      "epoch: 354 loss: 1.5311511754989624 grad: 2.8374861044457593\n",
      "epoch: 355 loss: 1.5433073043823242 grad: 3.9945183723514295\n",
      "epoch: 356 loss: 1.5353367328643799 grad: 3.36835989184751\n",
      "epoch: 357 loss: 1.5258746147155762 grad: 2.5938460953726303\n",
      "epoch: 358 loss: 1.5302287340164185 grad: 2.666898676146705\n",
      "epoch: 359 loss: 1.5232046842575073 grad: 2.516667141416202\n",
      "epoch: 360 loss: 1.537937879562378 grad: 1.4273838880276775\n",
      "epoch: 361 loss: 1.5227822065353394 grad: 2.209627987840831\n",
      "epoch: 362 loss: 1.5396459102630615 grad: 3.8225799732640624\n",
      "epoch: 363 loss: 1.5362871885299683 grad: 2.785700935412029\n",
      "epoch: 364 loss: 1.5326118469238281 grad: 2.6507870315494384\n",
      "epoch: 365 loss: 1.5201371908187866 grad: 2.836680445682956\n",
      "epoch: 366 loss: 1.5394268035888672 grad: 4.1589886978065715\n",
      "epoch: 367 loss: 1.554524302482605 grad: 4.451903415297908\n",
      "epoch: 368 loss: 1.526645302772522 grad: 2.7932096878440484\n",
      "epoch: 369 loss: 1.529312014579773 grad: 5.31182094943451\n",
      "epoch: 370 loss: 1.5470112562179565 grad: 2.691219500675882\n",
      "epoch: 371 loss: 1.534351110458374 grad: 3.737350577616603\n",
      "epoch: 372 loss: 1.522554874420166 grad: 3.0969561151706033\n",
      "epoch: 373 loss: 1.537412166595459 grad: 3.220362078637072\n",
      "epoch: 374 loss: 1.520584225654602 grad: 2.1698540617129747\n",
      "epoch: 375 loss: 1.5240565538406372 grad: 3.516654893139321\n",
      "epoch: 376 loss: 1.5345208644866943 grad: 2.910831215996629\n",
      "epoch: 377 loss: 1.526404619216919 grad: 2.2385185386780955\n",
      "epoch: 378 loss: 1.5396924018859863 grad: 3.068230297523939\n",
      "epoch: 379 loss: 1.5377241373062134 grad: 3.0730091198330367\n",
      "epoch: 380 loss: 1.5241680145263672 grad: 2.203829855467409\n",
      "epoch: 381 loss: 1.5368305444717407 grad: 3.3634582255033156\n",
      "epoch: 382 loss: 1.5431245565414429 grad: 3.4926738632291956\n",
      "epoch: 383 loss: 1.534258484840393 grad: 3.3735786553586142\n",
      "epoch: 384 loss: 1.5549979209899902 grad: 3.6806715494520925\n",
      "epoch: 385 loss: 1.550856113433838 grad: 3.2918316227318516\n",
      "epoch: 386 loss: 1.5350338220596313 grad: 3.531866192892527\n",
      "epoch: 387 loss: 1.5311869382858276 grad: 2.953705169485772\n",
      "epoch: 388 loss: 1.537270426750183 grad: 4.446581349074946\n",
      "epoch: 389 loss: 1.5531821250915527 grad: 2.7006483438755975\n",
      "epoch: 390 loss: 1.5312399864196777 grad: 3.813220847669839\n",
      "epoch: 391 loss: 1.5507502555847168 grad: 4.390665431304989\n",
      "epoch: 392 loss: 1.5697517395019531 grad: 4.440136993681119\n",
      "epoch: 393 loss: 1.5478661060333252 grad: 4.414412110229534\n",
      "epoch: 394 loss: 1.5426661968231201 grad: 3.689565585065229\n",
      "epoch: 395 loss: 1.5468592643737793 grad: 2.1324483012941635\n",
      "epoch: 396 loss: 1.5285297632217407 grad: 2.648597845889718\n",
      "epoch: 397 loss: 1.5314568281173706 grad: 3.3799982931954675\n",
      "epoch: 398 loss: 1.5302658081054688 grad: 2.4700254932384285\n",
      "epoch: 399 loss: 1.5211907625198364 grad: 2.270405065546179\n",
      "epoch: 400 loss: 1.5298335552215576 grad: 1.8687352065802263\n",
      "epoch: 401 loss: 1.5365641117095947 grad: 4.001508582918341\n",
      "epoch: 402 loss: 1.5190390348434448 grad: 2.543162731473204\n",
      "epoch: 403 loss: 1.5250201225280762 grad: 3.5471136040699998\n",
      "epoch: 404 loss: 1.5304068326950073 grad: 2.9241914407370526\n",
      "epoch: 405 loss: 1.5275452136993408 grad: 3.0821797616565743\n",
      "epoch: 406 loss: 1.523829460144043 grad: 2.660883397643113\n",
      "epoch: 407 loss: 1.5229451656341553 grad: 2.9518374415477973\n",
      "epoch: 408 loss: 1.5376062393188477 grad: 3.564181859192918\n",
      "epoch: 409 loss: 1.54717218875885 grad: 3.83808970314335\n",
      "epoch: 410 loss: 1.5309436321258545 grad: 2.2439082554199934\n",
      "epoch: 411 loss: 1.535503625869751 grad: 2.683898754508237\n",
      "epoch: 412 loss: 1.5270429849624634 grad: 2.6944298758682477\n",
      "epoch: 413 loss: 1.514493703842163 grad: 1.9842719816591274\n",
      "epoch: 414 loss: 1.523971438407898 grad: 2.8570165380719117\n",
      "epoch: 415 loss: 1.525429129600525 grad: 1.7855043019640076\n",
      "epoch: 416 loss: 1.5230458974838257 grad: 2.6586914066233303\n",
      "epoch: 417 loss: 1.5263397693634033 grad: 2.7511898707147298\n",
      "epoch: 418 loss: 1.5142792463302612 grad: 1.3450328140441616\n",
      "epoch: 419 loss: 1.5287282466888428 grad: 3.175577295981248\n",
      "epoch: 420 loss: 1.5344371795654297 grad: 3.1208721700548447\n",
      "epoch: 421 loss: 1.5253561735153198 grad: 3.305176252970641\n",
      "epoch: 422 loss: 1.5459877252578735 grad: 4.681095734359629\n",
      "epoch: 423 loss: 1.5310137271881104 grad: 2.2052144546189942\n",
      "epoch: 424 loss: 1.5235588550567627 grad: 2.675283198890247\n",
      "epoch: 425 loss: 1.5235742330551147 grad: 3.7735265956146677\n",
      "epoch: 426 loss: 1.5276107788085938 grad: 2.267008258370399\n",
      "epoch: 427 loss: 1.5243456363677979 grad: 2.808321538817661\n",
      "epoch: 428 loss: 1.5417066812515259 grad: 2.000678025848464\n",
      "epoch: 429 loss: 1.5316355228424072 grad: 4.628347925766221\n",
      "epoch: 430 loss: 1.554111123085022 grad: 3.6694168655829102\n",
      "epoch: 431 loss: 1.5244659185409546 grad: 2.1704663721679385\n",
      "epoch: 432 loss: 1.530021071434021 grad: 4.108341559408429\n",
      "epoch: 433 loss: 1.5271772146224976 grad: 2.794790526430464\n",
      "epoch: 434 loss: 1.5414401292800903 grad: 3.8493366078700544\n",
      "epoch: 435 loss: 1.5353575944900513 grad: 2.245286403567261\n",
      "epoch: 436 loss: 1.5246878862380981 grad: 2.8254573639299214\n",
      "epoch: 437 loss: 1.5291683673858643 grad: 2.9151103423864697\n",
      "epoch: 438 loss: 1.5277330875396729 grad: 2.976023424118874\n",
      "epoch: 439 loss: 1.5176246166229248 grad: 2.364009930801664\n",
      "epoch: 440 loss: 1.5273380279541016 grad: 3.3456601952695335\n",
      "epoch: 441 loss: 1.5350441932678223 grad: 2.844293640339551\n",
      "epoch: 442 loss: 1.532293677330017 grad: 3.0136566195515724\n",
      "epoch: 443 loss: 1.5388362407684326 grad: 3.296183284846072\n",
      "epoch: 444 loss: 1.5408570766448975 grad: 2.838757270744801\n",
      "epoch: 445 loss: 1.5899940729141235 grad: 4.441844936054146\n",
      "epoch: 446 loss: 1.554879069328308 grad: 4.4450466059277085\n",
      "epoch: 447 loss: 1.547284483909607 grad: 4.472645575971307\n",
      "epoch: 448 loss: 1.5257041454315186 grad: 3.1584346682081805\n",
      "epoch: 449 loss: 1.5236291885375977 grad: 2.949746327273102\n",
      "epoch: 450 loss: 1.5189543962478638 grad: 2.9205937773368613\n",
      "epoch: 451 loss: 1.5206140279769897 grad: 2.561890540414092\n",
      "epoch: 452 loss: 1.5281661748886108 grad: 2.6908234690778774\n",
      "epoch: 453 loss: 1.536188006401062 grad: 3.818237508683665\n",
      "epoch: 454 loss: 1.529266357421875 grad: 3.10732901325383\n",
      "epoch: 455 loss: 1.5595530271530151 grad: 4.137455229367944\n",
      "epoch: 456 loss: 1.5439997911453247 grad: 2.9336449902836894\n",
      "epoch: 457 loss: 1.5325944423675537 grad: 3.3883768678233293\n",
      "epoch: 458 loss: 1.5465738773345947 grad: 4.292179955517084\n",
      "epoch: 459 loss: 1.5261317491531372 grad: 2.7839560510273182\n",
      "epoch: 460 loss: 1.5269966125488281 grad: 3.8115267874861685\n",
      "epoch: 461 loss: 1.5229203701019287 grad: 2.4879335965442464\n",
      "epoch: 462 loss: 1.5284792184829712 grad: 2.856360139543217\n",
      "epoch: 463 loss: 1.536578893661499 grad: 3.9673662869816053\n",
      "epoch: 464 loss: 1.526947259902954 grad: 3.4449787792933386\n",
      "epoch: 465 loss: 1.5312390327453613 grad: 2.301193531911857\n",
      "epoch: 466 loss: 1.528047800064087 grad: 2.7062262267971673\n",
      "epoch: 467 loss: 1.5221426486968994 grad: 2.160779356499049\n",
      "epoch: 468 loss: 1.528835415840149 grad: 2.414179365600656\n",
      "epoch: 469 loss: 1.5270307064056396 grad: 2.1449959016764333\n",
      "epoch: 470 loss: 1.5111894607543945 grad: 1.3450285115274658\n",
      "epoch: 471 loss: 1.516476035118103 grad: 2.3586711229336688\n",
      "epoch: 472 loss: 1.5340094566345215 grad: 4.127208491857518\n",
      "epoch: 473 loss: 1.5337026119232178 grad: 3.034323480603064\n",
      "epoch: 474 loss: 1.547848105430603 grad: 3.96771959638972\n",
      "epoch: 475 loss: 1.5461572408676147 grad: 5.16536864640282\n",
      "epoch: 476 loss: 1.5355771780014038 grad: 3.18256998432993\n",
      "epoch: 477 loss: 1.541210651397705 grad: 3.0767096615539327\n",
      "epoch: 478 loss: 1.5336483716964722 grad: 2.628950582145568\n",
      "epoch: 479 loss: 1.5224560499191284 grad: 2.0089960834684426\n",
      "epoch: 480 loss: 1.519831895828247 grad: 2.236177406708049\n",
      "epoch: 481 loss: 1.5223034620285034 grad: 2.900334732166083\n",
      "epoch: 482 loss: 1.5377311706542969 grad: 4.098795260895659\n",
      "epoch: 483 loss: 1.5320289134979248 grad: 2.6724550786789796\n",
      "epoch: 484 loss: 1.5282989740371704 grad: 2.1339753130792447\n",
      "epoch: 485 loss: 1.515283226966858 grad: 1.9456728825515603\n",
      "epoch: 486 loss: 1.5219277143478394 grad: 2.5879883814908675\n",
      "epoch: 487 loss: 1.528867244720459 grad: 2.284114920027022\n",
      "epoch: 488 loss: 1.5225023031234741 grad: 2.6225477278003937\n",
      "epoch: 489 loss: 1.5205187797546387 grad: 2.194866390474482\n",
      "epoch: 490 loss: 1.5209869146347046 grad: 2.5307165199333337\n",
      "epoch: 491 loss: 1.5414830446243286 grad: 2.724253656107119\n",
      "epoch: 492 loss: 1.5343669652938843 grad: 3.3125321885776144\n",
      "epoch: 493 loss: 1.5444104671478271 grad: 3.6187344792764367\n",
      "epoch: 494 loss: 1.553085207939148 grad: 3.9001991534853158\n",
      "epoch: 495 loss: 1.5239911079406738 grad: 2.684033755997605\n",
      "epoch: 496 loss: 1.5276167392730713 grad: 2.824826110131538\n",
      "epoch: 497 loss: 1.5546497106552124 grad: 3.374540701926685\n",
      "epoch: 498 loss: 1.5318654775619507 grad: 3.7045952273137175\n",
      "epoch: 499 loss: 1.5304875373840332 grad: 3.3027659752796508\n",
      "1.837291680276394\n",
      "epoch: 0 loss: 2.3025572299957275 grad: 1.3136689318639656\n",
      "epoch: 1 loss: 2.3031020164489746 grad: 1.3049211665758833\n",
      "epoch: 2 loss: 2.3025412559509277 grad: 1.312865707790479\n",
      "epoch: 3 loss: 2.3026838302612305 grad: 1.3122697618257786\n",
      "epoch: 4 loss: 2.3030385971069336 grad: 1.3153587623170415\n",
      "epoch: 5 loss: 2.302725076675415 grad: 1.3101176683225535\n",
      "epoch: 6 loss: 2.3030357360839844 grad: 1.304217409749057\n",
      "epoch: 7 loss: 2.3027584552764893 grad: 1.3188114643673456\n",
      "epoch: 8 loss: 2.302671194076538 grad: 1.3064490101108002\n",
      "epoch: 9 loss: 2.3023316860198975 grad: 1.3209612582133905\n",
      "epoch: 10 loss: 2.3023242950439453 grad: 1.3160774718068304\n",
      "epoch: 11 loss: 2.3024723529815674 grad: 1.3184946047249324\n",
      "epoch: 12 loss: 2.302893877029419 grad: 1.3053156131313048\n",
      "epoch: 13 loss: 2.302400827407837 grad: 1.319994108270972\n",
      "epoch: 14 loss: 2.3028059005737305 grad: 1.3032988792041404\n",
      "epoch: 15 loss: 2.3029491901397705 grad: 1.3033617243580964\n",
      "epoch: 16 loss: 2.303170680999756 grad: 1.3045978224374324\n",
      "epoch: 17 loss: 2.3028676509857178 grad: 1.3074274339458152\n",
      "epoch: 18 loss: 2.303103446960449 grad: 1.295083306254893\n",
      "epoch: 19 loss: 2.3025290966033936 grad: 1.3050417473561884\n",
      "epoch: 20 loss: 2.302600145339966 grad: 1.3124665283756922\n",
      "epoch: 21 loss: 2.3023529052734375 grad: 1.3135203777901119\n",
      "epoch: 22 loss: 2.3022143840789795 grad: 1.31157489011382\n",
      "epoch: 23 loss: 2.302546501159668 grad: 1.308366570218895\n",
      "epoch: 24 loss: 2.3024351596832275 grad: 1.3231069789478733\n",
      "epoch: 25 loss: 2.3026833534240723 grad: 1.3002473403208166\n",
      "epoch: 26 loss: 2.303483486175537 grad: 1.288844022108981\n",
      "epoch: 27 loss: 2.302269220352173 grad: 1.3108036811149397\n",
      "epoch: 28 loss: 2.3023486137390137 grad: 1.3048165639130664\n",
      "epoch: 29 loss: 2.303135633468628 grad: 1.2921233631500473\n",
      "epoch: 30 loss: 2.3025901317596436 grad: 1.3113190984844953\n",
      "epoch: 31 loss: 2.302314281463623 grad: 1.312659690601914\n",
      "epoch: 32 loss: 2.3029816150665283 grad: 1.3021515143281293\n",
      "epoch: 33 loss: 2.302513599395752 grad: 1.3141665670813785\n",
      "epoch: 34 loss: 2.3026013374328613 grad: 1.3089161135814344\n",
      "epoch: 35 loss: 2.3025825023651123 grad: 1.3006620291317443\n",
      "epoch: 36 loss: 2.3028221130371094 grad: 1.3020630486675404\n",
      "epoch: 37 loss: 2.3029043674468994 grad: 1.2938917087712547\n",
      "epoch: 38 loss: 2.302438259124756 grad: 1.3110227098056515\n",
      "epoch: 39 loss: 2.3031835556030273 grad: 1.29545911216724\n",
      "epoch: 40 loss: 2.3029942512512207 grad: 1.2864167458758438\n",
      "epoch: 41 loss: 2.3024919033050537 grad: 1.297823572915698\n",
      "epoch: 42 loss: 2.3022501468658447 grad: 1.2995207465756389\n",
      "epoch: 43 loss: 2.302513599395752 grad: 1.304942703077806\n",
      "epoch: 44 loss: 2.3019535541534424 grad: 1.311061558941941\n",
      "epoch: 45 loss: 2.3033740520477295 grad: 1.2924133542119451\n",
      "epoch: 46 loss: 2.3020520210266113 grad: 1.3049785760508494\n",
      "epoch: 47 loss: 2.3022103309631348 grad: 1.3039965423559474\n",
      "epoch: 48 loss: 2.302835702896118 grad: 1.2957324676219344\n",
      "epoch: 49 loss: 2.3027398586273193 grad: 1.3035481567143477\n",
      "epoch: 50 loss: 2.3023931980133057 grad: 1.3056793600849306\n",
      "epoch: 51 loss: 2.3027374744415283 grad: 1.3028074548069744\n",
      "epoch: 52 loss: 2.302847385406494 grad: 1.2999736100180252\n",
      "epoch: 53 loss: 2.302670955657959 grad: 1.2988263611175446\n",
      "epoch: 54 loss: 2.3029417991638184 grad: 1.2989063725958296\n",
      "epoch: 55 loss: 2.302717924118042 grad: 1.2900620264163802\n",
      "epoch: 56 loss: 2.3023428916931152 grad: 1.2914550708263137\n",
      "epoch: 57 loss: 2.3022499084472656 grad: 1.293825452775872\n",
      "epoch: 58 loss: 2.3023087978363037 grad: 1.2913394341954874\n",
      "epoch: 59 loss: 2.302651882171631 grad: 1.3064493841218157\n",
      "epoch: 60 loss: 2.3027896881103516 grad: 1.2928530178125208\n",
      "epoch: 61 loss: 2.30254864692688 grad: 1.2969385046929505\n",
      "epoch: 62 loss: 2.3027539253234863 grad: 1.2917591945068645\n",
      "epoch: 63 loss: 2.3026740550994873 grad: 1.3058256049093508\n",
      "epoch: 64 loss: 2.3027889728546143 grad: 1.283530100664523\n",
      "epoch: 65 loss: 2.3026068210601807 grad: 1.2908018542017552\n",
      "epoch: 66 loss: 2.3025624752044678 grad: 1.2963093523793514\n",
      "epoch: 67 loss: 2.3024489879608154 grad: 1.299209215231092\n",
      "epoch: 68 loss: 2.3026628494262695 grad: 1.2992888568874656\n",
      "epoch: 69 loss: 2.3028295040130615 grad: 1.2888092861311244\n",
      "epoch: 70 loss: 2.3031744956970215 grad: 1.2856821600857766\n",
      "epoch: 71 loss: 2.302654266357422 grad: 1.2957050597760826\n",
      "epoch: 72 loss: 2.3026793003082275 grad: 1.2900356942037534\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 73 loss: 2.30264949798584 grad: 1.295970885515479\n",
      "epoch: 74 loss: 2.3025403022766113 grad: 1.2970480021876505\n",
      "epoch: 75 loss: 2.3030107021331787 grad: 1.283244512049437\n",
      "epoch: 76 loss: 2.30263614654541 grad: 1.292804146015514\n",
      "epoch: 77 loss: 2.3032190799713135 grad: 1.282929292689669\n",
      "epoch: 78 loss: 2.3024470806121826 grad: 1.2942913944134489\n",
      "epoch: 79 loss: 2.302464723587036 grad: 1.2947071516934399\n",
      "epoch: 80 loss: 2.302145481109619 grad: 1.2973662955217093\n",
      "epoch: 81 loss: 2.303067207336426 grad: 1.282100489570035\n",
      "epoch: 82 loss: 2.3022568225860596 grad: 1.2911621082337603\n",
      "epoch: 83 loss: 2.3022170066833496 grad: 1.2965543195087876\n",
      "epoch: 84 loss: 2.3027100563049316 grad: 1.2929712611283841\n",
      "epoch: 85 loss: 2.302520513534546 grad: 1.2905206205378774\n",
      "epoch: 86 loss: 2.302206039428711 grad: 1.2983478526880463\n",
      "epoch: 87 loss: 2.302372932434082 grad: 1.3009601010357044\n",
      "epoch: 88 loss: 2.302851915359497 grad: 1.2817681013987148\n",
      "epoch: 89 loss: 2.3025014400482178 grad: 1.2913230382061254\n",
      "epoch: 90 loss: 2.301989793777466 grad: 1.3002355710699385\n",
      "epoch: 91 loss: 2.3020730018615723 grad: 1.2949519109143506\n",
      "epoch: 92 loss: 2.302478075027466 grad: 1.2842322503741357\n",
      "epoch: 93 loss: 2.3025121688842773 grad: 1.2918521949877253\n",
      "epoch: 94 loss: 2.3022799491882324 grad: 1.2918156690004887\n",
      "epoch: 95 loss: 2.302861213684082 grad: 1.2857199244363795\n",
      "epoch: 96 loss: 2.3024468421936035 grad: 1.2962617185687468\n",
      "epoch: 97 loss: 2.3024630546569824 grad: 1.2950678538726939\n",
      "epoch: 98 loss: 2.3023951053619385 grad: 1.292083027122158\n",
      "epoch: 99 loss: 2.301830530166626 grad: 1.3100907194173141\n",
      "epoch: 100 loss: 2.302208185195923 grad: 1.2907608833278543\n",
      "epoch: 101 loss: 2.3025460243225098 grad: 1.2902779839470953\n",
      "epoch: 102 loss: 2.302938938140869 grad: 1.2804077173110158\n",
      "epoch: 103 loss: 2.302299976348877 grad: 1.2884958091428473\n",
      "epoch: 104 loss: 2.3022279739379883 grad: 1.2943754402739513\n",
      "epoch: 105 loss: 2.302584171295166 grad: 1.292040718656536\n",
      "epoch: 106 loss: 2.3023345470428467 grad: 1.2957319146288293\n",
      "epoch: 107 loss: 2.3022027015686035 grad: 1.3011262757271262\n",
      "epoch: 108 loss: 2.3025870323181152 grad: 1.2893945704517324\n",
      "epoch: 109 loss: 2.302248001098633 grad: 1.291773647044061\n",
      "epoch: 110 loss: 2.3020718097686768 grad: 1.2951893826747047\n",
      "epoch: 111 loss: 2.301989793777466 grad: 1.294118505263228\n",
      "epoch: 112 loss: 2.3031654357910156 grad: 1.2814213339265228\n",
      "epoch: 113 loss: 2.302140712738037 grad: 1.2913963194762814\n",
      "epoch: 114 loss: 2.3022255897521973 grad: 1.2873395860864085\n",
      "epoch: 115 loss: 2.3020403385162354 grad: 1.30166971871245\n",
      "epoch: 116 loss: 2.302177906036377 grad: 1.300819134864483\n",
      "epoch: 117 loss: 2.3020451068878174 grad: 1.29288472983587\n",
      "epoch: 118 loss: 2.3023622035980225 grad: 1.2972702905018296\n",
      "epoch: 119 loss: 2.3019795417785645 grad: 1.299550216504565\n",
      "epoch: 120 loss: 2.302478075027466 grad: 1.2865361458610831\n",
      "epoch: 121 loss: 2.3020572662353516 grad: 1.2900889085842266\n",
      "epoch: 122 loss: 2.3023841381073 grad: 1.2974014312882598\n",
      "epoch: 123 loss: 2.301983118057251 grad: 1.298765176367606\n",
      "epoch: 124 loss: 2.302887201309204 grad: 1.2934061616847647\n",
      "epoch: 125 loss: 2.30226731300354 grad: 1.2992976595230017\n",
      "epoch: 126 loss: 2.30265212059021 grad: 1.2938393567382018\n",
      "epoch: 127 loss: 2.3021464347839355 grad: 1.2932837499316694\n",
      "epoch: 128 loss: 2.3018951416015625 grad: 1.3108150580960756\n",
      "epoch: 129 loss: 2.3023502826690674 grad: 1.2957268951142886\n",
      "epoch: 130 loss: 2.3020575046539307 grad: 1.296872533783908\n",
      "epoch: 131 loss: 2.3018510341644287 grad: 1.2973077357192302\n",
      "epoch: 132 loss: 2.302515983581543 grad: 1.2855980332094497\n",
      "epoch: 133 loss: 2.3023288249969482 grad: 1.2888000322993667\n",
      "epoch: 134 loss: 2.302196979522705 grad: 1.2983926513697952\n",
      "epoch: 135 loss: 2.3026504516601562 grad: 1.290804481327844\n",
      "epoch: 136 loss: 2.302116870880127 grad: 1.2975865437349836\n",
      "epoch: 137 loss: 2.301797389984131 grad: 1.2985717391739378\n",
      "epoch: 138 loss: 2.302760362625122 grad: 1.2906901346730246\n",
      "epoch: 139 loss: 2.3018970489501953 grad: 1.2906193262897432\n",
      "epoch: 140 loss: 2.3018040657043457 grad: 1.2944630706065616\n",
      "epoch: 141 loss: 2.3020718097686768 grad: 1.3000868717966128\n",
      "epoch: 142 loss: 2.302452564239502 grad: 1.289069098677294\n",
      "epoch: 143 loss: 2.3022680282592773 grad: 1.2967453705486915\n",
      "epoch: 144 loss: 2.3022563457489014 grad: 1.2868354054360045\n",
      "epoch: 145 loss: 2.3020107746124268 grad: 1.3010659488952823\n",
      "epoch: 146 loss: 2.301570177078247 grad: 1.2969267171371492\n",
      "epoch: 147 loss: 2.302126169204712 grad: 1.2917598338986171\n",
      "epoch: 148 loss: 2.3018136024475098 grad: 1.3033336340930195\n",
      "epoch: 149 loss: 2.3026890754699707 grad: 1.3024813374947934\n",
      "epoch: 150 loss: 2.3020248413085938 grad: 1.297518207931832\n",
      "epoch: 151 loss: 2.301771640777588 grad: 1.2966427183802431\n",
      "epoch: 152 loss: 2.302290201187134 grad: 1.2867893909754615\n",
      "epoch: 153 loss: 2.3020942211151123 grad: 1.2932319031392654\n",
      "epoch: 154 loss: 2.302222967147827 grad: 1.2983206034201893\n",
      "epoch: 155 loss: 2.3025741577148438 grad: 1.2943280171566007\n",
      "epoch: 156 loss: 2.301595687866211 grad: 1.3141907968111188\n",
      "epoch: 157 loss: 2.3025014400482178 grad: 1.2985331564661233\n",
      "epoch: 158 loss: 2.302771806716919 grad: 1.2871966172889289\n",
      "epoch: 159 loss: 2.302548408508301 grad: 1.2950909108104598\n",
      "epoch: 160 loss: 2.301513433456421 grad: 1.3181887438801665\n",
      "epoch: 161 loss: 2.3024444580078125 grad: 1.2913519857517843\n",
      "epoch: 162 loss: 2.3026225566864014 grad: 1.2990890265948745\n",
      "epoch: 163 loss: 2.302227258682251 grad: 1.2977727824223362\n",
      "epoch: 164 loss: 2.302478790283203 grad: 1.298171407914543\n",
      "epoch: 165 loss: 2.302065849304199 grad: 1.3035770345050546\n",
      "epoch: 166 loss: 2.30230975151062 grad: 1.2848514498762107\n",
      "epoch: 167 loss: 2.302138328552246 grad: 1.2955428711286494\n",
      "epoch: 168 loss: 2.3021399974823 grad: 1.2947309219319048\n",
      "epoch: 169 loss: 2.302353858947754 grad: 1.297025668767414\n",
      "epoch: 170 loss: 2.3024373054504395 grad: 1.3044564998671708\n",
      "epoch: 171 loss: 2.302199125289917 grad: 1.3029143175328268\n",
      "epoch: 172 loss: 2.302344560623169 grad: 1.308018023780148\n",
      "epoch: 173 loss: 2.3020429611206055 grad: 1.3018249140420397\n",
      "epoch: 174 loss: 2.3023290634155273 grad: 1.3005951691773676\n",
      "epoch: 175 loss: 2.3020496368408203 grad: 1.2991307331729562\n",
      "epoch: 176 loss: 2.302109479904175 grad: 1.3043088288294034\n",
      "epoch: 177 loss: 2.3022429943084717 grad: 1.3005130559849065\n",
      "epoch: 178 loss: 2.302109718322754 grad: 1.3007880513434342\n",
      "epoch: 179 loss: 2.302123785018921 grad: 1.3043120059051685\n",
      "epoch: 180 loss: 2.3017008304595947 grad: 1.308841785735687\n",
      "epoch: 181 loss: 2.3026819229125977 grad: 1.2987584124304472\n",
      "epoch: 182 loss: 2.302238941192627 grad: 1.305486379076712\n",
      "epoch: 183 loss: 2.301894187927246 grad: 1.3122568295230084\n",
      "epoch: 184 loss: 2.301745891571045 grad: 1.3142122672833798\n",
      "epoch: 185 loss: 2.30178165435791 grad: 1.3128044992419226\n",
      "epoch: 186 loss: 2.3022124767303467 grad: 1.302863101591356\n",
      "epoch: 187 loss: 2.3022348880767822 grad: 1.297716077095607\n",
      "epoch: 188 loss: 2.301791191101074 grad: 1.3127101662934624\n",
      "epoch: 189 loss: 2.3016600608825684 grad: 1.3124465977566109\n",
      "epoch: 190 loss: 2.30246639251709 grad: 1.3005296314331067\n",
      "epoch: 191 loss: 2.3019299507141113 grad: 1.3116914166603237\n",
      "epoch: 192 loss: 2.301837682723999 grad: 1.3149641904506892\n",
      "epoch: 193 loss: 2.3013696670532227 grad: 1.325793920879415\n",
      "epoch: 194 loss: 2.3008759021759033 grad: 1.3318866889144012\n",
      "epoch: 195 loss: 2.3012876510620117 grad: 1.3228575207444557\n",
      "epoch: 196 loss: 2.302243947982788 grad: 1.2985727253114983\n",
      "epoch: 197 loss: 2.30230975151062 grad: 1.3061270525176374\n",
      "epoch: 198 loss: 2.3021624088287354 grad: 1.3088807362734178\n",
      "epoch: 199 loss: 2.3023290634155273 grad: 1.3144422340306587\n",
      "epoch: 200 loss: 2.301347017288208 grad: 1.336093131221816\n",
      "epoch: 201 loss: 2.301788806915283 grad: 1.3254579213994837\n",
      "epoch: 202 loss: 2.3012781143188477 grad: 1.3359398284542656\n",
      "epoch: 203 loss: 2.301710844039917 grad: 1.3236410387566253\n",
      "epoch: 204 loss: 2.302112340927124 grad: 1.3113148805615122\n",
      "epoch: 205 loss: 2.302011728286743 grad: 1.311862328769787\n",
      "epoch: 206 loss: 2.300964593887329 grad: 1.3382928575174735\n",
      "epoch: 207 loss: 2.3018624782562256 grad: 1.3256187312552588\n",
      "epoch: 208 loss: 2.3021183013916016 grad: 1.3081169115427498\n",
      "epoch: 209 loss: 2.301698684692383 grad: 1.3175760504571603\n",
      "epoch: 210 loss: 2.3016104698181152 grad: 1.3223694023225339\n",
      "epoch: 211 loss: 2.301724910736084 grad: 1.3305044547795126\n",
      "epoch: 212 loss: 2.3020362854003906 grad: 1.3311597720390955\n",
      "epoch: 213 loss: 2.3014910221099854 grad: 1.3328965419796222\n",
      "epoch: 214 loss: 2.301290988922119 grad: 1.3311355238861686\n",
      "epoch: 215 loss: 2.302216053009033 grad: 1.3157870674594527\n",
      "epoch: 216 loss: 2.30204176902771 grad: 1.3247440967871438\n",
      "epoch: 217 loss: 2.301373243331909 grad: 1.3413553706255728\n",
      "epoch: 218 loss: 2.301757574081421 grad: 1.3300748401642999\n",
      "epoch: 219 loss: 2.301057815551758 grad: 1.3383763910378403\n",
      "epoch: 220 loss: 2.301941156387329 grad: 1.3346659090288633\n",
      "epoch: 221 loss: 2.301356792449951 grad: 1.3434609342662116\n",
      "epoch: 222 loss: 2.3010177612304688 grad: 1.3461395405539651\n",
      "epoch: 223 loss: 2.301541805267334 grad: 1.3410903501586753\n",
      "epoch: 224 loss: 2.3017332553863525 grad: 1.3264343006562234\n",
      "epoch: 225 loss: 2.3013522624969482 grad: 1.3500392960776235\n",
      "epoch: 226 loss: 2.300908327102661 grad: 1.3678061119373148\n",
      "epoch: 227 loss: 2.3012900352478027 grad: 1.3495252322874933\n",
      "epoch: 228 loss: 2.300692081451416 grad: 1.3722227289625961\n",
      "epoch: 229 loss: 2.3015944957733154 grad: 1.3618237133219189\n",
      "epoch: 230 loss: 2.300931692123413 grad: 1.3607697678814894\n",
      "epoch: 231 loss: 2.3016443252563477 grad: 1.3642501787389703\n",
      "epoch: 232 loss: 2.3015615940093994 grad: 1.3556017009744656\n",
      "epoch: 233 loss: 2.3015975952148438 grad: 1.3623404453456815\n",
      "epoch: 234 loss: 2.3007185459136963 grad: 1.3803506594905186\n",
      "epoch: 235 loss: 2.300701141357422 grad: 1.3809451773718355\n",
      "epoch: 236 loss: 2.3013288974761963 grad: 1.3689371065000102\n",
      "epoch: 237 loss: 2.301194667816162 grad: 1.379160871442836\n",
      "epoch: 238 loss: 2.300974130630493 grad: 1.3789416554509588\n",
      "epoch: 239 loss: 2.300568103790283 grad: 1.3990579018302793\n",
      "epoch: 240 loss: 2.301429033279419 grad: 1.3752126294291682\n",
      "epoch: 241 loss: 2.300132989883423 grad: 1.4212100692721645\n",
      "epoch: 242 loss: 2.301006317138672 grad: 1.393276488184855\n",
      "epoch: 243 loss: 2.300410032272339 grad: 1.4125144380931964\n",
      "epoch: 244 loss: 2.3012771606445312 grad: 1.3978269149305387\n",
      "epoch: 245 loss: 2.300926685333252 grad: 1.3931841131684088\n",
      "epoch: 246 loss: 2.3004508018493652 grad: 1.409893516015025\n",
      "epoch: 247 loss: 2.2996907234191895 grad: 1.4356089270681083\n",
      "epoch: 248 loss: 2.3012351989746094 grad: 1.3995642956616061\n",
      "epoch: 249 loss: 2.3007266521453857 grad: 1.417999692730576\n",
      "epoch: 250 loss: 2.3004441261291504 grad: 1.4237134391903907\n",
      "epoch: 251 loss: 2.3000714778900146 grad: 1.4341032005502798\n",
      "epoch: 252 loss: 2.3001530170440674 grad: 1.4356080860542577\n",
      "epoch: 253 loss: 2.3010566234588623 grad: 1.4242128299268346\n",
      "epoch: 254 loss: 2.300898790359497 grad: 1.4289668570586762\n",
      "epoch: 255 loss: 2.30098295211792 grad: 1.4476145158118998\n",
      "epoch: 256 loss: 2.2998242378234863 grad: 1.470797426747306\n",
      "epoch: 257 loss: 2.299837827682495 grad: 1.4719703292533282\n",
      "epoch: 258 loss: 2.300213098526001 grad: 1.4688563875332918\n",
      "epoch: 259 loss: 2.3001041412353516 grad: 1.4787572063339343\n",
      "epoch: 260 loss: 2.2994580268859863 grad: 1.4941312240580806\n",
      "epoch: 261 loss: 2.3005826473236084 grad: 1.486529811996863\n",
      "epoch: 262 loss: 2.2992806434631348 grad: 1.5151379400742284\n",
      "epoch: 263 loss: 2.29978609085083 grad: 1.5065424344594782\n",
      "epoch: 264 loss: 2.299384832382202 grad: 1.5186594445738824\n",
      "epoch: 265 loss: 2.2992782592773438 grad: 1.5433599997962277\n",
      "epoch: 266 loss: 2.2988364696502686 grad: 1.5505563178901665\n",
      "epoch: 267 loss: 2.2990479469299316 grad: 1.561991448652753\n",
      "epoch: 268 loss: 2.298670768737793 grad: 1.5681523399830366\n",
      "epoch: 269 loss: 2.2979559898376465 grad: 1.6125206550849336\n",
      "epoch: 270 loss: 2.297757387161255 grad: 1.6312792728791783\n",
      "epoch: 271 loss: 2.29823637008667 grad: 1.6292402874234886\n",
      "epoch: 272 loss: 2.2986197471618652 grad: 1.6241746055745772\n",
      "epoch: 273 loss: 2.297147512435913 grad: 1.6542104647110498\n",
      "epoch: 274 loss: 2.298220157623291 grad: 1.6823962079693697\n",
      "epoch: 275 loss: 2.2969982624053955 grad: 1.7131247784247592\n",
      "epoch: 276 loss: 2.297501802444458 grad: 1.7079907426876682\n",
      "epoch: 277 loss: 2.2961552143096924 grad: 1.7722587126588065\n",
      "epoch: 278 loss: 2.295797348022461 grad: 1.7911553788423864\n",
      "epoch: 279 loss: 2.2953386306762695 grad: 1.8404534736552114\n",
      "epoch: 280 loss: 2.295725107192993 grad: 1.8166802871514052\n",
      "epoch: 281 loss: 2.294910430908203 grad: 1.8902923111426866\n",
      "epoch: 282 loss: 2.294487953186035 grad: 1.866363724693656\n",
      "epoch: 283 loss: 2.293519973754883 grad: 1.9339658330094867\n",
      "epoch: 284 loss: 2.294318914413452 grad: 1.9396006762759672\n",
      "epoch: 285 loss: 2.292768955230713 grad: 1.9775775715243071\n",
      "epoch: 286 loss: 2.2919507026672363 grad: 2.0359800911567634\n",
      "epoch: 287 loss: 2.2919504642486572 grad: 2.0932472157107282\n",
      "epoch: 288 loss: 2.2910714149475098 grad: 2.1162935255265367\n",
      "epoch: 289 loss: 2.2887847423553467 grad: 2.154334813291724\n",
      "epoch: 290 loss: 2.288637638092041 grad: 2.1980051686913367\n",
      "epoch: 291 loss: 2.287672996520996 grad: 2.196589253517607\n",
      "epoch: 292 loss: 2.2850470542907715 grad: 2.2485306890171377\n",
      "epoch: 293 loss: 2.283604621887207 grad: 2.265213077858327\n",
      "epoch: 294 loss: 2.2808969020843506 grad: 2.316062791151039\n",
      "epoch: 295 loss: 2.279719352722168 grad: 2.273803029394162\n",
      "epoch: 296 loss: 2.2793359756469727 grad: 2.2822101083547173\n",
      "epoch: 297 loss: 2.277538776397705 grad: 2.2387737962676004\n",
      "epoch: 298 loss: 2.2783665657043457 grad: 2.34353119571368\n",
      "epoch: 299 loss: 2.276611804962158 grad: 2.2821463393712684\n",
      "epoch: 300 loss: 2.2733426094055176 grad: 2.3105734388883565\n",
      "epoch: 301 loss: 2.2711775302886963 grad: 2.2477487638289673\n",
      "epoch: 302 loss: 2.2716236114501953 grad: 2.2028097157691797\n",
      "epoch: 303 loss: 2.2701778411865234 grad: 2.1288100166711956\n",
      "epoch: 304 loss: 2.2689106464385986 grad: 2.1474112248739288\n",
      "epoch: 305 loss: 2.2661867141723633 grad: 2.0717559556000023\n",
      "epoch: 306 loss: 2.2651264667510986 grad: 2.034835387322505\n",
      "epoch: 307 loss: 2.264739751815796 grad: 1.9799524645675861\n",
      "epoch: 308 loss: 2.264277696609497 grad: 2.0088954836107966\n",
      "epoch: 309 loss: 2.263751745223999 grad: 1.957602644793778\n",
      "epoch: 310 loss: 2.2624404430389404 grad: 1.9277447219771733\n",
      "epoch: 311 loss: 2.2609052658081055 grad: 1.8731529709129107\n",
      "epoch: 312 loss: 2.261075735092163 grad: 1.8405741159693294\n",
      "epoch: 313 loss: 2.260493040084839 grad: 1.8318995738527664\n",
      "epoch: 314 loss: 2.2587404251098633 grad: 1.812901025844945\n",
      "epoch: 315 loss: 2.257577657699585 grad: 1.7475490741734763\n",
      "epoch: 316 loss: 2.255988836288452 grad: 1.7241533994804032\n",
      "epoch: 317 loss: 2.2560670375823975 grad: 1.7122827856468834\n",
      "epoch: 318 loss: 2.2590363025665283 grad: 1.8184722676588636\n",
      "epoch: 319 loss: 2.2574520111083984 grad: 1.7088652250674805\n",
      "epoch: 320 loss: 2.255383253097534 grad: 1.7257212316136925\n",
      "epoch: 321 loss: 2.2538375854492188 grad: 1.6294802569466391\n",
      "epoch: 322 loss: 2.252748489379883 grad: 1.599526036800521\n",
      "epoch: 323 loss: 2.2536885738372803 grad: 1.6657722194139506\n",
      "epoch: 324 loss: 2.2534728050231934 grad: 1.6173458085192132\n",
      "epoch: 325 loss: 2.2542247772216797 grad: 1.6693844120960595\n",
      "epoch: 326 loss: 2.25321626663208 grad: 1.632834297710187\n",
      "epoch: 327 loss: 2.252213716506958 grad: 1.5632343827488109\n",
      "epoch: 328 loss: 2.2518258094787598 grad: 1.5398671879019175\n",
      "epoch: 329 loss: 2.2494213581085205 grad: 1.4696748284659984\n",
      "epoch: 330 loss: 2.251349687576294 grad: 1.5188830525924761\n",
      "epoch: 331 loss: 2.250438928604126 grad: 1.5449414787414883\n",
      "epoch: 332 loss: 2.250239372253418 grad: 1.499385810684457\n",
      "epoch: 333 loss: 2.2497751712799072 grad: 1.4800844903451404\n",
      "epoch: 334 loss: 2.2499165534973145 grad: 1.4439509295348434\n",
      "epoch: 335 loss: 2.2483856678009033 grad: 1.4017038000655169\n",
      "epoch: 336 loss: 2.2486350536346436 grad: 1.4639404603439043\n",
      "epoch: 337 loss: 2.2486350536346436 grad: 1.4499637046976694\n",
      "epoch: 338 loss: 2.248228073120117 grad: 1.4409263996344561\n",
      "epoch: 339 loss: 2.2485549449920654 grad: 1.4311884645435458\n",
      "epoch: 340 loss: 2.246537208557129 grad: 1.3542849611461398\n",
      "epoch: 341 loss: 2.2487952709198 grad: 1.449253780750691\n",
      "epoch: 342 loss: 2.2462613582611084 grad: 1.3558650346554166\n",
      "epoch: 343 loss: 2.2454464435577393 grad: 1.3613825312442338\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 344 loss: 2.2459614276885986 grad: 1.3577385408607947\n",
      "epoch: 345 loss: 2.246302366256714 grad: 1.3451566814596483\n",
      "epoch: 346 loss: 2.244729518890381 grad: 1.3041217273566872\n",
      "epoch: 347 loss: 2.2462284564971924 grad: 1.353358143700346\n",
      "epoch: 348 loss: 2.2449076175689697 grad: 1.339608422447262\n",
      "epoch: 349 loss: 2.24497652053833 grad: 1.3240407811577566\n",
      "epoch: 350 loss: 2.244528293609619 grad: 1.3466599589927004\n",
      "epoch: 351 loss: 2.2446787357330322 grad: 1.3492188197486694\n",
      "epoch: 352 loss: 2.245008945465088 grad: 1.3266666591387346\n",
      "epoch: 353 loss: 2.246204376220703 grad: 1.3628220297257594\n",
      "epoch: 354 loss: 2.245497941970825 grad: 1.330205657197872\n",
      "epoch: 355 loss: 2.242830753326416 grad: 1.2635525988732716\n",
      "epoch: 356 loss: 2.2440414428710938 grad: 1.2842194215424123\n",
      "epoch: 357 loss: 2.2440266609191895 grad: 1.2997048329063026\n",
      "epoch: 358 loss: 2.243762731552124 grad: 1.271092561330454\n",
      "epoch: 359 loss: 2.2437973022460938 grad: 1.2483171675065976\n",
      "epoch: 360 loss: 2.2431511878967285 grad: 1.2735690963953468\n",
      "epoch: 361 loss: 2.242751121520996 grad: 1.2361805927791885\n",
      "epoch: 362 loss: 2.242361068725586 grad: 1.2534611123329442\n",
      "epoch: 363 loss: 2.2415390014648438 grad: 1.2249364007341985\n",
      "epoch: 364 loss: 2.2424609661102295 grad: 1.2249061890752129\n",
      "epoch: 365 loss: 2.2413408756256104 grad: 1.2349784762251177\n",
      "epoch: 366 loss: 2.2422728538513184 grad: 1.2337578207952902\n",
      "epoch: 367 loss: 2.243187189102173 grad: 1.2551631582531309\n",
      "epoch: 368 loss: 2.2411632537841797 grad: 1.2196066360698925\n",
      "epoch: 369 loss: 2.241988182067871 grad: 1.2338000636765851\n",
      "epoch: 370 loss: 2.2422986030578613 grad: 1.2484259589700886\n",
      "epoch: 371 loss: 2.2400405406951904 grad: 1.1652247956214798\n",
      "epoch: 372 loss: 2.241414785385132 grad: 1.1801161091582524\n",
      "epoch: 373 loss: 2.2414615154266357 grad: 1.2281277065501652\n",
      "epoch: 374 loss: 2.242339849472046 grad: 1.2602803973122574\n",
      "epoch: 375 loss: 2.241838216781616 grad: 1.2402447982125782\n",
      "epoch: 376 loss: 2.2401583194732666 grad: 1.1656048124728149\n",
      "epoch: 377 loss: 2.2409536838531494 grad: 1.1982694681556452\n",
      "epoch: 378 loss: 2.2397475242614746 grad: 1.1644468689854774\n",
      "epoch: 379 loss: 2.240347385406494 grad: 1.2174540584138225\n",
      "epoch: 380 loss: 2.2405312061309814 grad: 1.2068102510076844\n",
      "epoch: 381 loss: 2.2392468452453613 grad: 1.1431925875367597\n",
      "epoch: 382 loss: 2.240407943725586 grad: 1.2403882051714592\n",
      "epoch: 383 loss: 2.2391445636749268 grad: 1.1342907048344228\n",
      "epoch: 384 loss: 2.2426910400390625 grad: 1.2638650968456493\n",
      "epoch: 385 loss: 2.2397186756134033 grad: 1.1828651537338921\n",
      "epoch: 386 loss: 2.240262031555176 grad: 1.2003800130840983\n",
      "epoch: 387 loss: 2.2402031421661377 grad: 1.217261160712778\n",
      "epoch: 388 loss: 2.2395670413970947 grad: 1.1629518271952366\n",
      "epoch: 389 loss: 2.2401785850524902 grad: 1.172599639146707\n",
      "epoch: 390 loss: 2.2392425537109375 grad: 1.1439614543397467\n",
      "epoch: 391 loss: 2.2385947704315186 grad: 1.1246940681880842\n",
      "epoch: 392 loss: 2.237734794616699 grad: 1.0989252371909393\n",
      "epoch: 393 loss: 2.2386369705200195 grad: 1.1364227043814026\n",
      "epoch: 394 loss: 2.2392024993896484 grad: 1.1633346393687785\n",
      "epoch: 395 loss: 2.239875078201294 grad: 1.1523601403561539\n",
      "epoch: 396 loss: 2.2388787269592285 grad: 1.1501295639309175\n",
      "epoch: 397 loss: 2.2369415760040283 grad: 1.0716838087962335\n",
      "epoch: 398 loss: 2.2378125190734863 grad: 1.1356632380324991\n",
      "epoch: 399 loss: 2.238173723220825 grad: 1.1456329138221455\n",
      "epoch: 400 loss: 2.2375569343566895 grad: 1.0957309637904271\n",
      "epoch: 401 loss: 2.2379651069641113 grad: 1.150043318097088\n",
      "epoch: 402 loss: 2.2368404865264893 grad: 1.0754283250010173\n",
      "epoch: 403 loss: 2.237311601638794 grad: 1.104463693238647\n",
      "epoch: 404 loss: 2.237539052963257 grad: 1.1146775816598655\n",
      "epoch: 405 loss: 2.23813796043396 grad: 1.1513459738639613\n",
      "epoch: 406 loss: 2.2369110584259033 grad: 1.082785972665685\n",
      "epoch: 407 loss: 2.237231969833374 grad: 1.1491715386010972\n",
      "epoch: 408 loss: 2.2369000911712646 grad: 1.0794439299922762\n",
      "epoch: 409 loss: 2.2357239723205566 grad: 1.0810365549137166\n",
      "epoch: 410 loss: 2.23712158203125 grad: 1.1181108828648807\n",
      "epoch: 411 loss: 2.237448215484619 grad: 1.1475153959906912\n",
      "epoch: 412 loss: 2.236982583999634 grad: 1.1134107537190652\n",
      "epoch: 413 loss: 2.23854923248291 grad: 1.1786641235877242\n",
      "epoch: 414 loss: 2.2364275455474854 grad: 1.1053746884175029\n",
      "epoch: 415 loss: 2.2370502948760986 grad: 1.1301205543439008\n",
      "epoch: 416 loss: 2.23697566986084 grad: 1.1048033731668034\n",
      "epoch: 417 loss: 2.2378032207489014 grad: 1.1686487210690901\n",
      "epoch: 418 loss: 2.2366714477539062 grad: 1.0523103536697962\n",
      "epoch: 419 loss: 2.2349917888641357 grad: 1.0755168678615952\n",
      "epoch: 420 loss: 2.2361397743225098 grad: 1.1029106909520037\n",
      "epoch: 421 loss: 2.236252546310425 grad: 1.088898659883333\n",
      "epoch: 422 loss: 2.235880136489868 grad: 1.111157517896832\n",
      "epoch: 423 loss: 2.237485408782959 grad: 1.1167108107280608\n",
      "epoch: 424 loss: 2.2361955642700195 grad: 1.0971146956112028\n",
      "epoch: 425 loss: 2.2357866764068604 grad: 1.1097251266501622\n",
      "epoch: 426 loss: 2.237004280090332 grad: 1.099218578652538\n",
      "epoch: 427 loss: 2.236314058303833 grad: 1.08023767356321\n",
      "epoch: 428 loss: 2.2364871501922607 grad: 1.1276913674359785\n",
      "epoch: 429 loss: 2.235792398452759 grad: 1.1182678924126934\n",
      "epoch: 430 loss: 2.2364070415496826 grad: 1.1020443578017876\n",
      "epoch: 431 loss: 2.2350778579711914 grad: 1.052676336197663\n",
      "epoch: 432 loss: 2.234267234802246 grad: 1.0576468177420635\n",
      "epoch: 433 loss: 2.235170841217041 grad: 1.056945028441352\n",
      "epoch: 434 loss: 2.23482608795166 grad: 1.0844645413897178\n",
      "epoch: 435 loss: 2.2342352867126465 grad: 1.0750288877392276\n",
      "epoch: 436 loss: 2.235015869140625 grad: 1.0759591046371497\n",
      "epoch: 437 loss: 2.2351930141448975 grad: 1.1156153787151053\n",
      "epoch: 438 loss: 2.2349562644958496 grad: 1.066576112142121\n",
      "epoch: 439 loss: 2.2349154949188232 grad: 1.0919717291928088\n",
      "epoch: 440 loss: 2.235015869140625 grad: 1.0669064470040168\n",
      "epoch: 441 loss: 2.2351911067962646 grad: 1.113092919400457\n",
      "epoch: 442 loss: 2.2355144023895264 grad: 1.143497953439937\n",
      "epoch: 443 loss: 2.2339155673980713 grad: 1.0715935378241175\n",
      "epoch: 444 loss: 2.2335336208343506 grad: 0.9990753069333362\n",
      "epoch: 445 loss: 2.2352428436279297 grad: 1.0843554082001368\n",
      "epoch: 446 loss: 2.2340035438537598 grad: 1.0075420797978054\n",
      "epoch: 447 loss: 2.233043670654297 grad: 1.0341235935532798\n",
      "epoch: 448 loss: 2.2330996990203857 grad: 1.050072563553436\n",
      "epoch: 449 loss: 2.2337753772735596 grad: 1.0560259835310428\n",
      "epoch: 450 loss: 2.234462261199951 grad: 1.1018003300183439\n",
      "epoch: 451 loss: 2.2338690757751465 grad: 1.0911869077143141\n",
      "epoch: 452 loss: 2.2344441413879395 grad: 1.0814439868951764\n",
      "epoch: 453 loss: 2.233119249343872 grad: 1.0816690537760714\n",
      "epoch: 454 loss: 2.2362842559814453 grad: 1.1811668109462878\n",
      "epoch: 455 loss: 2.2335433959960938 grad: 1.0594050963547834\n",
      "epoch: 456 loss: 2.2344484329223633 grad: 1.0990968979451627\n",
      "epoch: 457 loss: 2.2337026596069336 grad: 1.0985441779836067\n",
      "epoch: 458 loss: 2.2345807552337646 grad: 1.142425293511238\n",
      "epoch: 459 loss: 2.2329342365264893 grad: 1.0895381633419587\n",
      "epoch: 460 loss: 2.233201265335083 grad: 1.092655585033797\n",
      "epoch: 461 loss: 2.23240327835083 grad: 1.0396253040091814\n",
      "epoch: 462 loss: 2.232795476913452 grad: 1.0724242499212748\n",
      "epoch: 463 loss: 2.2337844371795654 grad: 1.1261516116496677\n",
      "epoch: 464 loss: 2.233091354370117 grad: 1.0895731034420713\n",
      "epoch: 465 loss: 2.2339799404144287 grad: 1.102531781560549\n",
      "epoch: 466 loss: 2.233142614364624 grad: 1.105306162784386\n",
      "epoch: 467 loss: 2.2331676483154297 grad: 1.0649494218237197\n",
      "epoch: 468 loss: 2.232135772705078 grad: 1.0866569492601907\n",
      "epoch: 469 loss: 2.231917381286621 grad: 1.0506692061973144\n",
      "epoch: 470 loss: 2.2320590019226074 grad: 1.0535779994504069\n",
      "epoch: 471 loss: 2.231187105178833 grad: 1.02060283762255\n",
      "epoch: 472 loss: 2.233173131942749 grad: 1.1208667194504025\n",
      "epoch: 473 loss: 2.232309341430664 grad: 1.103768922329422\n",
      "epoch: 474 loss: 2.2321417331695557 grad: 1.1137202045656667\n",
      "epoch: 475 loss: 2.2322280406951904 grad: 1.096832182842292\n",
      "epoch: 476 loss: 2.2319512367248535 grad: 1.0953780398408453\n",
      "epoch: 477 loss: 2.2317419052124023 grad: 1.1137489407334389\n",
      "epoch: 478 loss: 2.231652021408081 grad: 1.0702491620285732\n",
      "epoch: 479 loss: 2.2318081855773926 grad: 1.1171664359197686\n",
      "epoch: 480 loss: 2.2317492961883545 grad: 1.0891297272460105\n",
      "epoch: 481 loss: 2.231010913848877 grad: 1.0969097445717095\n",
      "epoch: 482 loss: 2.231497287750244 grad: 1.0789216041975167\n",
      "epoch: 483 loss: 2.230839967727661 grad: 1.0937462643829234\n",
      "epoch: 484 loss: 2.2328524589538574 grad: 1.108213080423108\n",
      "epoch: 485 loss: 2.231839179992676 grad: 1.1118223491985912\n",
      "epoch: 486 loss: 2.2313153743743896 grad: 1.1309502957710287\n",
      "epoch: 487 loss: 2.232382297515869 grad: 1.1603515540999878\n",
      "epoch: 488 loss: 2.2296371459960938 grad: 1.0335026048964613\n",
      "epoch: 489 loss: 2.2301857471466064 grad: 1.0920853521490086\n",
      "epoch: 490 loss: 2.2321932315826416 grad: 1.1922315619035906\n",
      "epoch: 491 loss: 2.2309868335723877 grad: 1.119442154242221\n",
      "epoch: 492 loss: 2.2304322719573975 grad: 1.0975793602761799\n",
      "epoch: 493 loss: 2.2304294109344482 grad: 1.0582876361385432\n",
      "epoch: 494 loss: 2.229483127593994 grad: 1.0883418542392078\n",
      "epoch: 495 loss: 2.2312228679656982 grad: 1.077164175107129\n",
      "epoch: 496 loss: 2.231043577194214 grad: 1.1418784742552182\n",
      "epoch: 497 loss: 2.230403423309326 grad: 1.1162084903824883\n",
      "epoch: 498 loss: 2.230013608932495 grad: 1.1216529251394114\n",
      "epoch: 499 loss: 2.229844093322754 grad: 1.1233052766090998\n",
      "2.251134306192398\n",
      "epoch: 0 loss: 2.3030312061309814 grad: 1.3881330259388225\n",
      "epoch: 1 loss: 2.302460193634033 grad: 1.3789934564108355\n",
      "epoch: 2 loss: 2.3009917736053467 grad: 1.3937412652090961\n",
      "epoch: 3 loss: 2.299757242202759 grad: 1.4585424001025598\n",
      "epoch: 4 loss: 2.295727014541626 grad: 1.626093096620891\n",
      "epoch: 5 loss: 2.293691396713257 grad: 1.6979758556237414\n",
      "epoch: 6 loss: 2.2912814617156982 grad: 1.7498076763170372\n",
      "epoch: 7 loss: 2.28847336769104 grad: 1.846947295432319\n",
      "epoch: 8 loss: 2.2863235473632812 grad: 1.9765957674577035\n",
      "epoch: 9 loss: 2.2855911254882812 grad: 2.103752780325031\n",
      "epoch: 10 loss: 2.281087875366211 grad: 2.2036638502419614\n",
      "epoch: 11 loss: 2.2798821926116943 grad: 2.387939459740347\n",
      "epoch: 12 loss: 2.2752432823181152 grad: 2.4717300776835707\n",
      "epoch: 13 loss: 2.268604040145874 grad: 2.6056959973980804\n",
      "epoch: 14 loss: 2.2660462856292725 grad: 2.7985416306145785\n",
      "epoch: 15 loss: 2.2609293460845947 grad: 2.7766109332405327\n",
      "epoch: 16 loss: 2.257887363433838 grad: 3.145163311312596\n",
      "epoch: 17 loss: 2.251096725463867 grad: 3.1457701335727637\n",
      "epoch: 18 loss: 2.2470312118530273 grad: 3.4061790489783834\n",
      "epoch: 19 loss: 2.241708993911743 grad: 3.361999210639162\n",
      "epoch: 20 loss: 2.236865520477295 grad: 3.612017248764575\n",
      "epoch: 21 loss: 2.2335169315338135 grad: 3.7951962436283275\n",
      "epoch: 22 loss: 2.223212480545044 grad: 4.042842135003339\n",
      "epoch: 23 loss: 2.2193102836608887 grad: 4.260090365052401\n",
      "epoch: 24 loss: 2.213991165161133 grad: 4.129952919591839\n",
      "epoch: 25 loss: 2.2076447010040283 grad: 4.475381982261463\n",
      "epoch: 26 loss: 2.198521375656128 grad: 5.063694366808271\n",
      "epoch: 27 loss: 2.1965177059173584 grad: 4.936298326589167\n",
      "epoch: 28 loss: 2.1850242614746094 grad: 5.3354044242850724\n",
      "epoch: 29 loss: 2.174938440322876 grad: 5.528716200001774\n",
      "epoch: 30 loss: 2.1686646938323975 grad: 5.552654278265046\n",
      "epoch: 31 loss: 2.1611406803131104 grad: 5.593842450381508\n",
      "epoch: 32 loss: 2.154780149459839 grad: 5.66494963550201\n",
      "epoch: 33 loss: 2.1469597816467285 grad: 5.88039964704316\n",
      "epoch: 34 loss: 2.142202377319336 grad: 5.735022213746099\n",
      "epoch: 35 loss: 2.1407179832458496 grad: 5.737447252862954\n",
      "epoch: 36 loss: 2.1279726028442383 grad: 5.748262868166739\n",
      "epoch: 37 loss: 2.126274824142456 grad: 6.011827880694043\n",
      "epoch: 38 loss: 2.123717784881592 grad: 5.8540276035829075\n",
      "epoch: 39 loss: 2.113447427749634 grad: 5.652776870070883\n",
      "epoch: 40 loss: 2.11409068107605 grad: 5.838730569625835\n",
      "epoch: 41 loss: 2.113384485244751 grad: 5.749268056728715\n",
      "epoch: 42 loss: 2.1097640991210938 grad: 5.581055540111034\n",
      "epoch: 43 loss: 2.106783628463745 grad: 5.833514697746271\n",
      "epoch: 44 loss: 2.096809148788452 grad: 5.800152101398756\n",
      "epoch: 45 loss: 2.0945866107940674 grad: 5.719136395691229\n",
      "epoch: 46 loss: 2.0934109687805176 grad: 5.815302930654041\n",
      "epoch: 47 loss: 2.098484516143799 grad: 6.113789109372726\n",
      "epoch: 48 loss: 2.0896573066711426 grad: 5.706114255291011\n",
      "epoch: 49 loss: 2.0861008167266846 grad: 5.806747368669936\n",
      "epoch: 50 loss: 2.0901620388031006 grad: 5.826940509941547\n",
      "epoch: 51 loss: 2.0819849967956543 grad: 6.019155568480196\n",
      "epoch: 52 loss: 2.0837533473968506 grad: 5.998135981268235\n",
      "epoch: 53 loss: 2.079559087753296 grad: 6.0995801946828285\n",
      "epoch: 54 loss: 2.0791139602661133 grad: 5.8668435317508525\n",
      "epoch: 55 loss: 2.074160099029541 grad: 6.024631044250869\n",
      "epoch: 56 loss: 2.0783534049987793 grad: 6.477401689345402\n",
      "epoch: 57 loss: 2.0740010738372803 grad: 6.170642911486091\n",
      "epoch: 58 loss: 2.063434600830078 grad: 5.879329513034059\n",
      "epoch: 59 loss: 2.0625882148742676 grad: 6.2917716406315325\n",
      "epoch: 60 loss: 2.0622634887695312 grad: 6.43515054000512\n",
      "epoch: 61 loss: 2.061002016067505 grad: 6.496915624462186\n",
      "epoch: 62 loss: 2.0555713176727295 grad: 6.177843530448006\n",
      "epoch: 63 loss: 2.0533015727996826 grad: 6.159153211078356\n",
      "epoch: 64 loss: 2.050626277923584 grad: 6.288921301489666\n",
      "epoch: 65 loss: 2.0508456230163574 grad: 6.5941519873320225\n",
      "epoch: 66 loss: 2.047713279724121 grad: 6.450220640475256\n",
      "epoch: 67 loss: 2.046391010284424 grad: 6.745867852735082\n",
      "epoch: 68 loss: 2.0406317710876465 grad: 6.570743819646951\n",
      "epoch: 69 loss: 2.037942409515381 grad: 6.606101264312331\n",
      "epoch: 70 loss: 2.0400326251983643 grad: 6.696856228383406\n",
      "epoch: 71 loss: 2.03408145904541 grad: 7.069946504545412\n",
      "epoch: 72 loss: 2.0361225605010986 grad: 7.256973086752826\n",
      "epoch: 73 loss: 2.034724473953247 grad: 7.213852159265015\n",
      "epoch: 74 loss: 2.029583692550659 grad: 7.2213548794980085\n",
      "epoch: 75 loss: 2.0349392890930176 grad: 7.450689137351537\n",
      "epoch: 76 loss: 2.0220186710357666 grad: 7.77410184002171\n",
      "epoch: 77 loss: 2.0167055130004883 grad: 7.4616050491375585\n",
      "epoch: 78 loss: 2.0175514221191406 grad: 7.4496471136808395\n",
      "epoch: 79 loss: 2.014741897583008 grad: 7.761429792270064\n",
      "epoch: 80 loss: 2.0135602951049805 grad: 7.422829136917634\n",
      "epoch: 81 loss: 2.0112361907958984 grad: 8.058923415130092\n",
      "epoch: 82 loss: 2.005872964859009 grad: 7.595597122455874\n",
      "epoch: 83 loss: 2.003617525100708 grad: 8.020371869132514\n",
      "epoch: 84 loss: 1.9968717098236084 grad: 8.164548458339322\n",
      "epoch: 85 loss: 1.992106556892395 grad: 8.042769017126707\n",
      "epoch: 86 loss: 1.9979195594787598 grad: 8.255394397924343\n",
      "epoch: 87 loss: 1.9968056678771973 grad: 8.614142593587674\n",
      "epoch: 88 loss: 1.9876285791397095 grad: 8.445686046743678\n",
      "epoch: 89 loss: 1.9812253713607788 grad: 8.19254156988528\n",
      "epoch: 90 loss: 1.9770623445510864 grad: 8.337324502212661\n",
      "epoch: 91 loss: 1.9756994247436523 grad: 8.525759982196467\n",
      "epoch: 92 loss: 1.9752517938613892 grad: 8.947594314118819\n",
      "epoch: 93 loss: 1.9741997718811035 grad: 8.674244610045756\n",
      "epoch: 94 loss: 1.9644330739974976 grad: 8.192461335100234\n",
      "epoch: 95 loss: 1.971164345741272 grad: 8.816436959548838\n",
      "epoch: 96 loss: 1.960802674293518 grad: 8.440257889514287\n",
      "epoch: 97 loss: 1.9633734226226807 grad: 8.455379359231937\n",
      "epoch: 98 loss: 1.9638962745666504 grad: 9.070441805254964\n",
      "epoch: 99 loss: 1.950674057006836 grad: 8.43161798255252\n",
      "epoch: 100 loss: 1.95545494556427 grad: 8.869320333757926\n",
      "epoch: 101 loss: 1.947641134262085 grad: 9.202805902335852\n",
      "epoch: 102 loss: 1.9512795209884644 grad: 9.142739807033823\n",
      "epoch: 103 loss: 1.9516639709472656 grad: 9.205522186034138\n",
      "epoch: 104 loss: 1.944198489189148 grad: 9.193512563017153\n",
      "epoch: 105 loss: 1.944319725036621 grad: 9.086024961404739\n",
      "epoch: 106 loss: 1.9426031112670898 grad: 9.41083447074902\n",
      "epoch: 107 loss: 1.936713457107544 grad: 9.1108687751823\n",
      "epoch: 108 loss: 1.9290099143981934 grad: 9.572353155603485\n",
      "epoch: 109 loss: 1.9337266683578491 grad: 8.984117320679601\n",
      "epoch: 110 loss: 1.9288864135742188 grad: 9.404812358334542\n",
      "epoch: 111 loss: 1.9279627799987793 grad: 9.371227354254751\n",
      "epoch: 112 loss: 1.9230835437774658 grad: 9.160314543157934\n",
      "epoch: 113 loss: 1.9178305864334106 grad: 9.50444956629404\n",
      "epoch: 114 loss: 1.9143168926239014 grad: 9.058053234710343\n",
      "epoch: 115 loss: 1.9157487154006958 grad: 10.177568701554149\n",
      "epoch: 116 loss: 1.913116455078125 grad: 10.017381392434121\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 117 loss: 1.9046155214309692 grad: 9.666644895419715\n",
      "epoch: 118 loss: 1.9048810005187988 grad: 9.428299069670695\n",
      "epoch: 119 loss: 1.9034578800201416 grad: 9.654783501585444\n",
      "epoch: 120 loss: 1.905213713645935 grad: 9.527869383375796\n",
      "epoch: 121 loss: 1.901365876197815 grad: 10.27633268510302\n",
      "epoch: 122 loss: 1.8933531045913696 grad: 9.512543539605325\n",
      "epoch: 123 loss: 1.9034782648086548 grad: 10.245583726758403\n",
      "epoch: 124 loss: 1.8967890739440918 grad: 10.11461559440645\n",
      "epoch: 125 loss: 1.902787685394287 grad: 9.9939093800439\n",
      "epoch: 126 loss: 1.9004076719284058 grad: 10.203815936835277\n",
      "epoch: 127 loss: 1.8951648473739624 grad: 9.871015769370374\n",
      "epoch: 128 loss: 1.89163339138031 grad: 9.894776572177689\n",
      "epoch: 129 loss: 1.8956397771835327 grad: 9.870254300224284\n",
      "epoch: 130 loss: 1.891597032546997 grad: 10.258679217185884\n",
      "epoch: 131 loss: 1.8878746032714844 grad: 9.950853904014425\n",
      "epoch: 132 loss: 1.8836493492126465 grad: 9.72028497148246\n",
      "epoch: 133 loss: 1.8828518390655518 grad: 9.839496999335964\n",
      "epoch: 134 loss: 1.8815454244613647 grad: 10.184538215524443\n",
      "epoch: 135 loss: 1.883849024772644 grad: 9.92814333825594\n",
      "epoch: 136 loss: 1.8843133449554443 grad: 10.014132305772769\n",
      "epoch: 137 loss: 1.8760085105895996 grad: 10.041042062557406\n",
      "epoch: 138 loss: 1.879359245300293 grad: 10.458496560933925\n",
      "epoch: 139 loss: 1.8818854093551636 grad: 10.290525330633427\n",
      "epoch: 140 loss: 1.8701062202453613 grad: 10.03374975431888\n",
      "epoch: 141 loss: 1.8711923360824585 grad: 9.992600214490224\n",
      "epoch: 142 loss: 1.8654122352600098 grad: 10.20232085749093\n",
      "epoch: 143 loss: 1.8779900074005127 grad: 10.196622038437496\n",
      "epoch: 144 loss: 1.8753163814544678 grad: 10.552588449864988\n",
      "epoch: 145 loss: 1.8648898601531982 grad: 9.932815938345378\n",
      "epoch: 146 loss: 1.8637045621871948 grad: 9.704131337178369\n",
      "epoch: 147 loss: 1.864097237586975 grad: 10.224213474371012\n",
      "epoch: 148 loss: 1.8560882806777954 grad: 9.82528183031236\n",
      "epoch: 149 loss: 1.8598414659500122 grad: 9.738495108198434\n",
      "epoch: 150 loss: 1.8648974895477295 grad: 9.865603307764681\n",
      "epoch: 151 loss: 1.8567923307418823 grad: 10.177896520581156\n",
      "epoch: 152 loss: 1.8555022478103638 grad: 10.157808713422764\n",
      "epoch: 153 loss: 1.8530265092849731 grad: 10.11838097330774\n",
      "epoch: 154 loss: 1.8541308641433716 grad: 10.33876429025143\n",
      "epoch: 155 loss: 1.8493554592132568 grad: 10.028063580142481\n",
      "epoch: 156 loss: 1.8489786386489868 grad: 9.949694969927863\n",
      "epoch: 157 loss: 1.8568023443222046 grad: 9.781342774097409\n",
      "epoch: 158 loss: 1.855352759361267 grad: 9.925677031751663\n",
      "epoch: 159 loss: 1.8523865938186646 grad: 10.070534744181685\n",
      "epoch: 160 loss: 1.8530592918395996 grad: 10.181077921659583\n",
      "epoch: 161 loss: 1.8532212972640991 grad: 10.529353927532654\n",
      "epoch: 162 loss: 1.8450708389282227 grad: 10.346230781533652\n",
      "epoch: 163 loss: 1.8560272455215454 grad: 10.392664841036238\n",
      "epoch: 164 loss: 1.8518033027648926 grad: 10.63328743939628\n",
      "epoch: 165 loss: 1.8511754274368286 grad: 10.274125365954307\n",
      "epoch: 166 loss: 1.8416708707809448 grad: 9.855938243901445\n",
      "epoch: 167 loss: 1.851706862449646 grad: 9.924542765029603\n",
      "epoch: 168 loss: 1.8511075973510742 grad: 9.789815317129804\n",
      "epoch: 169 loss: 1.8452000617980957 grad: 10.409493038567552\n",
      "epoch: 170 loss: 1.8404755592346191 grad: 10.337330775128471\n",
      "epoch: 171 loss: 1.841122031211853 grad: 10.358278144564894\n",
      "epoch: 172 loss: 1.8468232154846191 grad: 10.356488072549896\n",
      "epoch: 173 loss: 1.8370461463928223 grad: 10.135351347833103\n",
      "epoch: 174 loss: 1.839043140411377 grad: 10.348921479206414\n",
      "epoch: 175 loss: 1.8371418714523315 grad: 10.19475402144922\n",
      "epoch: 176 loss: 1.8407776355743408 grad: 10.31289542231354\n",
      "epoch: 177 loss: 1.8456579446792603 grad: 10.556128908022647\n",
      "epoch: 178 loss: 1.8374035358428955 grad: 10.43226774484067\n",
      "epoch: 179 loss: 1.8296688795089722 grad: 10.562822526335598\n",
      "epoch: 180 loss: 1.837810754776001 grad: 10.53697853557588\n",
      "epoch: 181 loss: 1.8314067125320435 grad: 9.83337720310212\n",
      "epoch: 182 loss: 1.8426620960235596 grad: 10.567945265403342\n",
      "epoch: 183 loss: 1.8336362838745117 grad: 10.512902851933466\n",
      "epoch: 184 loss: 1.842146873474121 grad: 10.260870056241632\n",
      "epoch: 185 loss: 1.8245924711227417 grad: 10.163135954016258\n",
      "epoch: 186 loss: 1.8357819318771362 grad: 10.131863473153244\n",
      "epoch: 187 loss: 1.835050106048584 grad: 10.194351800480886\n",
      "epoch: 188 loss: 1.830395221710205 grad: 10.247169315534096\n",
      "epoch: 189 loss: 1.8318052291870117 grad: 11.043235081587992\n",
      "epoch: 190 loss: 1.8334927558898926 grad: 10.428557845778645\n",
      "epoch: 191 loss: 1.8341869115829468 grad: 9.580424429981836\n",
      "epoch: 192 loss: 1.8254714012145996 grad: 10.063288107026546\n",
      "epoch: 193 loss: 1.8294594287872314 grad: 10.598513530715117\n",
      "epoch: 194 loss: 1.8282448053359985 grad: 10.413819523661264\n",
      "epoch: 195 loss: 1.8221092224121094 grad: 10.592213722566763\n",
      "epoch: 196 loss: 1.8291701078414917 grad: 10.940201439377335\n",
      "epoch: 197 loss: 1.8291093111038208 grad: 10.463186265560724\n",
      "epoch: 198 loss: 1.8263180255889893 grad: 10.411611202852947\n",
      "epoch: 199 loss: 1.8277842998504639 grad: 10.471603039807329\n",
      "epoch: 200 loss: 1.8191196918487549 grad: 10.31478854440271\n",
      "epoch: 201 loss: 1.8227864503860474 grad: 9.9522715101669\n",
      "epoch: 202 loss: 1.824530839920044 grad: 10.642556639033414\n",
      "epoch: 203 loss: 1.8226064443588257 grad: 10.487603673711419\n",
      "epoch: 204 loss: 1.8186269998550415 grad: 10.745980659854554\n",
      "epoch: 205 loss: 1.8180344104766846 grad: 10.04326652899562\n",
      "epoch: 206 loss: 1.8138245344161987 grad: 10.481626153834874\n",
      "epoch: 207 loss: 1.8223313093185425 grad: 10.391507359916373\n",
      "epoch: 208 loss: 1.81015145778656 grad: 10.594718797871518\n",
      "epoch: 209 loss: 1.8147833347320557 grad: 10.94762111484768\n",
      "epoch: 210 loss: 1.8145660161972046 grad: 10.937841179278044\n",
      "epoch: 211 loss: 1.8228983879089355 grad: 10.864777120857662\n",
      "epoch: 212 loss: 1.8240312337875366 grad: 10.250760181688719\n",
      "epoch: 213 loss: 1.8195173740386963 grad: 10.422664450348488\n",
      "epoch: 214 loss: 1.8247085809707642 grad: 10.8638145193635\n",
      "epoch: 215 loss: 1.8088715076446533 grad: 10.983889068831646\n",
      "epoch: 216 loss: 1.8197591304779053 grad: 11.074698569386133\n",
      "epoch: 217 loss: 1.8074978590011597 grad: 10.681736891675326\n",
      "epoch: 218 loss: 1.8146315813064575 grad: 11.053730116551003\n",
      "epoch: 219 loss: 1.815474510192871 grad: 10.58478895931076\n",
      "epoch: 220 loss: 1.817785382270813 grad: 10.771003950298542\n",
      "epoch: 221 loss: 1.819199562072754 grad: 11.20984630564612\n",
      "epoch: 222 loss: 1.8122721910476685 grad: 10.561836402863264\n",
      "epoch: 223 loss: 1.8083692789077759 grad: 10.656301032227006\n",
      "epoch: 224 loss: 1.818245530128479 grad: 10.29895554131843\n",
      "epoch: 225 loss: 1.8036127090454102 grad: 10.980768921725925\n",
      "epoch: 226 loss: 1.809592604637146 grad: 10.181043753053046\n",
      "epoch: 227 loss: 1.8119382858276367 grad: 9.725436317911814\n",
      "epoch: 228 loss: 1.805837869644165 grad: 10.690574201296956\n",
      "epoch: 229 loss: 1.8089629411697388 grad: 10.36390173556431\n",
      "epoch: 230 loss: 1.8050968647003174 grad: 10.468198211183624\n",
      "epoch: 231 loss: 1.8049410581588745 grad: 10.65787155005253\n",
      "epoch: 232 loss: 1.8135507106781006 grad: 10.87710190381086\n",
      "epoch: 233 loss: 1.8022468090057373 grad: 11.28124450263937\n",
      "epoch: 234 loss: 1.8013819456100464 grad: 10.541233778975549\n",
      "epoch: 235 loss: 1.7944092750549316 grad: 10.284935568363244\n",
      "epoch: 236 loss: 1.7974143028259277 grad: 10.741230108109969\n",
      "epoch: 237 loss: 1.798069715499878 grad: 10.811698523778764\n",
      "epoch: 238 loss: 1.8118059635162354 grad: 11.14306740411779\n",
      "epoch: 239 loss: 1.8097761869430542 grad: 10.823966789044558\n",
      "epoch: 240 loss: 1.7927922010421753 grad: 10.353552120309027\n",
      "epoch: 241 loss: 1.8079710006713867 grad: 10.51089205365214\n",
      "epoch: 242 loss: 1.799296259880066 grad: 10.578618410516471\n",
      "epoch: 243 loss: 1.800527572631836 grad: 10.901851397672933\n",
      "epoch: 244 loss: 1.8050681352615356 grad: 11.000503109723685\n",
      "epoch: 245 loss: 1.7997113466262817 grad: 10.7622146962861\n",
      "epoch: 246 loss: 1.8065788745880127 grad: 10.946164844040242\n",
      "epoch: 247 loss: 1.7958348989486694 grad: 11.319611923695202\n",
      "epoch: 248 loss: 1.7982192039489746 grad: 10.230263593384908\n",
      "epoch: 249 loss: 1.8008534908294678 grad: 10.905969457449538\n",
      "epoch: 250 loss: 1.7969974279403687 grad: 11.049693769065751\n",
      "epoch: 251 loss: 1.8016767501831055 grad: 11.724111363099563\n",
      "epoch: 252 loss: 1.791972279548645 grad: 10.417740808770297\n",
      "epoch: 253 loss: 1.8009246587753296 grad: 11.19656631700872\n",
      "epoch: 254 loss: 1.7892926931381226 grad: 10.63464308666095\n",
      "epoch: 255 loss: 1.7928485870361328 grad: 11.066112636115461\n",
      "epoch: 256 loss: 1.795511245727539 grad: 11.148860858162008\n",
      "epoch: 257 loss: 1.7965888977050781 grad: 10.997485585362902\n",
      "epoch: 258 loss: 1.7946490049362183 grad: 11.41550771887636\n",
      "epoch: 259 loss: 1.7865101099014282 grad: 10.978681751630372\n",
      "epoch: 260 loss: 1.799010157585144 grad: 11.254940170321673\n",
      "epoch: 261 loss: 1.7928807735443115 grad: 10.911270598932687\n",
      "epoch: 262 loss: 1.7842432260513306 grad: 11.238789403456307\n",
      "epoch: 263 loss: 1.7921478748321533 grad: 11.633273458729187\n",
      "epoch: 264 loss: 1.783547043800354 grad: 10.959842646997126\n",
      "epoch: 265 loss: 1.7801012992858887 grad: 10.843975913208274\n",
      "epoch: 266 loss: 1.7894047498703003 grad: 10.743887877328293\n",
      "epoch: 267 loss: 1.7915626764297485 grad: 11.499152370181585\n",
      "epoch: 268 loss: 1.7874068021774292 grad: 11.27468458234909\n",
      "epoch: 269 loss: 1.7905391454696655 grad: 10.962511924043712\n",
      "epoch: 270 loss: 1.7917561531066895 grad: 11.51490271370858\n",
      "epoch: 271 loss: 1.7824454307556152 grad: 10.558753376309243\n",
      "epoch: 272 loss: 1.7848052978515625 grad: 10.832696781360678\n",
      "epoch: 273 loss: 1.783324956893921 grad: 11.305911420726233\n",
      "epoch: 274 loss: 1.7844587564468384 grad: 11.146478091943122\n",
      "epoch: 275 loss: 1.7861909866333008 grad: 11.131973470502075\n",
      "epoch: 276 loss: 1.783737301826477 grad: 11.132854443176516\n",
      "epoch: 277 loss: 1.7799491882324219 grad: 11.13544424332028\n",
      "epoch: 278 loss: 1.7822333574295044 grad: 11.516037565301216\n",
      "epoch: 279 loss: 1.784667730331421 grad: 11.060373991232602\n",
      "epoch: 280 loss: 1.788084864616394 grad: 11.718988370194676\n",
      "epoch: 281 loss: 1.7809807062149048 grad: 10.93254971680128\n",
      "epoch: 282 loss: 1.7842795848846436 grad: 11.128281857419227\n",
      "epoch: 283 loss: 1.7873430252075195 grad: 11.553820110680093\n",
      "epoch: 284 loss: 1.781596064567566 grad: 11.165543615670195\n",
      "epoch: 285 loss: 1.7869155406951904 grad: 11.527150747055808\n",
      "epoch: 286 loss: 1.773530125617981 grad: 10.487903465753392\n",
      "epoch: 287 loss: 1.777390718460083 grad: 10.92828597474311\n",
      "epoch: 288 loss: 1.7855526208877563 grad: 11.88404362713031\n",
      "epoch: 289 loss: 1.7761945724487305 grad: 11.051296328645318\n",
      "epoch: 290 loss: 1.7845568656921387 grad: 11.575045624260037\n",
      "epoch: 291 loss: 1.7690190076828003 grad: 11.201038427783974\n",
      "epoch: 292 loss: 1.7770063877105713 grad: 11.574656445961741\n",
      "epoch: 293 loss: 1.7688686847686768 grad: 10.944165050029932\n",
      "epoch: 294 loss: 1.7772166728973389 grad: 11.76488500025626\n",
      "epoch: 295 loss: 1.7769359350204468 grad: 10.963625026364175\n",
      "epoch: 296 loss: 1.7715935707092285 grad: 11.25839361978606\n",
      "epoch: 297 loss: 1.7745870351791382 grad: 10.839176011330906\n",
      "epoch: 298 loss: 1.7826913595199585 grad: 11.916216430431675\n",
      "epoch: 299 loss: 1.770363450050354 grad: 11.669638491339153\n",
      "epoch: 300 loss: 1.7772303819656372 grad: 11.442222163362045\n",
      "epoch: 301 loss: 1.7666926383972168 grad: 10.475141816550778\n",
      "epoch: 302 loss: 1.7738115787506104 grad: 11.307139238298294\n",
      "epoch: 303 loss: 1.7851550579071045 grad: 12.023638806202346\n",
      "epoch: 304 loss: 1.7743539810180664 grad: 10.503429260873606\n",
      "epoch: 305 loss: 1.7765100002288818 grad: 11.242496489798503\n",
      "epoch: 306 loss: 1.768002986907959 grad: 11.379531840069426\n",
      "epoch: 307 loss: 1.7750405073165894 grad: 11.625220907615526\n",
      "epoch: 308 loss: 1.7617979049682617 grad: 10.514653532780589\n",
      "epoch: 309 loss: 1.758707046508789 grad: 11.417821042808807\n",
      "epoch: 310 loss: 1.7666743993759155 grad: 11.703218692411033\n",
      "epoch: 311 loss: 1.761042833328247 grad: 11.55530701397312\n",
      "epoch: 312 loss: 1.7634271383285522 grad: 11.95448405217261\n",
      "epoch: 313 loss: 1.768746256828308 grad: 12.291855844535998\n",
      "epoch: 314 loss: 1.7662389278411865 grad: 12.023826201032433\n",
      "epoch: 315 loss: 1.7688082456588745 grad: 11.263487254905085\n",
      "epoch: 316 loss: 1.7687904834747314 grad: 11.17684077539496\n",
      "epoch: 317 loss: 1.7598276138305664 grad: 11.305612913820715\n",
      "epoch: 318 loss: 1.766831398010254 grad: 11.727531087363051\n",
      "epoch: 319 loss: 1.7601001262664795 grad: 11.971430350346344\n",
      "epoch: 320 loss: 1.7594096660614014 grad: 11.900095616016419\n",
      "epoch: 321 loss: 1.7547521591186523 grad: 11.667905943024726\n",
      "epoch: 322 loss: 1.7629157304763794 grad: 11.69603203024183\n",
      "epoch: 323 loss: 1.7590707540512085 grad: 11.116284609092252\n",
      "epoch: 324 loss: 1.7642205953598022 grad: 11.558831791009103\n",
      "epoch: 325 loss: 1.7524685859680176 grad: 11.781009344421031\n",
      "epoch: 326 loss: 1.7582240104675293 grad: 11.60445166571391\n",
      "epoch: 327 loss: 1.7566797733306885 grad: 11.738925531181314\n",
      "epoch: 328 loss: 1.7589454650878906 grad: 11.043526703144408\n",
      "epoch: 329 loss: 1.750633716583252 grad: 10.920385177794193\n",
      "epoch: 330 loss: 1.7611197233200073 grad: 12.518806101384735\n",
      "epoch: 331 loss: 1.7504416704177856 grad: 11.50347210718171\n",
      "epoch: 332 loss: 1.7595818042755127 grad: 11.361728760472957\n",
      "epoch: 333 loss: 1.7624187469482422 grad: 11.225064927564254\n",
      "epoch: 334 loss: 1.767266869544983 grad: 12.668148633683957\n",
      "epoch: 335 loss: 1.7492074966430664 grad: 11.397087588876722\n",
      "epoch: 336 loss: 1.7664599418640137 grad: 12.016400725994673\n",
      "epoch: 337 loss: 1.7525646686553955 grad: 11.989394596674376\n",
      "epoch: 338 loss: 1.7608919143676758 grad: 12.279896943545383\n",
      "epoch: 339 loss: 1.7556287050247192 grad: 12.744571292225922\n",
      "epoch: 340 loss: 1.7515556812286377 grad: 11.373218818124206\n",
      "epoch: 341 loss: 1.7536810636520386 grad: 11.551672755629712\n",
      "epoch: 342 loss: 1.7557895183563232 grad: 11.610328653916007\n",
      "epoch: 343 loss: 1.7591859102249146 grad: 11.773942157700066\n",
      "epoch: 344 loss: 1.7434191703796387 grad: 11.812138967201232\n",
      "epoch: 345 loss: 1.74751615524292 grad: 11.808122899176347\n",
      "epoch: 346 loss: 1.7512940168380737 grad: 11.777332464750442\n",
      "epoch: 347 loss: 1.7556078433990479 grad: 11.478049443524686\n",
      "epoch: 348 loss: 1.7493144273757935 grad: 11.894361811350025\n",
      "epoch: 349 loss: 1.7522774934768677 grad: 11.65999483164873\n",
      "epoch: 350 loss: 1.7518564462661743 grad: 11.021659914404154\n",
      "epoch: 351 loss: 1.756211757659912 grad: 12.098451168365067\n",
      "epoch: 352 loss: 1.7480990886688232 grad: 11.37530631255654\n",
      "epoch: 353 loss: 1.7566001415252686 grad: 11.798274737272767\n",
      "epoch: 354 loss: 1.7482564449310303 grad: 11.252940905199106\n",
      "epoch: 355 loss: 1.7565234899520874 grad: 12.191827004679316\n",
      "epoch: 356 loss: 1.7468533515930176 grad: 11.747236707949982\n",
      "epoch: 357 loss: 1.7409909963607788 grad: 11.073785127014927\n",
      "epoch: 358 loss: 1.7553991079330444 grad: 11.532573036287749\n",
      "epoch: 359 loss: 1.7462339401245117 grad: 11.64835674805005\n",
      "epoch: 360 loss: 1.751359224319458 grad: 11.390134721314388\n",
      "epoch: 361 loss: 1.7517368793487549 grad: 11.636147413166269\n",
      "epoch: 362 loss: 1.7541024684906006 grad: 12.008717483855666\n",
      "epoch: 363 loss: 1.739182710647583 grad: 11.982755242891255\n",
      "epoch: 364 loss: 1.7461899518966675 grad: 11.227597182158322\n",
      "epoch: 365 loss: 1.744349479675293 grad: 11.219789073787748\n",
      "epoch: 366 loss: 1.7429320812225342 grad: 11.815386846602436\n",
      "epoch: 367 loss: 1.7490484714508057 grad: 11.640372304844536\n",
      "epoch: 368 loss: 1.7352087497711182 grad: 11.171525717461629\n",
      "epoch: 369 loss: 1.7448889017105103 grad: 11.493931952154352\n",
      "epoch: 370 loss: 1.7467564344406128 grad: 11.733493709020198\n",
      "epoch: 371 loss: 1.75311279296875 grad: 12.365124549243658\n",
      "epoch: 372 loss: 1.738792896270752 grad: 12.07835456477626\n",
      "epoch: 373 loss: 1.7483108043670654 grad: 12.111491362349915\n",
      "epoch: 374 loss: 1.7413643598556519 grad: 11.167354848169323\n",
      "epoch: 375 loss: 1.746211290359497 grad: 11.528054828777732\n",
      "epoch: 376 loss: 1.740841031074524 grad: 11.821302663490531\n",
      "epoch: 377 loss: 1.7404712438583374 grad: 12.045191576172199\n",
      "epoch: 378 loss: 1.7300902605056763 grad: 11.146752278054398\n",
      "epoch: 379 loss: 1.7337173223495483 grad: 11.357125248774768\n",
      "epoch: 380 loss: 1.7464826107025146 grad: 12.932479657306676\n",
      "epoch: 381 loss: 1.740920901298523 grad: 11.980135647979166\n",
      "epoch: 382 loss: 1.7466404438018799 grad: 11.80626090080847\n",
      "epoch: 383 loss: 1.7429975271224976 grad: 12.028550326572878\n",
      "epoch: 384 loss: 1.7391173839569092 grad: 11.79985738452524\n",
      "epoch: 385 loss: 1.7375683784484863 grad: 11.289303762354104\n",
      "epoch: 386 loss: 1.7356897592544556 grad: 12.270469099127999\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 387 loss: 1.7378907203674316 grad: 11.410492776375678\n",
      "epoch: 388 loss: 1.7381004095077515 grad: 11.579107975942039\n",
      "epoch: 389 loss: 1.735921859741211 grad: 11.77701436167228\n",
      "epoch: 390 loss: 1.7347650527954102 grad: 11.785789757826558\n",
      "epoch: 391 loss: 1.7425594329833984 grad: 11.505046842338901\n",
      "epoch: 392 loss: 1.7399808168411255 grad: 12.026173195905155\n",
      "epoch: 393 loss: 1.7359293699264526 grad: 12.187550136523823\n",
      "epoch: 394 loss: 1.7435388565063477 grad: 11.895978630283876\n",
      "epoch: 395 loss: 1.7335150241851807 grad: 11.990900875453557\n",
      "epoch: 396 loss: 1.7261202335357666 grad: 12.628814589394818\n",
      "epoch: 397 loss: 1.7344911098480225 grad: 11.66798773469285\n",
      "epoch: 398 loss: 1.7344025373458862 grad: 11.1756216751722\n",
      "epoch: 399 loss: 1.7300820350646973 grad: 12.246610761368794\n",
      "epoch: 400 loss: 1.7249553203582764 grad: 12.249410386603799\n",
      "epoch: 401 loss: 1.7305811643600464 grad: 10.998551285751756\n",
      "epoch: 402 loss: 1.7390705347061157 grad: 11.300262320284096\n",
      "epoch: 403 loss: 1.7351394891738892 grad: 11.982515571808944\n",
      "epoch: 404 loss: 1.727292776107788 grad: 11.487281226966944\n",
      "epoch: 405 loss: 1.7268444299697876 grad: 11.375504567805264\n",
      "epoch: 406 loss: 1.7335227727890015 grad: 12.38993984114911\n",
      "epoch: 407 loss: 1.7269866466522217 grad: 11.249469169733366\n",
      "epoch: 408 loss: 1.7263299226760864 grad: 11.930939714505618\n",
      "epoch: 409 loss: 1.731705665588379 grad: 11.375810878950038\n",
      "epoch: 410 loss: 1.7243620157241821 grad: 11.951528394010865\n",
      "epoch: 411 loss: 1.7277315855026245 grad: 12.3097641805246\n",
      "epoch: 412 loss: 1.7328249216079712 grad: 12.228022744036501\n",
      "epoch: 413 loss: 1.7375813722610474 grad: 12.081820900485452\n",
      "epoch: 414 loss: 1.727388620376587 grad: 12.126870620759233\n",
      "epoch: 415 loss: 1.7237720489501953 grad: 12.388803810583399\n",
      "epoch: 416 loss: 1.7279313802719116 grad: 11.509333297100273\n",
      "epoch: 417 loss: 1.7222464084625244 grad: 11.734579722278767\n",
      "epoch: 418 loss: 1.731399416923523 grad: 12.36222123857292\n",
      "epoch: 419 loss: 1.7248799800872803 grad: 11.523351237384809\n",
      "epoch: 420 loss: 1.7337199449539185 grad: 12.808301701025654\n",
      "epoch: 421 loss: 1.7208740711212158 grad: 11.539407493047682\n",
      "epoch: 422 loss: 1.722730278968811 grad: 11.73194053185187\n",
      "epoch: 423 loss: 1.729977011680603 grad: 12.415759170952711\n",
      "epoch: 424 loss: 1.7247648239135742 grad: 12.447666901895511\n",
      "epoch: 425 loss: 1.7180099487304688 grad: 12.099343167965316\n",
      "epoch: 426 loss: 1.7280070781707764 grad: 11.603864195771397\n",
      "epoch: 427 loss: 1.723912239074707 grad: 11.64441708581049\n",
      "epoch: 428 loss: 1.7311735153198242 grad: 12.646749603192484\n",
      "epoch: 429 loss: 1.7160381078720093 grad: 12.1530425091688\n",
      "epoch: 430 loss: 1.7359424829483032 grad: 12.07270209915522\n",
      "epoch: 431 loss: 1.7289025783538818 grad: 11.53887735517873\n",
      "epoch: 432 loss: 1.7203272581100464 grad: 11.309251914673027\n",
      "epoch: 433 loss: 1.7228598594665527 grad: 12.516169893163596\n",
      "epoch: 434 loss: 1.723789930343628 grad: 12.680311500050482\n",
      "epoch: 435 loss: 1.7222357988357544 grad: 11.86192142195438\n",
      "epoch: 436 loss: 1.7216641902923584 grad: 11.437829011666869\n",
      "epoch: 437 loss: 1.7239872217178345 grad: 12.41138836050347\n",
      "epoch: 438 loss: 1.722424030303955 grad: 11.854438919389237\n",
      "epoch: 439 loss: 1.7153408527374268 grad: 11.766926442997324\n",
      "epoch: 440 loss: 1.7185322046279907 grad: 12.709599558264017\n",
      "epoch: 441 loss: 1.724982738494873 grad: 12.134310737156147\n",
      "epoch: 442 loss: 1.7214382886886597 grad: 11.759398418308665\n",
      "epoch: 443 loss: 1.7174283266067505 grad: 12.290359553356197\n",
      "epoch: 444 loss: 1.7233003377914429 grad: 12.30039205209219\n",
      "epoch: 445 loss: 1.724381685256958 grad: 13.1347719214354\n",
      "epoch: 446 loss: 1.7139781713485718 grad: 12.08486256300516\n",
      "epoch: 447 loss: 1.7115492820739746 grad: 11.678046889802706\n",
      "epoch: 448 loss: 1.7232009172439575 grad: 11.603508960470439\n",
      "epoch: 449 loss: 1.7150267362594604 grad: 11.753271768786131\n",
      "epoch: 450 loss: 1.7176398038864136 grad: 12.28314480436818\n",
      "epoch: 451 loss: 1.719604730606079 grad: 11.791443533626282\n",
      "epoch: 452 loss: 1.7173609733581543 grad: 11.80276945141691\n",
      "epoch: 453 loss: 1.7134038209915161 grad: 11.076672492208816\n",
      "epoch: 454 loss: 1.7181657552719116 grad: 12.134317623373741\n",
      "epoch: 455 loss: 1.7174694538116455 grad: 11.791303940353886\n",
      "epoch: 456 loss: 1.712437629699707 grad: 11.725349453632676\n",
      "epoch: 457 loss: 1.7180513143539429 grad: 11.946604815755217\n",
      "epoch: 458 loss: 1.7210055589675903 grad: 12.827015970330981\n",
      "epoch: 459 loss: 1.7169358730316162 grad: 11.662231310063767\n",
      "epoch: 460 loss: 1.7160924673080444 grad: 11.911844442554173\n",
      "epoch: 461 loss: 1.720071792602539 grad: 11.380824756852927\n",
      "epoch: 462 loss: 1.712337851524353 grad: 11.469167771423974\n",
      "epoch: 463 loss: 1.7167831659317017 grad: 11.994880230949512\n",
      "epoch: 464 loss: 1.7174955606460571 grad: 11.752280980740334\n",
      "epoch: 465 loss: 1.7139757871627808 grad: 12.195216046091879\n",
      "epoch: 466 loss: 1.7145015001296997 grad: 12.054204826346702\n",
      "epoch: 467 loss: 1.7158390283584595 grad: 11.813025005996996\n",
      "epoch: 468 loss: 1.7079931497573853 grad: 11.97445315135909\n",
      "epoch: 469 loss: 1.706092119216919 grad: 11.92057428085467\n",
      "epoch: 470 loss: 1.712320327758789 grad: 12.323615247642415\n",
      "epoch: 471 loss: 1.7130844593048096 grad: 11.62183873260039\n",
      "epoch: 472 loss: 1.7060966491699219 grad: 12.267898710791968\n",
      "epoch: 473 loss: 1.7116032838821411 grad: 12.43067335080917\n",
      "epoch: 474 loss: 1.7081376314163208 grad: 11.688435024980988\n",
      "epoch: 475 loss: 1.7068421840667725 grad: 12.650830383353409\n",
      "epoch: 476 loss: 1.7099794149398804 grad: 12.006859884626927\n",
      "epoch: 477 loss: 1.7063003778457642 grad: 11.662967845427966\n",
      "epoch: 478 loss: 1.7095303535461426 grad: 11.39078585294977\n",
      "epoch: 479 loss: 1.7098476886749268 grad: 12.754576196143818\n",
      "epoch: 480 loss: 1.7077898979187012 grad: 11.621527945888895\n",
      "epoch: 481 loss: 1.7131202220916748 grad: 11.72093748940628\n",
      "epoch: 482 loss: 1.7038662433624268 grad: 11.681931632186567\n",
      "epoch: 483 loss: 1.711658000946045 grad: 11.443462527482696\n",
      "epoch: 484 loss: 1.7124531269073486 grad: 12.52403060954419\n",
      "epoch: 485 loss: 1.709993600845337 grad: 12.034686414229254\n",
      "epoch: 486 loss: 1.7127710580825806 grad: 11.542092019049008\n",
      "epoch: 487 loss: 1.7030459642410278 grad: 12.072675689567058\n",
      "epoch: 488 loss: 1.7047439813613892 grad: 11.966728365300076\n",
      "epoch: 489 loss: 1.7059253454208374 grad: 11.477623621112711\n",
      "epoch: 490 loss: 1.7101199626922607 grad: 12.263683330770286\n",
      "epoch: 491 loss: 1.7010829448699951 grad: 12.116363849394792\n",
      "epoch: 492 loss: 1.709607481956482 grad: 12.265253055663337\n",
      "epoch: 493 loss: 1.6985944509506226 grad: 12.315997844901942\n",
      "epoch: 494 loss: 1.7109577655792236 grad: 12.632386386172758\n",
      "epoch: 495 loss: 1.697003722190857 grad: 11.815717589804931\n",
      "epoch: 496 loss: 1.7065469026565552 grad: 11.903892461713108\n",
      "epoch: 497 loss: 1.7048256397247314 grad: 12.421050685391362\n",
      "epoch: 498 loss: 1.6977933645248413 grad: 12.156014896286209\n",
      "epoch: 499 loss: 1.7002521753311157 grad: 12.411578007500678\n",
      "1.9625417068600655\n",
      "epoch: 0 loss: 2.298142433166504 grad: 1.1326858702148976\n",
      "epoch: 1 loss: 2.2435970306396484 grad: 2.069607363679328\n",
      "epoch: 2 loss: 2.17983078956604 grad: 2.657244278805419\n",
      "epoch: 3 loss: 2.1192328929901123 grad: 2.8120457186365484\n",
      "epoch: 4 loss: 2.100983142852783 grad: 3.5082043520939936\n",
      "epoch: 5 loss: 2.061006546020508 grad: 3.92222279308009\n",
      "epoch: 6 loss: 2.0127053260803223 grad: 5.035094122969664\n",
      "epoch: 7 loss: 1.9959702491760254 grad: 4.96051114818473\n",
      "epoch: 8 loss: 1.975014567375183 grad: 5.668927460483881\n",
      "epoch: 9 loss: 1.9467393159866333 grad: 5.324054778840888\n",
      "epoch: 10 loss: 1.9346014261245728 grad: 5.676178460268097\n",
      "epoch: 11 loss: 1.9395034313201904 grad: 5.9486280336462345\n",
      "epoch: 12 loss: 1.9035265445709229 grad: 5.840790311557367\n",
      "epoch: 13 loss: 1.9025487899780273 grad: 6.184162744334788\n",
      "epoch: 14 loss: 1.886190414428711 grad: 6.430917551454585\n",
      "epoch: 15 loss: 1.8748480081558228 grad: 5.603766181714101\n",
      "epoch: 16 loss: 1.8789687156677246 grad: 5.911823592412041\n",
      "epoch: 17 loss: 1.8566827774047852 grad: 5.365693569619907\n",
      "epoch: 18 loss: 1.8563177585601807 grad: 5.9555960954980005\n",
      "epoch: 19 loss: 1.8293837308883667 grad: 6.502930340130762\n",
      "epoch: 20 loss: 1.8453092575073242 grad: 5.84317242922557\n",
      "epoch: 21 loss: 1.826203465461731 grad: 6.5685710458520115\n",
      "epoch: 22 loss: 1.808691143989563 grad: 5.6894386380320485\n",
      "epoch: 23 loss: 1.8032753467559814 grad: 5.507364515796773\n",
      "epoch: 24 loss: 1.7956384420394897 grad: 5.690106090176703\n",
      "epoch: 25 loss: 1.78521728515625 grad: 5.630360953491098\n",
      "epoch: 26 loss: 1.8094056844711304 grad: 5.850139033358862\n",
      "epoch: 27 loss: 1.7980376482009888 grad: 5.55384615941425\n",
      "epoch: 28 loss: 1.7897840738296509 grad: 5.3445311119726355\n",
      "epoch: 29 loss: 1.7867300510406494 grad: 5.714163924356283\n",
      "epoch: 30 loss: 1.8142980337142944 grad: 6.394578547934384\n",
      "epoch: 31 loss: 1.7883082628250122 grad: 5.875221377792759\n",
      "epoch: 32 loss: 1.7671161890029907 grad: 5.501624857734275\n",
      "epoch: 33 loss: 1.796080470085144 grad: 6.559151655347604\n",
      "epoch: 34 loss: 1.7837024927139282 grad: 6.650597978442896\n",
      "epoch: 35 loss: 1.7485612630844116 grad: 5.868162313257695\n",
      "epoch: 36 loss: 1.740864872932434 grad: 7.028446835294802\n",
      "epoch: 37 loss: 1.727007269859314 grad: 6.932006510166777\n",
      "epoch: 38 loss: 1.7198433876037598 grad: 6.713823487148768\n",
      "epoch: 39 loss: 1.7176839113235474 grad: 6.991779418577651\n",
      "epoch: 40 loss: 1.7085845470428467 grad: 6.44332279545802\n",
      "epoch: 41 loss: 1.6987353563308716 grad: 6.862641812712398\n",
      "epoch: 42 loss: 1.6975127458572388 grad: 6.924972222532175\n",
      "epoch: 43 loss: 1.6703791618347168 grad: 6.854277069091848\n",
      "epoch: 44 loss: 1.6777294874191284 grad: 6.806405288098927\n",
      "epoch: 45 loss: 1.6880825757980347 grad: 6.909293488896404\n",
      "epoch: 46 loss: 1.6741043329238892 grad: 6.833224126811339\n",
      "epoch: 47 loss: 1.6805254220962524 grad: 5.890085230993535\n",
      "epoch: 48 loss: 1.653607726097107 grad: 6.173546472207702\n",
      "epoch: 49 loss: 1.6423555612564087 grad: 6.272787442608942\n",
      "epoch: 50 loss: 1.6449542045593262 grad: 6.432724608269165\n",
      "epoch: 51 loss: 1.6469475030899048 grad: 7.2508293245986035\n",
      "epoch: 52 loss: 1.6685177087783813 grad: 8.060075271606264\n",
      "epoch: 53 loss: 1.6638286113739014 grad: 6.4177529845217665\n",
      "epoch: 54 loss: 1.6553754806518555 grad: 6.783094130514771\n",
      "epoch: 55 loss: 1.6608965396881104 grad: 6.48977061785898\n",
      "epoch: 56 loss: 1.67315673828125 grad: 7.01724054916468\n",
      "epoch: 57 loss: 1.6397103071212769 grad: 6.09494511157229\n",
      "epoch: 58 loss: 1.64589262008667 grad: 7.288606574376495\n",
      "epoch: 59 loss: 1.6290034055709839 grad: 6.533393926012477\n",
      "epoch: 60 loss: 1.6374754905700684 grad: 6.831818979299564\n",
      "epoch: 61 loss: 1.6232482194900513 grad: 5.502985560983587\n",
      "epoch: 62 loss: 1.6237070560455322 grad: 6.135434077817153\n",
      "epoch: 63 loss: 1.6312625408172607 grad: 7.1433766288206995\n",
      "epoch: 64 loss: 1.636734962463379 grad: 5.837537865524942\n",
      "epoch: 65 loss: 1.6245687007904053 grad: 6.383365235143708\n",
      "epoch: 66 loss: 1.6201741695404053 grad: 5.948334105807878\n",
      "epoch: 67 loss: 1.6178669929504395 grad: 7.90997709041655\n",
      "epoch: 68 loss: 1.6150039434432983 grad: 5.60999797350238\n",
      "epoch: 69 loss: 1.6249216794967651 grad: 5.136167986112743\n",
      "epoch: 70 loss: 1.6474132537841797 grad: 6.722685402014851\n",
      "epoch: 71 loss: 1.6206258535385132 grad: 6.246588469846294\n",
      "epoch: 72 loss: 1.6360048055648804 grad: 6.272415696155428\n",
      "epoch: 73 loss: 1.6173183917999268 grad: 6.740385266773205\n",
      "epoch: 74 loss: 1.6026363372802734 grad: 6.336697468005335\n",
      "epoch: 75 loss: 1.6106841564178467 grad: 5.386746628685831\n",
      "epoch: 76 loss: 1.6095967292785645 grad: 6.1495386248176604\n",
      "epoch: 77 loss: 1.6301651000976562 grad: 7.035902722605175\n",
      "epoch: 78 loss: 1.6140506267547607 grad: 5.921612103373581\n",
      "epoch: 79 loss: 1.6206039190292358 grad: 5.950215512503097\n",
      "epoch: 80 loss: 1.611162543296814 grad: 6.458633060725232\n",
      "epoch: 81 loss: 1.6038204431533813 grad: 6.337767052664103\n",
      "epoch: 82 loss: 1.6024140119552612 grad: 5.292992408181672\n",
      "epoch: 83 loss: 1.6053147315979004 grad: 5.878637661904259\n",
      "epoch: 84 loss: 1.6056396961212158 grad: 5.392467947264474\n",
      "epoch: 85 loss: 1.598933458328247 grad: 6.514101888789088\n",
      "epoch: 86 loss: 1.6160802841186523 grad: 6.436149189841094\n",
      "epoch: 87 loss: 1.6309282779693604 grad: 6.3484262351773815\n",
      "epoch: 88 loss: 1.5963420867919922 grad: 5.096617707835697\n",
      "epoch: 89 loss: 1.6072461605072021 grad: 5.69833370772222\n",
      "epoch: 90 loss: 1.5977756977081299 grad: 6.680144136252657\n",
      "epoch: 91 loss: 1.5976074934005737 grad: 6.48596588580262\n",
      "epoch: 92 loss: 1.5883830785751343 grad: 4.80141818625103\n",
      "epoch: 93 loss: 1.5896779298782349 grad: 6.131370784578419\n",
      "epoch: 94 loss: 1.5905849933624268 grad: 5.400290361478313\n",
      "epoch: 95 loss: 1.5977251529693604 grad: 5.014730124364192\n",
      "epoch: 96 loss: 1.5961277484893799 grad: 5.800252603746302\n",
      "epoch: 97 loss: 1.5903539657592773 grad: 6.569984603236085\n",
      "epoch: 98 loss: 1.575278401374817 grad: 4.960592818601086\n",
      "epoch: 99 loss: 1.569912075996399 grad: 4.501962492348462\n",
      "epoch: 100 loss: 1.5909186601638794 grad: 5.877463947842588\n",
      "epoch: 101 loss: 1.595752477645874 grad: 6.741815203803598\n",
      "epoch: 102 loss: 1.6020082235336304 grad: 5.486097091739451\n",
      "epoch: 103 loss: 1.5774426460266113 grad: 5.869859680619089\n",
      "epoch: 104 loss: 1.5921913385391235 grad: 6.195032107023999\n",
      "epoch: 105 loss: 1.5884954929351807 grad: 5.020145598456455\n",
      "epoch: 106 loss: 1.5756925344467163 grad: 5.22258600938175\n",
      "epoch: 107 loss: 1.599351167678833 grad: 6.038674054256349\n",
      "epoch: 108 loss: 1.5761139392852783 grad: 5.914195690822215\n",
      "epoch: 109 loss: 1.587417483329773 grad: 4.516378088851337\n",
      "epoch: 110 loss: 1.587753415107727 grad: 5.66155536296437\n",
      "epoch: 111 loss: 1.5901286602020264 grad: 6.15887793476063\n",
      "epoch: 112 loss: 1.5740536451339722 grad: 5.103533499846183\n",
      "epoch: 113 loss: 1.611810326576233 grad: 6.783404944073048\n",
      "epoch: 114 loss: 1.5996192693710327 grad: 5.673473809415483\n",
      "epoch: 115 loss: 1.5793436765670776 grad: 5.610696111865908\n",
      "epoch: 116 loss: 1.5948973894119263 grad: 5.633765424315019\n",
      "epoch: 117 loss: 1.5717456340789795 grad: 5.2816247063381265\n",
      "epoch: 118 loss: 1.6098138093948364 grad: 4.367398183309397\n",
      "epoch: 119 loss: 1.573014497756958 grad: 4.588595882504099\n",
      "epoch: 120 loss: 1.611656904220581 grad: 6.384782956017601\n",
      "epoch: 121 loss: 1.5827566385269165 grad: 5.345011511309196\n",
      "epoch: 122 loss: 1.6332378387451172 grad: 6.534384812643537\n",
      "epoch: 123 loss: 1.5716699361801147 grad: 4.870190621870396\n",
      "epoch: 124 loss: 1.5650736093521118 grad: 4.819829934869812\n",
      "epoch: 125 loss: 1.575243592262268 grad: 5.079618106734415\n",
      "epoch: 126 loss: 1.5551105737686157 grad: 4.392201217373821\n",
      "epoch: 127 loss: 1.5777338743209839 grad: 5.716836529903813\n",
      "epoch: 128 loss: 1.5802605152130127 grad: 4.83232292227119\n",
      "epoch: 129 loss: 1.5747982263565063 grad: 5.031988768497184\n",
      "epoch: 130 loss: 1.5786731243133545 grad: 5.015662342986205\n",
      "epoch: 131 loss: 1.572550654411316 grad: 4.395361565688009\n",
      "epoch: 132 loss: 1.5726325511932373 grad: 4.716402509918117\n",
      "epoch: 133 loss: 1.5840928554534912 grad: 4.95038281585705\n",
      "epoch: 134 loss: 1.6070442199707031 grad: 5.032640591674863\n",
      "epoch: 135 loss: 1.569732904434204 grad: 5.184839435648193\n",
      "epoch: 136 loss: 1.5684070587158203 grad: 4.430444823826252\n",
      "epoch: 137 loss: 1.5719058513641357 grad: 4.481328233430405\n",
      "epoch: 138 loss: 1.5740759372711182 grad: 4.609171560387502\n",
      "epoch: 139 loss: 1.5634973049163818 grad: 4.432790706887967\n",
      "epoch: 140 loss: 1.5515106916427612 grad: 3.3579259110486253\n",
      "epoch: 141 loss: 1.5872141122817993 grad: 5.40271126281258\n",
      "epoch: 142 loss: 1.5726354122161865 grad: 4.715317679829954\n",
      "epoch: 143 loss: 1.5548536777496338 grad: 4.65014150156463\n",
      "epoch: 144 loss: 1.5768218040466309 grad: 5.667135811964295\n",
      "epoch: 145 loss: 1.5649696588516235 grad: 5.421278529281338\n",
      "epoch: 146 loss: 1.5739930868148804 grad: 3.875750712719898\n",
      "epoch: 147 loss: 1.5624827146530151 grad: 4.314899564973039\n",
      "epoch: 148 loss: 1.5681617259979248 grad: 5.616685266352731\n",
      "epoch: 149 loss: 1.5760935544967651 grad: 4.374503157773342\n",
      "epoch: 150 loss: 1.5625561475753784 grad: 3.913876339119212\n",
      "epoch: 151 loss: 1.562477469444275 grad: 5.309096956869814\n",
      "epoch: 152 loss: 1.563660740852356 grad: 3.9852703033731096\n",
      "epoch: 153 loss: 1.5633474588394165 grad: 3.424680044880217\n",
      "epoch: 154 loss: 1.5632096529006958 grad: 5.226180431176051\n",
      "epoch: 155 loss: 1.5631459951400757 grad: 3.9521447858652277\n",
      "epoch: 156 loss: 1.57187020778656 grad: 5.38244226797711\n",
      "epoch: 157 loss: 1.5604442358016968 grad: 4.22192387238258\n",
      "epoch: 158 loss: 1.5560870170593262 grad: 4.331535021481597\n",
      "epoch: 159 loss: 1.5685172080993652 grad: 4.731512969953735\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 160 loss: 1.5596868991851807 grad: 4.682796813449591\n",
      "epoch: 161 loss: 1.594649314880371 grad: 5.061901360107712\n",
      "epoch: 162 loss: 1.5711499452590942 grad: 5.022388573950434\n",
      "epoch: 163 loss: 1.578740119934082 grad: 6.017282534561877\n",
      "epoch: 164 loss: 1.5822137594223022 grad: 4.479915291790392\n",
      "epoch: 165 loss: 1.5980943441390991 grad: 5.593877582125104\n",
      "epoch: 166 loss: 1.558748722076416 grad: 4.298501922887968\n",
      "epoch: 167 loss: 1.564324975013733 grad: 3.5439026550659887\n",
      "epoch: 168 loss: 1.5601420402526855 grad: 4.489926371308815\n",
      "epoch: 169 loss: 1.5596990585327148 grad: 4.333564317998322\n",
      "epoch: 170 loss: 1.558607816696167 grad: 4.380301988773448\n",
      "epoch: 171 loss: 1.5586862564086914 grad: 3.190614202738974\n",
      "epoch: 172 loss: 1.5552997589111328 grad: 3.988845153714394\n",
      "epoch: 173 loss: 1.5617423057556152 grad: 4.854814648153264\n",
      "epoch: 174 loss: 1.5654535293579102 grad: 4.985969937692336\n",
      "epoch: 175 loss: 1.5734370946884155 grad: 3.7049276816665144\n",
      "epoch: 176 loss: 1.5688371658325195 grad: 3.993338766109647\n",
      "epoch: 177 loss: 1.5610628128051758 grad: 4.261232802989195\n",
      "epoch: 178 loss: 1.5499306917190552 grad: 4.730551415198851\n",
      "epoch: 179 loss: 1.5912294387817383 grad: 5.481442308397882\n",
      "epoch: 180 loss: 1.5575112104415894 grad: 3.7584486291757004\n",
      "epoch: 181 loss: 1.5597662925720215 grad: 4.596684491008147\n",
      "epoch: 182 loss: 1.5441060066223145 grad: 3.50328404595189\n",
      "epoch: 183 loss: 1.5615023374557495 grad: 4.5773406441678075\n",
      "epoch: 184 loss: 1.569685459136963 grad: 4.633557696945683\n",
      "epoch: 185 loss: 1.5601351261138916 grad: 3.7782251286793116\n",
      "epoch: 186 loss: 1.559968113899231 grad: 4.967615677636612\n",
      "epoch: 187 loss: 1.5639058351516724 grad: 4.303484349716766\n",
      "epoch: 188 loss: 1.5703247785568237 grad: 5.224974440386507\n",
      "epoch: 189 loss: 1.5565404891967773 grad: 4.275725164583587\n",
      "epoch: 190 loss: 1.551386833190918 grad: 3.889607524601423\n",
      "epoch: 191 loss: 1.554401159286499 grad: 4.446795029205629\n",
      "epoch: 192 loss: 1.5626174211502075 grad: 4.962996979275998\n",
      "epoch: 193 loss: 1.5657284259796143 grad: 4.735687218255357\n",
      "epoch: 194 loss: 1.5545933246612549 grad: 5.03667214315978\n",
      "epoch: 195 loss: 1.5570322275161743 grad: 3.827261400327465\n",
      "epoch: 196 loss: 1.5818116664886475 grad: 6.466143202957619\n",
      "epoch: 197 loss: 1.5643881559371948 grad: 5.603338183022732\n",
      "epoch: 198 loss: 1.5521358251571655 grad: 3.9995643379942467\n",
      "epoch: 199 loss: 1.5470696687698364 grad: 4.236413938806442\n",
      "epoch: 200 loss: 1.553037166595459 grad: 4.4808887030323055\n",
      "epoch: 201 loss: 1.5430965423583984 grad: 2.9440625876216497\n",
      "epoch: 202 loss: 1.546114444732666 grad: 4.24272967116117\n",
      "epoch: 203 loss: 1.5514637231826782 grad: 5.515024022368172\n",
      "epoch: 204 loss: 1.5544992685317993 grad: 4.484708751707509\n",
      "epoch: 205 loss: 1.5667203664779663 grad: 4.768639386164232\n",
      "epoch: 206 loss: 1.552595853805542 grad: 3.194645356068643\n",
      "epoch: 207 loss: 1.5589486360549927 grad: 4.041482884967292\n",
      "epoch: 208 loss: 1.5831749439239502 grad: 5.38437325698545\n",
      "epoch: 209 loss: 1.552882194519043 grad: 4.082912810739375\n",
      "epoch: 210 loss: 1.5479778051376343 grad: 4.548900385181202\n",
      "epoch: 211 loss: 1.55524480342865 grad: 3.0480961464609972\n",
      "epoch: 212 loss: 1.5535223484039307 grad: 4.0518962334642135\n",
      "epoch: 213 loss: 1.5475521087646484 grad: 3.782902036219377\n",
      "epoch: 214 loss: 1.5383652448654175 grad: 3.0418137778823944\n",
      "epoch: 215 loss: 1.5413024425506592 grad: 3.3349459894475273\n",
      "epoch: 216 loss: 1.547872543334961 grad: 4.175170722226392\n",
      "epoch: 217 loss: 1.5632020235061646 grad: 6.149126087886902\n",
      "epoch: 218 loss: 1.5753828287124634 grad: 5.360531567957402\n",
      "epoch: 219 loss: 1.5713422298431396 grad: 4.885063410588703\n",
      "epoch: 220 loss: 1.5679954290390015 grad: 4.103344933361994\n",
      "epoch: 221 loss: 1.552192211151123 grad: 3.977152246402194\n",
      "epoch: 222 loss: 1.5455673933029175 grad: 4.558968840234705\n",
      "epoch: 223 loss: 1.575086236000061 grad: 4.795504611507979\n",
      "epoch: 224 loss: 1.5651612281799316 grad: 4.549463211654251\n",
      "epoch: 225 loss: 1.5575990676879883 grad: 4.015043459387525\n",
      "epoch: 226 loss: 1.5673604011535645 grad: 5.102615768094193\n",
      "epoch: 227 loss: 1.5801260471343994 grad: 4.365554886322422\n",
      "epoch: 228 loss: 1.550958275794983 grad: 4.282163495207423\n",
      "epoch: 229 loss: 1.5632280111312866 grad: 4.060110044959566\n",
      "epoch: 230 loss: 1.5592604875564575 grad: 5.290174257724853\n",
      "epoch: 231 loss: 1.5540640354156494 grad: 3.334936264645531\n",
      "epoch: 232 loss: 1.561643362045288 grad: 4.3399500367736215\n",
      "epoch: 233 loss: 1.5580881834030151 grad: 3.76478691662387\n",
      "epoch: 234 loss: 1.5609568357467651 grad: 5.159351615449141\n",
      "epoch: 235 loss: 1.5864670276641846 grad: 4.541473233696273\n",
      "epoch: 236 loss: 1.5847859382629395 grad: 4.991871181658916\n",
      "epoch: 237 loss: 1.5628753900527954 grad: 3.4512666733893456\n",
      "epoch: 238 loss: 1.5727736949920654 grad: 3.813990179895692\n",
      "epoch: 239 loss: 1.5474317073822021 grad: 4.385540922196536\n",
      "epoch: 240 loss: 1.5459449291229248 grad: 4.25749637275615\n",
      "epoch: 241 loss: 1.5586141347885132 grad: 4.496845392035046\n",
      "epoch: 242 loss: 1.557650089263916 grad: 3.7272159721743297\n",
      "epoch: 243 loss: 1.554362177848816 grad: 2.8738594863209608\n",
      "epoch: 244 loss: 1.5471587181091309 grad: 3.215916490755157\n",
      "epoch: 245 loss: 1.5503246784210205 grad: 4.5544374798018605\n",
      "epoch: 246 loss: 1.5538588762283325 grad: 3.686475534363052\n",
      "epoch: 247 loss: 1.5426173210144043 grad: 3.1468691544798557\n",
      "epoch: 248 loss: 1.5474385023117065 grad: 4.309504983896527\n",
      "epoch: 249 loss: 1.5603331327438354 grad: 3.78033785528601\n",
      "epoch: 250 loss: 1.5403542518615723 grad: 3.0490964839557773\n",
      "epoch: 251 loss: 1.5456055402755737 grad: 2.574179966433734\n",
      "epoch: 252 loss: 1.5611661672592163 grad: 4.305165160245004\n",
      "epoch: 253 loss: 1.5663200616836548 grad: 3.5769872832728318\n",
      "epoch: 254 loss: 1.5430724620819092 grad: 3.9426098025939136\n",
      "epoch: 255 loss: 1.5720983743667603 grad: 4.847951638140795\n",
      "epoch: 256 loss: 1.5470067262649536 grad: 3.9453745574873973\n",
      "epoch: 257 loss: 1.5424060821533203 grad: 4.441526837582048\n",
      "epoch: 258 loss: 1.5376406908035278 grad: 3.3108623366563936\n",
      "epoch: 259 loss: 1.5754332542419434 grad: 4.570732554553059\n",
      "epoch: 260 loss: 1.5401273965835571 grad: 3.4115015138509155\n",
      "epoch: 261 loss: 1.5512291193008423 grad: 3.0817236607589558\n",
      "epoch: 262 loss: 1.5350079536437988 grad: 3.325461561658895\n",
      "epoch: 263 loss: 1.5649867057800293 grad: 3.988652398071014\n",
      "epoch: 264 loss: 1.5565061569213867 grad: 3.7404546909064265\n",
      "epoch: 265 loss: 1.545505404472351 grad: 3.5199558863388103\n",
      "epoch: 266 loss: 1.5639158487319946 grad: 4.975348363707961\n",
      "epoch: 267 loss: 1.5509099960327148 grad: 3.8489982272146133\n",
      "epoch: 268 loss: 1.565504789352417 grad: 4.677604647022043\n",
      "epoch: 269 loss: 1.564517617225647 grad: 5.28172258423413\n",
      "epoch: 270 loss: 1.5480438470840454 grad: 3.512110491713482\n",
      "epoch: 271 loss: 1.54944908618927 grad: 3.1875475465469547\n",
      "epoch: 272 loss: 1.5531752109527588 grad: 3.6171744648070696\n",
      "epoch: 273 loss: 1.5687611103057861 grad: 4.220594198970018\n",
      "epoch: 274 loss: 1.5527290105819702 grad: 3.684724147347612\n",
      "epoch: 275 loss: 1.541800856590271 grad: 3.7217646615298885\n",
      "epoch: 276 loss: 1.5670677423477173 grad: 4.072736717024309\n",
      "epoch: 277 loss: 1.55024254322052 grad: 4.191125105290233\n",
      "epoch: 278 loss: 1.5539560317993164 grad: 3.959566822218836\n",
      "epoch: 279 loss: 1.5482823848724365 grad: 4.474269704543944\n",
      "epoch: 280 loss: 1.5523189306259155 grad: 2.7617298106878505\n",
      "epoch: 281 loss: 1.5386065244674683 grad: 3.0061667810052595\n",
      "epoch: 282 loss: 1.5477770566940308 grad: 3.3431926359754325\n",
      "epoch: 283 loss: 1.553252100944519 grad: 3.5645044955842673\n",
      "epoch: 284 loss: 1.5394697189331055 grad: 3.3868408959785765\n",
      "epoch: 285 loss: 1.5771377086639404 grad: 3.750069807395782\n",
      "epoch: 286 loss: 1.534051537513733 grad: 3.719492316442913\n",
      "epoch: 287 loss: 1.5407541990280151 grad: 3.0967206431510816\n",
      "epoch: 288 loss: 1.5412466526031494 grad: 3.008126760628889\n",
      "epoch: 289 loss: 1.5445010662078857 grad: 3.130239828791412\n",
      "epoch: 290 loss: 1.5303007364273071 grad: 2.0260793497044673\n",
      "epoch: 291 loss: 1.545344352722168 grad: 3.2105198743152257\n",
      "epoch: 292 loss: 1.5437031984329224 grad: 5.09825735276054\n",
      "epoch: 293 loss: 1.538250207901001 grad: 3.485426409441366\n",
      "epoch: 294 loss: 1.5452550649642944 grad: 3.210373743885205\n",
      "epoch: 295 loss: 1.536417841911316 grad: 3.846776172880939\n",
      "epoch: 296 loss: 1.5349090099334717 grad: 2.1274466607483173\n",
      "epoch: 297 loss: 1.5475221872329712 grad: 3.880759626523422\n",
      "epoch: 298 loss: 1.5414681434631348 grad: 3.5649311299833966\n",
      "epoch: 299 loss: 1.5421302318572998 grad: 5.399468366206267\n",
      "epoch: 300 loss: 1.5681244134902954 grad: 4.295521120591852\n",
      "epoch: 301 loss: 1.572790503501892 grad: 5.725774292593273\n",
      "epoch: 302 loss: 1.5472638607025146 grad: 3.433457385546156\n",
      "epoch: 303 loss: 1.525829792022705 grad: 3.0168146230724457\n",
      "epoch: 304 loss: 1.5303382873535156 grad: 2.987628098294068\n",
      "epoch: 305 loss: 1.5360511541366577 grad: 3.9712886795474738\n",
      "epoch: 306 loss: 1.547860026359558 grad: 4.185714087388682\n",
      "epoch: 307 loss: 1.5508843660354614 grad: 4.327990609628481\n",
      "epoch: 308 loss: 1.5490108728408813 grad: 3.675452284521357\n",
      "epoch: 309 loss: 1.5303081274032593 grad: 3.5387667134426333\n",
      "epoch: 310 loss: 1.5525840520858765 grad: 4.836855042550053\n",
      "epoch: 311 loss: 1.5434370040893555 grad: 3.8441790854522844\n",
      "epoch: 312 loss: 1.5494465827941895 grad: 3.7061808487271044\n",
      "epoch: 313 loss: 1.5473735332489014 grad: 3.8530527237086107\n",
      "epoch: 314 loss: 1.5384478569030762 grad: 2.31810329441126\n",
      "epoch: 315 loss: 1.5306966304779053 grad: 3.1429799647783514\n",
      "epoch: 316 loss: 1.5308620929718018 grad: 3.690698708360699\n",
      "epoch: 317 loss: 1.541642189025879 grad: 2.7717833068065025\n",
      "epoch: 318 loss: 1.5394690036773682 grad: 3.343349408880629\n",
      "epoch: 319 loss: 1.553550124168396 grad: 3.4747912184297634\n",
      "epoch: 320 loss: 1.5384420156478882 grad: 2.2455718568469574\n",
      "epoch: 321 loss: 1.5292612314224243 grad: 2.5586539999311597\n",
      "epoch: 322 loss: 1.5371488332748413 grad: 2.842459824766498\n",
      "epoch: 323 loss: 1.543036699295044 grad: 3.8253271538075695\n",
      "epoch: 324 loss: 1.5477780103683472 grad: 2.825238895107659\n",
      "epoch: 325 loss: 1.5445398092269897 grad: 3.05513675085116\n",
      "epoch: 326 loss: 1.5474815368652344 grad: 3.8972531102509094\n",
      "epoch: 327 loss: 1.5392122268676758 grad: 3.921028036376583\n",
      "epoch: 328 loss: 1.5444445610046387 grad: 3.3404660884583515\n",
      "epoch: 329 loss: 1.547163963317871 grad: 2.7706093486813117\n",
      "epoch: 330 loss: 1.5568376779556274 grad: 3.5674329012452533\n",
      "epoch: 331 loss: 1.5423152446746826 grad: 3.6019807582662287\n",
      "epoch: 332 loss: 1.5561635494232178 grad: 3.34894945236071\n",
      "epoch: 333 loss: 1.5296478271484375 grad: 4.064607479395161\n",
      "epoch: 334 loss: 1.52971351146698 grad: 3.4851656641255775\n",
      "epoch: 335 loss: 1.5364749431610107 grad: 4.0766799939060165\n",
      "epoch: 336 loss: 1.5456477403640747 grad: 3.2292742701265054\n",
      "epoch: 337 loss: 1.5288654565811157 grad: 2.8569855636198107\n",
      "epoch: 338 loss: 1.533258080482483 grad: 2.0701121509653264\n",
      "epoch: 339 loss: 1.5314043760299683 grad: 2.797181975139559\n",
      "epoch: 340 loss: 1.540045142173767 grad: 4.515269587296205\n",
      "epoch: 341 loss: 1.5580363273620605 grad: 4.322736013454437\n",
      "epoch: 342 loss: 1.5482865571975708 grad: 3.480149946437823\n",
      "epoch: 343 loss: 1.5454193353652954 grad: 3.0188256169462613\n",
      "epoch: 344 loss: 1.5357584953308105 grad: 2.645916803339305\n",
      "epoch: 345 loss: 1.5469934940338135 grad: 4.269587559766312\n",
      "epoch: 346 loss: 1.5347378253936768 grad: 4.170618868944358\n",
      "epoch: 347 loss: 1.5451421737670898 grad: 3.733525784088077\n",
      "epoch: 348 loss: 1.5292840003967285 grad: 3.492642712481047\n",
      "epoch: 349 loss: 1.575232744216919 grad: 4.942894815052716\n",
      "epoch: 350 loss: 1.5605521202087402 grad: 3.6079315454365566\n",
      "epoch: 351 loss: 1.5529335737228394 grad: 3.451647371711637\n",
      "epoch: 352 loss: 1.5846033096313477 grad: 7.124416112896327\n",
      "epoch: 353 loss: 1.58657968044281 grad: 3.895463772689928\n",
      "epoch: 354 loss: 1.550875186920166 grad: 4.320259802528693\n",
      "epoch: 355 loss: 1.5678459405899048 grad: 4.010315287745697\n",
      "epoch: 356 loss: 1.5383931398391724 grad: 2.2466815349716676\n",
      "epoch: 357 loss: 1.5339629650115967 grad: 2.9250173044355665\n",
      "epoch: 358 loss: 1.5426254272460938 grad: 2.4279624201239662\n",
      "epoch: 359 loss: 1.5370697975158691 grad: 3.015193637229198\n",
      "epoch: 360 loss: 1.5411590337753296 grad: 3.4271238879337402\n",
      "epoch: 361 loss: 1.5390256643295288 grad: 3.420051343875959\n",
      "epoch: 362 loss: 1.5538791418075562 grad: 2.7426027676936013\n",
      "epoch: 363 loss: 1.5416452884674072 grad: 4.0111139799534925\n",
      "epoch: 364 loss: 1.533791422843933 grad: 4.630124842547418\n",
      "epoch: 365 loss: 1.5331447124481201 grad: 2.3758112073022843\n",
      "epoch: 366 loss: 1.5369716882705688 grad: 3.082667810919839\n",
      "epoch: 367 loss: 1.5344464778900146 grad: 3.3525807119806936\n",
      "epoch: 368 loss: 1.5489355325698853 grad: 3.165730383934854\n",
      "epoch: 369 loss: 1.5381841659545898 grad: 3.5066724687518342\n",
      "epoch: 370 loss: 1.5295727252960205 grad: 3.0013466772084385\n",
      "epoch: 371 loss: 1.5301153659820557 grad: 2.037522926404726\n",
      "epoch: 372 loss: 1.5460309982299805 grad: 4.342127863298479\n",
      "epoch: 373 loss: 1.5421409606933594 grad: 3.4433400313442735\n",
      "epoch: 374 loss: 1.5440400838851929 grad: 4.297921680194805\n",
      "epoch: 375 loss: 1.528894305229187 grad: 2.9295352381162427\n",
      "epoch: 376 loss: 1.5266005992889404 grad: 3.039955338425423\n",
      "epoch: 377 loss: 1.5410948991775513 grad: 2.7547863153157057\n",
      "epoch: 378 loss: 1.539795994758606 grad: 2.023174128666937\n",
      "epoch: 379 loss: 1.531397819519043 grad: 3.597256294721007\n",
      "epoch: 380 loss: 1.5618412494659424 grad: 4.934720713284811\n",
      "epoch: 381 loss: 1.5467051267623901 grad: 4.3640107312776015\n",
      "epoch: 382 loss: 1.582367181777954 grad: 5.273140084256829\n",
      "epoch: 383 loss: 1.6328039169311523 grad: 4.558981779493307\n",
      "epoch: 384 loss: 1.5372918844223022 grad: 2.763840333637225\n",
      "epoch: 385 loss: 1.5258432626724243 grad: 3.999552107802634\n",
      "epoch: 386 loss: 1.5535451173782349 grad: 3.7689120188873404\n",
      "epoch: 387 loss: 1.5354576110839844 grad: 2.331669405564845\n",
      "epoch: 388 loss: 1.5355294942855835 grad: 3.5384430474690096\n",
      "epoch: 389 loss: 1.526604175567627 grad: 3.3302273871811274\n",
      "epoch: 390 loss: 1.538772463798523 grad: 2.3865465351707886\n",
      "epoch: 391 loss: 1.530830979347229 grad: 2.6796690698833574\n",
      "epoch: 392 loss: 1.5207043886184692 grad: 2.836237639665893\n",
      "epoch: 393 loss: 1.5318989753723145 grad: 3.3192145303279603\n",
      "epoch: 394 loss: 1.5479810237884521 grad: 2.89576472484725\n",
      "epoch: 395 loss: 1.525604248046875 grad: 2.8896692635444174\n",
      "epoch: 396 loss: 1.5349382162094116 grad: 2.9344760989701393\n",
      "epoch: 397 loss: 1.5330309867858887 grad: 3.626598731789164\n",
      "epoch: 398 loss: 1.5326210260391235 grad: 3.2946183954529418\n",
      "epoch: 399 loss: 1.5208877325057983 grad: 3.1049141048183904\n",
      "epoch: 400 loss: 1.5207370519638062 grad: 3.8323841458213654\n",
      "epoch: 401 loss: 1.5649081468582153 grad: 3.411733693551473\n",
      "epoch: 402 loss: 1.5412564277648926 grad: 4.195836476113276\n",
      "epoch: 403 loss: 1.5572679042816162 grad: 3.140453797372715\n",
      "epoch: 404 loss: 1.5386024713516235 grad: 2.9824264398865563\n",
      "epoch: 405 loss: 1.5357666015625 grad: 3.316396586666865\n",
      "epoch: 406 loss: 1.5281628370285034 grad: 3.4187418614684186\n",
      "epoch: 407 loss: 1.5467936992645264 grad: 3.654028352739428\n",
      "epoch: 408 loss: 1.547446846961975 grad: 3.161092716535122\n",
      "epoch: 409 loss: 1.5414659976959229 grad: 3.3932142420125273\n",
      "epoch: 410 loss: 1.5296815633773804 grad: 3.1330721654302485\n",
      "epoch: 411 loss: 1.5417184829711914 grad: 4.504610877395673\n",
      "epoch: 412 loss: 1.5382764339447021 grad: 3.5112599483483335\n",
      "epoch: 413 loss: 1.5218498706817627 grad: 2.377221318603749\n",
      "epoch: 414 loss: 1.550854206085205 grad: 4.795281666236802\n",
      "epoch: 415 loss: 1.5355247259140015 grad: 3.1033908110167294\n",
      "epoch: 416 loss: 1.5618112087249756 grad: 4.212187540877769\n",
      "epoch: 417 loss: 1.5391731262207031 grad: 3.107255795814531\n",
      "epoch: 418 loss: 1.534593939781189 grad: 2.104239567532708\n",
      "epoch: 419 loss: 1.5503475666046143 grad: 4.356640339006815\n",
      "epoch: 420 loss: 1.5528123378753662 grad: 4.522397869708174\n",
      "epoch: 421 loss: 1.534433126449585 grad: 2.8790131823087513\n",
      "epoch: 422 loss: 1.5253134965896606 grad: 4.011947918589151\n",
      "epoch: 423 loss: 1.5284782648086548 grad: 2.935692083300381\n",
      "epoch: 424 loss: 1.5284000635147095 grad: 1.5579557262831671\n",
      "epoch: 425 loss: 1.5223991870880127 grad: 2.418719119994289\n",
      "epoch: 426 loss: 1.5266494750976562 grad: 3.482536566856158\n",
      "epoch: 427 loss: 1.5334645509719849 grad: 3.1121667547856973\n",
      "epoch: 428 loss: 1.542037010192871 grad: 4.984459972101656\n",
      "epoch: 429 loss: 1.538743495941162 grad: 4.54709828442613\n",
      "epoch: 430 loss: 1.5458507537841797 grad: 3.773288367336782\n",
      "epoch: 431 loss: 1.5539960861206055 grad: 2.291925106456768\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 432 loss: 1.5414714813232422 grad: 3.2781427752389023\n",
      "epoch: 433 loss: 1.5318913459777832 grad: 3.7937789667794735\n",
      "epoch: 434 loss: 1.530009388923645 grad: 2.0084958610170367\n",
      "epoch: 435 loss: 1.5438567399978638 grad: 3.810173892112925\n",
      "epoch: 436 loss: 1.5424548387527466 grad: 5.599964894400565\n",
      "epoch: 437 loss: 1.5449011325836182 grad: 4.550732926460388\n",
      "epoch: 438 loss: 1.5386310815811157 grad: 2.6376332010057832\n",
      "epoch: 439 loss: 1.546957015991211 grad: 4.341696945100159\n",
      "epoch: 440 loss: 1.5273025035858154 grad: 3.8909703835136553\n",
      "epoch: 441 loss: 1.5402579307556152 grad: 1.9246586816087563\n",
      "epoch: 442 loss: 1.5356403589248657 grad: 1.7561858035096634\n",
      "epoch: 443 loss: 1.5240756273269653 grad: 2.6358300026075705\n",
      "epoch: 444 loss: 1.5174375772476196 grad: 2.0771343417935\n",
      "epoch: 445 loss: 1.5390640497207642 grad: 3.014836540747261\n",
      "epoch: 446 loss: 1.5272495746612549 grad: 3.1075721061421957\n",
      "epoch: 447 loss: 1.5304853916168213 grad: 2.2624417414685367\n",
      "epoch: 448 loss: 1.5233821868896484 grad: 1.7116127995354808\n",
      "epoch: 449 loss: 1.5232387781143188 grad: 2.891304315010335\n",
      "epoch: 450 loss: 1.553462028503418 grad: 3.109340886494484\n",
      "epoch: 451 loss: 1.524091124534607 grad: 3.7592626242737603\n",
      "epoch: 452 loss: 1.5262863636016846 grad: 2.2089840242959835\n",
      "epoch: 453 loss: 1.5271464586257935 grad: 2.635908258060709\n",
      "epoch: 454 loss: 1.5308154821395874 grad: 3.20287354302117\n",
      "epoch: 455 loss: 1.5271005630493164 grad: 4.01594848638488\n",
      "epoch: 456 loss: 1.521009087562561 grad: 2.2488368718884324\n",
      "epoch: 457 loss: 1.5505170822143555 grad: 4.311598382277347\n",
      "epoch: 458 loss: 1.582287073135376 grad: 4.843323637527874\n",
      "epoch: 459 loss: 1.5337618589401245 grad: 3.195088195978596\n",
      "epoch: 460 loss: 1.5500837564468384 grad: 3.330253391488122\n",
      "epoch: 461 loss: 1.5220686197280884 grad: 1.7657245108221935\n",
      "epoch: 462 loss: 1.5282894372940063 grad: 1.7683665696987527\n",
      "epoch: 463 loss: 1.5248199701309204 grad: 1.4347773956555394\n",
      "epoch: 464 loss: 1.5266380310058594 grad: 2.4432446796309297\n",
      "epoch: 465 loss: 1.5247247219085693 grad: 3.700239664314674\n",
      "epoch: 466 loss: 1.5442330837249756 grad: 2.6694557556101515\n",
      "epoch: 467 loss: 1.5387383699417114 grad: 3.100162825907289\n",
      "epoch: 468 loss: 1.541400671005249 grad: 4.430646592484483\n",
      "epoch: 469 loss: 1.5270365476608276 grad: 2.550636987086697\n",
      "epoch: 470 loss: 1.5333300828933716 grad: 3.2739153928861646\n",
      "epoch: 471 loss: 1.5210886001586914 grad: 2.001290158221087\n",
      "epoch: 472 loss: 1.5292630195617676 grad: 2.323012673627781\n",
      "epoch: 473 loss: 1.5270380973815918 grad: 1.7766995212586276\n",
      "epoch: 474 loss: 1.5390748977661133 grad: 2.7325480662259483\n",
      "epoch: 475 loss: 1.540239930152893 grad: 1.5331362652087994\n",
      "epoch: 476 loss: 1.5442262887954712 grad: 2.6699753572054745\n",
      "epoch: 477 loss: 1.5216463804244995 grad: 3.0785469431597763\n",
      "epoch: 478 loss: 1.5180931091308594 grad: 1.9031842453330412\n",
      "epoch: 479 loss: 1.5455734729766846 grad: 4.764895031071846\n",
      "epoch: 480 loss: 1.5373005867004395 grad: 2.7618647545049164\n",
      "epoch: 481 loss: 1.5378847122192383 grad: 2.825496179275931\n",
      "epoch: 482 loss: 1.5280441045761108 grad: 3.7904277024087216\n",
      "epoch: 483 loss: 1.5236588716506958 grad: 3.101887340400616\n",
      "epoch: 484 loss: 1.53079092502594 grad: 2.4377626183917007\n",
      "epoch: 485 loss: 1.537256121635437 grad: 3.7245354439331693\n",
      "epoch: 486 loss: 1.5277879238128662 grad: 3.87597953793612\n",
      "epoch: 487 loss: 1.5226842164993286 grad: 2.229272998185554\n",
      "epoch: 488 loss: 1.5224484205245972 grad: 1.8261899685912066\n",
      "epoch: 489 loss: 1.5187448263168335 grad: 3.1880239082416155\n",
      "epoch: 490 loss: 1.5286058187484741 grad: 2.632673061863147\n",
      "epoch: 491 loss: 1.5236934423446655 grad: 3.046016020458402\n",
      "epoch: 492 loss: 1.525666356086731 grad: 3.743549490376634\n",
      "epoch: 493 loss: 1.545573353767395 grad: 3.672619139090875\n",
      "epoch: 494 loss: 1.5208110809326172 grad: 2.2531416050804904\n",
      "epoch: 495 loss: 1.530922532081604 grad: 3.5850580298628683\n",
      "epoch: 496 loss: 1.5353342294692993 grad: 3.9405241887495666\n",
      "epoch: 497 loss: 1.542830228805542 grad: 3.180191741947931\n",
      "epoch: 498 loss: 1.520666480064392 grad: 3.21466734049566\n",
      "epoch: 499 loss: 1.5200365781784058 grad: 2.004907667480744\n",
      "1.9226455241441727\n",
      "epoch: 0 loss: 2.3027167320251465 grad: 1.4492467565218075\n",
      "epoch: 1 loss: 2.302964448928833 grad: 1.448869688113013\n",
      "epoch: 2 loss: 2.3026983737945557 grad: 1.4441037752244266\n",
      "epoch: 3 loss: 2.301943778991699 grad: 1.4542746718876833\n",
      "epoch: 4 loss: 2.3027901649475098 grad: 1.4454854243261266\n",
      "epoch: 5 loss: 2.30271053314209 grad: 1.4448191039855518\n",
      "epoch: 6 loss: 2.3027901649475098 grad: 1.4497503194466441\n",
      "epoch: 7 loss: 2.3027377128601074 grad: 1.4503691622115198\n",
      "epoch: 8 loss: 2.3029818534851074 grad: 1.4427659098254813\n",
      "epoch: 9 loss: 2.302720069885254 grad: 1.4522430454565596\n",
      "epoch: 10 loss: 2.3024089336395264 grad: 1.4546843992956426\n",
      "epoch: 11 loss: 2.3024909496307373 grad: 1.462385796027125\n",
      "epoch: 12 loss: 2.3026998043060303 grad: 1.4506290877914234\n",
      "epoch: 13 loss: 2.3028879165649414 grad: 1.4471333151136243\n",
      "epoch: 14 loss: 2.302654504776001 grad: 1.4559694776359562\n",
      "epoch: 15 loss: 2.302098274230957 grad: 1.4599175210099755\n",
      "epoch: 16 loss: 2.3027124404907227 grad: 1.4454083340612078\n",
      "epoch: 17 loss: 2.3035295009613037 grad: 1.4367013502947337\n",
      "epoch: 18 loss: 2.3023996353149414 grad: 1.447685094576122\n",
      "epoch: 19 loss: 2.302375078201294 grad: 1.4506704242500876\n",
      "epoch: 20 loss: 2.3025031089782715 grad: 1.461566927048215\n",
      "epoch: 21 loss: 2.3025906085968018 grad: 1.456367174764016\n",
      "epoch: 22 loss: 2.3027453422546387 grad: 1.447296172184574\n",
      "epoch: 23 loss: 2.3025028705596924 grad: 1.4590453921765503\n",
      "epoch: 24 loss: 2.3024344444274902 grad: 1.4483587159220839\n",
      "epoch: 25 loss: 2.3023288249969482 grad: 1.4465167684783597\n",
      "epoch: 26 loss: 2.3023481369018555 grad: 1.4442972323713115\n",
      "epoch: 27 loss: 2.3023273944854736 grad: 1.4555256603681113\n",
      "epoch: 28 loss: 2.302600622177124 grad: 1.4609326235340199\n",
      "epoch: 29 loss: 2.3028416633605957 grad: 1.4479296824521577\n",
      "epoch: 30 loss: 2.302492618560791 grad: 1.4495793961095698\n",
      "epoch: 31 loss: 2.3020381927490234 grad: 1.4663979664873628\n",
      "epoch: 32 loss: 2.3026885986328125 grad: 1.4395093742835645\n",
      "epoch: 33 loss: 2.3019983768463135 grad: 1.4594766325502109\n",
      "epoch: 34 loss: 2.302150249481201 grad: 1.4620793105162206\n",
      "epoch: 35 loss: 2.3021390438079834 grad: 1.4585883507915285\n",
      "epoch: 36 loss: 2.3023266792297363 grad: 1.4584864701831801\n",
      "epoch: 37 loss: 2.302377939224243 grad: 1.4554122603564923\n",
      "epoch: 38 loss: 2.302165985107422 grad: 1.4641738889631741\n",
      "epoch: 39 loss: 2.3028085231781006 grad: 1.4588483276089566\n",
      "epoch: 40 loss: 2.3025636672973633 grad: 1.4565109943228198\n",
      "epoch: 41 loss: 2.3026440143585205 grad: 1.4572508971960771\n",
      "epoch: 42 loss: 2.302638530731201 grad: 1.448189806119199\n",
      "epoch: 43 loss: 2.3019704818725586 grad: 1.4666414098030636\n",
      "epoch: 44 loss: 2.3031060695648193 grad: 1.4486493495522097\n",
      "epoch: 45 loss: 2.302861213684082 grad: 1.4484258160246388\n",
      "epoch: 46 loss: 2.302767276763916 grad: 1.4434455356205858\n",
      "epoch: 47 loss: 2.3026323318481445 grad: 1.450473832777731\n",
      "epoch: 48 loss: 2.302712917327881 grad: 1.4594660761566567\n",
      "epoch: 49 loss: 2.302488327026367 grad: 1.4570181520640968\n",
      "epoch: 50 loss: 2.3024940490722656 grad: 1.453103542983872\n",
      "epoch: 51 loss: 2.302238941192627 grad: 1.450802440853006\n",
      "epoch: 52 loss: 2.3019206523895264 grad: 1.4591408509517176\n",
      "epoch: 53 loss: 2.3028316497802734 grad: 1.451797157540799\n",
      "epoch: 54 loss: 2.302590847015381 grad: 1.4522815988997795\n",
      "epoch: 55 loss: 2.302367925643921 grad: 1.4603281378236024\n",
      "epoch: 56 loss: 2.3024282455444336 grad: 1.4562508681408382\n",
      "epoch: 57 loss: 2.303253650665283 grad: 1.448105184747542\n",
      "epoch: 58 loss: 2.302669048309326 grad: 1.4440682611191675\n",
      "epoch: 59 loss: 2.3021631240844727 grad: 1.4523810182461545\n",
      "epoch: 60 loss: 2.3026325702667236 grad: 1.4434953316499197\n",
      "epoch: 61 loss: 2.3017404079437256 grad: 1.459409325150773\n",
      "epoch: 62 loss: 2.3029820919036865 grad: 1.4420762474146036\n",
      "epoch: 63 loss: 2.302349090576172 grad: 1.4553139412993683\n",
      "epoch: 64 loss: 2.302541971206665 grad: 1.4539074653478723\n",
      "epoch: 65 loss: 2.3023877143859863 grad: 1.4490501520053913\n",
      "epoch: 66 loss: 2.3024868965148926 grad: 1.455376992964866\n",
      "epoch: 67 loss: 2.302377223968506 grad: 1.4622963883411435\n",
      "epoch: 68 loss: 2.3023977279663086 grad: 1.4529471815608086\n",
      "epoch: 69 loss: 2.3029935359954834 grad: 1.4441671406439993\n",
      "epoch: 70 loss: 2.302483081817627 grad: 1.4550575559112495\n",
      "epoch: 71 loss: 2.3025994300842285 grad: 1.4587566733992259\n",
      "epoch: 72 loss: 2.30285906791687 grad: 1.4540905513124363\n",
      "epoch: 73 loss: 2.3029236793518066 grad: 1.4426932104767138\n",
      "epoch: 74 loss: 2.3026769161224365 grad: 1.4532940798357779\n",
      "epoch: 75 loss: 2.3021199703216553 grad: 1.47045659743959\n",
      "epoch: 76 loss: 2.302598714828491 grad: 1.4524358063381875\n",
      "epoch: 77 loss: 2.3020572662353516 grad: 1.4583407342212187\n",
      "epoch: 78 loss: 2.3029074668884277 grad: 1.455077663546295\n",
      "epoch: 79 loss: 2.302103042602539 grad: 1.4609627801082319\n",
      "epoch: 80 loss: 2.3027219772338867 grad: 1.459897401944054\n",
      "epoch: 81 loss: 2.3019278049468994 grad: 1.4720124386007054\n",
      "epoch: 82 loss: 2.3030190467834473 grad: 1.4592673032293244\n",
      "epoch: 83 loss: 2.3025271892547607 grad: 1.4546708472568306\n",
      "epoch: 84 loss: 2.302093029022217 grad: 1.4712932158911984\n",
      "epoch: 85 loss: 2.3025169372558594 grad: 1.4439266452155564\n",
      "epoch: 86 loss: 2.3023431301116943 grad: 1.4584675932595033\n",
      "epoch: 87 loss: 2.302241325378418 grad: 1.4656148394994764\n",
      "epoch: 88 loss: 2.301931858062744 grad: 1.4547453178517846\n",
      "epoch: 89 loss: 2.3022708892822266 grad: 1.4630244956148553\n",
      "epoch: 90 loss: 2.301910400390625 grad: 1.4665027062024272\n",
      "epoch: 91 loss: 2.3022964000701904 grad: 1.4653618706645266\n",
      "epoch: 92 loss: 2.3020918369293213 grad: 1.4739696773449107\n",
      "epoch: 93 loss: 2.302973508834839 grad: 1.4534298087200446\n",
      "epoch: 94 loss: 2.3023183345794678 grad: 1.4601872015988366\n",
      "epoch: 95 loss: 2.302647113800049 grad: 1.452327744817243\n",
      "epoch: 96 loss: 2.302259922027588 grad: 1.454601829501963\n",
      "epoch: 97 loss: 2.3017361164093018 grad: 1.4728719265743468\n",
      "epoch: 98 loss: 2.3019940853118896 grad: 1.4704428191503718\n",
      "epoch: 99 loss: 2.3016936779022217 grad: 1.466875073760526\n",
      "epoch: 100 loss: 2.3026020526885986 grad: 1.4588175604899696\n",
      "epoch: 101 loss: 2.3027095794677734 grad: 1.4569994431499036\n",
      "epoch: 102 loss: 2.3021926879882812 grad: 1.4675233136448596\n",
      "epoch: 103 loss: 2.3028626441955566 grad: 1.4499704232919843\n",
      "epoch: 104 loss: 2.3021388053894043 grad: 1.4634892951959508\n",
      "epoch: 105 loss: 2.302569627761841 grad: 1.457878445206757\n",
      "epoch: 106 loss: 2.301884412765503 grad: 1.467900169093073\n",
      "epoch: 107 loss: 2.3023879528045654 grad: 1.4608527256419794\n",
      "epoch: 108 loss: 2.303032875061035 grad: 1.4480642794893819\n",
      "epoch: 109 loss: 2.303079605102539 grad: 1.4471435477155157\n",
      "epoch: 110 loss: 2.302415609359741 grad: 1.4567260701978018\n",
      "epoch: 111 loss: 2.302384376525879 grad: 1.4488900779960825\n",
      "epoch: 112 loss: 2.302022695541382 grad: 1.4583108816702393\n",
      "epoch: 113 loss: 2.3022685050964355 grad: 1.4527080836927606\n",
      "epoch: 114 loss: 2.301839828491211 grad: 1.4593115332480964\n",
      "epoch: 115 loss: 2.301964282989502 grad: 1.4666390966084446\n",
      "epoch: 116 loss: 2.3022053241729736 grad: 1.4678232759451642\n",
      "epoch: 117 loss: 2.3024556636810303 grad: 1.465717609661321\n",
      "epoch: 118 loss: 2.3019556999206543 grad: 1.460187198546168\n",
      "epoch: 119 loss: 2.3029754161834717 grad: 1.4574131119648912\n",
      "epoch: 120 loss: 2.3020896911621094 grad: 1.4701068191086903\n",
      "epoch: 121 loss: 2.301929235458374 grad: 1.4707820325616807\n",
      "epoch: 122 loss: 2.302380323410034 grad: 1.4649475485082746\n",
      "epoch: 123 loss: 2.3017866611480713 grad: 1.476561226473663\n",
      "epoch: 124 loss: 2.3019356727600098 grad: 1.4679254798296217\n",
      "epoch: 125 loss: 2.3028903007507324 grad: 1.4520756496940666\n",
      "epoch: 126 loss: 2.302442789077759 grad: 1.4637957962640074\n",
      "epoch: 127 loss: 2.301837921142578 grad: 1.4623326851712866\n",
      "epoch: 128 loss: 2.30220365524292 grad: 1.4770835317589992\n",
      "epoch: 129 loss: 2.3023576736450195 grad: 1.451952536996927\n",
      "epoch: 130 loss: 2.3024919033050537 grad: 1.4685254652563127\n",
      "epoch: 131 loss: 2.302417516708374 grad: 1.4669351728895443\n",
      "epoch: 132 loss: 2.302513599395752 grad: 1.4654641025274666\n",
      "epoch: 133 loss: 2.3019559383392334 grad: 1.472637512377419\n",
      "epoch: 134 loss: 2.302556276321411 grad: 1.45360813332012\n",
      "epoch: 135 loss: 2.3023338317871094 grad: 1.472085128732336\n",
      "epoch: 136 loss: 2.3020169734954834 grad: 1.4742277443227876\n",
      "epoch: 137 loss: 2.302218198776245 grad: 1.4612379063471472\n",
      "epoch: 138 loss: 2.302091121673584 grad: 1.4657234984490695\n",
      "epoch: 139 loss: 2.3025245666503906 grad: 1.4664001298665499\n",
      "epoch: 140 loss: 2.302008867263794 grad: 1.4707454710030958\n",
      "epoch: 141 loss: 2.3025500774383545 grad: 1.451716367162705\n",
      "epoch: 142 loss: 2.3024423122406006 grad: 1.472689305993891\n",
      "epoch: 143 loss: 2.3021059036254883 grad: 1.4666577623048354\n",
      "epoch: 144 loss: 2.302544593811035 grad: 1.4450502047640463\n",
      "epoch: 145 loss: 2.301677942276001 grad: 1.4769401232165003\n",
      "epoch: 146 loss: 2.3024203777313232 grad: 1.4719900613103711\n",
      "epoch: 147 loss: 2.302035093307495 grad: 1.470693811947953\n",
      "epoch: 148 loss: 2.3022780418395996 grad: 1.4640536335599978\n",
      "epoch: 149 loss: 2.301669120788574 grad: 1.4658945312368727\n",
      "epoch: 150 loss: 2.301638603210449 grad: 1.4746905556041008\n",
      "epoch: 151 loss: 2.3027119636535645 grad: 1.447492958164759\n",
      "epoch: 152 loss: 2.3015692234039307 grad: 1.4852377437129025\n",
      "epoch: 153 loss: 2.3020994663238525 grad: 1.4839298796196956\n",
      "epoch: 154 loss: 2.3019275665283203 grad: 1.4657471895657688\n",
      "epoch: 155 loss: 2.3020176887512207 grad: 1.4704364425750331\n",
      "epoch: 156 loss: 2.3024849891662598 grad: 1.463873345262578\n",
      "epoch: 157 loss: 2.3025104999542236 grad: 1.4625384675076467\n",
      "epoch: 158 loss: 2.3022260665893555 grad: 1.4708402283186655\n",
      "epoch: 159 loss: 2.3017208576202393 grad: 1.487992806487628\n",
      "epoch: 160 loss: 2.3022079467773438 grad: 1.47157487695268\n",
      "epoch: 161 loss: 2.302168369293213 grad: 1.4802757799218866\n",
      "epoch: 162 loss: 2.3024301528930664 grad: 1.4654094409788885\n",
      "epoch: 163 loss: 2.302194356918335 grad: 1.4610447278006062\n",
      "epoch: 164 loss: 2.3022232055664062 grad: 1.4728924280775355\n",
      "epoch: 165 loss: 2.301910877227783 grad: 1.4751471552705866\n",
      "epoch: 166 loss: 2.3020455837249756 grad: 1.4745157798234787\n",
      "epoch: 167 loss: 2.302367925643921 grad: 1.4728014983924194\n",
      "epoch: 168 loss: 2.301954507827759 grad: 1.474096315875945\n",
      "epoch: 169 loss: 2.301819086074829 grad: 1.468837522241908\n",
      "epoch: 170 loss: 2.302123546600342 grad: 1.4705007827881398\n",
      "epoch: 171 loss: 2.3029119968414307 grad: 1.4708928343145147\n",
      "epoch: 172 loss: 2.301668405532837 grad: 1.469961569842232\n",
      "epoch: 173 loss: 2.302100658416748 grad: 1.4747787710974023\n",
      "epoch: 174 loss: 2.3023147583007812 grad: 1.4786422855335302\n",
      "epoch: 175 loss: 2.3023922443389893 grad: 1.4846423901414263\n",
      "epoch: 176 loss: 2.3020405769348145 grad: 1.4871136595398957\n",
      "epoch: 177 loss: 2.3029088973999023 grad: 1.4807447847126731\n",
      "epoch: 178 loss: 2.302248954772949 grad: 1.4697489991658441\n",
      "epoch: 179 loss: 2.3024094104766846 grad: 1.4620749815866085\n",
      "epoch: 180 loss: 2.3020107746124268 grad: 1.4781250561761212\n",
      "epoch: 181 loss: 2.302016258239746 grad: 1.4775860079837637\n",
      "epoch: 182 loss: 2.301750659942627 grad: 1.4794047086551372\n",
      "epoch: 183 loss: 2.3021984100341797 grad: 1.486243484593514\n",
      "epoch: 184 loss: 2.302277088165283 grad: 1.4814128623462268\n",
      "epoch: 185 loss: 2.302203416824341 grad: 1.4827433700898722\n",
      "epoch: 186 loss: 2.30206561088562 grad: 1.4786303843489834\n",
      "epoch: 187 loss: 2.301919460296631 grad: 1.4737736266900947\n",
      "epoch: 188 loss: 2.3018743991851807 grad: 1.4939110388217995\n",
      "epoch: 189 loss: 2.3021671772003174 grad: 1.4765145245011866\n",
      "epoch: 190 loss: 2.3017239570617676 grad: 1.488264665024222\n",
      "epoch: 191 loss: 2.301987409591675 grad: 1.4845214768179826\n",
      "epoch: 192 loss: 2.301600694656372 grad: 1.491475807098184\n",
      "epoch: 193 loss: 2.3024542331695557 grad: 1.4790185620150869\n",
      "epoch: 194 loss: 2.301900625228882 grad: 1.4819461507870564\n",
      "epoch: 195 loss: 2.3016765117645264 grad: 1.4912582766855993\n",
      "epoch: 196 loss: 2.302454710006714 grad: 1.4789571379466604\n",
      "epoch: 197 loss: 2.301680564880371 grad: 1.4949334940137637\n",
      "epoch: 198 loss: 2.3015642166137695 grad: 1.4910215419524955\n",
      "epoch: 199 loss: 2.3020503520965576 grad: 1.4864192869540096\n",
      "epoch: 200 loss: 2.3012607097625732 grad: 1.4980722718764954\n",
      "epoch: 201 loss: 2.301565170288086 grad: 1.4946350594224882\n",
      "epoch: 202 loss: 2.3017868995666504 grad: 1.4905281595937494\n",
      "epoch: 203 loss: 2.3017725944519043 grad: 1.477355101735272\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 204 loss: 2.301720380783081 grad: 1.4969301640817394\n",
      "epoch: 205 loss: 2.301731586456299 grad: 1.4905655337423678\n",
      "epoch: 206 loss: 2.302086353302002 grad: 1.4886933708127352\n",
      "epoch: 207 loss: 2.3018975257873535 grad: 1.4903093377656733\n",
      "epoch: 208 loss: 2.302013397216797 grad: 1.4947474899180677\n",
      "epoch: 209 loss: 2.3015215396881104 grad: 1.5005402978369227\n",
      "epoch: 210 loss: 2.30210018157959 grad: 1.4745256782967657\n",
      "epoch: 211 loss: 2.302096128463745 grad: 1.4897013300519792\n",
      "epoch: 212 loss: 2.301543951034546 grad: 1.5045523927602473\n",
      "epoch: 213 loss: 2.3014638423919678 grad: 1.503377067998776\n",
      "epoch: 214 loss: 2.3006646633148193 grad: 1.5125252903671935\n",
      "epoch: 215 loss: 2.3018312454223633 grad: 1.5034690198566143\n",
      "epoch: 216 loss: 2.302318811416626 grad: 1.494877963681661\n",
      "epoch: 217 loss: 2.301217794418335 grad: 1.4987039518513021\n",
      "epoch: 218 loss: 2.301793336868286 grad: 1.5025501715329785\n",
      "epoch: 219 loss: 2.3013548851013184 grad: 1.5035009628553535\n",
      "epoch: 220 loss: 2.3019988536834717 grad: 1.4802282435656895\n",
      "epoch: 221 loss: 2.3015642166137695 grad: 1.5013908249370398\n",
      "epoch: 222 loss: 2.3016200065612793 grad: 1.4987094098229021\n",
      "epoch: 223 loss: 2.302133321762085 grad: 1.4856683617524271\n",
      "epoch: 224 loss: 2.3014869689941406 grad: 1.5046089621027932\n",
      "epoch: 225 loss: 2.301891565322876 grad: 1.4998008633246793\n",
      "epoch: 226 loss: 2.301680088043213 grad: 1.4925266288161751\n",
      "epoch: 227 loss: 2.301870107650757 grad: 1.4968656018276565\n",
      "epoch: 228 loss: 2.3014321327209473 grad: 1.5007072572729416\n",
      "epoch: 229 loss: 2.30191969871521 grad: 1.4854729397791542\n",
      "epoch: 230 loss: 2.301854133605957 grad: 1.497432048378941\n",
      "epoch: 231 loss: 2.301337718963623 grad: 1.509279774980516\n",
      "epoch: 232 loss: 2.302044630050659 grad: 1.5004680065201625\n",
      "epoch: 233 loss: 2.3017683029174805 grad: 1.5075652024021284\n",
      "epoch: 234 loss: 2.301546812057495 grad: 1.521651493723593\n",
      "epoch: 235 loss: 2.301452159881592 grad: 1.5177707283587625\n",
      "epoch: 236 loss: 2.3009870052337646 grad: 1.5193863331935265\n",
      "epoch: 237 loss: 2.3017420768737793 grad: 1.5090558764576498\n",
      "epoch: 238 loss: 2.301837921142578 grad: 1.499754065049014\n",
      "epoch: 239 loss: 2.301997423171997 grad: 1.5032615943937488\n",
      "epoch: 240 loss: 2.301581859588623 grad: 1.5140632119044544\n",
      "epoch: 241 loss: 2.301893711090088 grad: 1.5118978270828458\n",
      "epoch: 242 loss: 2.3019182682037354 grad: 1.494212491703885\n",
      "epoch: 243 loss: 2.3014254570007324 grad: 1.5151859730637323\n",
      "epoch: 244 loss: 2.301647424697876 grad: 1.5204441782090783\n",
      "epoch: 245 loss: 2.301581859588623 grad: 1.5108563560245942\n",
      "epoch: 246 loss: 2.3015809059143066 grad: 1.5141939781199667\n",
      "epoch: 247 loss: 2.3016602993011475 grad: 1.5091827705295549\n",
      "epoch: 248 loss: 2.301499605178833 grad: 1.5100261317861696\n",
      "epoch: 249 loss: 2.3012523651123047 grad: 1.5240708294579581\n",
      "epoch: 250 loss: 2.301715135574341 grad: 1.5110201808302441\n",
      "epoch: 251 loss: 2.3012521266937256 grad: 1.521688269362563\n",
      "epoch: 252 loss: 2.3010826110839844 grad: 1.5221256772296443\n",
      "epoch: 253 loss: 2.3018202781677246 grad: 1.5061189083323356\n",
      "epoch: 254 loss: 2.3011817932128906 grad: 1.529980200852844\n",
      "epoch: 255 loss: 2.3009095191955566 grad: 1.5217168997614718\n",
      "epoch: 256 loss: 2.301370859146118 grad: 1.5369147254922797\n",
      "epoch: 257 loss: 2.300602436065674 grad: 1.5466371050514724\n",
      "epoch: 258 loss: 2.3013856410980225 grad: 1.5311537153486694\n",
      "epoch: 259 loss: 2.3013322353363037 grad: 1.5186784826995183\n",
      "epoch: 260 loss: 2.3010504245758057 grad: 1.5236295470764625\n",
      "epoch: 261 loss: 2.301063299179077 grad: 1.5303258089540852\n",
      "epoch: 262 loss: 2.301098346710205 grad: 1.5247146936894824\n",
      "epoch: 263 loss: 2.300673246383667 grad: 1.5352178716289235\n",
      "epoch: 264 loss: 2.300671339035034 grad: 1.5357169229130718\n",
      "epoch: 265 loss: 2.3017420768737793 grad: 1.5313181487680783\n",
      "epoch: 266 loss: 2.3007819652557373 grad: 1.54696833062917\n",
      "epoch: 267 loss: 2.300650119781494 grad: 1.5382883821425604\n",
      "epoch: 268 loss: 2.301255702972412 grad: 1.5283247526746155\n",
      "epoch: 269 loss: 2.300567150115967 grad: 1.5530453024188144\n",
      "epoch: 270 loss: 2.3012380599975586 grad: 1.5355507779057094\n",
      "epoch: 271 loss: 2.3007335662841797 grad: 1.5451351394340958\n",
      "epoch: 272 loss: 2.3009095191955566 grad: 1.5570323988887673\n",
      "epoch: 273 loss: 2.3010780811309814 grad: 1.551816220099609\n",
      "epoch: 274 loss: 2.300999879837036 grad: 1.5427159350439315\n",
      "epoch: 275 loss: 2.3012166023254395 grad: 1.5493925022966568\n",
      "epoch: 276 loss: 2.301039457321167 grad: 1.540949765960538\n",
      "epoch: 277 loss: 2.3002846240997314 grad: 1.5669288697933395\n",
      "epoch: 278 loss: 2.300828695297241 grad: 1.5426058849534168\n",
      "epoch: 279 loss: 2.300252914428711 grad: 1.5701054861096457\n",
      "epoch: 280 loss: 2.300701141357422 grad: 1.5583262884664157\n",
      "epoch: 281 loss: 2.2997677326202393 grad: 1.582510312154357\n",
      "epoch: 282 loss: 2.3002231121063232 grad: 1.562003309553903\n",
      "epoch: 283 loss: 2.301068067550659 grad: 1.5580186511644916\n",
      "epoch: 284 loss: 2.3005480766296387 grad: 1.5759445208860265\n",
      "epoch: 285 loss: 2.3000245094299316 grad: 1.5792814908042876\n",
      "epoch: 286 loss: 2.301011800765991 grad: 1.5560455056228897\n",
      "epoch: 287 loss: 2.3004541397094727 grad: 1.5799792876858856\n",
      "epoch: 288 loss: 2.3005874156951904 grad: 1.5724242981486318\n",
      "epoch: 289 loss: 2.301470994949341 grad: 1.54073159431573\n",
      "epoch: 290 loss: 2.300642967224121 grad: 1.5794826176143177\n",
      "epoch: 291 loss: 2.300215005874634 grad: 1.5742704983253681\n",
      "epoch: 292 loss: 2.3010964393615723 grad: 1.5748952241533154\n",
      "epoch: 293 loss: 2.2993955612182617 grad: 1.5863382023507877\n",
      "epoch: 294 loss: 2.300318479537964 grad: 1.582435954589441\n",
      "epoch: 295 loss: 2.299874782562256 grad: 1.59063863666499\n",
      "epoch: 296 loss: 2.300006866455078 grad: 1.6018290313917936\n",
      "epoch: 297 loss: 2.299669027328491 grad: 1.6026511391447413\n",
      "epoch: 298 loss: 2.2997140884399414 grad: 1.5990974224165142\n",
      "epoch: 299 loss: 2.3002328872680664 grad: 1.595030882072428\n",
      "epoch: 300 loss: 2.300352096557617 grad: 1.5851470019283986\n",
      "epoch: 301 loss: 2.2997641563415527 grad: 1.6003758610884053\n",
      "epoch: 302 loss: 2.3005709648132324 grad: 1.6005633412804898\n",
      "epoch: 303 loss: 2.2997779846191406 grad: 1.6001015573939574\n",
      "epoch: 304 loss: 2.299708366394043 grad: 1.614091234525577\n",
      "epoch: 305 loss: 2.299553632736206 grad: 1.626173465553346\n",
      "epoch: 306 loss: 2.2993197441101074 grad: 1.6309263926786592\n",
      "epoch: 307 loss: 2.29976487159729 grad: 1.6272598975005426\n",
      "epoch: 308 loss: 2.299546957015991 grad: 1.6358114501058554\n",
      "epoch: 309 loss: 2.2995288372039795 grad: 1.6520720878708368\n",
      "epoch: 310 loss: 2.299744129180908 grad: 1.6220724665678092\n",
      "epoch: 311 loss: 2.2991585731506348 grad: 1.6379160379569622\n",
      "epoch: 312 loss: 2.2991013526916504 grad: 1.6307407815086965\n",
      "epoch: 313 loss: 2.299067497253418 grad: 1.63979990116971\n",
      "epoch: 314 loss: 2.2992279529571533 grad: 1.641360506093839\n",
      "epoch: 315 loss: 2.2989869117736816 grad: 1.6545309057045314\n",
      "epoch: 316 loss: 2.2980828285217285 grad: 1.6764131997238905\n",
      "epoch: 317 loss: 2.2997336387634277 grad: 1.625991693021552\n",
      "epoch: 318 loss: 2.2991487979888916 grad: 1.6596563662206458\n",
      "epoch: 319 loss: 2.299196243286133 grad: 1.6590446023684409\n",
      "epoch: 320 loss: 2.298830032348633 grad: 1.6685500409757157\n",
      "epoch: 321 loss: 2.2984070777893066 grad: 1.6789656607415675\n",
      "epoch: 322 loss: 2.299288034439087 grad: 1.6729296703845085\n",
      "epoch: 323 loss: 2.298532485961914 grad: 1.6772417711419245\n",
      "epoch: 324 loss: 2.298642873764038 grad: 1.6876783634772494\n",
      "epoch: 325 loss: 2.298393964767456 grad: 1.7085258955475948\n",
      "epoch: 326 loss: 2.299330234527588 grad: 1.6855521179894577\n",
      "epoch: 327 loss: 2.298288583755493 grad: 1.7195251119056982\n",
      "epoch: 328 loss: 2.298243761062622 grad: 1.724394359490982\n",
      "epoch: 329 loss: 2.29795503616333 grad: 1.739848182610576\n",
      "epoch: 330 loss: 2.297567844390869 grad: 1.7619952518670332\n",
      "epoch: 331 loss: 2.297443389892578 grad: 1.7469918940600657\n",
      "epoch: 332 loss: 2.296499252319336 grad: 1.7868289065931642\n",
      "epoch: 333 loss: 2.2976303100585938 grad: 1.760602798102246\n",
      "epoch: 334 loss: 2.2972910404205322 grad: 1.7932715672326998\n",
      "epoch: 335 loss: 2.2964375019073486 grad: 1.8103851964660285\n",
      "epoch: 336 loss: 2.296858310699463 grad: 1.799500129292793\n",
      "epoch: 337 loss: 2.295588254928589 grad: 1.8520676508205869\n",
      "epoch: 338 loss: 2.296189546585083 grad: 1.8459513923190238\n",
      "epoch: 339 loss: 2.297182321548462 grad: 1.8308507848072737\n",
      "epoch: 340 loss: 2.2956578731536865 grad: 1.874080152790402\n",
      "epoch: 341 loss: 2.2961692810058594 grad: 1.8638664499878705\n",
      "epoch: 342 loss: 2.2957189083099365 grad: 1.8791806851624555\n",
      "epoch: 343 loss: 2.2962379455566406 grad: 1.871930583346901\n",
      "epoch: 344 loss: 2.2949233055114746 grad: 1.9088688955128577\n",
      "epoch: 345 loss: 2.294677257537842 grad: 1.9208941072159047\n",
      "epoch: 346 loss: 2.294667959213257 grad: 1.936150059181576\n",
      "epoch: 347 loss: 2.2940568923950195 grad: 1.970814343133483\n",
      "epoch: 348 loss: 2.292555570602417 grad: 2.0422918395405367\n",
      "epoch: 349 loss: 2.293478012084961 grad: 2.0338009210924306\n",
      "epoch: 350 loss: 2.2928621768951416 grad: 2.0443940543983548\n",
      "epoch: 351 loss: 2.293332576751709 grad: 2.029589683782043\n",
      "epoch: 352 loss: 2.291017770767212 grad: 2.0945429913219185\n",
      "epoch: 353 loss: 2.289616346359253 grad: 2.1547456011471766\n",
      "epoch: 354 loss: 2.29083514213562 grad: 2.1491167937656717\n",
      "epoch: 355 loss: 2.2905819416046143 grad: 2.1523338909416148\n",
      "epoch: 356 loss: 2.2871193885803223 grad: 2.228514016480259\n",
      "epoch: 357 loss: 2.286616563796997 grad: 2.295669989612338\n",
      "epoch: 358 loss: 2.2869679927825928 grad: 2.2565046788178504\n",
      "epoch: 359 loss: 2.285975933074951 grad: 2.2938701263000625\n",
      "epoch: 360 loss: 2.2845427989959717 grad: 2.3030858208233167\n",
      "epoch: 361 loss: 2.2846639156341553 grad: 2.336876030819165\n",
      "epoch: 362 loss: 2.282560348510742 grad: 2.3449169378432018\n",
      "epoch: 363 loss: 2.282299757003784 grad: 2.372437146969051\n",
      "epoch: 364 loss: 2.2814366817474365 grad: 2.314132966807053\n",
      "epoch: 365 loss: 2.2799460887908936 grad: 2.3695287305736055\n",
      "epoch: 366 loss: 2.2780799865722656 grad: 2.3937517715625405\n",
      "epoch: 367 loss: 2.279719591140747 grad: 2.3985653069602058\n",
      "epoch: 368 loss: 2.2755634784698486 grad: 2.311953372551158\n",
      "epoch: 369 loss: 2.273172616958618 grad: 2.3253450206820925\n",
      "epoch: 370 loss: 2.2727580070495605 grad: 2.296295018556217\n",
      "epoch: 371 loss: 2.2739410400390625 grad: 2.3338982540677997\n",
      "epoch: 372 loss: 2.270282745361328 grad: 2.302103647204589\n",
      "epoch: 373 loss: 2.2680535316467285 grad: 2.282110511389975\n",
      "epoch: 374 loss: 2.2691454887390137 grad: 2.2980208537607854\n",
      "epoch: 375 loss: 2.2653849124908447 grad: 2.1666091229666824\n",
      "epoch: 376 loss: 2.26454496383667 grad: 2.1572275759655954\n",
      "epoch: 377 loss: 2.2650811672210693 grad: 2.074341350183305\n",
      "epoch: 378 loss: 2.2620503902435303 grad: 2.1129722868439758\n",
      "epoch: 379 loss: 2.261763572692871 grad: 2.042348473634024\n",
      "epoch: 380 loss: 2.2610275745391846 grad: 2.0454422983023086\n",
      "epoch: 381 loss: 2.2582225799560547 grad: 1.9396101696535\n",
      "epoch: 382 loss: 2.2587432861328125 grad: 1.9660108090481825\n",
      "epoch: 383 loss: 2.2575643062591553 grad: 1.9242271161120799\n",
      "epoch: 384 loss: 2.2578213214874268 grad: 1.9331766248603042\n",
      "epoch: 385 loss: 2.257253885269165 grad: 1.8821357814317925\n",
      "epoch: 386 loss: 2.2571301460266113 grad: 1.8427681994055294\n",
      "epoch: 387 loss: 2.255063533782959 grad: 1.8140682955124667\n",
      "epoch: 388 loss: 2.2540597915649414 grad: 1.787831122240436\n",
      "epoch: 389 loss: 2.2562856674194336 grad: 1.8184434999102017\n",
      "epoch: 390 loss: 2.2537124156951904 grad: 1.7978713190800228\n",
      "epoch: 391 loss: 2.252415895462036 grad: 1.6934205654561372\n",
      "epoch: 392 loss: 2.2520480155944824 grad: 1.6734314978839682\n",
      "epoch: 393 loss: 2.2533318996429443 grad: 1.776059020436295\n",
      "epoch: 394 loss: 2.251913547515869 grad: 1.7243310017160154\n",
      "epoch: 395 loss: 2.251591682434082 grad: 1.6455116915638515\n",
      "epoch: 396 loss: 2.25015926361084 grad: 1.677327181092493\n",
      "epoch: 397 loss: 2.2501296997070312 grad: 1.629062983122403\n",
      "epoch: 398 loss: 2.251758337020874 grad: 1.657405971030202\n",
      "epoch: 399 loss: 2.250519037246704 grad: 1.5944156272296188\n",
      "epoch: 400 loss: 2.249943971633911 grad: 1.604436909220004\n",
      "epoch: 401 loss: 2.248563289642334 grad: 1.5250417514803953\n",
      "epoch: 402 loss: 2.2495546340942383 grad: 1.5989197490308138\n",
      "epoch: 403 loss: 2.2488725185394287 grad: 1.6189956808248387\n",
      "epoch: 404 loss: 2.24674916267395 grad: 1.5323788836979055\n",
      "epoch: 405 loss: 2.2480037212371826 grad: 1.5303277266877038\n",
      "epoch: 406 loss: 2.2470295429229736 grad: 1.4900808056395145\n",
      "epoch: 407 loss: 2.247974157333374 grad: 1.5023648540733294\n",
      "epoch: 408 loss: 2.2468419075012207 grad: 1.49765301011281\n",
      "epoch: 409 loss: 2.2463390827178955 grad: 1.4774142949609086\n",
      "epoch: 410 loss: 2.246837854385376 grad: 1.4788078812952523\n",
      "epoch: 411 loss: 2.2454426288604736 grad: 1.4610021610980823\n",
      "epoch: 412 loss: 2.2468581199645996 grad: 1.5339848957844966\n",
      "epoch: 413 loss: 2.245816230773926 grad: 1.4462684799920738\n",
      "epoch: 414 loss: 2.246249198913574 grad: 1.4624914358894798\n",
      "epoch: 415 loss: 2.2439143657684326 grad: 1.425808362210066\n",
      "epoch: 416 loss: 2.243175745010376 grad: 1.39100363128449\n",
      "epoch: 417 loss: 2.24495267868042 grad: 1.4093274676817513\n",
      "epoch: 418 loss: 2.243551254272461 grad: 1.4096901536298294\n",
      "epoch: 419 loss: 2.244795083999634 grad: 1.4246498992082677\n",
      "epoch: 420 loss: 2.243304491043091 grad: 1.3846590058667407\n",
      "epoch: 421 loss: 2.2419686317443848 grad: 1.3285320867832366\n",
      "epoch: 422 loss: 2.2436952590942383 grad: 1.3548919232654577\n",
      "epoch: 423 loss: 2.2433254718780518 grad: 1.394907637887324\n",
      "epoch: 424 loss: 2.2437052726745605 grad: 1.3930207636976053\n",
      "epoch: 425 loss: 2.241894006729126 grad: 1.322451585299513\n",
      "epoch: 426 loss: 2.242051839828491 grad: 1.3351349071174534\n",
      "epoch: 427 loss: 2.242033004760742 grad: 1.3382693128863585\n",
      "epoch: 428 loss: 2.2423768043518066 grad: 1.2860888688000924\n",
      "epoch: 429 loss: 2.242426872253418 grad: 1.3711948975872632\n",
      "epoch: 430 loss: 2.241102695465088 grad: 1.3142379015676737\n",
      "epoch: 431 loss: 2.2405617237091064 grad: 1.2738728521240226\n",
      "epoch: 432 loss: 2.2409019470214844 grad: 1.2670109510931762\n",
      "epoch: 433 loss: 2.2414798736572266 grad: 1.3234764080132462\n",
      "epoch: 434 loss: 2.241861343383789 grad: 1.3151721454609835\n",
      "epoch: 435 loss: 2.2399284839630127 grad: 1.3130086046506813\n",
      "epoch: 436 loss: 2.2412784099578857 grad: 1.3538156903685175\n",
      "epoch: 437 loss: 2.240011692047119 grad: 1.2844262338069725\n",
      "epoch: 438 loss: 2.2423973083496094 grad: 1.3624255228732225\n",
      "epoch: 439 loss: 2.240997791290283 grad: 1.3308802143696488\n",
      "epoch: 440 loss: 2.2388601303100586 grad: 1.219724250876064\n",
      "epoch: 441 loss: 2.2402520179748535 grad: 1.2742745543770966\n",
      "epoch: 442 loss: 2.2392404079437256 grad: 1.2109323523177336\n",
      "epoch: 443 loss: 2.239940881729126 grad: 1.2795464577345503\n",
      "epoch: 444 loss: 2.2386131286621094 grad: 1.2336673259731412\n",
      "epoch: 445 loss: 2.240154504776001 grad: 1.2969523523121127\n",
      "epoch: 446 loss: 2.239661693572998 grad: 1.3037101859060516\n",
      "epoch: 447 loss: 2.238973617553711 grad: 1.2079253345820313\n",
      "epoch: 448 loss: 2.2388057708740234 grad: 1.2423059615650258\n",
      "epoch: 449 loss: 2.237849712371826 grad: 1.2105232767819885\n",
      "epoch: 450 loss: 2.2386443614959717 grad: 1.2666423794414317\n",
      "epoch: 451 loss: 2.2393555641174316 grad: 1.253099184786339\n",
      "epoch: 452 loss: 2.2395334243774414 grad: 1.2618947628153754\n",
      "epoch: 453 loss: 2.2385151386260986 grad: 1.2459434717043585\n",
      "epoch: 454 loss: 2.238765239715576 grad: 1.2237081587876355\n",
      "epoch: 455 loss: 2.2392163276672363 grad: 1.3146589111928488\n",
      "epoch: 456 loss: 2.2390296459198 grad: 1.2818348328250326\n",
      "epoch: 457 loss: 2.2385146617889404 grad: 1.2150215910403945\n",
      "epoch: 458 loss: 2.237056255340576 grad: 1.2023638632806344\n",
      "epoch: 459 loss: 2.2371768951416016 grad: 1.205000395110498\n",
      "epoch: 460 loss: 2.238880157470703 grad: 1.2385131133228748\n",
      "epoch: 461 loss: 2.237144708633423 grad: 1.1955539435905862\n",
      "epoch: 462 loss: 2.237995147705078 grad: 1.2326636322282463\n",
      "epoch: 463 loss: 2.2369067668914795 grad: 1.1762202020276278\n",
      "epoch: 464 loss: 2.235727548599243 grad: 1.1426406848421764\n",
      "epoch: 465 loss: 2.2377896308898926 grad: 1.1908095144345203\n",
      "epoch: 466 loss: 2.237093448638916 grad: 1.2084505233935834\n",
      "epoch: 467 loss: 2.23728084564209 grad: 1.188878874991104\n",
      "epoch: 468 loss: 2.2359161376953125 grad: 1.1659991324690746\n",
      "epoch: 469 loss: 2.2371649742126465 grad: 1.2124817685283247\n",
      "epoch: 470 loss: 2.2365310192108154 grad: 1.189993594366584\n",
      "epoch: 471 loss: 2.237504482269287 grad: 1.1686926337683365\n",
      "epoch: 472 loss: 2.2368557453155518 grad: 1.193359737598618\n",
      "epoch: 473 loss: 2.2356784343719482 grad: 1.1722972755142975\n",
      "epoch: 474 loss: 2.2356317043304443 grad: 1.1356176208623403\n",
      "epoch: 475 loss: 2.2353343963623047 grad: 1.1344017812461105\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 476 loss: 2.235508441925049 grad: 1.1388230398796233\n",
      "epoch: 477 loss: 2.2353110313415527 grad: 1.1287117682208883\n",
      "epoch: 478 loss: 2.2355988025665283 grad: 1.185439281350386\n",
      "epoch: 479 loss: 2.23494291305542 grad: 1.1205399429041243\n",
      "epoch: 480 loss: 2.2348814010620117 grad: 1.1242058371223274\n",
      "epoch: 481 loss: 2.234867572784424 grad: 1.0812254684740707\n",
      "epoch: 482 loss: 2.235396385192871 grad: 1.1444578433782602\n",
      "epoch: 483 loss: 2.235619306564331 grad: 1.1907990946109215\n",
      "epoch: 484 loss: 2.2344725131988525 grad: 1.1143999472574613\n",
      "epoch: 485 loss: 2.235337257385254 grad: 1.1692975362936509\n",
      "epoch: 486 loss: 2.2338879108428955 grad: 1.1269702339445107\n",
      "epoch: 487 loss: 2.23468279838562 grad: 1.1490139062627263\n",
      "epoch: 488 loss: 2.2349650859832764 grad: 1.1873802305180727\n",
      "epoch: 489 loss: 2.2350714206695557 grad: 1.0945830939500223\n",
      "epoch: 490 loss: 2.234091281890869 grad: 1.1130836318110278\n",
      "epoch: 491 loss: 2.2365121841430664 grad: 1.220018909752576\n",
      "epoch: 492 loss: 2.234495162963867 grad: 1.116594646782023\n",
      "epoch: 493 loss: 2.2353804111480713 grad: 1.1072401852117821\n",
      "epoch: 494 loss: 2.2343859672546387 grad: 1.1505873700038396\n",
      "epoch: 495 loss: 2.2341701984405518 grad: 1.1300832461233117\n",
      "epoch: 496 loss: 2.2330148220062256 grad: 1.0875669567243358\n",
      "epoch: 497 loss: 2.233563184738159 grad: 1.0829507654518007\n",
      "epoch: 498 loss: 2.2336843013763428 grad: 1.1128309381671162\n",
      "epoch: 499 loss: 2.233814001083374 grad: 1.1134610642597729\n",
      "2.2579292953014374\n",
      "epoch: 0 loss: 2.3033370971679688 grad: 1.2885448459243876\n",
      "epoch: 1 loss: 2.3019931316375732 grad: 1.2663158518003508\n",
      "epoch: 2 loss: 2.301168203353882 grad: 1.2843240023080615\n",
      "epoch: 3 loss: 2.2991650104522705 grad: 1.331014542252801\n",
      "epoch: 4 loss: 2.295924425125122 grad: 1.366284796341677\n",
      "epoch: 5 loss: 2.2923622131347656 grad: 1.4159413046972265\n",
      "epoch: 6 loss: 2.2842814922332764 grad: 1.6806236087595896\n",
      "epoch: 7 loss: 2.2693262100219727 grad: 1.8375927711474813\n",
      "epoch: 8 loss: 2.245502233505249 grad: 1.6309877703066118\n",
      "epoch: 9 loss: 2.237851142883301 grad: 1.4180175424959984\n",
      "epoch: 10 loss: 2.2321836948394775 grad: 1.3651412853320677\n",
      "epoch: 11 loss: 2.2293217182159424 grad: 1.3494875907873927\n",
      "epoch: 12 loss: 2.2247915267944336 grad: 1.436701148317846\n",
      "epoch: 13 loss: 2.2212259769439697 grad: 1.6157877899314617\n",
      "epoch: 14 loss: 2.2173116207122803 grad: 1.672554979830729\n",
      "epoch: 15 loss: 2.214815139770508 grad: 1.8856601633560208\n",
      "epoch: 16 loss: 2.2077157497406006 grad: 2.044648961191775\n",
      "epoch: 17 loss: 2.2025887966156006 grad: 2.1895255124536415\n",
      "epoch: 18 loss: 2.1935184001922607 grad: 2.34439742362075\n",
      "epoch: 19 loss: 2.186230421066284 grad: 2.647258176477552\n",
      "epoch: 20 loss: 2.1835875511169434 grad: 2.8652690263162\n",
      "epoch: 21 loss: 2.177241325378418 grad: 3.189956889339974\n",
      "epoch: 22 loss: 2.1718735694885254 grad: 3.3441568582377856\n",
      "epoch: 23 loss: 2.166710376739502 grad: 3.5324226282167412\n",
      "epoch: 24 loss: 2.154567241668701 grad: 3.76904972960862\n",
      "epoch: 25 loss: 2.153829336166382 grad: 3.879886945901764\n",
      "epoch: 26 loss: 2.1466002464294434 grad: 4.271077196002894\n",
      "epoch: 27 loss: 2.1374380588531494 grad: 4.223063022792635\n",
      "epoch: 28 loss: 2.1344573497772217 grad: 4.091257971412103\n",
      "epoch: 29 loss: 2.1302480697631836 grad: 4.136691990674341\n",
      "epoch: 30 loss: 2.1246888637542725 grad: 4.230247696055957\n",
      "epoch: 31 loss: 2.1197872161865234 grad: 4.294066059007679\n",
      "epoch: 32 loss: 2.1183583736419678 grad: 4.305968847476863\n",
      "epoch: 33 loss: 2.1132164001464844 grad: 4.58714991365929\n",
      "epoch: 34 loss: 2.108381748199463 grad: 4.546440320155982\n",
      "epoch: 35 loss: 2.1055049896240234 grad: 4.449906605842804\n",
      "epoch: 36 loss: 2.1009562015533447 grad: 4.899781387927573\n",
      "epoch: 37 loss: 2.09688663482666 grad: 4.391299342743993\n",
      "epoch: 38 loss: 2.087700605392456 grad: 4.608860417453957\n",
      "epoch: 39 loss: 2.0953147411346436 grad: 4.806612024638092\n",
      "epoch: 40 loss: 2.0820975303649902 grad: 4.793150333805927\n",
      "epoch: 41 loss: 2.0795373916625977 grad: 4.783657864187031\n",
      "epoch: 42 loss: 2.081491708755493 grad: 5.056378769858312\n",
      "epoch: 43 loss: 2.0698227882385254 grad: 4.894071500947965\n",
      "epoch: 44 loss: 2.068800449371338 grad: 5.210330856025278\n",
      "epoch: 45 loss: 2.065936803817749 grad: 5.240450883439432\n",
      "epoch: 46 loss: 2.0588414669036865 grad: 4.996457592632237\n",
      "epoch: 47 loss: 2.055042028427124 grad: 5.04356059468987\n",
      "epoch: 48 loss: 2.0559463500976562 grad: 5.356410114922458\n",
      "epoch: 49 loss: 2.0526487827301025 grad: 5.379164211367006\n",
      "epoch: 50 loss: 2.053560256958008 grad: 5.049148045927434\n",
      "epoch: 51 loss: 2.047450542449951 grad: 5.596632075799067\n",
      "epoch: 52 loss: 2.043292284011841 grad: 5.473291982793146\n",
      "epoch: 53 loss: 2.0501952171325684 grad: 5.561540023283293\n",
      "epoch: 54 loss: 2.038119316101074 grad: 5.25624390565125\n",
      "epoch: 55 loss: 2.036477565765381 grad: 5.342800901400754\n",
      "epoch: 56 loss: 2.034587860107422 grad: 5.603045041044612\n",
      "epoch: 57 loss: 2.0323550701141357 grad: 5.322913124617781\n",
      "epoch: 58 loss: 2.0327413082122803 grad: 5.838178194017106\n",
      "epoch: 59 loss: 2.0322766304016113 grad: 5.822022180797325\n",
      "epoch: 60 loss: 2.026895761489868 grad: 5.123102930300529\n",
      "epoch: 61 loss: 2.0283262729644775 grad: 5.510590976288927\n",
      "epoch: 62 loss: 2.027625799179077 grad: 5.643446872376704\n",
      "epoch: 63 loss: 2.026116371154785 grad: 5.745863258831262\n",
      "epoch: 64 loss: 2.0192904472351074 grad: 5.573236906960133\n",
      "epoch: 65 loss: 2.0195703506469727 grad: 5.540558733674328\n",
      "epoch: 66 loss: 2.0176379680633545 grad: 5.75882898588177\n",
      "epoch: 67 loss: 2.013770341873169 grad: 5.687839202560662\n",
      "epoch: 68 loss: 2.0142788887023926 grad: 6.094355228083534\n",
      "epoch: 69 loss: 2.013249635696411 grad: 6.147063213400543\n",
      "epoch: 70 loss: 2.01358699798584 grad: 5.84855316039027\n",
      "epoch: 71 loss: 2.012742042541504 grad: 6.0280280347233495\n",
      "epoch: 72 loss: 2.0107879638671875 grad: 6.380489182577188\n",
      "epoch: 73 loss: 2.0105040073394775 grad: 6.125540231421057\n",
      "epoch: 74 loss: 2.0034499168395996 grad: 5.680606424172837\n",
      "epoch: 75 loss: 2.01009464263916 grad: 6.074257764314848\n",
      "epoch: 76 loss: 2.008622884750366 grad: 5.851865497447314\n",
      "epoch: 77 loss: 2.0075340270996094 grad: 6.333082583023324\n",
      "epoch: 78 loss: 2.0049526691436768 grad: 6.454743713983113\n",
      "epoch: 79 loss: 2.0010154247283936 grad: 6.549672642238586\n",
      "epoch: 80 loss: 2.000094413757324 grad: 6.350288523590222\n",
      "epoch: 81 loss: 1.9971681833267212 grad: 6.1299408836556335\n",
      "epoch: 82 loss: 1.9931994676589966 grad: 6.476800205629496\n",
      "epoch: 83 loss: 1.992978572845459 grad: 6.203277222693912\n",
      "epoch: 84 loss: 1.9945008754730225 grad: 6.447959846255207\n",
      "epoch: 85 loss: 1.9927775859832764 grad: 6.184415168387608\n",
      "epoch: 86 loss: 1.9897381067276 grad: 6.3433314026924705\n",
      "epoch: 87 loss: 1.9840813875198364 grad: 6.179139133335815\n",
      "epoch: 88 loss: 1.9903367757797241 grad: 6.499809735343748\n",
      "epoch: 89 loss: 1.990411639213562 grad: 6.797226628842985\n",
      "epoch: 90 loss: 1.9822258949279785 grad: 6.464951896448693\n",
      "epoch: 91 loss: 1.989622950553894 grad: 6.680611580625058\n",
      "epoch: 92 loss: 1.977493166923523 grad: 6.539112259493401\n",
      "epoch: 93 loss: 1.9818781614303589 grad: 7.416006864174196\n",
      "epoch: 94 loss: 1.9761193990707397 grad: 7.222358536832626\n",
      "epoch: 95 loss: 1.972338318824768 grad: 6.990227047050934\n",
      "epoch: 96 loss: 1.97164785861969 grad: 7.361250314743272\n",
      "epoch: 97 loss: 1.9753440618515015 grad: 7.666294198719755\n",
      "epoch: 98 loss: 1.9664455652236938 grad: 6.7761151686769034\n",
      "epoch: 99 loss: 1.9649556875228882 grad: 7.621168972835655\n",
      "epoch: 100 loss: 1.9655017852783203 grad: 7.601711609637335\n",
      "epoch: 101 loss: 1.9592686891555786 grad: 7.738892211327477\n",
      "epoch: 102 loss: 1.9657529592514038 grad: 8.118593333688166\n",
      "epoch: 103 loss: 1.9632179737091064 grad: 7.85079464025145\n",
      "epoch: 104 loss: 1.955756425857544 grad: 7.699462542561666\n",
      "epoch: 105 loss: 1.9504026174545288 grad: 7.922301225866827\n",
      "epoch: 106 loss: 1.961103916168213 grad: 7.73425474372648\n",
      "epoch: 107 loss: 1.9510563611984253 grad: 8.356882104058824\n",
      "epoch: 108 loss: 1.950072169303894 grad: 8.022324540726249\n",
      "epoch: 109 loss: 1.9486991167068481 grad: 8.214384708427898\n",
      "epoch: 110 loss: 1.9448699951171875 grad: 8.034785673288363\n",
      "epoch: 111 loss: 1.9441838264465332 grad: 8.464115511396871\n",
      "epoch: 112 loss: 1.9390705823898315 grad: 8.267431991174817\n",
      "epoch: 113 loss: 1.941358208656311 grad: 8.562839647385454\n",
      "epoch: 114 loss: 1.939582109451294 grad: 8.258786823630096\n",
      "epoch: 115 loss: 1.9369478225708008 grad: 8.645853349066797\n",
      "epoch: 116 loss: 1.9368867874145508 grad: 8.95624143516438\n",
      "epoch: 117 loss: 1.9395557641983032 grad: 9.30066888000343\n",
      "epoch: 118 loss: 1.935091257095337 grad: 8.857442153632523\n",
      "epoch: 119 loss: 1.9269150495529175 grad: 8.900125490338912\n",
      "epoch: 120 loss: 1.9251025915145874 grad: 9.131256602187124\n",
      "epoch: 121 loss: 1.9256809949874878 grad: 9.096137032186288\n",
      "epoch: 122 loss: 1.9186042547225952 grad: 8.98353801686908\n",
      "epoch: 123 loss: 1.922550916671753 grad: 8.636614676535366\n",
      "epoch: 124 loss: 1.9220658540725708 grad: 9.210465848091102\n",
      "epoch: 125 loss: 1.9138976335525513 grad: 9.215399232781714\n",
      "epoch: 126 loss: 1.9139623641967773 grad: 9.473526679023745\n",
      "epoch: 127 loss: 1.9126949310302734 grad: 9.07991035952277\n",
      "epoch: 128 loss: 1.9090982675552368 grad: 8.957840610369448\n",
      "epoch: 129 loss: 1.904314398765564 grad: 9.491379207931459\n",
      "epoch: 130 loss: 1.9058878421783447 grad: 9.422432022213581\n",
      "epoch: 131 loss: 1.904555320739746 grad: 9.186850806446893\n",
      "epoch: 132 loss: 1.9082400798797607 grad: 9.517920310165556\n",
      "epoch: 133 loss: 1.899971604347229 grad: 9.23824658850947\n",
      "epoch: 134 loss: 1.900100588798523 grad: 9.592633087217571\n",
      "epoch: 135 loss: 1.8911993503570557 grad: 8.890523074091309\n",
      "epoch: 136 loss: 1.8992317914962769 grad: 9.86995372214606\n",
      "epoch: 137 loss: 1.8972361087799072 grad: 9.329906591480333\n",
      "epoch: 138 loss: 1.8930548429489136 grad: 9.576683430163751\n",
      "epoch: 139 loss: 1.8912659883499146 grad: 9.512242192269436\n",
      "epoch: 140 loss: 1.8926790952682495 grad: 9.488021587036432\n",
      "epoch: 141 loss: 1.889672875404358 grad: 9.857942192246103\n",
      "epoch: 142 loss: 1.8850048780441284 grad: 10.354779610011194\n",
      "epoch: 143 loss: 1.8805936574935913 grad: 10.107903416830277\n",
      "epoch: 144 loss: 1.8754866123199463 grad: 9.79888024825662\n",
      "epoch: 145 loss: 1.8818013668060303 grad: 9.85886332150253\n",
      "epoch: 146 loss: 1.868114709854126 grad: 10.555635967986687\n",
      "epoch: 147 loss: 1.8719803094863892 grad: 9.870156788843728\n",
      "epoch: 148 loss: 1.8763560056686401 grad: 10.097736123062315\n",
      "epoch: 149 loss: 1.8744703531265259 grad: 10.197900723458993\n",
      "epoch: 150 loss: 1.8748313188552856 grad: 9.769058475063908\n",
      "epoch: 151 loss: 1.8685661554336548 grad: 9.781199372240476\n",
      "epoch: 152 loss: 1.869606375694275 grad: 9.629071015066334\n",
      "epoch: 153 loss: 1.861547827720642 grad: 10.226176521533894\n",
      "epoch: 154 loss: 1.8630410432815552 grad: 9.954696754008413\n",
      "epoch: 155 loss: 1.8655160665512085 grad: 9.630394257368549\n",
      "epoch: 156 loss: 1.8633226156234741 grad: 10.307522043644909\n",
      "epoch: 157 loss: 1.8631316423416138 grad: 10.264336453824644\n",
      "epoch: 158 loss: 1.8679701089859009 grad: 10.444212091421443\n",
      "epoch: 159 loss: 1.858901023864746 grad: 10.11188464602899\n",
      "epoch: 160 loss: 1.8607245683670044 grad: 10.039054904650483\n",
      "epoch: 161 loss: 1.852486252784729 grad: 9.692063508703121\n",
      "epoch: 162 loss: 1.8559643030166626 grad: 10.239336120304726\n",
      "epoch: 163 loss: 1.8526545763015747 grad: 9.75645654988549\n",
      "epoch: 164 loss: 1.8567098379135132 grad: 10.378627718721946\n",
      "epoch: 165 loss: 1.8545243740081787 grad: 9.969468934202773\n",
      "epoch: 166 loss: 1.8566865921020508 grad: 10.488544376153085\n",
      "epoch: 167 loss: 1.8512009382247925 grad: 9.928628289717293\n",
      "epoch: 168 loss: 1.8479828834533691 grad: 10.087055132901739\n",
      "epoch: 169 loss: 1.8433725833892822 grad: 9.927086132933342\n",
      "epoch: 170 loss: 1.8504586219787598 grad: 9.524341041399609\n",
      "epoch: 171 loss: 1.8532741069793701 grad: 10.3905457656254\n",
      "epoch: 172 loss: 1.8414641618728638 grad: 10.412450851769083\n",
      "epoch: 173 loss: 1.851722002029419 grad: 10.568604731673581\n",
      "epoch: 174 loss: 1.8500118255615234 grad: 10.134323946429445\n",
      "epoch: 175 loss: 1.8415268659591675 grad: 10.105173867646723\n",
      "epoch: 176 loss: 1.8295708894729614 grad: 10.127761410364498\n",
      "epoch: 177 loss: 1.8329977989196777 grad: 10.201439550545599\n",
      "epoch: 178 loss: 1.8334261178970337 grad: 10.483751281962864\n",
      "epoch: 179 loss: 1.8405967950820923 grad: 10.12972084083964\n",
      "epoch: 180 loss: 1.8355344533920288 grad: 10.116185334585015\n",
      "epoch: 181 loss: 1.839502215385437 grad: 10.312577337240947\n",
      "epoch: 182 loss: 1.8359096050262451 grad: 10.543547663542013\n",
      "epoch: 183 loss: 1.8314226865768433 grad: 10.569456096827274\n",
      "epoch: 184 loss: 1.8364042043685913 grad: 10.214595039833396\n",
      "epoch: 185 loss: 1.8385099172592163 grad: 10.93756689769142\n",
      "epoch: 186 loss: 1.834883689880371 grad: 10.217456731324395\n",
      "epoch: 187 loss: 1.8326456546783447 grad: 10.018958865132715\n",
      "epoch: 188 loss: 1.8225817680358887 grad: 9.826763812060808\n",
      "epoch: 189 loss: 1.835721731185913 grad: 9.819539173269673\n",
      "epoch: 190 loss: 1.8267148733139038 grad: 10.962867591840526\n",
      "epoch: 191 loss: 1.8339532613754272 grad: 10.999248261097819\n",
      "epoch: 192 loss: 1.8323204517364502 grad: 10.679933621222892\n",
      "epoch: 193 loss: 1.8305913209915161 grad: 10.074430147525929\n",
      "epoch: 194 loss: 1.8214548826217651 grad: 9.529518501640904\n",
      "epoch: 195 loss: 1.826775074005127 grad: 10.503749689353365\n",
      "epoch: 196 loss: 1.8230972290039062 grad: 10.258536644575615\n",
      "epoch: 197 loss: 1.8211508989334106 grad: 10.80264614414542\n",
      "epoch: 198 loss: 1.8240807056427002 grad: 10.153821127459643\n",
      "epoch: 199 loss: 1.8197089433670044 grad: 10.8532737143456\n",
      "epoch: 200 loss: 1.8208212852478027 grad: 10.36955870894922\n",
      "epoch: 201 loss: 1.8196192979812622 grad: 10.37544716845843\n",
      "epoch: 202 loss: 1.8162639141082764 grad: 10.461225817305229\n",
      "epoch: 203 loss: 1.8153218030929565 grad: 10.148904719286495\n",
      "epoch: 204 loss: 1.822685956954956 grad: 10.402891271570255\n",
      "epoch: 205 loss: 1.81423819065094 grad: 10.073764961464184\n",
      "epoch: 206 loss: 1.8245139122009277 grad: 10.212812141810973\n",
      "epoch: 207 loss: 1.8083438873291016 grad: 10.392420497560312\n",
      "epoch: 208 loss: 1.8174288272857666 grad: 10.022280773576645\n",
      "epoch: 209 loss: 1.80869460105896 grad: 10.163254253551482\n",
      "epoch: 210 loss: 1.8145384788513184 grad: 10.922646785509729\n",
      "epoch: 211 loss: 1.808487057685852 grad: 9.684231605728172\n",
      "epoch: 212 loss: 1.8094408512115479 grad: 10.140931940659703\n",
      "epoch: 213 loss: 1.8042349815368652 grad: 10.311776134296364\n",
      "epoch: 214 loss: 1.8093620538711548 grad: 10.251034555121487\n",
      "epoch: 215 loss: 1.8147664070129395 grad: 10.460743891991793\n",
      "epoch: 216 loss: 1.8036307096481323 grad: 10.271694463574224\n",
      "epoch: 217 loss: 1.8130145072937012 grad: 11.2516247445407\n",
      "epoch: 218 loss: 1.8023076057434082 grad: 10.21808952575786\n",
      "epoch: 219 loss: 1.8061580657958984 grad: 10.815218671535453\n",
      "epoch: 220 loss: 1.8067556619644165 grad: 10.409818770548712\n",
      "epoch: 221 loss: 1.818668007850647 grad: 10.1120656989367\n",
      "epoch: 222 loss: 1.8092451095581055 grad: 10.691793450583068\n",
      "epoch: 223 loss: 1.802938461303711 grad: 10.285201613872593\n",
      "epoch: 224 loss: 1.8010202646255493 grad: 10.071855679612666\n",
      "epoch: 225 loss: 1.8033217191696167 grad: 10.656650205172362\n",
      "epoch: 226 loss: 1.8030595779418945 grad: 10.549674770366105\n",
      "epoch: 227 loss: 1.8017463684082031 grad: 10.19216946493243\n",
      "epoch: 228 loss: 1.7980847358703613 grad: 10.0352466025848\n",
      "epoch: 229 loss: 1.805410623550415 grad: 10.426079382159052\n",
      "epoch: 230 loss: 1.7990363836288452 grad: 10.569809663028176\n",
      "epoch: 231 loss: 1.8013149499893188 grad: 10.405017433806307\n",
      "epoch: 232 loss: 1.7992842197418213 grad: 10.610322943526423\n",
      "epoch: 233 loss: 1.7964096069335938 grad: 10.209385013666063\n",
      "epoch: 234 loss: 1.7919925451278687 grad: 10.172503156299214\n",
      "epoch: 235 loss: 1.7941304445266724 grad: 10.084877988966625\n",
      "epoch: 236 loss: 1.7975994348526 grad: 11.014170950448642\n",
      "epoch: 237 loss: 1.7976787090301514 grad: 10.291856032426631\n",
      "epoch: 238 loss: 1.7943280935287476 grad: 9.96113551043654\n",
      "epoch: 239 loss: 1.7921922206878662 grad: 9.80694468130195\n",
      "epoch: 240 loss: 1.7939897775650024 grad: 10.20976935918369\n",
      "epoch: 241 loss: 1.8018280267715454 grad: 10.435496061655973\n",
      "epoch: 242 loss: 1.7926597595214844 grad: 10.294706474575731\n",
      "epoch: 243 loss: 1.7935452461242676 grad: 10.2200056927663\n",
      "epoch: 244 loss: 1.795330286026001 grad: 10.276252152538666\n",
      "epoch: 245 loss: 1.7931302785873413 grad: 10.934624575669803\n",
      "epoch: 246 loss: 1.798073172569275 grad: 11.063072407352072\n",
      "epoch: 247 loss: 1.790984869003296 grad: 10.598590928721167\n",
      "epoch: 248 loss: 1.791945457458496 grad: 10.329420181301733\n",
      "epoch: 249 loss: 1.7857391834259033 grad: 9.95764452084485\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 250 loss: 1.791428804397583 grad: 10.357337699759574\n",
      "epoch: 251 loss: 1.7980260848999023 grad: 10.304083808081312\n",
      "epoch: 252 loss: 1.7902634143829346 grad: 10.370742635697955\n",
      "epoch: 253 loss: 1.786914587020874 grad: 10.00460820905273\n",
      "epoch: 254 loss: 1.7809804677963257 grad: 10.309696942863484\n",
      "epoch: 255 loss: 1.7923943996429443 grad: 10.053587388786827\n",
      "epoch: 256 loss: 1.7947934865951538 grad: 9.650483417908646\n",
      "epoch: 257 loss: 1.7866836786270142 grad: 10.547846166919621\n",
      "epoch: 258 loss: 1.780271291732788 grad: 9.985122757439044\n",
      "epoch: 259 loss: 1.7855651378631592 grad: 10.254178482189124\n",
      "epoch: 260 loss: 1.7867858409881592 grad: 10.26049337548662\n",
      "epoch: 261 loss: 1.7837461233139038 grad: 10.277837112738144\n",
      "epoch: 262 loss: 1.7794767618179321 grad: 9.694295444984048\n",
      "epoch: 263 loss: 1.7807607650756836 grad: 9.668691040504546\n",
      "epoch: 264 loss: 1.7829118967056274 grad: 10.244381269218312\n",
      "epoch: 265 loss: 1.7880972623825073 grad: 10.088930626798954\n",
      "epoch: 266 loss: 1.779068946838379 grad: 10.930049786174168\n",
      "epoch: 267 loss: 1.7737153768539429 grad: 9.883063749728045\n",
      "epoch: 268 loss: 1.7863538265228271 grad: 10.72894536361601\n",
      "epoch: 269 loss: 1.7736155986785889 grad: 10.1520449684615\n",
      "epoch: 270 loss: 1.7826489210128784 grad: 10.429648512346109\n",
      "epoch: 271 loss: 1.7804324626922607 grad: 10.680730824225716\n",
      "epoch: 272 loss: 1.779587984085083 grad: 10.496824817547191\n",
      "epoch: 273 loss: 1.775755763053894 grad: 10.592471478166916\n",
      "epoch: 274 loss: 1.7827370166778564 grad: 10.47184726465789\n",
      "epoch: 275 loss: 1.7815243005752563 grad: 10.742814142478718\n",
      "epoch: 276 loss: 1.7804850339889526 grad: 10.126779490675304\n",
      "epoch: 277 loss: 1.775534749031067 grad: 10.835851839640075\n",
      "epoch: 278 loss: 1.777532935142517 grad: 10.558588418673487\n",
      "epoch: 279 loss: 1.77545964717865 grad: 9.950799258684533\n",
      "epoch: 280 loss: 1.7754039764404297 grad: 10.372223751685981\n",
      "epoch: 281 loss: 1.774141550064087 grad: 9.901185805103667\n",
      "epoch: 282 loss: 1.7708203792572021 grad: 9.9703095834924\n",
      "epoch: 283 loss: 1.77593994140625 grad: 9.918365582616794\n",
      "epoch: 284 loss: 1.776146411895752 grad: 11.294137887523643\n",
      "epoch: 285 loss: 1.7753323316574097 grad: 10.907599154726736\n",
      "epoch: 286 loss: 1.7790303230285645 grad: 11.077044036778961\n",
      "epoch: 287 loss: 1.7759647369384766 grad: 10.690374139733317\n",
      "epoch: 288 loss: 1.7708603143692017 grad: 10.283106326295565\n",
      "epoch: 289 loss: 1.7726718187332153 grad: 10.499476400558793\n",
      "epoch: 290 loss: 1.7722996473312378 grad: 10.685857005579958\n",
      "epoch: 291 loss: 1.7774726152420044 grad: 10.319441445120093\n",
      "epoch: 292 loss: 1.7717921733856201 grad: 10.680802827870975\n",
      "epoch: 293 loss: 1.7718380689620972 grad: 10.568517448727988\n",
      "epoch: 294 loss: 1.7652742862701416 grad: 10.35104697852558\n",
      "epoch: 295 loss: 1.7701674699783325 grad: 10.444082538168582\n",
      "epoch: 296 loss: 1.767810583114624 grad: 9.882145559526093\n",
      "epoch: 297 loss: 1.7675833702087402 grad: 10.541328749235069\n",
      "epoch: 298 loss: 1.767957091331482 grad: 10.469073374253062\n",
      "epoch: 299 loss: 1.7636573314666748 grad: 10.499431146737484\n",
      "epoch: 300 loss: 1.7601534128189087 grad: 10.70019302901531\n",
      "epoch: 301 loss: 1.7643624544143677 grad: 11.091116506517643\n",
      "epoch: 302 loss: 1.7633594274520874 grad: 10.838678140215398\n",
      "epoch: 303 loss: 1.7594331502914429 grad: 11.557190466273044\n",
      "epoch: 304 loss: 1.7681900262832642 grad: 10.770569524897764\n",
      "epoch: 305 loss: 1.7633155584335327 grad: 10.46740226548106\n",
      "epoch: 306 loss: 1.7550208568572998 grad: 10.772182844638351\n",
      "epoch: 307 loss: 1.7620458602905273 grad: 10.078139006810646\n",
      "epoch: 308 loss: 1.7652395963668823 grad: 11.718584056307991\n",
      "epoch: 309 loss: 1.7578723430633545 grad: 11.136107295123299\n",
      "epoch: 310 loss: 1.7561194896697998 grad: 11.463609768521218\n",
      "epoch: 311 loss: 1.7598493099212646 grad: 12.07014187134891\n",
      "epoch: 312 loss: 1.7638198137283325 grad: 11.248365817236758\n",
      "epoch: 313 loss: 1.7561819553375244 grad: 10.424765313938556\n",
      "epoch: 314 loss: 1.7515997886657715 grad: 11.03433853557836\n",
      "epoch: 315 loss: 1.7534615993499756 grad: 11.156272305722629\n",
      "epoch: 316 loss: 1.7561228275299072 grad: 11.503230627700095\n",
      "epoch: 317 loss: 1.7469203472137451 grad: 11.122727063987108\n",
      "epoch: 318 loss: 1.7520428895950317 grad: 11.416819142185092\n",
      "epoch: 319 loss: 1.7449991703033447 grad: 11.243882349027055\n",
      "epoch: 320 loss: 1.750715970993042 grad: 11.266279801681993\n",
      "epoch: 321 loss: 1.7495002746582031 grad: 11.49806436911107\n",
      "epoch: 322 loss: 1.749211311340332 grad: 10.882869122209884\n",
      "epoch: 323 loss: 1.7509022951126099 grad: 10.637445692253847\n",
      "epoch: 324 loss: 1.7411447763442993 grad: 11.295148369124425\n",
      "epoch: 325 loss: 1.7485824823379517 grad: 10.640719048871052\n",
      "epoch: 326 loss: 1.7464784383773804 grad: 11.17499698246164\n",
      "epoch: 327 loss: 1.7462005615234375 grad: 12.01129575440335\n",
      "epoch: 328 loss: 1.7427384853363037 grad: 10.803600539157669\n",
      "epoch: 329 loss: 1.739615559577942 grad: 11.052267573788644\n",
      "epoch: 330 loss: 1.7434171438217163 grad: 11.547895067814915\n",
      "epoch: 331 loss: 1.743417501449585 grad: 11.624606278562357\n",
      "epoch: 332 loss: 1.7321090698242188 grad: 10.76975382613166\n",
      "epoch: 333 loss: 1.7434663772583008 grad: 10.893901765908277\n",
      "epoch: 334 loss: 1.7374005317687988 grad: 11.69692026007743\n",
      "epoch: 335 loss: 1.7445783615112305 grad: 11.983773537652773\n",
      "epoch: 336 loss: 1.7332663536071777 grad: 11.699524264161786\n",
      "epoch: 337 loss: 1.7350536584854126 grad: 11.178174891716075\n",
      "epoch: 338 loss: 1.7460918426513672 grad: 11.793207626279798\n",
      "epoch: 339 loss: 1.7370398044586182 grad: 11.29532288358591\n",
      "epoch: 340 loss: 1.741184115409851 grad: 10.676715485929023\n",
      "epoch: 341 loss: 1.7408446073532104 grad: 11.90076248535502\n",
      "epoch: 342 loss: 1.7355600595474243 grad: 11.297886727170813\n",
      "epoch: 343 loss: 1.7394741773605347 grad: 11.547317225175599\n",
      "epoch: 344 loss: 1.734426498413086 grad: 12.174174965063612\n",
      "epoch: 345 loss: 1.7396587133407593 grad: 11.482039289704213\n",
      "epoch: 346 loss: 1.7386127710342407 grad: 11.039150261379305\n",
      "epoch: 347 loss: 1.7408983707427979 grad: 11.545620869386882\n",
      "epoch: 348 loss: 1.735068917274475 grad: 11.601408673997318\n",
      "epoch: 349 loss: 1.7327275276184082 grad: 11.11005509161346\n",
      "epoch: 350 loss: 1.7276231050491333 grad: 11.131981702846668\n",
      "epoch: 351 loss: 1.7286951541900635 grad: 11.704000140599433\n",
      "epoch: 352 loss: 1.731049656867981 grad: 11.694793658168425\n",
      "epoch: 353 loss: 1.7267674207687378 grad: 11.7367376051991\n",
      "epoch: 354 loss: 1.7286852598190308 grad: 11.36460016363315\n",
      "epoch: 355 loss: 1.7247267961502075 grad: 11.693295467718844\n",
      "epoch: 356 loss: 1.7304657697677612 grad: 11.937952929723357\n",
      "epoch: 357 loss: 1.7207309007644653 grad: 11.333036151818103\n",
      "epoch: 358 loss: 1.7276251316070557 grad: 11.824943929356301\n",
      "epoch: 359 loss: 1.7248878479003906 grad: 11.26563073827752\n",
      "epoch: 360 loss: 1.7257715463638306 grad: 11.199237493901617\n",
      "epoch: 361 loss: 1.7376238107681274 grad: 12.149108440807414\n",
      "epoch: 362 loss: 1.727709412574768 grad: 11.219695368981254\n",
      "epoch: 363 loss: 1.7245007753372192 grad: 11.859460951553451\n",
      "epoch: 364 loss: 1.7169018983840942 grad: 11.601180463940615\n",
      "epoch: 365 loss: 1.720491886138916 grad: 11.597108443733305\n",
      "epoch: 366 loss: 1.7263052463531494 grad: 11.871991088495605\n",
      "epoch: 367 loss: 1.7151715755462646 grad: 11.122508544290055\n",
      "epoch: 368 loss: 1.7158198356628418 grad: 11.397382422557307\n",
      "epoch: 369 loss: 1.7201875448226929 grad: 11.758915833493193\n",
      "epoch: 370 loss: 1.7227990627288818 grad: 11.631689911767367\n",
      "epoch: 371 loss: 1.7307623624801636 grad: 12.080234552896211\n",
      "epoch: 372 loss: 1.7288732528686523 grad: 11.849736124210592\n",
      "epoch: 373 loss: 1.7130790948867798 grad: 11.885020938132786\n",
      "epoch: 374 loss: 1.720665693283081 grad: 12.111847367167236\n",
      "epoch: 375 loss: 1.7157789468765259 grad: 12.723322690826738\n",
      "epoch: 376 loss: 1.7173267602920532 grad: 11.820767162471181\n",
      "epoch: 377 loss: 1.7126246690750122 grad: 11.625981540988302\n",
      "epoch: 378 loss: 1.712384581565857 grad: 11.725223570056851\n",
      "epoch: 379 loss: 1.7213165760040283 grad: 12.127932458724235\n",
      "epoch: 380 loss: 1.721773386001587 grad: 12.263624272567945\n",
      "epoch: 381 loss: 1.7155263423919678 grad: 11.24877282883972\n",
      "epoch: 382 loss: 1.7165088653564453 grad: 11.848972085612042\n",
      "epoch: 383 loss: 1.713290810585022 grad: 11.601555357731524\n",
      "epoch: 384 loss: 1.7042431831359863 grad: 11.94135419539516\n",
      "epoch: 385 loss: 1.7194429636001587 grad: 11.868005933594846\n",
      "epoch: 386 loss: 1.7020747661590576 grad: 12.096480410383453\n",
      "epoch: 387 loss: 1.7161215543746948 grad: 11.934150364212988\n",
      "epoch: 388 loss: 1.722330093383789 grad: 11.930664826191903\n",
      "epoch: 389 loss: 1.7136492729187012 grad: 11.89882289819301\n",
      "epoch: 390 loss: 1.7135143280029297 grad: 11.412088550405489\n",
      "epoch: 391 loss: 1.7220335006713867 grad: 12.62398770013972\n",
      "epoch: 392 loss: 1.7177015542984009 grad: 11.924090548329765\n",
      "epoch: 393 loss: 1.7149783372879028 grad: 11.412931770263683\n",
      "epoch: 394 loss: 1.7074953317642212 grad: 12.6218731573502\n",
      "epoch: 395 loss: 1.708640694618225 grad: 11.226214298520178\n",
      "epoch: 396 loss: 1.7124700546264648 grad: 11.694972804703173\n",
      "epoch: 397 loss: 1.7222458124160767 grad: 11.736210954316434\n",
      "epoch: 398 loss: 1.7064050436019897 grad: 12.055011077222252\n",
      "epoch: 399 loss: 1.7073673009872437 grad: 11.485549891337989\n",
      "epoch: 400 loss: 1.7066489458084106 grad: 11.793299713815074\n",
      "epoch: 401 loss: 1.7122431993484497 grad: 12.01209908666917\n",
      "epoch: 402 loss: 1.7028249502182007 grad: 11.758781169260304\n",
      "epoch: 403 loss: 1.7140519618988037 grad: 11.39988588107129\n",
      "epoch: 404 loss: 1.7052242755889893 grad: 11.247338212272595\n",
      "epoch: 405 loss: 1.7110207080841064 grad: 12.01429081337142\n",
      "epoch: 406 loss: 1.7005722522735596 grad: 11.201941064588489\n",
      "epoch: 407 loss: 1.7015752792358398 grad: 11.956589398092575\n",
      "epoch: 408 loss: 1.707222819328308 grad: 11.680740689474439\n",
      "epoch: 409 loss: 1.7057985067367554 grad: 11.984117151045847\n",
      "epoch: 410 loss: 1.7028920650482178 grad: 11.673499795674745\n",
      "epoch: 411 loss: 1.701594591140747 grad: 12.469294163723669\n",
      "epoch: 412 loss: 1.706655740737915 grad: 11.78208777231593\n",
      "epoch: 413 loss: 1.6991631984710693 grad: 11.823368212991646\n",
      "epoch: 414 loss: 1.7043735980987549 grad: 12.082507725302426\n",
      "epoch: 415 loss: 1.7014926671981812 grad: 12.78643542429107\n",
      "epoch: 416 loss: 1.6998708248138428 grad: 11.669068765538256\n",
      "epoch: 417 loss: 1.7016916275024414 grad: 12.179906285353123\n",
      "epoch: 418 loss: 1.7011468410491943 grad: 10.952415841616808\n",
      "epoch: 419 loss: 1.6994982957839966 grad: 11.432577864658679\n",
      "epoch: 420 loss: 1.7023818492889404 grad: 11.645138966939633\n",
      "epoch: 421 loss: 1.701531171798706 grad: 10.968716564765643\n",
      "epoch: 422 loss: 1.6982800960540771 grad: 11.384505425121576\n",
      "epoch: 423 loss: 1.68598473072052 grad: 11.036062481081379\n",
      "epoch: 424 loss: 1.6978929042816162 grad: 12.9335546861994\n",
      "epoch: 425 loss: 1.69380784034729 grad: 11.627831077661424\n",
      "epoch: 426 loss: 1.7005244493484497 grad: 12.738085935697965\n",
      "epoch: 427 loss: 1.6942170858383179 grad: 11.971865713182423\n",
      "epoch: 428 loss: 1.694081425666809 grad: 12.089193286862047\n",
      "epoch: 429 loss: 1.6942604780197144 grad: 11.345324777561935\n",
      "epoch: 430 loss: 1.697525143623352 grad: 12.974574665538967\n",
      "epoch: 431 loss: 1.6907598972320557 grad: 11.859756721789756\n",
      "epoch: 432 loss: 1.7014448642730713 grad: 12.24805534468402\n",
      "epoch: 433 loss: 1.6968389749526978 grad: 11.879867864447453\n",
      "epoch: 434 loss: 1.7043919563293457 grad: 11.977040356623807\n",
      "epoch: 435 loss: 1.6943235397338867 grad: 11.592072250661515\n",
      "epoch: 436 loss: 1.7028614282608032 grad: 12.447854009043011\n",
      "epoch: 437 loss: 1.6958186626434326 grad: 11.654142224348135\n",
      "epoch: 438 loss: 1.6990156173706055 grad: 11.825959319034444\n",
      "epoch: 439 loss: 1.6994106769561768 grad: 12.155405808092347\n",
      "epoch: 440 loss: 1.6957502365112305 grad: 11.397268577124036\n",
      "epoch: 441 loss: 1.694023609161377 grad: 11.905636447297026\n",
      "epoch: 442 loss: 1.6989208459854126 grad: 12.354067191814206\n",
      "epoch: 443 loss: 1.6929636001586914 grad: 12.567184724401505\n",
      "epoch: 444 loss: 1.6956628561019897 grad: 12.666711820999073\n",
      "epoch: 445 loss: 1.6885197162628174 grad: 11.690548942934367\n",
      "epoch: 446 loss: 1.6974800825119019 grad: 12.566420202269144\n",
      "epoch: 447 loss: 1.6895403861999512 grad: 12.722926210501187\n",
      "epoch: 448 loss: 1.6917057037353516 grad: 11.832358004954008\n",
      "epoch: 449 loss: 1.6904754638671875 grad: 11.739839131810836\n",
      "epoch: 450 loss: 1.6840075254440308 grad: 11.808701171554507\n",
      "epoch: 451 loss: 1.6881884336471558 grad: 11.972045159972613\n",
      "epoch: 452 loss: 1.68880295753479 grad: 11.807712972740687\n",
      "epoch: 453 loss: 1.6956603527069092 grad: 12.581225362399387\n",
      "epoch: 454 loss: 1.695306420326233 grad: 12.586524636883821\n",
      "epoch: 455 loss: 1.6882754564285278 grad: 12.147640878438121\n",
      "epoch: 456 loss: 1.681734561920166 grad: 12.256386942784523\n",
      "epoch: 457 loss: 1.6973577737808228 grad: 11.864657986872194\n",
      "epoch: 458 loss: 1.689683198928833 grad: 12.674868835402387\n",
      "epoch: 459 loss: 1.6898328065872192 grad: 13.211574619162887\n",
      "epoch: 460 loss: 1.6815921068191528 grad: 12.135483286565258\n",
      "epoch: 461 loss: 1.6783274412155151 grad: 12.22162502151101\n",
      "epoch: 462 loss: 1.6855418682098389 grad: 11.897469113610448\n",
      "epoch: 463 loss: 1.6956777572631836 grad: 12.55863787174698\n",
      "epoch: 464 loss: 1.6897032260894775 grad: 11.59979650458055\n",
      "epoch: 465 loss: 1.686873197555542 grad: 11.815208428021934\n",
      "epoch: 466 loss: 1.685351848602295 grad: 12.51789443607309\n",
      "epoch: 467 loss: 1.6900385618209839 grad: 12.597990067483533\n",
      "epoch: 468 loss: 1.6806907653808594 grad: 12.250156231601501\n",
      "epoch: 469 loss: 1.6832616329193115 grad: 12.297489224090462\n",
      "epoch: 470 loss: 1.6838443279266357 grad: 12.234638692145902\n",
      "epoch: 471 loss: 1.6825264692306519 grad: 12.188027231488377\n",
      "epoch: 472 loss: 1.6846933364868164 grad: 12.297020811668878\n",
      "epoch: 473 loss: 1.6782476902008057 grad: 12.016533127956329\n",
      "epoch: 474 loss: 1.6783779859542847 grad: 12.743678522237119\n",
      "epoch: 475 loss: 1.681892991065979 grad: 11.91203611910284\n",
      "epoch: 476 loss: 1.6787418127059937 grad: 12.419531290160698\n",
      "epoch: 477 loss: 1.6889125108718872 grad: 12.884791567958596\n",
      "epoch: 478 loss: 1.677937388420105 grad: 12.37664969739992\n",
      "epoch: 479 loss: 1.6786361932754517 grad: 11.355381937919272\n",
      "epoch: 480 loss: 1.6814820766448975 grad: 11.992668242629854\n",
      "epoch: 481 loss: 1.6790413856506348 grad: 12.000290761923505\n",
      "epoch: 482 loss: 1.6840369701385498 grad: 12.651693581374333\n",
      "epoch: 483 loss: 1.6793336868286133 grad: 12.154988058295752\n",
      "epoch: 484 loss: 1.6830755472183228 grad: 12.712677835272478\n",
      "epoch: 485 loss: 1.6803573369979858 grad: 12.674726722651117\n",
      "epoch: 486 loss: 1.6731303930282593 grad: 12.61100606867186\n",
      "epoch: 487 loss: 1.6848418712615967 grad: 13.393557699485903\n",
      "epoch: 488 loss: 1.6827818155288696 grad: 13.449854170622688\n",
      "epoch: 489 loss: 1.6744554042816162 grad: 12.267366314425118\n",
      "epoch: 490 loss: 1.678534984588623 grad: 11.875018131298324\n",
      "epoch: 491 loss: 1.6800020933151245 grad: 12.668237909290289\n",
      "epoch: 492 loss: 1.6843594312667847 grad: 12.776450587436557\n",
      "epoch: 493 loss: 1.6739590167999268 grad: 13.413708916333105\n",
      "epoch: 494 loss: 1.6820740699768066 grad: 12.189233670875963\n",
      "epoch: 495 loss: 1.681956171989441 grad: 12.744055370245839\n",
      "epoch: 496 loss: 1.6750630140304565 grad: 11.896490493013212\n",
      "epoch: 497 loss: 1.6681193113327026 grad: 12.084519996544318\n",
      "epoch: 498 loss: 1.677135705947876 grad: 12.525582542657734\n",
      "epoch: 499 loss: 1.6822620630264282 grad: 12.47174722160257\n",
      "1.9151214361190796\n",
      "epoch: 0 loss: 2.3042428493499756 grad: 1.0422026410020726\n",
      "epoch: 1 loss: 2.2793428897857666 grad: 1.4428422188461159\n",
      "epoch: 2 loss: 2.2312169075012207 grad: 2.062248270613112\n",
      "epoch: 3 loss: 2.1888649463653564 grad: 2.3874992885361683\n",
      "epoch: 4 loss: 2.1127994060516357 grad: 2.9896711850777224\n",
      "epoch: 5 loss: 2.0714311599731445 grad: 4.00191333546998\n",
      "epoch: 6 loss: 2.0415165424346924 grad: 4.255469219882913\n",
      "epoch: 7 loss: 2.0345044136047363 grad: 4.6340694976850445\n",
      "epoch: 8 loss: 2.0104105472564697 grad: 4.604006088162321\n",
      "epoch: 9 loss: 1.981960415840149 grad: 5.655257058295695\n",
      "epoch: 10 loss: 1.9838969707489014 grad: 4.866048695646145\n",
      "epoch: 11 loss: 1.9578133821487427 grad: 5.461560504568283\n",
      "epoch: 12 loss: 1.9241667985916138 grad: 5.32445919924667\n",
      "epoch: 13 loss: 1.9068611860275269 grad: 6.114106851230774\n",
      "epoch: 14 loss: 1.8856487274169922 grad: 5.934743020696462\n",
      "epoch: 15 loss: 1.8621906042099 grad: 6.1352082317277405\n",
      "epoch: 16 loss: 1.879382610321045 grad: 6.422856515999662\n",
      "epoch: 17 loss: 1.85010826587677 grad: 6.7867680963605554\n",
      "epoch: 18 loss: 1.8087975978851318 grad: 5.964160809263824\n",
      "epoch: 19 loss: 1.802822232246399 grad: 7.042835407295367\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 20 loss: 1.8419002294540405 grad: 6.79705059517818\n",
      "epoch: 21 loss: 1.7795895338058472 grad: 6.416451749902787\n",
      "epoch: 22 loss: 1.7872612476348877 grad: 7.097541643455366\n",
      "epoch: 23 loss: 1.7811191082000732 grad: 6.954008010769492\n",
      "epoch: 24 loss: 1.7582621574401855 grad: 7.637858966136322\n",
      "epoch: 25 loss: 1.7743549346923828 grad: 7.2356133538497875\n",
      "epoch: 26 loss: 1.7428662776947021 grad: 6.637803800850331\n",
      "epoch: 27 loss: 1.7411623001098633 grad: 6.993410375294467\n",
      "epoch: 28 loss: 1.735198974609375 grad: 6.955730621953355\n",
      "epoch: 29 loss: 1.7065110206604004 grad: 7.0911411483548505\n",
      "epoch: 30 loss: 1.7173680067062378 grad: 6.427490923688599\n",
      "epoch: 31 loss: 1.7289140224456787 grad: 6.674054238500373\n",
      "epoch: 32 loss: 1.723422884941101 grad: 6.889645722871166\n",
      "epoch: 33 loss: 1.6882433891296387 grad: 6.708249598883124\n",
      "epoch: 34 loss: 1.6967250108718872 grad: 6.856615193094873\n",
      "epoch: 35 loss: 1.6990677118301392 grad: 6.753183343143771\n",
      "epoch: 36 loss: 1.6815811395645142 grad: 6.2156638136844515\n",
      "epoch: 37 loss: 1.7130295038223267 grad: 7.459866001746074\n",
      "epoch: 38 loss: 1.6825079917907715 grad: 7.083648940754338\n",
      "epoch: 39 loss: 1.6919481754302979 grad: 7.114148402231789\n",
      "epoch: 40 loss: 1.69697904586792 grad: 7.879665759551923\n",
      "epoch: 41 loss: 1.6790730953216553 grad: 7.116770226421645\n",
      "epoch: 42 loss: 1.6563678979873657 grad: 6.468225880311885\n",
      "epoch: 43 loss: 1.6806002855300903 grad: 6.6759549938686265\n",
      "epoch: 44 loss: 1.6776154041290283 grad: 7.269140405778122\n",
      "epoch: 45 loss: 1.6580519676208496 grad: 7.020576359694204\n",
      "epoch: 46 loss: 1.666939377784729 grad: 5.992668800937642\n",
      "epoch: 47 loss: 1.6736615896224976 grad: 6.742833793076912\n",
      "epoch: 48 loss: 1.6637409925460815 grad: 6.533982354898254\n",
      "epoch: 49 loss: 1.6711878776550293 grad: 6.594028188103992\n",
      "epoch: 50 loss: 1.654825210571289 grad: 6.692016062310561\n",
      "epoch: 51 loss: 1.6525369882583618 grad: 6.738792234464661\n",
      "epoch: 52 loss: 1.6590083837509155 grad: 7.024941371017901\n",
      "epoch: 53 loss: 1.6670355796813965 grad: 6.490543172907189\n",
      "epoch: 54 loss: 1.6624675989151 grad: 5.961970530282362\n",
      "epoch: 55 loss: 1.660364031791687 grad: 6.67314513994152\n",
      "epoch: 56 loss: 1.6445213556289673 grad: 6.108773742373852\n",
      "epoch: 57 loss: 1.639326810836792 grad: 5.61571269599725\n",
      "epoch: 58 loss: 1.6368095874786377 grad: 6.35661099272866\n",
      "epoch: 59 loss: 1.655859112739563 grad: 6.14072418821461\n",
      "epoch: 60 loss: 1.6438182592391968 grad: 6.216276659919545\n",
      "epoch: 61 loss: 1.6514743566513062 grad: 6.384307758867166\n",
      "epoch: 62 loss: 1.6382535696029663 grad: 6.5460068712501585\n",
      "epoch: 63 loss: 1.6456340551376343 grad: 6.5445013481204075\n",
      "epoch: 64 loss: 1.6518678665161133 grad: 6.153109979881438\n",
      "epoch: 65 loss: 1.6350198984146118 grad: 6.768956943390736\n",
      "epoch: 66 loss: 1.67610764503479 grad: 7.514282789179965\n",
      "epoch: 67 loss: 1.614519715309143 grad: 6.4971588797025825\n",
      "epoch: 68 loss: 1.6259146928787231 grad: 5.672112577292691\n",
      "epoch: 69 loss: 1.6174508333206177 grad: 5.752978073662783\n",
      "epoch: 70 loss: 1.6313029527664185 grad: 6.074169307918401\n",
      "epoch: 71 loss: 1.6208165884017944 grad: 5.9933758879296\n",
      "epoch: 72 loss: 1.6098989248275757 grad: 5.980235865674504\n",
      "epoch: 73 loss: 1.6235986948013306 grad: 5.85726402820734\n",
      "epoch: 74 loss: 1.6204719543457031 grad: 6.109215247488471\n",
      "epoch: 75 loss: 1.6157385110855103 grad: 5.91086320351199\n",
      "epoch: 76 loss: 1.610278844833374 grad: 5.630922191104983\n",
      "epoch: 77 loss: 1.611092448234558 grad: 5.771966820157393\n",
      "epoch: 78 loss: 1.6000128984451294 grad: 4.8833574660859\n",
      "epoch: 79 loss: 1.5927475690841675 grad: 5.198381818329157\n",
      "epoch: 80 loss: 1.6022769212722778 grad: 5.475765924271804\n",
      "epoch: 81 loss: 1.611986517906189 grad: 5.583239239986488\n",
      "epoch: 82 loss: 1.6142675876617432 grad: 5.791796167327058\n",
      "epoch: 83 loss: 1.61782968044281 grad: 6.63796935776866\n",
      "epoch: 84 loss: 1.603511095046997 grad: 4.9813401487246\n",
      "epoch: 85 loss: 1.6066839694976807 grad: 6.465119257900196\n",
      "epoch: 86 loss: 1.6155202388763428 grad: 5.52903556761804\n",
      "epoch: 87 loss: 1.6169854402542114 grad: 5.168089486904455\n",
      "epoch: 88 loss: 1.5993282794952393 grad: 4.9467144835032535\n",
      "epoch: 89 loss: 1.6002459526062012 grad: 5.792121095156911\n",
      "epoch: 90 loss: 1.5892002582550049 grad: 5.591110804105165\n",
      "epoch: 91 loss: 1.6069691181182861 grad: 6.071304788751842\n",
      "epoch: 92 loss: 1.6131519079208374 grad: 5.795021400224377\n",
      "epoch: 93 loss: 1.6085286140441895 grad: 5.691909029241193\n",
      "epoch: 94 loss: 1.588606357574463 grad: 4.582031201127183\n",
      "epoch: 95 loss: 1.6023447513580322 grad: 6.2477398876757695\n",
      "epoch: 96 loss: 1.6119790077209473 grad: 5.413411205281367\n",
      "epoch: 97 loss: 1.6015812158584595 grad: 5.056304362910692\n",
      "epoch: 98 loss: 1.6016255617141724 grad: 4.5900019411402315\n",
      "epoch: 99 loss: 1.604015827178955 grad: 4.235099401047924\n",
      "epoch: 100 loss: 1.6004279851913452 grad: 6.100398213307781\n",
      "epoch: 101 loss: 1.6076791286468506 grad: 6.113894198847722\n",
      "epoch: 102 loss: 1.6148326396942139 grad: 6.156175459972834\n",
      "epoch: 103 loss: 1.5928335189819336 grad: 5.05233205368766\n",
      "epoch: 104 loss: 1.590375542640686 grad: 5.5226779072956615\n",
      "epoch: 105 loss: 1.5774697065353394 grad: 4.42571823440743\n",
      "epoch: 106 loss: 1.6037403345108032 grad: 5.723926668167382\n",
      "epoch: 107 loss: 1.6073638200759888 grad: 5.122893647044942\n",
      "epoch: 108 loss: 1.5934052467346191 grad: 4.621300247477965\n",
      "epoch: 109 loss: 1.5774562358856201 grad: 4.271694876129076\n",
      "epoch: 110 loss: 1.5993342399597168 grad: 5.100924203436859\n",
      "epoch: 111 loss: 1.6018389463424683 grad: 5.079858978644234\n",
      "epoch: 112 loss: 1.589100956916809 grad: 5.073564754844079\n",
      "epoch: 113 loss: 1.5812559127807617 grad: 6.039375969141792\n",
      "epoch: 114 loss: 1.613903522491455 grad: 6.623940104864348\n",
      "epoch: 115 loss: 1.6015664339065552 grad: 4.765518757137533\n",
      "epoch: 116 loss: 1.5870007276535034 grad: 5.217274434263532\n",
      "epoch: 117 loss: 1.6073193550109863 grad: 4.821794583124041\n",
      "epoch: 118 loss: 1.576942801475525 grad: 5.4617777931026135\n",
      "epoch: 119 loss: 1.5825806856155396 grad: 5.025926708439531\n",
      "epoch: 120 loss: 1.5888981819152832 grad: 5.042328188197788\n",
      "epoch: 121 loss: 1.5890288352966309 grad: 4.671130398086864\n",
      "epoch: 122 loss: 1.5944315195083618 grad: 5.880904360793133\n",
      "epoch: 123 loss: 1.5909039974212646 grad: 4.691192973073929\n",
      "epoch: 124 loss: 1.5956231355667114 grad: 5.122837600168255\n",
      "epoch: 125 loss: 1.5744028091430664 grad: 3.996040532030336\n",
      "epoch: 126 loss: 1.5734165906906128 grad: 4.855097435482471\n",
      "epoch: 127 loss: 1.5805052518844604 grad: 4.732849846924593\n",
      "epoch: 128 loss: 1.5843027830123901 grad: 5.945851892885933\n",
      "epoch: 129 loss: 1.572561502456665 grad: 4.705199940947754\n",
      "epoch: 130 loss: 1.5742909908294678 grad: 4.498129423326983\n",
      "epoch: 131 loss: 1.5740429162979126 grad: 5.140508115065376\n",
      "epoch: 132 loss: 1.582350730895996 grad: 4.297243059712624\n",
      "epoch: 133 loss: 1.5802056789398193 grad: 5.116163449497414\n",
      "epoch: 134 loss: 1.5806182622909546 grad: 4.853577934674823\n",
      "epoch: 135 loss: 1.5751214027404785 grad: 5.558272728499605\n",
      "epoch: 136 loss: 1.5872358083724976 grad: 4.46618605377916\n",
      "epoch: 137 loss: 1.6145753860473633 grad: 6.111021374918552\n",
      "epoch: 138 loss: 1.6019028425216675 grad: 6.138037734549175\n",
      "epoch: 139 loss: 1.573758602142334 grad: 4.03621559570236\n",
      "epoch: 140 loss: 1.566970944404602 grad: 3.631457380177374\n",
      "epoch: 141 loss: 1.6077808141708374 grad: 6.247531211313237\n",
      "epoch: 142 loss: 1.5842609405517578 grad: 5.321193757116946\n",
      "epoch: 143 loss: 1.6004966497421265 grad: 5.181033956785943\n",
      "epoch: 144 loss: 1.5802472829818726 grad: 4.598395409025404\n",
      "epoch: 145 loss: 1.573103904724121 grad: 4.143133841614678\n",
      "epoch: 146 loss: 1.574326753616333 grad: 4.695928719980695\n",
      "epoch: 147 loss: 1.597159743309021 grad: 5.2692191714538446\n",
      "epoch: 148 loss: 1.6021591424942017 grad: 6.19103780092252\n",
      "epoch: 149 loss: 1.5821794271469116 grad: 5.92715015018183\n",
      "epoch: 150 loss: 1.587950348854065 grad: 4.44378841843181\n",
      "epoch: 151 loss: 1.5838195085525513 grad: 4.941228076896706\n",
      "epoch: 152 loss: 1.5885000228881836 grad: 5.401111331805585\n",
      "epoch: 153 loss: 1.5679725408554077 grad: 4.455102199565739\n",
      "epoch: 154 loss: 1.5665405988693237 grad: 4.043417456141991\n",
      "epoch: 155 loss: 1.5635466575622559 grad: 4.7892140106254235\n",
      "epoch: 156 loss: 1.576392412185669 grad: 4.6752982548051305\n",
      "epoch: 157 loss: 1.5805057287216187 grad: 4.933722707897591\n",
      "epoch: 158 loss: 1.576595425605774 grad: 5.1911226588186645\n",
      "epoch: 159 loss: 1.5704982280731201 grad: 4.578443996069262\n",
      "epoch: 160 loss: 1.571407675743103 grad: 4.235309413418395\n",
      "epoch: 161 loss: 1.5774030685424805 grad: 5.221915771525806\n",
      "epoch: 162 loss: 1.583593487739563 grad: 5.449112274255094\n",
      "epoch: 163 loss: 1.591086506843567 grad: 4.436967544714461\n",
      "epoch: 164 loss: 1.5874204635620117 grad: 5.526012669408819\n",
      "epoch: 165 loss: 1.5809355974197388 grad: 4.634163835708485\n",
      "epoch: 166 loss: 1.5646494626998901 grad: 4.661653158605452\n",
      "epoch: 167 loss: 1.5648912191390991 grad: 4.341701578297731\n",
      "epoch: 168 loss: 1.571078896522522 grad: 5.740540579556384\n",
      "epoch: 169 loss: 1.6045438051223755 grad: 4.714547773544087\n",
      "epoch: 170 loss: 1.5738930702209473 grad: 4.3956109665749405\n",
      "epoch: 171 loss: 1.5849714279174805 grad: 5.296664236046368\n",
      "epoch: 172 loss: 1.5624666213989258 grad: 4.658161131096929\n",
      "epoch: 173 loss: 1.5775463581085205 grad: 3.916223350275911\n",
      "epoch: 174 loss: 1.584242343902588 grad: 5.983417025405433\n",
      "epoch: 175 loss: 1.5789144039154053 grad: 4.656971278253038\n",
      "epoch: 176 loss: 1.6119385957717896 grad: 5.432614688836948\n",
      "epoch: 177 loss: 1.586045265197754 grad: 6.175368287863854\n",
      "epoch: 178 loss: 1.587862253189087 grad: 4.740692510056269\n",
      "epoch: 179 loss: 1.5654586553573608 grad: 5.0266404130404805\n",
      "epoch: 180 loss: 1.5949931144714355 grad: 5.035022976610543\n",
      "epoch: 181 loss: 1.5848428010940552 grad: 4.923813373173371\n",
      "epoch: 182 loss: 1.5680757761001587 grad: 3.4699970748885782\n",
      "epoch: 183 loss: 1.5555968284606934 grad: 3.5661660947761114\n",
      "epoch: 184 loss: 1.573098063468933 grad: 4.535797871181717\n",
      "epoch: 185 loss: 1.5735479593276978 grad: 4.701577698501349\n",
      "epoch: 186 loss: 1.5771061182022095 grad: 5.520279526197593\n",
      "epoch: 187 loss: 1.5730215311050415 grad: 3.9500966521503527\n",
      "epoch: 188 loss: 1.5772744417190552 grad: 3.8970866640847457\n",
      "epoch: 189 loss: 1.5717297792434692 grad: 3.6755624074908804\n",
      "epoch: 190 loss: 1.567878007888794 grad: 5.222177374940992\n",
      "epoch: 191 loss: 1.5669314861297607 grad: 5.359062619435766\n",
      "epoch: 192 loss: 1.5623904466629028 grad: 3.923677771958031\n",
      "epoch: 193 loss: 1.5689796209335327 grad: 4.882335414654144\n",
      "epoch: 194 loss: 1.5666311979293823 grad: 4.118723968871168\n",
      "epoch: 195 loss: 1.5739920139312744 grad: 4.322756744323922\n",
      "epoch: 196 loss: 1.5651822090148926 grad: 4.940253511979726\n",
      "epoch: 197 loss: 1.5910724401474 grad: 4.478837860007423\n",
      "epoch: 198 loss: 1.5686116218566895 grad: 3.613752455475443\n",
      "epoch: 199 loss: 1.5644069910049438 grad: 4.311931152822963\n",
      "epoch: 200 loss: 1.5655865669250488 grad: 4.195458722342276\n",
      "epoch: 201 loss: 1.5655838251113892 grad: 3.8081588380139753\n",
      "epoch: 202 loss: 1.5778454542160034 grad: 4.326986164392596\n",
      "epoch: 203 loss: 1.5653120279312134 grad: 3.5503081245735117\n",
      "epoch: 204 loss: 1.5810577869415283 grad: 5.759908143713242\n",
      "epoch: 205 loss: 1.5631424188613892 grad: 3.116419470392913\n",
      "epoch: 206 loss: 1.568583607673645 grad: 5.404186919728759\n",
      "epoch: 207 loss: 1.5794137716293335 grad: 3.9764597100867825\n",
      "epoch: 208 loss: 1.5541749000549316 grad: 4.420235821005716\n",
      "epoch: 209 loss: 1.558475136756897 grad: 3.993880106222539\n",
      "epoch: 210 loss: 1.5620477199554443 grad: 5.046244582035998\n",
      "epoch: 211 loss: 1.5595232248306274 grad: 4.201055346605122\n",
      "epoch: 212 loss: 1.5804853439331055 grad: 4.978979016851644\n",
      "epoch: 213 loss: 1.5776283740997314 grad: 5.213326441035554\n",
      "epoch: 214 loss: 1.5656436681747437 grad: 3.8742813285941518\n",
      "epoch: 215 loss: 1.5540212392807007 grad: 3.776942598430418\n",
      "epoch: 216 loss: 1.5659416913986206 grad: 3.7858454969854645\n",
      "epoch: 217 loss: 1.577783465385437 grad: 5.208259111820327\n",
      "epoch: 218 loss: 1.5621871948242188 grad: 3.7241279150992357\n",
      "epoch: 219 loss: 1.55609130859375 grad: 4.449457689398286\n",
      "epoch: 220 loss: 1.5604417324066162 grad: 3.9885858972534565\n",
      "epoch: 221 loss: 1.5777273178100586 grad: 4.495904989531664\n",
      "epoch: 222 loss: 1.5621830224990845 grad: 4.07054679023863\n",
      "epoch: 223 loss: 1.5642918348312378 grad: 4.104837592858133\n",
      "epoch: 224 loss: 1.570369005203247 grad: 5.098573553950053\n",
      "epoch: 225 loss: 1.5667749643325806 grad: 4.110690937266673\n",
      "epoch: 226 loss: 1.5644363164901733 grad: 4.5575481655168435\n",
      "epoch: 227 loss: 1.5510127544403076 grad: 3.3201715866769224\n",
      "epoch: 228 loss: 1.5708948373794556 grad: 5.024302737508864\n",
      "epoch: 229 loss: 1.5672252178192139 grad: 4.424067468593678\n",
      "epoch: 230 loss: 1.5643397569656372 grad: 5.170735884400933\n",
      "epoch: 231 loss: 1.561070442199707 grad: 3.6808749938878034\n",
      "epoch: 232 loss: 1.5618205070495605 grad: 3.908665789339876\n",
      "epoch: 233 loss: 1.5596504211425781 grad: 3.288716709087107\n",
      "epoch: 234 loss: 1.5577399730682373 grad: 3.562971523201536\n",
      "epoch: 235 loss: 1.5678550004959106 grad: 4.500402991119685\n",
      "epoch: 236 loss: 1.5818110704421997 grad: 4.686709785073458\n",
      "epoch: 237 loss: 1.5475407838821411 grad: 3.720494010808842\n",
      "epoch: 238 loss: 1.5534943342208862 grad: 3.1472892865316964\n",
      "epoch: 239 loss: 1.572026252746582 grad: 4.461941188817957\n",
      "epoch: 240 loss: 1.5518367290496826 grad: 3.98164864611614\n",
      "epoch: 241 loss: 1.549396276473999 grad: 2.652424804979243\n",
      "epoch: 242 loss: 1.5688591003417969 grad: 4.948769174693835\n",
      "epoch: 243 loss: 1.5956684350967407 grad: 4.150082166626668\n",
      "epoch: 244 loss: 1.5491493940353394 grad: 3.9966714336724074\n",
      "epoch: 245 loss: 1.5517210960388184 grad: 3.770826750995034\n",
      "epoch: 246 loss: 1.557508111000061 grad: 2.996270800153774\n",
      "epoch: 247 loss: 1.5514720678329468 grad: 2.9197127441118225\n",
      "epoch: 248 loss: 1.5545622110366821 grad: 5.052069706847553\n",
      "epoch: 249 loss: 1.5752389430999756 grad: 4.804326060098942\n",
      "epoch: 250 loss: 1.5635557174682617 grad: 3.6708207892476437\n",
      "epoch: 251 loss: 1.5695101022720337 grad: 3.4122562498482973\n",
      "epoch: 252 loss: 1.549778938293457 grad: 3.277274935135407\n",
      "epoch: 253 loss: 1.565014362335205 grad: 4.723601447588588\n",
      "epoch: 254 loss: 1.5603606700897217 grad: 3.9522046268857136\n",
      "epoch: 255 loss: 1.5564343929290771 grad: 2.862990951905612\n",
      "epoch: 256 loss: 1.55804443359375 grad: 3.47583857834127\n",
      "epoch: 257 loss: 1.559202790260315 grad: 3.8061410788384005\n",
      "epoch: 258 loss: 1.5565823316574097 grad: 3.5836085707226397\n",
      "epoch: 259 loss: 1.5563222169876099 grad: 3.8438202012429823\n",
      "epoch: 260 loss: 1.5436365604400635 grad: 2.890523443548945\n",
      "epoch: 261 loss: 1.5696929693222046 grad: 4.1087675767302505\n",
      "epoch: 262 loss: 1.563129186630249 grad: 3.8459719970865947\n",
      "epoch: 263 loss: 1.5661206245422363 grad: 4.5303919153710535\n",
      "epoch: 264 loss: 1.5581979751586914 grad: 4.300731217580635\n",
      "epoch: 265 loss: 1.5607022047042847 grad: 4.43150359115463\n",
      "epoch: 266 loss: 1.554508924484253 grad: 3.8541028675812656\n",
      "epoch: 267 loss: 1.5543664693832397 grad: 4.237282991286942\n",
      "epoch: 268 loss: 1.5627208948135376 grad: 4.619005213372358\n",
      "epoch: 269 loss: 1.556963324546814 grad: 4.5743924082612475\n",
      "epoch: 270 loss: 1.590448260307312 grad: 6.363771803324528\n",
      "epoch: 271 loss: 1.564527153968811 grad: 3.431181469049325\n",
      "epoch: 272 loss: 1.5640273094177246 grad: 4.210432374473915\n",
      "epoch: 273 loss: 1.546033501625061 grad: 3.34875285059954\n",
      "epoch: 274 loss: 1.5506997108459473 grad: 3.166079941477566\n",
      "epoch: 275 loss: 1.5558772087097168 grad: 3.7597455661587005\n",
      "epoch: 276 loss: 1.5573936700820923 grad: 4.403744074481311\n",
      "epoch: 277 loss: 1.5487514734268188 grad: 2.790851933275693\n",
      "epoch: 278 loss: 1.5542716979980469 grad: 2.908782319612203\n",
      "epoch: 279 loss: 1.5620696544647217 grad: 4.1192542722480905\n",
      "epoch: 280 loss: 1.569800615310669 grad: 5.362921607428845\n",
      "epoch: 281 loss: 1.5549023151397705 grad: 3.833679585106262\n",
      "epoch: 282 loss: 1.5557681322097778 grad: 3.6868983878743515\n",
      "epoch: 283 loss: 1.5443817377090454 grad: 3.61944448722388\n",
      "epoch: 284 loss: 1.568992257118225 grad: 4.278679405016765\n",
      "epoch: 285 loss: 1.5499401092529297 grad: 3.7497381580834612\n",
      "epoch: 286 loss: 1.560999870300293 grad: 4.26446586111233\n",
      "epoch: 287 loss: 1.5581891536712646 grad: 4.761345225325932\n",
      "epoch: 288 loss: 1.5465861558914185 grad: 3.6068559210922735\n",
      "epoch: 289 loss: 1.5636953115463257 grad: 3.9016321140130197\n",
      "epoch: 290 loss: 1.5685114860534668 grad: 3.856097120837963\n",
      "epoch: 291 loss: 1.5775070190429688 grad: 4.764981503021805\n",
      "epoch: 292 loss: 1.5456792116165161 grad: 3.301699114469881\n",
      "epoch: 293 loss: 1.5450681447982788 grad: 3.6714354010070895\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 294 loss: 1.544938087463379 grad: 3.9138949916252623\n",
      "epoch: 295 loss: 1.5571324825286865 grad: 3.375080203078334\n",
      "epoch: 296 loss: 1.5463902950286865 grad: 4.499320552440929\n",
      "epoch: 297 loss: 1.5681754350662231 grad: 3.8305184833080266\n",
      "epoch: 298 loss: 1.558345913887024 grad: 4.212170948206195\n",
      "epoch: 299 loss: 1.5720304250717163 grad: 3.6132974017194646\n",
      "epoch: 300 loss: 1.554276943206787 grad: 3.580729430232589\n",
      "epoch: 301 loss: 1.5415552854537964 grad: 4.729803818760076\n",
      "epoch: 302 loss: 1.5576236248016357 grad: 4.511375241316501\n",
      "epoch: 303 loss: 1.5662328004837036 grad: 4.428020105189145\n",
      "epoch: 304 loss: 1.5590771436691284 grad: 3.5868654032015623\n",
      "epoch: 305 loss: 1.5523165464401245 grad: 4.009724660486727\n",
      "epoch: 306 loss: 1.547736644744873 grad: 4.539993631262965\n",
      "epoch: 307 loss: 1.56369149684906 grad: 5.913765002611446\n",
      "epoch: 308 loss: 1.564356803894043 grad: 3.9754048823923256\n",
      "epoch: 309 loss: 1.5451024770736694 grad: 3.738693528615697\n",
      "epoch: 310 loss: 1.5539048910140991 grad: 3.2170104540435225\n",
      "epoch: 311 loss: 1.5398427248001099 grad: 3.2655429351703043\n",
      "epoch: 312 loss: 1.5638929605484009 grad: 4.06126121940528\n",
      "epoch: 313 loss: 1.5592931509017944 grad: 5.180408850109148\n",
      "epoch: 314 loss: 1.548915147781372 grad: 3.110445704938569\n",
      "epoch: 315 loss: 1.5475362539291382 grad: 4.191971792698096\n",
      "epoch: 316 loss: 1.5412360429763794 grad: 2.428401537587007\n",
      "epoch: 317 loss: 1.5362399816513062 grad: 2.9124186290049643\n",
      "epoch: 318 loss: 1.55586838722229 grad: 3.382994088923583\n",
      "epoch: 319 loss: 1.5506104230880737 grad: 4.000458565470564\n",
      "epoch: 320 loss: 1.5490100383758545 grad: 4.373911972832861\n",
      "epoch: 321 loss: 1.5569970607757568 grad: 4.628730888483574\n",
      "epoch: 322 loss: 1.569093108177185 grad: 4.943540177627954\n",
      "epoch: 323 loss: 1.5479974746704102 grad: 3.5603017004057738\n",
      "epoch: 324 loss: 1.548003077507019 grad: 3.9134667763401287\n",
      "epoch: 325 loss: 1.5639959573745728 grad: 3.9329327773368123\n",
      "epoch: 326 loss: 1.5538203716278076 grad: 3.423787447159855\n",
      "epoch: 327 loss: 1.5553005933761597 grad: 4.077237685009557\n",
      "epoch: 328 loss: 1.5493475198745728 grad: 2.7567362387439225\n",
      "epoch: 329 loss: 1.5678298473358154 grad: 4.289680251797956\n",
      "epoch: 330 loss: 1.5530226230621338 grad: 3.1072421018152463\n",
      "epoch: 331 loss: 1.53764009475708 grad: 2.409666454729207\n",
      "epoch: 332 loss: 1.5408861637115479 grad: 4.011385068394478\n",
      "epoch: 333 loss: 1.550392746925354 grad: 3.8108987350306123\n",
      "epoch: 334 loss: 1.5530951023101807 grad: 3.995043689764766\n",
      "epoch: 335 loss: 1.5569201707839966 grad: 3.714580680554618\n",
      "epoch: 336 loss: 1.5447365045547485 grad: 3.1578276354073953\n",
      "epoch: 337 loss: 1.5488762855529785 grad: 3.331511702250033\n",
      "epoch: 338 loss: 1.5519139766693115 grad: 3.543354003924276\n",
      "epoch: 339 loss: 1.5702451467514038 grad: 3.8805977592777463\n",
      "epoch: 340 loss: 1.5629637241363525 grad: 3.24525387370247\n",
      "epoch: 341 loss: 1.5483607053756714 grad: 4.082315401034503\n",
      "epoch: 342 loss: 1.5533300638198853 grad: 3.989342951548772\n",
      "epoch: 343 loss: 1.541774868965149 grad: 2.9300562206864207\n",
      "epoch: 344 loss: 1.5485297441482544 grad: 3.1761147264014595\n",
      "epoch: 345 loss: 1.5521965026855469 grad: 3.874680175023258\n",
      "epoch: 346 loss: 1.5463875532150269 grad: 3.258673818449278\n",
      "epoch: 347 loss: 1.5426844358444214 grad: 3.7024242927718936\n",
      "epoch: 348 loss: 1.5394282341003418 grad: 2.8576249607216306\n",
      "epoch: 349 loss: 1.5376801490783691 grad: 3.6851164319962244\n",
      "epoch: 350 loss: 1.5520325899124146 grad: 4.023743386640663\n",
      "epoch: 351 loss: 1.550785779953003 grad: 3.9025518309729703\n",
      "epoch: 352 loss: 1.549497365951538 grad: 3.6530183395595937\n",
      "epoch: 353 loss: 1.5599251985549927 grad: 3.721270276880465\n",
      "epoch: 354 loss: 1.5503510236740112 grad: 5.592768263061416\n",
      "epoch: 355 loss: 1.5522894859313965 grad: 3.794349558845031\n",
      "epoch: 356 loss: 1.54442298412323 grad: 3.648163922152787\n",
      "epoch: 357 loss: 1.540238618850708 grad: 3.351968631932967\n",
      "epoch: 358 loss: 1.555648922920227 grad: 3.094967628954035\n",
      "epoch: 359 loss: 1.5468660593032837 grad: 3.0018600712126533\n",
      "epoch: 360 loss: 1.5431158542633057 grad: 3.0339037597667406\n",
      "epoch: 361 loss: 1.5348275899887085 grad: 3.2741427925150908\n",
      "epoch: 362 loss: 1.5398844480514526 grad: 2.2550305591132602\n",
      "epoch: 363 loss: 1.546661138534546 grad: 2.2566815153290616\n",
      "epoch: 364 loss: 1.5403010845184326 grad: 2.7416547344966373\n",
      "epoch: 365 loss: 1.547721028327942 grad: 3.613814014759401\n",
      "epoch: 366 loss: 1.579126238822937 grad: 4.797261249128694\n",
      "epoch: 367 loss: 1.5483860969543457 grad: 2.656916112370708\n",
      "epoch: 368 loss: 1.5412558317184448 grad: 3.953042488258444\n",
      "epoch: 369 loss: 1.5402007102966309 grad: 3.3542324998674133\n",
      "epoch: 370 loss: 1.5551910400390625 grad: 4.2025543493412885\n",
      "epoch: 371 loss: 1.5516737699508667 grad: 3.72511866767435\n",
      "epoch: 372 loss: 1.5421438217163086 grad: 3.1706064787086925\n",
      "epoch: 373 loss: 1.5417557954788208 grad: 3.941364433978967\n",
      "epoch: 374 loss: 1.5688689947128296 grad: 3.992554698271354\n",
      "epoch: 375 loss: 1.5526667833328247 grad: 3.203644754146712\n",
      "epoch: 376 loss: 1.5386093854904175 grad: 2.269690954022613\n",
      "epoch: 377 loss: 1.5566339492797852 grad: 4.1193267069290105\n",
      "epoch: 378 loss: 1.5343679189682007 grad: 2.576856652053454\n",
      "epoch: 379 loss: 1.5481650829315186 grad: 3.6288860156519807\n",
      "epoch: 380 loss: 1.5689703226089478 grad: 4.003694695142349\n",
      "epoch: 381 loss: 1.563996434211731 grad: 3.5391417999911954\n",
      "epoch: 382 loss: 1.5558871030807495 grad: 3.9609830862296547\n",
      "epoch: 383 loss: 1.5706392526626587 grad: 4.60858017213308\n",
      "epoch: 384 loss: 1.5456572771072388 grad: 3.38429620050024\n",
      "epoch: 385 loss: 1.5509668588638306 grad: 3.4830848095007627\n",
      "epoch: 386 loss: 1.5430066585540771 grad: 2.7646760732287534\n",
      "epoch: 387 loss: 1.5377556085586548 grad: 3.140134309818128\n",
      "epoch: 388 loss: 1.5307146310806274 grad: 2.293258856621374\n",
      "epoch: 389 loss: 1.5383315086364746 grad: 3.4599922836169927\n",
      "epoch: 390 loss: 1.5418663024902344 grad: 2.1204800947427525\n",
      "epoch: 391 loss: 1.5430220365524292 grad: 3.5612103377751487\n",
      "epoch: 392 loss: 1.5467013120651245 grad: 3.1408544706784918\n",
      "epoch: 393 loss: 1.550918459892273 grad: 2.200144871976559\n",
      "epoch: 394 loss: 1.5345274209976196 grad: 2.0982851547392722\n",
      "epoch: 395 loss: 1.5358120203018188 grad: 2.955118849956394\n",
      "epoch: 396 loss: 1.5603575706481934 grad: 3.7800492234309866\n",
      "epoch: 397 loss: 1.5530003309249878 grad: 5.224192561666715\n",
      "epoch: 398 loss: 1.533747911453247 grad: 2.6509597449951476\n",
      "epoch: 399 loss: 1.5429409742355347 grad: 2.3355045222662785\n",
      "epoch: 400 loss: 1.545078992843628 grad: 3.5396426284251126\n",
      "epoch: 401 loss: 1.5567727088928223 grad: 3.9244774607438693\n",
      "epoch: 402 loss: 1.5383012294769287 grad: 2.8510914075479032\n",
      "epoch: 403 loss: 1.5534542798995972 grad: 4.312426735469335\n",
      "epoch: 404 loss: 1.5392316579818726 grad: 3.400278353908576\n",
      "epoch: 405 loss: 1.5489038228988647 grad: 2.891190642110773\n",
      "epoch: 406 loss: 1.5515105724334717 grad: 3.732885458313616\n",
      "epoch: 407 loss: 1.5618668794631958 grad: 4.114756512558377\n",
      "epoch: 408 loss: 1.541770339012146 grad: 3.1449665840943033\n",
      "epoch: 409 loss: 1.5489176511764526 grad: 4.3145708812528785\n",
      "epoch: 410 loss: 1.551446557044983 grad: 3.859451967314211\n",
      "epoch: 411 loss: 1.548701286315918 grad: 2.9386083287756763\n",
      "epoch: 412 loss: 1.5398800373077393 grad: 3.6934141947498906\n",
      "epoch: 413 loss: 1.5453649759292603 grad: 3.5372149801077657\n",
      "epoch: 414 loss: 1.5502738952636719 grad: 2.4013119436412453\n",
      "epoch: 415 loss: 1.5606166124343872 grad: 4.235506393220069\n",
      "epoch: 416 loss: 1.5599421262741089 grad: 3.016081817490115\n",
      "epoch: 417 loss: 1.5450347661972046 grad: 2.4071806152164434\n",
      "epoch: 418 loss: 1.5393133163452148 grad: 3.6793914749796808\n",
      "epoch: 419 loss: 1.539116382598877 grad: 2.562273783789813\n",
      "epoch: 420 loss: 1.5455453395843506 grad: 3.170925722371087\n",
      "epoch: 421 loss: 1.5390751361846924 grad: 3.870635758661011\n",
      "epoch: 422 loss: 1.5349414348602295 grad: 3.8496907085038807\n",
      "epoch: 423 loss: 1.5508108139038086 grad: 3.1445660893595138\n",
      "epoch: 424 loss: 1.5316420793533325 grad: 2.749309520394035\n",
      "epoch: 425 loss: 1.5555528402328491 grad: 2.995381585751035\n",
      "epoch: 426 loss: 1.551978349685669 grad: 2.5217929219135264\n",
      "epoch: 427 loss: 1.5331406593322754 grad: 3.4203828083342644\n",
      "epoch: 428 loss: 1.542303442955017 grad: 2.6332475350189455\n",
      "epoch: 429 loss: 1.5334326028823853 grad: 3.0853517086627207\n",
      "epoch: 430 loss: 1.5412061214447021 grad: 4.256923677817776\n",
      "epoch: 431 loss: 1.5374513864517212 grad: 2.1681637272160237\n",
      "epoch: 432 loss: 1.5390598773956299 grad: 4.033848006987332\n",
      "epoch: 433 loss: 1.5492721796035767 grad: 3.2182111256776165\n",
      "epoch: 434 loss: 1.5441420078277588 grad: 2.0143254773921098\n",
      "epoch: 435 loss: 1.5536339282989502 grad: 3.748697949057405\n",
      "epoch: 436 loss: 1.5415040254592896 grad: 3.3026753338087405\n",
      "epoch: 437 loss: 1.5547488927841187 grad: 2.0809187191785585\n",
      "epoch: 438 loss: 1.5403428077697754 grad: 4.270383497442041\n",
      "epoch: 439 loss: 1.5903321504592896 grad: 3.9044313882686708\n",
      "epoch: 440 loss: 1.5469632148742676 grad: 2.252521431116911\n",
      "epoch: 441 loss: 1.5508480072021484 grad: 2.5920748702375778\n",
      "epoch: 442 loss: 1.563775897026062 grad: 4.658051105811153\n",
      "epoch: 443 loss: 1.5530893802642822 grad: 3.040524782170354\n",
      "epoch: 444 loss: 1.5420703887939453 grad: 2.6330622916825153\n",
      "epoch: 445 loss: 1.5557470321655273 grad: 3.6157970105187345\n",
      "epoch: 446 loss: 1.5548416376113892 grad: 4.43238281536471\n",
      "epoch: 447 loss: 1.5409752130508423 grad: 3.307061769894298\n",
      "epoch: 448 loss: 1.5304570198059082 grad: 2.2121416621651706\n",
      "epoch: 449 loss: 1.5258679389953613 grad: 3.006008881166751\n",
      "epoch: 450 loss: 1.5323638916015625 grad: 3.922014787508466\n",
      "epoch: 451 loss: 1.5327621698379517 grad: 3.723642253554881\n",
      "epoch: 452 loss: 1.5248876810073853 grad: 2.083848905183393\n",
      "epoch: 453 loss: 1.5296305418014526 grad: 3.205564326604051\n",
      "epoch: 454 loss: 1.5525764226913452 grad: 2.4534403826771705\n",
      "epoch: 455 loss: 1.5364737510681152 grad: 3.3149136769774628\n",
      "epoch: 456 loss: 1.5488477945327759 grad: 5.263217453378847\n",
      "epoch: 457 loss: 1.527549386024475 grad: 2.350947167800107\n",
      "epoch: 458 loss: 1.5262805223464966 grad: 3.362286562896484\n",
      "epoch: 459 loss: 1.5551187992095947 grad: 4.449149533127806\n",
      "epoch: 460 loss: 1.5420693159103394 grad: 2.5068425294895005\n",
      "epoch: 461 loss: 1.5424326658248901 grad: 3.1489016363702276\n",
      "epoch: 462 loss: 1.55035400390625 grad: 3.9166936601313727\n",
      "epoch: 463 loss: 1.532064437866211 grad: 2.5377732857817916\n",
      "epoch: 464 loss: 1.5294169187545776 grad: 2.5868425347098865\n",
      "epoch: 465 loss: 1.5448986291885376 grad: 3.325566470679466\n",
      "epoch: 466 loss: 1.5484411716461182 grad: 4.5541206345684655\n",
      "epoch: 467 loss: 1.534754753112793 grad: 3.2513017107480753\n",
      "epoch: 468 loss: 1.530501365661621 grad: 2.7768577617690307\n",
      "epoch: 469 loss: 1.5229365825653076 grad: 2.1631051300291753\n",
      "epoch: 470 loss: 1.5434699058532715 grad: 4.079092054939501\n",
      "epoch: 471 loss: 1.544830083847046 grad: 3.081093992722782\n",
      "epoch: 472 loss: 1.5288596153259277 grad: 3.010314513651818\n",
      "epoch: 473 loss: 1.5247535705566406 grad: 2.693716510678849\n",
      "epoch: 474 loss: 1.5468318462371826 grad: 2.6196491270191524\n",
      "epoch: 475 loss: 1.5448452234268188 grad: 3.9930506542032367\n",
      "epoch: 476 loss: 1.5520272254943848 grad: 3.6790758700864163\n",
      "epoch: 477 loss: 1.5305854082107544 grad: 3.1422116856440727\n",
      "epoch: 478 loss: 1.5337834358215332 grad: 3.288005568834057\n",
      "epoch: 479 loss: 1.5266609191894531 grad: 2.532007909989534\n",
      "epoch: 480 loss: 1.529317855834961 grad: 2.8977589570755335\n",
      "epoch: 481 loss: 1.54574453830719 grad: 2.5111561796658393\n",
      "epoch: 482 loss: 1.5288033485412598 grad: 2.300882341404341\n",
      "epoch: 483 loss: 1.5352303981781006 grad: 3.033574601818251\n",
      "epoch: 484 loss: 1.5276939868927002 grad: 3.417105626080445\n",
      "epoch: 485 loss: 1.550557017326355 grad: 4.480795859577547\n",
      "epoch: 486 loss: 1.5337436199188232 grad: 2.3363692554617153\n",
      "epoch: 487 loss: 1.5273219347000122 grad: 3.6011896697869012\n",
      "epoch: 488 loss: 1.5716756582260132 grad: 3.7060048127040837\n",
      "epoch: 489 loss: 1.551613211631775 grad: 3.026158022325968\n",
      "epoch: 490 loss: 1.5484851598739624 grad: 4.637575619172489\n",
      "epoch: 491 loss: 1.540635347366333 grad: 3.380986414443939\n",
      "epoch: 492 loss: 1.5344592332839966 grad: 3.426700302564402\n",
      "epoch: 493 loss: 1.5366162061691284 grad: 3.1810748476342448\n",
      "epoch: 494 loss: 1.5365639925003052 grad: 2.6812159731448193\n",
      "epoch: 495 loss: 1.5349266529083252 grad: 3.374714636399854\n",
      "epoch: 496 loss: 1.5179204940795898 grad: 1.8674959757803102\n",
      "epoch: 497 loss: 1.529566764831543 grad: 2.5138052252806253\n",
      "epoch: 498 loss: 1.5337194204330444 grad: 3.559958368029043\n",
      "epoch: 499 loss: 1.5331312417984009 grad: 1.8620407369535115\n",
      "1.9369078949093819\n",
      "epoch: 0 loss: 2.3030405044555664 grad: 1.416422182217329\n",
      "epoch: 1 loss: 2.303055763244629 grad: 1.4175442002144538\n",
      "epoch: 2 loss: 2.3034181594848633 grad: 1.4142434240895367\n",
      "epoch: 3 loss: 2.303382396697998 grad: 1.4184571384888378\n",
      "epoch: 4 loss: 2.302945375442505 grad: 1.4196440617457802\n",
      "epoch: 5 loss: 2.3027992248535156 grad: 1.435081053090962\n",
      "epoch: 6 loss: 2.302762031555176 grad: 1.4381480675526999\n",
      "epoch: 7 loss: 2.303093433380127 grad: 1.4167194666584866\n",
      "epoch: 8 loss: 2.3025622367858887 grad: 1.42484420006873\n",
      "epoch: 9 loss: 2.3028430938720703 grad: 1.4260600588639223\n",
      "epoch: 10 loss: 2.3025877475738525 grad: 1.4305227808451044\n",
      "epoch: 11 loss: 2.302969217300415 grad: 1.4198315707035363\n",
      "epoch: 12 loss: 2.3028430938720703 grad: 1.4365784014087348\n",
      "epoch: 13 loss: 2.3024117946624756 grad: 1.4336703144150624\n",
      "epoch: 14 loss: 2.3033199310302734 grad: 1.4185282706637823\n",
      "epoch: 15 loss: 2.303379774093628 grad: 1.4150286064028652\n",
      "epoch: 16 loss: 2.302572250366211 grad: 1.427232000950931\n",
      "epoch: 17 loss: 2.303260326385498 grad: 1.4114201332457246\n",
      "epoch: 18 loss: 2.3030779361724854 grad: 1.415012718954434\n",
      "epoch: 19 loss: 2.302316904067993 grad: 1.4217629414994182\n",
      "epoch: 20 loss: 2.302548885345459 grad: 1.428069447363091\n",
      "epoch: 21 loss: 2.302495241165161 grad: 1.4151017075397134\n",
      "epoch: 22 loss: 2.302940845489502 grad: 1.417702366616429\n",
      "epoch: 23 loss: 2.3030803203582764 grad: 1.4208390132065802\n",
      "epoch: 24 loss: 2.3023464679718018 grad: 1.4307087928441071\n",
      "epoch: 25 loss: 2.302471399307251 grad: 1.4337001030799001\n",
      "epoch: 26 loss: 2.3033478260040283 grad: 1.412755735312766\n",
      "epoch: 27 loss: 2.3026862144470215 grad: 1.4136235146757423\n",
      "epoch: 28 loss: 2.3028531074523926 grad: 1.4237021982396347\n",
      "epoch: 29 loss: 2.302813768386841 grad: 1.436427987021734\n",
      "epoch: 30 loss: 2.3027305603027344 grad: 1.430945570488268\n",
      "epoch: 31 loss: 2.3027682304382324 grad: 1.4220526216862102\n",
      "epoch: 32 loss: 2.302394151687622 grad: 1.41404596624142\n",
      "epoch: 33 loss: 2.302488327026367 grad: 1.4335131626576185\n",
      "epoch: 34 loss: 2.3030002117156982 grad: 1.4159616889886646\n",
      "epoch: 35 loss: 2.3028104305267334 grad: 1.4307679495670729\n",
      "epoch: 36 loss: 2.3028571605682373 grad: 1.4218128325051762\n",
      "epoch: 37 loss: 2.302358865737915 grad: 1.426594104606747\n",
      "epoch: 38 loss: 2.3023712635040283 grad: 1.4375980432987923\n",
      "epoch: 39 loss: 2.3023688793182373 grad: 1.4280241779975653\n",
      "epoch: 40 loss: 2.3023056983947754 grad: 1.41947063363512\n",
      "epoch: 41 loss: 2.302596092224121 grad: 1.426600664325561\n",
      "epoch: 42 loss: 2.302938461303711 grad: 1.4224876513342477\n",
      "epoch: 43 loss: 2.3025195598602295 grad: 1.4307912594679417\n",
      "epoch: 44 loss: 2.3024380207061768 grad: 1.4272874092816241\n",
      "epoch: 45 loss: 2.3023569583892822 grad: 1.4220700968437576\n",
      "epoch: 46 loss: 2.3030648231506348 grad: 1.4262515902279005\n",
      "epoch: 47 loss: 2.3033859729766846 grad: 1.4205854421607145\n",
      "epoch: 48 loss: 2.30263352394104 grad: 1.4209551316028135\n",
      "epoch: 49 loss: 2.303086519241333 grad: 1.4136348841175999\n",
      "epoch: 50 loss: 2.302626371383667 grad: 1.427281687501818\n",
      "epoch: 51 loss: 2.3027350902557373 grad: 1.4279324991428959\n",
      "epoch: 52 loss: 2.303313970565796 grad: 1.4154695931448793\n",
      "epoch: 53 loss: 2.3024327754974365 grad: 1.4338968244218637\n",
      "epoch: 54 loss: 2.303041934967041 grad: 1.4128777268749204\n",
      "epoch: 55 loss: 2.3020246028900146 grad: 1.4349949261365784\n",
      "epoch: 56 loss: 2.3026676177978516 grad: 1.4196976262407142\n",
      "epoch: 57 loss: 2.3025922775268555 grad: 1.4296627836708453\n",
      "epoch: 58 loss: 2.302642822265625 grad: 1.4219511446010853\n",
      "epoch: 59 loss: 2.3031930923461914 grad: 1.4218099495536456\n",
      "epoch: 60 loss: 2.302497625350952 grad: 1.426174364130323\n",
      "epoch: 61 loss: 2.3026986122131348 grad: 1.4285806754256585\n",
      "epoch: 62 loss: 2.3035831451416016 grad: 1.4238286688018382\n",
      "epoch: 63 loss: 2.302579402923584 grad: 1.4340704457875015\n",
      "epoch: 64 loss: 2.3026540279388428 grad: 1.4369428154665032\n",
      "epoch: 65 loss: 2.3029844760894775 grad: 1.4217990052716305\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 66 loss: 2.3026535511016846 grad: 1.4208241611985224\n",
      "epoch: 67 loss: 2.3027615547180176 grad: 1.4275777012290847\n",
      "epoch: 68 loss: 2.302501916885376 grad: 1.4327400316898193\n",
      "epoch: 69 loss: 2.302964448928833 grad: 1.411061061004783\n",
      "epoch: 70 loss: 2.302584171295166 grad: 1.4338766698880743\n",
      "epoch: 71 loss: 2.30283784866333 grad: 1.4194551008376515\n",
      "epoch: 72 loss: 2.3026368618011475 grad: 1.4275844011137941\n",
      "epoch: 73 loss: 2.3024706840515137 grad: 1.4303543819539575\n",
      "epoch: 74 loss: 2.3031466007232666 grad: 1.4212833064079786\n",
      "epoch: 75 loss: 2.3027546405792236 grad: 1.429830602431182\n",
      "epoch: 76 loss: 2.30263090133667 grad: 1.4188230185702975\n",
      "epoch: 77 loss: 2.3019168376922607 grad: 1.4347717172894923\n",
      "epoch: 78 loss: 2.3024730682373047 grad: 1.4287610306803669\n",
      "epoch: 79 loss: 2.302314043045044 grad: 1.4431314767220071\n",
      "epoch: 80 loss: 2.3028156757354736 grad: 1.424033685661261\n",
      "epoch: 81 loss: 2.30293345451355 grad: 1.4222149206288455\n",
      "epoch: 82 loss: 2.3031668663024902 grad: 1.425871755164634\n",
      "epoch: 83 loss: 2.3025436401367188 grad: 1.4370824264081579\n",
      "epoch: 84 loss: 2.3022336959838867 grad: 1.4361176892619816\n",
      "epoch: 85 loss: 2.302180767059326 grad: 1.4274322239881647\n",
      "epoch: 86 loss: 2.302706003189087 grad: 1.4194327831020697\n",
      "epoch: 87 loss: 2.301976203918457 grad: 1.439986100392638\n",
      "epoch: 88 loss: 2.3026504516601562 grad: 1.4386913676539228\n",
      "epoch: 89 loss: 2.3023316860198975 grad: 1.440350784423081\n",
      "epoch: 90 loss: 2.302109956741333 grad: 1.4539475921829719\n",
      "epoch: 91 loss: 2.3019907474517822 grad: 1.4314101544940578\n",
      "epoch: 92 loss: 2.3020999431610107 grad: 1.4465839270177105\n",
      "epoch: 93 loss: 2.3027853965759277 grad: 1.424159763406755\n",
      "epoch: 94 loss: 2.3023295402526855 grad: 1.4378650646531097\n",
      "epoch: 95 loss: 2.3023741245269775 grad: 1.4326393455156081\n",
      "epoch: 96 loss: 2.302156925201416 grad: 1.4437085961265164\n",
      "epoch: 97 loss: 2.3021743297576904 grad: 1.4446982180344916\n",
      "epoch: 98 loss: 2.301957845687866 grad: 1.4419993467274166\n",
      "epoch: 99 loss: 2.302504539489746 grad: 1.4386790713409907\n",
      "epoch: 100 loss: 2.3023924827575684 grad: 1.4374250169152334\n",
      "epoch: 101 loss: 2.3021678924560547 grad: 1.4492462068936596\n",
      "epoch: 102 loss: 2.302727460861206 grad: 1.4278390001623877\n",
      "epoch: 103 loss: 2.3025128841400146 grad: 1.4499792421702296\n",
      "epoch: 104 loss: 2.3027966022491455 grad: 1.4443079712652853\n",
      "epoch: 105 loss: 2.302177667617798 grad: 1.4504195179269161\n",
      "epoch: 106 loss: 2.3021702766418457 grad: 1.4495989570915255\n",
      "epoch: 107 loss: 2.302034616470337 grad: 1.4530540217889385\n",
      "epoch: 108 loss: 2.302091121673584 grad: 1.4576054212363763\n",
      "epoch: 109 loss: 2.3024237155914307 grad: 1.4498261794529206\n",
      "epoch: 110 loss: 2.302366256713867 grad: 1.4468330104986855\n",
      "epoch: 111 loss: 2.3023180961608887 grad: 1.4421901388263831\n",
      "epoch: 112 loss: 2.302039384841919 grad: 1.4608407492623738\n",
      "epoch: 113 loss: 2.3022899627685547 grad: 1.4575809908250996\n",
      "epoch: 114 loss: 2.3020694255828857 grad: 1.4671399458662593\n",
      "epoch: 115 loss: 2.3022289276123047 grad: 1.4576691138033298\n",
      "epoch: 116 loss: 2.3025450706481934 grad: 1.4475111627807131\n",
      "epoch: 117 loss: 2.302509307861328 grad: 1.4436931931783283\n",
      "epoch: 118 loss: 2.3019535541534424 grad: 1.45570613732118\n",
      "epoch: 119 loss: 2.302450180053711 grad: 1.4574755043981389\n",
      "epoch: 120 loss: 2.3025002479553223 grad: 1.4556862732805755\n",
      "epoch: 121 loss: 2.3015694618225098 grad: 1.4763934827919694\n",
      "epoch: 122 loss: 2.3015964031219482 grad: 1.4808568855071262\n",
      "epoch: 123 loss: 2.301867961883545 grad: 1.4593224933090072\n",
      "epoch: 124 loss: 2.3022360801696777 grad: 1.4682518983378061\n",
      "epoch: 125 loss: 2.302441120147705 grad: 1.4742738218416298\n",
      "epoch: 126 loss: 2.30233097076416 grad: 1.4616089738934996\n",
      "epoch: 127 loss: 2.3024392127990723 grad: 1.4568171427429963\n",
      "epoch: 128 loss: 2.302280902862549 grad: 1.4631925830469719\n",
      "epoch: 129 loss: 2.3022348880767822 grad: 1.4631198777795016\n",
      "epoch: 130 loss: 2.301814556121826 grad: 1.4758363955853773\n",
      "epoch: 131 loss: 2.3020970821380615 grad: 1.4661224465632428\n",
      "epoch: 132 loss: 2.3021605014801025 grad: 1.4705005782889202\n",
      "epoch: 133 loss: 2.3016719818115234 grad: 1.4861522290914777\n",
      "epoch: 134 loss: 2.3019261360168457 grad: 1.4686067193443517\n",
      "epoch: 135 loss: 2.302116870880127 grad: 1.4832524112961625\n",
      "epoch: 136 loss: 2.3018925189971924 grad: 1.4763465255964547\n",
      "epoch: 137 loss: 2.3019261360168457 grad: 1.4616350098272846\n",
      "epoch: 138 loss: 2.302189350128174 grad: 1.4672081207095216\n",
      "epoch: 139 loss: 2.3022074699401855 grad: 1.4696502123704358\n",
      "epoch: 140 loss: 2.301860809326172 grad: 1.472477680024144\n",
      "epoch: 141 loss: 2.3027422428131104 grad: 1.457235359631124\n",
      "epoch: 142 loss: 2.3018808364868164 grad: 1.4836497707458745\n",
      "epoch: 143 loss: 2.3019440174102783 grad: 1.4846392423357992\n",
      "epoch: 144 loss: 2.302079916000366 grad: 1.4825740454973475\n",
      "epoch: 145 loss: 2.3018157482147217 grad: 1.4863637261469627\n",
      "epoch: 146 loss: 2.302058696746826 grad: 1.487018290593008\n",
      "epoch: 147 loss: 2.302473783493042 grad: 1.4768558086546522\n",
      "epoch: 148 loss: 2.3018252849578857 grad: 1.49014414100176\n",
      "epoch: 149 loss: 2.302293300628662 grad: 1.4897838626925404\n",
      "epoch: 150 loss: 2.3015313148498535 grad: 1.4930349899112203\n",
      "epoch: 151 loss: 2.302262544631958 grad: 1.509361219008468\n",
      "epoch: 152 loss: 2.3014211654663086 grad: 1.5070167867585071\n",
      "epoch: 153 loss: 2.3018741607666016 grad: 1.4843785463396224\n",
      "epoch: 154 loss: 2.301851511001587 grad: 1.5172023512755655\n",
      "epoch: 155 loss: 2.3018321990966797 grad: 1.5069266633474312\n",
      "epoch: 156 loss: 2.302386522293091 grad: 1.4950973868835717\n",
      "epoch: 157 loss: 2.301737070083618 grad: 1.504857423840948\n",
      "epoch: 158 loss: 2.301952362060547 grad: 1.4969736715771318\n",
      "epoch: 159 loss: 2.3011229038238525 grad: 1.5271625324847207\n",
      "epoch: 160 loss: 2.3009896278381348 grad: 1.5238812144860507\n",
      "epoch: 161 loss: 2.3018980026245117 grad: 1.5209888168795418\n",
      "epoch: 162 loss: 2.3017940521240234 grad: 1.5069930663919964\n",
      "epoch: 163 loss: 2.301934242248535 grad: 1.5068318185780847\n",
      "epoch: 164 loss: 2.3017983436584473 grad: 1.5125085893050132\n",
      "epoch: 165 loss: 2.3021810054779053 grad: 1.5164589141680311\n",
      "epoch: 166 loss: 2.301440954208374 grad: 1.533791832840218\n",
      "epoch: 167 loss: 2.3015248775482178 grad: 1.5402136612240047\n",
      "epoch: 168 loss: 2.3013439178466797 grad: 1.5215471748092642\n",
      "epoch: 169 loss: 2.30143141746521 grad: 1.5423048454288777\n",
      "epoch: 170 loss: 2.3014166355133057 grad: 1.5489916300090651\n",
      "epoch: 171 loss: 2.300647020339966 grad: 1.5331043669795026\n",
      "epoch: 172 loss: 2.3017220497131348 grad: 1.5316461499758243\n",
      "epoch: 173 loss: 2.301570415496826 grad: 1.539713209513427\n",
      "epoch: 174 loss: 2.3007171154022217 grad: 1.5513538049999624\n",
      "epoch: 175 loss: 2.300872564315796 grad: 1.5709478229095803\n",
      "epoch: 176 loss: 2.3004190921783447 grad: 1.5797523126165043\n",
      "epoch: 177 loss: 2.300992012023926 grad: 1.5763933408805835\n",
      "epoch: 178 loss: 2.300818681716919 grad: 1.5754243340638896\n",
      "epoch: 179 loss: 2.3005025386810303 grad: 1.5943780812372024\n",
      "epoch: 180 loss: 2.3001859188079834 grad: 1.6031184513399022\n",
      "epoch: 181 loss: 2.3015687465667725 grad: 1.5727668702639344\n",
      "epoch: 182 loss: 2.301370143890381 grad: 1.5757532174004212\n",
      "epoch: 183 loss: 2.3014588356018066 grad: 1.586083591098912\n",
      "epoch: 184 loss: 2.301337480545044 grad: 1.589719248602965\n",
      "epoch: 185 loss: 2.30021071434021 grad: 1.6008929774786036\n",
      "epoch: 186 loss: 2.3004634380340576 grad: 1.6066693755786954\n",
      "epoch: 187 loss: 2.3012592792510986 grad: 1.5975955410745912\n",
      "epoch: 188 loss: 2.3012654781341553 grad: 1.5883355317803631\n",
      "epoch: 189 loss: 2.3003554344177246 grad: 1.623152409635839\n",
      "epoch: 190 loss: 2.300405979156494 grad: 1.6079720332885958\n",
      "epoch: 191 loss: 2.301046133041382 grad: 1.643554449617301\n",
      "epoch: 192 loss: 2.3001418113708496 grad: 1.6646975874401895\n",
      "epoch: 193 loss: 2.3001186847686768 grad: 1.6472844324436866\n",
      "epoch: 194 loss: 2.299293279647827 grad: 1.6825501213020215\n",
      "epoch: 195 loss: 2.3000922203063965 grad: 1.6839121340105074\n",
      "epoch: 196 loss: 2.2995073795318604 grad: 1.6974545172711333\n",
      "epoch: 197 loss: 2.300351619720459 grad: 1.6628994582339176\n",
      "epoch: 198 loss: 2.29935884475708 grad: 1.7090983762838212\n",
      "epoch: 199 loss: 2.299743413925171 grad: 1.7049735699325712\n",
      "epoch: 200 loss: 2.2992122173309326 grad: 1.746339377714321\n",
      "epoch: 201 loss: 2.2990567684173584 grad: 1.7520621806726835\n",
      "epoch: 202 loss: 2.29923677444458 grad: 1.7392788490406164\n",
      "epoch: 203 loss: 2.2992782592773438 grad: 1.7368783272529347\n",
      "epoch: 204 loss: 2.299055814743042 grad: 1.7722077573047181\n",
      "epoch: 205 loss: 2.299556016921997 grad: 1.7790486567084574\n",
      "epoch: 206 loss: 2.298020601272583 grad: 1.8058927456316138\n",
      "epoch: 207 loss: 2.2974958419799805 grad: 1.8580959369834986\n",
      "epoch: 208 loss: 2.2988712787628174 grad: 1.8343974484411616\n",
      "epoch: 209 loss: 2.2966558933258057 grad: 1.8962634277496753\n",
      "epoch: 210 loss: 2.2964117527008057 grad: 1.9343943277573479\n",
      "epoch: 211 loss: 2.2966954708099365 grad: 1.9305463303176185\n",
      "epoch: 212 loss: 2.296908378601074 grad: 1.935781583932805\n",
      "epoch: 213 loss: 2.2973697185516357 grad: 1.9650859398553\n",
      "epoch: 214 loss: 2.296267509460449 grad: 2.004457088896916\n",
      "epoch: 215 loss: 2.2954819202423096 grad: 2.0397710570038132\n",
      "epoch: 216 loss: 2.2958343029022217 grad: 2.0285021029708403\n",
      "epoch: 217 loss: 2.2941677570343018 grad: 2.0833575946596703\n",
      "epoch: 218 loss: 2.2944858074188232 grad: 2.123721639906603\n",
      "epoch: 219 loss: 2.293119430541992 grad: 2.1811490682811137\n",
      "epoch: 220 loss: 2.2940292358398438 grad: 2.1631670478853353\n",
      "epoch: 221 loss: 2.2926981449127197 grad: 2.2159707828827706\n",
      "epoch: 222 loss: 2.29177188873291 grad: 2.257753837142243\n",
      "epoch: 223 loss: 2.2891323566436768 grad: 2.3300339227305753\n",
      "epoch: 224 loss: 2.291745662689209 grad: 2.2872253781783263\n",
      "epoch: 225 loss: 2.2888734340667725 grad: 2.3779559262459062\n",
      "epoch: 226 loss: 2.286996364593506 grad: 2.369264311493478\n",
      "epoch: 227 loss: 2.285928964614868 grad: 2.3970595278041733\n",
      "epoch: 228 loss: 2.286806344985962 grad: 2.402472391048269\n",
      "epoch: 229 loss: 2.285090923309326 grad: 2.436694165440424\n",
      "epoch: 230 loss: 2.2828803062438965 grad: 2.4371275920310014\n",
      "epoch: 231 loss: 2.2819342613220215 grad: 2.443111772567684\n",
      "epoch: 232 loss: 2.279355764389038 grad: 2.4714524079435725\n",
      "epoch: 233 loss: 2.2788565158843994 grad: 2.380900679788153\n",
      "epoch: 234 loss: 2.2762322425842285 grad: 2.341585648804164\n",
      "epoch: 235 loss: 2.276843547821045 grad: 2.385331278304673\n",
      "epoch: 236 loss: 2.2741329669952393 grad: 2.3619125959637115\n",
      "epoch: 237 loss: 2.2728519439697266 grad: 2.320929089021529\n",
      "epoch: 238 loss: 2.2733981609344482 grad: 2.3439863328119768\n",
      "epoch: 239 loss: 2.271688222885132 grad: 2.3194487794276535\n",
      "epoch: 240 loss: 2.2692840099334717 grad: 2.2181931854824404\n",
      "epoch: 241 loss: 2.2698287963867188 grad: 2.2588747472701862\n",
      "epoch: 242 loss: 2.2660679817199707 grad: 2.1161658291091463\n",
      "epoch: 243 loss: 2.2668051719665527 grad: 2.1579090880862037\n",
      "epoch: 244 loss: 2.2682836055755615 grad: 2.1426231666663957\n",
      "epoch: 245 loss: 2.263443946838379 grad: 2.0351278158181922\n",
      "epoch: 246 loss: 2.263895034790039 grad: 1.9956841437859343\n",
      "epoch: 247 loss: 2.262162208557129 grad: 1.9974933686233791\n",
      "epoch: 248 loss: 2.26155948638916 grad: 1.9686669383737598\n",
      "epoch: 249 loss: 2.261439323425293 grad: 1.9315857784342139\n",
      "epoch: 250 loss: 2.2594473361968994 grad: 1.9245686367808266\n",
      "epoch: 251 loss: 2.259018659591675 grad: 1.8712124831342538\n",
      "epoch: 252 loss: 2.2597529888153076 grad: 1.8968454416553002\n",
      "epoch: 253 loss: 2.257697820663452 grad: 1.8029995332065496\n",
      "epoch: 254 loss: 2.256894826889038 grad: 1.8030028945141812\n",
      "epoch: 255 loss: 2.2579457759857178 grad: 1.8148735150609845\n",
      "epoch: 256 loss: 2.2565910816192627 grad: 1.776604081688833\n",
      "epoch: 257 loss: 2.2548139095306396 grad: 1.6922539562515413\n",
      "epoch: 258 loss: 2.2540833950042725 grad: 1.6981920218963678\n",
      "epoch: 259 loss: 2.254805564880371 grad: 1.7331122662003582\n",
      "epoch: 260 loss: 2.253840446472168 grad: 1.7104892981929765\n",
      "epoch: 261 loss: 2.2522246837615967 grad: 1.6293790177589962\n",
      "epoch: 262 loss: 2.253281354904175 grad: 1.6501485940719407\n",
      "epoch: 263 loss: 2.252354621887207 grad: 1.6222156417696545\n",
      "epoch: 264 loss: 2.251389980316162 grad: 1.575046670752474\n",
      "epoch: 265 loss: 2.251556873321533 grad: 1.584955058775709\n",
      "epoch: 266 loss: 2.252256393432617 grad: 1.6304865598231406\n",
      "epoch: 267 loss: 2.25185227394104 grad: 1.5566283240452379\n",
      "epoch: 268 loss: 2.2501683235168457 grad: 1.5182336604699405\n",
      "epoch: 269 loss: 2.250084638595581 grad: 1.54634736273216\n",
      "epoch: 270 loss: 2.2496414184570312 grad: 1.5566748683876728\n",
      "epoch: 271 loss: 2.2495779991149902 grad: 1.5320884429624244\n",
      "epoch: 272 loss: 2.2500691413879395 grad: 1.548070494371969\n",
      "epoch: 273 loss: 2.246837615966797 grad: 1.4354821386883805\n",
      "epoch: 274 loss: 2.2477707862854004 grad: 1.4561656030164736\n",
      "epoch: 275 loss: 2.2485082149505615 grad: 1.4566109559853517\n",
      "epoch: 276 loss: 2.2493531703948975 grad: 1.5005324421439408\n",
      "epoch: 277 loss: 2.246990442276001 grad: 1.4273349762957042\n",
      "epoch: 278 loss: 2.2466673851013184 grad: 1.422312139829118\n",
      "epoch: 279 loss: 2.247021436691284 grad: 1.4056842267431968\n",
      "epoch: 280 loss: 2.245812177658081 grad: 1.4161334572016218\n",
      "epoch: 281 loss: 2.2459049224853516 grad: 1.4220565562912573\n",
      "epoch: 282 loss: 2.246332883834839 grad: 1.3933706009254185\n",
      "epoch: 283 loss: 2.245591878890991 grad: 1.4165423131928527\n",
      "epoch: 284 loss: 2.2456843852996826 grad: 1.355190051442367\n",
      "epoch: 285 loss: 2.243894338607788 grad: 1.34605351321414\n",
      "epoch: 286 loss: 2.244509220123291 grad: 1.372878483420844\n",
      "epoch: 287 loss: 2.245060682296753 grad: 1.3669680718975585\n",
      "epoch: 288 loss: 2.2443408966064453 grad: 1.3637509588170649\n",
      "epoch: 289 loss: 2.2431187629699707 grad: 1.2574014035515517\n",
      "epoch: 290 loss: 2.2440779209136963 grad: 1.344574316899987\n",
      "epoch: 291 loss: 2.2448785305023193 grad: 1.3474055802697198\n",
      "epoch: 292 loss: 2.243671178817749 grad: 1.2922282754332715\n",
      "epoch: 293 loss: 2.243713140487671 grad: 1.326352553353423\n",
      "epoch: 294 loss: 2.2445874214172363 grad: 1.306303603086798\n",
      "epoch: 295 loss: 2.2435762882232666 grad: 1.3229139607292526\n",
      "epoch: 296 loss: 2.241356134414673 grad: 1.2703586732469765\n",
      "epoch: 297 loss: 2.2428503036499023 grad: 1.2966652702584507\n",
      "epoch: 298 loss: 2.24177622795105 grad: 1.2434536175902136\n",
      "epoch: 299 loss: 2.2418301105499268 grad: 1.2443402572590414\n",
      "epoch: 300 loss: 2.2415804862976074 grad: 1.2636314234252841\n",
      "epoch: 301 loss: 2.241602897644043 grad: 1.2619195283198403\n",
      "epoch: 302 loss: 2.243001699447632 grad: 1.276888110201865\n",
      "epoch: 303 loss: 2.2407407760620117 grad: 1.228562106973388\n",
      "epoch: 304 loss: 2.2399415969848633 grad: 1.1923412445503923\n",
      "epoch: 305 loss: 2.2414231300354004 grad: 1.2620199740945643\n",
      "epoch: 306 loss: 2.2400004863739014 grad: 1.1872595908196037\n",
      "epoch: 307 loss: 2.24005126953125 grad: 1.1911253115468998\n",
      "epoch: 308 loss: 2.2408063411712646 grad: 1.2569743251605403\n",
      "epoch: 309 loss: 2.2410943508148193 grad: 1.2598803041794795\n",
      "epoch: 310 loss: 2.240729570388794 grad: 1.2650791947537707\n",
      "epoch: 311 loss: 2.2401199340820312 grad: 1.2364441230985528\n",
      "epoch: 312 loss: 2.2400879859924316 grad: 1.1990564392975693\n",
      "epoch: 313 loss: 2.239382266998291 grad: 1.1654121852174977\n",
      "epoch: 314 loss: 2.2402260303497314 grad: 1.2159079586466153\n",
      "epoch: 315 loss: 2.2397618293762207 grad: 1.2499729099421066\n",
      "epoch: 316 loss: 2.2399771213531494 grad: 1.232345521819615\n",
      "epoch: 317 loss: 2.2387585639953613 grad: 1.1498788841815282\n",
      "epoch: 318 loss: 2.238967180252075 grad: 1.1873903887508999\n",
      "epoch: 319 loss: 2.2382798194885254 grad: 1.1465503673377773\n",
      "epoch: 320 loss: 2.2379539012908936 grad: 1.136708887815032\n",
      "epoch: 321 loss: 2.238802671432495 grad: 1.1873802951646097\n",
      "epoch: 322 loss: 2.2380075454711914 grad: 1.105425964734177\n",
      "epoch: 323 loss: 2.238393783569336 grad: 1.181199286413926\n",
      "epoch: 324 loss: 2.2389230728149414 grad: 1.2064398010797237\n",
      "epoch: 325 loss: 2.237684726715088 grad: 1.1468662040396815\n",
      "epoch: 326 loss: 2.239314317703247 grad: 1.176191348638866\n",
      "epoch: 327 loss: 2.238455295562744 grad: 1.154566307696292\n",
      "epoch: 328 loss: 2.237438440322876 grad: 1.166186284525172\n",
      "epoch: 329 loss: 2.2369632720947266 grad: 1.0841971057585427\n",
      "epoch: 330 loss: 2.238206624984741 grad: 1.1828597969697079\n",
      "epoch: 331 loss: 2.2375359535217285 grad: 1.1320726317704641\n",
      "epoch: 332 loss: 2.236900806427002 grad: 1.108656938200713\n",
      "epoch: 333 loss: 2.23893141746521 grad: 1.1833725038191512\n",
      "epoch: 334 loss: 2.236804723739624 grad: 1.0883010699023818\n",
      "epoch: 335 loss: 2.2361772060394287 grad: 1.0746912277527227\n",
      "epoch: 336 loss: 2.236663579940796 grad: 1.1251077600357506\n",
      "epoch: 337 loss: 2.236471176147461 grad: 1.1037781291663469\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 338 loss: 2.2348978519439697 grad: 1.1098149822810517\n",
      "epoch: 339 loss: 2.2368075847625732 grad: 1.126457244441438\n",
      "epoch: 340 loss: 2.2373602390289307 grad: 1.1634213541493943\n",
      "epoch: 341 loss: 2.236666202545166 grad: 1.1402131466320642\n",
      "epoch: 342 loss: 2.236298084259033 grad: 1.1093235889889508\n",
      "epoch: 343 loss: 2.2360622882843018 grad: 1.1403900837675403\n",
      "epoch: 344 loss: 2.235785961151123 grad: 1.0808663434951404\n",
      "epoch: 345 loss: 2.236323595046997 grad: 1.091263553979511\n",
      "epoch: 346 loss: 2.2355456352233887 grad: 1.132901433361916\n",
      "epoch: 347 loss: 2.236502170562744 grad: 1.1832715473119317\n",
      "epoch: 348 loss: 2.235673427581787 grad: 1.1060556346691022\n",
      "epoch: 349 loss: 2.2356696128845215 grad: 1.085742685124315\n",
      "epoch: 350 loss: 2.235405683517456 grad: 1.112519436216514\n",
      "epoch: 351 loss: 2.2348411083221436 grad: 1.0795846484797371\n",
      "epoch: 352 loss: 2.234808921813965 grad: 1.1064279254476008\n",
      "epoch: 353 loss: 2.235226631164551 grad: 1.139510130042225\n",
      "epoch: 354 loss: 2.2345988750457764 grad: 1.1003215125981822\n",
      "epoch: 355 loss: 2.2356085777282715 grad: 1.1326373012815898\n",
      "epoch: 356 loss: 2.2338480949401855 grad: 1.0577959182666659\n",
      "epoch: 357 loss: 2.234675407409668 grad: 1.09832222162125\n",
      "epoch: 358 loss: 2.2352123260498047 grad: 1.138029400545675\n",
      "epoch: 359 loss: 2.234708786010742 grad: 1.1002116788766303\n",
      "epoch: 360 loss: 2.2352492809295654 grad: 1.117019359464018\n",
      "epoch: 361 loss: 2.234631299972534 grad: 1.100532618160951\n",
      "epoch: 362 loss: 2.2339556217193604 grad: 1.0516901290467349\n",
      "epoch: 363 loss: 2.2337098121643066 grad: 1.0808663077944416\n",
      "epoch: 364 loss: 2.234375476837158 grad: 1.1123337245533347\n",
      "epoch: 365 loss: 2.2335398197174072 grad: 1.0651667926382895\n",
      "epoch: 366 loss: 2.2336251735687256 grad: 1.0631010630241935\n",
      "epoch: 367 loss: 2.233431816101074 grad: 1.0679824818018084\n",
      "epoch: 368 loss: 2.233032464981079 grad: 1.046874859253876\n",
      "epoch: 369 loss: 2.2335805892944336 grad: 1.093316261859847\n",
      "epoch: 370 loss: 2.2334470748901367 grad: 1.047014219432308\n",
      "epoch: 371 loss: 2.233884811401367 grad: 1.0976033962279972\n",
      "epoch: 372 loss: 2.2327680587768555 grad: 1.079536507252626\n",
      "epoch: 373 loss: 2.2339515686035156 grad: 1.1045802907208868\n",
      "epoch: 374 loss: 2.2336771488189697 grad: 1.1078970537831385\n",
      "epoch: 375 loss: 2.232713460922241 grad: 1.0458897987864764\n",
      "epoch: 376 loss: 2.2336339950561523 grad: 1.064825703825114\n",
      "epoch: 377 loss: 2.2333810329437256 grad: 1.068436190933137\n",
      "epoch: 378 loss: 2.232653856277466 grad: 1.0604695357744478\n",
      "epoch: 379 loss: 2.232642650604248 grad: 1.096082611848408\n",
      "epoch: 380 loss: 2.2337729930877686 grad: 1.1242802387929434\n",
      "epoch: 381 loss: 2.2328033447265625 grad: 1.0636548840963755\n",
      "epoch: 382 loss: 2.231808662414551 grad: 1.0332354716587042\n",
      "epoch: 383 loss: 2.232667922973633 grad: 1.1109675643115586\n",
      "epoch: 384 loss: 2.2332959175109863 grad: 1.1206756954456472\n",
      "epoch: 385 loss: 2.232198715209961 grad: 1.095180127441713\n",
      "epoch: 386 loss: 2.2315609455108643 grad: 1.0621294493349047\n",
      "epoch: 387 loss: 2.2319071292877197 grad: 1.043378781496791\n",
      "epoch: 388 loss: 2.231898784637451 grad: 1.0297579137000463\n",
      "epoch: 389 loss: 2.2321395874023438 grad: 1.051246385643488\n",
      "epoch: 390 loss: 2.2333428859710693 grad: 1.0675234613701745\n",
      "epoch: 391 loss: 2.232534646987915 grad: 1.0826388666921827\n",
      "epoch: 392 loss: 2.231078863143921 grad: 1.0285689386304482\n",
      "epoch: 393 loss: 2.2319042682647705 grad: 1.064560523465468\n",
      "epoch: 394 loss: 2.2312920093536377 grad: 1.0504231486582227\n",
      "epoch: 395 loss: 2.2321572303771973 grad: 1.0741768611118285\n",
      "epoch: 396 loss: 2.231454849243164 grad: 1.0705545194029424\n",
      "epoch: 397 loss: 2.2308950424194336 grad: 1.0201070820543146\n",
      "epoch: 398 loss: 2.2317793369293213 grad: 1.0666127055116545\n",
      "epoch: 399 loss: 2.231084108352661 grad: 1.0135399607104427\n",
      "epoch: 400 loss: 2.2302494049072266 grad: 1.0613617480765762\n",
      "epoch: 401 loss: 2.231062889099121 grad: 1.0716402267100333\n",
      "epoch: 402 loss: 2.231253147125244 grad: 1.0206640445320527\n",
      "epoch: 403 loss: 2.2310774326324463 grad: 1.0614977233021312\n",
      "epoch: 404 loss: 2.231938362121582 grad: 1.0401078076831745\n",
      "epoch: 405 loss: 2.2311291694641113 grad: 1.0410387776838246\n",
      "epoch: 406 loss: 2.2305972576141357 grad: 1.0241560655209931\n",
      "epoch: 407 loss: 2.2310616970062256 grad: 1.0846633333463356\n",
      "epoch: 408 loss: 2.230232000350952 grad: 1.0255048173084294\n",
      "epoch: 409 loss: 2.2294721603393555 grad: 1.0209373853590695\n",
      "epoch: 410 loss: 2.2304322719573975 grad: 1.0372940401088386\n",
      "epoch: 411 loss: 2.231729745864868 grad: 1.0642960972553637\n",
      "epoch: 412 loss: 2.2307748794555664 grad: 1.1022459112850593\n",
      "epoch: 413 loss: 2.230761766433716 grad: 1.0815858090710309\n",
      "epoch: 414 loss: 2.2303638458251953 grad: 1.0456273976818746\n",
      "epoch: 415 loss: 2.229764461517334 grad: 1.0442579882783032\n",
      "epoch: 416 loss: 2.230414390563965 grad: 1.047032390857884\n",
      "epoch: 417 loss: 2.2305212020874023 grad: 1.0655243555398008\n",
      "epoch: 418 loss: 2.2303361892700195 grad: 1.0679538538254472\n",
      "epoch: 419 loss: 2.2303531169891357 grad: 1.0582936247339516\n",
      "epoch: 420 loss: 2.2294421195983887 grad: 1.0129037807410997\n",
      "epoch: 421 loss: 2.229943037033081 grad: 1.0773512278018254\n",
      "epoch: 422 loss: 2.2301721572875977 grad: 1.083248996009518\n",
      "epoch: 423 loss: 2.229377269744873 grad: 1.0136436575558037\n",
      "epoch: 424 loss: 2.229529857635498 grad: 1.0008722519629547\n",
      "epoch: 425 loss: 2.2295737266540527 grad: 1.085763523574098\n",
      "epoch: 426 loss: 2.2277133464813232 grad: 0.9323354152729735\n",
      "epoch: 427 loss: 2.2296478748321533 grad: 1.0288400440892604\n",
      "epoch: 428 loss: 2.2292110919952393 grad: 1.0204522198358077\n",
      "epoch: 429 loss: 2.2286431789398193 grad: 1.0927840494754029\n",
      "epoch: 430 loss: 2.228811264038086 grad: 1.0279187868905462\n",
      "epoch: 431 loss: 2.2298777103424072 grad: 1.0985078935387604\n",
      "epoch: 432 loss: 2.2287662029266357 grad: 1.0339795041955002\n",
      "epoch: 433 loss: 2.2296142578125 grad: 1.0785569431849695\n",
      "epoch: 434 loss: 2.2284600734710693 grad: 1.0206966308344687\n",
      "epoch: 435 loss: 2.229017734527588 grad: 1.0599129038247546\n",
      "epoch: 436 loss: 2.228849172592163 grad: 1.0496156437170974\n",
      "epoch: 437 loss: 2.2284374237060547 grad: 0.9836955640856768\n",
      "epoch: 438 loss: 2.2289302349090576 grad: 1.0231962864664161\n",
      "epoch: 439 loss: 2.228142261505127 grad: 1.0239583327128212\n",
      "epoch: 440 loss: 2.2280895709991455 grad: 1.057799468982026\n",
      "epoch: 441 loss: 2.229578971862793 grad: 1.0685195769737696\n",
      "epoch: 442 loss: 2.2283759117126465 grad: 1.0480388431460597\n",
      "epoch: 443 loss: 2.2292044162750244 grad: 1.0689433519146405\n",
      "epoch: 444 loss: 2.2282016277313232 grad: 1.0476730845199662\n",
      "epoch: 445 loss: 2.2282540798187256 grad: 1.0433947496284317\n",
      "epoch: 446 loss: 2.228492498397827 grad: 1.047816468136651\n",
      "epoch: 447 loss: 2.2289509773254395 grad: 1.0515522152455228\n",
      "epoch: 448 loss: 2.2287654876708984 grad: 1.0335656700605926\n",
      "epoch: 449 loss: 2.227586507797241 grad: 1.041945103161399\n",
      "epoch: 450 loss: 2.2274420261383057 grad: 1.0300688052740288\n",
      "epoch: 451 loss: 2.228541851043701 grad: 1.0743459213963\n",
      "epoch: 452 loss: 2.228633403778076 grad: 1.0750779454819932\n",
      "epoch: 453 loss: 2.2280094623565674 grad: 1.0502944804223564\n",
      "epoch: 454 loss: 2.227759838104248 grad: 1.042191222392296\n",
      "epoch: 455 loss: 2.227339267730713 grad: 0.9983765396635078\n",
      "epoch: 456 loss: 2.227175235748291 grad: 0.979410804456122\n",
      "epoch: 457 loss: 2.226930856704712 grad: 0.9980343041612604\n",
      "epoch: 458 loss: 2.2270421981811523 grad: 1.053717313548698\n",
      "epoch: 459 loss: 2.2268335819244385 grad: 1.0214994038078224\n",
      "epoch: 460 loss: 2.2269017696380615 grad: 1.022536302375282\n",
      "epoch: 461 loss: 2.227243423461914 grad: 1.0066814917871463\n",
      "epoch: 462 loss: 2.227492094039917 grad: 1.0518113190016252\n",
      "epoch: 463 loss: 2.2273197174072266 grad: 1.0022395838528784\n",
      "epoch: 464 loss: 2.2276854515075684 grad: 1.0463570096273167\n",
      "epoch: 465 loss: 2.227874517440796 grad: 1.0791512460166972\n",
      "epoch: 466 loss: 2.2277777194976807 grad: 1.078117196114608\n",
      "epoch: 467 loss: 2.2267937660217285 grad: 1.0264791398455153\n",
      "epoch: 468 loss: 2.2264232635498047 grad: 1.0381106893589263\n",
      "epoch: 469 loss: 2.2275209426879883 grad: 1.03982882327973\n",
      "epoch: 470 loss: 2.2278592586517334 grad: 1.0657667948371021\n",
      "epoch: 471 loss: 2.2266910076141357 grad: 1.0464477826090943\n",
      "epoch: 472 loss: 2.2265021800994873 grad: 1.0516362382461213\n",
      "epoch: 473 loss: 2.225918769836426 grad: 1.0256572949103198\n",
      "epoch: 474 loss: 2.2276129722595215 grad: 1.0852366813138823\n",
      "epoch: 475 loss: 2.22689151763916 grad: 1.0670112768919873\n",
      "epoch: 476 loss: 2.2262959480285645 grad: 1.0311111306572067\n",
      "epoch: 477 loss: 2.2256224155426025 grad: 0.9746331524737697\n",
      "epoch: 478 loss: 2.2274229526519775 grad: 1.0501105491254878\n",
      "epoch: 479 loss: 2.2266764640808105 grad: 1.0982045740857425\n",
      "epoch: 480 loss: 2.2273073196411133 grad: 1.0139589407887784\n",
      "epoch: 481 loss: 2.225682497024536 grad: 0.981084325150328\n",
      "epoch: 482 loss: 2.226611375808716 grad: 1.0410549453744251\n",
      "epoch: 483 loss: 2.225621223449707 grad: 1.03390655362524\n",
      "epoch: 484 loss: 2.2259178161621094 grad: 1.1026560605507314\n",
      "epoch: 485 loss: 2.2261126041412354 grad: 1.046426478791834\n",
      "epoch: 486 loss: 2.226128339767456 grad: 0.998818862767491\n",
      "epoch: 487 loss: 2.2254233360290527 grad: 1.069078602068614\n",
      "epoch: 488 loss: 2.225850820541382 grad: 1.0466725100044323\n",
      "epoch: 489 loss: 2.2264490127563477 grad: 1.0365174650279287\n",
      "epoch: 490 loss: 2.2254247665405273 grad: 1.0330684804034211\n",
      "epoch: 491 loss: 2.224787712097168 grad: 0.9822930026973139\n",
      "epoch: 492 loss: 2.2252485752105713 grad: 0.9916297969397246\n",
      "epoch: 493 loss: 2.225815773010254 grad: 1.0747029549129943\n",
      "epoch: 494 loss: 2.2247705459594727 grad: 1.0315339469308373\n",
      "epoch: 495 loss: 2.2254998683929443 grad: 1.0314295470071513\n",
      "epoch: 496 loss: 2.225785493850708 grad: 1.1128788957786229\n",
      "epoch: 497 loss: 2.225217580795288 grad: 1.0404845401561553\n",
      "epoch: 498 loss: 2.2260563373565674 grad: 1.0897664528493474\n",
      "epoch: 499 loss: 2.22528338432312 grad: 1.100211554337182\n",
      "2.245029404759407\n",
      "epoch: 0 loss: 2.303840160369873 grad: 1.2155529011137014\n",
      "epoch: 1 loss: 2.3021459579467773 grad: 1.186819594251805\n",
      "epoch: 2 loss: 2.301405668258667 grad: 1.173356289749906\n",
      "epoch: 3 loss: 2.3007450103759766 grad: 1.1944983013506447\n",
      "epoch: 4 loss: 2.298733711242676 grad: 1.2494025011620824\n",
      "epoch: 5 loss: 2.2971384525299072 grad: 1.2874747129815025\n",
      "epoch: 6 loss: 2.2932324409484863 grad: 1.429721433907703\n",
      "epoch: 7 loss: 2.2896461486816406 grad: 1.5716030407781965\n",
      "epoch: 8 loss: 2.2839770317077637 grad: 1.740163749172574\n",
      "epoch: 9 loss: 2.2773308753967285 grad: 1.9364976344208809\n",
      "epoch: 10 loss: 2.274845838546753 grad: 2.0641382500540377\n",
      "epoch: 11 loss: 2.2655038833618164 grad: 2.2268339444454464\n",
      "epoch: 12 loss: 2.2611169815063477 grad: 2.351039532743882\n",
      "epoch: 13 loss: 2.2558202743530273 grad: 2.483244931691193\n",
      "epoch: 14 loss: 2.2480626106262207 grad: 2.6997508169946425\n",
      "epoch: 15 loss: 2.244184970855713 grad: 2.6701063094087805\n",
      "epoch: 16 loss: 2.2403860092163086 grad: 2.9818796744673617\n",
      "epoch: 17 loss: 2.237342119216919 grad: 3.011616926965496\n",
      "epoch: 18 loss: 2.233719825744629 grad: 3.3016682309874645\n",
      "epoch: 19 loss: 2.229527235031128 grad: 3.3344073413893405\n",
      "epoch: 20 loss: 2.226609706878662 grad: 3.340087181134593\n",
      "epoch: 21 loss: 2.2229907512664795 grad: 3.3789197649355858\n",
      "epoch: 22 loss: 2.2185447216033936 grad: 3.6243182587666465\n",
      "epoch: 23 loss: 2.2151906490325928 grad: 3.511467991045691\n",
      "epoch: 24 loss: 2.208735704421997 grad: 4.015994879069724\n",
      "epoch: 25 loss: 2.20304536819458 grad: 4.165571146008987\n",
      "epoch: 26 loss: 2.193441867828369 grad: 4.591996644882278\n",
      "epoch: 27 loss: 2.1806106567382812 grad: 4.78643464566105\n",
      "epoch: 28 loss: 2.1677181720733643 grad: 4.638978415797095\n",
      "epoch: 29 loss: 2.1592254638671875 grad: 4.684863683933925\n",
      "epoch: 30 loss: 2.155151844024658 grad: 4.822029618694196\n",
      "epoch: 31 loss: 2.135394334793091 grad: 4.874162323373769\n",
      "epoch: 32 loss: 2.1366794109344482 grad: 4.938417864261225\n",
      "epoch: 33 loss: 2.12846302986145 grad: 4.811473989186601\n",
      "epoch: 34 loss: 2.1281588077545166 grad: 4.967701907070087\n",
      "epoch: 35 loss: 2.1183416843414307 grad: 4.909836764791093\n",
      "epoch: 36 loss: 2.124199390411377 grad: 4.87442380171417\n",
      "epoch: 37 loss: 2.1089227199554443 grad: 4.771433389856524\n",
      "epoch: 38 loss: 2.109025716781616 grad: 4.696245172844519\n",
      "epoch: 39 loss: 2.107962131500244 grad: 4.862062454940603\n",
      "epoch: 40 loss: 2.1038784980773926 grad: 4.802967585083689\n",
      "epoch: 41 loss: 2.099815607070923 grad: 5.008530295890061\n",
      "epoch: 42 loss: 2.102302074432373 grad: 4.926877928631646\n",
      "epoch: 43 loss: 2.09536075592041 grad: 4.944219891133438\n",
      "epoch: 44 loss: 2.090186834335327 grad: 4.8305459904026185\n",
      "epoch: 45 loss: 2.0880331993103027 grad: 4.86521267482183\n",
      "epoch: 46 loss: 2.0892786979675293 grad: 4.920504868207943\n",
      "epoch: 47 loss: 2.0861475467681885 grad: 4.863539653578921\n",
      "epoch: 48 loss: 2.089111089706421 grad: 5.137836656311438\n",
      "epoch: 49 loss: 2.0809333324432373 grad: 5.040562848737907\n",
      "epoch: 50 loss: 2.0839173793792725 grad: 4.810121975713483\n",
      "epoch: 51 loss: 2.078294038772583 grad: 4.979183117607756\n",
      "epoch: 52 loss: 2.0740373134613037 grad: 4.943813661394256\n",
      "epoch: 53 loss: 2.071782112121582 grad: 5.185755439220913\n",
      "epoch: 54 loss: 2.0720577239990234 grad: 4.979889569138842\n",
      "epoch: 55 loss: 2.0638434886932373 grad: 4.918753319937322\n",
      "epoch: 56 loss: 2.0713398456573486 grad: 5.1500108333836705\n",
      "epoch: 57 loss: 2.0665359497070312 grad: 4.964569905041052\n",
      "epoch: 58 loss: 2.064629554748535 grad: 4.994791375014872\n",
      "epoch: 59 loss: 2.0640060901641846 grad: 5.286822477082116\n",
      "epoch: 60 loss: 2.061750888824463 grad: 5.051584747590361\n",
      "epoch: 61 loss: 2.059739351272583 grad: 5.2317993542889045\n",
      "epoch: 62 loss: 2.061340093612671 grad: 5.300203049067585\n",
      "epoch: 63 loss: 2.056293487548828 grad: 5.442755604865\n",
      "epoch: 64 loss: 2.0533103942871094 grad: 5.386774281431581\n",
      "epoch: 65 loss: 2.053687334060669 grad: 5.2793582524764275\n",
      "epoch: 66 loss: 2.058021306991577 grad: 5.717212587705857\n",
      "epoch: 67 loss: 2.0492351055145264 grad: 5.529623347408478\n",
      "epoch: 68 loss: 2.0565459728240967 grad: 5.919023662369462\n",
      "epoch: 69 loss: 2.04943585395813 grad: 5.737483831728617\n",
      "epoch: 70 loss: 2.052706241607666 grad: 5.853474425100204\n",
      "epoch: 71 loss: 2.0454204082489014 grad: 5.419428447438848\n",
      "epoch: 72 loss: 2.0460102558135986 grad: 5.275844131980742\n",
      "epoch: 73 loss: 2.0424692630767822 grad: 5.358167349146531\n",
      "epoch: 74 loss: 2.039858818054199 grad: 5.7044220194442286\n",
      "epoch: 75 loss: 2.0409352779388428 grad: 5.577401621548074\n",
      "epoch: 76 loss: 2.0401718616485596 grad: 5.995111803590719\n",
      "epoch: 77 loss: 2.0408802032470703 grad: 6.067717738338702\n",
      "epoch: 78 loss: 2.0387604236602783 grad: 5.7956021194464515\n",
      "epoch: 79 loss: 2.034093141555786 grad: 5.727910969258537\n",
      "epoch: 80 loss: 2.032848358154297 grad: 5.690929965507831\n",
      "epoch: 81 loss: 2.032653570175171 grad: 5.774523239693648\n",
      "epoch: 82 loss: 2.031487464904785 grad: 5.652924457091897\n",
      "epoch: 83 loss: 2.027282476425171 grad: 5.791675728257923\n",
      "epoch: 84 loss: 2.02811861038208 grad: 6.190034258497199\n",
      "epoch: 85 loss: 2.0273401737213135 grad: 5.753086968724217\n",
      "epoch: 86 loss: 2.0255117416381836 grad: 5.585051478256309\n",
      "epoch: 87 loss: 2.0254852771759033 grad: 6.162403824827855\n",
      "epoch: 88 loss: 2.026646614074707 grad: 6.322992098140752\n",
      "epoch: 89 loss: 2.020340919494629 grad: 6.262059266523768\n",
      "epoch: 90 loss: 2.0233876705169678 grad: 5.540328431416244\n",
      "epoch: 91 loss: 2.0202505588531494 grad: 5.6523423659733485\n",
      "epoch: 92 loss: 2.0219857692718506 grad: 6.043162442204203\n",
      "epoch: 93 loss: 2.01826810836792 grad: 6.3349406332708895\n",
      "epoch: 94 loss: 2.0135498046875 grad: 5.977173967013461\n",
      "epoch: 95 loss: 2.0134758949279785 grad: 6.290394789982765\n",
      "epoch: 96 loss: 2.0177671909332275 grad: 6.276435591006977\n",
      "epoch: 97 loss: 2.0145888328552246 grad: 6.269821686492789\n",
      "epoch: 98 loss: 2.007749080657959 grad: 5.931106799696055\n",
      "epoch: 99 loss: 2.0128555297851562 grad: 6.027012420286026\n",
      "epoch: 100 loss: 2.005664110183716 grad: 6.6119135697150515\n",
      "epoch: 101 loss: 2.009883403778076 grad: 6.449669267568323\n",
      "epoch: 102 loss: 2.0056538581848145 grad: 6.473497085088479\n",
      "epoch: 103 loss: 2.0039567947387695 grad: 6.470506564152265\n",
      "epoch: 104 loss: 2.003812074661255 grad: 5.878518316887378\n",
      "epoch: 105 loss: 2.003161907196045 grad: 6.572561626196912\n",
      "epoch: 106 loss: 1.9952303171157837 grad: 6.441621632145215\n",
      "epoch: 107 loss: 1.99905264377594 grad: 6.15690275451671\n",
      "epoch: 108 loss: 2.0011277198791504 grad: 6.537173527499868\n",
      "epoch: 109 loss: 1.9993778467178345 grad: 6.305842317559476\n",
      "epoch: 110 loss: 1.9981194734573364 grad: 6.309965245758316\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 111 loss: 1.9957751035690308 grad: 6.4529466367297115\n",
      "epoch: 112 loss: 1.994201898574829 grad: 6.246421802626361\n",
      "epoch: 113 loss: 1.9872972965240479 grad: 6.727592597419899\n",
      "epoch: 114 loss: 1.9909840822219849 grad: 6.392613647719993\n",
      "epoch: 115 loss: 1.990908145904541 grad: 6.615566298491248\n",
      "epoch: 116 loss: 1.9881151914596558 grad: 6.657915901895317\n",
      "epoch: 117 loss: 1.9915404319763184 grad: 6.883892561612089\n",
      "epoch: 118 loss: 1.9878312349319458 grad: 6.573004659790072\n",
      "epoch: 119 loss: 1.9914108514785767 grad: 6.946975489871369\n",
      "epoch: 120 loss: 1.9896152019500732 grad: 7.035299491625102\n",
      "epoch: 121 loss: 1.9777995347976685 grad: 6.885220267736013\n",
      "epoch: 122 loss: 1.983310580253601 grad: 6.864612817779065\n",
      "epoch: 123 loss: 1.9898258447647095 grad: 7.34601973300238\n",
      "epoch: 124 loss: 1.984878420829773 grad: 7.177377334027182\n",
      "epoch: 125 loss: 1.978044867515564 grad: 7.067941131883315\n",
      "epoch: 126 loss: 1.9769489765167236 grad: 7.326941858651856\n",
      "epoch: 127 loss: 1.9854185581207275 grad: 7.183517976013559\n",
      "epoch: 128 loss: 1.9787898063659668 grad: 7.460180073473898\n",
      "epoch: 129 loss: 1.9765267372131348 grad: 7.078180966994887\n",
      "epoch: 130 loss: 1.9763860702514648 grad: 7.084459355840134\n",
      "epoch: 131 loss: 1.9731203317642212 grad: 7.220463626552373\n",
      "epoch: 132 loss: 1.966153860092163 grad: 7.375000825632245\n",
      "epoch: 133 loss: 1.9713269472122192 grad: 7.106422160700378\n",
      "epoch: 134 loss: 1.970531702041626 grad: 7.226276102756697\n",
      "epoch: 135 loss: 1.9662864208221436 grad: 7.261134888134187\n",
      "epoch: 136 loss: 1.9626420736312866 grad: 7.284495739561934\n",
      "epoch: 137 loss: 1.964539647102356 grad: 7.629188881174381\n",
      "epoch: 138 loss: 1.960230827331543 grad: 7.8436062428213305\n",
      "epoch: 139 loss: 1.962516188621521 grad: 7.717083819787062\n",
      "epoch: 140 loss: 1.960139513015747 grad: 7.776802816176935\n",
      "epoch: 141 loss: 1.9573789834976196 grad: 7.865883303702706\n",
      "epoch: 142 loss: 1.9583090543746948 grad: 8.173388816889316\n",
      "epoch: 143 loss: 1.9560190439224243 grad: 7.761788915650594\n",
      "epoch: 144 loss: 1.9551841020584106 grad: 7.758162424042229\n",
      "epoch: 145 loss: 1.95082426071167 grad: 8.148470070627\n",
      "epoch: 146 loss: 1.9566103219985962 grad: 8.339646865909417\n",
      "epoch: 147 loss: 1.9579178094863892 grad: 8.346632058613949\n",
      "epoch: 148 loss: 1.953542709350586 grad: 8.562545756765065\n",
      "epoch: 149 loss: 1.9497027397155762 grad: 8.63922547949626\n",
      "epoch: 150 loss: 1.948401927947998 grad: 8.157023668939631\n",
      "epoch: 151 loss: 1.9397797584533691 grad: 8.700672113440103\n",
      "epoch: 152 loss: 1.9448184967041016 grad: 8.51159223136566\n",
      "epoch: 153 loss: 1.9495265483856201 grad: 8.623322356270538\n",
      "epoch: 154 loss: 1.9380607604980469 grad: 8.65791275078756\n",
      "epoch: 155 loss: 1.945095419883728 grad: 8.6400751821135\n",
      "epoch: 156 loss: 1.9340659379959106 grad: 8.809728552498633\n",
      "epoch: 157 loss: 1.9392213821411133 grad: 9.346216178173938\n",
      "epoch: 158 loss: 1.9339736700057983 grad: 8.627374516652218\n",
      "epoch: 159 loss: 1.9373410940170288 grad: 8.774511500941736\n",
      "epoch: 160 loss: 1.929146409034729 grad: 8.786570882262101\n",
      "epoch: 161 loss: 1.9285999536514282 grad: 8.958556872289924\n",
      "epoch: 162 loss: 1.9302093982696533 grad: 9.116524621548633\n",
      "epoch: 163 loss: 1.9268022775650024 grad: 9.383557810862031\n",
      "epoch: 164 loss: 1.9275552034378052 grad: 9.451750360163194\n",
      "epoch: 165 loss: 1.92061448097229 grad: 9.567661366617632\n",
      "epoch: 166 loss: 1.9273146390914917 grad: 9.356125694256098\n",
      "epoch: 167 loss: 1.9242409467697144 grad: 9.470541776497923\n",
      "epoch: 168 loss: 1.9296529293060303 grad: 9.577499013748907\n",
      "epoch: 169 loss: 1.925196886062622 grad: 9.805473936485155\n",
      "epoch: 170 loss: 1.9180481433868408 grad: 9.42294498983889\n",
      "epoch: 171 loss: 1.9127291440963745 grad: 9.506383326451575\n",
      "epoch: 172 loss: 1.91653573513031 grad: 9.620437865766386\n",
      "epoch: 173 loss: 1.9259124994277954 grad: 9.483565810239977\n",
      "epoch: 174 loss: 1.9151216745376587 grad: 9.974492208559125\n",
      "epoch: 175 loss: 1.9119656085968018 grad: 9.335810860796343\n",
      "epoch: 176 loss: 1.9139347076416016 grad: 9.565200758743144\n",
      "epoch: 177 loss: 1.9078134298324585 grad: 10.549346632900692\n",
      "epoch: 178 loss: 1.9147677421569824 grad: 10.027433698701243\n",
      "epoch: 179 loss: 1.9090603590011597 grad: 9.942865634484896\n",
      "epoch: 180 loss: 1.9094842672348022 grad: 10.316349751389925\n",
      "epoch: 181 loss: 1.9049307107925415 grad: 10.440558941354828\n",
      "epoch: 182 loss: 1.9045796394348145 grad: 10.00358306699329\n",
      "epoch: 183 loss: 1.9052115678787231 grad: 10.29570391098599\n",
      "epoch: 184 loss: 1.9101057052612305 grad: 10.100006309899664\n",
      "epoch: 185 loss: 1.9007885456085205 grad: 10.589741780289582\n",
      "epoch: 186 loss: 1.9040406942367554 grad: 10.11058060600171\n",
      "epoch: 187 loss: 1.900842547416687 grad: 10.09739137609445\n",
      "epoch: 188 loss: 1.8996460437774658 grad: 10.532281163828594\n",
      "epoch: 189 loss: 1.8961772918701172 grad: 10.256520602763409\n",
      "epoch: 190 loss: 1.8904895782470703 grad: 10.08024940199204\n",
      "epoch: 191 loss: 1.9005447626113892 grad: 10.427115310826117\n",
      "epoch: 192 loss: 1.9011664390563965 grad: 10.293809620500912\n",
      "epoch: 193 loss: 1.8933712244033813 grad: 10.22412138314001\n",
      "epoch: 194 loss: 1.8960243463516235 grad: 10.989790170645666\n",
      "epoch: 195 loss: 1.8952051401138306 grad: 10.204314535528066\n",
      "epoch: 196 loss: 1.8942888975143433 grad: 10.14078667391062\n",
      "epoch: 197 loss: 1.8923382759094238 grad: 10.551745630519848\n",
      "epoch: 198 loss: 1.8879456520080566 grad: 9.809567956179972\n",
      "epoch: 199 loss: 1.8916720151901245 grad: 10.434894089808775\n",
      "epoch: 200 loss: 1.8807884454727173 grad: 10.684276065375242\n",
      "epoch: 201 loss: 1.8866064548492432 grad: 10.433125182897562\n",
      "epoch: 202 loss: 1.8817830085754395 grad: 11.040033686388698\n",
      "epoch: 203 loss: 1.8864670991897583 grad: 10.75732058036836\n",
      "epoch: 204 loss: 1.88094961643219 grad: 10.5004031322453\n",
      "epoch: 205 loss: 1.8857423067092896 grad: 10.882016014396434\n",
      "epoch: 206 loss: 1.8843002319335938 grad: 10.97915763869172\n",
      "epoch: 207 loss: 1.8774161338806152 grad: 10.975451135704855\n",
      "epoch: 208 loss: 1.8789910078048706 grad: 10.86204396248869\n",
      "epoch: 209 loss: 1.8769304752349854 grad: 11.03511030532952\n",
      "epoch: 210 loss: 1.8787543773651123 grad: 10.263971630572563\n",
      "epoch: 211 loss: 1.878944754600525 grad: 10.982410617246632\n",
      "epoch: 212 loss: 1.872837781906128 grad: 10.853231701452936\n",
      "epoch: 213 loss: 1.8739898204803467 grad: 10.918009603011702\n",
      "epoch: 214 loss: 1.87284255027771 grad: 11.297427048049276\n",
      "epoch: 215 loss: 1.8743594884872437 grad: 10.826236947277\n",
      "epoch: 216 loss: 1.8682245016098022 grad: 11.121939705847392\n",
      "epoch: 217 loss: 1.868607759475708 grad: 11.470463657145581\n",
      "epoch: 218 loss: 1.8664014339447021 grad: 10.494883801315039\n",
      "epoch: 219 loss: 1.8658030033111572 grad: 10.771153783913524\n",
      "epoch: 220 loss: 1.8657927513122559 grad: 10.734470185335903\n",
      "epoch: 221 loss: 1.8722420930862427 grad: 11.045659846005341\n",
      "epoch: 222 loss: 1.8668302297592163 grad: 11.13939757460344\n",
      "epoch: 223 loss: 1.8622368574142456 grad: 11.102411981819877\n",
      "epoch: 224 loss: 1.8587753772735596 grad: 10.989881571840554\n",
      "epoch: 225 loss: 1.8670933246612549 grad: 11.28510058844196\n",
      "epoch: 226 loss: 1.8653761148452759 grad: 11.933917141002086\n",
      "epoch: 227 loss: 1.8538105487823486 grad: 10.531397220885587\n",
      "epoch: 228 loss: 1.8610138893127441 grad: 11.367770221793936\n",
      "epoch: 229 loss: 1.865851879119873 grad: 11.27415842344127\n",
      "epoch: 230 loss: 1.8640910387039185 grad: 11.232892593161928\n",
      "epoch: 231 loss: 1.8534021377563477 grad: 11.280358339319863\n",
      "epoch: 232 loss: 1.8548455238342285 grad: 11.439866871070413\n",
      "epoch: 233 loss: 1.8604838848114014 grad: 11.009424620884515\n",
      "epoch: 234 loss: 1.8593909740447998 grad: 10.953716020351129\n",
      "epoch: 235 loss: 1.865695595741272 grad: 11.608192183299078\n",
      "epoch: 236 loss: 1.8472334146499634 grad: 10.65671141303721\n",
      "epoch: 237 loss: 1.8554729223251343 grad: 11.260241641411705\n",
      "epoch: 238 loss: 1.8564133644104004 grad: 11.203090244837638\n",
      "epoch: 239 loss: 1.84639573097229 grad: 11.215227513825374\n",
      "epoch: 240 loss: 1.852323055267334 grad: 11.004446910324669\n",
      "epoch: 241 loss: 1.8471416234970093 grad: 11.568774839656221\n",
      "epoch: 242 loss: 1.8467046022415161 grad: 11.23089907829842\n",
      "epoch: 243 loss: 1.8472243547439575 grad: 11.550981963038563\n",
      "epoch: 244 loss: 1.8485103845596313 grad: 11.44048334699538\n",
      "epoch: 245 loss: 1.8504924774169922 grad: 11.046754099953446\n",
      "epoch: 246 loss: 1.8462051153182983 grad: 11.045869726761584\n",
      "epoch: 247 loss: 1.8440734148025513 grad: 11.241305245263945\n",
      "epoch: 248 loss: 1.8375351428985596 grad: 11.411376516645154\n",
      "epoch: 249 loss: 1.838102102279663 grad: 11.677123081899943\n",
      "epoch: 250 loss: 1.848737120628357 grad: 11.942648681457198\n",
      "epoch: 251 loss: 1.8397550582885742 grad: 11.53994768337598\n",
      "epoch: 252 loss: 1.8527060747146606 grad: 11.797195198332211\n",
      "epoch: 253 loss: 1.8276267051696777 grad: 11.07220416405194\n",
      "epoch: 254 loss: 1.8370572328567505 grad: 11.478701625595845\n",
      "epoch: 255 loss: 1.8368319272994995 grad: 11.584473558701575\n",
      "epoch: 256 loss: 1.8423949480056763 grad: 11.596204191342824\n",
      "epoch: 257 loss: 1.8330971002578735 grad: 11.627770873762312\n",
      "epoch: 258 loss: 1.840574860572815 grad: 11.202656896637073\n",
      "epoch: 259 loss: 1.844443678855896 grad: 11.762448459908011\n",
      "epoch: 260 loss: 1.8313140869140625 grad: 12.04591420510163\n",
      "epoch: 261 loss: 1.83507239818573 grad: 11.928311157469002\n",
      "epoch: 262 loss: 1.8215347528457642 grad: 11.659705251159648\n",
      "epoch: 263 loss: 1.826821208000183 grad: 11.833694954166218\n",
      "epoch: 264 loss: 1.8246041536331177 grad: 12.063359470357971\n",
      "epoch: 265 loss: 1.8306083679199219 grad: 11.653337552197396\n",
      "epoch: 266 loss: 1.8270281553268433 grad: 11.459859308402335\n",
      "epoch: 267 loss: 1.828515887260437 grad: 10.955963183135268\n",
      "epoch: 268 loss: 1.8200875520706177 grad: 11.955700994927495\n",
      "epoch: 269 loss: 1.8234323263168335 grad: 11.59970371528632\n",
      "epoch: 270 loss: 1.828283429145813 grad: 11.568074132729736\n",
      "epoch: 271 loss: 1.8195412158966064 grad: 12.07112347551932\n",
      "epoch: 272 loss: 1.8234120607376099 grad: 11.983869226058088\n",
      "epoch: 273 loss: 1.8281983137130737 grad: 12.53039901824816\n",
      "epoch: 274 loss: 1.8180168867111206 grad: 12.134265533382338\n",
      "epoch: 275 loss: 1.8239721059799194 grad: 11.622776911120921\n",
      "epoch: 276 loss: 1.8228179216384888 grad: 11.664009459760218\n",
      "epoch: 277 loss: 1.81728994846344 grad: 11.827922510160576\n",
      "epoch: 278 loss: 1.829245686531067 grad: 12.125125742162622\n",
      "epoch: 279 loss: 1.8193644285202026 grad: 12.383883605474635\n",
      "epoch: 280 loss: 1.8111605644226074 grad: 11.75635688308449\n",
      "epoch: 281 loss: 1.8130428791046143 grad: 12.322230741278165\n",
      "epoch: 282 loss: 1.806214451789856 grad: 11.795251899561475\n",
      "epoch: 283 loss: 1.8110491037368774 grad: 12.575030857815392\n",
      "epoch: 284 loss: 1.8184661865234375 grad: 13.054060044447107\n",
      "epoch: 285 loss: 1.8023711442947388 grad: 12.083066869453187\n",
      "epoch: 286 loss: 1.8136965036392212 grad: 12.267244101206343\n",
      "epoch: 287 loss: 1.8053784370422363 grad: 12.38768990456112\n",
      "epoch: 288 loss: 1.8112375736236572 grad: 12.334211251654086\n",
      "epoch: 289 loss: 1.8158862590789795 grad: 12.194098956143808\n",
      "epoch: 290 loss: 1.8120554685592651 grad: 12.776267508192667\n",
      "epoch: 291 loss: 1.8063114881515503 grad: 12.340932335231512\n",
      "epoch: 292 loss: 1.809813141822815 grad: 12.60895483717618\n",
      "epoch: 293 loss: 1.8061319589614868 grad: 11.856958057716607\n",
      "epoch: 294 loss: 1.7978135347366333 grad: 12.365805568809192\n",
      "epoch: 295 loss: 1.8073484897613525 grad: 12.237268714396844\n",
      "epoch: 296 loss: 1.8150687217712402 grad: 12.311899347969938\n",
      "epoch: 297 loss: 1.8008315563201904 grad: 11.974395815785678\n",
      "epoch: 298 loss: 1.8077431917190552 grad: 12.243003491519225\n",
      "epoch: 299 loss: 1.7895026206970215 grad: 11.408087394362877\n",
      "epoch: 300 loss: 1.8043084144592285 grad: 12.878971846715089\n",
      "epoch: 301 loss: 1.8061155080795288 grad: 12.880372829543102\n",
      "epoch: 302 loss: 1.7914689779281616 grad: 13.040041950013903\n",
      "epoch: 303 loss: 1.8037481307983398 grad: 12.927459541116916\n",
      "epoch: 304 loss: 1.7892760038375854 grad: 12.436335487941664\n",
      "epoch: 305 loss: 1.798925518989563 grad: 12.995446854699699\n",
      "epoch: 306 loss: 1.8009775876998901 grad: 12.237941741514655\n",
      "epoch: 307 loss: 1.7985804080963135 grad: 12.281353142585546\n",
      "epoch: 308 loss: 1.7895334959030151 grad: 13.25532835244482\n",
      "epoch: 309 loss: 1.7942949533462524 grad: 12.951506404590512\n",
      "epoch: 310 loss: 1.7944695949554443 grad: 12.731064510649986\n",
      "epoch: 311 loss: 1.7839394807815552 grad: 12.967610817949568\n",
      "epoch: 312 loss: 1.7841057777404785 grad: 13.37091355432298\n",
      "epoch: 313 loss: 1.7831379175186157 grad: 12.787063177911536\n",
      "epoch: 314 loss: 1.7937819957733154 grad: 12.460052702827232\n",
      "epoch: 315 loss: 1.8001524209976196 grad: 13.287842087617646\n",
      "epoch: 316 loss: 1.7812633514404297 grad: 12.395481406622345\n",
      "epoch: 317 loss: 1.7858165502548218 grad: 12.803428410995929\n",
      "epoch: 318 loss: 1.778557300567627 grad: 12.669751353029694\n",
      "epoch: 319 loss: 1.7908819913864136 grad: 12.866115588576548\n",
      "epoch: 320 loss: 1.7888585329055786 grad: 13.261137545833158\n",
      "epoch: 321 loss: 1.7788355350494385 grad: 12.839130634988939\n",
      "epoch: 322 loss: 1.7817425727844238 grad: 12.328097453488716\n",
      "epoch: 323 loss: 1.7869279384613037 grad: 12.945092663006296\n",
      "epoch: 324 loss: 1.7866209745407104 grad: 12.847582353057252\n",
      "epoch: 325 loss: 1.7772023677825928 grad: 12.69220335199128\n",
      "epoch: 326 loss: 1.7827684879302979 grad: 13.41363151636093\n",
      "epoch: 327 loss: 1.7809617519378662 grad: 13.05303681090415\n",
      "epoch: 328 loss: 1.7814892530441284 grad: 12.587958213001016\n",
      "epoch: 329 loss: 1.7697851657867432 grad: 12.362164595075662\n",
      "epoch: 330 loss: 1.7777270078659058 grad: 13.459998122357305\n",
      "epoch: 331 loss: 1.7729589939117432 grad: 13.15791598439867\n",
      "epoch: 332 loss: 1.7606984376907349 grad: 13.053988949809638\n",
      "epoch: 333 loss: 1.7799664735794067 grad: 12.656893338934179\n",
      "epoch: 334 loss: 1.775408148765564 grad: 13.293653899537665\n",
      "epoch: 335 loss: 1.7694534063339233 grad: 13.350593891896544\n",
      "epoch: 336 loss: 1.7593576908111572 grad: 12.816887366615\n",
      "epoch: 337 loss: 1.7630836963653564 grad: 13.076367127886485\n",
      "epoch: 338 loss: 1.761939525604248 grad: 12.881340090259318\n",
      "epoch: 339 loss: 1.7699744701385498 grad: 13.443370352499187\n",
      "epoch: 340 loss: 1.766707420349121 grad: 13.021124727343993\n",
      "epoch: 341 loss: 1.7638177871704102 grad: 12.602521105610307\n",
      "epoch: 342 loss: 1.762299656867981 grad: 13.012576434288233\n",
      "epoch: 343 loss: 1.7691168785095215 grad: 12.998887903086604\n",
      "epoch: 344 loss: 1.7663651704788208 grad: 12.934918397076665\n",
      "epoch: 345 loss: 1.760946273803711 grad: 13.145667799334559\n",
      "epoch: 346 loss: 1.7467900514602661 grad: 13.238298550750764\n",
      "epoch: 347 loss: 1.765962839126587 grad: 12.887675964598737\n",
      "epoch: 348 loss: 1.76193368434906 grad: 13.000343999721938\n",
      "epoch: 349 loss: 1.7541539669036865 grad: 13.137452744139683\n",
      "epoch: 350 loss: 1.7484996318817139 grad: 13.608247615086535\n",
      "epoch: 351 loss: 1.7632635831832886 grad: 13.251470432069803\n",
      "epoch: 352 loss: 1.7616360187530518 grad: 13.03824937892043\n",
      "epoch: 353 loss: 1.7522538900375366 grad: 13.32968452294904\n",
      "epoch: 354 loss: 1.754396677017212 grad: 13.236297249454\n",
      "epoch: 355 loss: 1.7584242820739746 grad: 13.233091167706464\n",
      "epoch: 356 loss: 1.7555181980133057 grad: 13.505764951796404\n",
      "epoch: 357 loss: 1.757727861404419 grad: 13.227437930580761\n",
      "epoch: 358 loss: 1.7501178979873657 grad: 13.088070646844923\n",
      "epoch: 359 loss: 1.7467734813690186 grad: 13.280122723179085\n",
      "epoch: 360 loss: 1.7584829330444336 grad: 13.006791952709179\n",
      "epoch: 361 loss: 1.7587491273880005 grad: 13.359482475231209\n",
      "epoch: 362 loss: 1.7490037679672241 grad: 13.367102183490282\n",
      "epoch: 363 loss: 1.7482742071151733 grad: 13.214786830173422\n",
      "epoch: 364 loss: 1.74911630153656 grad: 13.419418421500023\n",
      "epoch: 365 loss: 1.7470242977142334 grad: 13.089179903446208\n",
      "epoch: 366 loss: 1.7441977262496948 grad: 13.344995214529927\n",
      "epoch: 367 loss: 1.7426296472549438 grad: 13.189747414551675\n",
      "epoch: 368 loss: 1.7523976564407349 grad: 13.206673035945093\n",
      "epoch: 369 loss: 1.74931001663208 grad: 13.382451039132855\n",
      "epoch: 370 loss: 1.741978406906128 grad: 13.24487699442617\n",
      "epoch: 371 loss: 1.7412980794906616 grad: 13.455262249320864\n",
      "epoch: 372 loss: 1.7364943027496338 grad: 13.413347808304168\n",
      "epoch: 373 loss: 1.7419345378875732 grad: 13.363519930014652\n",
      "epoch: 374 loss: 1.742364764213562 grad: 13.624418757693281\n",
      "epoch: 375 loss: 1.745242714881897 grad: 13.7669627866486\n",
      "epoch: 376 loss: 1.7469252347946167 grad: 13.256057777737697\n",
      "epoch: 377 loss: 1.7386689186096191 grad: 12.467470526133502\n",
      "epoch: 378 loss: 1.7441534996032715 grad: 13.326781309564554\n",
      "epoch: 379 loss: 1.747658133506775 grad: 13.801844362879084\n",
      "epoch: 380 loss: 1.7300761938095093 grad: 13.686141254143818\n",
      "epoch: 381 loss: 1.7446658611297607 grad: 14.110198995083689\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 382 loss: 1.7391526699066162 grad: 13.747389142549345\n",
      "epoch: 383 loss: 1.7362804412841797 grad: 13.471251106776652\n",
      "epoch: 384 loss: 1.7354143857955933 grad: 13.533401134305649\n",
      "epoch: 385 loss: 1.7321794033050537 grad: 13.32233515575469\n",
      "epoch: 386 loss: 1.736560344696045 grad: 14.180866190527995\n",
      "epoch: 387 loss: 1.7337290048599243 grad: 13.322840187661646\n",
      "epoch: 388 loss: 1.7332417964935303 grad: 13.268321943809353\n",
      "epoch: 389 loss: 1.73065185546875 grad: 13.906287349627487\n",
      "epoch: 390 loss: 1.7394753694534302 grad: 14.102099413880044\n",
      "epoch: 391 loss: 1.7392048835754395 grad: 13.785887206475886\n",
      "epoch: 392 loss: 1.7220999002456665 grad: 13.346706485434893\n",
      "epoch: 393 loss: 1.7270365953445435 grad: 13.775959748671287\n",
      "epoch: 394 loss: 1.7226332426071167 grad: 13.553714255876248\n",
      "epoch: 395 loss: 1.728593111038208 grad: 14.090159848598498\n",
      "epoch: 396 loss: 1.725803256034851 grad: 13.350113796099784\n",
      "epoch: 397 loss: 1.7184323072433472 grad: 14.013613736404785\n",
      "epoch: 398 loss: 1.7217028141021729 grad: 13.575783356240699\n",
      "epoch: 399 loss: 1.725551962852478 grad: 13.46798855069256\n",
      "epoch: 400 loss: 1.7181360721588135 grad: 13.685610392840491\n",
      "epoch: 401 loss: 1.7201660871505737 grad: 12.860290606432255\n",
      "epoch: 402 loss: 1.7246042490005493 grad: 14.14748232391855\n",
      "epoch: 403 loss: 1.7280932664871216 grad: 13.321558693601261\n",
      "epoch: 404 loss: 1.7270762920379639 grad: 14.381837977022524\n",
      "epoch: 405 loss: 1.718409538269043 grad: 13.567258075810969\n",
      "epoch: 406 loss: 1.71665620803833 grad: 13.411361910387992\n",
      "epoch: 407 loss: 1.727846384048462 grad: 13.504204165900038\n",
      "epoch: 408 loss: 1.7242419719696045 grad: 13.798410374863398\n",
      "epoch: 409 loss: 1.712548851966858 grad: 13.357227723690725\n",
      "epoch: 410 loss: 1.711628794670105 grad: 13.932373412101278\n",
      "epoch: 411 loss: 1.7183078527450562 grad: 13.879597279050994\n",
      "epoch: 412 loss: 1.7203408479690552 grad: 13.36892054133886\n",
      "epoch: 413 loss: 1.7100794315338135 grad: 13.31335793243396\n",
      "epoch: 414 loss: 1.7170708179473877 grad: 13.9333452904183\n",
      "epoch: 415 loss: 1.7212779521942139 grad: 13.85488355146455\n",
      "epoch: 416 loss: 1.7150647640228271 grad: 14.699023372789343\n",
      "epoch: 417 loss: 1.7237489223480225 grad: 14.864755905588114\n",
      "epoch: 418 loss: 1.7244535684585571 grad: 14.148134905224046\n",
      "epoch: 419 loss: 1.7134944200515747 grad: 13.4819270691997\n",
      "epoch: 420 loss: 1.714160680770874 grad: 13.999193996427552\n",
      "epoch: 421 loss: 1.7107551097869873 grad: 13.996098928005686\n",
      "epoch: 422 loss: 1.7090420722961426 grad: 13.538802698727638\n",
      "epoch: 423 loss: 1.7081578969955444 grad: 13.729298428307095\n",
      "epoch: 424 loss: 1.7080003023147583 grad: 13.803204365577253\n",
      "epoch: 425 loss: 1.7177468538284302 grad: 13.650149935501672\n",
      "epoch: 426 loss: 1.700127363204956 grad: 14.025791952770854\n",
      "epoch: 427 loss: 1.6998409032821655 grad: 13.502451553615549\n",
      "epoch: 428 loss: 1.709877610206604 grad: 13.524222881104501\n",
      "epoch: 429 loss: 1.7101054191589355 grad: 14.0081720442792\n",
      "epoch: 430 loss: 1.7012226581573486 grad: 13.497842684772516\n",
      "epoch: 431 loss: 1.7008217573165894 grad: 13.603802676342191\n",
      "epoch: 432 loss: 1.7088133096694946 grad: 13.987432025535593\n",
      "epoch: 433 loss: 1.6994268894195557 grad: 14.309674099013801\n",
      "epoch: 434 loss: 1.696488618850708 grad: 13.853487029479492\n",
      "epoch: 435 loss: 1.6960936784744263 grad: 13.583067337169297\n",
      "epoch: 436 loss: 1.7016944885253906 grad: 14.16884211903172\n",
      "epoch: 437 loss: 1.7012410163879395 grad: 13.627604623546912\n",
      "epoch: 438 loss: 1.6937624216079712 grad: 13.276480504873371\n",
      "epoch: 439 loss: 1.7097457647323608 grad: 13.5013606214068\n",
      "epoch: 440 loss: 1.697813630104065 grad: 12.987029058090041\n",
      "epoch: 441 loss: 1.7064951658248901 grad: 13.803522555867122\n",
      "epoch: 442 loss: 1.7024645805358887 grad: 13.418084710718148\n",
      "epoch: 443 loss: 1.7020858526229858 grad: 12.725556256027804\n",
      "epoch: 444 loss: 1.6949310302734375 grad: 13.183878518123594\n",
      "epoch: 445 loss: 1.7076711654663086 grad: 14.583617951513993\n",
      "epoch: 446 loss: 1.699655294418335 grad: 14.320804672907032\n",
      "epoch: 447 loss: 1.6949913501739502 grad: 13.761637233227255\n",
      "epoch: 448 loss: 1.6920177936553955 grad: 13.405155638572834\n",
      "epoch: 449 loss: 1.693158745765686 grad: 14.2309048088297\n",
      "epoch: 450 loss: 1.6944782733917236 grad: 13.052885753427825\n",
      "epoch: 451 loss: 1.6872981786727905 grad: 13.007341911380609\n",
      "epoch: 452 loss: 1.6977564096450806 grad: 13.664309340425664\n",
      "epoch: 453 loss: 1.6837379932403564 grad: 13.585487605870835\n",
      "epoch: 454 loss: 1.6992698907852173 grad: 13.525660403176314\n",
      "epoch: 455 loss: 1.6920852661132812 grad: 13.320366486330473\n",
      "epoch: 456 loss: 1.6888376474380493 grad: 13.85930488038335\n",
      "epoch: 457 loss: 1.6904882192611694 grad: 13.321629154392415\n",
      "epoch: 458 loss: 1.6900346279144287 grad: 13.956866911893327\n",
      "epoch: 459 loss: 1.7005274295806885 grad: 14.0463061139638\n",
      "epoch: 460 loss: 1.6877663135528564 grad: 13.440125050466685\n",
      "epoch: 461 loss: 1.6997531652450562 grad: 13.9057312478267\n",
      "epoch: 462 loss: 1.6892709732055664 grad: 14.010660008645601\n",
      "epoch: 463 loss: 1.6968711614608765 grad: 13.327087224490704\n",
      "epoch: 464 loss: 1.6876981258392334 grad: 13.024388446043881\n",
      "epoch: 465 loss: 1.6926069259643555 grad: 13.980896903837602\n",
      "epoch: 466 loss: 1.698041319847107 grad: 14.002146502897617\n",
      "epoch: 467 loss: 1.686238169670105 grad: 14.500667550408888\n",
      "epoch: 468 loss: 1.6903564929962158 grad: 13.500239224897491\n",
      "epoch: 469 loss: 1.6998372077941895 grad: 13.66587867287712\n",
      "epoch: 470 loss: 1.6957643032073975 grad: 13.278533616517153\n",
      "epoch: 471 loss: 1.688673734664917 grad: 13.651999022309033\n",
      "epoch: 472 loss: 1.686232566833496 grad: 13.841109185228271\n",
      "epoch: 473 loss: 1.6864997148513794 grad: 14.5764308622373\n",
      "epoch: 474 loss: 1.6917986869812012 grad: 13.31095780767796\n",
      "epoch: 475 loss: 1.6875360012054443 grad: 15.136806083857895\n",
      "epoch: 476 loss: 1.6896405220031738 grad: 13.210055667810911\n",
      "epoch: 477 loss: 1.6950628757476807 grad: 14.009858876171092\n",
      "epoch: 478 loss: 1.6904621124267578 grad: 13.913695789341416\n",
      "epoch: 479 loss: 1.6835265159606934 grad: 13.715408561389065\n",
      "epoch: 480 loss: 1.6901605129241943 grad: 14.070323305278425\n",
      "epoch: 481 loss: 1.6863057613372803 grad: 14.002746943162666\n",
      "epoch: 482 loss: 1.6812478303909302 grad: 14.165507721906852\n",
      "epoch: 483 loss: 1.677256464958191 grad: 13.549454998195408\n",
      "epoch: 484 loss: 1.6939126253128052 grad: 14.113644094369004\n",
      "epoch: 485 loss: 1.6944594383239746 grad: 14.725596392882013\n",
      "epoch: 486 loss: 1.677882432937622 grad: 13.366602621632554\n",
      "epoch: 487 loss: 1.6818879842758179 grad: 13.595976118367934\n",
      "epoch: 488 loss: 1.6818492412567139 grad: 13.73560795354997\n",
      "epoch: 489 loss: 1.6875308752059937 grad: 14.623055244426405\n",
      "epoch: 490 loss: 1.6773303747177124 grad: 13.684223598467984\n",
      "epoch: 491 loss: 1.6805256605148315 grad: 13.912689484204979\n",
      "epoch: 492 loss: 1.6786019802093506 grad: 13.751510570668394\n",
      "epoch: 493 loss: 1.6890369653701782 grad: 13.000898970187539\n",
      "epoch: 494 loss: 1.6774910688400269 grad: 14.100518411550198\n",
      "epoch: 495 loss: 1.676798939704895 grad: 13.787039193576055\n",
      "epoch: 496 loss: 1.6898659467697144 grad: 14.737559618664877\n",
      "epoch: 497 loss: 1.6816197633743286 grad: 13.639213852702625\n",
      "epoch: 498 loss: 1.681411623954773 grad: 14.529316609969275\n",
      "epoch: 499 loss: 1.683874249458313 grad: 14.042032010173278\n",
      "1.9912742376327515\n",
      "epoch: 0 loss: 2.3044958114624023 grad: 1.0212349986513367\n",
      "epoch: 1 loss: 2.2899656295776367 grad: 1.2257480520943536\n",
      "epoch: 2 loss: 2.247466802597046 grad: 1.8631926765378994\n",
      "epoch: 3 loss: 2.151994228363037 grad: 3.2269778620176357\n",
      "epoch: 4 loss: 2.088721752166748 grad: 4.215226508332379\n",
      "epoch: 5 loss: 2.0452592372894287 grad: 4.2441469321160445\n",
      "epoch: 6 loss: 2.020353317260742 grad: 4.661094244752478\n",
      "epoch: 7 loss: 1.9974417686462402 grad: 4.694796985110438\n",
      "epoch: 8 loss: 1.9934183359146118 grad: 4.453992810026403\n",
      "epoch: 9 loss: 1.9652904272079468 grad: 4.824552888292746\n",
      "epoch: 10 loss: 1.9548829793930054 grad: 4.5777939725935175\n",
      "epoch: 11 loss: 1.9480085372924805 grad: 5.1928407986743546\n",
      "epoch: 12 loss: 1.923275113105774 grad: 4.980960684889902\n",
      "epoch: 13 loss: 1.910629391670227 grad: 5.06914616231243\n",
      "epoch: 14 loss: 1.9033695459365845 grad: 5.390419916124157\n",
      "epoch: 15 loss: 1.8904225826263428 grad: 6.168569867949127\n",
      "epoch: 16 loss: 1.889453411102295 grad: 5.199169953107475\n",
      "epoch: 17 loss: 1.865804672241211 grad: 5.254035606923502\n",
      "epoch: 18 loss: 1.855525255203247 grad: 5.868444872256886\n",
      "epoch: 19 loss: 1.8477675914764404 grad: 6.202853474732293\n",
      "epoch: 20 loss: 1.8613920211791992 grad: 6.220534952422549\n",
      "epoch: 21 loss: 1.8285073041915894 grad: 5.576493570820377\n",
      "epoch: 22 loss: 1.823559284210205 grad: 5.993290999025616\n",
      "epoch: 23 loss: 1.819205403327942 grad: 5.358309627100382\n",
      "epoch: 24 loss: 1.8079099655151367 grad: 5.641610763407597\n",
      "epoch: 25 loss: 1.8094382286071777 grad: 5.714425632002531\n",
      "epoch: 26 loss: 1.775781512260437 grad: 6.232849114138858\n",
      "epoch: 27 loss: 1.7776544094085693 grad: 6.625841937378966\n",
      "epoch: 28 loss: 1.7720977067947388 grad: 6.824314444112898\n",
      "epoch: 29 loss: 1.7614558935165405 grad: 6.563870945980954\n",
      "epoch: 30 loss: 1.7583646774291992 grad: 6.587293861672238\n",
      "epoch: 31 loss: 1.7431840896606445 grad: 6.451852238851614\n",
      "epoch: 32 loss: 1.746971607208252 grad: 6.977508624527319\n",
      "epoch: 33 loss: 1.720351219177246 grad: 6.244150811496804\n",
      "epoch: 34 loss: 1.748095989227295 grad: 6.814264984087444\n",
      "epoch: 35 loss: 1.72189199924469 grad: 6.572917310081215\n",
      "epoch: 36 loss: 1.7217854261398315 grad: 6.597768185305916\n",
      "epoch: 37 loss: 1.7276533842086792 grad: 6.619220874825491\n",
      "epoch: 38 loss: 1.7043887376785278 grad: 6.194271358402422\n",
      "epoch: 39 loss: 1.7087591886520386 grad: 6.53878435137495\n",
      "epoch: 40 loss: 1.7099335193634033 grad: 6.016834415240853\n",
      "epoch: 41 loss: 1.6941999197006226 grad: 6.99692743286326\n",
      "epoch: 42 loss: 1.6973999738693237 grad: 6.860985648961061\n",
      "epoch: 43 loss: 1.7206687927246094 grad: 7.05403255559929\n",
      "epoch: 44 loss: 1.6920725107192993 grad: 6.10316898215526\n",
      "epoch: 45 loss: 1.6826139688491821 grad: 6.314087008414115\n",
      "epoch: 46 loss: 1.6745638847351074 grad: 6.694318389316669\n",
      "epoch: 47 loss: 1.6755598783493042 grad: 6.714806010851236\n",
      "epoch: 48 loss: 1.6632968187332153 grad: 6.263432196477273\n",
      "epoch: 49 loss: 1.673454999923706 grad: 6.7041439467335175\n",
      "epoch: 50 loss: 1.6802818775177002 grad: 7.037565101580445\n",
      "epoch: 51 loss: 1.6632964611053467 grad: 6.867175698609254\n",
      "epoch: 52 loss: 1.661112666130066 grad: 6.256471647879586\n",
      "epoch: 53 loss: 1.6604435443878174 grad: 6.42937691439297\n",
      "epoch: 54 loss: 1.6723254919052124 grad: 6.43136718343351\n",
      "epoch: 55 loss: 1.650045394897461 grad: 6.486442073836063\n",
      "epoch: 56 loss: 1.6724880933761597 grad: 7.3936135843150765\n",
      "epoch: 57 loss: 1.6720315217971802 grad: 7.258880647238656\n",
      "epoch: 58 loss: 1.6445404291152954 grad: 5.364739818331145\n",
      "epoch: 59 loss: 1.6503324508666992 grad: 6.123029741507563\n",
      "epoch: 60 loss: 1.6568127870559692 grad: 6.157748365892552\n",
      "epoch: 61 loss: 1.658592939376831 grad: 5.608957968647744\n",
      "epoch: 62 loss: 1.6452364921569824 grad: 6.526782234720414\n",
      "epoch: 63 loss: 1.651650071144104 grad: 6.681675416129154\n",
      "epoch: 64 loss: 1.64597487449646 grad: 5.334216569331364\n",
      "epoch: 65 loss: 1.6408671140670776 grad: 6.5562446193194654\n",
      "epoch: 66 loss: 1.646729826927185 grad: 6.127817593246575\n",
      "epoch: 67 loss: 1.6549272537231445 grad: 6.50701913429426\n",
      "epoch: 68 loss: 1.6436576843261719 grad: 5.856645452327535\n",
      "epoch: 69 loss: 1.6480276584625244 grad: 6.5041344249256365\n",
      "epoch: 70 loss: 1.6336630582809448 grad: 4.718886837790186\n",
      "epoch: 71 loss: 1.6290265321731567 grad: 5.797604752403299\n",
      "epoch: 72 loss: 1.6089515686035156 grad: 5.5630169077910345\n",
      "epoch: 73 loss: 1.6326956748962402 grad: 6.786764713458113\n",
      "epoch: 74 loss: 1.6322778463363647 grad: 5.381357603261489\n",
      "epoch: 75 loss: 1.6167083978652954 grad: 5.65708213876889\n",
      "epoch: 76 loss: 1.6335936784744263 grad: 5.397236698378471\n",
      "epoch: 77 loss: 1.6214485168457031 grad: 6.21200107376792\n",
      "epoch: 78 loss: 1.6259684562683105 grad: 6.266160541477196\n",
      "epoch: 79 loss: 1.6159729957580566 grad: 5.20699174895529\n",
      "epoch: 80 loss: 1.6289989948272705 grad: 5.718345466436793\n",
      "epoch: 81 loss: 1.630481481552124 grad: 6.045755096926725\n",
      "epoch: 82 loss: 1.6449989080429077 grad: 7.539016879232977\n",
      "epoch: 83 loss: 1.654343843460083 grad: 6.2247059937868645\n",
      "epoch: 84 loss: 1.6273940801620483 grad: 5.70325004303803\n",
      "epoch: 85 loss: 1.6377253532409668 grad: 5.1587092281692355\n",
      "epoch: 86 loss: 1.6249310970306396 grad: 5.43026908367623\n",
      "epoch: 87 loss: 1.6225004196166992 grad: 4.851440798027989\n",
      "epoch: 88 loss: 1.620957851409912 grad: 6.292575519022764\n",
      "epoch: 89 loss: 1.6035792827606201 grad: 5.822145007807339\n",
      "epoch: 90 loss: 1.5970920324325562 grad: 4.881366751830582\n",
      "epoch: 91 loss: 1.6030638217926025 grad: 6.079287557507794\n",
      "epoch: 92 loss: 1.623692274093628 grad: 5.827715746391083\n",
      "epoch: 93 loss: 1.5950926542282104 grad: 4.743739386759949\n",
      "epoch: 94 loss: 1.6069059371948242 grad: 4.961186185204883\n",
      "epoch: 95 loss: 1.6072322130203247 grad: 5.874997971833052\n",
      "epoch: 96 loss: 1.5877227783203125 grad: 5.126008722827609\n",
      "epoch: 97 loss: 1.6078184843063354 grad: 5.486448326331753\n",
      "epoch: 98 loss: 1.614012598991394 grad: 6.805677288571356\n",
      "epoch: 99 loss: 1.5991171598434448 grad: 4.629212126118243\n",
      "epoch: 100 loss: 1.6132985353469849 grad: 5.4514724161495645\n",
      "epoch: 101 loss: 1.6099646091461182 grad: 4.52516259735966\n",
      "epoch: 102 loss: 1.6056302785873413 grad: 5.849467768005976\n",
      "epoch: 103 loss: 1.608773946762085 grad: 5.054827506502988\n",
      "epoch: 104 loss: 1.604546308517456 grad: 6.123131469831072\n",
      "epoch: 105 loss: 1.6145730018615723 grad: 5.416173037508016\n",
      "epoch: 106 loss: 1.6014498472213745 grad: 4.6586546168369205\n",
      "epoch: 107 loss: 1.596822738647461 grad: 4.54935023499156\n",
      "epoch: 108 loss: 1.6006083488464355 grad: 4.603905046926518\n",
      "epoch: 109 loss: 1.6044732332229614 grad: 5.730689371255447\n",
      "epoch: 110 loss: 1.5977153778076172 grad: 5.106430666029651\n",
      "epoch: 111 loss: 1.610656976699829 grad: 4.590574136536181\n",
      "epoch: 112 loss: 1.593468189239502 grad: 4.20144277745507\n",
      "epoch: 113 loss: 1.5885733366012573 grad: 5.1298057466595495\n",
      "epoch: 114 loss: 1.6026968955993652 grad: 4.468600025114377\n",
      "epoch: 115 loss: 1.595583200454712 grad: 4.9744489768584295\n",
      "epoch: 116 loss: 1.5981965065002441 grad: 5.38662049035543\n",
      "epoch: 117 loss: 1.5890170335769653 grad: 5.042111894308008\n",
      "epoch: 118 loss: 1.5947308540344238 grad: 5.353299189262601\n",
      "epoch: 119 loss: 1.580986738204956 grad: 3.516914048912094\n",
      "epoch: 120 loss: 1.5824894905090332 grad: 4.824243171886178\n",
      "epoch: 121 loss: 1.6008001565933228 grad: 5.311642333447354\n",
      "epoch: 122 loss: 1.5918488502502441 grad: 5.8364303481792605\n",
      "epoch: 123 loss: 1.5871942043304443 grad: 4.774448319263362\n",
      "epoch: 124 loss: 1.5926105976104736 grad: 5.751079429466729\n",
      "epoch: 125 loss: 1.5886526107788086 grad: 5.465795576824225\n",
      "epoch: 126 loss: 1.5995227098464966 grad: 5.699757514765683\n",
      "epoch: 127 loss: 1.5837037563323975 grad: 5.472234464936726\n",
      "epoch: 128 loss: 1.604842185974121 grad: 6.062965629489561\n",
      "epoch: 129 loss: 1.5880448818206787 grad: 4.845363859167899\n",
      "epoch: 130 loss: 1.5838333368301392 grad: 6.197931060432517\n",
      "epoch: 131 loss: 1.595828890800476 grad: 5.20186840442494\n",
      "epoch: 132 loss: 1.5988391637802124 grad: 5.913349840951043\n",
      "epoch: 133 loss: 1.60551917552948 grad: 5.1213757385629295\n",
      "epoch: 134 loss: 1.5818506479263306 grad: 5.17114210368\n",
      "epoch: 135 loss: 1.5839837789535522 grad: 5.586061762251986\n",
      "epoch: 136 loss: 1.613210916519165 grad: 5.870077301121672\n",
      "epoch: 137 loss: 1.5872431993484497 grad: 5.095345309428133\n",
      "epoch: 138 loss: 1.568342924118042 grad: 3.939726312872197\n",
      "epoch: 139 loss: 1.5712924003601074 grad: 5.133236596450258\n",
      "epoch: 140 loss: 1.5954177379608154 grad: 4.291083280437825\n",
      "epoch: 141 loss: 1.5763295888900757 grad: 5.290779277805245\n",
      "epoch: 142 loss: 1.5903124809265137 grad: 5.125833508029419\n",
      "epoch: 143 loss: 1.5945762395858765 grad: 5.048083380281407\n",
      "epoch: 144 loss: 1.6034233570098877 grad: 6.137985946866722\n",
      "epoch: 145 loss: 1.5867805480957031 grad: 5.918245410713509\n",
      "epoch: 146 loss: 1.57004714012146 grad: 3.326192061731617\n",
      "epoch: 147 loss: 1.5626229047775269 grad: 4.876006511953486\n",
      "epoch: 148 loss: 1.5803754329681396 grad: 4.2674373501041405\n",
      "epoch: 149 loss: 1.5688207149505615 grad: 4.031275901779591\n",
      "epoch: 150 loss: 1.5790119171142578 grad: 5.123323881143479\n",
      "epoch: 151 loss: 1.579967737197876 grad: 4.344687996091355\n",
      "epoch: 152 loss: 1.5637987852096558 grad: 3.3492191916683147\n",
      "epoch: 153 loss: 1.5666433572769165 grad: 4.769480910580093\n",
      "epoch: 154 loss: 1.5802114009857178 grad: 5.2997779175769155\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 155 loss: 1.5743366479873657 grad: 4.244252546741515\n",
      "epoch: 156 loss: 1.5662009716033936 grad: 4.313566409773005\n",
      "epoch: 157 loss: 1.568056583404541 grad: 4.961707612115066\n",
      "epoch: 158 loss: 1.5886331796646118 grad: 5.045246852424624\n",
      "epoch: 159 loss: 1.581304907798767 grad: 4.944979343609442\n",
      "epoch: 160 loss: 1.581235647201538 grad: 4.802709523612885\n",
      "epoch: 161 loss: 1.576906681060791 grad: 5.884593377118257\n",
      "epoch: 162 loss: 1.6094712018966675 grad: 5.221110880450003\n",
      "epoch: 163 loss: 1.5739058256149292 grad: 4.269943418369089\n",
      "epoch: 164 loss: 1.5790488719940186 grad: 5.939712376364068\n",
      "epoch: 165 loss: 1.580384373664856 grad: 5.410269825127692\n",
      "epoch: 166 loss: 1.564089059829712 grad: 4.492059105347676\n",
      "epoch: 167 loss: 1.5670965909957886 grad: 5.152172381981205\n",
      "epoch: 168 loss: 1.5713552236557007 grad: 4.2346347714021935\n",
      "epoch: 169 loss: 1.572375774383545 grad: 5.055042858883394\n",
      "epoch: 170 loss: 1.562919020652771 grad: 4.7794954814862445\n",
      "epoch: 171 loss: 1.5629003047943115 grad: 4.861281741673875\n",
      "epoch: 172 loss: 1.5753164291381836 grad: 5.180018817074004\n",
      "epoch: 173 loss: 1.560839056968689 grad: 4.687591586662068\n",
      "epoch: 174 loss: 1.5572998523712158 grad: 4.966455157791601\n",
      "epoch: 175 loss: 1.5622981786727905 grad: 3.594619569528513\n",
      "epoch: 176 loss: 1.5748257637023926 grad: 5.506245912794787\n",
      "epoch: 177 loss: 1.5644299983978271 grad: 3.9701501387044433\n",
      "epoch: 178 loss: 1.577559232711792 grad: 4.623102490598387\n",
      "epoch: 179 loss: 1.5662809610366821 grad: 4.8391191961265365\n",
      "epoch: 180 loss: 1.5624113082885742 grad: 4.216756645104815\n",
      "epoch: 181 loss: 1.5618458986282349 grad: 3.791374103870049\n",
      "epoch: 182 loss: 1.5583012104034424 grad: 4.604378682047927\n",
      "epoch: 183 loss: 1.595048189163208 grad: 5.414424774048428\n",
      "epoch: 184 loss: 1.56728196144104 grad: 5.043352431228867\n",
      "epoch: 185 loss: 1.5536869764328003 grad: 3.068310945429951\n",
      "epoch: 186 loss: 1.566746711730957 grad: 4.739449122178196\n",
      "epoch: 187 loss: 1.5630110502243042 grad: 4.1455581538658\n",
      "epoch: 188 loss: 1.565677523612976 grad: 4.21285932272641\n",
      "epoch: 189 loss: 1.5588401556015015 grad: 3.52944822039139\n",
      "epoch: 190 loss: 1.5586791038513184 grad: 3.6324671309839696\n",
      "epoch: 191 loss: 1.5766565799713135 grad: 5.338227983848317\n",
      "epoch: 192 loss: 1.5687836408615112 grad: 4.662087939314294\n",
      "epoch: 193 loss: 1.5754344463348389 grad: 4.707587182133188\n",
      "epoch: 194 loss: 1.5675231218338013 grad: 4.132145087479774\n",
      "epoch: 195 loss: 1.5447040796279907 grad: 3.2820041563247426\n",
      "epoch: 196 loss: 1.5610934495925903 grad: 4.673218488854458\n",
      "epoch: 197 loss: 1.5553922653198242 grad: 4.02386770092656\n",
      "epoch: 198 loss: 1.5708892345428467 grad: 4.306404239972705\n",
      "epoch: 199 loss: 1.5648133754730225 grad: 4.124524942734332\n",
      "epoch: 200 loss: 1.572440266609192 grad: 4.494153949395004\n",
      "epoch: 201 loss: 1.552119493484497 grad: 3.7864247205712727\n",
      "epoch: 202 loss: 1.5597940683364868 grad: 3.8382198951910937\n",
      "epoch: 203 loss: 1.5647298097610474 grad: 4.663822701490839\n",
      "epoch: 204 loss: 1.569439172744751 grad: 4.090845169890476\n",
      "epoch: 205 loss: 1.5509308576583862 grad: 2.983633840071344\n",
      "epoch: 206 loss: 1.5617289543151855 grad: 3.9591391831925598\n",
      "epoch: 207 loss: 1.567144751548767 grad: 5.311532525008246\n",
      "epoch: 208 loss: 1.5711950063705444 grad: 4.891621730753813\n",
      "epoch: 209 loss: 1.5677025318145752 grad: 6.0297324994095325\n",
      "epoch: 210 loss: 1.567986249923706 grad: 3.866591796201307\n",
      "epoch: 211 loss: 1.5667951107025146 grad: 4.3696439797430005\n",
      "epoch: 212 loss: 1.5613653659820557 grad: 4.116631405611122\n",
      "epoch: 213 loss: 1.5740375518798828 grad: 5.519835528468333\n",
      "epoch: 214 loss: 1.563389778137207 grad: 3.236615542806168\n",
      "epoch: 215 loss: 1.5554510354995728 grad: 4.598828558735973\n",
      "epoch: 216 loss: 1.570573091506958 grad: 4.134810004089408\n",
      "epoch: 217 loss: 1.5797293186187744 grad: 5.036678183144619\n",
      "epoch: 218 loss: 1.5531208515167236 grad: 3.8591887866355967\n",
      "epoch: 219 loss: 1.5720754861831665 grad: 3.994786403936212\n",
      "epoch: 220 loss: 1.5777755975723267 grad: 4.971427470275937\n",
      "epoch: 221 loss: 1.5581179857254028 grad: 3.9946938821554654\n",
      "epoch: 222 loss: 1.5447921752929688 grad: 2.6795809542955986\n",
      "epoch: 223 loss: 1.5405845642089844 grad: 4.000943386220718\n",
      "epoch: 224 loss: 1.5443377494812012 grad: 2.8684303367122292\n",
      "epoch: 225 loss: 1.5577472448349 grad: 4.503151559536337\n",
      "epoch: 226 loss: 1.559592366218567 grad: 4.475225636761607\n",
      "epoch: 227 loss: 1.5594946146011353 grad: 3.6862218830964713\n",
      "epoch: 228 loss: 1.545837640762329 grad: 3.0224033122579366\n",
      "epoch: 229 loss: 1.551788568496704 grad: 2.9520164986695434\n",
      "epoch: 230 loss: 1.5458757877349854 grad: 2.692105528080028\n",
      "epoch: 231 loss: 1.552258849143982 grad: 4.226533478230778\n",
      "epoch: 232 loss: 1.5440889596939087 grad: 3.4179839843808266\n",
      "epoch: 233 loss: 1.5578458309173584 grad: 3.835647859915403\n",
      "epoch: 234 loss: 1.548954963684082 grad: 3.8227981383533436\n",
      "epoch: 235 loss: 1.5787216424942017 grad: 4.54948036829346\n",
      "epoch: 236 loss: 1.560242772102356 grad: 4.554477769896369\n",
      "epoch: 237 loss: 1.5716184377670288 grad: 4.612634119353066\n",
      "epoch: 238 loss: 1.5426381826400757 grad: 3.4134111457133343\n",
      "epoch: 239 loss: 1.5596747398376465 grad: 4.08591546492208\n",
      "epoch: 240 loss: 1.5490249395370483 grad: 3.610702356190038\n",
      "epoch: 241 loss: 1.5526037216186523 grad: 4.323540020983575\n",
      "epoch: 242 loss: 1.5481526851654053 grad: 4.030456020020156\n",
      "epoch: 243 loss: 1.564404010772705 grad: 3.9397096595975793\n",
      "epoch: 244 loss: 1.5551716089248657 grad: 4.157328064116554\n",
      "epoch: 245 loss: 1.564091444015503 grad: 3.6393377495344303\n",
      "epoch: 246 loss: 1.5623393058776855 grad: 4.173756930116498\n",
      "epoch: 247 loss: 1.5543906688690186 grad: 4.337475112905239\n",
      "epoch: 248 loss: 1.571484923362732 grad: 4.440858221616186\n",
      "epoch: 249 loss: 1.5605586767196655 grad: 4.698971111910225\n",
      "epoch: 250 loss: 1.5612894296646118 grad: 3.7260786860823534\n",
      "epoch: 251 loss: 1.5477185249328613 grad: 3.6787734922211106\n",
      "epoch: 252 loss: 1.5570136308670044 grad: 4.004692771819315\n",
      "epoch: 253 loss: 1.5531747341156006 grad: 3.840416897901376\n",
      "epoch: 254 loss: 1.5424644947052002 grad: 4.019195326001348\n",
      "epoch: 255 loss: 1.5476640462875366 grad: 3.596080795472288\n",
      "epoch: 256 loss: 1.5470592975616455 grad: 4.092667284139123\n",
      "epoch: 257 loss: 1.5537177324295044 grad: 4.276307642452174\n",
      "epoch: 258 loss: 1.546855092048645 grad: 3.3108287507939274\n",
      "epoch: 259 loss: 1.5470784902572632 grad: 3.44953675198031\n",
      "epoch: 260 loss: 1.547716498374939 grad: 3.0974137527969217\n",
      "epoch: 261 loss: 1.5525610446929932 grad: 4.978694027151316\n",
      "epoch: 262 loss: 1.5524369478225708 grad: 3.847904125874493\n",
      "epoch: 263 loss: 1.5475138425827026 grad: 3.5733118312463317\n",
      "epoch: 264 loss: 1.5568840503692627 grad: 4.2009698033527725\n",
      "epoch: 265 loss: 1.5586785078048706 grad: 4.347410288909672\n",
      "epoch: 266 loss: 1.5668689012527466 grad: 4.29595325123908\n",
      "epoch: 267 loss: 1.554301142692566 grad: 5.027825709692281\n",
      "epoch: 268 loss: 1.562250018119812 grad: 5.227629264930847\n",
      "epoch: 269 loss: 1.5340943336486816 grad: 3.058206869374475\n",
      "epoch: 270 loss: 1.554455041885376 grad: 4.219463433519804\n",
      "epoch: 271 loss: 1.5587786436080933 grad: 2.7074808996731194\n",
      "epoch: 272 loss: 1.5738517045974731 grad: 5.483517423977662\n",
      "epoch: 273 loss: 1.5561349391937256 grad: 4.782096683809133\n",
      "epoch: 274 loss: 1.5490472316741943 grad: 2.7970024560976414\n",
      "epoch: 275 loss: 1.5476200580596924 grad: 3.898861086481102\n",
      "epoch: 276 loss: 1.5400171279907227 grad: 3.0698766499533288\n",
      "epoch: 277 loss: 1.5397833585739136 grad: 3.3657375874223483\n",
      "epoch: 278 loss: 1.5445636510849 grad: 3.7280022074633523\n",
      "epoch: 279 loss: 1.5319498777389526 grad: 3.621813378302022\n",
      "epoch: 280 loss: 1.5420433282852173 grad: 3.2726410013744034\n",
      "epoch: 281 loss: 1.5605342388153076 grad: 3.0866254132832123\n",
      "epoch: 282 loss: 1.5407683849334717 grad: 2.927081133321197\n",
      "epoch: 283 loss: 1.5327260494232178 grad: 3.5170351793586465\n",
      "epoch: 284 loss: 1.5423619747161865 grad: 3.9608546959140583\n",
      "epoch: 285 loss: 1.5582318305969238 grad: 3.1594658382763323\n",
      "epoch: 286 loss: 1.5325729846954346 grad: 3.1005217826371387\n",
      "epoch: 287 loss: 1.5530678033828735 grad: 3.8842434248259994\n",
      "epoch: 288 loss: 1.5550246238708496 grad: 5.308177641621183\n",
      "epoch: 289 loss: 1.5426990985870361 grad: 3.558163099703046\n",
      "epoch: 290 loss: 1.554539442062378 grad: 3.505210956304417\n",
      "epoch: 291 loss: 1.545700192451477 grad: 3.357839029469466\n",
      "epoch: 292 loss: 1.5596985816955566 grad: 3.2765219420836393\n",
      "epoch: 293 loss: 1.5675609111785889 grad: 5.1282538738459325\n",
      "epoch: 294 loss: 1.5513033866882324 grad: 4.257448583770023\n",
      "epoch: 295 loss: 1.5352189540863037 grad: 2.97713739877022\n",
      "epoch: 296 loss: 1.5293155908584595 grad: 2.570208562865212\n",
      "epoch: 297 loss: 1.536865234375 grad: 3.2045578270547828\n",
      "epoch: 298 loss: 1.5458989143371582 grad: 3.6322714035045167\n",
      "epoch: 299 loss: 1.566222906112671 grad: 4.104792253390062\n",
      "epoch: 300 loss: 1.5603559017181396 grad: 4.441268231223931\n",
      "epoch: 301 loss: 1.5499836206436157 grad: 3.433700170180775\n",
      "epoch: 302 loss: 1.5391011238098145 grad: 3.388239622124526\n",
      "epoch: 303 loss: 1.540657639503479 grad: 3.4268504326886253\n",
      "epoch: 304 loss: 1.5408920049667358 grad: 3.0350302898333683\n",
      "epoch: 305 loss: 1.5353171825408936 grad: 2.8079413396136443\n",
      "epoch: 306 loss: 1.537685513496399 grad: 3.3732532873743732\n",
      "epoch: 307 loss: 1.5524967908859253 grad: 5.537893633423141\n",
      "epoch: 308 loss: 1.5691872835159302 grad: 3.777315648532806\n",
      "epoch: 309 loss: 1.5345195531845093 grad: 3.159704118104614\n",
      "epoch: 310 loss: 1.5398141145706177 grad: 2.8613064363507714\n",
      "epoch: 311 loss: 1.5313148498535156 grad: 2.659986470176747\n",
      "epoch: 312 loss: 1.5482765436172485 grad: 3.2531399955597022\n",
      "epoch: 313 loss: 1.5533342361450195 grad: 3.625598434422256\n",
      "epoch: 314 loss: 1.5416373014450073 grad: 2.807786826085857\n",
      "epoch: 315 loss: 1.547395944595337 grad: 3.411056494227193\n",
      "epoch: 316 loss: 1.5547490119934082 grad: 5.463158039519661\n",
      "epoch: 317 loss: 1.5470802783966064 grad: 3.869051963905558\n",
      "epoch: 318 loss: 1.539955496788025 grad: 2.7143347614126085\n",
      "epoch: 319 loss: 1.5407532453536987 grad: 2.403302590126711\n",
      "epoch: 320 loss: 1.5365712642669678 grad: 3.0943290523646563\n",
      "epoch: 321 loss: 1.5364996194839478 grad: 3.1642246373907903\n",
      "epoch: 322 loss: 1.5429471731185913 grad: 3.2838947401061356\n",
      "epoch: 323 loss: 1.5531851053237915 grad: 3.934909583583036\n",
      "epoch: 324 loss: 1.551329255104065 grad: 4.219317652437011\n",
      "epoch: 325 loss: 1.5471677780151367 grad: 3.8913868044774533\n",
      "epoch: 326 loss: 1.538210153579712 grad: 3.70275507344191\n",
      "epoch: 327 loss: 1.5423191785812378 grad: 4.840168310902249\n",
      "epoch: 328 loss: 1.5448932647705078 grad: 4.450069616348635\n",
      "epoch: 329 loss: 1.546807885169983 grad: 3.8501318296924842\n",
      "epoch: 330 loss: 1.526865839958191 grad: 4.498686407945162\n",
      "epoch: 331 loss: 1.55258309841156 grad: 4.537326880887916\n",
      "epoch: 332 loss: 1.5401495695114136 grad: 2.7070649126643156\n",
      "epoch: 333 loss: 1.5304511785507202 grad: 2.708940943010914\n",
      "epoch: 334 loss: 1.5201586484909058 grad: 1.830749127010301\n",
      "epoch: 335 loss: 1.5305567979812622 grad: 3.1646882785991384\n",
      "epoch: 336 loss: 1.543204426765442 grad: 3.981538200577148\n",
      "epoch: 337 loss: 1.5232504606246948 grad: 1.9252153720170564\n",
      "epoch: 338 loss: 1.5349973440170288 grad: 3.502372863855393\n",
      "epoch: 339 loss: 1.533853530883789 grad: 3.836283216743968\n",
      "epoch: 340 loss: 1.5692096948623657 grad: 3.7697359600875213\n",
      "epoch: 341 loss: 1.5357191562652588 grad: 3.638167303623361\n",
      "epoch: 342 loss: 1.5388067960739136 grad: 3.177646215971473\n",
      "epoch: 343 loss: 1.5653492212295532 grad: 4.216038268378536\n",
      "epoch: 344 loss: 1.537366509437561 grad: 2.9837070895833437\n",
      "epoch: 345 loss: 1.5539616346359253 grad: 4.059903027208764\n",
      "epoch: 346 loss: 1.5374785661697388 grad: 3.675804910398821\n",
      "epoch: 347 loss: 1.5393831729888916 grad: 3.641647593218467\n",
      "epoch: 348 loss: 1.540672779083252 grad: 3.2875382223954035\n",
      "epoch: 349 loss: 1.5486983060836792 grad: 3.4614017067696907\n",
      "epoch: 350 loss: 1.5643728971481323 grad: 3.7276807837639554\n",
      "epoch: 351 loss: 1.5374373197555542 grad: 4.232979536890761\n",
      "epoch: 352 loss: 1.5399099588394165 grad: 3.5129297642249817\n",
      "epoch: 353 loss: 1.5493334531784058 grad: 3.389289922135056\n",
      "epoch: 354 loss: 1.5268625020980835 grad: 4.1725140548958075\n",
      "epoch: 355 loss: 1.528695821762085 grad: 2.8503740616938593\n",
      "epoch: 356 loss: 1.5245580673217773 grad: 3.4147608730368075\n",
      "epoch: 357 loss: 1.5231460332870483 grad: 2.9719186474352672\n",
      "epoch: 358 loss: 1.5368802547454834 grad: 3.8672790207770897\n",
      "epoch: 359 loss: 1.5318354368209839 grad: 3.4374316948205434\n",
      "epoch: 360 loss: 1.54500412940979 grad: 4.161472725889859\n",
      "epoch: 361 loss: 1.5631277561187744 grad: 4.5107252684609485\n",
      "epoch: 362 loss: 1.5653048753738403 grad: 3.0796700753212853\n",
      "epoch: 363 loss: 1.530267357826233 grad: 3.1191123481150043\n",
      "epoch: 364 loss: 1.5213541984558105 grad: 2.3771750406323586\n",
      "epoch: 365 loss: 1.5314353704452515 grad: 3.740133641660252\n",
      "epoch: 366 loss: 1.542391300201416 grad: 4.102078150363725\n",
      "epoch: 367 loss: 1.558742880821228 grad: 3.9530607656454055\n",
      "epoch: 368 loss: 1.5372731685638428 grad: 3.2939799790886166\n",
      "epoch: 369 loss: 1.533803939819336 grad: 3.075477197409149\n",
      "epoch: 370 loss: 1.5401272773742676 grad: 4.547331628879457\n",
      "epoch: 371 loss: 1.5210723876953125 grad: 2.21539031350556\n",
      "epoch: 372 loss: 1.5240105390548706 grad: 3.0930975904163716\n",
      "epoch: 373 loss: 1.5423892736434937 grad: 3.2170839271542047\n",
      "epoch: 374 loss: 1.5307172536849976 grad: 3.8052635700243425\n",
      "epoch: 375 loss: 1.5437558889389038 grad: 3.752583807220654\n",
      "epoch: 376 loss: 1.5537241697311401 grad: 4.906527370365323\n",
      "epoch: 377 loss: 1.5291213989257812 grad: 2.865373496179873\n",
      "epoch: 378 loss: 1.5350863933563232 grad: 3.401047345220033\n",
      "epoch: 379 loss: 1.5433380603790283 grad: 3.734267912648962\n",
      "epoch: 380 loss: 1.52845299243927 grad: 2.8367464206817\n",
      "epoch: 381 loss: 1.5313642024993896 grad: 2.7942570865674075\n",
      "epoch: 382 loss: 1.533611536026001 grad: 2.9593794421569224\n",
      "epoch: 383 loss: 1.54169499874115 grad: 3.5026819970732492\n",
      "epoch: 384 loss: 1.5425355434417725 grad: 4.533277288829861\n",
      "epoch: 385 loss: 1.5384577512741089 grad: 4.039438209468498\n",
      "epoch: 386 loss: 1.553807020187378 grad: 3.5344881398569483\n",
      "epoch: 387 loss: 1.533553957939148 grad: 3.962860559045086\n",
      "epoch: 388 loss: 1.5359070301055908 grad: 3.0302256808871757\n",
      "epoch: 389 loss: 1.5315322875976562 grad: 2.8113764763518896\n",
      "epoch: 390 loss: 1.5282783508300781 grad: 3.329186889193047\n",
      "epoch: 391 loss: 1.5312755107879639 grad: 2.688708435458936\n",
      "epoch: 392 loss: 1.5452643632888794 grad: 4.396989777855127\n",
      "epoch: 393 loss: 1.5406601428985596 grad: 3.169798968528135\n",
      "epoch: 394 loss: 1.5395978689193726 grad: 3.267553476339572\n",
      "epoch: 395 loss: 1.528517723083496 grad: 3.0111802987573224\n",
      "epoch: 396 loss: 1.5219770669937134 grad: 3.0024898825113215\n",
      "epoch: 397 loss: 1.5223156213760376 grad: 2.1724919935655085\n",
      "epoch: 398 loss: 1.5405213832855225 grad: 3.2513295847656436\n",
      "epoch: 399 loss: 1.523149847984314 grad: 3.5644281562622346\n",
      "epoch: 400 loss: 1.530773401260376 grad: 2.6804426896450755\n",
      "epoch: 401 loss: 1.5242983102798462 grad: 2.396335186652313\n",
      "epoch: 402 loss: 1.5302097797393799 grad: 2.9752412956665073\n",
      "epoch: 403 loss: 1.5255850553512573 grad: 2.6139814114489686\n",
      "epoch: 404 loss: 1.5364437103271484 grad: 3.682432849627035\n",
      "epoch: 405 loss: 1.5348137617111206 grad: 4.077369053617302\n",
      "epoch: 406 loss: 1.5294386148452759 grad: 2.6080787349176524\n",
      "epoch: 407 loss: 1.5228632688522339 grad: 2.7879262543025027\n",
      "epoch: 408 loss: 1.523148775100708 grad: 3.221116781745963\n",
      "epoch: 409 loss: 1.5427311658859253 grad: 4.560778506243638\n",
      "epoch: 410 loss: 1.5348917245864868 grad: 2.4421974451428543\n",
      "epoch: 411 loss: 1.5288101434707642 grad: 3.182415486023882\n",
      "epoch: 412 loss: 1.533717393875122 grad: 3.525002209818299\n",
      "epoch: 413 loss: 1.517343521118164 grad: 3.0940777718232217\n",
      "epoch: 414 loss: 1.569737434387207 grad: 3.863454663795264\n",
      "epoch: 415 loss: 1.5399360656738281 grad: 3.13438799604171\n",
      "epoch: 416 loss: 1.525376558303833 grad: 3.1740457549143777\n",
      "epoch: 417 loss: 1.518639087677002 grad: 3.0140323124352713\n",
      "epoch: 418 loss: 1.550093650817871 grad: 3.201881045205214\n",
      "epoch: 419 loss: 1.529853343963623 grad: 3.0552009833600304\n",
      "epoch: 420 loss: 1.5210833549499512 grad: 2.786949942429849\n",
      "epoch: 421 loss: 1.5179272890090942 grad: 3.0989180331738617\n",
      "epoch: 422 loss: 1.53519868850708 grad: 2.7369010740810764\n",
      "epoch: 423 loss: 1.5349853038787842 grad: 4.175017580503329\n",
      "epoch: 424 loss: 1.5446045398712158 grad: 4.350190650505491\n",
      "epoch: 425 loss: 1.53151535987854 grad: 2.5837452967682295\n",
      "epoch: 426 loss: 1.5373735427856445 grad: 3.057482326207592\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 427 loss: 1.5306220054626465 grad: 2.623732346672181\n",
      "epoch: 428 loss: 1.5399634838104248 grad: 2.3869910058573747\n",
      "epoch: 429 loss: 1.5348151922225952 grad: 3.450960762073221\n",
      "epoch: 430 loss: 1.5355839729309082 grad: 4.090099089800547\n",
      "epoch: 431 loss: 1.5360146760940552 grad: 3.826483815900681\n",
      "epoch: 432 loss: 1.5260828733444214 grad: 3.103111974601568\n",
      "epoch: 433 loss: 1.538710594177246 grad: 3.607186201904912\n",
      "epoch: 434 loss: 1.5379538536071777 grad: 3.1353279982547453\n",
      "epoch: 435 loss: 1.533647060394287 grad: 3.091812642077545\n",
      "epoch: 436 loss: 1.5253418684005737 grad: 2.136877765326349\n",
      "epoch: 437 loss: 1.5164049863815308 grad: 2.814269539295683\n",
      "epoch: 438 loss: 1.5163218975067139 grad: 1.7785745314469958\n",
      "epoch: 439 loss: 1.5283225774765015 grad: 2.4674323683515933\n",
      "epoch: 440 loss: 1.528419017791748 grad: 2.954318677963084\n",
      "epoch: 441 loss: 1.525913953781128 grad: 3.235158739764947\n",
      "epoch: 442 loss: 1.5292556285858154 grad: 3.9972439853912007\n",
      "epoch: 443 loss: 1.5231654644012451 grad: 2.779007434369846\n",
      "epoch: 444 loss: 1.530147671699524 grad: 3.566740378425239\n",
      "epoch: 445 loss: 1.5381418466567993 grad: 3.5870224125285497\n",
      "epoch: 446 loss: 1.5224695205688477 grad: 3.285593513096216\n",
      "epoch: 447 loss: 1.5240685939788818 grad: 2.4634887198126547\n",
      "epoch: 448 loss: 1.5266273021697998 grad: 2.2300687096044793\n",
      "epoch: 449 loss: 1.5204267501831055 grad: 2.073167209853745\n",
      "epoch: 450 loss: 1.5211485624313354 grad: 2.83079390173548\n",
      "epoch: 451 loss: 1.5168085098266602 grad: 1.901665372095389\n",
      "epoch: 452 loss: 1.5248767137527466 grad: 2.691157267672732\n",
      "epoch: 453 loss: 1.5288084745407104 grad: 2.6947300967147862\n",
      "epoch: 454 loss: 1.5214513540267944 grad: 1.7382808134617387\n",
      "epoch: 455 loss: 1.5359216928482056 grad: 4.3280447200192524\n",
      "epoch: 456 loss: 1.5277554988861084 grad: 2.715734554478212\n",
      "epoch: 457 loss: 1.529366135597229 grad: 2.7367735425903907\n",
      "epoch: 458 loss: 1.5204405784606934 grad: 2.2761411717007274\n",
      "epoch: 459 loss: 1.523343563079834 grad: 4.490984726470829\n",
      "epoch: 460 loss: 1.557652473449707 grad: 3.3996829506046704\n",
      "epoch: 461 loss: 1.5314358472824097 grad: 2.561895813287506\n",
      "epoch: 462 loss: 1.5269968509674072 grad: 2.1767665519554282\n",
      "epoch: 463 loss: 1.534995198249817 grad: 4.909322349739094\n",
      "epoch: 464 loss: 1.5588488578796387 grad: 2.7121948675519527\n",
      "epoch: 465 loss: 1.5345584154129028 grad: 2.701801961221575\n",
      "epoch: 466 loss: 1.5459572076797485 grad: 2.7271051640616184\n",
      "epoch: 467 loss: 1.5315862894058228 grad: 4.657763711773726\n",
      "epoch: 468 loss: 1.5434315204620361 grad: 2.6594458724723626\n",
      "epoch: 469 loss: 1.529194951057434 grad: 2.2741206365619924\n",
      "epoch: 470 loss: 1.5224571228027344 grad: 3.7517079746180824\n",
      "epoch: 471 loss: 1.534028172492981 grad: 2.9734124253075933\n",
      "epoch: 472 loss: 1.5186601877212524 grad: 2.714989870186247\n",
      "epoch: 473 loss: 1.5219351053237915 grad: 2.7491391038504727\n",
      "epoch: 474 loss: 1.5271427631378174 grad: 3.7928963966989655\n",
      "epoch: 475 loss: 1.5250276327133179 grad: 2.710552705996484\n",
      "epoch: 476 loss: 1.5255794525146484 grad: 3.0054058005789486\n",
      "epoch: 477 loss: 1.5251169204711914 grad: 2.806087699481847\n",
      "epoch: 478 loss: 1.5279579162597656 grad: 4.206588838584662\n",
      "epoch: 479 loss: 1.5220674276351929 grad: 4.413209783587644\n",
      "epoch: 480 loss: 1.5540192127227783 grad: 4.223650053375166\n",
      "epoch: 481 loss: 1.523680329322815 grad: 2.61678202556211\n",
      "epoch: 482 loss: 1.5253193378448486 grad: 3.0991195749794858\n",
      "epoch: 483 loss: 1.5140801668167114 grad: 1.4222640223028102\n",
      "epoch: 484 loss: 1.5267845392227173 grad: 2.3632883175949213\n",
      "epoch: 485 loss: 1.5251092910766602 grad: 3.338015332429804\n",
      "epoch: 486 loss: 1.5177143812179565 grad: 2.9440418722092643\n",
      "epoch: 487 loss: 1.5290732383728027 grad: 2.392312191959074\n",
      "epoch: 488 loss: 1.526474118232727 grad: 3.0345955992278872\n",
      "epoch: 489 loss: 1.5185059309005737 grad: 2.819565699908487\n",
      "epoch: 490 loss: 1.5145442485809326 grad: 2.4204535470073614\n",
      "epoch: 491 loss: 1.5307663679122925 grad: 3.2283869748513174\n",
      "epoch: 492 loss: 1.5204046964645386 grad: 1.8626420232084289\n",
      "epoch: 493 loss: 1.5165767669677734 grad: 1.3465838459548956\n",
      "epoch: 494 loss: 1.515800952911377 grad: 1.8578052900246238\n",
      "epoch: 495 loss: 1.5194568634033203 grad: 2.6894162129254564\n",
      "epoch: 496 loss: 1.5313698053359985 grad: 2.4628775560157408\n",
      "epoch: 497 loss: 1.5069644451141357 grad: 1.2663694154096141\n",
      "epoch: 498 loss: 1.5097675323486328 grad: 2.4129137458210574\n",
      "epoch: 499 loss: 1.5234036445617676 grad: 2.502688871183416\n",
      "1.8362243920564651\n",
      "epoch: 0 loss: 2.3032541275024414 grad: 1.3402037591976483\n",
      "epoch: 1 loss: 2.30273175239563 grad: 1.340077292251711\n",
      "epoch: 2 loss: 2.302889347076416 grad: 1.3432833427592876\n",
      "epoch: 3 loss: 2.302593469619751 grad: 1.3445353438405112\n",
      "epoch: 4 loss: 2.302929162979126 grad: 1.3359000187529813\n",
      "epoch: 5 loss: 2.303192377090454 grad: 1.3384854638771642\n",
      "epoch: 6 loss: 2.302598714828491 grad: 1.3383838148928056\n",
      "epoch: 7 loss: 2.303138256072998 grad: 1.3433058184501345\n",
      "epoch: 8 loss: 2.3025856018066406 grad: 1.3379339611320387\n",
      "epoch: 9 loss: 2.3028836250305176 grad: 1.3346095793540516\n",
      "epoch: 10 loss: 2.3024961948394775 grad: 1.3496949298026424\n",
      "epoch: 11 loss: 2.3029301166534424 grad: 1.3419829041249902\n",
      "epoch: 12 loss: 2.302682399749756 grad: 1.3379592776376132\n",
      "epoch: 13 loss: 2.3022990226745605 grad: 1.344781516855287\n",
      "epoch: 14 loss: 2.302818775177002 grad: 1.3451666520568468\n",
      "epoch: 15 loss: 2.303030014038086 grad: 1.3362299693186606\n",
      "epoch: 16 loss: 2.302598476409912 grad: 1.3461110738165203\n",
      "epoch: 17 loss: 2.3027148246765137 grad: 1.3368634406942874\n",
      "epoch: 18 loss: 2.3028311729431152 grad: 1.3325925851998377\n",
      "epoch: 19 loss: 2.30295991897583 grad: 1.3406901133231937\n",
      "epoch: 20 loss: 2.3025336265563965 grad: 1.343970982526015\n",
      "epoch: 21 loss: 2.302644729614258 grad: 1.3384422505558986\n",
      "epoch: 22 loss: 2.3020434379577637 grad: 1.3474744056861492\n",
      "epoch: 23 loss: 2.30268931388855 grad: 1.3471942985511667\n",
      "epoch: 24 loss: 2.302438497543335 grad: 1.345726672608021\n",
      "epoch: 25 loss: 2.3025271892547607 grad: 1.357934879471681\n",
      "epoch: 26 loss: 2.3024871349334717 grad: 1.3413073026338622\n",
      "epoch: 27 loss: 2.303100109100342 grad: 1.3315469749726443\n",
      "epoch: 28 loss: 2.302654504776001 grad: 1.3383349504392033\n",
      "epoch: 29 loss: 2.3023078441619873 grad: 1.3450606495219593\n",
      "epoch: 30 loss: 2.3017354011535645 grad: 1.3456920033915796\n",
      "epoch: 31 loss: 2.3027145862579346 grad: 1.342256614273148\n",
      "epoch: 32 loss: 2.302670955657959 grad: 1.338653283576215\n",
      "epoch: 33 loss: 2.3018202781677246 grad: 1.3464051398674086\n",
      "epoch: 34 loss: 2.3030452728271484 grad: 1.3334203614494837\n",
      "epoch: 35 loss: 2.3025996685028076 grad: 1.3380419816932685\n",
      "epoch: 36 loss: 2.3027162551879883 grad: 1.328914729708303\n",
      "epoch: 37 loss: 2.302579879760742 grad: 1.3261656980325898\n",
      "epoch: 38 loss: 2.30273699760437 grad: 1.33049114160831\n",
      "epoch: 39 loss: 2.302318572998047 grad: 1.340775451199743\n",
      "epoch: 40 loss: 2.3031063079833984 grad: 1.3317513164273271\n",
      "epoch: 41 loss: 2.3030436038970947 grad: 1.3396801026667364\n",
      "epoch: 42 loss: 2.3029065132141113 grad: 1.3198340628000478\n",
      "epoch: 43 loss: 2.303104877471924 grad: 1.3329567122753592\n",
      "epoch: 44 loss: 2.3026790618896484 grad: 1.3407283302060224\n",
      "epoch: 45 loss: 2.302825689315796 grad: 1.323743706173633\n",
      "epoch: 46 loss: 2.3029119968414307 grad: 1.3259353984834714\n",
      "epoch: 47 loss: 2.3025619983673096 grad: 1.3407825392500927\n",
      "epoch: 48 loss: 2.302643060684204 grad: 1.3225339343401765\n",
      "epoch: 49 loss: 2.3027260303497314 grad: 1.3308539584515586\n",
      "epoch: 50 loss: 2.3026843070983887 grad: 1.3426415684618174\n",
      "epoch: 51 loss: 2.302217483520508 grad: 1.332448023753906\n",
      "epoch: 52 loss: 2.3026487827301025 grad: 1.3373201997887845\n",
      "epoch: 53 loss: 2.30279541015625 grad: 1.3221807964016787\n",
      "epoch: 54 loss: 2.302659034729004 grad: 1.3267758840635893\n",
      "epoch: 55 loss: 2.3030412197113037 grad: 1.3200639653488964\n",
      "epoch: 56 loss: 2.302685022354126 grad: 1.3272599729391494\n",
      "epoch: 57 loss: 2.3023393154144287 grad: 1.3357826286209895\n",
      "epoch: 58 loss: 2.30237078666687 grad: 1.3330138085265866\n",
      "epoch: 59 loss: 2.302280902862549 grad: 1.3426423522677007\n",
      "epoch: 60 loss: 2.3030076026916504 grad: 1.3239055078861022\n",
      "epoch: 61 loss: 2.3029606342315674 grad: 1.3346275924741926\n",
      "epoch: 62 loss: 2.302839517593384 grad: 1.3230145741087784\n",
      "epoch: 63 loss: 2.3024234771728516 grad: 1.3327326707852383\n",
      "epoch: 64 loss: 2.3024890422821045 grad: 1.331932328569348\n",
      "epoch: 65 loss: 2.302460193634033 grad: 1.3213396308489056\n",
      "epoch: 66 loss: 2.303135871887207 grad: 1.3177025838762462\n",
      "epoch: 67 loss: 2.3028671741485596 grad: 1.3338200492481331\n",
      "epoch: 68 loss: 2.302905559539795 grad: 1.32353812388684\n",
      "epoch: 69 loss: 2.3024449348449707 grad: 1.3389238437512032\n",
      "epoch: 70 loss: 2.302568197250366 grad: 1.3311009423563345\n",
      "epoch: 71 loss: 2.302622079849243 grad: 1.3367608080133944\n",
      "epoch: 72 loss: 2.302885055541992 grad: 1.3273132162479062\n",
      "epoch: 73 loss: 2.3023011684417725 grad: 1.3414125216289585\n",
      "epoch: 74 loss: 2.302487373352051 grad: 1.336750764373897\n",
      "epoch: 75 loss: 2.3024232387542725 grad: 1.3325009462423623\n",
      "epoch: 76 loss: 2.3021514415740967 grad: 1.3353748050692034\n",
      "epoch: 77 loss: 2.3024685382843018 grad: 1.3196480295635642\n",
      "epoch: 78 loss: 2.3025498390197754 grad: 1.3244338768944588\n",
      "epoch: 79 loss: 2.302495241165161 grad: 1.3236610458550295\n",
      "epoch: 80 loss: 2.302837371826172 grad: 1.3220190913139267\n",
      "epoch: 81 loss: 2.302175760269165 grad: 1.3350619318606776\n",
      "epoch: 82 loss: 2.30285906791687 grad: 1.3284932818034634\n",
      "epoch: 83 loss: 2.3018746376037598 grad: 1.3327883751693343\n",
      "epoch: 84 loss: 2.302574872970581 grad: 1.321354785592236\n",
      "epoch: 85 loss: 2.302785634994507 grad: 1.3253550390705526\n",
      "epoch: 86 loss: 2.302206516265869 grad: 1.3387455179888224\n",
      "epoch: 87 loss: 2.3027842044830322 grad: 1.3250666138464733\n",
      "epoch: 88 loss: 2.302248001098633 grad: 1.3403059625388345\n",
      "epoch: 89 loss: 2.3026137351989746 grad: 1.3277189841693533\n",
      "epoch: 90 loss: 2.3024473190307617 grad: 1.3360603152892538\n",
      "epoch: 91 loss: 2.3024330139160156 grad: 1.3384694555656067\n",
      "epoch: 92 loss: 2.30203914642334 grad: 1.3419248841107927\n",
      "epoch: 93 loss: 2.303100109100342 grad: 1.3226074480880348\n",
      "epoch: 94 loss: 2.3026630878448486 grad: 1.3235028078650228\n",
      "epoch: 95 loss: 2.302992582321167 grad: 1.329239523938177\n",
      "epoch: 96 loss: 2.3022847175598145 grad: 1.3389954651347435\n",
      "epoch: 97 loss: 2.302619695663452 grad: 1.3302341465974996\n",
      "epoch: 98 loss: 2.302260160446167 grad: 1.335473890671329\n",
      "epoch: 99 loss: 2.302311658859253 grad: 1.3229823041899456\n",
      "epoch: 100 loss: 2.3031866550445557 grad: 1.3127230833643042\n",
      "epoch: 101 loss: 2.302672863006592 grad: 1.3278613868465146\n",
      "epoch: 102 loss: 2.3024489879608154 grad: 1.3277195978481027\n",
      "epoch: 103 loss: 2.302064895629883 grad: 1.3311354959150776\n",
      "epoch: 104 loss: 2.302337884902954 grad: 1.3333979334002213\n",
      "epoch: 105 loss: 2.302225112915039 grad: 1.3346146340334109\n",
      "epoch: 106 loss: 2.302178144454956 grad: 1.3371403110915765\n",
      "epoch: 107 loss: 2.3025012016296387 grad: 1.3205261271602164\n",
      "epoch: 108 loss: 2.3020083904266357 grad: 1.3292922279649666\n",
      "epoch: 109 loss: 2.3025894165039062 grad: 1.328735151710654\n",
      "epoch: 110 loss: 2.302706003189087 grad: 1.320962160559637\n",
      "epoch: 111 loss: 2.3028509616851807 grad: 1.3231409332726063\n",
      "epoch: 112 loss: 2.302863836288452 grad: 1.337930500773447\n",
      "epoch: 113 loss: 2.3029396533966064 grad: 1.3220918036346871\n",
      "epoch: 114 loss: 2.302826166152954 grad: 1.3271622538330063\n",
      "epoch: 115 loss: 2.302271604537964 grad: 1.3336157767408867\n",
      "epoch: 116 loss: 2.3027446269989014 grad: 1.3296630072873086\n",
      "epoch: 117 loss: 2.3023552894592285 grad: 1.3296805258308138\n",
      "epoch: 118 loss: 2.302077293395996 grad: 1.3390265164142918\n",
      "epoch: 119 loss: 2.3027849197387695 grad: 1.3314780294876694\n",
      "epoch: 120 loss: 2.302351951599121 grad: 1.3244325963702674\n",
      "epoch: 121 loss: 2.3021786212921143 grad: 1.3298313375932003\n",
      "epoch: 122 loss: 2.302790880203247 grad: 1.3240595932695127\n",
      "epoch: 123 loss: 2.3022637367248535 grad: 1.3232111161729943\n",
      "epoch: 124 loss: 2.3028504848480225 grad: 1.3145352447634593\n",
      "epoch: 125 loss: 2.302778482437134 grad: 1.3217100877987429\n",
      "epoch: 126 loss: 2.3022663593292236 grad: 1.3378377257594987\n",
      "epoch: 127 loss: 2.3022491931915283 grad: 1.338738556324859\n",
      "epoch: 128 loss: 2.3024744987487793 grad: 1.3349525582392714\n",
      "epoch: 129 loss: 2.3025341033935547 grad: 1.3245770652752578\n",
      "epoch: 130 loss: 2.3018648624420166 grad: 1.3454468405236386\n",
      "epoch: 131 loss: 2.3026559352874756 grad: 1.3263115769156093\n",
      "epoch: 132 loss: 2.303067922592163 grad: 1.3194019893805187\n",
      "epoch: 133 loss: 2.302077054977417 grad: 1.3348009697464664\n",
      "epoch: 134 loss: 2.301754951477051 grad: 1.3291864105322886\n",
      "epoch: 135 loss: 2.302633762359619 grad: 1.333034764871829\n",
      "epoch: 136 loss: 2.302447557449341 grad: 1.3276674021922408\n",
      "epoch: 137 loss: 2.3023715019226074 grad: 1.3276696365829261\n",
      "epoch: 138 loss: 2.3017330169677734 grad: 1.33673599777588\n",
      "epoch: 139 loss: 2.302388906478882 grad: 1.3393704978941334\n",
      "epoch: 140 loss: 2.3023977279663086 grad: 1.329723998638136\n",
      "epoch: 141 loss: 2.302671194076538 grad: 1.3246993425612648\n",
      "epoch: 142 loss: 2.302288770675659 grad: 1.3280470011781693\n",
      "epoch: 143 loss: 2.3014256954193115 grad: 1.3408370669690952\n",
      "epoch: 144 loss: 2.3020365238189697 grad: 1.342293088498067\n",
      "epoch: 145 loss: 2.302572011947632 grad: 1.3254076247602435\n",
      "epoch: 146 loss: 2.302069902420044 grad: 1.3424859890115581\n",
      "epoch: 147 loss: 2.302105188369751 grad: 1.3358941414053478\n",
      "epoch: 148 loss: 2.3023924827575684 grad: 1.3200039141737516\n",
      "epoch: 149 loss: 2.3019657135009766 grad: 1.3439651552646878\n",
      "epoch: 150 loss: 2.302194595336914 grad: 1.3364112201102434\n",
      "epoch: 151 loss: 2.301689863204956 grad: 1.3375342229163156\n",
      "epoch: 152 loss: 2.3021950721740723 grad: 1.3301362715742833\n",
      "epoch: 153 loss: 2.3020646572113037 grad: 1.3389059200731388\n",
      "epoch: 154 loss: 2.3020107746124268 grad: 1.3368161177033528\n",
      "epoch: 155 loss: 2.301798105239868 grad: 1.3345162102357588\n",
      "epoch: 156 loss: 2.3014369010925293 grad: 1.3439959573803382\n",
      "epoch: 157 loss: 2.3025083541870117 grad: 1.3246017484186543\n",
      "epoch: 158 loss: 2.302596092224121 grad: 1.3272846623523427\n",
      "epoch: 159 loss: 2.3023619651794434 grad: 1.3272173412528538\n",
      "epoch: 160 loss: 2.3016271591186523 grad: 1.3375612826064407\n",
      "epoch: 161 loss: 2.3022043704986572 grad: 1.333455386264841\n",
      "epoch: 162 loss: 2.3024938106536865 grad: 1.3357062729367513\n",
      "epoch: 163 loss: 2.301386833190918 grad: 1.3452419345248638\n",
      "epoch: 164 loss: 2.302957057952881 grad: 1.3269593477700024\n",
      "epoch: 165 loss: 2.302736282348633 grad: 1.329912061507385\n",
      "epoch: 166 loss: 2.3022079467773438 grad: 1.3230004710559216\n",
      "epoch: 167 loss: 2.3020968437194824 grad: 1.336688947364954\n",
      "epoch: 168 loss: 2.302201271057129 grad: 1.3277246162613174\n",
      "epoch: 169 loss: 2.3016819953918457 grad: 1.3447511713020504\n",
      "epoch: 170 loss: 2.301830530166626 grad: 1.3318315285317126\n",
      "epoch: 171 loss: 2.302558422088623 grad: 1.331653885643131\n",
      "epoch: 172 loss: 2.3021795749664307 grad: 1.3415555684598133\n",
      "epoch: 173 loss: 2.301495313644409 grad: 1.3510696603768757\n",
      "epoch: 174 loss: 2.3020453453063965 grad: 1.3379855370407716\n",
      "epoch: 175 loss: 2.3021457195281982 grad: 1.3351410281593128\n",
      "epoch: 176 loss: 2.3023054599761963 grad: 1.3288495035136179\n",
      "epoch: 177 loss: 2.3017146587371826 grad: 1.3488382250957547\n",
      "epoch: 178 loss: 2.302408218383789 grad: 1.3237178253253834\n",
      "epoch: 179 loss: 2.3014988899230957 grad: 1.355521774714044\n",
      "epoch: 180 loss: 2.3017685413360596 grad: 1.3452404778864648\n",
      "epoch: 181 loss: 2.302814245223999 grad: 1.3223643213998348\n",
      "epoch: 182 loss: 2.3019022941589355 grad: 1.3413777199263375\n",
      "epoch: 183 loss: 2.3019981384277344 grad: 1.340462776569886\n",
      "epoch: 184 loss: 2.3019702434539795 grad: 1.3441314380301812\n",
      "epoch: 185 loss: 2.3020200729370117 grad: 1.3389213276723961\n",
      "epoch: 186 loss: 2.3015105724334717 grad: 1.3448364546980769\n",
      "epoch: 187 loss: 2.3013172149658203 grad: 1.3532533116974972\n",
      "epoch: 188 loss: 2.3023743629455566 grad: 1.3423152098299138\n",
      "epoch: 189 loss: 2.302685499191284 grad: 1.328270594970072\n",
      "epoch: 190 loss: 2.3022654056549072 grad: 1.3382023222825772\n",
      "epoch: 191 loss: 2.302367687225342 grad: 1.341068096242712\n",
      "epoch: 192 loss: 2.301560640335083 grad: 1.3346448941895412\n",
      "epoch: 193 loss: 2.30112886428833 grad: 1.3599486802667675\n",
      "epoch: 194 loss: 2.3018267154693604 grad: 1.3333599031274577\n",
      "epoch: 195 loss: 2.301522970199585 grad: 1.3389948916599332\n",
      "epoch: 196 loss: 2.3015899658203125 grad: 1.3536554251202486\n",
      "epoch: 197 loss: 2.3023459911346436 grad: 1.3367181725315898\n",
      "epoch: 198 loss: 2.3017191886901855 grad: 1.3495701249348857\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 199 loss: 2.3020541667938232 grad: 1.338414006419332\n",
      "epoch: 200 loss: 2.302339553833008 grad: 1.3353314619744197\n",
      "epoch: 201 loss: 2.3016912937164307 grad: 1.3460319235325895\n",
      "epoch: 202 loss: 2.3014795780181885 grad: 1.3454407346416413\n",
      "epoch: 203 loss: 2.3020544052124023 grad: 1.3481088464022688\n",
      "epoch: 204 loss: 2.3013720512390137 grad: 1.3578672896320414\n",
      "epoch: 205 loss: 2.3015596866607666 grad: 1.3604167538088938\n",
      "epoch: 206 loss: 2.3011152744293213 grad: 1.354843639179192\n",
      "epoch: 207 loss: 2.3013789653778076 grad: 1.3562073214201344\n",
      "epoch: 208 loss: 2.30163836479187 grad: 1.3481212113374135\n",
      "epoch: 209 loss: 2.3017172813415527 grad: 1.3436027479077142\n",
      "epoch: 210 loss: 2.301795244216919 grad: 1.350453031722397\n",
      "epoch: 211 loss: 2.301253318786621 grad: 1.3582921227188929\n",
      "epoch: 212 loss: 2.301645040512085 grad: 1.3463944698913053\n",
      "epoch: 213 loss: 2.3017776012420654 grad: 1.3517229160153499\n",
      "epoch: 214 loss: 2.301060914993286 grad: 1.3654018676385196\n",
      "epoch: 215 loss: 2.301492929458618 grad: 1.3548110757976592\n",
      "epoch: 216 loss: 2.3012168407440186 grad: 1.367529838907695\n",
      "epoch: 217 loss: 2.3019213676452637 grad: 1.3510630322169395\n",
      "epoch: 218 loss: 2.3014912605285645 grad: 1.353643640302979\n",
      "epoch: 219 loss: 2.301513910293579 grad: 1.3597438038393324\n",
      "epoch: 220 loss: 2.3020896911621094 grad: 1.3419637730130778\n",
      "epoch: 221 loss: 2.3012239933013916 grad: 1.355929507208722\n",
      "epoch: 222 loss: 2.3022499084472656 grad: 1.3503950786433139\n",
      "epoch: 223 loss: 2.3009984493255615 grad: 1.3677955023807635\n",
      "epoch: 224 loss: 2.301478624343872 grad: 1.3590977233335642\n",
      "epoch: 225 loss: 2.3020284175872803 grad: 1.3468390520355324\n",
      "epoch: 226 loss: 2.301743268966675 grad: 1.3566181411789286\n",
      "epoch: 227 loss: 2.301337718963623 grad: 1.3798539763434776\n",
      "epoch: 228 loss: 2.30186128616333 grad: 1.3537448844909372\n",
      "epoch: 229 loss: 2.3013548851013184 grad: 1.3745035643593246\n",
      "epoch: 230 loss: 2.301645278930664 grad: 1.3590324984730355\n",
      "epoch: 231 loss: 2.3019285202026367 grad: 1.3691810542821057\n",
      "epoch: 232 loss: 2.3014822006225586 grad: 1.3582768975147268\n",
      "epoch: 233 loss: 2.301765203475952 grad: 1.369183613150011\n",
      "epoch: 234 loss: 2.3006341457366943 grad: 1.3711161898423194\n",
      "epoch: 235 loss: 2.3014965057373047 grad: 1.3616129183432175\n",
      "epoch: 236 loss: 2.3013250827789307 grad: 1.368284493252369\n",
      "epoch: 237 loss: 2.301487684249878 grad: 1.3707327709888064\n",
      "epoch: 238 loss: 2.30126690864563 grad: 1.3660650439449542\n",
      "epoch: 239 loss: 2.301567792892456 grad: 1.361389929046189\n",
      "epoch: 240 loss: 2.301358461380005 grad: 1.376025209839027\n",
      "epoch: 241 loss: 2.3013510704040527 grad: 1.3632961123597822\n",
      "epoch: 242 loss: 2.3014719486236572 grad: 1.372912116581574\n",
      "epoch: 243 loss: 2.301316261291504 grad: 1.363880134520254\n",
      "epoch: 244 loss: 2.3009605407714844 grad: 1.377778007597145\n",
      "epoch: 245 loss: 2.301693916320801 grad: 1.3665541609719631\n",
      "epoch: 246 loss: 2.300954818725586 grad: 1.385354903354753\n",
      "epoch: 247 loss: 2.3013463020324707 grad: 1.377676600353822\n",
      "epoch: 248 loss: 2.3008735179901123 grad: 1.3894000104979598\n",
      "epoch: 249 loss: 2.3012237548828125 grad: 1.3818249241356546\n",
      "epoch: 250 loss: 2.3010122776031494 grad: 1.3776255516697549\n",
      "epoch: 251 loss: 2.3005218505859375 grad: 1.388206123339293\n",
      "epoch: 252 loss: 2.3011090755462646 grad: 1.382570495415065\n",
      "epoch: 253 loss: 2.301370143890381 grad: 1.3881647713955432\n",
      "epoch: 254 loss: 2.30126690864563 grad: 1.3827285452280194\n",
      "epoch: 255 loss: 2.301379680633545 grad: 1.39081593698615\n",
      "epoch: 256 loss: 2.3009443283081055 grad: 1.3892016694807108\n",
      "epoch: 257 loss: 2.3013784885406494 grad: 1.3879668679114223\n",
      "epoch: 258 loss: 2.301241397857666 grad: 1.3855905989554549\n",
      "epoch: 259 loss: 2.300708770751953 grad: 1.4000132970275387\n",
      "epoch: 260 loss: 2.300750255584717 grad: 1.4112761301369154\n",
      "epoch: 261 loss: 2.301485300064087 grad: 1.3781031123953797\n",
      "epoch: 262 loss: 2.300746202468872 grad: 1.4035265729984356\n",
      "epoch: 263 loss: 2.30029296875 grad: 1.4164078639827609\n",
      "epoch: 264 loss: 2.301377296447754 grad: 1.397096303276836\n",
      "epoch: 265 loss: 2.3010005950927734 grad: 1.399874385217175\n",
      "epoch: 266 loss: 2.300651788711548 grad: 1.4179287847271929\n",
      "epoch: 267 loss: 2.3004438877105713 grad: 1.4152060303234657\n",
      "epoch: 268 loss: 2.30039644241333 grad: 1.4295616623195302\n",
      "epoch: 269 loss: 2.3005874156951904 grad: 1.4103968675536591\n",
      "epoch: 270 loss: 2.3014183044433594 grad: 1.4072280516995797\n",
      "epoch: 271 loss: 2.3002352714538574 grad: 1.4186765762611426\n",
      "epoch: 272 loss: 2.300851345062256 grad: 1.4096670044652586\n",
      "epoch: 273 loss: 2.3002538681030273 grad: 1.429597862338322\n",
      "epoch: 274 loss: 2.300837755203247 grad: 1.4313331830503775\n",
      "epoch: 275 loss: 2.3002030849456787 grad: 1.4207171931315863\n",
      "epoch: 276 loss: 2.300398349761963 grad: 1.4334306643004455\n",
      "epoch: 277 loss: 2.300551414489746 grad: 1.4287058704953997\n",
      "epoch: 278 loss: 2.29972505569458 grad: 1.4430031458522001\n",
      "epoch: 279 loss: 2.299579381942749 grad: 1.4444597503927994\n",
      "epoch: 280 loss: 2.3002398014068604 grad: 1.4451438151724962\n",
      "epoch: 281 loss: 2.29975962638855 grad: 1.4624209911155972\n",
      "epoch: 282 loss: 2.300366163253784 grad: 1.447955930132478\n",
      "epoch: 283 loss: 2.2995946407318115 grad: 1.4634361133895932\n",
      "epoch: 284 loss: 2.2999744415283203 grad: 1.4572170301033776\n",
      "epoch: 285 loss: 2.300264596939087 grad: 1.4615857565409638\n",
      "epoch: 286 loss: 2.299833297729492 grad: 1.4772561705626903\n",
      "epoch: 287 loss: 2.30010724067688 grad: 1.4622577487616726\n",
      "epoch: 288 loss: 2.300139904022217 grad: 1.4622032305055728\n",
      "epoch: 289 loss: 2.300760269165039 grad: 1.4536233455744676\n",
      "epoch: 290 loss: 2.299666166305542 grad: 1.4793030123063733\n",
      "epoch: 291 loss: 2.299886465072632 grad: 1.4671592451890723\n",
      "epoch: 292 loss: 2.299499750137329 grad: 1.478930227794788\n",
      "epoch: 293 loss: 2.299793243408203 grad: 1.492246274799404\n",
      "epoch: 294 loss: 2.299272060394287 grad: 1.490478252173431\n",
      "epoch: 295 loss: 2.299889326095581 grad: 1.506148588852883\n",
      "epoch: 296 loss: 2.299600601196289 grad: 1.5177791931052944\n",
      "epoch: 297 loss: 2.2995104789733887 grad: 1.5038990499969158\n",
      "epoch: 298 loss: 2.2995500564575195 grad: 1.5117656965998725\n",
      "epoch: 299 loss: 2.2994465827941895 grad: 1.528489120821986\n",
      "epoch: 300 loss: 2.299485206604004 grad: 1.5268381996309415\n",
      "epoch: 301 loss: 2.299074649810791 grad: 1.5330537976216643\n",
      "epoch: 302 loss: 2.2994003295898438 grad: 1.524415198739411\n",
      "epoch: 303 loss: 2.2981841564178467 grad: 1.5646768073987452\n",
      "epoch: 304 loss: 2.2986671924591064 grad: 1.562476605117794\n",
      "epoch: 305 loss: 2.2986679077148438 grad: 1.5697345793217656\n",
      "epoch: 306 loss: 2.298130989074707 grad: 1.590522539783417\n",
      "epoch: 307 loss: 2.2979209423065186 grad: 1.5861269798026316\n",
      "epoch: 308 loss: 2.2989351749420166 grad: 1.594796468828997\n",
      "epoch: 309 loss: 2.296929359436035 grad: 1.663003240283283\n",
      "epoch: 310 loss: 2.298197031021118 grad: 1.626735603178127\n",
      "epoch: 311 loss: 2.2973718643188477 grad: 1.6307324819887679\n",
      "epoch: 312 loss: 2.297159433364868 grad: 1.6378532448923955\n",
      "epoch: 313 loss: 2.2981696128845215 grad: 1.6385330336042754\n",
      "epoch: 314 loss: 2.2971882820129395 grad: 1.6722716184421664\n",
      "epoch: 315 loss: 2.2976789474487305 grad: 1.6673232524559671\n",
      "epoch: 316 loss: 2.2976438999176025 grad: 1.667006103388433\n",
      "epoch: 317 loss: 2.296957492828369 grad: 1.6784235041751157\n",
      "epoch: 318 loss: 2.2958691120147705 grad: 1.7351175543504753\n",
      "epoch: 319 loss: 2.296961784362793 grad: 1.7269246433584375\n",
      "epoch: 320 loss: 2.294651508331299 grad: 1.781260449627769\n",
      "epoch: 321 loss: 2.296549081802368 grad: 1.7528505654865136\n",
      "epoch: 322 loss: 2.2956910133361816 grad: 1.7710555917768191\n",
      "epoch: 323 loss: 2.2952017784118652 grad: 1.8211144961431505\n",
      "epoch: 324 loss: 2.2949814796447754 grad: 1.8347668469188705\n",
      "epoch: 325 loss: 2.293931722640991 grad: 1.8889818330081032\n",
      "epoch: 326 loss: 2.2937591075897217 grad: 1.889788366113198\n",
      "epoch: 327 loss: 2.2924416065216064 grad: 1.9068169622785516\n",
      "epoch: 328 loss: 2.2918524742126465 grad: 1.9895458708568994\n",
      "epoch: 329 loss: 2.290726900100708 grad: 1.9951687109774896\n",
      "epoch: 330 loss: 2.291093349456787 grad: 2.0284944338639015\n",
      "epoch: 331 loss: 2.2904467582702637 grad: 2.037509040212229\n",
      "epoch: 332 loss: 2.290146827697754 grad: 2.0545101325759396\n",
      "epoch: 333 loss: 2.2875661849975586 grad: 2.145403371924268\n",
      "epoch: 334 loss: 2.288295030593872 grad: 2.172481141751632\n",
      "epoch: 335 loss: 2.287372350692749 grad: 2.1785920871872575\n",
      "epoch: 336 loss: 2.2849910259246826 grad: 2.2225456843780917\n",
      "epoch: 337 loss: 2.2847115993499756 grad: 2.2336957067849914\n",
      "epoch: 338 loss: 2.2843177318573 grad: 2.2887426977515193\n",
      "epoch: 339 loss: 2.2828123569488525 grad: 2.2679741872393246\n",
      "epoch: 340 loss: 2.282534122467041 grad: 2.3633294239388927\n",
      "epoch: 341 loss: 2.278430938720703 grad: 2.311934563142824\n",
      "epoch: 342 loss: 2.2753891944885254 grad: 2.326940810111987\n",
      "epoch: 343 loss: 2.274888515472412 grad: 2.3055605028149864\n",
      "epoch: 344 loss: 2.275663137435913 grad: 2.336543161052442\n",
      "epoch: 345 loss: 2.2737982273101807 grad: 2.2737363377190563\n",
      "epoch: 346 loss: 2.2714571952819824 grad: 2.2238312916948444\n",
      "epoch: 347 loss: 2.2703661918640137 grad: 2.2003553013986212\n",
      "epoch: 348 loss: 2.268841505050659 grad: 2.2552514136140602\n",
      "epoch: 349 loss: 2.2684547901153564 grad: 2.215277996596082\n",
      "epoch: 350 loss: 2.2674524784088135 grad: 2.2064617612170028\n",
      "epoch: 351 loss: 2.264176368713379 grad: 2.1603911440036008\n",
      "epoch: 352 loss: 2.262596368789673 grad: 2.0425961661717986\n",
      "epoch: 353 loss: 2.263298988342285 grad: 2.1067869737171496\n",
      "epoch: 354 loss: 2.2603960037231445 grad: 2.0226093643522334\n",
      "epoch: 355 loss: 2.261664390563965 grad: 2.0772710749454473\n",
      "epoch: 356 loss: 2.259721279144287 grad: 2.016127042812369\n",
      "epoch: 357 loss: 2.2598183155059814 grad: 2.0039489980461815\n",
      "epoch: 358 loss: 2.25675630569458 grad: 1.9868013773442408\n",
      "epoch: 359 loss: 2.2560596466064453 grad: 1.9314003802211364\n",
      "epoch: 360 loss: 2.256392002105713 grad: 1.9014227899707972\n",
      "epoch: 361 loss: 2.2558414936065674 grad: 1.8636578015377006\n",
      "epoch: 362 loss: 2.2547459602355957 grad: 1.8615165091644499\n",
      "epoch: 363 loss: 2.253852605819702 grad: 1.8805029797367752\n",
      "epoch: 364 loss: 2.2532384395599365 grad: 1.835988281919281\n",
      "epoch: 365 loss: 2.2529077529907227 grad: 1.7931938470149087\n",
      "epoch: 366 loss: 2.25030779838562 grad: 1.6995444565656639\n",
      "epoch: 367 loss: 2.24953293800354 grad: 1.77221909285863\n",
      "epoch: 368 loss: 2.249666452407837 grad: 1.720859284695637\n",
      "epoch: 369 loss: 2.2499704360961914 grad: 1.7283244092010022\n",
      "epoch: 370 loss: 2.2500436305999756 grad: 1.72008720640507\n",
      "epoch: 371 loss: 2.2481789588928223 grad: 1.6736019242680558\n",
      "epoch: 372 loss: 2.2500414848327637 grad: 1.7388230274959897\n",
      "epoch: 373 loss: 2.2477619647979736 grad: 1.6727416717968437\n",
      "epoch: 374 loss: 2.2482388019561768 grad: 1.6716352630377052\n",
      "epoch: 375 loss: 2.247014284133911 grad: 1.6599659590320366\n",
      "epoch: 376 loss: 2.243471622467041 grad: 1.5064693881006586\n",
      "epoch: 377 loss: 2.244861602783203 grad: 1.5534909083193817\n",
      "epoch: 378 loss: 2.247044801712036 grad: 1.597916342493605\n",
      "epoch: 379 loss: 2.2453668117523193 grad: 1.571284013303248\n",
      "epoch: 380 loss: 2.2447311878204346 grad: 1.5858174612863907\n",
      "epoch: 381 loss: 2.2449984550476074 grad: 1.5685495726749419\n",
      "epoch: 382 loss: 2.2438650131225586 grad: 1.5430814094974525\n",
      "epoch: 383 loss: 2.2419052124023438 grad: 1.4619222119956883\n",
      "epoch: 384 loss: 2.242046356201172 grad: 1.5033975685540113\n",
      "epoch: 385 loss: 2.24153733253479 grad: 1.4788491156003956\n",
      "epoch: 386 loss: 2.24373459815979 grad: 1.542888919026443\n",
      "epoch: 387 loss: 2.2414090633392334 grad: 1.45412903738999\n",
      "epoch: 388 loss: 2.242648124694824 grad: 1.5431776867517906\n",
      "epoch: 389 loss: 2.241004228591919 grad: 1.4156183407841516\n",
      "epoch: 390 loss: 2.2416577339172363 grad: 1.5458649341275708\n",
      "epoch: 391 loss: 2.241210699081421 grad: 1.4567357000843104\n",
      "epoch: 392 loss: 2.2407593727111816 grad: 1.4280971531379258\n",
      "epoch: 393 loss: 2.240349531173706 grad: 1.4384765468559981\n",
      "epoch: 394 loss: 2.241424322128296 grad: 1.4832805493026084\n",
      "epoch: 395 loss: 2.239811897277832 grad: 1.4282719183044272\n",
      "epoch: 396 loss: 2.2395637035369873 grad: 1.4562906749446742\n",
      "epoch: 397 loss: 2.238199472427368 grad: 1.3664689998674606\n",
      "epoch: 398 loss: 2.238657236099243 grad: 1.4239149923964833\n",
      "epoch: 399 loss: 2.239107847213745 grad: 1.412608701345836\n",
      "epoch: 400 loss: 2.23797345161438 grad: 1.3388243345395914\n",
      "epoch: 401 loss: 2.237963914871216 grad: 1.3956504533739968\n",
      "epoch: 402 loss: 2.240334987640381 grad: 1.48869658013924\n",
      "epoch: 403 loss: 2.2392783164978027 grad: 1.5018924843678843\n",
      "epoch: 404 loss: 2.2386975288391113 grad: 1.4351692539990866\n",
      "epoch: 405 loss: 2.239133834838867 grad: 1.4175737990447068\n",
      "epoch: 406 loss: 2.2373507022857666 grad: 1.3769012370279856\n",
      "epoch: 407 loss: 2.237159252166748 grad: 1.3411453638820805\n",
      "epoch: 408 loss: 2.236286163330078 grad: 1.3558812131440001\n",
      "epoch: 409 loss: 2.236509323120117 grad: 1.3330877267955137\n",
      "epoch: 410 loss: 2.2390482425689697 grad: 1.4999881394185304\n",
      "epoch: 411 loss: 2.2369494438171387 grad: 1.3887130199702427\n",
      "epoch: 412 loss: 2.2370245456695557 grad: 1.457443948921984\n",
      "epoch: 413 loss: 2.237703561782837 grad: 1.4634714690776216\n",
      "epoch: 414 loss: 2.2359306812286377 grad: 1.3695565087883363\n",
      "epoch: 415 loss: 2.235379457473755 grad: 1.3363945562085728\n",
      "epoch: 416 loss: 2.2363827228546143 grad: 1.4106128218838767\n",
      "epoch: 417 loss: 2.2362048625946045 grad: 1.4054721788732365\n",
      "epoch: 418 loss: 2.235787868499756 grad: 1.4126203778506596\n",
      "epoch: 419 loss: 2.235424757003784 grad: 1.3629611200072789\n",
      "epoch: 420 loss: 2.234311580657959 grad: 1.318617229567959\n",
      "epoch: 421 loss: 2.2357990741729736 grad: 1.418501173120199\n",
      "epoch: 422 loss: 2.233365297317505 grad: 1.2426610454114981\n",
      "epoch: 423 loss: 2.23372745513916 grad: 1.2969304745451413\n",
      "epoch: 424 loss: 2.235628128051758 grad: 1.488641983273232\n",
      "epoch: 425 loss: 2.233410120010376 grad: 1.2915223884204077\n",
      "epoch: 426 loss: 2.2344460487365723 grad: 1.3834319933805437\n",
      "epoch: 427 loss: 2.2347426414489746 grad: 1.4383238355355663\n",
      "epoch: 428 loss: 2.2333052158355713 grad: 1.3392774347263936\n",
      "epoch: 429 loss: 2.234614610671997 grad: 1.3910988794809709\n",
      "epoch: 430 loss: 2.234434127807617 grad: 1.3554633702816707\n",
      "epoch: 431 loss: 2.2339189052581787 grad: 1.3111089826118023\n",
      "epoch: 432 loss: 2.232243537902832 grad: 1.275094085635381\n",
      "epoch: 433 loss: 2.232382297515869 grad: 1.3486039295260395\n",
      "epoch: 434 loss: 2.2327539920806885 grad: 1.243219554021452\n",
      "epoch: 435 loss: 2.2332475185394287 grad: 1.3819542480706577\n",
      "epoch: 436 loss: 2.2328546047210693 grad: 1.306455676133434\n",
      "epoch: 437 loss: 2.2317898273468018 grad: 1.2705090408442572\n",
      "epoch: 438 loss: 2.2338781356811523 grad: 1.4606023166450628\n",
      "epoch: 439 loss: 2.232513904571533 grad: 1.2952978426575779\n",
      "epoch: 440 loss: 2.232313394546509 grad: 1.2526959941670712\n",
      "epoch: 441 loss: 2.232985019683838 grad: 1.3675382190978982\n",
      "epoch: 442 loss: 2.232609987258911 grad: 1.330439585355288\n",
      "epoch: 443 loss: 2.2321674823760986 grad: 1.345078966613593\n",
      "epoch: 444 loss: 2.231302261352539 grad: 1.318456879779992\n",
      "epoch: 445 loss: 2.231160879135132 grad: 1.2996297827071792\n",
      "epoch: 446 loss: 2.2327768802642822 grad: 1.3377297195709414\n",
      "epoch: 447 loss: 2.2322440147399902 grad: 1.3550879116399244\n",
      "epoch: 448 loss: 2.2316155433654785 grad: 1.3456917586366808\n",
      "epoch: 449 loss: 2.2315447330474854 grad: 1.317568410250787\n",
      "epoch: 450 loss: 2.230041742324829 grad: 1.2330059159273608\n",
      "epoch: 451 loss: 2.230654001235962 grad: 1.2730064815287256\n",
      "epoch: 452 loss: 2.2303638458251953 grad: 1.2675616614768164\n",
      "epoch: 453 loss: 2.2310233116149902 grad: 1.3397215862614325\n",
      "epoch: 454 loss: 2.230823040008545 grad: 1.342961213331566\n",
      "epoch: 455 loss: 2.2293593883514404 grad: 1.2731105870925747\n",
      "epoch: 456 loss: 2.230837821960449 grad: 1.3032676526973586\n",
      "epoch: 457 loss: 2.2306039333343506 grad: 1.3324188974515965\n",
      "epoch: 458 loss: 2.2294774055480957 grad: 1.2514097601607708\n",
      "epoch: 459 loss: 2.2292251586914062 grad: 1.2846780090504104\n",
      "epoch: 460 loss: 2.2314014434814453 grad: 1.3388160297828209\n",
      "epoch: 461 loss: 2.230283737182617 grad: 1.3248198493420782\n",
      "epoch: 462 loss: 2.229495048522949 grad: 1.2664403185776865\n",
      "epoch: 463 loss: 2.2300431728363037 grad: 1.2803165434826431\n",
      "epoch: 464 loss: 2.2294483184814453 grad: 1.2773985650523432\n",
      "epoch: 465 loss: 2.230015277862549 grad: 1.2629621323800484\n",
      "epoch: 466 loss: 2.2298200130462646 grad: 1.2467316348929816\n",
      "epoch: 467 loss: 2.2299156188964844 grad: 1.2825777380845496\n",
      "epoch: 468 loss: 2.22956919670105 grad: 1.2592167863677743\n",
      "epoch: 469 loss: 2.2287914752960205 grad: 1.275883040693958\n",
      "epoch: 470 loss: 2.2290854454040527 grad: 1.3282106339613655\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 471 loss: 2.2286789417266846 grad: 1.243531241150026\n",
      "epoch: 472 loss: 2.2296338081359863 grad: 1.3113427041634356\n",
      "epoch: 473 loss: 2.2286505699157715 grad: 1.3375173177984025\n",
      "epoch: 474 loss: 2.2286109924316406 grad: 1.2289933252115068\n",
      "epoch: 475 loss: 2.2280707359313965 grad: 1.2382032597596417\n",
      "epoch: 476 loss: 2.2278008460998535 grad: 1.2893035757643658\n",
      "epoch: 477 loss: 2.2285163402557373 grad: 1.2933506998935684\n",
      "epoch: 478 loss: 2.2283380031585693 grad: 1.2878050737430355\n",
      "epoch: 479 loss: 2.2286860942840576 grad: 1.2480620441012202\n",
      "epoch: 480 loss: 2.2282216548919678 grad: 1.3067939989970967\n",
      "epoch: 481 loss: 2.2285571098327637 grad: 1.3058527322312343\n",
      "epoch: 482 loss: 2.2267367839813232 grad: 1.2148527831674392\n",
      "epoch: 483 loss: 2.2292556762695312 grad: 1.3628645946219977\n",
      "epoch: 484 loss: 2.22751784324646 grad: 1.2652983341924107\n",
      "epoch: 485 loss: 2.2274367809295654 grad: 1.302831401963467\n",
      "epoch: 486 loss: 2.2283895015716553 grad: 1.286994079985316\n",
      "epoch: 487 loss: 2.227308750152588 grad: 1.2118024163129222\n",
      "epoch: 488 loss: 2.227728843688965 grad: 1.2768536489290585\n",
      "epoch: 489 loss: 2.2272958755493164 grad: 1.2420942809447528\n",
      "epoch: 490 loss: 2.2275381088256836 grad: 1.31404217906178\n",
      "epoch: 491 loss: 2.2269039154052734 grad: 1.2000989654445133\n",
      "epoch: 492 loss: 2.228003978729248 grad: 1.310427914393903\n",
      "epoch: 493 loss: 2.228865623474121 grad: 1.3782608412568353\n",
      "epoch: 494 loss: 2.226393222808838 grad: 1.2740852272818013\n",
      "epoch: 495 loss: 2.2262959480285645 grad: 1.2205847884022025\n",
      "epoch: 496 loss: 2.2271153926849365 grad: 1.204394517087614\n",
      "epoch: 497 loss: 2.226769208908081 grad: 1.2998477410107467\n",
      "epoch: 498 loss: 2.2275660037994385 grad: 1.354993636551727\n",
      "epoch: 499 loss: 2.2265329360961914 grad: 1.2816017883430635\n",
      "2.253906488418579\n",
      "epoch: 0 loss: 2.3035030364990234 grad: 1.2350888122519892\n",
      "epoch: 1 loss: 2.303128242492676 grad: 1.2130635218909158\n",
      "epoch: 2 loss: 2.30264949798584 grad: 1.1956324980313342\n",
      "epoch: 3 loss: 2.3023760318756104 grad: 1.1956317611703915\n",
      "epoch: 4 loss: 2.3025686740875244 grad: 1.183114806177198\n",
      "epoch: 5 loss: 2.302086591720581 grad: 1.1783794156656349\n",
      "epoch: 6 loss: 2.3022279739379883 grad: 1.1865508868543815\n",
      "epoch: 7 loss: 2.3026657104492188 grad: 1.1754186330085976\n",
      "epoch: 8 loss: 2.3007609844207764 grad: 1.1952850805237032\n",
      "epoch: 9 loss: 2.30100154876709 grad: 1.1922456420374117\n",
      "epoch: 10 loss: 2.299140453338623 grad: 1.2164134434886307\n",
      "epoch: 11 loss: 2.2988879680633545 grad: 1.2291048070866732\n",
      "epoch: 12 loss: 2.297377586364746 grad: 1.266231686002501\n",
      "epoch: 13 loss: 2.295522928237915 grad: 1.3054711220726845\n",
      "epoch: 14 loss: 2.294673442840576 grad: 1.3493106872626832\n",
      "epoch: 15 loss: 2.2924280166625977 grad: 1.385501467027805\n",
      "epoch: 16 loss: 2.2920262813568115 grad: 1.4222638940490369\n",
      "epoch: 17 loss: 2.289391040802002 grad: 1.5093116830805287\n",
      "epoch: 18 loss: 2.286114454269409 grad: 1.5908987184225152\n",
      "epoch: 19 loss: 2.281184434890747 grad: 1.7800926836429252\n",
      "epoch: 20 loss: 2.2681026458740234 grad: 1.9078158534331513\n",
      "epoch: 21 loss: 2.253973960876465 grad: 1.7540879801196594\n",
      "epoch: 22 loss: 2.249084234237671 grad: 1.5998498359140718\n",
      "epoch: 23 loss: 2.2431373596191406 grad: 1.4369869779884106\n",
      "epoch: 24 loss: 2.2398605346679688 grad: 1.3384608264535753\n",
      "epoch: 25 loss: 2.236694097518921 grad: 1.2130173551702192\n",
      "epoch: 26 loss: 2.235746383666992 grad: 1.2641020302535109\n",
      "epoch: 27 loss: 2.234077215194702 grad: 1.252280883319188\n",
      "epoch: 28 loss: 2.2324941158294678 grad: 1.2213737574989894\n",
      "epoch: 29 loss: 2.230311870574951 grad: 1.2215715838829055\n",
      "epoch: 30 loss: 2.229724884033203 grad: 1.2458395004366702\n",
      "epoch: 31 loss: 2.2286758422851562 grad: 1.3634896286899993\n",
      "epoch: 32 loss: 2.224862813949585 grad: 1.3274524513824237\n",
      "epoch: 33 loss: 2.22420072555542 grad: 1.3973272942304094\n",
      "epoch: 34 loss: 2.2213351726531982 grad: 1.5529340165168313\n",
      "epoch: 35 loss: 2.220045804977417 grad: 1.5920653620740355\n",
      "epoch: 36 loss: 2.2173280715942383 grad: 1.6791848015605606\n",
      "epoch: 37 loss: 2.2138655185699463 grad: 1.6950019083433001\n",
      "epoch: 38 loss: 2.210012197494507 grad: 1.8749895324239447\n",
      "epoch: 39 loss: 2.207117795944214 grad: 1.9034878672045168\n",
      "epoch: 40 loss: 2.2023329734802246 grad: 1.9761940343582647\n",
      "epoch: 41 loss: 2.2027456760406494 grad: 2.0333884613059965\n",
      "epoch: 42 loss: 2.196692943572998 grad: 2.0215305839886977\n",
      "epoch: 43 loss: 2.196528673171997 grad: 1.9854741119114416\n",
      "epoch: 44 loss: 2.1936123371124268 grad: 1.9416093841677398\n",
      "epoch: 45 loss: 2.191359043121338 grad: 1.9861316088612915\n",
      "epoch: 46 loss: 2.1889548301696777 grad: 1.9455435114934863\n",
      "epoch: 47 loss: 2.184730052947998 grad: 2.018155304302964\n",
      "epoch: 48 loss: 2.1869235038757324 grad: 2.1514988863334383\n",
      "epoch: 49 loss: 2.1856298446655273 grad: 2.09113335912855\n",
      "epoch: 50 loss: 2.18442440032959 grad: 2.0763442921193525\n",
      "epoch: 51 loss: 2.179715871810913 grad: 2.128529152797816\n",
      "epoch: 52 loss: 2.1778042316436768 grad: 2.2228024838610536\n",
      "epoch: 53 loss: 2.1780011653900146 grad: 2.21236782287994\n",
      "epoch: 54 loss: 2.1747798919677734 grad: 2.3005788445007056\n",
      "epoch: 55 loss: 2.1747772693634033 grad: 2.157623868962262\n",
      "epoch: 56 loss: 2.176766872406006 grad: 2.256074546925014\n",
      "epoch: 57 loss: 2.173816680908203 grad: 2.4062865718530255\n",
      "epoch: 58 loss: 2.1710565090179443 grad: 2.2154604293080786\n",
      "epoch: 59 loss: 2.1682369709014893 grad: 2.209595333271113\n",
      "epoch: 60 loss: 2.1666672229766846 grad: 2.3990758132403864\n",
      "epoch: 61 loss: 2.168602705001831 grad: 2.399484843119151\n",
      "epoch: 62 loss: 2.166041135787964 grad: 2.3684878515334624\n",
      "epoch: 63 loss: 2.165888786315918 grad: 2.4012450237226273\n",
      "epoch: 64 loss: 2.1648356914520264 grad: 2.3692213946580147\n",
      "epoch: 65 loss: 2.1634533405303955 grad: 2.458094999050012\n",
      "epoch: 66 loss: 2.1634368896484375 grad: 2.4491891768698153\n",
      "epoch: 67 loss: 2.1598222255706787 grad: 2.3416986963046447\n",
      "epoch: 68 loss: 2.158647298812866 grad: 2.516439354263379\n",
      "epoch: 69 loss: 2.1616404056549072 grad: 2.6272947636122503\n",
      "epoch: 70 loss: 2.1608073711395264 grad: 2.5106593065872964\n",
      "epoch: 71 loss: 2.1563291549682617 grad: 2.273100631997093\n",
      "epoch: 72 loss: 2.1574971675872803 grad: 2.7217385062877653\n",
      "epoch: 73 loss: 2.1541948318481445 grad: 2.5889668367573964\n",
      "epoch: 74 loss: 2.1576316356658936 grad: 2.7760655919555575\n",
      "epoch: 75 loss: 2.154221534729004 grad: 2.6159535039083233\n",
      "epoch: 76 loss: 2.155061960220337 grad: 2.7182050739869563\n",
      "epoch: 77 loss: 2.1516177654266357 grad: 2.750964556628513\n",
      "epoch: 78 loss: 2.1523597240448 grad: 2.899275721021233\n",
      "epoch: 79 loss: 2.1497459411621094 grad: 2.496914564341765\n",
      "epoch: 80 loss: 2.152818441390991 grad: 2.69916630713343\n",
      "epoch: 81 loss: 2.150022029876709 grad: 2.9530211454312805\n",
      "epoch: 82 loss: 2.152743339538574 grad: 2.8543797826934014\n",
      "epoch: 83 loss: 2.148611307144165 grad: 2.736007994785535\n",
      "epoch: 84 loss: 2.14717960357666 grad: 2.690755364568239\n",
      "epoch: 85 loss: 2.1452932357788086 grad: 2.8681467308030864\n",
      "epoch: 86 loss: 2.1477768421173096 grad: 2.8637780362984078\n",
      "epoch: 87 loss: 2.144827365875244 grad: 2.9468998127701944\n",
      "epoch: 88 loss: 2.146939516067505 grad: 2.8127768450760327\n",
      "epoch: 89 loss: 2.1448280811309814 grad: 2.879343884660759\n",
      "epoch: 90 loss: 2.1469991207122803 grad: 3.4424409712110426\n",
      "epoch: 91 loss: 2.1413238048553467 grad: 3.2990501279395725\n",
      "epoch: 92 loss: 2.1435112953186035 grad: 3.127078355984792\n",
      "epoch: 93 loss: 2.1411187648773193 grad: 3.1688796925979354\n",
      "epoch: 94 loss: 2.1416006088256836 grad: 3.155001325008001\n",
      "epoch: 95 loss: 2.1459615230560303 grad: 3.176781390261437\n",
      "epoch: 96 loss: 2.1410250663757324 grad: 3.390304720642725\n",
      "epoch: 97 loss: 2.1394569873809814 grad: 3.539610854477533\n",
      "epoch: 98 loss: 2.1374049186706543 grad: 3.64025512729801\n",
      "epoch: 99 loss: 2.1337690353393555 grad: 3.5534681719025625\n",
      "epoch: 100 loss: 2.135429859161377 grad: 3.758363800940089\n",
      "epoch: 101 loss: 2.135775089263916 grad: 3.474897760964398\n",
      "epoch: 102 loss: 2.1383166313171387 grad: 3.8535555677880193\n",
      "epoch: 103 loss: 2.136904239654541 grad: 3.811457566336714\n",
      "epoch: 104 loss: 2.130556106567383 grad: 3.678747702075819\n",
      "epoch: 105 loss: 2.132955551147461 grad: 3.848977838228974\n",
      "epoch: 106 loss: 2.1305747032165527 grad: 4.033107027319068\n",
      "epoch: 107 loss: 2.12959361076355 grad: 4.0955782068213304\n",
      "epoch: 108 loss: 2.1312341690063477 grad: 4.073592194319067\n",
      "epoch: 109 loss: 2.125420093536377 grad: 4.159765953722868\n",
      "epoch: 110 loss: 2.122756242752075 grad: 4.4635540265552995\n",
      "epoch: 111 loss: 2.124081611633301 grad: 4.223015047358497\n",
      "epoch: 112 loss: 2.129056930541992 grad: 4.262033528796146\n",
      "epoch: 113 loss: 2.122466802597046 grad: 4.245166068730343\n",
      "epoch: 114 loss: 2.118551254272461 grad: 4.1951774873526855\n",
      "epoch: 115 loss: 2.118561267852783 grad: 4.4100321628086805\n",
      "epoch: 116 loss: 2.1160778999328613 grad: 4.01067840132404\n",
      "epoch: 117 loss: 2.1192922592163086 grad: 4.412284361630944\n",
      "epoch: 118 loss: 2.1160292625427246 grad: 4.420405473471398\n",
      "epoch: 119 loss: 2.1128337383270264 grad: 4.441036865924529\n",
      "epoch: 120 loss: 2.1172945499420166 grad: 4.686241161351698\n",
      "epoch: 121 loss: 2.118821144104004 grad: 4.439227448148091\n",
      "epoch: 122 loss: 2.1170969009399414 grad: 4.997387428320796\n",
      "epoch: 123 loss: 2.1124613285064697 grad: 4.659019355281507\n",
      "epoch: 124 loss: 2.110466241836548 grad: 4.750097333235548\n",
      "epoch: 125 loss: 2.113489866256714 grad: 4.968585064575549\n",
      "epoch: 126 loss: 2.109334707260132 grad: 4.940133347105797\n",
      "epoch: 127 loss: 2.1093101501464844 grad: 4.739910226766138\n",
      "epoch: 128 loss: 2.105820417404175 grad: 4.872419596553618\n",
      "epoch: 129 loss: 2.1058685779571533 grad: 5.026993445749025\n",
      "epoch: 130 loss: 2.1062185764312744 grad: 4.908862785347516\n",
      "epoch: 131 loss: 2.0989480018615723 grad: 4.751272546497011\n",
      "epoch: 132 loss: 2.1026134490966797 grad: 4.928574727718821\n",
      "epoch: 133 loss: 2.101006507873535 grad: 4.98262541528259\n",
      "epoch: 134 loss: 2.1037628650665283 grad: 4.935755558711078\n",
      "epoch: 135 loss: 2.100252628326416 grad: 5.158860856349329\n",
      "epoch: 136 loss: 2.1013975143432617 grad: 5.1723419884995865\n",
      "epoch: 137 loss: 2.100510597229004 grad: 5.2896136628641255\n",
      "epoch: 138 loss: 2.0983059406280518 grad: 5.3565586391126825\n",
      "epoch: 139 loss: 2.0965352058410645 grad: 5.355769425523394\n",
      "epoch: 140 loss: 2.093658208847046 grad: 5.3789086226255645\n",
      "epoch: 141 loss: 2.0897634029388428 grad: 5.009375506291343\n",
      "epoch: 142 loss: 2.0858864784240723 grad: 5.142236615198532\n",
      "epoch: 143 loss: 2.096426010131836 grad: 5.801048173997847\n",
      "epoch: 144 loss: 2.0904862880706787 grad: 5.43339371493101\n",
      "epoch: 145 loss: 2.092175245285034 grad: 5.396465474351619\n",
      "epoch: 146 loss: 2.0904691219329834 grad: 5.429239651750004\n",
      "epoch: 147 loss: 2.088738203048706 grad: 5.449644332492931\n",
      "epoch: 148 loss: 2.0808303356170654 grad: 5.117613722791984\n",
      "epoch: 149 loss: 2.0891239643096924 grad: 5.209001288497968\n",
      "epoch: 150 loss: 2.081148147583008 grad: 5.450565486706586\n",
      "epoch: 151 loss: 2.0860376358032227 grad: 5.6674186618082105\n",
      "epoch: 152 loss: 2.0820014476776123 grad: 5.473276350118723\n",
      "epoch: 153 loss: 2.081432819366455 grad: 5.427432448706693\n",
      "epoch: 154 loss: 2.086066961288452 grad: 5.334798038811496\n",
      "epoch: 155 loss: 2.0831708908081055 grad: 5.073603095446107\n",
      "epoch: 156 loss: 2.0841853618621826 grad: 5.542205679581486\n",
      "epoch: 157 loss: 2.0784361362457275 grad: 5.6970403448175935\n",
      "epoch: 158 loss: 2.0780370235443115 grad: 5.721367345834595\n",
      "epoch: 159 loss: 2.0765247344970703 grad: 5.694911424809741\n",
      "epoch: 160 loss: 2.076946973800659 grad: 5.484388102008592\n",
      "epoch: 161 loss: 2.076106309890747 grad: 5.626490185303347\n",
      "epoch: 162 loss: 2.069889545440674 grad: 5.654258070350994\n",
      "epoch: 163 loss: 2.0734221935272217 grad: 5.428759005556386\n",
      "epoch: 164 loss: 2.0754551887512207 grad: 5.559142200985835\n",
      "epoch: 165 loss: 2.0696256160736084 grad: 5.731495251280388\n",
      "epoch: 166 loss: 2.0712883472442627 grad: 5.846966774509628\n",
      "epoch: 167 loss: 2.071868658065796 grad: 6.027735316231551\n",
      "epoch: 168 loss: 2.0686094760894775 grad: 5.5157931815862415\n",
      "epoch: 169 loss: 2.075758218765259 grad: 5.5225514831124904\n",
      "epoch: 170 loss: 2.0681166648864746 grad: 5.621040257455278\n",
      "epoch: 171 loss: 2.0656445026397705 grad: 5.823320239930163\n",
      "epoch: 172 loss: 2.0667030811309814 grad: 5.591400857138935\n",
      "epoch: 173 loss: 2.0719852447509766 grad: 6.15027113367493\n",
      "epoch: 174 loss: 2.06902813911438 grad: 5.940835892222822\n",
      "epoch: 175 loss: 2.068767786026001 grad: 5.786132134408469\n",
      "epoch: 176 loss: 2.0701377391815186 grad: 5.770040897940773\n",
      "epoch: 177 loss: 2.0621917247772217 grad: 5.961183422725529\n",
      "epoch: 178 loss: 2.065316915512085 grad: 5.9247074537274855\n",
      "epoch: 179 loss: 2.05959153175354 grad: 5.414340268162685\n",
      "epoch: 180 loss: 2.065336227416992 grad: 5.943148351133993\n",
      "epoch: 181 loss: 2.058216094970703 grad: 6.013025116966298\n",
      "epoch: 182 loss: 2.060375452041626 grad: 6.134196249176822\n",
      "epoch: 183 loss: 2.064237356185913 grad: 6.304203682098656\n",
      "epoch: 184 loss: 2.0646286010742188 grad: 6.0344545142281625\n",
      "epoch: 185 loss: 2.055588483810425 grad: 6.071717006331753\n",
      "epoch: 186 loss: 2.056544065475464 grad: 6.037535659673195\n",
      "epoch: 187 loss: 2.05444073677063 grad: 5.919599209298631\n",
      "epoch: 188 loss: 2.0595948696136475 grad: 6.0900699804640475\n",
      "epoch: 189 loss: 2.055999755859375 grad: 6.184771785963445\n",
      "epoch: 190 loss: 2.058533191680908 grad: 5.987763721813699\n",
      "epoch: 191 loss: 2.0514562129974365 grad: 5.662537630662204\n",
      "epoch: 192 loss: 2.051588296890259 grad: 6.027458712798617\n",
      "epoch: 193 loss: 2.053839921951294 grad: 6.214363941257553\n",
      "epoch: 194 loss: 2.058189868927002 grad: 6.113183953791916\n",
      "epoch: 195 loss: 2.0533595085144043 grad: 6.504975927564951\n",
      "epoch: 196 loss: 2.055299758911133 grad: 6.324032507156805\n",
      "epoch: 197 loss: 2.047008752822876 grad: 6.152426743658171\n",
      "epoch: 198 loss: 2.056178092956543 grad: 6.529391927932877\n",
      "epoch: 199 loss: 2.055311918258667 grad: 6.4162266115465805\n",
      "epoch: 200 loss: 2.0472846031188965 grad: 5.998648776111031\n",
      "epoch: 201 loss: 2.0536997318267822 grad: 6.539093914811337\n",
      "epoch: 202 loss: 2.0500073432922363 grad: 6.174596981433708\n",
      "epoch: 203 loss: 2.0472466945648193 grad: 6.777107632622892\n",
      "epoch: 204 loss: 2.044447422027588 grad: 6.64898664557508\n",
      "epoch: 205 loss: 2.0478782653808594 grad: 6.202832302596006\n",
      "epoch: 206 loss: 2.0499579906463623 grad: 6.595771142518118\n",
      "epoch: 207 loss: 2.0489892959594727 grad: 6.348580063379828\n",
      "epoch: 208 loss: 2.044959783554077 grad: 6.4613858710102265\n",
      "epoch: 209 loss: 2.0421931743621826 grad: 6.573373607648093\n",
      "epoch: 210 loss: 2.0476062297821045 grad: 6.469378727229519\n",
      "epoch: 211 loss: 2.049783945083618 grad: 6.3461357764973645\n",
      "epoch: 212 loss: 2.0427298545837402 grad: 6.385478297507183\n",
      "epoch: 213 loss: 2.039257287979126 grad: 6.595320998033183\n",
      "epoch: 214 loss: 2.044555425643921 grad: 7.3635815863852345\n",
      "epoch: 215 loss: 2.0377960205078125 grad: 6.429676460619602\n",
      "epoch: 216 loss: 2.0367963314056396 grad: 6.514522720483088\n",
      "epoch: 217 loss: 2.0400969982147217 grad: 6.427624424087948\n",
      "epoch: 218 loss: 2.034189224243164 grad: 6.457773383241147\n",
      "epoch: 219 loss: 2.03310227394104 grad: 6.845319735115424\n",
      "epoch: 220 loss: 2.033268690109253 grad: 7.195904899115068\n",
      "epoch: 221 loss: 2.0285181999206543 grad: 6.830758755915754\n",
      "epoch: 222 loss: 2.0360589027404785 grad: 6.686655759464004\n",
      "epoch: 223 loss: 2.0361413955688477 grad: 6.976953910405023\n",
      "epoch: 224 loss: 2.0355520248413086 grad: 7.063243895939123\n",
      "epoch: 225 loss: 2.0296566486358643 grad: 7.229156931573969\n",
      "epoch: 226 loss: 2.0285391807556152 grad: 6.896131777278487\n",
      "epoch: 227 loss: 2.0300841331481934 grad: 7.246726209645174\n",
      "epoch: 228 loss: 2.0248212814331055 grad: 6.758659114979858\n",
      "epoch: 229 loss: 2.031581163406372 grad: 6.83080340320954\n",
      "epoch: 230 loss: 2.025665760040283 grad: 7.049853288524208\n",
      "epoch: 231 loss: 2.0332610607147217 grad: 7.2684829185849855\n",
      "epoch: 232 loss: 2.0235908031463623 grad: 7.665560242409508\n",
      "epoch: 233 loss: 2.027090072631836 grad: 7.460638698279148\n",
      "epoch: 234 loss: 2.022853374481201 grad: 6.9982075238644725\n",
      "epoch: 235 loss: 2.02701473236084 grad: 8.01640463073457\n",
      "epoch: 236 loss: 2.018968343734741 grad: 7.2094903622517394\n",
      "epoch: 237 loss: 2.024946451187134 grad: 7.749119109097158\n",
      "epoch: 238 loss: 2.015794515609741 grad: 7.500981014835397\n",
      "epoch: 239 loss: 2.020237684249878 grad: 7.734902027048289\n",
      "epoch: 240 loss: 2.017305374145508 grad: 7.278497483108252\n",
      "epoch: 241 loss: 2.024725914001465 grad: 7.615348721699168\n",
      "epoch: 242 loss: 2.0171303749084473 grad: 7.385733481311786\n",
      "epoch: 243 loss: 2.0134928226470947 grad: 7.011142344524463\n",
      "epoch: 244 loss: 2.018815517425537 grad: 7.853330786694729\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 245 loss: 2.015195846557617 grad: 7.6766950471090185\n",
      "epoch: 246 loss: 2.0123987197875977 grad: 7.6371751129922885\n",
      "epoch: 247 loss: 2.013770818710327 grad: 7.897595272162959\n",
      "epoch: 248 loss: 2.013209104537964 grad: 7.530644933988769\n",
      "epoch: 249 loss: 2.0080771446228027 grad: 7.53244058947478\n",
      "epoch: 250 loss: 2.0081732273101807 grad: 7.5978528408791925\n",
      "epoch: 251 loss: 2.0165088176727295 grad: 7.653472122640187\n",
      "epoch: 252 loss: 2.0110397338867188 grad: 7.625871426825013\n",
      "epoch: 253 loss: 2.0105204582214355 grad: 7.976046535666914\n",
      "epoch: 254 loss: 2.009575605392456 grad: 7.579936742974771\n",
      "epoch: 255 loss: 2.0037648677825928 grad: 7.478311055495094\n",
      "epoch: 256 loss: 2.0047860145568848 grad: 7.705404721784391\n",
      "epoch: 257 loss: 2.00244402885437 grad: 7.88631957239427\n",
      "epoch: 258 loss: 1.9956451654434204 grad: 7.291832353535389\n",
      "epoch: 259 loss: 1.9988361597061157 grad: 8.146569687562684\n",
      "epoch: 260 loss: 2.002988815307617 grad: 7.632118550498808\n",
      "epoch: 261 loss: 2.005641460418701 grad: 7.633388198143433\n",
      "epoch: 262 loss: 2.002178907394409 grad: 7.811606287165353\n",
      "epoch: 263 loss: 1.9982119798660278 grad: 8.052974860590425\n",
      "epoch: 264 loss: 2.002039670944214 grad: 8.032047612570404\n",
      "epoch: 265 loss: 1.9971566200256348 grad: 7.984695244580507\n",
      "epoch: 266 loss: 1.9970757961273193 grad: 8.554402558399099\n",
      "epoch: 267 loss: 1.995823860168457 grad: 7.460315274289026\n",
      "epoch: 268 loss: 1.998777985572815 grad: 8.001080369125933\n",
      "epoch: 269 loss: 1.9929859638214111 grad: 7.586653286221599\n",
      "epoch: 270 loss: 1.999229907989502 grad: 8.265108193766089\n",
      "epoch: 271 loss: 1.991789698600769 grad: 7.834817885820355\n",
      "epoch: 272 loss: 1.9989176988601685 grad: 8.138854683258586\n",
      "epoch: 273 loss: 1.997187852859497 grad: 8.583308139091564\n",
      "epoch: 274 loss: 1.9890021085739136 grad: 8.700414351217212\n",
      "epoch: 275 loss: 1.995187520980835 grad: 7.9615868378785395\n",
      "epoch: 276 loss: 1.9872138500213623 grad: 8.159243040097257\n",
      "epoch: 277 loss: 1.98863685131073 grad: 8.441704123413988\n",
      "epoch: 278 loss: 1.9946492910385132 grad: 8.55462624208026\n",
      "epoch: 279 loss: 1.9891504049301147 grad: 8.053156509611105\n",
      "epoch: 280 loss: 1.9863895177841187 grad: 8.273022576360889\n",
      "epoch: 281 loss: 1.9938122034072876 grad: 8.13012889596737\n",
      "epoch: 282 loss: 1.982852816581726 grad: 8.510388240055551\n",
      "epoch: 283 loss: 1.9816546440124512 grad: 8.340356656645854\n",
      "epoch: 284 loss: 1.9881740808486938 grad: 8.16953697574458\n",
      "epoch: 285 loss: 1.9864846467971802 grad: 8.430598404746325\n",
      "epoch: 286 loss: 1.9874560832977295 grad: 8.596413638864068\n",
      "epoch: 287 loss: 1.9865527153015137 grad: 8.336573187394865\n",
      "epoch: 288 loss: 1.9774895906448364 grad: 8.063541234515252\n",
      "epoch: 289 loss: 1.9812158346176147 grad: 8.06215307144596\n",
      "epoch: 290 loss: 1.982322335243225 grad: 8.878204121461344\n",
      "epoch: 291 loss: 1.9765888452529907 grad: 8.595367942552363\n",
      "epoch: 292 loss: 1.9815539121627808 grad: 9.276067704405813\n",
      "epoch: 293 loss: 1.9824494123458862 grad: 9.016196976888866\n",
      "epoch: 294 loss: 1.9764572381973267 grad: 8.890432745321757\n",
      "epoch: 295 loss: 1.9860700368881226 grad: 9.265599435343155\n",
      "epoch: 296 loss: 1.979038953781128 grad: 9.491424633988313\n",
      "epoch: 297 loss: 1.9795520305633545 grad: 8.563600551647445\n",
      "epoch: 298 loss: 1.9740568399429321 grad: 8.775795505832999\n",
      "epoch: 299 loss: 1.9805500507354736 grad: 8.804920149035752\n",
      "epoch: 300 loss: 1.97211492061615 grad: 8.829027794478904\n",
      "epoch: 301 loss: 1.9764431715011597 grad: 9.01240970639305\n",
      "epoch: 302 loss: 1.9675005674362183 grad: 8.430029996537737\n",
      "epoch: 303 loss: 1.974866271018982 grad: 9.600446940917108\n",
      "epoch: 304 loss: 1.9669464826583862 grad: 8.976233322557713\n",
      "epoch: 305 loss: 1.9729869365692139 grad: 8.62908516908508\n",
      "epoch: 306 loss: 1.9738891124725342 grad: 9.01995096163499\n",
      "epoch: 307 loss: 1.9717941284179688 grad: 9.154512683949655\n",
      "epoch: 308 loss: 1.9688376188278198 grad: 8.957070153250935\n",
      "epoch: 309 loss: 1.9697604179382324 grad: 8.738484787872977\n",
      "epoch: 310 loss: 1.9705121517181396 grad: 9.426879610334124\n",
      "epoch: 311 loss: 1.9605709314346313 grad: 9.180400650696976\n",
      "epoch: 312 loss: 1.9686613082885742 grad: 9.225527789088941\n",
      "epoch: 313 loss: 1.9672443866729736 grad: 9.074541543750831\n",
      "epoch: 314 loss: 1.967934012413025 grad: 9.229274327098022\n",
      "epoch: 315 loss: 1.9639756679534912 grad: 9.039837158270299\n",
      "epoch: 316 loss: 1.960099220275879 grad: 9.22609002868985\n",
      "epoch: 317 loss: 1.9594484567642212 grad: 8.800236743180053\n",
      "epoch: 318 loss: 1.963192343711853 grad: 9.644140101984025\n",
      "epoch: 319 loss: 1.9578546285629272 grad: 9.124137631558355\n",
      "epoch: 320 loss: 1.9645867347717285 grad: 9.197448821960105\n",
      "epoch: 321 loss: 1.966905951499939 grad: 9.329917797301379\n",
      "epoch: 322 loss: 1.9632843732833862 grad: 10.004971022569826\n",
      "epoch: 323 loss: 1.973369836807251 grad: 9.25514907445315\n",
      "epoch: 324 loss: 1.9569681882858276 grad: 9.187827767079902\n",
      "epoch: 325 loss: 1.9663134813308716 grad: 9.559565101513668\n",
      "epoch: 326 loss: 1.963066816329956 grad: 9.758533340479646\n",
      "epoch: 327 loss: 1.9612096548080444 grad: 9.344714326281396\n",
      "epoch: 328 loss: 1.957014560699463 grad: 8.8457379833396\n",
      "epoch: 329 loss: 1.9600595235824585 grad: 9.482514894419602\n",
      "epoch: 330 loss: 1.9589266777038574 grad: 9.821830423031416\n",
      "epoch: 331 loss: 1.959916591644287 grad: 10.006159390751568\n",
      "epoch: 332 loss: 1.9618092775344849 grad: 9.626459433601076\n",
      "epoch: 333 loss: 1.955936312675476 grad: 8.964459652923757\n",
      "epoch: 334 loss: 1.9536869525909424 grad: 10.239817526398433\n",
      "epoch: 335 loss: 1.9540328979492188 grad: 10.18757667278664\n",
      "epoch: 336 loss: 1.9553320407867432 grad: 9.900171280661155\n",
      "epoch: 337 loss: 1.9549769163131714 grad: 9.855600949761177\n",
      "epoch: 338 loss: 1.94684898853302 grad: 9.357650940705623\n",
      "epoch: 339 loss: 1.9486593008041382 grad: 9.760056924267065\n",
      "epoch: 340 loss: 1.9475435018539429 grad: 9.638670865276326\n",
      "epoch: 341 loss: 1.9569467306137085 grad: 10.209844113371911\n",
      "epoch: 342 loss: 1.9455970525741577 grad: 9.770672359548154\n",
      "epoch: 343 loss: 1.95025634765625 grad: 9.552453779497199\n",
      "epoch: 344 loss: 1.9451708793640137 grad: 10.157493760454512\n",
      "epoch: 345 loss: 1.9421190023422241 grad: 9.713714522413081\n",
      "epoch: 346 loss: 1.9454915523529053 grad: 10.03847852663418\n",
      "epoch: 347 loss: 1.9502769708633423 grad: 10.2497275733862\n",
      "epoch: 348 loss: 1.9489456415176392 grad: 9.737424190821391\n",
      "epoch: 349 loss: 1.9329843521118164 grad: 10.193055303900369\n",
      "epoch: 350 loss: 1.9466221332550049 grad: 10.386841895073534\n",
      "epoch: 351 loss: 1.9465488195419312 grad: 10.41216331581393\n",
      "epoch: 352 loss: 1.9496698379516602 grad: 10.64306892825675\n",
      "epoch: 353 loss: 1.9490669965744019 grad: 10.025710916279682\n",
      "epoch: 354 loss: 1.9456027746200562 grad: 9.544588612762118\n",
      "epoch: 355 loss: 1.9450618028640747 grad: 9.679981274005499\n",
      "epoch: 356 loss: 1.9538758993148804 grad: 10.57599478040541\n",
      "epoch: 357 loss: 1.9366625547409058 grad: 10.547813167943367\n",
      "epoch: 358 loss: 1.9466968774795532 grad: 10.379753009416163\n",
      "epoch: 359 loss: 1.938413143157959 grad: 10.33952532423335\n",
      "epoch: 360 loss: 1.9330155849456787 grad: 10.507289967884029\n",
      "epoch: 361 loss: 1.9450217485427856 grad: 10.209217721965933\n",
      "epoch: 362 loss: 1.9412524700164795 grad: 10.027389773182453\n",
      "epoch: 363 loss: 1.9419997930526733 grad: 9.905858928382042\n",
      "epoch: 364 loss: 1.942128300666809 grad: 10.473960830519596\n",
      "epoch: 365 loss: 1.9361681938171387 grad: 10.692453355129276\n",
      "epoch: 366 loss: 1.9372093677520752 grad: 9.915402917501828\n",
      "epoch: 367 loss: 1.933971643447876 grad: 10.503814821486317\n",
      "epoch: 368 loss: 1.9381662607192993 grad: 10.710031268807748\n",
      "epoch: 369 loss: 1.9305716753005981 grad: 10.583465408356417\n",
      "epoch: 370 loss: 1.9411615133285522 grad: 10.346839435176836\n",
      "epoch: 371 loss: 1.9380073547363281 grad: 10.336802874765699\n",
      "epoch: 372 loss: 1.9340859651565552 grad: 10.011249251885427\n",
      "epoch: 373 loss: 1.9417730569839478 grad: 10.806136630002468\n",
      "epoch: 374 loss: 1.9391865730285645 grad: 10.56268958507904\n",
      "epoch: 375 loss: 1.9353156089782715 grad: 10.299975902019511\n",
      "epoch: 376 loss: 1.9303643703460693 grad: 11.240923895086679\n",
      "epoch: 377 loss: 1.9313265085220337 grad: 11.016885304335682\n",
      "epoch: 378 loss: 1.9315698146820068 grad: 10.2093342615528\n",
      "epoch: 379 loss: 1.9337180852890015 grad: 10.48773646163976\n",
      "epoch: 380 loss: 1.9316519498825073 grad: 11.325726765163598\n",
      "epoch: 381 loss: 1.9325751066207886 grad: 10.498452501031496\n",
      "epoch: 382 loss: 1.9199550151824951 grad: 10.317377562797258\n",
      "epoch: 383 loss: 1.93035089969635 grad: 10.151447486620219\n",
      "epoch: 384 loss: 1.9325287342071533 grad: 10.853961462243682\n",
      "epoch: 385 loss: 1.9260542392730713 grad: 10.150894772808348\n",
      "epoch: 386 loss: 1.919400930404663 grad: 10.297570721364565\n",
      "epoch: 387 loss: 1.9282492399215698 grad: 10.672841865879795\n",
      "epoch: 388 loss: 1.9243009090423584 grad: 10.55386409188606\n",
      "epoch: 389 loss: 1.9228440523147583 grad: 10.424615536380323\n",
      "epoch: 390 loss: 1.9311388731002808 grad: 10.469546272493307\n",
      "epoch: 391 loss: 1.9214732646942139 grad: 10.252197326101836\n",
      "epoch: 392 loss: 1.9185196161270142 grad: 10.538263604976237\n",
      "epoch: 393 loss: 1.92375648021698 grad: 10.653839769167087\n",
      "epoch: 394 loss: 1.9207117557525635 grad: 10.281270943404664\n",
      "epoch: 395 loss: 1.9227144718170166 grad: 10.39366346155663\n",
      "epoch: 396 loss: 1.9209035634994507 grad: 11.167811887885724\n",
      "epoch: 397 loss: 1.923195719718933 grad: 10.394628874972344\n",
      "epoch: 398 loss: 1.9188120365142822 grad: 11.014924009493182\n",
      "epoch: 399 loss: 1.9199135303497314 grad: 11.067342356290846\n",
      "epoch: 400 loss: 1.929159164428711 grad: 10.624199454864812\n",
      "epoch: 401 loss: 1.9216173887252808 grad: 10.818025074463101\n",
      "epoch: 402 loss: 1.925124168395996 grad: 11.24308779524521\n",
      "epoch: 403 loss: 1.9148703813552856 grad: 10.593322966735633\n",
      "epoch: 404 loss: 1.926727294921875 grad: 10.907907821016298\n",
      "epoch: 405 loss: 1.9234706163406372 grad: 10.562189952485145\n",
      "epoch: 406 loss: 1.9270153045654297 grad: 11.151438653069947\n",
      "epoch: 407 loss: 1.9183003902435303 grad: 10.635949697227232\n",
      "epoch: 408 loss: 1.9145748615264893 grad: 10.519395932703027\n",
      "epoch: 409 loss: 1.921952486038208 grad: 11.036968431568571\n",
      "epoch: 410 loss: 1.916035532951355 grad: 10.83892014473381\n",
      "epoch: 411 loss: 1.9195725917816162 grad: 10.54591845224301\n",
      "epoch: 412 loss: 1.9172714948654175 grad: 10.653931229626613\n",
      "epoch: 413 loss: 1.9079149961471558 grad: 11.186227556051952\n",
      "epoch: 414 loss: 1.916373610496521 grad: 11.016768524157149\n",
      "epoch: 415 loss: 1.912204623222351 grad: 10.756834796289839\n",
      "epoch: 416 loss: 1.9062532186508179 grad: 11.469592893969208\n",
      "epoch: 417 loss: 1.9161899089813232 grad: 10.754040731102346\n",
      "epoch: 418 loss: 1.9170876741409302 grad: 11.572940948108831\n",
      "epoch: 419 loss: 1.9119911193847656 grad: 10.801390351609342\n",
      "epoch: 420 loss: 1.907789707183838 grad: 10.838945225442922\n",
      "epoch: 421 loss: 1.921590805053711 grad: 11.010410348736933\n",
      "epoch: 422 loss: 1.9101417064666748 grad: 11.228195977752053\n",
      "epoch: 423 loss: 1.9065895080566406 grad: 11.000061198773365\n",
      "epoch: 424 loss: 1.9068182706832886 grad: 11.42009605383057\n",
      "epoch: 425 loss: 1.9085856676101685 grad: 11.821826930172623\n",
      "epoch: 426 loss: 1.9060577154159546 grad: 11.040652150938671\n",
      "epoch: 427 loss: 1.909505844116211 grad: 11.135728659884384\n",
      "epoch: 428 loss: 1.9124246835708618 grad: 10.983921070886215\n",
      "epoch: 429 loss: 1.9137229919433594 grad: 11.237496624552897\n",
      "epoch: 430 loss: 1.9031167030334473 grad: 10.783414630869787\n",
      "epoch: 431 loss: 1.9064239263534546 grad: 11.015773923742392\n",
      "epoch: 432 loss: 1.9109666347503662 grad: 11.448189316125262\n",
      "epoch: 433 loss: 1.900648593902588 grad: 11.48855009221191\n",
      "epoch: 434 loss: 1.9114184379577637 grad: 11.166578786905914\n",
      "epoch: 435 loss: 1.8961467742919922 grad: 10.954056438842109\n",
      "epoch: 436 loss: 1.915024995803833 grad: 11.15436205863657\n",
      "epoch: 437 loss: 1.8957465887069702 grad: 11.061265776806053\n",
      "epoch: 438 loss: 1.907219409942627 grad: 11.144835752294592\n",
      "epoch: 439 loss: 1.9021549224853516 grad: 11.106483500628244\n",
      "epoch: 440 loss: 1.904328465461731 grad: 11.721062048515748\n",
      "epoch: 441 loss: 1.9072954654693604 grad: 11.286484643181284\n",
      "epoch: 442 loss: 1.8947184085845947 grad: 10.811566892449582\n",
      "epoch: 443 loss: 1.8997886180877686 grad: 11.547138539955967\n",
      "epoch: 444 loss: 1.9042593240737915 grad: 11.340967887820351\n",
      "epoch: 445 loss: 1.9135284423828125 grad: 11.373890182432083\n",
      "epoch: 446 loss: 1.8998119831085205 grad: 11.21577324545277\n",
      "epoch: 447 loss: 1.8943322896957397 grad: 10.650411670125784\n",
      "epoch: 448 loss: 1.8949565887451172 grad: 10.753007859701203\n",
      "epoch: 449 loss: 1.8912185430526733 grad: 11.117086271651917\n",
      "epoch: 450 loss: 1.904072642326355 grad: 12.010551610946774\n",
      "epoch: 451 loss: 1.9088588953018188 grad: 11.173597942771655\n",
      "epoch: 452 loss: 1.8965775966644287 grad: 11.400026008811972\n",
      "epoch: 453 loss: 1.901482343673706 grad: 10.541238893518253\n",
      "epoch: 454 loss: 1.8960875272750854 grad: 11.502749052785692\n",
      "epoch: 455 loss: 1.8938710689544678 grad: 11.520947183748442\n",
      "epoch: 456 loss: 1.898684024810791 grad: 11.463583276658836\n",
      "epoch: 457 loss: 1.8976733684539795 grad: 11.705698606040743\n",
      "epoch: 458 loss: 1.8932045698165894 grad: 11.139291797276764\n",
      "epoch: 459 loss: 1.8977969884872437 grad: 11.314132790790783\n",
      "epoch: 460 loss: 1.893925666809082 grad: 11.397653834399073\n",
      "epoch: 461 loss: 1.8952873945236206 grad: 11.550365902453898\n",
      "epoch: 462 loss: 1.8882290124893188 grad: 11.196588046686163\n",
      "epoch: 463 loss: 1.8942289352416992 grad: 11.41632446833694\n",
      "epoch: 464 loss: 1.8854169845581055 grad: 11.673195395189973\n",
      "epoch: 465 loss: 1.898952603340149 grad: 11.65786777532822\n",
      "epoch: 466 loss: 1.8998913764953613 grad: 11.186746231324616\n",
      "epoch: 467 loss: 1.8941936492919922 grad: 11.34988128380584\n",
      "epoch: 468 loss: 1.8963239192962646 grad: 12.313366547182557\n",
      "epoch: 469 loss: 1.883217215538025 grad: 11.246694487194338\n",
      "epoch: 470 loss: 1.8988128900527954 grad: 11.969113717993928\n",
      "epoch: 471 loss: 1.88687002658844 grad: 11.262298192488887\n",
      "epoch: 472 loss: 1.8941439390182495 grad: 10.9872781730937\n",
      "epoch: 473 loss: 1.88680899143219 grad: 11.472991881359901\n",
      "epoch: 474 loss: 1.8848097324371338 grad: 11.823138237339519\n",
      "epoch: 475 loss: 1.88437819480896 grad: 11.090883430537014\n",
      "epoch: 476 loss: 1.884344220161438 grad: 11.533435882911796\n",
      "epoch: 477 loss: 1.8869541883468628 grad: 11.453498642122934\n",
      "epoch: 478 loss: 1.881710410118103 grad: 11.25544166251544\n",
      "epoch: 479 loss: 1.8906725645065308 grad: 11.550283066174458\n",
      "epoch: 480 loss: 1.8847352266311646 grad: 11.674180900012809\n",
      "epoch: 481 loss: 1.8899768590927124 grad: 11.738165148799974\n",
      "epoch: 482 loss: 1.8842694759368896 grad: 10.918918860277959\n",
      "epoch: 483 loss: 1.898545503616333 grad: 11.480500639933679\n",
      "epoch: 484 loss: 1.8891026973724365 grad: 11.866221241933841\n",
      "epoch: 485 loss: 1.8818275928497314 grad: 11.383313419578213\n",
      "epoch: 486 loss: 1.8888871669769287 grad: 11.686218459979587\n",
      "epoch: 487 loss: 1.8991048336029053 grad: 11.685049494565835\n",
      "epoch: 488 loss: 1.8828877210617065 grad: 11.81657316600756\n",
      "epoch: 489 loss: 1.889021396636963 grad: 12.23085527429505\n",
      "epoch: 490 loss: 1.8781172037124634 grad: 10.56455855016848\n",
      "epoch: 491 loss: 1.8754221200942993 grad: 11.402988730929792\n",
      "epoch: 492 loss: 1.8859009742736816 grad: 10.533281935748482\n",
      "epoch: 493 loss: 1.8812408447265625 grad: 11.752043465507173\n",
      "epoch: 494 loss: 1.8923486471176147 grad: 11.782634735550909\n",
      "epoch: 495 loss: 1.886838674545288 grad: 11.565701772488417\n",
      "epoch: 496 loss: 1.8720649480819702 grad: 11.50503301868836\n",
      "epoch: 497 loss: 1.886640191078186 grad: 10.910184172566034\n",
      "epoch: 498 loss: 1.879997730255127 grad: 11.878512817287138\n",
      "epoch: 499 loss: 1.8773722648620605 grad: 11.295040675128499\n",
      "2.08141503483057\n",
      "epoch: 0 loss: 2.30328369140625 grad: 0.9561007524469114\n",
      "epoch: 1 loss: 2.2877748012542725 grad: 1.1503743386045764\n",
      "epoch: 2 loss: 2.253936767578125 grad: 1.8314039447998058\n",
      "epoch: 3 loss: 2.221691846847534 grad: 2.355645511294752\n",
      "epoch: 4 loss: 2.179332971572876 grad: 2.3186286551645026\n",
      "epoch: 5 loss: 2.14686918258667 grad: 2.954940991182368\n",
      "epoch: 6 loss: 2.1205952167510986 grad: 3.7903538995038066\n",
      "epoch: 7 loss: 2.0984644889831543 grad: 3.676877987818674\n",
      "epoch: 8 loss: 2.0657765865325928 grad: 3.7464014692102663\n",
      "epoch: 9 loss: 2.047252893447876 grad: 4.241958614174528\n",
      "epoch: 10 loss: 2.024078845977783 grad: 4.7335305061812205\n",
      "epoch: 11 loss: 2.0188963413238525 grad: 4.498173767469809\n",
      "epoch: 12 loss: 2.000781536102295 grad: 5.004712989121409\n",
      "epoch: 13 loss: 1.9851956367492676 grad: 5.05089079246058\n",
      "epoch: 14 loss: 1.9623860120773315 grad: 5.217874158805769\n",
      "epoch: 15 loss: 1.9555041790008545 grad: 5.124476676049184\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 16 loss: 1.9534791707992554 grad: 5.392218353084496\n",
      "epoch: 17 loss: 1.9121986627578735 grad: 5.3480865283266805\n",
      "epoch: 18 loss: 1.9169186353683472 grad: 5.477888349018666\n",
      "epoch: 19 loss: 1.93626070022583 grad: 5.152487456783771\n",
      "epoch: 20 loss: 1.903189778327942 grad: 5.796310515152217\n",
      "epoch: 21 loss: 1.908437967300415 grad: 5.667679874230147\n",
      "epoch: 22 loss: 1.8777645826339722 grad: 6.146587036580534\n",
      "epoch: 23 loss: 1.8782979249954224 grad: 5.407361137340703\n",
      "epoch: 24 loss: 1.8824820518493652 grad: 5.827636086287731\n",
      "epoch: 25 loss: 1.8560431003570557 grad: 6.3210985888967235\n",
      "epoch: 26 loss: 1.8667948246002197 grad: 5.893928811097303\n",
      "epoch: 27 loss: 1.8593562841415405 grad: 6.146316688524888\n",
      "epoch: 28 loss: 1.8459680080413818 grad: 5.368560128230398\n",
      "epoch: 29 loss: 1.8561785221099854 grad: 6.764134404591344\n",
      "epoch: 30 loss: 1.8617453575134277 grad: 6.408049544297336\n",
      "epoch: 31 loss: 1.8160078525543213 grad: 5.618449114456159\n",
      "epoch: 32 loss: 1.8122632503509521 grad: 6.044476175736192\n",
      "epoch: 33 loss: 1.8433045148849487 grad: 6.3123658266480245\n",
      "epoch: 34 loss: 1.8234409093856812 grad: 5.848601635800035\n",
      "epoch: 35 loss: 1.8123397827148438 grad: 6.386641361583893\n",
      "epoch: 36 loss: 1.8082773685455322 grad: 6.939602253318299\n",
      "epoch: 37 loss: 1.8183904886245728 grad: 6.053456349793585\n",
      "epoch: 38 loss: 1.7857316732406616 grad: 5.5697887815204306\n",
      "epoch: 39 loss: 1.7884019613265991 grad: 5.575317871201107\n",
      "epoch: 40 loss: 1.7920424938201904 grad: 5.898155342559293\n",
      "epoch: 41 loss: 1.7869595289230347 grad: 6.759183399732426\n",
      "epoch: 42 loss: 1.797791600227356 grad: 7.285997261723553\n",
      "epoch: 43 loss: 1.792321801185608 grad: 5.9111325194867925\n",
      "epoch: 44 loss: 1.764663577079773 grad: 5.646436121457973\n",
      "epoch: 45 loss: 1.7810429334640503 grad: 6.283587077585426\n",
      "epoch: 46 loss: 1.7639672756195068 grad: 6.123608146116726\n",
      "epoch: 47 loss: 1.7958579063415527 grad: 5.904183198775937\n",
      "epoch: 48 loss: 1.774340271949768 grad: 5.452626519653547\n",
      "epoch: 49 loss: 1.7661539316177368 grad: 5.756277430185976\n",
      "epoch: 50 loss: 1.7529268264770508 grad: 5.080852378352632\n",
      "epoch: 51 loss: 1.738954782485962 grad: 5.528659272102116\n",
      "epoch: 52 loss: 1.7538361549377441 grad: 5.948023771203312\n",
      "epoch: 53 loss: 1.7680375576019287 grad: 6.311383730928471\n",
      "epoch: 54 loss: 1.774473786354065 grad: 5.54918832865697\n",
      "epoch: 55 loss: 1.7513304948806763 grad: 6.3182452034883365\n",
      "epoch: 56 loss: 1.7534847259521484 grad: 6.177360240628736\n",
      "epoch: 57 loss: 1.7327769994735718 grad: 5.499505018596311\n",
      "epoch: 58 loss: 1.7426233291625977 grad: 5.509191125544252\n",
      "epoch: 59 loss: 1.7746732234954834 grad: 6.896587222559093\n",
      "epoch: 60 loss: 1.747172474861145 grad: 6.250480028125734\n",
      "epoch: 61 loss: 1.7398109436035156 grad: 6.921466998777413\n",
      "epoch: 62 loss: 1.7425868511199951 grad: 5.398329996447992\n",
      "epoch: 63 loss: 1.7247649431228638 grad: 6.683504375354257\n",
      "epoch: 64 loss: 1.6997549533843994 grad: 5.49852252035727\n",
      "epoch: 65 loss: 1.687784194946289 grad: 5.37001144453617\n",
      "epoch: 66 loss: 1.719718337059021 grad: 5.8015377640277\n",
      "epoch: 67 loss: 1.7061353921890259 grad: 5.975302356005404\n",
      "epoch: 68 loss: 1.7213915586471558 grad: 6.689913723261617\n",
      "epoch: 69 loss: 1.6882455348968506 grad: 6.569835773345345\n",
      "epoch: 70 loss: 1.7141157388687134 grad: 6.941230220010131\n",
      "epoch: 71 loss: 1.7152742147445679 grad: 7.659034343065402\n",
      "epoch: 72 loss: 1.6845333576202393 grad: 6.209169307140872\n",
      "epoch: 73 loss: 1.6679164171218872 grad: 5.946306565974188\n",
      "epoch: 74 loss: 1.6756982803344727 grad: 6.037142175376334\n",
      "epoch: 75 loss: 1.6795228719711304 grad: 6.442656568358033\n",
      "epoch: 76 loss: 1.6676205396652222 grad: 7.118204233153919\n",
      "epoch: 77 loss: 1.6735742092132568 grad: 6.811919635293475\n",
      "epoch: 78 loss: 1.6768614053726196 grad: 6.6916084668736735\n",
      "epoch: 79 loss: 1.6834521293640137 grad: 6.68132226380551\n",
      "epoch: 80 loss: 1.6801713705062866 grad: 7.207083111447568\n",
      "epoch: 81 loss: 1.694456934928894 grad: 7.192918255369896\n",
      "epoch: 82 loss: 1.6722837686538696 grad: 6.270051942264088\n",
      "epoch: 83 loss: 1.6525871753692627 grad: 5.977484228590223\n",
      "epoch: 84 loss: 1.6621778011322021 grad: 6.289842161639374\n",
      "epoch: 85 loss: 1.6485987901687622 grad: 5.602389647158127\n",
      "epoch: 86 loss: 1.6480085849761963 grad: 6.081263788426267\n",
      "epoch: 87 loss: 1.6396434307098389 grad: 5.484436174870805\n",
      "epoch: 88 loss: 1.6457679271697998 grad: 6.001302602805294\n",
      "epoch: 89 loss: 1.6387441158294678 grad: 5.975913565468444\n",
      "epoch: 90 loss: 1.678587794303894 grad: 6.958967233160654\n",
      "epoch: 91 loss: 1.6459299325942993 grad: 5.971583982961117\n",
      "epoch: 92 loss: 1.6577575206756592 grad: 6.659419789713057\n",
      "epoch: 93 loss: 1.6630421876907349 grad: 5.99548669973491\n",
      "epoch: 94 loss: 1.6495709419250488 grad: 5.735735375977547\n",
      "epoch: 95 loss: 1.6431946754455566 grad: 7.6201226304378835\n",
      "epoch: 96 loss: 1.6446982622146606 grad: 5.885282825685286\n",
      "epoch: 97 loss: 1.6422830820083618 grad: 5.768799216676035\n",
      "epoch: 98 loss: 1.6282559633255005 grad: 5.535683799439871\n",
      "epoch: 99 loss: 1.639909029006958 grad: 5.9085061604517195\n",
      "epoch: 100 loss: 1.634208083152771 grad: 6.159999800376508\n",
      "epoch: 101 loss: 1.6234947443008423 grad: 5.268844871879184\n",
      "epoch: 102 loss: 1.649216890335083 grad: 6.050966082910178\n",
      "epoch: 103 loss: 1.643591284751892 grad: 6.261633115650814\n",
      "epoch: 104 loss: 1.6319025754928589 grad: 5.5915295541035155\n",
      "epoch: 105 loss: 1.6371502876281738 grad: 7.235537829168895\n",
      "epoch: 106 loss: 1.6688255071640015 grad: 6.0696014552917665\n",
      "epoch: 107 loss: 1.6344300508499146 grad: 6.476406024712011\n",
      "epoch: 108 loss: 1.6247341632843018 grad: 6.434241637232036\n",
      "epoch: 109 loss: 1.6424813270568848 grad: 5.414255463621365\n",
      "epoch: 110 loss: 1.6188908815383911 grad: 4.186711184243443\n",
      "epoch: 111 loss: 1.6136515140533447 grad: 5.340785443911694\n",
      "epoch: 112 loss: 1.6258598566055298 grad: 6.136927973981651\n",
      "epoch: 113 loss: 1.6614934206008911 grad: 6.453183454670667\n",
      "epoch: 114 loss: 1.614013910293579 grad: 5.7704238913029835\n",
      "epoch: 115 loss: 1.6219710111618042 grad: 5.047749752077516\n",
      "epoch: 116 loss: 1.6215178966522217 grad: 5.554546548064594\n",
      "epoch: 117 loss: 1.632020354270935 grad: 5.42065741341692\n",
      "epoch: 118 loss: 1.621248483657837 grad: 4.858144915867934\n",
      "epoch: 119 loss: 1.627590537071228 grad: 5.67649774454999\n",
      "epoch: 120 loss: 1.6068426370620728 grad: 5.220367330305476\n",
      "epoch: 121 loss: 1.6245771646499634 grad: 6.67338485908459\n",
      "epoch: 122 loss: 1.6275267601013184 grad: 6.54943340858015\n",
      "epoch: 123 loss: 1.620425820350647 grad: 4.46607830288277\n",
      "epoch: 124 loss: 1.6161524057388306 grad: 5.574014661390619\n",
      "epoch: 125 loss: 1.6196370124816895 grad: 6.926739343018516\n",
      "epoch: 126 loss: 1.6256879568099976 grad: 5.179670174259901\n",
      "epoch: 127 loss: 1.622307538986206 grad: 5.667320254582765\n",
      "epoch: 128 loss: 1.607519268989563 grad: 4.196242789202924\n",
      "epoch: 129 loss: 1.6022193431854248 grad: 4.424352447281589\n",
      "epoch: 130 loss: 1.618851661682129 grad: 4.233421350996708\n",
      "epoch: 131 loss: 1.6087470054626465 grad: 5.868882051451272\n",
      "epoch: 132 loss: 1.6200988292694092 grad: 5.5445388355016645\n",
      "epoch: 133 loss: 1.6215614080429077 grad: 5.5040219212523445\n",
      "epoch: 134 loss: 1.6221598386764526 grad: 5.067192106665826\n",
      "epoch: 135 loss: 1.6291295289993286 grad: 6.466132217326843\n",
      "epoch: 136 loss: 1.6105674505233765 grad: 5.437091941317906\n",
      "epoch: 137 loss: 1.607113003730774 grad: 5.385332606053323\n",
      "epoch: 138 loss: 1.627821445465088 grad: 5.875713874807901\n",
      "epoch: 139 loss: 1.6148985624313354 grad: 5.018053087515996\n",
      "epoch: 140 loss: 1.6088563203811646 grad: 5.212894901939892\n",
      "epoch: 141 loss: 1.6197675466537476 grad: 5.713537199236314\n",
      "epoch: 142 loss: 1.614412784576416 grad: 4.766292770932306\n",
      "epoch: 143 loss: 1.6225844621658325 grad: 5.614532159823948\n",
      "epoch: 144 loss: 1.5984282493591309 grad: 5.249966159039769\n",
      "epoch: 145 loss: 1.6270660161972046 grad: 4.586038489853135\n",
      "epoch: 146 loss: 1.6017053127288818 grad: 4.7792719000643995\n",
      "epoch: 147 loss: 1.5980989933013916 grad: 4.145094872941569\n",
      "epoch: 148 loss: 1.6272079944610596 grad: 6.187149824975186\n",
      "epoch: 149 loss: 1.6161929368972778 grad: 4.909294034129469\n",
      "epoch: 150 loss: 1.619006872177124 grad: 5.515466218588353\n",
      "epoch: 151 loss: 1.6216644048690796 grad: 5.245747749924758\n",
      "epoch: 152 loss: 1.6057236194610596 grad: 6.255975432088484\n",
      "epoch: 153 loss: 1.622333288192749 grad: 4.971251306354725\n",
      "epoch: 154 loss: 1.5987035036087036 grad: 5.00287801784212\n",
      "epoch: 155 loss: 1.5887320041656494 grad: 4.393946967467521\n",
      "epoch: 156 loss: 1.6037111282348633 grad: 3.7565711601027365\n",
      "epoch: 157 loss: 1.5965204238891602 grad: 5.300283532945596\n",
      "epoch: 158 loss: 1.603094220161438 grad: 4.956182881529548\n",
      "epoch: 159 loss: 1.5943385362625122 grad: 5.619591735118421\n",
      "epoch: 160 loss: 1.6182665824890137 grad: 5.089397324838735\n",
      "epoch: 161 loss: 1.5998663902282715 grad: 5.497896909610323\n",
      "epoch: 162 loss: 1.6012808084487915 grad: 5.287513373314783\n",
      "epoch: 163 loss: 1.6008273363113403 grad: 4.078917662186418\n",
      "epoch: 164 loss: 1.6258705854415894 grad: 4.787056632749414\n",
      "epoch: 165 loss: 1.5947412252426147 grad: 4.892878064173235\n",
      "epoch: 166 loss: 1.6089202165603638 grad: 4.4843041667705\n",
      "epoch: 167 loss: 1.6255271434783936 grad: 6.548210317984091\n",
      "epoch: 168 loss: 1.6130342483520508 grad: 4.979014248263743\n",
      "epoch: 169 loss: 1.6011056900024414 grad: 4.914575670820745\n",
      "epoch: 170 loss: 1.6183162927627563 grad: 4.651962547733854\n",
      "epoch: 171 loss: 1.5954102277755737 grad: 4.1872929479068155\n",
      "epoch: 172 loss: 1.6114070415496826 grad: 6.125313181048301\n",
      "epoch: 173 loss: 1.5939795970916748 grad: 5.249699317079267\n",
      "epoch: 174 loss: 1.5966567993164062 grad: 4.646496060261168\n",
      "epoch: 175 loss: 1.5897690057754517 grad: 4.555021734293977\n",
      "epoch: 176 loss: 1.590691089630127 grad: 4.2719326610054695\n",
      "epoch: 177 loss: 1.5886785984039307 grad: 4.700878672148021\n",
      "epoch: 178 loss: 1.5854092836380005 grad: 4.621956980067165\n",
      "epoch: 179 loss: 1.6075950860977173 grad: 6.685394231620856\n",
      "epoch: 180 loss: 1.5989842414855957 grad: 5.475817269859348\n",
      "epoch: 181 loss: 1.6128512620925903 grad: 4.363454728231666\n",
      "epoch: 182 loss: 1.6242974996566772 grad: 6.593406492985066\n",
      "epoch: 183 loss: 1.5951616764068604 grad: 4.270704817044461\n",
      "epoch: 184 loss: 1.5954172611236572 grad: 4.479780691453896\n",
      "epoch: 185 loss: 1.6017227172851562 grad: 4.731948907664822\n",
      "epoch: 186 loss: 1.5936921834945679 grad: 4.365496737964983\n",
      "epoch: 187 loss: 1.5956257581710815 grad: 5.173311888007235\n",
      "epoch: 188 loss: 1.5951520204544067 grad: 4.65529940712755\n",
      "epoch: 189 loss: 1.5956186056137085 grad: 5.016924944066052\n",
      "epoch: 190 loss: 1.5962766408920288 grad: 4.97185406773091\n",
      "epoch: 191 loss: 1.5923088788986206 grad: 4.50325031025262\n",
      "epoch: 192 loss: 1.5862460136413574 grad: 4.2334305162463375\n",
      "epoch: 193 loss: 1.5858861207962036 grad: 5.0966142634530724\n",
      "epoch: 194 loss: 1.6004061698913574 grad: 4.292098995383561\n",
      "epoch: 195 loss: 1.587061882019043 grad: 4.856639035132106\n",
      "epoch: 196 loss: 1.6008139848709106 grad: 4.547285750759098\n",
      "epoch: 197 loss: 1.6049610376358032 grad: 5.348089447893832\n",
      "epoch: 198 loss: 1.638370394706726 grad: 6.086194167239228\n",
      "epoch: 199 loss: 1.6044286489486694 grad: 4.848751998703775\n",
      "epoch: 200 loss: 1.6052982807159424 grad: 4.209335952961687\n",
      "epoch: 201 loss: 1.5936009883880615 grad: 4.169448295985164\n",
      "epoch: 202 loss: 1.5868775844573975 grad: 4.158634130695812\n",
      "epoch: 203 loss: 1.5811336040496826 grad: 4.504548989766922\n",
      "epoch: 204 loss: 1.6056784391403198 grad: 5.235821119960161\n",
      "epoch: 205 loss: 1.6066181659698486 grad: 6.451988378707004\n",
      "epoch: 206 loss: 1.5889134407043457 grad: 4.110079180484397\n",
      "epoch: 207 loss: 1.5857635736465454 grad: 4.47854626930746\n",
      "epoch: 208 loss: 1.5965826511383057 grad: 5.1444097088969185\n",
      "epoch: 209 loss: 1.6005531549453735 grad: 4.956757421255776\n",
      "epoch: 210 loss: 1.6030399799346924 grad: 5.470857382264483\n",
      "epoch: 211 loss: 1.5920028686523438 grad: 4.729900954215616\n",
      "epoch: 212 loss: 1.5799998044967651 grad: 4.747064120156094\n",
      "epoch: 213 loss: 1.5872187614440918 grad: 4.430400158875327\n",
      "epoch: 214 loss: 1.574519395828247 grad: 4.464776914998298\n",
      "epoch: 215 loss: 1.5931835174560547 grad: 4.322025624202952\n",
      "epoch: 216 loss: 1.5919564962387085 grad: 4.410279521670556\n",
      "epoch: 217 loss: 1.5755412578582764 grad: 4.358305061975689\n",
      "epoch: 218 loss: 1.5988695621490479 grad: 4.878504816408435\n",
      "epoch: 219 loss: 1.604966640472412 grad: 4.935890529309579\n",
      "epoch: 220 loss: 1.5906317234039307 grad: 5.311341200994145\n",
      "epoch: 221 loss: 1.5786610841751099 grad: 3.533345316008161\n",
      "epoch: 222 loss: 1.5801438093185425 grad: 4.368335182517061\n",
      "epoch: 223 loss: 1.5998493432998657 grad: 5.1376500063737955\n",
      "epoch: 224 loss: 1.5872002840042114 grad: 4.302814205698834\n",
      "epoch: 225 loss: 1.5975760221481323 grad: 5.431003328898828\n",
      "epoch: 226 loss: 1.6042063236236572 grad: 5.2771786999923345\n",
      "epoch: 227 loss: 1.5991779565811157 grad: 6.242063835001967\n",
      "epoch: 228 loss: 1.5854003429412842 grad: 4.955810019490288\n",
      "epoch: 229 loss: 1.5727452039718628 grad: 4.74557276644246\n",
      "epoch: 230 loss: 1.5793150663375854 grad: 3.9684726485872908\n",
      "epoch: 231 loss: 1.57100248336792 grad: 3.9316166229058958\n",
      "epoch: 232 loss: 1.5839042663574219 grad: 4.798298901082756\n",
      "epoch: 233 loss: 1.5831894874572754 grad: 3.109128406092943\n",
      "epoch: 234 loss: 1.5767587423324585 grad: 3.8299401249587284\n",
      "epoch: 235 loss: 1.5814768075942993 grad: 4.276868330210989\n",
      "epoch: 236 loss: 1.575503945350647 grad: 4.668086854021004\n",
      "epoch: 237 loss: 1.5809723138809204 grad: 5.133372659917378\n",
      "epoch: 238 loss: 1.585157871246338 grad: 4.41892809615016\n",
      "epoch: 239 loss: 1.5693472623825073 grad: 3.5487680103312167\n",
      "epoch: 240 loss: 1.5859088897705078 grad: 4.280318731403043\n",
      "epoch: 241 loss: 1.58502995967865 grad: 3.3557295617940537\n",
      "epoch: 242 loss: 1.577907681465149 grad: 4.350934591057412\n",
      "epoch: 243 loss: 1.5707095861434937 grad: 4.107236830419172\n",
      "epoch: 244 loss: 1.5936169624328613 grad: 5.095425179462569\n",
      "epoch: 245 loss: 1.5937650203704834 grad: 5.143129845116337\n",
      "epoch: 246 loss: 1.577307939529419 grad: 4.5363683709885585\n",
      "epoch: 247 loss: 1.5742028951644897 grad: 4.319317981056253\n",
      "epoch: 248 loss: 1.5747919082641602 grad: 3.94649756735815\n",
      "epoch: 249 loss: 1.607570767402649 grad: 5.626538321667737\n",
      "epoch: 250 loss: 1.603916883468628 grad: 4.816508037405767\n",
      "epoch: 251 loss: 1.5737801790237427 grad: 3.5253756737895174\n",
      "epoch: 252 loss: 1.5787838697433472 grad: 4.321197403443559\n",
      "epoch: 253 loss: 1.5805962085723877 grad: 4.768325876063022\n",
      "epoch: 254 loss: 1.5791078805923462 grad: 5.424467629439811\n",
      "epoch: 255 loss: 1.576695442199707 grad: 3.507887764923731\n",
      "epoch: 256 loss: 1.5801786184310913 grad: 5.170572453933938\n",
      "epoch: 257 loss: 1.599522590637207 grad: 4.867725607373621\n",
      "epoch: 258 loss: 1.5663937330245972 grad: 4.138698565546729\n",
      "epoch: 259 loss: 1.585703730583191 grad: 3.6076672198702813\n",
      "epoch: 260 loss: 1.581666111946106 grad: 4.11398524718175\n",
      "epoch: 261 loss: 1.5679948329925537 grad: 5.183334997869897\n",
      "epoch: 262 loss: 1.5682755708694458 grad: 4.207832544582452\n",
      "epoch: 263 loss: 1.5843437910079956 grad: 4.227788216010086\n",
      "epoch: 264 loss: 1.5839426517486572 grad: 3.7931608943219977\n",
      "epoch: 265 loss: 1.5674080848693848 grad: 4.604763332175812\n",
      "epoch: 266 loss: 1.5672805309295654 grad: 4.341105037898968\n",
      "epoch: 267 loss: 1.572782278060913 grad: 5.038855453058065\n",
      "epoch: 268 loss: 1.5776219367980957 grad: 5.095273234473444\n",
      "epoch: 269 loss: 1.568004846572876 grad: 3.713801794069777\n",
      "epoch: 270 loss: 1.5799921751022339 grad: 3.2511349072772866\n",
      "epoch: 271 loss: 1.5925219058990479 grad: 5.512397901427387\n",
      "epoch: 272 loss: 1.5759727954864502 grad: 4.611906942047484\n",
      "epoch: 273 loss: 1.5676085948944092 grad: 3.6214343728311964\n",
      "epoch: 274 loss: 1.5718997716903687 grad: 4.171915452174598\n",
      "epoch: 275 loss: 1.586902379989624 grad: 4.510076118798608\n",
      "epoch: 276 loss: 1.6143072843551636 grad: 4.482648532049646\n",
      "epoch: 277 loss: 1.5677180290222168 grad: 4.438495812600569\n",
      "epoch: 278 loss: 1.5690399408340454 grad: 3.335359250062078\n",
      "epoch: 279 loss: 1.5617456436157227 grad: 3.020747252125491\n",
      "epoch: 280 loss: 1.5649120807647705 grad: 4.345645230737941\n",
      "epoch: 281 loss: 1.5672329664230347 grad: 3.2541195178962155\n",
      "epoch: 282 loss: 1.5645582675933838 grad: 3.6093515962970635\n",
      "epoch: 283 loss: 1.5668977499008179 grad: 3.855961184171189\n",
      "epoch: 284 loss: 1.5895529985427856 grad: 5.472960608269457\n",
      "epoch: 285 loss: 1.5696871280670166 grad: 4.7127844780281745\n",
      "epoch: 286 loss: 1.5997761487960815 grad: 4.70963433276082\n",
      "epoch: 287 loss: 1.583421230316162 grad: 3.825404292847484\n",
      "epoch: 288 loss: 1.5827195644378662 grad: 4.009390634647539\n",
      "epoch: 289 loss: 1.5925438404083252 grad: 5.253396093200293\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 290 loss: 1.5651780366897583 grad: 4.3372920254343965\n",
      "epoch: 291 loss: 1.5820883512496948 grad: 4.765876555455402\n",
      "epoch: 292 loss: 1.5814687013626099 grad: 3.6518254187197936\n",
      "epoch: 293 loss: 1.5699994564056396 grad: 4.822380377419623\n",
      "epoch: 294 loss: 1.5953965187072754 grad: 4.509035977862613\n",
      "epoch: 295 loss: 1.5639872550964355 grad: 3.858196452042127\n",
      "epoch: 296 loss: 1.5646178722381592 grad: 3.6342088643190946\n",
      "epoch: 297 loss: 1.581939458847046 grad: 4.619795846815472\n",
      "epoch: 298 loss: 1.578020453453064 grad: 4.770700897803024\n",
      "epoch: 299 loss: 1.6026861667633057 grad: 3.6272682274223955\n",
      "epoch: 300 loss: 1.5793426036834717 grad: 3.603677733166468\n",
      "epoch: 301 loss: 1.5779913663864136 grad: 4.644744732676621\n",
      "epoch: 302 loss: 1.5764740705490112 grad: 4.531948836046583\n",
      "epoch: 303 loss: 1.5591638088226318 grad: 3.600534548857138\n",
      "epoch: 304 loss: 1.5678085088729858 grad: 3.6204983168302403\n",
      "epoch: 305 loss: 1.5855717658996582 grad: 4.638484934197782\n",
      "epoch: 306 loss: 1.5757472515106201 grad: 3.5232483739169793\n",
      "epoch: 307 loss: 1.5698280334472656 grad: 4.112932603631082\n",
      "epoch: 308 loss: 1.563846230506897 grad: 4.381907362707683\n",
      "epoch: 309 loss: 1.583898901939392 grad: 3.5891397611563476\n",
      "epoch: 310 loss: 1.5782185792922974 grad: 4.272413827289503\n",
      "epoch: 311 loss: 1.5718966722488403 grad: 4.152277155541953\n",
      "epoch: 312 loss: 1.5882729291915894 grad: 3.896631456967912\n",
      "epoch: 313 loss: 1.5757352113723755 grad: 6.1765325865656955\n",
      "epoch: 314 loss: 1.5750584602355957 grad: 4.808270395420963\n",
      "epoch: 315 loss: 1.5722486972808838 grad: 4.38556095293771\n",
      "epoch: 316 loss: 1.5594826936721802 grad: 3.812319425072625\n",
      "epoch: 317 loss: 1.5762605667114258 grad: 4.376414458951521\n",
      "epoch: 318 loss: 1.5738916397094727 grad: 3.9865263765872605\n",
      "epoch: 319 loss: 1.5714324712753296 grad: 4.906003602967776\n",
      "epoch: 320 loss: 1.5772364139556885 grad: 4.825708988985768\n",
      "epoch: 321 loss: 1.5626758337020874 grad: 3.428383669498166\n",
      "epoch: 322 loss: 1.5763146877288818 grad: 4.737464189347975\n",
      "epoch: 323 loss: 1.5688997507095337 grad: 3.7494401289484345\n",
      "epoch: 324 loss: 1.5637240409851074 grad: 5.115925013191881\n",
      "epoch: 325 loss: 1.562909722328186 grad: 3.6528129669123177\n",
      "epoch: 326 loss: 1.5610162019729614 grad: 4.4272249487194655\n",
      "epoch: 327 loss: 1.5786329507827759 grad: 3.6803035687782253\n",
      "epoch: 328 loss: 1.574853539466858 grad: 4.029486622693106\n",
      "epoch: 329 loss: 1.56479012966156 grad: 3.535379542792793\n",
      "epoch: 330 loss: 1.5608165264129639 grad: 2.4295111634073643\n",
      "epoch: 331 loss: 1.5605767965316772 grad: 2.7697963430347974\n",
      "epoch: 332 loss: 1.5544233322143555 grad: 2.5259237514570234\n",
      "epoch: 333 loss: 1.559849500656128 grad: 4.637565510051328\n",
      "epoch: 334 loss: 1.5995932817459106 grad: 5.114899275614868\n",
      "epoch: 335 loss: 1.566490888595581 grad: 3.7251140709733126\n",
      "epoch: 336 loss: 1.5888574123382568 grad: 4.425309001059687\n",
      "epoch: 337 loss: 1.5607372522354126 grad: 4.342403330243645\n",
      "epoch: 338 loss: 1.559841513633728 grad: 2.7822495740128614\n",
      "epoch: 339 loss: 1.5842936038970947 grad: 5.978661952509088\n",
      "epoch: 340 loss: 1.5871424674987793 grad: 4.3015666971533575\n",
      "epoch: 341 loss: 1.5770230293273926 grad: 4.723474806529272\n",
      "epoch: 342 loss: 1.5828709602355957 grad: 5.240453524695463\n",
      "epoch: 343 loss: 1.5805774927139282 grad: 5.598883223256361\n",
      "epoch: 344 loss: 1.5859569311141968 grad: 4.6953722834400535\n",
      "epoch: 345 loss: 1.5795360803604126 grad: 3.6773877415796012\n",
      "epoch: 346 loss: 1.5587986707687378 grad: 3.134579273926888\n",
      "epoch: 347 loss: 1.5741310119628906 grad: 3.984209454394037\n",
      "epoch: 348 loss: 1.5621464252471924 grad: 3.2493059854994866\n",
      "epoch: 349 loss: 1.5545638799667358 grad: 3.370305984321162\n",
      "epoch: 350 loss: 1.574218511581421 grad: 3.751208020079325\n",
      "epoch: 351 loss: 1.580822229385376 grad: 4.877882105668568\n",
      "epoch: 352 loss: 1.588525652885437 grad: 4.359143693029118\n",
      "epoch: 353 loss: 1.601672887802124 grad: 4.69281580223135\n",
      "epoch: 354 loss: 1.5637688636779785 grad: 3.5642827001415234\n",
      "epoch: 355 loss: 1.5751986503601074 grad: 4.124614536376886\n",
      "epoch: 356 loss: 1.5892868041992188 grad: 6.557388295488889\n",
      "epoch: 357 loss: 1.5727930068969727 grad: 3.6523120368287905\n",
      "epoch: 358 loss: 1.5672850608825684 grad: 3.3057893445900826\n",
      "epoch: 359 loss: 1.5563000440597534 grad: 3.4641924181651564\n",
      "epoch: 360 loss: 1.5823860168457031 grad: 5.492793716579053\n",
      "epoch: 361 loss: 1.5696868896484375 grad: 3.879606243022842\n",
      "epoch: 362 loss: 1.5912857055664062 grad: 4.580098985160551\n",
      "epoch: 363 loss: 1.5795135498046875 grad: 5.579862518287013\n",
      "epoch: 364 loss: 1.5946627855300903 grad: 4.60879746781448\n",
      "epoch: 365 loss: 1.5612504482269287 grad: 3.0368678881004265\n",
      "epoch: 366 loss: 1.5536078214645386 grad: 2.294039820262115\n",
      "epoch: 367 loss: 1.5598176717758179 grad: 3.3594193278356017\n",
      "epoch: 368 loss: 1.5537892580032349 grad: 3.3698779265486416\n",
      "epoch: 369 loss: 1.554005742073059 grad: 4.444063470561607\n",
      "epoch: 370 loss: 1.5643765926361084 grad: 4.118641504755008\n",
      "epoch: 371 loss: 1.5690199136734009 grad: 3.6702464672093784\n",
      "epoch: 372 loss: 1.566046953201294 grad: 2.5950595985147307\n",
      "epoch: 373 loss: 1.5733696222305298 grad: 3.3597675278362162\n",
      "epoch: 374 loss: 1.5639535188674927 grad: 3.4539099205524795\n",
      "epoch: 375 loss: 1.579472303390503 grad: 4.372988313514602\n",
      "epoch: 376 loss: 1.5739738941192627 grad: 4.890187116994385\n",
      "epoch: 377 loss: 1.5576953887939453 grad: 3.019221000922465\n",
      "epoch: 378 loss: 1.5551893711090088 grad: 4.01798914267563\n",
      "epoch: 379 loss: 1.5629079341888428 grad: 2.6917727558636177\n",
      "epoch: 380 loss: 1.5503170490264893 grad: 2.53889178907001\n",
      "epoch: 381 loss: 1.558443307876587 grad: 4.004355460559667\n",
      "epoch: 382 loss: 1.552066683769226 grad: 3.3005072226697374\n",
      "epoch: 383 loss: 1.5682270526885986 grad: 4.374020371146259\n",
      "epoch: 384 loss: 1.561948299407959 grad: 3.8425567795124738\n",
      "epoch: 385 loss: 1.5687572956085205 grad: 3.30007266891293\n",
      "epoch: 386 loss: 1.5659109354019165 grad: 2.9336660903121627\n",
      "epoch: 387 loss: 1.5617700815200806 grad: 4.82515800533386\n",
      "epoch: 388 loss: 1.5623581409454346 grad: 3.456885482137618\n",
      "epoch: 389 loss: 1.566146969795227 grad: 3.738022022433542\n",
      "epoch: 390 loss: 1.5577129125595093 grad: 2.6294933440576904\n",
      "epoch: 391 loss: 1.5567312240600586 grad: 3.596317284646409\n",
      "epoch: 392 loss: 1.556889533996582 grad: 2.2605472159563305\n",
      "epoch: 393 loss: 1.563895344734192 grad: 5.060460797342061\n",
      "epoch: 394 loss: 1.5605058670043945 grad: 2.5429175264883384\n",
      "epoch: 395 loss: 1.5662187337875366 grad: 3.665923620187621\n",
      "epoch: 396 loss: 1.5692437887191772 grad: 3.7333202356325743\n",
      "epoch: 397 loss: 1.55947744846344 grad: 2.974782949819801\n",
      "epoch: 398 loss: 1.5737711191177368 grad: 4.055574149321923\n",
      "epoch: 399 loss: 1.5657122135162354 grad: 4.074713745749843\n",
      "epoch: 400 loss: 1.5559577941894531 grad: 3.455817175121438\n",
      "epoch: 401 loss: 1.5791436433792114 grad: 3.2741746007843737\n",
      "epoch: 402 loss: 1.571176528930664 grad: 4.433380120823517\n",
      "epoch: 403 loss: 1.5640634298324585 grad: 4.144966249369848\n",
      "epoch: 404 loss: 1.554795503616333 grad: 3.1722293122752934\n",
      "epoch: 405 loss: 1.5477303266525269 grad: 3.0838161435625118\n",
      "epoch: 406 loss: 1.5721333026885986 grad: 4.572974149380931\n",
      "epoch: 407 loss: 1.5775967836380005 grad: 5.112712537748006\n",
      "epoch: 408 loss: 1.557806134223938 grad: 3.239996339803206\n",
      "epoch: 409 loss: 1.5571589469909668 grad: 3.4313720593083206\n",
      "epoch: 410 loss: 1.5694726705551147 grad: 4.031821495331415\n",
      "epoch: 411 loss: 1.5705721378326416 grad: 4.542382012198657\n",
      "epoch: 412 loss: 1.5765491724014282 grad: 3.5687054807716296\n",
      "epoch: 413 loss: 1.5611289739608765 grad: 3.4000324041869554\n",
      "epoch: 414 loss: 1.5618178844451904 grad: 3.394248330944913\n",
      "epoch: 415 loss: 1.5691670179367065 grad: 3.7827201465692784\n",
      "epoch: 416 loss: 1.5585836172103882 grad: 4.329957704494384\n",
      "epoch: 417 loss: 1.5767618417739868 grad: 4.1539840989850605\n",
      "epoch: 418 loss: 1.5889184474945068 grad: 5.0669711111577564\n",
      "epoch: 419 loss: 1.568906307220459 grad: 3.8306702108113964\n",
      "epoch: 420 loss: 1.5698459148406982 grad: 4.581933627152902\n",
      "epoch: 421 loss: 1.570376992225647 grad: 4.040231711424066\n",
      "epoch: 422 loss: 1.5651178359985352 grad: 3.5029222946108427\n",
      "epoch: 423 loss: 1.5559437274932861 grad: 4.800088774612507\n",
      "epoch: 424 loss: 1.552521824836731 grad: 3.3716947999795646\n",
      "epoch: 425 loss: 1.5894750356674194 grad: 5.328086485257688\n",
      "epoch: 426 loss: 1.5634350776672363 grad: 3.9381989065101544\n",
      "epoch: 427 loss: 1.5560308694839478 grad: 3.1825371465458594\n",
      "epoch: 428 loss: 1.557991862297058 grad: 2.8890664057168447\n",
      "epoch: 429 loss: 1.5543837547302246 grad: 3.535643599937778\n",
      "epoch: 430 loss: 1.5757999420166016 grad: 4.787428386539694\n",
      "epoch: 431 loss: 1.5866931676864624 grad: 4.352580579296045\n",
      "epoch: 432 loss: 1.559645414352417 grad: 3.1497162274364374\n",
      "epoch: 433 loss: 1.5784369707107544 grad: 3.930518568092243\n",
      "epoch: 434 loss: 1.5570157766342163 grad: 3.04776468853079\n",
      "epoch: 435 loss: 1.553124189376831 grad: 3.643675083319354\n",
      "epoch: 436 loss: 1.5712462663650513 grad: 3.9359094345040013\n",
      "epoch: 437 loss: 1.5621627569198608 grad: 2.8961837513644206\n",
      "epoch: 438 loss: 1.577290415763855 grad: 3.833402880711978\n",
      "epoch: 439 loss: 1.560299038887024 grad: 3.2397134847143785\n",
      "epoch: 440 loss: 1.5578609704971313 grad: 3.9361487709727476\n",
      "epoch: 441 loss: 1.5429216623306274 grad: 4.501151012575177\n",
      "epoch: 442 loss: 1.5887963771820068 grad: 5.054830728578388\n",
      "epoch: 443 loss: 1.567771553993225 grad: 4.815595236249284\n",
      "epoch: 444 loss: 1.5638362169265747 grad: 4.0507179132018525\n",
      "epoch: 445 loss: 1.5787814855575562 grad: 3.356456202264278\n",
      "epoch: 446 loss: 1.5558465719223022 grad: 3.0642272935933157\n",
      "epoch: 447 loss: 1.555322289466858 grad: 4.014921062708082\n",
      "epoch: 448 loss: 1.5625935792922974 grad: 3.470057149993761\n",
      "epoch: 449 loss: 1.5442190170288086 grad: 1.9227021853884088\n",
      "epoch: 450 loss: 1.5448403358459473 grad: 2.457730506504345\n",
      "epoch: 451 loss: 1.549049735069275 grad: 2.9302465438306755\n",
      "epoch: 452 loss: 1.5412561893463135 grad: 2.6736763492612488\n",
      "epoch: 453 loss: 1.552203893661499 grad: 3.1666713524110772\n",
      "epoch: 454 loss: 1.5508735179901123 grad: 3.28278301594441\n",
      "epoch: 455 loss: 1.5507583618164062 grad: 2.9604627163365063\n",
      "epoch: 456 loss: 1.5583677291870117 grad: 3.4881616147610637\n",
      "epoch: 457 loss: 1.5609362125396729 grad: 3.0436518393743577\n",
      "epoch: 458 loss: 1.5598671436309814 grad: 3.542050080962867\n",
      "epoch: 459 loss: 1.5540214776992798 grad: 3.7661165237651377\n",
      "epoch: 460 loss: 1.546364188194275 grad: 3.3616958877241503\n",
      "epoch: 461 loss: 1.5848981142044067 grad: 4.691788703399939\n",
      "epoch: 462 loss: 1.5637098550796509 grad: 3.86757150303387\n",
      "epoch: 463 loss: 1.5454682111740112 grad: 2.16070331953803\n",
      "epoch: 464 loss: 1.553936243057251 grad: 4.5228698784671195\n",
      "epoch: 465 loss: 1.5433545112609863 grad: 2.9239332841521177\n",
      "epoch: 466 loss: 1.5472427606582642 grad: 3.374086250787487\n",
      "epoch: 467 loss: 1.5465282201766968 grad: 3.4959623926081624\n",
      "epoch: 468 loss: 1.5496211051940918 grad: 3.013536359702911\n",
      "epoch: 469 loss: 1.5551958084106445 grad: 4.0750088228263515\n",
      "epoch: 470 loss: 1.5554773807525635 grad: 3.744530892590903\n",
      "epoch: 471 loss: 1.5630017518997192 grad: 3.8634947645412763\n",
      "epoch: 472 loss: 1.6160744428634644 grad: 4.416993172191345\n",
      "epoch: 473 loss: 1.5764756202697754 grad: 4.82066784707978\n",
      "epoch: 474 loss: 1.5694650411605835 grad: 2.92193923679861\n",
      "epoch: 475 loss: 1.5668270587921143 grad: 3.12553384860084\n",
      "epoch: 476 loss: 1.5639264583587646 grad: 3.911452824539903\n",
      "epoch: 477 loss: 1.5606932640075684 grad: 4.5705639705253835\n",
      "epoch: 478 loss: 1.5618292093276978 grad: 3.5053799006626614\n",
      "epoch: 479 loss: 1.559865117073059 grad: 3.5277285365280284\n",
      "epoch: 480 loss: 1.5514277219772339 grad: 3.2853965638581326\n",
      "epoch: 481 loss: 1.5638446807861328 grad: 3.584696547273517\n",
      "epoch: 482 loss: 1.550735592842102 grad: 2.9762887209654574\n",
      "epoch: 483 loss: 1.5532389879226685 grad: 4.139722029847803\n",
      "epoch: 484 loss: 1.5752525329589844 grad: 3.6553757985798025\n",
      "epoch: 485 loss: 1.5633695125579834 grad: 3.3060143256338317\n",
      "epoch: 486 loss: 1.5420680046081543 grad: 2.851427983344657\n",
      "epoch: 487 loss: 1.5444917678833008 grad: 2.4597815594029213\n",
      "epoch: 488 loss: 1.5378963947296143 grad: 3.3376956744272084\n",
      "epoch: 489 loss: 1.5592753887176514 grad: 3.4256597803790942\n",
      "epoch: 490 loss: 1.5556678771972656 grad: 2.8791287642607473\n",
      "epoch: 491 loss: 1.5489739179611206 grad: 4.107920608564355\n",
      "epoch: 492 loss: 1.5483367443084717 grad: 2.984895909130242\n",
      "epoch: 493 loss: 1.5415452718734741 grad: 3.499457574165746\n",
      "epoch: 494 loss: 1.5469216108322144 grad: 3.4707823345779802\n",
      "epoch: 495 loss: 1.553468108177185 grad: 3.665396115351924\n",
      "epoch: 496 loss: 1.5481147766113281 grad: 3.6865665660516007\n",
      "epoch: 497 loss: 1.5490120649337769 grad: 3.258685031085159\n",
      "epoch: 498 loss: 1.5611138343811035 grad: 5.186610712285357\n",
      "epoch: 499 loss: 1.5460089445114136 grad: 3.2094951268345007\n",
      "1.8850326761603355\n",
      "epoch: 0 loss: 2.30279803276062 grad: 1.3480483914895485\n",
      "epoch: 1 loss: 2.3031933307647705 grad: 1.356031636275085\n",
      "epoch: 2 loss: 2.302449941635132 grad: 1.3560324208552226\n",
      "epoch: 3 loss: 2.3035659790039062 grad: 1.3393974089052616\n",
      "epoch: 4 loss: 2.3034074306488037 grad: 1.3423975775136598\n",
      "epoch: 5 loss: 2.3024821281433105 grad: 1.3531876383312342\n",
      "epoch: 6 loss: 2.3031883239746094 grad: 1.345953474444012\n",
      "epoch: 7 loss: 2.303096294403076 grad: 1.3565510500606799\n",
      "epoch: 8 loss: 2.3026809692382812 grad: 1.3620391096217588\n",
      "epoch: 9 loss: 2.3028552532196045 grad: 1.351730574362187\n",
      "epoch: 10 loss: 2.303255796432495 grad: 1.3466584250415927\n",
      "epoch: 11 loss: 2.3032827377319336 grad: 1.3419448970188756\n",
      "epoch: 12 loss: 2.3027689456939697 grad: 1.3518177238348428\n",
      "epoch: 13 loss: 2.302903175354004 grad: 1.3484280790675371\n",
      "epoch: 14 loss: 2.3027195930480957 grad: 1.3559700100616152\n",
      "epoch: 15 loss: 2.3030436038970947 grad: 1.3476100394979031\n",
      "epoch: 16 loss: 2.302525043487549 grad: 1.3573415517171343\n",
      "epoch: 17 loss: 2.302811861038208 grad: 1.355403555180168\n",
      "epoch: 18 loss: 2.302798271179199 grad: 1.3554169988159888\n",
      "epoch: 19 loss: 2.302647829055786 grad: 1.3512480022821811\n",
      "epoch: 20 loss: 2.3031082153320312 grad: 1.3471251984703398\n",
      "epoch: 21 loss: 2.3028934001922607 grad: 1.3612902829726596\n",
      "epoch: 22 loss: 2.3026745319366455 grad: 1.3415757237272041\n",
      "epoch: 23 loss: 2.302677631378174 grad: 1.3476146597429992\n",
      "epoch: 24 loss: 2.3026864528656006 grad: 1.3641947106133023\n",
      "epoch: 25 loss: 2.303223133087158 grad: 1.3397117397315534\n",
      "epoch: 26 loss: 2.3028833866119385 grad: 1.3479172607869028\n",
      "epoch: 27 loss: 2.302744150161743 grad: 1.3585967740731402\n",
      "epoch: 28 loss: 2.303102970123291 grad: 1.3540619317357176\n",
      "epoch: 29 loss: 2.303534507751465 grad: 1.3241166718995259\n",
      "epoch: 30 loss: 2.302927255630493 grad: 1.3408778762917906\n",
      "epoch: 31 loss: 2.3028881549835205 grad: 1.3453500966434293\n",
      "epoch: 32 loss: 2.303048610687256 grad: 1.3401569409428962\n",
      "epoch: 33 loss: 2.3026442527770996 grad: 1.3533949976387833\n",
      "epoch: 34 loss: 2.3031184673309326 grad: 1.3452132370910563\n",
      "epoch: 35 loss: 2.3027074337005615 grad: 1.3424952611334562\n",
      "epoch: 36 loss: 2.302902936935425 grad: 1.3520590705530984\n",
      "epoch: 37 loss: 2.3031938076019287 grad: 1.345909014885639\n",
      "epoch: 38 loss: 2.303096055984497 grad: 1.3432628864437224\n",
      "epoch: 39 loss: 2.3032987117767334 grad: 1.3430819026368213\n",
      "epoch: 40 loss: 2.3026723861694336 grad: 1.3504211988617918\n",
      "epoch: 41 loss: 2.3028786182403564 grad: 1.3423530262532748\n",
      "epoch: 42 loss: 2.3029444217681885 grad: 1.3494858642382221\n",
      "epoch: 43 loss: 2.3028454780578613 grad: 1.3554200328321062\n",
      "epoch: 44 loss: 2.303135395050049 grad: 1.3338409585541942\n",
      "epoch: 45 loss: 2.3030662536621094 grad: 1.337411098721777\n",
      "epoch: 46 loss: 2.3028883934020996 grad: 1.3555517326892605\n",
      "epoch: 47 loss: 2.3030614852905273 grad: 1.3509915195542226\n",
      "epoch: 48 loss: 2.303645610809326 grad: 1.3361717861733355\n",
      "epoch: 49 loss: 2.3029236793518066 grad: 1.3489598118263992\n",
      "epoch: 50 loss: 2.30336856842041 grad: 1.3289501607503063\n",
      "epoch: 51 loss: 2.3029956817626953 grad: 1.3555847501404406\n",
      "epoch: 52 loss: 2.3025050163269043 grad: 1.3497995852588838\n",
      "epoch: 53 loss: 2.303062915802002 grad: 1.3511527835295374\n",
      "epoch: 54 loss: 2.302671194076538 grad: 1.3570433046968122\n",
      "epoch: 55 loss: 2.3029863834381104 grad: 1.3387595144274187\n",
      "epoch: 56 loss: 2.303004741668701 grad: 1.3448699994238154\n",
      "epoch: 57 loss: 2.3024468421936035 grad: 1.3446219108170934\n",
      "epoch: 58 loss: 2.3020853996276855 grad: 1.3481012146443216\n",
      "epoch: 59 loss: 2.302917003631592 grad: 1.348980951021307\n",
      "epoch: 60 loss: 2.30220627784729 grad: 1.3521340354364217\n",
      "epoch: 61 loss: 2.3029654026031494 grad: 1.3441163037038808\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 62 loss: 2.302802562713623 grad: 1.3453160856355217\n",
      "epoch: 63 loss: 2.303004026412964 grad: 1.3411356031299673\n",
      "epoch: 64 loss: 2.302661657333374 grad: 1.3402822649601611\n",
      "epoch: 65 loss: 2.302712917327881 grad: 1.352252421752801\n",
      "epoch: 66 loss: 2.302159309387207 grad: 1.3508925342947127\n",
      "epoch: 67 loss: 2.302953004837036 grad: 1.3500720454871447\n",
      "epoch: 68 loss: 2.302356004714966 grad: 1.3528829489627645\n",
      "epoch: 69 loss: 2.3026487827301025 grad: 1.3447401641557615\n",
      "epoch: 70 loss: 2.302983283996582 grad: 1.3440935382885593\n",
      "epoch: 71 loss: 2.3033721446990967 grad: 1.3371427369669877\n",
      "epoch: 72 loss: 2.3026282787323 grad: 1.34790032344412\n",
      "epoch: 73 loss: 2.302680015563965 grad: 1.3454901723612456\n",
      "epoch: 74 loss: 2.3029630184173584 grad: 1.3400633438797076\n",
      "epoch: 75 loss: 2.302886724472046 grad: 1.3376216551359181\n",
      "epoch: 76 loss: 2.30352520942688 grad: 1.3439511566012654\n",
      "epoch: 77 loss: 2.302522897720337 grad: 1.3533638209134105\n",
      "epoch: 78 loss: 2.3028929233551025 grad: 1.3365640988396037\n",
      "epoch: 79 loss: 2.3030192852020264 grad: 1.3425308989715719\n",
      "epoch: 80 loss: 2.3026158809661865 grad: 1.346674430481572\n",
      "epoch: 81 loss: 2.3029325008392334 grad: 1.3376421453394292\n",
      "epoch: 82 loss: 2.3024754524230957 grad: 1.3456156402327386\n",
      "epoch: 83 loss: 2.3029751777648926 grad: 1.3355626431035086\n",
      "epoch: 84 loss: 2.302424430847168 grad: 1.3504034611137792\n",
      "epoch: 85 loss: 2.302263021469116 grad: 1.346526764362814\n",
      "epoch: 86 loss: 2.302811622619629 grad: 1.333812479158893\n",
      "epoch: 87 loss: 2.302637815475464 grad: 1.340580122968522\n",
      "epoch: 88 loss: 2.303474187850952 grad: 1.3358529211310226\n",
      "epoch: 89 loss: 2.303330659866333 grad: 1.3239970196053268\n",
      "epoch: 90 loss: 2.302412509918213 grad: 1.3553101496054007\n",
      "epoch: 91 loss: 2.303683280944824 grad: 1.327030177224457\n",
      "epoch: 92 loss: 2.3030357360839844 grad: 1.336914472106386\n",
      "epoch: 93 loss: 2.302814245223999 grad: 1.3383585125566386\n",
      "epoch: 94 loss: 2.3025991916656494 grad: 1.3410226645886838\n",
      "epoch: 95 loss: 2.3022377490997314 grad: 1.3540238446966257\n",
      "epoch: 96 loss: 2.303011894226074 grad: 1.3325615128768342\n",
      "epoch: 97 loss: 2.3021764755249023 grad: 1.3446905841248937\n",
      "epoch: 98 loss: 2.3024961948394775 grad: 1.3509260980811502\n",
      "epoch: 99 loss: 2.303027391433716 grad: 1.336510306612278\n",
      "epoch: 100 loss: 2.3030030727386475 grad: 1.3484849070036222\n",
      "epoch: 101 loss: 2.3030900955200195 grad: 1.333935107937866\n",
      "epoch: 102 loss: 2.303114175796509 grad: 1.3361270258273368\n",
      "epoch: 103 loss: 2.302966356277466 grad: 1.344863881990831\n",
      "epoch: 104 loss: 2.302896022796631 grad: 1.3313022560499135\n",
      "epoch: 105 loss: 2.302750825881958 grad: 1.3423360585316366\n",
      "epoch: 106 loss: 2.302928924560547 grad: 1.3335437663121237\n",
      "epoch: 107 loss: 2.3024981021881104 grad: 1.3366370579719336\n",
      "epoch: 108 loss: 2.302703619003296 grad: 1.3444851132420201\n",
      "epoch: 109 loss: 2.3027920722961426 grad: 1.3381332148583458\n",
      "epoch: 110 loss: 2.3029325008392334 grad: 1.3355782411083401\n",
      "epoch: 111 loss: 2.30324649810791 grad: 1.3436621338542964\n",
      "epoch: 112 loss: 2.302811861038208 grad: 1.3334333848537108\n",
      "epoch: 113 loss: 2.302584409713745 grad: 1.3398057227577305\n",
      "epoch: 114 loss: 2.3023288249969482 grad: 1.3437257734652135\n",
      "epoch: 115 loss: 2.302274227142334 grad: 1.342370435857909\n",
      "epoch: 116 loss: 2.3032517433166504 grad: 1.3345351241277679\n",
      "epoch: 117 loss: 2.3025448322296143 grad: 1.3486801833875242\n",
      "epoch: 118 loss: 2.3029677867889404 grad: 1.3419863684878994\n",
      "epoch: 119 loss: 2.3026204109191895 grad: 1.340426518792464\n",
      "epoch: 120 loss: 2.3034605979919434 grad: 1.32967616604375\n",
      "epoch: 121 loss: 2.3024022579193115 grad: 1.3497670367064456\n",
      "epoch: 122 loss: 2.3019802570343018 grad: 1.3460059490623988\n",
      "epoch: 123 loss: 2.302997589111328 grad: 1.345690487133753\n",
      "epoch: 124 loss: 2.3028504848480225 grad: 1.3400404125707046\n",
      "epoch: 125 loss: 2.3028595447540283 grad: 1.336298039284653\n",
      "epoch: 126 loss: 2.3024606704711914 grad: 1.3374100818283974\n",
      "epoch: 127 loss: 2.302611827850342 grad: 1.3408944396198623\n",
      "epoch: 128 loss: 2.302327871322632 grad: 1.3435828581134537\n",
      "epoch: 129 loss: 2.3026721477508545 grad: 1.3430270428200148\n",
      "epoch: 130 loss: 2.302767515182495 grad: 1.341215446835295\n",
      "epoch: 131 loss: 2.3028793334960938 grad: 1.342344201962641\n",
      "epoch: 132 loss: 2.3022024631500244 grad: 1.3436708291955588\n",
      "epoch: 133 loss: 2.3024160861968994 grad: 1.344657265401948\n",
      "epoch: 134 loss: 2.3023841381073 grad: 1.3412232269248408\n",
      "epoch: 135 loss: 2.302417516708374 grad: 1.3492230621724581\n",
      "epoch: 136 loss: 2.3030428886413574 grad: 1.336892160006784\n",
      "epoch: 137 loss: 2.3027219772338867 grad: 1.3306615528380794\n",
      "epoch: 138 loss: 2.30253267288208 grad: 1.3348238741210292\n",
      "epoch: 139 loss: 2.302427291870117 grad: 1.341748569105264\n",
      "epoch: 140 loss: 2.3027803897857666 grad: 1.3416987004457042\n",
      "epoch: 141 loss: 2.302395820617676 grad: 1.3405246997385152\n",
      "epoch: 142 loss: 2.3023104667663574 grad: 1.3428333524378047\n",
      "epoch: 143 loss: 2.3028688430786133 grad: 1.342081222513188\n",
      "epoch: 144 loss: 2.3027660846710205 grad: 1.33495081126106\n",
      "epoch: 145 loss: 2.302659511566162 grad: 1.3385841833087542\n",
      "epoch: 146 loss: 2.302863359451294 grad: 1.330842424182236\n",
      "epoch: 147 loss: 2.302887201309204 grad: 1.3394211261304065\n",
      "epoch: 148 loss: 2.3029751777648926 grad: 1.3353464568203817\n",
      "epoch: 149 loss: 2.302900791168213 grad: 1.3406422056501643\n",
      "epoch: 150 loss: 2.3025238513946533 grad: 1.3408387664646384\n",
      "epoch: 151 loss: 2.302792549133301 grad: 1.3283345037960403\n",
      "epoch: 152 loss: 2.3030507564544678 grad: 1.3328313539987282\n",
      "epoch: 153 loss: 2.3024563789367676 grad: 1.345019593432043\n",
      "epoch: 154 loss: 2.302891969680786 grad: 1.3333362313948336\n",
      "epoch: 155 loss: 2.3031740188598633 grad: 1.3299463466105481\n",
      "epoch: 156 loss: 2.3027453422546387 grad: 1.3535698819184854\n",
      "epoch: 157 loss: 2.302069902420044 grad: 1.3432369581165\n",
      "epoch: 158 loss: 2.302401065826416 grad: 1.3435452058726538\n",
      "epoch: 159 loss: 2.3027584552764893 grad: 1.3345185427830393\n",
      "epoch: 160 loss: 2.3023629188537598 grad: 1.3499202226429055\n",
      "epoch: 161 loss: 2.303205966949463 grad: 1.3255352342043012\n",
      "epoch: 162 loss: 2.302917242050171 grad: 1.338310131226622\n",
      "epoch: 163 loss: 2.3025341033935547 grad: 1.3376663706065821\n",
      "epoch: 164 loss: 2.3031256198883057 grad: 1.3220758719318029\n",
      "epoch: 165 loss: 2.3019726276397705 grad: 1.3407143928565173\n",
      "epoch: 166 loss: 2.302511215209961 grad: 1.3312205452996764\n",
      "epoch: 167 loss: 2.3024537563323975 grad: 1.3311919473547724\n",
      "epoch: 168 loss: 2.302981376647949 grad: 1.340379846581657\n",
      "epoch: 169 loss: 2.302208185195923 grad: 1.3447346176309067\n",
      "epoch: 170 loss: 2.3020355701446533 grad: 1.352202944322637\n",
      "epoch: 171 loss: 2.3029162883758545 grad: 1.3435890968401163\n",
      "epoch: 172 loss: 2.3029110431671143 grad: 1.3379691596556869\n",
      "epoch: 173 loss: 2.3020834922790527 grad: 1.3377259705633309\n",
      "epoch: 174 loss: 2.3028414249420166 grad: 1.3226302491005746\n",
      "epoch: 175 loss: 2.302720308303833 grad: 1.3390233686992101\n",
      "epoch: 176 loss: 2.302968978881836 grad: 1.3256536544492794\n",
      "epoch: 177 loss: 2.3028812408447266 grad: 1.3384956456258863\n",
      "epoch: 178 loss: 2.3032939434051514 grad: 1.329054699733942\n",
      "epoch: 179 loss: 2.3022170066833496 grad: 1.346250167877842\n",
      "epoch: 180 loss: 2.3027262687683105 grad: 1.3320287218269344\n",
      "epoch: 181 loss: 2.302887439727783 grad: 1.3425946118021828\n",
      "epoch: 182 loss: 2.3024282455444336 grad: 1.3336252220000864\n",
      "epoch: 183 loss: 2.3028452396392822 grad: 1.334343222782962\n",
      "epoch: 184 loss: 2.302452325820923 grad: 1.3326538811578224\n",
      "epoch: 185 loss: 2.303100109100342 grad: 1.336408744547664\n",
      "epoch: 186 loss: 2.3026137351989746 grad: 1.3441266193819632\n",
      "epoch: 187 loss: 2.302797317504883 grad: 1.3288344319536542\n",
      "epoch: 188 loss: 2.3024771213531494 grad: 1.3329318975752575\n",
      "epoch: 189 loss: 2.302165985107422 grad: 1.3376121485461703\n",
      "epoch: 190 loss: 2.302398443222046 grad: 1.3483054721173608\n",
      "epoch: 191 loss: 2.3028318881988525 grad: 1.3422887787104598\n",
      "epoch: 192 loss: 2.3026623725891113 grad: 1.328976611832216\n",
      "epoch: 193 loss: 2.3021037578582764 grad: 1.3309461221427819\n",
      "epoch: 194 loss: 2.3025221824645996 grad: 1.3381401907785662\n",
      "epoch: 195 loss: 2.302748680114746 grad: 1.3298133770373488\n",
      "epoch: 196 loss: 2.3027713298797607 grad: 1.3419273397571125\n",
      "epoch: 197 loss: 2.3028459548950195 grad: 1.3291945115308321\n",
      "epoch: 198 loss: 2.302290916442871 grad: 1.3335060597478694\n",
      "epoch: 199 loss: 2.3023900985717773 grad: 1.3507960912261514\n",
      "epoch: 200 loss: 2.3030245304107666 grad: 1.3343673021854123\n",
      "epoch: 201 loss: 2.3025553226470947 grad: 1.3417035015410788\n",
      "epoch: 202 loss: 2.3020901679992676 grad: 1.3509654209076885\n",
      "epoch: 203 loss: 2.303307294845581 grad: 1.3266857612715472\n",
      "epoch: 204 loss: 2.3029568195343018 grad: 1.3342531006635419\n",
      "epoch: 205 loss: 2.3026912212371826 grad: 1.3336839586688531\n",
      "epoch: 206 loss: 2.30273699760437 grad: 1.3276228229404383\n",
      "epoch: 207 loss: 2.3024396896362305 grad: 1.3416416299167193\n",
      "epoch: 208 loss: 2.302797317504883 grad: 1.3261993841733783\n",
      "epoch: 209 loss: 2.3023130893707275 grad: 1.348688899567129\n",
      "epoch: 210 loss: 2.302877426147461 grad: 1.3298367662835748\n",
      "epoch: 211 loss: 2.302510976791382 grad: 1.328723125085826\n",
      "epoch: 212 loss: 2.3026139736175537 grad: 1.3363843364678027\n",
      "epoch: 213 loss: 2.3023569583892822 grad: 1.3415517727253101\n",
      "epoch: 214 loss: 2.302083969116211 grad: 1.3432869207380074\n",
      "epoch: 215 loss: 2.302267551422119 grad: 1.3363939961436988\n",
      "epoch: 216 loss: 2.3022167682647705 grad: 1.340830124020281\n",
      "epoch: 217 loss: 2.3026044368743896 grad: 1.34204936419828\n",
      "epoch: 218 loss: 2.302821397781372 grad: 1.3217163129232912\n",
      "epoch: 219 loss: 2.302861213684082 grad: 1.3360230060246225\n",
      "epoch: 220 loss: 2.3020856380462646 grad: 1.345291682069988\n",
      "epoch: 221 loss: 2.3027589321136475 grad: 1.3362874403514617\n",
      "epoch: 222 loss: 2.3025569915771484 grad: 1.3376777039559942\n",
      "epoch: 223 loss: 2.3029751777648926 grad: 1.3254546063530834\n",
      "epoch: 224 loss: 2.3023300170898438 grad: 1.3454535962174838\n",
      "epoch: 225 loss: 2.3020269870758057 grad: 1.3431368551054408\n",
      "epoch: 226 loss: 2.3022687435150146 grad: 1.3315507078761353\n",
      "epoch: 227 loss: 2.3023946285247803 grad: 1.3429882087493463\n",
      "epoch: 228 loss: 2.3028464317321777 grad: 1.3294783108572046\n",
      "epoch: 229 loss: 2.3020076751708984 grad: 1.3553768724890514\n",
      "epoch: 230 loss: 2.3024396896362305 grad: 1.3382288006296943\n",
      "epoch: 231 loss: 2.3029119968414307 grad: 1.330216079140969\n",
      "epoch: 232 loss: 2.3027420043945312 grad: 1.335222409685172\n",
      "epoch: 233 loss: 2.3030552864074707 grad: 1.3243624615567988\n",
      "epoch: 234 loss: 2.302581787109375 grad: 1.3316512678783121\n",
      "epoch: 235 loss: 2.3022964000701904 grad: 1.3420327577115376\n",
      "epoch: 236 loss: 2.302607536315918 grad: 1.3370461133678282\n",
      "epoch: 237 loss: 2.3034088611602783 grad: 1.3269702942916266\n",
      "epoch: 238 loss: 2.3029944896698 grad: 1.329849326317864\n",
      "epoch: 239 loss: 2.303079128265381 grad: 1.3437502366298484\n",
      "epoch: 240 loss: 2.3027780055999756 grad: 1.3349907234152187\n",
      "epoch: 241 loss: 2.302267074584961 grad: 1.3403766385856128\n",
      "epoch: 242 loss: 2.302401304244995 grad: 1.3365376494300094\n",
      "epoch: 243 loss: 2.302663564682007 grad: 1.3323987207674821\n",
      "epoch: 244 loss: 2.302316904067993 grad: 1.3302555519566384\n",
      "epoch: 245 loss: 2.3026866912841797 grad: 1.3278747268671554\n",
      "epoch: 246 loss: 2.30275559425354 grad: 1.332991622133358\n",
      "epoch: 247 loss: 2.3028407096862793 grad: 1.3258691163205112\n",
      "epoch: 248 loss: 2.301635503768921 grad: 1.3531932790859764\n",
      "epoch: 249 loss: 2.302111864089966 grad: 1.3409061392303556\n",
      "epoch: 250 loss: 2.302452802658081 grad: 1.3344028973249749\n",
      "epoch: 251 loss: 2.302370071411133 grad: 1.342189551985246\n",
      "epoch: 252 loss: 2.3020737171173096 grad: 1.3381949843291843\n",
      "epoch: 253 loss: 2.3026256561279297 grad: 1.3289594744805187\n",
      "epoch: 254 loss: 2.302816390991211 grad: 1.3467891771117195\n",
      "epoch: 255 loss: 2.302220106124878 grad: 1.3386193465363856\n",
      "epoch: 256 loss: 2.3027360439300537 grad: 1.334191696075279\n",
      "epoch: 257 loss: 2.303040027618408 grad: 1.3259026697718552\n",
      "epoch: 258 loss: 2.3022804260253906 grad: 1.3397456842644642\n",
      "epoch: 259 loss: 2.3028101921081543 grad: 1.3323871304876067\n",
      "epoch: 260 loss: 2.302725076675415 grad: 1.3342301067545093\n",
      "epoch: 261 loss: 2.302737236022949 grad: 1.330769953025978\n",
      "epoch: 262 loss: 2.3022286891937256 grad: 1.3312541213392886\n",
      "epoch: 263 loss: 2.3031492233276367 grad: 1.325842371289914\n",
      "epoch: 264 loss: 2.302001714706421 grad: 1.3425493618022533\n",
      "epoch: 265 loss: 2.3025801181793213 grad: 1.3380578869624833\n",
      "epoch: 266 loss: 2.302622079849243 grad: 1.3359601872581397\n",
      "epoch: 267 loss: 2.302684783935547 grad: 1.3189997066381491\n",
      "epoch: 268 loss: 2.302473783493042 grad: 1.3303989052166423\n",
      "epoch: 269 loss: 2.3031132221221924 grad: 1.3273836290186627\n",
      "epoch: 270 loss: 2.302794933319092 grad: 1.3325984794387802\n",
      "epoch: 271 loss: 2.3030893802642822 grad: 1.3252204686333056\n",
      "epoch: 272 loss: 2.3028159141540527 grad: 1.32855700078376\n",
      "epoch: 273 loss: 2.3024661540985107 grad: 1.335879370675511\n",
      "epoch: 274 loss: 2.302478075027466 grad: 1.3387014560793187\n",
      "epoch: 275 loss: 2.3028745651245117 grad: 1.3170357255324248\n",
      "epoch: 276 loss: 2.302300214767456 grad: 1.3393938215116836\n",
      "epoch: 277 loss: 2.3025245666503906 grad: 1.3293325323611498\n",
      "epoch: 278 loss: 2.3017656803131104 grad: 1.3486023808068166\n",
      "epoch: 279 loss: 2.302281141281128 grad: 1.329782517942866\n",
      "epoch: 280 loss: 2.3025081157684326 grad: 1.3358075297622394\n",
      "epoch: 281 loss: 2.3024990558624268 grad: 1.3301733944136354\n",
      "epoch: 282 loss: 2.302654981613159 grad: 1.320799423839956\n",
      "epoch: 283 loss: 2.302351236343384 grad: 1.337009060619739\n",
      "epoch: 284 loss: 2.302276611328125 grad: 1.3426600998334055\n",
      "epoch: 285 loss: 2.302316665649414 grad: 1.3412870347762245\n",
      "epoch: 286 loss: 2.302471399307251 grad: 1.3359135846710868\n",
      "epoch: 287 loss: 2.3024511337280273 grad: 1.334661769222409\n",
      "epoch: 288 loss: 2.30218243598938 grad: 1.3363423760544273\n",
      "epoch: 289 loss: 2.3021774291992188 grad: 1.3398561233484616\n",
      "epoch: 290 loss: 2.3032381534576416 grad: 1.3259576187443196\n",
      "epoch: 291 loss: 2.3023955821990967 grad: 1.3424327082761993\n",
      "epoch: 292 loss: 2.302372694015503 grad: 1.3389752581992762\n",
      "epoch: 293 loss: 2.302630662918091 grad: 1.3354084897150715\n",
      "epoch: 294 loss: 2.3027150630950928 grad: 1.3364352450377146\n",
      "epoch: 295 loss: 2.3024282455444336 grad: 1.3324167359498373\n",
      "epoch: 296 loss: 2.3019964694976807 grad: 1.3364758566724106\n",
      "epoch: 297 loss: 2.3022971153259277 grad: 1.3306009801389236\n",
      "epoch: 298 loss: 2.3025641441345215 grad: 1.3376231116190966\n",
      "epoch: 299 loss: 2.302321195602417 grad: 1.34536655446411\n",
      "epoch: 300 loss: 2.302086114883423 grad: 1.3429672976286846\n",
      "epoch: 301 loss: 2.302133798599243 grad: 1.3373825744326626\n",
      "epoch: 302 loss: 2.302708864212036 grad: 1.3293645421323914\n",
      "epoch: 303 loss: 2.3029274940490723 grad: 1.3267346803535012\n",
      "epoch: 304 loss: 2.3027994632720947 grad: 1.3444298830212256\n",
      "epoch: 305 loss: 2.3019325733184814 grad: 1.3384294230084393\n",
      "epoch: 306 loss: 2.3029377460479736 grad: 1.326558912261611\n",
      "epoch: 307 loss: 2.3022072315216064 grad: 1.330360453581393\n",
      "epoch: 308 loss: 2.302635908126831 grad: 1.3344333075016501\n",
      "epoch: 309 loss: 2.3025503158569336 grad: 1.3254354303325748\n",
      "epoch: 310 loss: 2.3027501106262207 grad: 1.3353965553410707\n",
      "epoch: 311 loss: 2.3022100925445557 grad: 1.33695768770237\n",
      "epoch: 312 loss: 2.302391290664673 grad: 1.3417737895626545\n",
      "epoch: 313 loss: 2.3028721809387207 grad: 1.3310845191350267\n",
      "epoch: 314 loss: 2.3029189109802246 grad: 1.3362528924213073\n",
      "epoch: 315 loss: 2.302459955215454 grad: 1.3293159420801592\n",
      "epoch: 316 loss: 2.3022968769073486 grad: 1.3315110702311532\n",
      "epoch: 317 loss: 2.3031229972839355 grad: 1.3204624644306946\n",
      "epoch: 318 loss: 2.301952838897705 grad: 1.3505327950087598\n",
      "epoch: 319 loss: 2.3028407096862793 grad: 1.330790147904144\n",
      "epoch: 320 loss: 2.3028371334075928 grad: 1.327151378962241\n",
      "epoch: 321 loss: 2.302236318588257 grad: 1.3365395987713118\n",
      "epoch: 322 loss: 2.3025872707366943 grad: 1.3263013169339428\n",
      "epoch: 323 loss: 2.3025219440460205 grad: 1.3293812765263109\n",
      "epoch: 324 loss: 2.301852226257324 grad: 1.3351408646549172\n",
      "epoch: 325 loss: 2.3024368286132812 grad: 1.3302743101459262\n",
      "epoch: 326 loss: 2.3018155097961426 grad: 1.336317272731177\n",
      "epoch: 327 loss: 2.3022987842559814 grad: 1.3370937420912679\n",
      "epoch: 328 loss: 2.3024957180023193 grad: 1.3403532833622267\n",
      "epoch: 329 loss: 2.302845001220703 grad: 1.32861624797067\n",
      "epoch: 330 loss: 2.301903247833252 grad: 1.329846452919781\n",
      "epoch: 331 loss: 2.302288293838501 grad: 1.3416607254036954\n",
      "epoch: 332 loss: 2.3024089336395264 grad: 1.3426625918770683\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 333 loss: 2.302340030670166 grad: 1.3462472585665564\n",
      "epoch: 334 loss: 2.302703380584717 grad: 1.32973584344071\n",
      "epoch: 335 loss: 2.3026363849639893 grad: 1.324005332923243\n",
      "epoch: 336 loss: 2.302523374557495 grad: 1.3380462423979587\n",
      "epoch: 337 loss: 2.3028440475463867 grad: 1.3271516197294528\n",
      "epoch: 338 loss: 2.302131175994873 grad: 1.3468170578901966\n",
      "epoch: 339 loss: 2.3025400638580322 grad: 1.3370237928401265\n",
      "epoch: 340 loss: 2.302438974380493 grad: 1.3323500747866337\n",
      "epoch: 341 loss: 2.3024187088012695 grad: 1.333372659225475\n",
      "epoch: 342 loss: 2.3016679286956787 grad: 1.350310494254772\n",
      "epoch: 343 loss: 2.3022613525390625 grad: 1.3407282222280397\n",
      "epoch: 344 loss: 2.302838087081909 grad: 1.3366524025572404\n",
      "epoch: 345 loss: 2.301919460296631 grad: 1.3418963027319737\n",
      "epoch: 346 loss: 2.3022608757019043 grad: 1.327868809245364\n",
      "epoch: 347 loss: 2.302926778793335 grad: 1.3186187371445288\n",
      "epoch: 348 loss: 2.3028111457824707 grad: 1.332545395811192\n",
      "epoch: 349 loss: 2.3029961585998535 grad: 1.3209306493471746\n",
      "epoch: 350 loss: 2.302427053451538 grad: 1.3284533836191432\n",
      "epoch: 351 loss: 2.302131414413452 grad: 1.3363515326479776\n",
      "epoch: 352 loss: 2.302635669708252 grad: 1.3388177395303038\n",
      "epoch: 353 loss: 2.3025624752044678 grad: 1.3311697962612563\n",
      "epoch: 354 loss: 2.3019821643829346 grad: 1.3429708705146959\n",
      "epoch: 355 loss: 2.3022918701171875 grad: 1.327604660747706\n",
      "epoch: 356 loss: 2.302598476409912 grad: 1.334981557077891\n",
      "epoch: 357 loss: 2.3028438091278076 grad: 1.331423570235659\n",
      "epoch: 358 loss: 2.302493095397949 grad: 1.3355094245080614\n",
      "epoch: 359 loss: 2.3019320964813232 grad: 1.3349572200206152\n",
      "epoch: 360 loss: 2.302433729171753 grad: 1.3313852237363804\n",
      "epoch: 361 loss: 2.3024632930755615 grad: 1.3280260716121466\n",
      "epoch: 362 loss: 2.3022735118865967 grad: 1.335969117802701\n",
      "epoch: 363 loss: 2.3024094104766846 grad: 1.3342715486688244\n",
      "epoch: 364 loss: 2.3028345108032227 grad: 1.3308095723420146\n",
      "epoch: 365 loss: 2.301851987838745 grad: 1.3289605182307285\n",
      "epoch: 366 loss: 2.301989793777466 grad: 1.342386595221118\n",
      "epoch: 367 loss: 2.302406072616577 grad: 1.3366740584088903\n",
      "epoch: 368 loss: 2.3022403717041016 grad: 1.3292249976232322\n",
      "epoch: 369 loss: 2.3029916286468506 grad: 1.3230774301152293\n",
      "epoch: 370 loss: 2.302284002304077 grad: 1.3346275466952533\n",
      "epoch: 371 loss: 2.3018903732299805 grad: 1.341710647751045\n",
      "epoch: 372 loss: 2.3023593425750732 grad: 1.3364608652357544\n",
      "epoch: 373 loss: 2.301992893218994 grad: 1.3298651098739356\n",
      "epoch: 374 loss: 2.3021116256713867 grad: 1.346813390404725\n",
      "epoch: 375 loss: 2.3026747703552246 grad: 1.3315833609602932\n",
      "epoch: 376 loss: 2.301849126815796 grad: 1.3411586289201671\n",
      "epoch: 377 loss: 2.3021953105926514 grad: 1.3362972821545092\n",
      "epoch: 378 loss: 2.3022093772888184 grad: 1.33708833442587\n",
      "epoch: 379 loss: 2.302795886993408 grad: 1.328525672847819\n",
      "epoch: 380 loss: 2.302837610244751 grad: 1.3342716130945418\n",
      "epoch: 381 loss: 2.3025753498077393 grad: 1.3341584653327507\n",
      "epoch: 382 loss: 2.302769899368286 grad: 1.3213660981143929\n",
      "epoch: 383 loss: 2.3025026321411133 grad: 1.3285682311425695\n",
      "epoch: 384 loss: 2.3019630908966064 grad: 1.341765927453895\n",
      "epoch: 385 loss: 2.3023908138275146 grad: 1.3436772910589796\n",
      "epoch: 386 loss: 2.302905797958374 grad: 1.3233710046864986\n",
      "epoch: 387 loss: 2.3025155067443848 grad: 1.3322469393670973\n",
      "epoch: 388 loss: 2.3023884296417236 grad: 1.335427182752432\n",
      "epoch: 389 loss: 2.302152156829834 grad: 1.3344291158053758\n",
      "epoch: 390 loss: 2.3025269508361816 grad: 1.3289994506002774\n",
      "epoch: 391 loss: 2.302335262298584 grad: 1.330600032799079\n",
      "epoch: 392 loss: 2.301567316055298 grad: 1.3459148699997938\n",
      "epoch: 393 loss: 2.302565574645996 grad: 1.334206697446043\n",
      "epoch: 394 loss: 2.3030009269714355 grad: 1.3231683885697128\n",
      "epoch: 395 loss: 2.302910089492798 grad: 1.323732959757012\n",
      "epoch: 396 loss: 2.3017730712890625 grad: 1.349975694850501\n",
      "epoch: 397 loss: 2.302420139312744 grad: 1.332532855975885\n",
      "epoch: 398 loss: 2.3027732372283936 grad: 1.3303339405240313\n",
      "epoch: 399 loss: 2.302032947540283 grad: 1.335864698717607\n",
      "epoch: 400 loss: 2.301828622817993 grad: 1.3441953323799969\n",
      "epoch: 401 loss: 2.3023715019226074 grad: 1.3312954400363008\n",
      "epoch: 402 loss: 2.3020925521850586 grad: 1.3383736004720308\n",
      "epoch: 403 loss: 2.302208185195923 grad: 1.3322519746974908\n",
      "epoch: 404 loss: 2.301997184753418 grad: 1.3339725377865963\n",
      "epoch: 405 loss: 2.302276372909546 grad: 1.3317905095136089\n",
      "epoch: 406 loss: 2.302100896835327 grad: 1.3355904436367194\n",
      "epoch: 407 loss: 2.302334785461426 grad: 1.3349203124110187\n",
      "epoch: 408 loss: 2.301905870437622 grad: 1.3432321105861948\n",
      "epoch: 409 loss: 2.302764415740967 grad: 1.3247432116167768\n",
      "epoch: 410 loss: 2.3018274307250977 grad: 1.3506857082247734\n",
      "epoch: 411 loss: 2.302248001098633 grad: 1.3390858655422186\n",
      "epoch: 412 loss: 2.3017733097076416 grad: 1.3395902978825487\n",
      "epoch: 413 loss: 2.3019192218780518 grad: 1.3396960118903765\n",
      "epoch: 414 loss: 2.3022091388702393 grad: 1.3490679812033675\n",
      "epoch: 415 loss: 2.3017985820770264 grad: 1.3477231657782953\n",
      "epoch: 416 loss: 2.302563428878784 grad: 1.3343834006153639\n",
      "epoch: 417 loss: 2.3018455505371094 grad: 1.3372474682114517\n",
      "epoch: 418 loss: 2.301678419113159 grad: 1.3404191116052162\n",
      "epoch: 419 loss: 2.302201986312866 grad: 1.3394707325136377\n",
      "epoch: 420 loss: 2.302424907684326 grad: 1.339538696534296\n",
      "epoch: 421 loss: 2.302119255065918 grad: 1.3457774941306857\n",
      "epoch: 422 loss: 2.302241802215576 grad: 1.3305061951165074\n",
      "epoch: 423 loss: 2.302294969558716 grad: 1.3259371246233405\n",
      "epoch: 424 loss: 2.302048444747925 grad: 1.3353915597064538\n",
      "epoch: 425 loss: 2.302103042602539 grad: 1.3436948385714214\n",
      "epoch: 426 loss: 2.3023078441619873 grad: 1.3331435303617682\n",
      "epoch: 427 loss: 2.3026936054229736 grad: 1.325775411007704\n",
      "epoch: 428 loss: 2.3018853664398193 grad: 1.341141703453595\n",
      "epoch: 429 loss: 2.3025400638580322 grad: 1.3241601109999928\n",
      "epoch: 430 loss: 2.302765130996704 grad: 1.3236891646640345\n",
      "epoch: 431 loss: 2.302515983581543 grad: 1.3325944760526043\n",
      "epoch: 432 loss: 2.3022918701171875 grad: 1.3256526825143882\n",
      "epoch: 433 loss: 2.302525043487549 grad: 1.3428431474806977\n",
      "epoch: 434 loss: 2.3020761013031006 grad: 1.3439080062791675\n",
      "epoch: 435 loss: 2.302114248275757 grad: 1.3455689538710027\n",
      "epoch: 436 loss: 2.3021209239959717 grad: 1.330656701661942\n",
      "epoch: 437 loss: 2.302340269088745 grad: 1.3302483527111777\n",
      "epoch: 438 loss: 2.302560329437256 grad: 1.3386249294438\n",
      "epoch: 439 loss: 2.302410125732422 grad: 1.3396582229669014\n",
      "epoch: 440 loss: 2.302520751953125 grad: 1.337906768698881\n",
      "epoch: 441 loss: 2.302896499633789 grad: 1.3274926652370522\n",
      "epoch: 442 loss: 2.3021717071533203 grad: 1.3357468380237973\n",
      "epoch: 443 loss: 2.3025388717651367 grad: 1.3330603811468573\n",
      "epoch: 444 loss: 2.3017938137054443 grad: 1.3469810001311884\n",
      "epoch: 445 loss: 2.302133560180664 grad: 1.342396918806203\n",
      "epoch: 446 loss: 2.30202054977417 grad: 1.338561190883555\n",
      "epoch: 447 loss: 2.301828145980835 grad: 1.3525583508187935\n",
      "epoch: 448 loss: 2.3025217056274414 grad: 1.330023501977502\n",
      "epoch: 449 loss: 2.30234694480896 grad: 1.325049360175543\n",
      "epoch: 450 loss: 2.3018314838409424 grad: 1.3373382754793892\n",
      "epoch: 451 loss: 2.3024325370788574 grad: 1.3335602204333843\n",
      "epoch: 452 loss: 2.302400827407837 grad: 1.3414368397659726\n",
      "epoch: 453 loss: 2.3025758266448975 grad: 1.3307698394896255\n",
      "epoch: 454 loss: 2.302251100540161 grad: 1.337773230107915\n",
      "epoch: 455 loss: 2.3022420406341553 grad: 1.3366101600473659\n",
      "epoch: 456 loss: 2.3025524616241455 grad: 1.3300428537740594\n",
      "epoch: 457 loss: 2.3020880222320557 grad: 1.3348823138549628\n",
      "epoch: 458 loss: 2.3022689819335938 grad: 1.3463667067976313\n",
      "epoch: 459 loss: 2.3019044399261475 grad: 1.3496857594813234\n",
      "epoch: 460 loss: 2.3027122020721436 grad: 1.3327940293432523\n",
      "epoch: 461 loss: 2.301898717880249 grad: 1.340618764571402\n",
      "epoch: 462 loss: 2.302556037902832 grad: 1.332656128825398\n",
      "epoch: 463 loss: 2.302149772644043 grad: 1.3290970708975303\n",
      "epoch: 464 loss: 2.301879644393921 grad: 1.3398187258243857\n",
      "epoch: 465 loss: 2.3025686740875244 grad: 1.3336807693805663\n",
      "epoch: 466 loss: 2.30183744430542 grad: 1.3457225426063237\n",
      "epoch: 467 loss: 2.3024075031280518 grad: 1.3423043395215202\n",
      "epoch: 468 loss: 2.302051544189453 grad: 1.3426253645152355\n",
      "epoch: 469 loss: 2.3021271228790283 grad: 1.3327970577936088\n",
      "epoch: 470 loss: 2.3017008304595947 grad: 1.3408542961170453\n",
      "epoch: 471 loss: 2.302628993988037 grad: 1.3320533321349926\n",
      "epoch: 472 loss: 2.302170991897583 grad: 1.3426830844107336\n",
      "epoch: 473 loss: 2.302020788192749 grad: 1.3394082148544608\n",
      "epoch: 474 loss: 2.302090883255005 grad: 1.3343705237207433\n",
      "epoch: 475 loss: 2.3021037578582764 grad: 1.3473354310041206\n",
      "epoch: 476 loss: 2.3023581504821777 grad: 1.335625873734465\n",
      "epoch: 477 loss: 2.3015477657318115 grad: 1.339369335311598\n",
      "epoch: 478 loss: 2.301889181137085 grad: 1.3355214140425984\n",
      "epoch: 479 loss: 2.3015549182891846 grad: 1.3542974609105538\n",
      "epoch: 480 loss: 2.3012380599975586 grad: 1.351748662376185\n",
      "epoch: 481 loss: 2.302025318145752 grad: 1.3418579667156179\n",
      "epoch: 482 loss: 2.3022620677948 grad: 1.3379795370782386\n",
      "epoch: 483 loss: 2.30267333984375 grad: 1.335540145886914\n",
      "epoch: 484 loss: 2.302419424057007 grad: 1.333141983861828\n",
      "epoch: 485 loss: 2.3026344776153564 grad: 1.3210330514019237\n",
      "epoch: 486 loss: 2.3019165992736816 grad: 1.3401689169547772\n",
      "epoch: 487 loss: 2.302253007888794 grad: 1.3366070848165288\n",
      "epoch: 488 loss: 2.301403045654297 grad: 1.353645187595652\n",
      "epoch: 489 loss: 2.301614761352539 grad: 1.349051087521874\n",
      "epoch: 490 loss: 2.302042245864868 grad: 1.3436965961582101\n",
      "epoch: 491 loss: 2.302020788192749 grad: 1.335761198522671\n",
      "epoch: 492 loss: 2.3012092113494873 grad: 1.3569066116072621\n",
      "epoch: 493 loss: 2.3024659156799316 grad: 1.3298841141818447\n",
      "epoch: 494 loss: 2.301647663116455 grad: 1.3441270386766908\n",
      "epoch: 495 loss: 2.302114725112915 grad: 1.3358578871573425\n",
      "epoch: 496 loss: 2.3026671409606934 grad: 1.333177574433475\n",
      "epoch: 497 loss: 2.301734209060669 grad: 1.3482853044785323\n",
      "epoch: 498 loss: 2.3019020557403564 grad: 1.3363950374787525\n",
      "epoch: 499 loss: 2.3021700382232666 grad: 1.3355064901286766\n",
      "2.3020943105220795\n",
      "epoch: 0 loss: 2.3033223152160645 grad: 1.2340834617341263\n",
      "epoch: 1 loss: 2.302412271499634 grad: 1.2296254802661548\n",
      "epoch: 2 loss: 2.3021297454833984 grad: 1.231764868881169\n",
      "epoch: 3 loss: 2.3016862869262695 grad: 1.255478478289978\n",
      "epoch: 4 loss: 2.301386594772339 grad: 1.2580605530131992\n",
      "epoch: 5 loss: 2.2989845275878906 grad: 1.3257973120614355\n",
      "epoch: 6 loss: 2.297356367111206 grad: 1.4815136953755947\n",
      "epoch: 7 loss: 2.29620361328125 grad: 1.5551846997391077\n",
      "epoch: 8 loss: 2.2954928874969482 grad: 1.5374689295329893\n",
      "epoch: 9 loss: 2.2926204204559326 grad: 1.560218046171709\n",
      "epoch: 10 loss: 2.2909512519836426 grad: 1.637537965185142\n",
      "epoch: 11 loss: 2.2896242141723633 grad: 1.6202685612324064\n",
      "epoch: 12 loss: 2.2875914573669434 grad: 1.6317081011310663\n",
      "epoch: 13 loss: 2.2868120670318604 grad: 1.6791960179402923\n",
      "epoch: 14 loss: 2.2857534885406494 grad: 1.7347355312575394\n",
      "epoch: 15 loss: 2.2843658924102783 grad: 1.6937001502854632\n",
      "epoch: 16 loss: 2.2831592559814453 grad: 1.752589451455851\n",
      "epoch: 17 loss: 2.2793996334075928 grad: 1.7248600758224104\n",
      "epoch: 18 loss: 2.2766120433807373 grad: 1.7938692629141437\n",
      "epoch: 19 loss: 2.276378870010376 grad: 1.8724343386268065\n",
      "epoch: 20 loss: 2.275132894515991 grad: 1.9134319644081332\n",
      "epoch: 21 loss: 2.270637035369873 grad: 2.0379902468439903\n",
      "epoch: 22 loss: 2.2656238079071045 grad: 2.22193844902647\n",
      "epoch: 23 loss: 2.263627290725708 grad: 2.367768325844765\n",
      "epoch: 24 loss: 2.2629177570343018 grad: 2.476675512875238\n",
      "epoch: 25 loss: 2.2562546730041504 grad: 2.541793461813266\n",
      "epoch: 26 loss: 2.254394769668579 grad: 2.7469665175211424\n",
      "epoch: 27 loss: 2.2520320415496826 grad: 2.854766124190526\n",
      "epoch: 28 loss: 2.2471582889556885 grad: 2.905096794912843\n",
      "epoch: 29 loss: 2.2401938438415527 grad: 3.1074709288798097\n",
      "epoch: 30 loss: 2.238123655319214 grad: 3.0808116570706408\n",
      "epoch: 31 loss: 2.231318950653076 grad: 3.1693282770732094\n",
      "epoch: 32 loss: 2.226914882659912 grad: 3.4837327691918563\n",
      "epoch: 33 loss: 2.2196078300476074 grad: 3.8569131908154795\n",
      "epoch: 34 loss: 2.202338457107544 grad: 4.045431606881764\n",
      "epoch: 35 loss: 2.1970696449279785 grad: 4.015714105577135\n",
      "epoch: 36 loss: 2.186929941177368 grad: 4.086154202938021\n",
      "epoch: 37 loss: 2.174649715423584 grad: 3.9172196078949444\n",
      "epoch: 38 loss: 2.1748158931732178 grad: 4.198095089981392\n",
      "epoch: 39 loss: 2.1684072017669678 grad: 3.8885705093890133\n",
      "epoch: 40 loss: 2.163755178451538 grad: 3.8065437118131076\n",
      "epoch: 41 loss: 2.1568613052368164 grad: 4.105886396209133\n",
      "epoch: 42 loss: 2.1543216705322266 grad: 4.078095210420471\n",
      "epoch: 43 loss: 2.154491662979126 grad: 4.1545973387066395\n",
      "epoch: 44 loss: 2.149534225463867 grad: 4.240606513909167\n",
      "epoch: 45 loss: 2.1512749195098877 grad: 4.180991004372666\n",
      "epoch: 46 loss: 2.1381754875183105 grad: 4.057939667993831\n",
      "epoch: 47 loss: 2.141904592514038 grad: 4.1784003356006\n",
      "epoch: 48 loss: 2.1350934505462646 grad: 4.346542458670835\n",
      "epoch: 49 loss: 2.14186954498291 grad: 4.458414184916321\n",
      "epoch: 50 loss: 2.131502866744995 grad: 4.450053511231783\n",
      "epoch: 51 loss: 2.1324174404144287 grad: 4.435469694154722\n",
      "epoch: 52 loss: 2.1313557624816895 grad: 4.3865086246052725\n",
      "epoch: 53 loss: 2.124091625213623 grad: 4.426846661970818\n",
      "epoch: 54 loss: 2.1275947093963623 grad: 4.419329810329521\n",
      "epoch: 55 loss: 2.1216509342193604 grad: 4.468224116394089\n",
      "epoch: 56 loss: 2.1258928775787354 grad: 4.840705069631989\n",
      "epoch: 57 loss: 2.124194383621216 grad: 4.790435272963747\n",
      "epoch: 58 loss: 2.118083953857422 grad: 4.369325898484224\n",
      "epoch: 59 loss: 2.1143076419830322 grad: 4.5023314321140155\n",
      "epoch: 60 loss: 2.114830732345581 grad: 4.595409363171914\n",
      "epoch: 61 loss: 2.115410566329956 grad: 4.44089526799877\n",
      "epoch: 62 loss: 2.1092162132263184 grad: 4.675549459440397\n",
      "epoch: 63 loss: 2.1104280948638916 grad: 4.56949842120299\n",
      "epoch: 64 loss: 2.1118531227111816 grad: 5.043520769998727\n",
      "epoch: 65 loss: 2.10493803024292 grad: 4.937783665977241\n",
      "epoch: 66 loss: 2.107478141784668 grad: 4.907403168224153\n",
      "epoch: 67 loss: 2.104806661605835 grad: 4.891519648277955\n",
      "epoch: 68 loss: 2.10418963432312 grad: 4.7521391071024395\n",
      "epoch: 69 loss: 2.1022746562957764 grad: 4.963375349599306\n",
      "epoch: 70 loss: 2.1007697582244873 grad: 4.629820104717972\n",
      "epoch: 71 loss: 2.0986487865448 grad: 4.860641062947079\n",
      "epoch: 72 loss: 2.101738691329956 grad: 4.731959230809783\n",
      "epoch: 73 loss: 2.1024954319000244 grad: 5.058431253738938\n",
      "epoch: 74 loss: 2.0963821411132812 grad: 4.6825433354011725\n",
      "epoch: 75 loss: 2.095144033432007 grad: 4.613093752613557\n",
      "epoch: 76 loss: 2.094684362411499 grad: 4.88957261281561\n",
      "epoch: 77 loss: 2.0954723358154297 grad: 4.896605404759092\n",
      "epoch: 78 loss: 2.0915446281433105 grad: 4.8656344998347025\n",
      "epoch: 79 loss: 2.0922107696533203 grad: 4.903639555191769\n",
      "epoch: 80 loss: 2.089916944503784 grad: 4.822672316412781\n",
      "epoch: 81 loss: 2.0903730392456055 grad: 4.974594067331285\n",
      "epoch: 82 loss: 2.090967893600464 grad: 4.785030755473094\n",
      "epoch: 83 loss: 2.091417074203491 grad: 4.843192348907155\n",
      "epoch: 84 loss: 2.0894904136657715 grad: 4.758244609737414\n",
      "epoch: 85 loss: 2.0909063816070557 grad: 4.89598018259904\n",
      "epoch: 86 loss: 2.0841495990753174 grad: 4.868475186424182\n",
      "epoch: 87 loss: 2.0826334953308105 grad: 4.907457255418339\n",
      "epoch: 88 loss: 2.0850424766540527 grad: 4.945394228729937\n",
      "epoch: 89 loss: 2.073084831237793 grad: 4.758788522591607\n",
      "epoch: 90 loss: 2.0780997276306152 grad: 5.126689974580788\n",
      "epoch: 91 loss: 2.078662872314453 grad: 5.185906804617613\n",
      "epoch: 92 loss: 2.079766035079956 grad: 5.216640731763272\n",
      "epoch: 93 loss: 2.0731451511383057 grad: 5.1837856609906465\n",
      "epoch: 94 loss: 2.083616018295288 grad: 5.507887823536755\n",
      "epoch: 95 loss: 2.0772621631622314 grad: 5.36639767165281\n",
      "epoch: 96 loss: 2.0741117000579834 grad: 5.241458215144655\n",
      "epoch: 97 loss: 2.0738537311553955 grad: 5.28374775961071\n",
      "epoch: 98 loss: 2.072535514831543 grad: 4.823592290910523\n",
      "epoch: 99 loss: 2.073965072631836 grad: 5.514399011996353\n",
      "epoch: 100 loss: 2.0702993869781494 grad: 5.616339996649278\n",
      "epoch: 101 loss: 2.070800542831421 grad: 5.1764099858036\n",
      "epoch: 102 loss: 2.073927402496338 grad: 5.3340015075953\n",
      "epoch: 103 loss: 2.0676448345184326 grad: 5.641368414748401\n",
      "epoch: 104 loss: 2.077876329421997 grad: 5.484735449753879\n",
      "epoch: 105 loss: 2.0683212280273438 grad: 5.593768859666492\n",
      "epoch: 106 loss: 2.066890239715576 grad: 5.632294607880924\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 107 loss: 2.0645155906677246 grad: 5.023126612217831\n",
      "epoch: 108 loss: 2.0638484954833984 grad: 5.675130918511146\n",
      "epoch: 109 loss: 2.0626332759857178 grad: 5.49842397668325\n",
      "epoch: 110 loss: 2.064359664916992 grad: 5.42059018655074\n",
      "epoch: 111 loss: 2.059569835662842 grad: 5.80289863090637\n",
      "epoch: 112 loss: 2.0630993843078613 grad: 5.814970608704561\n",
      "epoch: 113 loss: 2.0659422874450684 grad: 5.243702921824204\n",
      "epoch: 114 loss: 2.0603394508361816 grad: 6.039435331229239\n",
      "epoch: 115 loss: 2.0607314109802246 grad: 5.792133282315696\n",
      "epoch: 116 loss: 2.053873062133789 grad: 5.8071784991992725\n",
      "epoch: 117 loss: 2.059981107711792 grad: 5.545151162316047\n",
      "epoch: 118 loss: 2.0591299533843994 grad: 5.677216463345324\n",
      "epoch: 119 loss: 2.054286241531372 grad: 5.7458509388601495\n",
      "epoch: 120 loss: 2.054227352142334 grad: 5.562317715477317\n",
      "epoch: 121 loss: 2.054203510284424 grad: 5.853212884797286\n",
      "epoch: 122 loss: 2.0547471046447754 grad: 5.783045090091902\n",
      "epoch: 123 loss: 2.051872491836548 grad: 6.03936258258505\n",
      "epoch: 124 loss: 2.0531065464019775 grad: 5.655581412452554\n",
      "epoch: 125 loss: 2.056627035140991 grad: 5.716560149439684\n",
      "epoch: 126 loss: 2.053312301635742 grad: 5.831058308031292\n",
      "epoch: 127 loss: 2.0513362884521484 grad: 6.2018573292945\n",
      "epoch: 128 loss: 2.0485682487487793 grad: 5.615719925220464\n",
      "epoch: 129 loss: 2.044921636581421 grad: 5.945911123964285\n",
      "epoch: 130 loss: 2.0556905269622803 grad: 6.1143564608849825\n",
      "epoch: 131 loss: 2.044675588607788 grad: 6.208042924469781\n",
      "epoch: 132 loss: 2.0522685050964355 grad: 6.068481882960196\n",
      "epoch: 133 loss: 2.0462403297424316 grad: 6.161525965845656\n",
      "epoch: 134 loss: 2.046879529953003 grad: 6.454008752775807\n",
      "epoch: 135 loss: 2.044158935546875 grad: 6.528817004716349\n",
      "epoch: 136 loss: 2.0399091243743896 grad: 5.761538684353351\n",
      "epoch: 137 loss: 2.0412211418151855 grad: 5.899282422626302\n",
      "epoch: 138 loss: 2.0386929512023926 grad: 6.687810420029102\n",
      "epoch: 139 loss: 2.0411455631256104 grad: 6.4676828382108065\n",
      "epoch: 140 loss: 2.044807195663452 grad: 6.287542806154797\n",
      "epoch: 141 loss: 2.045102596282959 grad: 6.420678549815738\n",
      "epoch: 142 loss: 2.044379949569702 grad: 6.4574175200883355\n",
      "epoch: 143 loss: 2.0438897609710693 grad: 6.641106558098857\n",
      "epoch: 144 loss: 2.03908634185791 grad: 6.327672182220137\n",
      "epoch: 145 loss: 2.0427396297454834 grad: 6.595268417164565\n",
      "epoch: 146 loss: 2.034640073776245 grad: 6.222229726449956\n",
      "epoch: 147 loss: 2.037419557571411 grad: 6.281037117775885\n",
      "epoch: 148 loss: 2.032325267791748 grad: 6.539488539905361\n",
      "epoch: 149 loss: 2.030200719833374 grad: 6.441007603499447\n",
      "epoch: 150 loss: 2.030564308166504 grad: 6.587082241174011\n",
      "epoch: 151 loss: 2.037137985229492 grad: 6.56510654816197\n",
      "epoch: 152 loss: 2.028352737426758 grad: 6.358203947329746\n",
      "epoch: 153 loss: 2.040442943572998 grad: 6.739473355069224\n",
      "epoch: 154 loss: 2.034069776535034 grad: 6.661759614552711\n",
      "epoch: 155 loss: 2.034170627593994 grad: 6.644048701646546\n",
      "epoch: 156 loss: 2.0344579219818115 grad: 6.837530847306231\n",
      "epoch: 157 loss: 2.0316121578216553 grad: 6.708531019093084\n",
      "epoch: 158 loss: 2.029066801071167 grad: 6.742948862731398\n",
      "epoch: 159 loss: 2.028183698654175 grad: 7.084230857117782\n",
      "epoch: 160 loss: 2.025200605392456 grad: 6.805034436329844\n",
      "epoch: 161 loss: 2.0246500968933105 grad: 6.971764917485416\n",
      "epoch: 162 loss: 2.0278074741363525 grad: 7.112358316025209\n",
      "epoch: 163 loss: 2.026540994644165 grad: 7.056276662652159\n",
      "epoch: 164 loss: 2.027836799621582 grad: 6.9487165803208\n",
      "epoch: 165 loss: 2.027515172958374 grad: 7.394074892351729\n",
      "epoch: 166 loss: 2.0223474502563477 grad: 7.099345106838478\n",
      "epoch: 167 loss: 2.020095109939575 grad: 6.959489862648918\n",
      "epoch: 168 loss: 2.0222628116607666 grad: 7.050669038239571\n",
      "epoch: 169 loss: 2.0227560997009277 grad: 7.416447318713402\n",
      "epoch: 170 loss: 2.019679069519043 grad: 7.008224904958514\n",
      "epoch: 171 loss: 2.022233724594116 grad: 6.98451508682162\n",
      "epoch: 172 loss: 2.022085666656494 grad: 7.338480010377391\n",
      "epoch: 173 loss: 2.022212505340576 grad: 7.240479803082371\n",
      "epoch: 174 loss: 2.01658034324646 grad: 6.9386775778783925\n",
      "epoch: 175 loss: 2.018357276916504 grad: 7.729880512019412\n",
      "epoch: 176 loss: 2.0264110565185547 grad: 7.867524225250005\n",
      "epoch: 177 loss: 2.019883871078491 grad: 7.319971905282093\n",
      "epoch: 178 loss: 2.0138466358184814 grad: 7.483078566276365\n",
      "epoch: 179 loss: 2.0119941234588623 grad: 7.249254292616295\n",
      "epoch: 180 loss: 2.0254783630371094 grad: 7.598406661523595\n",
      "epoch: 181 loss: 2.0157198905944824 grad: 7.569711268081197\n",
      "epoch: 182 loss: 2.0129566192626953 grad: 7.148560550817776\n",
      "epoch: 183 loss: 2.017343759536743 grad: 7.305601893125901\n",
      "epoch: 184 loss: 2.013449192047119 grad: 7.59813856062228\n",
      "epoch: 185 loss: 2.0089807510375977 grad: 7.494386776039998\n",
      "epoch: 186 loss: 2.0122804641723633 grad: 7.4744363721637495\n",
      "epoch: 187 loss: 2.0140373706817627 grad: 7.5621219918959675\n",
      "epoch: 188 loss: 2.004034996032715 grad: 7.120213703370639\n",
      "epoch: 189 loss: 2.0137948989868164 grad: 7.3523714597824785\n",
      "epoch: 190 loss: 2.0127451419830322 grad: 7.6326990782076285\n",
      "epoch: 191 loss: 2.0032784938812256 grad: 7.7336322165256925\n",
      "epoch: 192 loss: 2.001193046569824 grad: 7.468841627964543\n",
      "epoch: 193 loss: 2.0053040981292725 grad: 8.013792822388785\n",
      "epoch: 194 loss: 2.012181520462036 grad: 7.392682348496266\n",
      "epoch: 195 loss: 2.004122257232666 grad: 7.629255688416639\n",
      "epoch: 196 loss: 2.0085813999176025 grad: 7.557229756998519\n",
      "epoch: 197 loss: 1.9977930784225464 grad: 7.345701014652612\n",
      "epoch: 198 loss: 2.0029656887054443 grad: 7.724553581822427\n",
      "epoch: 199 loss: 1.9999566078186035 grad: 8.087707754505415\n",
      "epoch: 200 loss: 2.0021588802337646 grad: 7.9668047191309075\n",
      "epoch: 201 loss: 2.004469871520996 grad: 7.478160951279163\n",
      "epoch: 202 loss: 1.9993157386779785 grad: 7.717262024828602\n",
      "epoch: 203 loss: 1.9992860555648804 grad: 7.493003343668072\n",
      "epoch: 204 loss: 1.9995213747024536 grad: 7.61434693909472\n",
      "epoch: 205 loss: 2.002220392227173 grad: 7.963935013254365\n",
      "epoch: 206 loss: 1.9916069507598877 grad: 7.526188376699648\n",
      "epoch: 207 loss: 1.9993208646774292 grad: 7.943654452421008\n",
      "epoch: 208 loss: 2.000589370727539 grad: 7.39489350206263\n",
      "epoch: 209 loss: 1.998065710067749 grad: 7.944503407053176\n",
      "epoch: 210 loss: 1.9922676086425781 grad: 7.554044397193051\n",
      "epoch: 211 loss: 2.0030319690704346 grad: 7.9422480093522205\n",
      "epoch: 212 loss: 1.997360348701477 grad: 7.8085131022694805\n",
      "epoch: 213 loss: 1.9977521896362305 grad: 8.216074656414252\n",
      "epoch: 214 loss: 1.9913890361785889 grad: 7.610576411465272\n",
      "epoch: 215 loss: 1.9955017566680908 grad: 8.06477897340757\n",
      "epoch: 216 loss: 1.995295524597168 grad: 7.847919853234161\n",
      "epoch: 217 loss: 1.9978855848312378 grad: 7.384100901591222\n",
      "epoch: 218 loss: 1.997843623161316 grad: 7.983543551852187\n",
      "epoch: 219 loss: 1.9955272674560547 grad: 8.077982038089504\n",
      "epoch: 220 loss: 1.9968597888946533 grad: 7.844379575900911\n",
      "epoch: 221 loss: 2.000340223312378 grad: 8.38050068576362\n",
      "epoch: 222 loss: 1.990086317062378 grad: 7.60637794459416\n",
      "epoch: 223 loss: 1.9979445934295654 grad: 7.720353113317359\n",
      "epoch: 224 loss: 1.9874054193496704 grad: 8.171411673686215\n",
      "epoch: 225 loss: 1.9868175983428955 grad: 7.881658105837507\n",
      "epoch: 226 loss: 1.9857991933822632 grad: 7.9833662858055465\n",
      "epoch: 227 loss: 1.9934368133544922 grad: 7.897173600589176\n",
      "epoch: 228 loss: 1.9956687688827515 grad: 8.299826416364382\n",
      "epoch: 229 loss: 1.9785270690917969 grad: 7.970438575638192\n",
      "epoch: 230 loss: 1.9826550483703613 grad: 8.102342761432132\n",
      "epoch: 231 loss: 1.9909595251083374 grad: 8.108401084252234\n",
      "epoch: 232 loss: 1.9873754978179932 grad: 7.695127311665269\n",
      "epoch: 233 loss: 1.9787471294403076 grad: 7.881095780067087\n",
      "epoch: 234 loss: 1.9895445108413696 grad: 8.142581949660938\n",
      "epoch: 235 loss: 1.9838521480560303 grad: 8.160839960614721\n",
      "epoch: 236 loss: 1.9869897365570068 grad: 8.463400993777055\n",
      "epoch: 237 loss: 1.9802987575531006 grad: 8.154829490663749\n",
      "epoch: 238 loss: 1.9835377931594849 grad: 7.74661650094721\n",
      "epoch: 239 loss: 1.9823154211044312 grad: 8.14529258882006\n",
      "epoch: 240 loss: 1.9830596446990967 grad: 8.313874048373055\n",
      "epoch: 241 loss: 1.9813451766967773 grad: 7.804287321200328\n",
      "epoch: 242 loss: 1.9882285594940186 grad: 7.731189476577417\n",
      "epoch: 243 loss: 1.985123634338379 grad: 8.03282099806275\n",
      "epoch: 244 loss: 1.978121280670166 grad: 8.07620005540195\n",
      "epoch: 245 loss: 1.9797416925430298 grad: 7.903576753368335\n",
      "epoch: 246 loss: 1.9796797037124634 grad: 8.067145575377499\n",
      "epoch: 247 loss: 1.9814600944519043 grad: 7.902421697220277\n",
      "epoch: 248 loss: 1.9703357219696045 grad: 7.933094809837048\n",
      "epoch: 249 loss: 1.9773670434951782 grad: 7.875264360332891\n",
      "epoch: 250 loss: 1.9735463857650757 grad: 7.975926722133798\n",
      "epoch: 251 loss: 1.9766485691070557 grad: 8.312230393275737\n",
      "epoch: 252 loss: 1.9754327535629272 grad: 8.25981241082477\n",
      "epoch: 253 loss: 1.9736307859420776 grad: 8.011637021270063\n",
      "epoch: 254 loss: 1.9757319688796997 grad: 8.269490119646347\n",
      "epoch: 255 loss: 1.9687455892562866 grad: 8.012747849219494\n",
      "epoch: 256 loss: 1.9696786403656006 grad: 8.294923414727526\n",
      "epoch: 257 loss: 1.975906491279602 grad: 8.214890025452608\n",
      "epoch: 258 loss: 1.9782154560089111 grad: 8.072159719254289\n",
      "epoch: 259 loss: 1.967621088027954 grad: 8.103764892681427\n",
      "epoch: 260 loss: 1.972632884979248 grad: 7.910268344251173\n",
      "epoch: 261 loss: 1.9811103343963623 grad: 8.95596979248027\n",
      "epoch: 262 loss: 1.9766221046447754 grad: 8.709495237599763\n",
      "epoch: 263 loss: 1.9682931900024414 grad: 8.337764730425699\n",
      "epoch: 264 loss: 1.9686682224273682 grad: 8.22815624207613\n",
      "epoch: 265 loss: 1.9686238765716553 grad: 8.03261946361985\n",
      "epoch: 266 loss: 1.9629353284835815 grad: 8.796943852042277\n",
      "epoch: 267 loss: 1.9703829288482666 grad: 8.036440150575741\n",
      "epoch: 268 loss: 1.969074010848999 grad: 8.824247219895442\n",
      "epoch: 269 loss: 1.9663095474243164 grad: 9.064199855713735\n",
      "epoch: 270 loss: 1.9655214548110962 grad: 8.5180702322414\n",
      "epoch: 271 loss: 1.9659812450408936 grad: 8.525677823579855\n",
      "epoch: 272 loss: 1.9761191606521606 grad: 8.218323394020517\n",
      "epoch: 273 loss: 1.9636383056640625 grad: 9.155263058870794\n",
      "epoch: 274 loss: 1.9626290798187256 grad: 8.20975321863911\n",
      "epoch: 275 loss: 1.9681849479675293 grad: 8.912240492786088\n",
      "epoch: 276 loss: 1.966397762298584 grad: 8.753534733716931\n",
      "epoch: 277 loss: 1.9655063152313232 grad: 8.82660824310271\n",
      "epoch: 278 loss: 1.953935980796814 grad: 8.48579599046045\n",
      "epoch: 279 loss: 1.9657598733901978 grad: 8.710432129261632\n",
      "epoch: 280 loss: 1.97028386592865 grad: 9.353611214559466\n",
      "epoch: 281 loss: 1.9617713689804077 grad: 8.53164238810894\n",
      "epoch: 282 loss: 1.9644911289215088 grad: 9.016920035801059\n",
      "epoch: 283 loss: 1.9581631422042847 grad: 8.44966819786304\n",
      "epoch: 284 loss: 1.9601904153823853 grad: 8.565581901989404\n",
      "epoch: 285 loss: 1.9565092325210571 grad: 8.822828379888383\n",
      "epoch: 286 loss: 1.9543476104736328 grad: 8.83870174131164\n",
      "epoch: 287 loss: 1.9556958675384521 grad: 8.35031015091827\n",
      "epoch: 288 loss: 1.9602404832839966 grad: 8.541358384340706\n",
      "epoch: 289 loss: 1.9633322954177856 grad: 8.688862285709806\n",
      "epoch: 290 loss: 1.961031436920166 grad: 8.963921680329515\n",
      "epoch: 291 loss: 1.958134651184082 grad: 9.225986638623807\n",
      "epoch: 292 loss: 1.9637988805770874 grad: 8.487712800147987\n",
      "epoch: 293 loss: 1.9652308225631714 grad: 8.622682536656539\n",
      "epoch: 294 loss: 1.96624755859375 grad: 8.608151464168692\n",
      "epoch: 295 loss: 1.9545222520828247 grad: 8.69628036724374\n",
      "epoch: 296 loss: 1.9614005088806152 grad: 8.669786134439091\n",
      "epoch: 297 loss: 1.9596151113510132 grad: 8.186303499975198\n",
      "epoch: 298 loss: 1.9511233568191528 grad: 8.970659444492961\n",
      "epoch: 299 loss: 1.9562928676605225 grad: 8.646486991920346\n",
      "epoch: 300 loss: 1.9521050453186035 grad: 8.914145105584923\n",
      "epoch: 301 loss: 1.9536131620407104 grad: 8.891778339787075\n",
      "epoch: 302 loss: 1.9524422883987427 grad: 8.788203674146818\n",
      "epoch: 303 loss: 1.9521702527999878 grad: 8.678574844536978\n",
      "epoch: 304 loss: 1.9502058029174805 grad: 8.568025053885307\n",
      "epoch: 305 loss: 1.9495183229446411 grad: 8.741159258528597\n",
      "epoch: 306 loss: 1.951492190361023 grad: 9.34196669447221\n",
      "epoch: 307 loss: 1.9523602724075317 grad: 9.817605934150162\n",
      "epoch: 308 loss: 1.9526540040969849 grad: 8.94654191734772\n",
      "epoch: 309 loss: 1.948945164680481 grad: 8.532671995594033\n",
      "epoch: 310 loss: 1.9483261108398438 grad: 9.253509644300692\n",
      "epoch: 311 loss: 1.9546469449996948 grad: 8.919866526913312\n",
      "epoch: 312 loss: 1.953956127166748 grad: 8.607157363837201\n",
      "epoch: 313 loss: 1.9440401792526245 grad: 9.004646653486859\n",
      "epoch: 314 loss: 1.9469176530838013 grad: 8.889081911139545\n",
      "epoch: 315 loss: 1.9414441585540771 grad: 9.040763904140997\n",
      "epoch: 316 loss: 1.9400643110275269 grad: 9.217189127594114\n",
      "epoch: 317 loss: 1.9446959495544434 grad: 8.539047002770184\n",
      "epoch: 318 loss: 1.9443373680114746 grad: 8.847054089271715\n",
      "epoch: 319 loss: 1.9512900114059448 grad: 8.794105582027917\n",
      "epoch: 320 loss: 1.940725326538086 grad: 8.514211321397433\n",
      "epoch: 321 loss: 1.9516620635986328 grad: 9.473320089753658\n",
      "epoch: 322 loss: 1.948249101638794 grad: 9.157323755501281\n",
      "epoch: 323 loss: 1.9430274963378906 grad: 8.865728321618267\n",
      "epoch: 324 loss: 1.9372763633728027 grad: 8.887753204213427\n",
      "epoch: 325 loss: 1.9381698369979858 grad: 9.274864125464644\n",
      "epoch: 326 loss: 1.9458527565002441 grad: 9.339682085942181\n",
      "epoch: 327 loss: 1.9463319778442383 grad: 9.18793416066864\n",
      "epoch: 328 loss: 1.9445182085037231 grad: 8.610937059472596\n",
      "epoch: 329 loss: 1.9430480003356934 grad: 9.546045851738503\n",
      "epoch: 330 loss: 1.9510496854782104 grad: 9.353564249662062\n",
      "epoch: 331 loss: 1.9364571571350098 grad: 8.777764235164911\n",
      "epoch: 332 loss: 1.9413021802902222 grad: 9.070681272340673\n",
      "epoch: 333 loss: 1.9416884183883667 grad: 9.071089690248112\n",
      "epoch: 334 loss: 1.9407073259353638 grad: 9.43976641864708\n",
      "epoch: 335 loss: 1.940002202987671 grad: 8.941488597527265\n",
      "epoch: 336 loss: 1.943371295928955 grad: 9.020833749996704\n",
      "epoch: 337 loss: 1.9385489225387573 grad: 9.284593271461153\n",
      "epoch: 338 loss: 1.93277907371521 grad: 9.382282397295866\n",
      "epoch: 339 loss: 1.9403353929519653 grad: 9.531761825143818\n",
      "epoch: 340 loss: 1.9396132230758667 grad: 8.487384236491625\n",
      "epoch: 341 loss: 1.9406973123550415 grad: 9.158465746804954\n",
      "epoch: 342 loss: 1.9349225759506226 grad: 8.932236665209372\n",
      "epoch: 343 loss: 1.9446078538894653 grad: 9.605981390627603\n",
      "epoch: 344 loss: 1.934950828552246 grad: 8.919246506818112\n",
      "epoch: 345 loss: 1.9403666257858276 grad: 9.08431696210293\n",
      "epoch: 346 loss: 1.9371988773345947 grad: 9.828444376868744\n",
      "epoch: 347 loss: 1.937501072883606 grad: 9.761717039603917\n",
      "epoch: 348 loss: 1.9355462789535522 grad: 8.81747745144521\n",
      "epoch: 349 loss: 1.9313992261886597 grad: 9.682598870979357\n",
      "epoch: 350 loss: 1.9364567995071411 grad: 8.306921347709638\n",
      "epoch: 351 loss: 1.9385923147201538 grad: 9.672465619239365\n",
      "epoch: 352 loss: 1.9380717277526855 grad: 9.518363726672732\n",
      "epoch: 353 loss: 1.935567855834961 grad: 8.819917981527627\n",
      "epoch: 354 loss: 1.9272503852844238 grad: 8.931380207110788\n",
      "epoch: 355 loss: 1.9377589225769043 grad: 9.264781378128285\n",
      "epoch: 356 loss: 1.9289515018463135 grad: 9.290659680932997\n",
      "epoch: 357 loss: 1.9343115091323853 grad: 9.322059188895519\n",
      "epoch: 358 loss: 1.9357167482376099 grad: 9.583902879263318\n",
      "epoch: 359 loss: 1.9374336004257202 grad: 9.211558307927575\n",
      "epoch: 360 loss: 1.9340828657150269 grad: 9.677804795286011\n",
      "epoch: 361 loss: 1.9317824840545654 grad: 9.40419968526574\n",
      "epoch: 362 loss: 1.9299850463867188 grad: 9.690580028160992\n",
      "epoch: 363 loss: 1.9353430271148682 grad: 9.333649824979522\n",
      "epoch: 364 loss: 1.9362854957580566 grad: 9.47888475373417\n",
      "epoch: 365 loss: 1.924168586730957 grad: 8.696434178397\n",
      "epoch: 366 loss: 1.9266139268875122 grad: 9.112515300763624\n",
      "epoch: 367 loss: 1.9281065464019775 grad: 9.082793389661385\n",
      "epoch: 368 loss: 1.9292560815811157 grad: 9.272519361900372\n",
      "epoch: 369 loss: 1.9313395023345947 grad: 9.301159674767405\n",
      "epoch: 370 loss: 1.9195427894592285 grad: 9.76781471642769\n",
      "epoch: 371 loss: 1.9195828437805176 grad: 8.52874282763029\n",
      "epoch: 372 loss: 1.938478946685791 grad: 9.160777784440489\n",
      "epoch: 373 loss: 1.9358409643173218 grad: 9.643727598349667\n",
      "epoch: 374 loss: 1.922100305557251 grad: 9.232254504913552\n",
      "epoch: 375 loss: 1.9251419305801392 grad: 8.926741599615308\n",
      "epoch: 376 loss: 1.9224783182144165 grad: 9.470877847390337\n",
      "epoch: 377 loss: 1.9267128705978394 grad: 9.21795967613746\n",
      "epoch: 378 loss: 1.9288055896759033 grad: 8.898022068893566\n",
      "epoch: 379 loss: 1.9215984344482422 grad: 8.96719924939264\n",
      "epoch: 380 loss: 1.9227315187454224 grad: 9.272346347939992\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 381 loss: 1.9250845909118652 grad: 9.29050438697376\n",
      "epoch: 382 loss: 1.9239753484725952 grad: 9.122635386943344\n",
      "epoch: 383 loss: 1.920035719871521 grad: 9.151136799331104\n",
      "epoch: 384 loss: 1.9203250408172607 grad: 8.898159471281346\n",
      "epoch: 385 loss: 1.9233982563018799 grad: 10.166539415111027\n",
      "epoch: 386 loss: 1.9189082384109497 grad: 9.30686036356917\n",
      "epoch: 387 loss: 1.9195681810379028 grad: 9.009032810764712\n",
      "epoch: 388 loss: 1.9308611154556274 grad: 9.383722381629346\n",
      "epoch: 389 loss: 1.91547691822052 grad: 8.970554881167436\n",
      "epoch: 390 loss: 1.9223709106445312 grad: 9.288880459084693\n",
      "epoch: 391 loss: 1.9240869283676147 grad: 8.946907811727936\n",
      "epoch: 392 loss: 1.9229532480239868 grad: 9.434268776504766\n",
      "epoch: 393 loss: 1.9283826351165771 grad: 8.820158765503457\n",
      "epoch: 394 loss: 1.9219117164611816 grad: 9.189321721682237\n",
      "epoch: 395 loss: 1.9265366792678833 grad: 9.723347090428607\n",
      "epoch: 396 loss: 1.9203534126281738 grad: 9.350688506302143\n",
      "epoch: 397 loss: 1.920091986656189 grad: 9.020484487718296\n",
      "epoch: 398 loss: 1.9159411191940308 grad: 8.955763166193806\n",
      "epoch: 399 loss: 1.9187182188034058 grad: 8.967520564646712\n",
      "epoch: 400 loss: 1.92010498046875 grad: 8.960540143809917\n",
      "epoch: 401 loss: 1.9190537929534912 grad: 9.247116126859236\n",
      "epoch: 402 loss: 1.9177535772323608 grad: 9.35302581450355\n",
      "epoch: 403 loss: 1.9224567413330078 grad: 9.496630495983279\n",
      "epoch: 404 loss: 1.9208064079284668 grad: 9.964994499252903\n",
      "epoch: 405 loss: 1.9171233177185059 grad: 8.846837401700517\n",
      "epoch: 406 loss: 1.918413519859314 grad: 9.210799343159628\n",
      "epoch: 407 loss: 1.9236136674880981 grad: 9.764391307053822\n",
      "epoch: 408 loss: 1.9231351613998413 grad: 9.160937142344045\n",
      "epoch: 409 loss: 1.9105182886123657 grad: 9.485882456798757\n",
      "epoch: 410 loss: 1.914400577545166 grad: 9.0452903388142\n",
      "epoch: 411 loss: 1.9146701097488403 grad: 8.860211678832355\n",
      "epoch: 412 loss: 1.916280746459961 grad: 8.95330692514304\n",
      "epoch: 413 loss: 1.921717882156372 grad: 9.228308238806056\n",
      "epoch: 414 loss: 1.916199803352356 grad: 8.817952842525546\n",
      "epoch: 415 loss: 1.9152823686599731 grad: 9.07833209041033\n",
      "epoch: 416 loss: 1.9135584831237793 grad: 9.109800282422276\n",
      "epoch: 417 loss: 1.915470004081726 grad: 9.02934593957154\n",
      "epoch: 418 loss: 1.9133374691009521 grad: 9.447233981866804\n",
      "epoch: 419 loss: 1.912010669708252 grad: 8.873415971633106\n",
      "epoch: 420 loss: 1.9107215404510498 grad: 9.188264911868684\n",
      "epoch: 421 loss: 1.9113333225250244 grad: 9.313699218104519\n",
      "epoch: 422 loss: 1.9204468727111816 grad: 9.922590928396122\n",
      "epoch: 423 loss: 1.912474274635315 grad: 9.00248173296836\n",
      "epoch: 424 loss: 1.9130792617797852 grad: 9.456311860883106\n",
      "epoch: 425 loss: 1.9131531715393066 grad: 9.405166391896763\n",
      "epoch: 426 loss: 1.9123698472976685 grad: 9.485712803929808\n",
      "epoch: 427 loss: 1.9148675203323364 grad: 9.32543812986345\n",
      "epoch: 428 loss: 1.9111803770065308 grad: 9.017681610467474\n",
      "epoch: 429 loss: 1.9122967720031738 grad: 8.843669121914973\n",
      "epoch: 430 loss: 1.9134420156478882 grad: 9.256949505960893\n",
      "epoch: 431 loss: 1.9185649156570435 grad: 9.150445803707939\n",
      "epoch: 432 loss: 1.9106558561325073 grad: 8.94939605179908\n",
      "epoch: 433 loss: 1.9074162244796753 grad: 9.445990515676963\n",
      "epoch: 434 loss: 1.9118119478225708 grad: 9.833206218297756\n",
      "epoch: 435 loss: 1.9159098863601685 grad: 9.597419183161701\n",
      "epoch: 436 loss: 1.9070281982421875 grad: 9.306551725027107\n",
      "epoch: 437 loss: 1.910569429397583 grad: 9.59360476511915\n",
      "epoch: 438 loss: 1.9083613157272339 grad: 8.819417037158495\n",
      "epoch: 439 loss: 1.907800316810608 grad: 9.465843961248913\n",
      "epoch: 440 loss: 1.9089207649230957 grad: 9.622144467884763\n",
      "epoch: 441 loss: 1.9068204164505005 grad: 9.335757721784628\n",
      "epoch: 442 loss: 1.9070401191711426 grad: 9.397419764475513\n",
      "epoch: 443 loss: 1.9057502746582031 grad: 9.119535903727252\n",
      "epoch: 444 loss: 1.9048761129379272 grad: 9.300458055396106\n",
      "epoch: 445 loss: 1.9124630689620972 grad: 9.852529529304732\n",
      "epoch: 446 loss: 1.9148368835449219 grad: 9.393123067383256\n",
      "epoch: 447 loss: 1.9139800071716309 grad: 9.367493752220144\n",
      "epoch: 448 loss: 1.9014191627502441 grad: 9.177904341192473\n",
      "epoch: 449 loss: 1.9116216897964478 grad: 9.881210540546961\n",
      "epoch: 450 loss: 1.9084645509719849 grad: 9.554360187021159\n",
      "epoch: 451 loss: 1.9029172658920288 grad: 9.234820751266348\n",
      "epoch: 452 loss: 1.9120852947235107 grad: 9.29686626103071\n",
      "epoch: 453 loss: 1.9131397008895874 grad: 9.318522034811654\n",
      "epoch: 454 loss: 1.9030519723892212 grad: 9.265484582699303\n",
      "epoch: 455 loss: 1.9136778116226196 grad: 9.490388468979665\n",
      "epoch: 456 loss: 1.9027482271194458 grad: 9.941943576818126\n",
      "epoch: 457 loss: 1.8999675512313843 grad: 9.499034017908372\n",
      "epoch: 458 loss: 1.9075977802276611 grad: 8.890197332490176\n",
      "epoch: 459 loss: 1.8971649408340454 grad: 9.23267662213997\n",
      "epoch: 460 loss: 1.9051462411880493 grad: 9.366552087360077\n",
      "epoch: 461 loss: 1.906141996383667 grad: 9.89980191424016\n",
      "epoch: 462 loss: 1.897261619567871 grad: 8.933824168370357\n",
      "epoch: 463 loss: 1.901682734489441 grad: 9.749776240112999\n",
      "epoch: 464 loss: 1.905948519706726 grad: 9.120842077680642\n",
      "epoch: 465 loss: 1.91057550907135 grad: 9.700052467027\n",
      "epoch: 466 loss: 1.9062144756317139 grad: 9.764144177186406\n",
      "epoch: 467 loss: 1.8998942375183105 grad: 9.656819187526015\n",
      "epoch: 468 loss: 1.9002138376235962 grad: 9.597521211035431\n",
      "epoch: 469 loss: 1.8992056846618652 grad: 10.108670039967235\n",
      "epoch: 470 loss: 1.909013271331787 grad: 9.450323638114487\n",
      "epoch: 471 loss: 1.8983582258224487 grad: 9.558147012463046\n",
      "epoch: 472 loss: 1.9035345315933228 grad: 9.16920157454701\n",
      "epoch: 473 loss: 1.9019325971603394 grad: 9.294372288569335\n",
      "epoch: 474 loss: 1.906987190246582 grad: 9.65628880150764\n",
      "epoch: 475 loss: 1.899170160293579 grad: 8.510800243577076\n",
      "epoch: 476 loss: 1.90583074092865 grad: 9.408635510087368\n",
      "epoch: 477 loss: 1.9059078693389893 grad: 9.491845889371776\n",
      "epoch: 478 loss: 1.910041332244873 grad: 9.888064462780243\n",
      "epoch: 479 loss: 1.8977645635604858 grad: 9.669600851493813\n",
      "epoch: 480 loss: 1.901070237159729 grad: 9.90700717009456\n",
      "epoch: 481 loss: 1.9070217609405518 grad: 9.661640373916025\n",
      "epoch: 482 loss: 1.8947564363479614 grad: 9.293202774229622\n",
      "epoch: 483 loss: 1.9088798761367798 grad: 9.580972754329975\n",
      "epoch: 484 loss: 1.8902405500411987 grad: 8.694778290163311\n",
      "epoch: 485 loss: 1.8986741304397583 grad: 9.33468820533109\n",
      "epoch: 486 loss: 1.9002310037612915 grad: 9.638112718830742\n",
      "epoch: 487 loss: 1.8930186033248901 grad: 9.575873557053182\n",
      "epoch: 488 loss: 1.895114541053772 grad: 9.40500627975497\n",
      "epoch: 489 loss: 1.9046355485916138 grad: 9.54262208741247\n",
      "epoch: 490 loss: 1.9048954248428345 grad: 8.951833570405604\n",
      "epoch: 491 loss: 1.9056669473648071 grad: 9.240402576277061\n",
      "epoch: 492 loss: 1.89924156665802 grad: 9.41272312309593\n",
      "epoch: 493 loss: 1.8954076766967773 grad: 9.780549267609974\n",
      "epoch: 494 loss: 1.8956938982009888 grad: 9.832512043497806\n",
      "epoch: 495 loss: 1.9022835493087769 grad: 9.593732967662314\n",
      "epoch: 496 loss: 1.8968582153320312 grad: 9.332281053546698\n",
      "epoch: 497 loss: 1.8928064107894897 grad: 10.083451337949743\n",
      "epoch: 498 loss: 1.9029457569122314 grad: 9.483643269107219\n",
      "epoch: 499 loss: 1.8918057680130005 grad: 9.373995188291051\n",
      "2.0746815279126167\n",
      "epoch: 0 loss: 2.3049025535583496 grad: 0.8832958636358232\n",
      "epoch: 1 loss: 2.30328106880188 grad: 0.6649437836765881\n",
      "epoch: 2 loss: 2.257011651992798 grad: 0.9968370402163441\n",
      "epoch: 3 loss: 2.1826183795928955 grad: 1.421117292438765\n",
      "epoch: 4 loss: 2.147899866104126 grad: 1.788176554731012\n",
      "epoch: 5 loss: 2.1386852264404297 grad: 1.5811384887659057\n",
      "epoch: 6 loss: 2.138814687728882 grad: 1.8465445297460685\n",
      "epoch: 7 loss: 2.1119043827056885 grad: 2.39891591659444\n",
      "epoch: 8 loss: 2.076510190963745 grad: 3.0425232747733215\n",
      "epoch: 9 loss: 2.0363481044769287 grad: 3.6747147878317814\n",
      "epoch: 10 loss: 2.009045362472534 grad: 4.419652581628364\n",
      "epoch: 11 loss: 1.9990698099136353 grad: 5.00969980223546\n",
      "epoch: 12 loss: 1.961179494857788 grad: 5.534621556377267\n",
      "epoch: 13 loss: 1.942794919013977 grad: 5.312369981972364\n",
      "epoch: 14 loss: 1.9290536642074585 grad: 5.565027503356326\n",
      "epoch: 15 loss: 1.906913161277771 grad: 5.561805798458711\n",
      "epoch: 16 loss: 1.8980084657669067 grad: 5.7944481957219685\n",
      "epoch: 17 loss: 1.8930083513259888 grad: 5.457834022118718\n",
      "epoch: 18 loss: 1.8882811069488525 grad: 5.433920626766242\n",
      "epoch: 19 loss: 1.8791261911392212 grad: 5.700700719677289\n",
      "epoch: 20 loss: 1.8606326580047607 grad: 5.879572359963768\n",
      "epoch: 21 loss: 1.8571912050247192 grad: 6.12004881149545\n",
      "epoch: 22 loss: 1.8511724472045898 grad: 6.08116497002202\n",
      "epoch: 23 loss: 1.86689293384552 grad: 6.3720979756225935\n",
      "epoch: 24 loss: 1.8484610319137573 grad: 5.769322921240394\n",
      "epoch: 25 loss: 1.842685580253601 grad: 5.9159131735634425\n",
      "epoch: 26 loss: 1.855436086654663 grad: 6.516526979815108\n",
      "epoch: 27 loss: 1.8364187479019165 grad: 6.309261103216115\n",
      "epoch: 28 loss: 1.8373699188232422 grad: 5.9605911470070065\n",
      "epoch: 29 loss: 1.8185175657272339 grad: 5.693894549005014\n",
      "epoch: 30 loss: 1.8179354667663574 grad: 7.0157761323632535\n",
      "epoch: 31 loss: 1.8147261142730713 grad: 6.661449480074687\n",
      "epoch: 32 loss: 1.8059154748916626 grad: 6.716516520584322\n",
      "epoch: 33 loss: 1.8150098323822021 grad: 6.453580849412237\n",
      "epoch: 34 loss: 1.811148762702942 grad: 7.299715275670649\n",
      "epoch: 35 loss: 1.8038556575775146 grad: 6.901516764019482\n",
      "epoch: 36 loss: 1.7875208854675293 grad: 6.528343590349236\n",
      "epoch: 37 loss: 1.7993525266647339 grad: 6.547230548185152\n",
      "epoch: 38 loss: 1.7746241092681885 grad: 6.256035515458771\n",
      "epoch: 39 loss: 1.7900855541229248 grad: 7.355954224676622\n",
      "epoch: 40 loss: 1.7755661010742188 grad: 6.495035116055367\n",
      "epoch: 41 loss: 1.7821294069290161 grad: 6.769129376440394\n",
      "epoch: 42 loss: 1.7894372940063477 grad: 6.528348331190904\n",
      "epoch: 43 loss: 1.762626051902771 grad: 6.237918551667318\n",
      "epoch: 44 loss: 1.7510679960250854 grad: 7.4612786492262595\n",
      "epoch: 45 loss: 1.7797561883926392 grad: 6.798892250183382\n",
      "epoch: 46 loss: 1.7488807439804077 grad: 8.00657363473678\n",
      "epoch: 47 loss: 1.7470545768737793 grad: 8.39961152537153\n",
      "epoch: 48 loss: 1.7643650770187378 grad: 6.706078464258185\n",
      "epoch: 49 loss: 1.754181146621704 grad: 7.926681983221594\n",
      "epoch: 50 loss: 1.725705862045288 grad: 6.407761021030767\n",
      "epoch: 51 loss: 1.7218530178070068 grad: 6.836169426179757\n",
      "epoch: 52 loss: 1.7255103588104248 grad: 7.3318345748217935\n",
      "epoch: 53 loss: 1.740683913230896 grad: 7.375774994095241\n",
      "epoch: 54 loss: 1.7132363319396973 grad: 7.310454757338563\n",
      "epoch: 55 loss: 1.7195345163345337 grad: 6.79079605318192\n",
      "epoch: 56 loss: 1.7202069759368896 grad: 8.0905165831879\n",
      "epoch: 57 loss: 1.713588833808899 grad: 6.878944625337017\n",
      "epoch: 58 loss: 1.7245090007781982 grad: 7.086522777189708\n",
      "epoch: 59 loss: 1.7123080492019653 grad: 6.892069611631635\n",
      "epoch: 60 loss: 1.7144299745559692 grad: 8.161388121180593\n",
      "epoch: 61 loss: 1.6982622146606445 grad: 6.749552412253309\n",
      "epoch: 62 loss: 1.697637915611267 grad: 6.986796324567718\n",
      "epoch: 63 loss: 1.7189780473709106 grad: 6.7774346249523605\n",
      "epoch: 64 loss: 1.690332055091858 grad: 6.6263188635484624\n",
      "epoch: 65 loss: 1.6964133977890015 grad: 6.865386251481213\n",
      "epoch: 66 loss: 1.7071943283081055 grad: 7.066600759100448\n",
      "epoch: 67 loss: 1.6970820426940918 grad: 6.936643308497936\n",
      "epoch: 68 loss: 1.6833586692810059 grad: 6.191303813163171\n",
      "epoch: 69 loss: 1.6904131174087524 grad: 6.866702765372576\n",
      "epoch: 70 loss: 1.6962848901748657 grad: 7.224665332740332\n",
      "epoch: 71 loss: 1.6838407516479492 grad: 7.1647338753491425\n",
      "epoch: 72 loss: 1.6768845319747925 grad: 6.546839913784222\n",
      "epoch: 73 loss: 1.6654607057571411 grad: 7.23250050628986\n",
      "epoch: 74 loss: 1.6723164319992065 grad: 7.784116183051198\n",
      "epoch: 75 loss: 1.6751309633255005 grad: 6.583257715377147\n",
      "epoch: 76 loss: 1.6795722246170044 grad: 6.706717353654861\n",
      "epoch: 77 loss: 1.6738741397857666 grad: 6.363148301803333\n",
      "epoch: 78 loss: 1.679876446723938 grad: 6.340645716035238\n",
      "epoch: 79 loss: 1.6667723655700684 grad: 6.453655593180133\n",
      "epoch: 80 loss: 1.6764730215072632 grad: 7.345462792789534\n",
      "epoch: 81 loss: 1.6960521936416626 grad: 6.990534039711329\n",
      "epoch: 82 loss: 1.6805402040481567 grad: 6.395797462128059\n",
      "epoch: 83 loss: 1.6926751136779785 grad: 6.608476981182032\n",
      "epoch: 84 loss: 1.663818359375 grad: 7.286540047378886\n",
      "epoch: 85 loss: 1.661504864692688 grad: 6.115706736680872\n",
      "epoch: 86 loss: 1.6644524335861206 grad: 6.516528166063677\n",
      "epoch: 87 loss: 1.67255699634552 grad: 7.1052540776415425\n",
      "epoch: 88 loss: 1.6700330972671509 grad: 7.251884004981202\n",
      "epoch: 89 loss: 1.6578898429870605 grad: 5.637297086572665\n",
      "epoch: 90 loss: 1.6644737720489502 grad: 7.205547656961287\n",
      "epoch: 91 loss: 1.661437749862671 grad: 6.746369768897513\n",
      "epoch: 92 loss: 1.6628702878952026 grad: 7.267669170208151\n",
      "epoch: 93 loss: 1.6621028184890747 grad: 5.726790769594132\n",
      "epoch: 94 loss: 1.651314377784729 grad: 7.197641672654768\n",
      "epoch: 95 loss: 1.6402344703674316 grad: 5.309960245980042\n",
      "epoch: 96 loss: 1.6277910470962524 grad: 5.8573243648709665\n",
      "epoch: 97 loss: 1.6460546255111694 grad: 6.689640505977069\n",
      "epoch: 98 loss: 1.667339563369751 grad: 6.544257628449977\n",
      "epoch: 99 loss: 1.6422463655471802 grad: 6.3757220516584185\n",
      "epoch: 100 loss: 1.6718460321426392 grad: 6.114338643998457\n",
      "epoch: 101 loss: 1.6529591083526611 grad: 7.163918777596134\n",
      "epoch: 102 loss: 1.6438294649124146 grad: 5.844534694070731\n",
      "epoch: 103 loss: 1.6283626556396484 grad: 6.245900631482996\n",
      "epoch: 104 loss: 1.6453571319580078 grad: 6.10099214328667\n",
      "epoch: 105 loss: 1.6476936340332031 grad: 7.495605055290793\n",
      "epoch: 106 loss: 1.6387848854064941 grad: 5.573238028674424\n",
      "epoch: 107 loss: 1.6475179195404053 grad: 5.741121379297092\n",
      "epoch: 108 loss: 1.6479886770248413 grad: 6.086992586999028\n",
      "epoch: 109 loss: 1.637863039970398 grad: 6.348957299398416\n",
      "epoch: 110 loss: 1.6510136127471924 grad: 6.389779896371663\n",
      "epoch: 111 loss: 1.6352581977844238 grad: 6.425247036917426\n",
      "epoch: 112 loss: 1.6998406648635864 grad: 6.819377788573489\n",
      "epoch: 113 loss: 1.6459788084030151 grad: 5.734636403661704\n",
      "epoch: 114 loss: 1.6397470235824585 grad: 6.113758463326482\n",
      "epoch: 115 loss: 1.6558018922805786 grad: 5.949613289395832\n",
      "epoch: 116 loss: 1.658148169517517 grad: 6.867930556433474\n",
      "epoch: 117 loss: 1.6473610401153564 grad: 6.732339645056137\n",
      "epoch: 118 loss: 1.6443530321121216 grad: 7.309327122653139\n",
      "epoch: 119 loss: 1.6529312133789062 grad: 5.582079289445328\n",
      "epoch: 120 loss: 1.6472558975219727 grad: 6.532765821987942\n",
      "epoch: 121 loss: 1.6469242572784424 grad: 6.766736182161785\n",
      "epoch: 122 loss: 1.6713279485702515 grad: 6.870045398299168\n",
      "epoch: 123 loss: 1.6403343677520752 grad: 6.501153752417373\n",
      "epoch: 124 loss: 1.6372110843658447 grad: 6.243068827901591\n",
      "epoch: 125 loss: 1.6294351816177368 grad: 6.091354154748438\n",
      "epoch: 126 loss: 1.6276674270629883 grad: 6.186825272858995\n",
      "epoch: 127 loss: 1.629517912864685 grad: 6.067889897096999\n",
      "epoch: 128 loss: 1.637460470199585 grad: 5.061210514110234\n",
      "epoch: 129 loss: 1.616054654121399 grad: 5.611237618090349\n",
      "epoch: 130 loss: 1.6148039102554321 grad: 5.591927038023728\n",
      "epoch: 131 loss: 1.6195541620254517 grad: 5.66516734752729\n",
      "epoch: 132 loss: 1.6174958944320679 grad: 6.376390660606535\n",
      "epoch: 133 loss: 1.6235326528549194 grad: 5.433703795177338\n",
      "epoch: 134 loss: 1.6218558549880981 grad: 5.724790280914772\n",
      "epoch: 135 loss: 1.6107970476150513 grad: 6.536997866712414\n",
      "epoch: 136 loss: 1.6296056509017944 grad: 6.8581118303643755\n",
      "epoch: 137 loss: 1.653388500213623 grad: 6.521727373270782\n",
      "epoch: 138 loss: 1.6139057874679565 grad: 5.370518493194328\n",
      "epoch: 139 loss: 1.637589931488037 grad: 7.169872213835204\n",
      "epoch: 140 loss: 1.6110413074493408 grad: 5.441471723363643\n",
      "epoch: 141 loss: 1.6185767650604248 grad: 5.551917246582759\n",
      "epoch: 142 loss: 1.62221097946167 grad: 6.34050221503781\n",
      "epoch: 143 loss: 1.609046220779419 grad: 5.927251565735729\n",
      "epoch: 144 loss: 1.6192713975906372 grad: 5.522769807600424\n",
      "epoch: 145 loss: 1.6297905445098877 grad: 6.22231905914553\n",
      "epoch: 146 loss: 1.6133977174758911 grad: 6.687526961905066\n",
      "epoch: 147 loss: 1.6229214668273926 grad: 7.049656194380943\n",
      "epoch: 148 loss: 1.6172786951065063 grad: 5.6685166951096075\n",
      "epoch: 149 loss: 1.6280125379562378 grad: 6.937971424731557\n",
      "epoch: 150 loss: 1.6416829824447632 grad: 6.119695379509606\n",
      "epoch: 151 loss: 1.6150087118148804 grad: 6.632848437861001\n",
      "epoch: 152 loss: 1.6167747974395752 grad: 6.189650516547288\n",
      "epoch: 153 loss: 1.6126502752304077 grad: 6.798932607507595\n",
      "epoch: 154 loss: 1.6333580017089844 grad: 5.948061751811514\n",
      "epoch: 155 loss: 1.607737421989441 grad: 5.250672992462714\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 156 loss: 1.6095515489578247 grad: 4.723557264008926\n",
      "epoch: 157 loss: 1.6054410934448242 grad: 6.0013658688811065\n",
      "epoch: 158 loss: 1.622570276260376 grad: 5.863482168310709\n",
      "epoch: 159 loss: 1.6170835494995117 grad: 6.417227579333167\n",
      "epoch: 160 loss: 1.6280611753463745 grad: 6.098865555154921\n",
      "epoch: 161 loss: 1.6339011192321777 grad: 7.135132795896454\n",
      "epoch: 162 loss: 1.6398718357086182 grad: 7.359309830268998\n",
      "epoch: 163 loss: 1.614838719367981 grad: 5.871721066861014\n",
      "epoch: 164 loss: 1.6071707010269165 grad: 6.700871001196021\n",
      "epoch: 165 loss: 1.6446326971054077 grad: 7.171447718671155\n",
      "epoch: 166 loss: 1.600165843963623 grad: 5.590026209465346\n",
      "epoch: 167 loss: 1.6045210361480713 grad: 5.021513827045741\n",
      "epoch: 168 loss: 1.59552001953125 grad: 5.956819443828762\n",
      "epoch: 169 loss: 1.605049729347229 grad: 6.687997326580531\n",
      "epoch: 170 loss: 1.5967893600463867 grad: 5.4244188371231425\n",
      "epoch: 171 loss: 1.5987125635147095 grad: 6.235845529153021\n",
      "epoch: 172 loss: 1.6005768775939941 grad: 5.206094538014967\n",
      "epoch: 173 loss: 1.6089569330215454 grad: 5.814802353461158\n",
      "epoch: 174 loss: 1.6237674951553345 grad: 5.718879126887721\n",
      "epoch: 175 loss: 1.5855597257614136 grad: 4.823874145834582\n",
      "epoch: 176 loss: 1.6040661334991455 grad: 5.65765382001504\n",
      "epoch: 177 loss: 1.6120710372924805 grad: 5.383737832038143\n",
      "epoch: 178 loss: 1.5961778163909912 grad: 5.12663620091495\n",
      "epoch: 179 loss: 1.5944689512252808 grad: 5.600727719188904\n",
      "epoch: 180 loss: 1.603523850440979 grad: 6.538144437333459\n",
      "epoch: 181 loss: 1.6053117513656616 grad: 6.040615915979433\n",
      "epoch: 182 loss: 1.5973416566848755 grad: 5.663292183456121\n",
      "epoch: 183 loss: 1.6048133373260498 grad: 5.155117325301395\n",
      "epoch: 184 loss: 1.6011117696762085 grad: 5.58283098695525\n",
      "epoch: 185 loss: 1.605181336402893 grad: 6.598257165440611\n",
      "epoch: 186 loss: 1.6063991785049438 grad: 6.091235311338038\n",
      "epoch: 187 loss: 1.5831122398376465 grad: 5.478996882255795\n",
      "epoch: 188 loss: 1.5960854291915894 grad: 5.978659449695283\n",
      "epoch: 189 loss: 1.5926110744476318 grad: 4.282286256141373\n",
      "epoch: 190 loss: 1.5835990905761719 grad: 4.140825743448435\n",
      "epoch: 191 loss: 1.5791714191436768 grad: 5.647871728802098\n",
      "epoch: 192 loss: 1.580237865447998 grad: 5.553507138474288\n",
      "epoch: 193 loss: 1.5864285230636597 grad: 5.211060105307268\n",
      "epoch: 194 loss: 1.601922869682312 grad: 5.6986738084921695\n",
      "epoch: 195 loss: 1.5818285942077637 grad: 5.653198852404723\n",
      "epoch: 196 loss: 1.6020809412002563 grad: 5.332244937632779\n",
      "epoch: 197 loss: 1.5867385864257812 grad: 5.715592567982192\n",
      "epoch: 198 loss: 1.6013524532318115 grad: 5.012789599138946\n",
      "epoch: 199 loss: 1.5955791473388672 grad: 6.004886301446095\n",
      "epoch: 200 loss: 1.6019790172576904 grad: 5.206430935847484\n",
      "epoch: 201 loss: 1.591538906097412 grad: 5.751939542205946\n",
      "epoch: 202 loss: 1.5962132215499878 grad: 5.336359890547953\n",
      "epoch: 203 loss: 1.5945587158203125 grad: 4.853198011621666\n",
      "epoch: 204 loss: 1.6042399406433105 grad: 5.411099299008273\n",
      "epoch: 205 loss: 1.588916540145874 grad: 4.670584218232228\n",
      "epoch: 206 loss: 1.5837777853012085 grad: 5.5208225911853575\n",
      "epoch: 207 loss: 1.5946203470230103 grad: 4.818515524183625\n",
      "epoch: 208 loss: 1.5862175226211548 grad: 5.928895961494618\n",
      "epoch: 209 loss: 1.6040197610855103 grad: 5.096244455279724\n",
      "epoch: 210 loss: 1.5942487716674805 grad: 6.538870151262462\n",
      "epoch: 211 loss: 1.589817762374878 grad: 4.753442672652649\n",
      "epoch: 212 loss: 1.5750881433486938 grad: 4.825019470966983\n",
      "epoch: 213 loss: 1.5912374258041382 grad: 5.013980454763109\n",
      "epoch: 214 loss: 1.5968588590621948 grad: 5.781252611826916\n",
      "epoch: 215 loss: 1.5904241800308228 grad: 5.004671768067792\n",
      "epoch: 216 loss: 1.577025055885315 grad: 4.313312916816426\n",
      "epoch: 217 loss: 1.5706592798233032 grad: 5.451325637627106\n",
      "epoch: 218 loss: 1.5907655954360962 grad: 5.34394462281033\n",
      "epoch: 219 loss: 1.5861090421676636 grad: 4.618710877640499\n",
      "epoch: 220 loss: 1.5835717916488647 grad: 5.715699219445967\n",
      "epoch: 221 loss: 1.576106071472168 grad: 4.212398547361603\n",
      "epoch: 222 loss: 1.577651023864746 grad: 4.715787961657259\n",
      "epoch: 223 loss: 1.5960257053375244 grad: 4.757007732411391\n",
      "epoch: 224 loss: 1.5927451848983765 grad: 4.77671158148235\n",
      "epoch: 225 loss: 1.5912580490112305 grad: 4.9931358411310525\n",
      "epoch: 226 loss: 1.5953823328018188 grad: 5.342901668022369\n",
      "epoch: 227 loss: 1.5922057628631592 grad: 5.621496021738263\n",
      "epoch: 228 loss: 1.6064140796661377 grad: 6.3144872162425845\n",
      "epoch: 229 loss: 1.5739234685897827 grad: 3.409452562045834\n",
      "epoch: 230 loss: 1.591082215309143 grad: 4.715464553230937\n",
      "epoch: 231 loss: 1.5890400409698486 grad: 5.385762394579059\n",
      "epoch: 232 loss: 1.6042684316635132 grad: 6.059265198225162\n",
      "epoch: 233 loss: 1.5694799423217773 grad: 4.255231844871973\n",
      "epoch: 234 loss: 1.5863343477249146 grad: 5.0962443625877265\n",
      "epoch: 235 loss: 1.578031063079834 grad: 4.608967189455023\n",
      "epoch: 236 loss: 1.5928425788879395 grad: 5.873543699235265\n",
      "epoch: 237 loss: 1.622320532798767 grad: 5.650038691095911\n",
      "epoch: 238 loss: 1.5979056358337402 grad: 5.286051197714371\n",
      "epoch: 239 loss: 1.5912848711013794 grad: 5.579258738384678\n",
      "epoch: 240 loss: 1.587852120399475 grad: 4.4996942753663935\n",
      "epoch: 241 loss: 1.5730125904083252 grad: 4.690390624220667\n",
      "epoch: 242 loss: 1.5843039751052856 grad: 5.2194358215865435\n",
      "epoch: 243 loss: 1.5615816116333008 grad: 3.721318082184205\n",
      "epoch: 244 loss: 1.559417486190796 grad: 4.047199919097686\n",
      "epoch: 245 loss: 1.6084164381027222 grad: 8.476227381020959\n",
      "epoch: 246 loss: 1.5999610424041748 grad: 5.055191868311403\n",
      "epoch: 247 loss: 1.5760043859481812 grad: 4.839573123592877\n",
      "epoch: 248 loss: 1.5690886974334717 grad: 5.009238444479663\n",
      "epoch: 249 loss: 1.5735160112380981 grad: 4.954809555557548\n",
      "epoch: 250 loss: 1.5727739334106445 grad: 3.687453720837831\n",
      "epoch: 251 loss: 1.5699650049209595 grad: 3.1140872742054806\n",
      "epoch: 252 loss: 1.5664936304092407 grad: 4.4969511024385564\n",
      "epoch: 253 loss: 1.576324462890625 grad: 4.27972586871483\n",
      "epoch: 254 loss: 1.5805585384368896 grad: 6.0342471684259165\n",
      "epoch: 255 loss: 1.5968960523605347 grad: 5.623120304540054\n",
      "epoch: 256 loss: 1.5958590507507324 grad: 5.360920648912948\n",
      "epoch: 257 loss: 1.6018468141555786 grad: 5.154785754781815\n",
      "epoch: 258 loss: 1.5820560455322266 grad: 5.497742876649333\n",
      "epoch: 259 loss: 1.5826648473739624 grad: 4.781638446522406\n",
      "epoch: 260 loss: 1.5891151428222656 grad: 3.971311072374092\n",
      "epoch: 261 loss: 1.5785255432128906 grad: 4.2472488214403405\n",
      "epoch: 262 loss: 1.5634064674377441 grad: 3.682757878967272\n",
      "epoch: 263 loss: 1.5629006624221802 grad: 3.493657894728654\n",
      "epoch: 264 loss: 1.560563564300537 grad: 4.372711582062138\n",
      "epoch: 265 loss: 1.5762066841125488 grad: 4.894280151622886\n",
      "epoch: 266 loss: 1.573129653930664 grad: 4.914960887563967\n",
      "epoch: 267 loss: 1.596630334854126 grad: 5.411427018442852\n",
      "epoch: 268 loss: 1.5993951559066772 grad: 6.344377516992056\n",
      "epoch: 269 loss: 1.6198140382766724 grad: 6.257688769428883\n",
      "epoch: 270 loss: 1.5926668643951416 grad: 5.21628134400258\n",
      "epoch: 271 loss: 1.5719821453094482 grad: 4.656538574166421\n",
      "epoch: 272 loss: 1.5722084045410156 grad: 5.2012268572706155\n",
      "epoch: 273 loss: 1.5689729452133179 grad: 4.8273317369194535\n",
      "epoch: 274 loss: 1.5584592819213867 grad: 3.4183263696493333\n",
      "epoch: 275 loss: 1.5636800527572632 grad: 3.571380333535561\n",
      "epoch: 276 loss: 1.5664591789245605 grad: 3.312438302727951\n",
      "epoch: 277 loss: 1.5756466388702393 grad: 5.378196646001542\n",
      "epoch: 278 loss: 1.5598691701889038 grad: 3.7246695612199425\n",
      "epoch: 279 loss: 1.5928353071212769 grad: 6.156106384502372\n",
      "epoch: 280 loss: 1.5991666316986084 grad: 6.76448723047331\n",
      "epoch: 281 loss: 1.6080297231674194 grad: 5.956645730622021\n",
      "epoch: 282 loss: 1.5838054418563843 grad: 4.460029694117569\n",
      "epoch: 283 loss: 1.5962954759597778 grad: 4.854310021302404\n",
      "epoch: 284 loss: 1.647106647491455 grad: 5.393130855123615\n",
      "epoch: 285 loss: 1.583585262298584 grad: 6.167703367400705\n",
      "epoch: 286 loss: 1.6154035329818726 grad: 4.85506440584474\n",
      "epoch: 287 loss: 1.5724517107009888 grad: 5.365785075138919\n",
      "epoch: 288 loss: 1.5822306871414185 grad: 5.241667702011432\n",
      "epoch: 289 loss: 1.5702108144760132 grad: 4.244651983870403\n",
      "epoch: 290 loss: 1.5667730569839478 grad: 4.86532775778127\n",
      "epoch: 291 loss: 1.5774686336517334 grad: 5.644608869317444\n",
      "epoch: 292 loss: 1.585742473602295 grad: 6.004418784403416\n",
      "epoch: 293 loss: 1.583327054977417 grad: 4.513760797382646\n",
      "epoch: 294 loss: 1.576273798942566 grad: 5.46154019360333\n",
      "epoch: 295 loss: 1.5766751766204834 grad: 4.198739299147671\n",
      "epoch: 296 loss: 1.5655440092086792 grad: 4.573408305405687\n",
      "epoch: 297 loss: 1.5637648105621338 grad: 4.457229302829445\n",
      "epoch: 298 loss: 1.5508009195327759 grad: 3.3735733992996146\n",
      "epoch: 299 loss: 1.5672985315322876 grad: 5.9109973019504105\n",
      "epoch: 300 loss: 1.580586552619934 grad: 5.656099197970288\n",
      "epoch: 301 loss: 1.5659757852554321 grad: 4.466358729304182\n",
      "epoch: 302 loss: 1.5751996040344238 grad: 4.011943738258488\n",
      "epoch: 303 loss: 1.5743887424468994 grad: 5.334462521185415\n",
      "epoch: 304 loss: 1.5742131471633911 grad: 3.7558560262018093\n",
      "epoch: 305 loss: 1.570208191871643 grad: 4.891836456647535\n",
      "epoch: 306 loss: 1.5732026100158691 grad: 4.2273078392336\n",
      "epoch: 307 loss: 1.571458339691162 grad: 5.029803299348679\n",
      "epoch: 308 loss: 1.564887523651123 grad: 3.1124544910078926\n",
      "epoch: 309 loss: 1.5556291341781616 grad: 3.7067517589586734\n",
      "epoch: 310 loss: 1.5690605640411377 grad: 3.6590352289314345\n",
      "epoch: 311 loss: 1.571690559387207 grad: 3.5753338845143965\n",
      "epoch: 312 loss: 1.5611509084701538 grad: 4.30387230761928\n",
      "epoch: 313 loss: 1.5632466077804565 grad: 4.7292142774526305\n",
      "epoch: 314 loss: 1.5658271312713623 grad: 4.245914266137604\n",
      "epoch: 315 loss: 1.5777171850204468 grad: 4.894351758938412\n",
      "epoch: 316 loss: 1.5713690519332886 grad: 4.968693171306226\n",
      "epoch: 317 loss: 1.5685089826583862 grad: 4.029278458589405\n",
      "epoch: 318 loss: 1.5527232885360718 grad: 3.4168893411226753\n",
      "epoch: 319 loss: 1.5728322267532349 grad: 3.902743617652986\n",
      "epoch: 320 loss: 1.559970498085022 grad: 3.8800725550061754\n",
      "epoch: 321 loss: 1.5613821744918823 grad: 3.7891133119732707\n",
      "epoch: 322 loss: 1.5738400220870972 grad: 4.694168050604461\n",
      "epoch: 323 loss: 1.5815720558166504 grad: 5.910480476167293\n",
      "epoch: 324 loss: 1.5695499181747437 grad: 4.32615570573354\n",
      "epoch: 325 loss: 1.5662004947662354 grad: 4.76999369389393\n",
      "epoch: 326 loss: 1.578713059425354 grad: 5.43921339923241\n",
      "epoch: 327 loss: 1.5766090154647827 grad: 3.615236503109789\n",
      "epoch: 328 loss: 1.5610607862472534 grad: 3.533374865193205\n",
      "epoch: 329 loss: 1.565476894378662 grad: 4.8165730639340545\n",
      "epoch: 330 loss: 1.567862629890442 grad: 3.3514597559383263\n",
      "epoch: 331 loss: 1.5585497617721558 grad: 3.649477809664092\n",
      "epoch: 332 loss: 1.5595284700393677 grad: 4.237886253508187\n",
      "epoch: 333 loss: 1.5543309450149536 grad: 2.876269197939537\n",
      "epoch: 334 loss: 1.5575164556503296 grad: 3.2561298227995694\n",
      "epoch: 335 loss: 1.557533621788025 grad: 3.9028884314711045\n",
      "epoch: 336 loss: 1.56146240234375 grad: 3.3286517475070396\n",
      "epoch: 337 loss: 1.573638916015625 grad: 4.558855874400367\n",
      "epoch: 338 loss: 1.57590651512146 grad: 3.9295697998406895\n",
      "epoch: 339 loss: 1.5906745195388794 grad: 5.645206330774987\n",
      "epoch: 340 loss: 1.5720689296722412 grad: 4.505426593390962\n",
      "epoch: 341 loss: 1.5592012405395508 grad: 3.666933467008427\n",
      "epoch: 342 loss: 1.5598880052566528 grad: 3.5911311134646713\n",
      "epoch: 343 loss: 1.5590529441833496 grad: 6.2631234035485175\n",
      "epoch: 344 loss: 1.6008821725845337 grad: 7.740008322508622\n",
      "epoch: 345 loss: 1.6029787063598633 grad: 5.533091927020314\n",
      "epoch: 346 loss: 1.5983706712722778 grad: 6.38461111672176\n",
      "epoch: 347 loss: 1.5904228687286377 grad: 4.325499337721132\n",
      "epoch: 348 loss: 1.5963468551635742 grad: 5.6218218854659545\n",
      "epoch: 349 loss: 1.5779943466186523 grad: 4.339026281893843\n",
      "epoch: 350 loss: 1.5611793994903564 grad: 4.082153555763884\n",
      "epoch: 351 loss: 1.5662741661071777 grad: 3.549699616918535\n",
      "epoch: 352 loss: 1.5740669965744019 grad: 5.794565685318213\n",
      "epoch: 353 loss: 1.567482829093933 grad: 4.50723481720553\n",
      "epoch: 354 loss: 1.5696877241134644 grad: 3.138834246011494\n",
      "epoch: 355 loss: 1.5544954538345337 grad: 3.1618199814703716\n",
      "epoch: 356 loss: 1.5808295011520386 grad: 4.136464918183294\n",
      "epoch: 357 loss: 1.5746879577636719 grad: 3.187583481803131\n",
      "epoch: 358 loss: 1.5643842220306396 grad: 3.3233225712243253\n",
      "epoch: 359 loss: 1.565037727355957 grad: 4.383913935528369\n",
      "epoch: 360 loss: 1.573203682899475 grad: 4.581313200595404\n",
      "epoch: 361 loss: 1.56961190700531 grad: 3.2683529496053514\n",
      "epoch: 362 loss: 1.5574849843978882 grad: 3.2399651294602303\n",
      "epoch: 363 loss: 1.5621486902236938 grad: 3.3923090962528133\n",
      "epoch: 364 loss: 1.5570688247680664 grad: 4.1994977503728705\n",
      "epoch: 365 loss: 1.5567619800567627 grad: 3.9033070634695815\n",
      "epoch: 366 loss: 1.5623893737792969 grad: 2.8888062482124495\n",
      "epoch: 367 loss: 1.5436878204345703 grad: 2.1579365226497065\n",
      "epoch: 368 loss: 1.5460065603256226 grad: 3.2322663296413374\n",
      "epoch: 369 loss: 1.5650596618652344 grad: 5.151367473410469\n",
      "epoch: 370 loss: 1.5666559934616089 grad: 5.673225272828643\n",
      "epoch: 371 loss: 1.589354157447815 grad: 6.8837870098283656\n",
      "epoch: 372 loss: 1.567252516746521 grad: 4.8747777885796495\n",
      "epoch: 373 loss: 1.568476676940918 grad: 4.9444036813096615\n",
      "epoch: 374 loss: 1.5805960893630981 grad: 4.874633029588639\n",
      "epoch: 375 loss: 1.5608528852462769 grad: 3.272722464313213\n",
      "epoch: 376 loss: 1.5997822284698486 grad: 6.041649743696562\n",
      "epoch: 377 loss: 1.5795092582702637 grad: 4.747141460022702\n",
      "epoch: 378 loss: 1.574244737625122 grad: 4.1550367479941155\n",
      "epoch: 379 loss: 1.563478946685791 grad: 4.286277998546872\n",
      "epoch: 380 loss: 1.5682893991470337 grad: 3.902125234710214\n",
      "epoch: 381 loss: 1.577880620956421 grad: 4.432570954683218\n",
      "epoch: 382 loss: 1.5739349126815796 grad: 4.130704720496804\n",
      "epoch: 383 loss: 1.5576950311660767 grad: 3.6342153671749866\n",
      "epoch: 384 loss: 1.5563664436340332 grad: 4.009823735356766\n",
      "epoch: 385 loss: 1.5602773427963257 grad: 4.990317934382125\n",
      "epoch: 386 loss: 1.5661529302597046 grad: 5.508773125033566\n",
      "epoch: 387 loss: 1.5608406066894531 grad: 3.342640495869655\n",
      "epoch: 388 loss: 1.5528290271759033 grad: 3.3716055136230305\n",
      "epoch: 389 loss: 1.5645098686218262 grad: 2.909111357102578\n",
      "epoch: 390 loss: 1.5590635538101196 grad: 3.015005016787244\n",
      "epoch: 391 loss: 1.5530763864517212 grad: 3.577394129298764\n",
      "epoch: 392 loss: 1.5438265800476074 grad: 3.3135606603531\n",
      "epoch: 393 loss: 1.550891637802124 grad: 3.2052453962611365\n",
      "epoch: 394 loss: 1.5577423572540283 grad: 4.885251394561361\n",
      "epoch: 395 loss: 1.5859352350234985 grad: 4.758053788897415\n",
      "epoch: 396 loss: 1.6002497673034668 grad: 6.088744302892131\n",
      "epoch: 397 loss: 1.5741714239120483 grad: 4.1935463280088054\n",
      "epoch: 398 loss: 1.5533605813980103 grad: 5.445898327261381\n",
      "epoch: 399 loss: 1.5756642818450928 grad: 5.353612130812425\n",
      "epoch: 400 loss: 1.5697041749954224 grad: 3.2620766441897118\n",
      "epoch: 401 loss: 1.55844247341156 grad: 4.558396579711134\n",
      "epoch: 402 loss: 1.562868595123291 grad: 2.9411799083819385\n",
      "epoch: 403 loss: 1.570546269416809 grad: 4.483587923005947\n",
      "epoch: 404 loss: 1.5598341226577759 grad: 4.8222133199618415\n",
      "epoch: 405 loss: 1.5706032514572144 grad: 5.285699469194008\n",
      "epoch: 406 loss: 1.5819125175476074 grad: 3.5000302558905396\n",
      "epoch: 407 loss: 1.5644875764846802 grad: 4.847201658052396\n",
      "epoch: 408 loss: 1.5503215789794922 grad: 3.309479728000941\n",
      "epoch: 409 loss: 1.5518229007720947 grad: 4.575596678519442\n",
      "epoch: 410 loss: 1.5472712516784668 grad: 2.603487757428205\n",
      "epoch: 411 loss: 1.5510809421539307 grad: 3.23534890788974\n",
      "epoch: 412 loss: 1.5499696731567383 grad: 4.245038997499781\n",
      "epoch: 413 loss: 1.553043007850647 grad: 4.253127064592072\n",
      "epoch: 414 loss: 1.5498360395431519 grad: 4.708607914789396\n",
      "epoch: 415 loss: 1.569369912147522 grad: 3.5287149816236996\n",
      "epoch: 416 loss: 1.5527487993240356 grad: 2.9141838243803644\n",
      "epoch: 417 loss: 1.5495439767837524 grad: 3.51076736949615\n",
      "epoch: 418 loss: 1.5520821809768677 grad: 5.324886204013876\n",
      "epoch: 419 loss: 1.5829824209213257 grad: 5.369827683561476\n",
      "epoch: 420 loss: 1.5739792585372925 grad: 4.87517012904536\n",
      "epoch: 421 loss: 1.5659037828445435 grad: 4.631321550032866\n",
      "epoch: 422 loss: 1.5613963603973389 grad: 3.3660485495929953\n",
      "epoch: 423 loss: 1.5564053058624268 grad: 3.716239106388822\n",
      "epoch: 424 loss: 1.567946434020996 grad: 3.8054250457462495\n",
      "epoch: 425 loss: 1.569745659828186 grad: 4.526833906657055\n",
      "epoch: 426 loss: 1.550703763961792 grad: 4.369277959126793\n",
      "epoch: 427 loss: 1.5572189092636108 grad: 4.113544792008098\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 428 loss: 1.5680698156356812 grad: 5.136037998701036\n",
      "epoch: 429 loss: 1.5640054941177368 grad: 3.2857540046856215\n",
      "epoch: 430 loss: 1.554280400276184 grad: 3.062233855905331\n",
      "epoch: 431 loss: 1.5634877681732178 grad: 3.646926810401215\n",
      "epoch: 432 loss: 1.556440830230713 grad: 3.821990513021941\n",
      "epoch: 433 loss: 1.5621528625488281 grad: 3.746745655903912\n",
      "epoch: 434 loss: 1.570762038230896 grad: 4.1155320748736655\n",
      "epoch: 435 loss: 1.5571434497833252 grad: 3.5239829042871955\n",
      "epoch: 436 loss: 1.5679359436035156 grad: 3.5146772256609653\n",
      "epoch: 437 loss: 1.5740293264389038 grad: 4.825223966725705\n",
      "epoch: 438 loss: 1.5673192739486694 grad: 4.151849397978264\n",
      "epoch: 439 loss: 1.5500941276550293 grad: 3.477682060905817\n",
      "epoch: 440 loss: 1.5493301153182983 grad: 3.8716596440092426\n",
      "epoch: 441 loss: 1.5641828775405884 grad: 5.570550151439901\n",
      "epoch: 442 loss: 1.594772458076477 grad: 4.334570937346943\n",
      "epoch: 443 loss: 1.555141806602478 grad: 3.221877969889371\n",
      "epoch: 444 loss: 1.567447304725647 grad: 4.521374613697842\n",
      "epoch: 445 loss: 1.563730239868164 grad: 3.9203273165152366\n",
      "epoch: 446 loss: 1.5516902208328247 grad: 3.5044954020602805\n",
      "epoch: 447 loss: 1.5525542497634888 grad: 3.4273218944202273\n",
      "epoch: 448 loss: 1.5587449073791504 grad: 3.1290276380994824\n",
      "epoch: 449 loss: 1.5626028776168823 grad: 4.506206856869754\n",
      "epoch: 450 loss: 1.567070484161377 grad: 4.430620560876825\n",
      "epoch: 451 loss: 1.546464443206787 grad: 3.144085998180736\n",
      "epoch: 452 loss: 1.5578376054763794 grad: 5.365052136220374\n",
      "epoch: 453 loss: 1.5543984174728394 grad: 3.212314488679825\n",
      "epoch: 454 loss: 1.5401915311813354 grad: 2.6702006237496745\n",
      "epoch: 455 loss: 1.5451107025146484 grad: 3.106046881899888\n",
      "epoch: 456 loss: 1.547084927558899 grad: 3.9642198294806907\n",
      "epoch: 457 loss: 1.5523525476455688 grad: 4.622721675662967\n",
      "epoch: 458 loss: 1.5635762214660645 grad: 3.6671623953988686\n",
      "epoch: 459 loss: 1.5721337795257568 grad: 5.903919004005575\n",
      "epoch: 460 loss: 1.5554075241088867 grad: 3.6417073317046964\n",
      "epoch: 461 loss: 1.5429396629333496 grad: 2.577018599086335\n",
      "epoch: 462 loss: 1.558867335319519 grad: 3.589797240219136\n",
      "epoch: 463 loss: 1.5433366298675537 grad: 2.9351376877151605\n",
      "epoch: 464 loss: 1.5382862091064453 grad: 2.5766291420762304\n",
      "epoch: 465 loss: 1.5505632162094116 grad: 3.399551415015602\n",
      "epoch: 466 loss: 1.560917615890503 grad: 3.1565311168700005\n",
      "epoch: 467 loss: 1.5578399896621704 grad: 3.5785134706204755\n",
      "epoch: 468 loss: 1.548468828201294 grad: 4.483312335953596\n",
      "epoch: 469 loss: 1.5504909753799438 grad: 4.199382622229039\n",
      "epoch: 470 loss: 1.5649994611740112 grad: 5.079849981884872\n",
      "epoch: 471 loss: 1.5559998750686646 grad: 4.371023510682559\n",
      "epoch: 472 loss: 1.5421719551086426 grad: 4.101493503565603\n",
      "epoch: 473 loss: 1.5641956329345703 grad: 4.940514990534371\n",
      "epoch: 474 loss: 1.5646603107452393 grad: 3.109218839572672\n",
      "epoch: 475 loss: 1.5626447200775146 grad: 3.8424424154272017\n",
      "epoch: 476 loss: 1.5475701093673706 grad: 2.540152072223861\n",
      "epoch: 477 loss: 1.5375285148620605 grad: 3.6914123000862906\n",
      "epoch: 478 loss: 1.5464376211166382 grad: 2.2797563406341554\n",
      "epoch: 479 loss: 1.5509527921676636 grad: 4.492481783757817\n",
      "epoch: 480 loss: 1.565436601638794 grad: 3.649734997801272\n",
      "epoch: 481 loss: 1.5581761598587036 grad: 3.48684249437914\n",
      "epoch: 482 loss: 1.5529602766036987 grad: 2.876334275555452\n",
      "epoch: 483 loss: 1.5724637508392334 grad: 5.6020322026640255\n",
      "epoch: 484 loss: 1.5696165561676025 grad: 3.4396921757773558\n",
      "epoch: 485 loss: 1.5432215929031372 grad: 3.448955972198316\n",
      "epoch: 486 loss: 1.5395456552505493 grad: 3.4328237713391077\n",
      "epoch: 487 loss: 1.5433965921401978 grad: 2.5153274159820076\n",
      "epoch: 488 loss: 1.533337950706482 grad: 2.546186519462911\n",
      "epoch: 489 loss: 1.5303584337234497 grad: 2.977055822748299\n",
      "epoch: 490 loss: 1.5480985641479492 grad: 3.0146423260272033\n",
      "epoch: 491 loss: 1.5467627048492432 grad: 2.7895785761251926\n",
      "epoch: 492 loss: 1.557039737701416 grad: 3.7259358296918554\n",
      "epoch: 493 loss: 1.5492305755615234 grad: 4.22909782476537\n",
      "epoch: 494 loss: 1.553459644317627 grad: 3.689415987413166\n",
      "epoch: 495 loss: 1.5421909093856812 grad: 3.1244567753228343\n",
      "epoch: 496 loss: 1.5630838871002197 grad: 4.32962188457121\n",
      "epoch: 497 loss: 1.6059942245483398 grad: 5.2738618464469775\n",
      "epoch: 498 loss: 1.5607279539108276 grad: 5.283237438122934\n",
      "epoch: 499 loss: 1.58009672164917 grad: 4.908556180402968\n",
      "1.8618905767798424\n",
      "epoch: 0 loss: 2.3030192852020264 grad: 1.2119427238783194\n",
      "epoch: 1 loss: 2.30271315574646 grad: 1.2215573443487908\n",
      "epoch: 2 loss: 2.302786350250244 grad: 1.212760938340724\n",
      "epoch: 3 loss: 2.3030059337615967 grad: 1.2148941969683777\n",
      "epoch: 4 loss: 2.303205728530884 grad: 1.2079514228842325\n",
      "epoch: 5 loss: 2.30375337600708 grad: 1.1988089449910655\n",
      "epoch: 6 loss: 2.303675413131714 grad: 1.1945139317946982\n",
      "epoch: 7 loss: 2.303072452545166 grad: 1.2080247897991083\n",
      "epoch: 8 loss: 2.303405284881592 grad: 1.209003443147854\n",
      "epoch: 9 loss: 2.3024611473083496 grad: 1.2224096624912428\n",
      "epoch: 10 loss: 2.302769184112549 grad: 1.2167974231313796\n",
      "epoch: 11 loss: 2.303264856338501 grad: 1.2080007883782928\n",
      "epoch: 12 loss: 2.3027896881103516 grad: 1.2033521523052413\n",
      "epoch: 13 loss: 2.3029329776763916 grad: 1.2085602441728707\n",
      "epoch: 14 loss: 2.302999973297119 grad: 1.2013679082313227\n",
      "epoch: 15 loss: 2.3035991191864014 grad: 1.2104282094320904\n",
      "epoch: 16 loss: 2.302462339401245 grad: 1.2130432211210034\n",
      "epoch: 17 loss: 2.3029181957244873 grad: 1.206598892412518\n",
      "epoch: 18 loss: 2.30299973487854 grad: 1.2048785497974013\n",
      "epoch: 19 loss: 2.3029909133911133 grad: 1.2118950226780263\n",
      "epoch: 20 loss: 2.303225517272949 grad: 1.2025849420137495\n",
      "epoch: 21 loss: 2.303406000137329 grad: 1.2123668703901034\n",
      "epoch: 22 loss: 2.3027687072753906 grad: 1.2160105331586526\n",
      "epoch: 23 loss: 2.3029208183288574 grad: 1.2112048818371333\n",
      "epoch: 24 loss: 2.3031153678894043 grad: 1.2042381142835237\n",
      "epoch: 25 loss: 2.303281545639038 grad: 1.214600607619754\n",
      "epoch: 26 loss: 2.3030357360839844 grad: 1.209950127444851\n",
      "epoch: 27 loss: 2.3027663230895996 grad: 1.2065632119386767\n",
      "epoch: 28 loss: 2.3029515743255615 grad: 1.2068804878379322\n",
      "epoch: 29 loss: 2.302656650543213 grad: 1.2027090260452251\n",
      "epoch: 30 loss: 2.3034937381744385 grad: 1.2026272050496782\n",
      "epoch: 31 loss: 2.302915334701538 grad: 1.2092521732621309\n",
      "epoch: 32 loss: 2.303091526031494 grad: 1.2124424221396948\n",
      "epoch: 33 loss: 2.3028478622436523 grad: 1.209284275239851\n",
      "epoch: 34 loss: 2.3027541637420654 grad: 1.201984379453481\n",
      "epoch: 35 loss: 2.30289363861084 grad: 1.2027739017521815\n",
      "epoch: 36 loss: 2.3028812408447266 grad: 1.2065830027115427\n",
      "epoch: 37 loss: 2.302419900894165 grad: 1.212857482951164\n",
      "epoch: 38 loss: 2.302882194519043 grad: 1.2070140213694511\n",
      "epoch: 39 loss: 2.3032073974609375 grad: 1.2044740566070975\n",
      "epoch: 40 loss: 2.3035736083984375 grad: 1.1972070727940827\n",
      "epoch: 41 loss: 2.303226947784424 grad: 1.2108442425018264\n",
      "epoch: 42 loss: 2.3030295372009277 grad: 1.2008498434461505\n",
      "epoch: 43 loss: 2.3028321266174316 grad: 1.1974497130380883\n",
      "epoch: 44 loss: 2.30285382270813 grad: 1.208832561609424\n",
      "epoch: 45 loss: 2.3027915954589844 grad: 1.2105144666348924\n",
      "epoch: 46 loss: 2.302793264389038 grad: 1.2179578651178864\n",
      "epoch: 47 loss: 2.3025405406951904 grad: 1.2122906914003015\n",
      "epoch: 48 loss: 2.302741289138794 grad: 1.2076392376773237\n",
      "epoch: 49 loss: 2.302661657333374 grad: 1.2051895470358431\n",
      "epoch: 50 loss: 2.3026673793792725 grad: 1.2059588192034483\n",
      "epoch: 51 loss: 2.302783727645874 grad: 1.2047106344400653\n",
      "epoch: 52 loss: 2.302924156188965 grad: 1.2056847222884821\n",
      "epoch: 53 loss: 2.3028652667999268 grad: 1.203167761561446\n",
      "epoch: 54 loss: 2.302964687347412 grad: 1.2076458113548894\n",
      "epoch: 55 loss: 2.3034136295318604 grad: 1.1981247405573312\n",
      "epoch: 56 loss: 2.302922248840332 grad: 1.205967675447316\n",
      "epoch: 57 loss: 2.3029985427856445 grad: 1.2089779233367788\n",
      "epoch: 58 loss: 2.3031835556030273 grad: 1.1921023517821192\n",
      "epoch: 59 loss: 2.302644729614258 grad: 1.2079853729718173\n",
      "epoch: 60 loss: 2.303410053253174 grad: 1.2023021840963453\n",
      "epoch: 61 loss: 2.3032822608947754 grad: 1.2028134570360953\n",
      "epoch: 62 loss: 2.3032968044281006 grad: 1.1957398169297015\n",
      "epoch: 63 loss: 2.302882671356201 grad: 1.210309588610904\n",
      "epoch: 64 loss: 2.3031365871429443 grad: 1.188326847562123\n",
      "epoch: 65 loss: 2.3029470443725586 grad: 1.200444512974678\n",
      "epoch: 66 loss: 2.3028109073638916 grad: 1.2018351964689495\n",
      "epoch: 67 loss: 2.3027384281158447 grad: 1.1954108385021784\n",
      "epoch: 68 loss: 2.302926540374756 grad: 1.2048110371743816\n",
      "epoch: 69 loss: 2.302696704864502 grad: 1.2083359565438023\n",
      "epoch: 70 loss: 2.3025712966918945 grad: 1.209949427943987\n",
      "epoch: 71 loss: 2.302943229675293 grad: 1.2042991599411748\n",
      "epoch: 72 loss: 2.3030357360839844 grad: 1.196292761249453\n",
      "epoch: 73 loss: 2.3029208183288574 grad: 1.1955064249018\n",
      "epoch: 74 loss: 2.30293869972229 grad: 1.207282572737082\n",
      "epoch: 75 loss: 2.30301833152771 grad: 1.1908635000997623\n",
      "epoch: 76 loss: 2.3034629821777344 grad: 1.188140701389842\n",
      "epoch: 77 loss: 2.302694082260132 grad: 1.2042518825739592\n",
      "epoch: 78 loss: 2.3030731678009033 grad: 1.1930068070383093\n",
      "epoch: 79 loss: 2.3031740188598633 grad: 1.200157316146596\n",
      "epoch: 80 loss: 2.3028805255889893 grad: 1.201311644905853\n",
      "epoch: 81 loss: 2.3025434017181396 grad: 1.2012418189126672\n",
      "epoch: 82 loss: 2.30340576171875 grad: 1.1903730771626302\n",
      "epoch: 83 loss: 2.302670478820801 grad: 1.1973193320334845\n",
      "epoch: 84 loss: 2.303110361099243 grad: 1.1993294031994919\n",
      "epoch: 85 loss: 2.3032305240631104 grad: 1.1961513581105494\n",
      "epoch: 86 loss: 2.3030037879943848 grad: 1.200472174890502\n",
      "epoch: 87 loss: 2.3030624389648438 grad: 1.1976233008114385\n",
      "epoch: 88 loss: 2.3028042316436768 grad: 1.202127571792401\n",
      "epoch: 89 loss: 2.302828788757324 grad: 1.1874761942881233\n",
      "epoch: 90 loss: 2.302844524383545 grad: 1.198414681289005\n",
      "epoch: 91 loss: 2.3032138347625732 grad: 1.1944424860652476\n",
      "epoch: 92 loss: 2.302107334136963 grad: 1.208711156355483\n",
      "epoch: 93 loss: 2.3023829460144043 grad: 1.2045688910006975\n",
      "epoch: 94 loss: 2.302722692489624 grad: 1.2079992970684543\n",
      "epoch: 95 loss: 2.302745819091797 grad: 1.200587899300329\n",
      "epoch: 96 loss: 2.303114891052246 grad: 1.2018347381806327\n",
      "epoch: 97 loss: 2.302743911743164 grad: 1.199312295263914\n",
      "epoch: 98 loss: 2.303276538848877 grad: 1.1933929671381882\n",
      "epoch: 99 loss: 2.302842855453491 grad: 1.2025809876180977\n",
      "epoch: 100 loss: 2.303050994873047 grad: 1.1954516174146048\n",
      "epoch: 101 loss: 2.302635908126831 grad: 1.1966211948902272\n",
      "epoch: 102 loss: 2.3028640747070312 grad: 1.1955278475920388\n",
      "epoch: 103 loss: 2.30330753326416 grad: 1.1913267669049905\n",
      "epoch: 104 loss: 2.303262710571289 grad: 1.189160676830123\n",
      "epoch: 105 loss: 2.303006172180176 grad: 1.1942982321202253\n",
      "epoch: 106 loss: 2.302790880203247 grad: 1.2020926148859814\n",
      "epoch: 107 loss: 2.302856683731079 grad: 1.1975675643632366\n",
      "epoch: 108 loss: 2.30318284034729 grad: 1.1878155672900557\n",
      "epoch: 109 loss: 2.3030788898468018 grad: 1.192186639801274\n",
      "epoch: 110 loss: 2.3030471801757812 grad: 1.1883359407037792\n",
      "epoch: 111 loss: 2.302802801132202 grad: 1.192929832277716\n",
      "epoch: 112 loss: 2.302992820739746 grad: 1.1930590026923233\n",
      "epoch: 113 loss: 2.302872896194458 grad: 1.1926457576198681\n",
      "epoch: 114 loss: 2.303288698196411 grad: 1.188000650782626\n",
      "epoch: 115 loss: 2.302666187286377 grad: 1.1943858242371963\n",
      "epoch: 116 loss: 2.3030078411102295 grad: 1.1873195759031834\n",
      "epoch: 117 loss: 2.303067922592163 grad: 1.1959304560533917\n",
      "epoch: 118 loss: 2.3028979301452637 grad: 1.1900181147706\n",
      "epoch: 119 loss: 2.302851676940918 grad: 1.189707528563246\n",
      "epoch: 120 loss: 2.302130699157715 grad: 1.1969851583523292\n",
      "epoch: 121 loss: 2.3028628826141357 grad: 1.1858584949864992\n",
      "epoch: 122 loss: 2.3024871349334717 grad: 1.1923449658493082\n",
      "epoch: 123 loss: 2.302891254425049 grad: 1.1848085860644157\n",
      "epoch: 124 loss: 2.3030807971954346 grad: 1.1907482967501328\n",
      "epoch: 125 loss: 2.303016185760498 grad: 1.1884434725904454\n",
      "epoch: 126 loss: 2.303236484527588 grad: 1.19263349065838\n",
      "epoch: 127 loss: 2.303236246109009 grad: 1.1749331746361262\n",
      "epoch: 128 loss: 2.3025498390197754 grad: 1.1945142483612197\n",
      "epoch: 129 loss: 2.3035645484924316 grad: 1.187369425422586\n",
      "epoch: 130 loss: 2.3032450675964355 grad: 1.1791069101290925\n",
      "epoch: 131 loss: 2.3024826049804688 grad: 1.199919777913093\n",
      "epoch: 132 loss: 2.302420139312744 grad: 1.1952922622421904\n",
      "epoch: 133 loss: 2.3025882244110107 grad: 1.188748612556429\n",
      "epoch: 134 loss: 2.3031747341156006 grad: 1.189046029208435\n",
      "epoch: 135 loss: 2.302419662475586 grad: 1.1935556581731708\n",
      "epoch: 136 loss: 2.302752733230591 grad: 1.1935481910357282\n",
      "epoch: 137 loss: 2.3027825355529785 grad: 1.1881096859773\n",
      "epoch: 138 loss: 2.3031461238861084 grad: 1.1827650140446153\n",
      "epoch: 139 loss: 2.30324649810791 grad: 1.1983906673877278\n",
      "epoch: 140 loss: 2.3030052185058594 grad: 1.181707484318712\n",
      "epoch: 141 loss: 2.302818775177002 grad: 1.1961210790674188\n",
      "epoch: 142 loss: 2.3024189472198486 grad: 1.1953236943827794\n",
      "epoch: 143 loss: 2.3031694889068604 grad: 1.1914101206209688\n",
      "epoch: 144 loss: 2.3028371334075928 grad: 1.1789553050240058\n",
      "epoch: 145 loss: 2.302731990814209 grad: 1.1877879623733905\n",
      "epoch: 146 loss: 2.3025877475738525 grad: 1.1898172916419478\n",
      "epoch: 147 loss: 2.30249285697937 grad: 1.1984104186957998\n",
      "epoch: 148 loss: 2.302928924560547 grad: 1.1889172165806123\n",
      "epoch: 149 loss: 2.3030214309692383 grad: 1.1863969792353197\n",
      "epoch: 150 loss: 2.302739381790161 grad: 1.1890794333635963\n",
      "epoch: 151 loss: 2.302628517150879 grad: 1.1904925845142098\n",
      "epoch: 152 loss: 2.3026413917541504 grad: 1.1885110313287153\n",
      "epoch: 153 loss: 2.3024826049804688 grad: 1.18566547779529\n",
      "epoch: 154 loss: 2.303377628326416 grad: 1.1821626526329458\n",
      "epoch: 155 loss: 2.3028266429901123 grad: 1.1845452453930019\n",
      "epoch: 156 loss: 2.302788496017456 grad: 1.178852112760531\n",
      "epoch: 157 loss: 2.302363872528076 grad: 1.187385305533156\n",
      "epoch: 158 loss: 2.3030283451080322 grad: 1.1862864828195483\n",
      "epoch: 159 loss: 2.303037405014038 grad: 1.1901819913071536\n",
      "epoch: 160 loss: 2.302680730819702 grad: 1.1869214485687691\n",
      "epoch: 161 loss: 2.3026938438415527 grad: 1.1885534805792666\n",
      "epoch: 162 loss: 2.3033788204193115 grad: 1.1813912518961829\n",
      "epoch: 163 loss: 2.302515745162964 grad: 1.185198877520475\n",
      "epoch: 164 loss: 2.3022899627685547 grad: 1.194297334382547\n",
      "epoch: 165 loss: 2.3030240535736084 grad: 1.1829751387408505\n",
      "epoch: 166 loss: 2.302705764770508 grad: 1.189837318257473\n",
      "epoch: 167 loss: 2.303178071975708 grad: 1.1781167992287211\n",
      "epoch: 168 loss: 2.302783727645874 grad: 1.1878398000558337\n",
      "epoch: 169 loss: 2.3031222820281982 grad: 1.179248481530637\n",
      "epoch: 170 loss: 2.3024892807006836 grad: 1.1754862287392218\n",
      "epoch: 171 loss: 2.3021366596221924 grad: 1.1996852218668672\n",
      "epoch: 172 loss: 2.3030903339385986 grad: 1.1735074705858197\n",
      "epoch: 173 loss: 2.3025853633880615 grad: 1.1821173400218998\n",
      "epoch: 174 loss: 2.3026487827301025 grad: 1.1840502012923861\n",
      "epoch: 175 loss: 2.3025100231170654 grad: 1.1854735159662566\n",
      "epoch: 176 loss: 2.302682399749756 grad: 1.1905169526377457\n",
      "epoch: 177 loss: 2.3025400638580322 grad: 1.1831655615519376\n",
      "epoch: 178 loss: 2.302600622177124 grad: 1.1980456413760308\n",
      "epoch: 179 loss: 2.3028225898742676 grad: 1.1773696941700542\n",
      "epoch: 180 loss: 2.3032732009887695 grad: 1.1820998663795994\n",
      "epoch: 181 loss: 2.3021087646484375 grad: 1.182915558164481\n",
      "epoch: 182 loss: 2.3034801483154297 grad: 1.17315255098104\n",
      "epoch: 183 loss: 2.30320143699646 grad: 1.1762877588200988\n",
      "epoch: 184 loss: 2.302579879760742 grad: 1.1915967368025568\n",
      "epoch: 185 loss: 2.3029420375823975 grad: 1.1829379603510635\n",
      "epoch: 186 loss: 2.3029110431671143 grad: 1.1754596501806869\n",
      "epoch: 187 loss: 2.303039312362671 grad: 1.1857527169779623\n",
      "epoch: 188 loss: 2.3027195930480957 grad: 1.1892659324165877\n",
      "epoch: 189 loss: 2.3026933670043945 grad: 1.180500718776048\n",
      "epoch: 190 loss: 2.3028643131256104 grad: 1.185257377908639\n",
      "epoch: 191 loss: 2.302220344543457 grad: 1.1873296384740295\n",
      "epoch: 192 loss: 2.30216121673584 grad: 1.203083100455207\n",
      "epoch: 193 loss: 2.3026609420776367 grad: 1.1810614676491933\n",
      "epoch: 194 loss: 2.302663803100586 grad: 1.18734590787374\n",
      "epoch: 195 loss: 2.302424192428589 grad: 1.1804721982436372\n",
      "epoch: 196 loss: 2.302826404571533 grad: 1.1780907575536284\n",
      "epoch: 197 loss: 2.302699089050293 grad: 1.182701653719599\n",
      "epoch: 198 loss: 2.303110361099243 grad: 1.1788883912007486\n",
      "epoch: 199 loss: 2.303079605102539 grad: 1.1813259365606226\n",
      "epoch: 200 loss: 2.302267074584961 grad: 1.1831624870195925\n",
      "epoch: 201 loss: 2.302297830581665 grad: 1.1853745389759305\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 202 loss: 2.303356885910034 grad: 1.1695133205133652\n",
      "epoch: 203 loss: 2.302633047103882 grad: 1.186921369718639\n",
      "epoch: 204 loss: 2.302428722381592 grad: 1.1956581516239408\n",
      "epoch: 205 loss: 2.3030142784118652 grad: 1.1876602845251678\n",
      "epoch: 206 loss: 2.3026821613311768 grad: 1.1816495375242084\n",
      "epoch: 207 loss: 2.3030331134796143 grad: 1.1796899858865857\n",
      "epoch: 208 loss: 2.3025615215301514 grad: 1.179426110586122\n",
      "epoch: 209 loss: 2.302664279937744 grad: 1.1770949760832572\n",
      "epoch: 210 loss: 2.3028817176818848 grad: 1.1839677566987654\n",
      "epoch: 211 loss: 2.3023715019226074 grad: 1.1836788453501723\n",
      "epoch: 212 loss: 2.302900552749634 grad: 1.1766560918370645\n",
      "epoch: 213 loss: 2.3028955459594727 grad: 1.1729858258447152\n",
      "epoch: 214 loss: 2.3026750087738037 grad: 1.1829826356288755\n",
      "epoch: 215 loss: 2.3032948970794678 grad: 1.1716313051107887\n",
      "epoch: 216 loss: 2.303110361099243 grad: 1.1823194212583263\n",
      "epoch: 217 loss: 2.3032288551330566 grad: 1.16776152393995\n",
      "epoch: 218 loss: 2.3029444217681885 grad: 1.1763224874952039\n",
      "epoch: 219 loss: 2.303060293197632 grad: 1.1738296314549175\n",
      "epoch: 220 loss: 2.3028969764709473 grad: 1.177028085738938\n",
      "epoch: 221 loss: 2.3024675846099854 grad: 1.1761631285439111\n",
      "epoch: 222 loss: 2.3029119968414307 grad: 1.1789612424419453\n",
      "epoch: 223 loss: 2.302985668182373 grad: 1.184030970427326\n",
      "epoch: 224 loss: 2.3026671409606934 grad: 1.182621697396306\n",
      "epoch: 225 loss: 2.302248239517212 grad: 1.183330409201084\n",
      "epoch: 226 loss: 2.30251407623291 grad: 1.1780095228995566\n",
      "epoch: 227 loss: 2.302640199661255 grad: 1.1792176855203238\n",
      "epoch: 228 loss: 2.302868366241455 grad: 1.1706248614659889\n",
      "epoch: 229 loss: 2.302055597305298 grad: 1.1850622536001048\n",
      "epoch: 230 loss: 2.3023340702056885 grad: 1.1814897616452995\n",
      "epoch: 231 loss: 2.3027381896972656 grad: 1.18266926821883\n",
      "epoch: 232 loss: 2.3023436069488525 grad: 1.1824764207667036\n",
      "epoch: 233 loss: 2.302278995513916 grad: 1.185654215701294\n",
      "epoch: 234 loss: 2.302187442779541 grad: 1.1874914898256224\n",
      "epoch: 235 loss: 2.3027877807617188 grad: 1.183889251669854\n",
      "epoch: 236 loss: 2.3026583194732666 grad: 1.1825847003021321\n",
      "epoch: 237 loss: 2.3026468753814697 grad: 1.1784399954421032\n",
      "epoch: 238 loss: 2.30271577835083 grad: 1.1722974501927161\n",
      "epoch: 239 loss: 2.302464246749878 grad: 1.177033864318334\n",
      "epoch: 240 loss: 2.303353786468506 grad: 1.16963734067533\n",
      "epoch: 241 loss: 2.3027548789978027 grad: 1.1747970632369822\n",
      "epoch: 242 loss: 2.3024914264678955 grad: 1.1842254800075251\n",
      "epoch: 243 loss: 2.302835702896118 grad: 1.175625284470337\n",
      "epoch: 244 loss: 2.303015947341919 grad: 1.167225273987574\n",
      "epoch: 245 loss: 2.3027737140655518 grad: 1.1778748427602714\n",
      "epoch: 246 loss: 2.302419900894165 grad: 1.1749694742251275\n",
      "epoch: 247 loss: 2.3020222187042236 grad: 1.1934544063572372\n",
      "epoch: 248 loss: 2.302750825881958 grad: 1.1775676273770395\n",
      "epoch: 249 loss: 2.302410125732422 grad: 1.1761478838965385\n",
      "epoch: 250 loss: 2.3027124404907227 grad: 1.178666979251873\n",
      "epoch: 251 loss: 2.3030319213867188 grad: 1.1738604618484036\n",
      "epoch: 252 loss: 2.3025288581848145 grad: 1.1811177981148904\n",
      "epoch: 253 loss: 2.3022711277008057 grad: 1.1788784843307758\n",
      "epoch: 254 loss: 2.302619457244873 grad: 1.1877660448681415\n",
      "epoch: 255 loss: 2.3024377822875977 grad: 1.1829564675914184\n",
      "epoch: 256 loss: 2.3024885654449463 grad: 1.175712396606936\n",
      "epoch: 257 loss: 2.3024070262908936 grad: 1.1795581734761418\n",
      "epoch: 258 loss: 2.3031508922576904 grad: 1.1780678815400554\n",
      "epoch: 259 loss: 2.3023455142974854 grad: 1.188808144151514\n",
      "epoch: 260 loss: 2.3023080825805664 grad: 1.180883227102828\n",
      "epoch: 261 loss: 2.302217721939087 grad: 1.1889276608163195\n",
      "epoch: 262 loss: 2.303050994873047 grad: 1.1798538821287423\n",
      "epoch: 263 loss: 2.3018641471862793 grad: 1.1802116259932518\n",
      "epoch: 264 loss: 2.3029048442840576 grad: 1.181202678046825\n",
      "epoch: 265 loss: 2.3028924465179443 grad: 1.1830502493983313\n",
      "epoch: 266 loss: 2.302253007888794 grad: 1.1817254054799884\n",
      "epoch: 267 loss: 2.302445411682129 grad: 1.1836132997210833\n",
      "epoch: 268 loss: 2.302896022796631 grad: 1.177707503061919\n",
      "epoch: 269 loss: 2.3026235103607178 grad: 1.1729583231536376\n",
      "epoch: 270 loss: 2.3027799129486084 grad: 1.17826635072503\n",
      "epoch: 271 loss: 2.3021936416625977 grad: 1.178479877426215\n",
      "epoch: 272 loss: 2.3028488159179688 grad: 1.1720359268919787\n",
      "epoch: 273 loss: 2.302459955215454 grad: 1.1879447680687354\n",
      "epoch: 274 loss: 2.3026905059814453 grad: 1.1798196218922616\n",
      "epoch: 275 loss: 2.302561044692993 grad: 1.1763006348462244\n",
      "epoch: 276 loss: 2.302208662033081 grad: 1.1856457945476804\n",
      "epoch: 277 loss: 2.302722930908203 grad: 1.1738104913254372\n",
      "epoch: 278 loss: 2.30251407623291 grad: 1.1859504609823315\n",
      "epoch: 279 loss: 2.302778720855713 grad: 1.1730958302191177\n",
      "epoch: 280 loss: 2.3027937412261963 grad: 1.1751604433862552\n",
      "epoch: 281 loss: 2.303151845932007 grad: 1.174079581010451\n",
      "epoch: 282 loss: 2.3020198345184326 grad: 1.1810410818905526\n",
      "epoch: 283 loss: 2.3029375076293945 grad: 1.1710041297344669\n",
      "epoch: 284 loss: 2.3023269176483154 grad: 1.1810391281420987\n",
      "epoch: 285 loss: 2.302849531173706 grad: 1.1731679309325824\n",
      "epoch: 286 loss: 2.3028175830841064 grad: 1.1720053762980989\n",
      "epoch: 287 loss: 2.302212715148926 grad: 1.186709645686538\n",
      "epoch: 288 loss: 2.302279472351074 grad: 1.1844364313837437\n",
      "epoch: 289 loss: 2.3026018142700195 grad: 1.1777770524227342\n",
      "epoch: 290 loss: 2.3024563789367676 grad: 1.1783697613965838\n",
      "epoch: 291 loss: 2.302798271179199 grad: 1.16994611753173\n",
      "epoch: 292 loss: 2.3024065494537354 grad: 1.177368904689386\n",
      "epoch: 293 loss: 2.3026607036590576 grad: 1.175552806456662\n",
      "epoch: 294 loss: 2.3028523921966553 grad: 1.1775900429957324\n",
      "epoch: 295 loss: 2.3025879859924316 grad: 1.1746994304444849\n",
      "epoch: 296 loss: 2.3028156757354736 grad: 1.1793045649149765\n",
      "epoch: 297 loss: 2.303215265274048 grad: 1.1742059028714835\n",
      "epoch: 298 loss: 2.3025400638580322 grad: 1.1718254958275736\n",
      "epoch: 299 loss: 2.3025646209716797 grad: 1.1729434105393934\n",
      "epoch: 300 loss: 2.302741765975952 grad: 1.1751948968259736\n",
      "epoch: 301 loss: 2.3025026321411133 grad: 1.1811643398814051\n",
      "epoch: 302 loss: 2.3029072284698486 grad: 1.1729568577600673\n",
      "epoch: 303 loss: 2.3024868965148926 grad: 1.1787726605432995\n",
      "epoch: 304 loss: 2.302539587020874 grad: 1.1828326973029308\n",
      "epoch: 305 loss: 2.3030943870544434 grad: 1.1745332529849655\n",
      "epoch: 306 loss: 2.3022541999816895 grad: 1.182582695260718\n",
      "epoch: 307 loss: 2.3025598526000977 grad: 1.177063749393537\n",
      "epoch: 308 loss: 2.302503824234009 grad: 1.1732118625807324\n",
      "epoch: 309 loss: 2.302433729171753 grad: 1.178265332830109\n",
      "epoch: 310 loss: 2.302593946456909 grad: 1.1738601010126462\n",
      "epoch: 311 loss: 2.302393674850464 grad: 1.1825403685012597\n",
      "epoch: 312 loss: 2.3024587631225586 grad: 1.1723834560252726\n",
      "epoch: 313 loss: 2.3027944564819336 grad: 1.1749429992910119\n",
      "epoch: 314 loss: 2.302523136138916 grad: 1.1764326484925631\n",
      "epoch: 315 loss: 2.3023085594177246 grad: 1.1854916334555055\n",
      "epoch: 316 loss: 2.3023812770843506 grad: 1.185058177023801\n",
      "epoch: 317 loss: 2.301985502243042 grad: 1.1849933110938837\n",
      "epoch: 318 loss: 2.3033840656280518 grad: 1.1669335443423026\n",
      "epoch: 319 loss: 2.302544593811035 grad: 1.1786750865239088\n",
      "epoch: 320 loss: 2.302643299102783 grad: 1.177161450270519\n",
      "epoch: 321 loss: 2.302844524383545 grad: 1.1736120825082743\n",
      "epoch: 322 loss: 2.3027708530426025 grad: 1.1803998579677668\n",
      "epoch: 323 loss: 2.3021090030670166 grad: 1.1815878773377912\n",
      "epoch: 324 loss: 2.3027498722076416 grad: 1.1781231010118351\n",
      "epoch: 325 loss: 2.302874803543091 grad: 1.1746599655450574\n",
      "epoch: 326 loss: 2.302700996398926 grad: 1.1836751787978712\n",
      "epoch: 327 loss: 2.3022634983062744 grad: 1.1727744426009141\n",
      "epoch: 328 loss: 2.302537441253662 grad: 1.1724882287228302\n",
      "epoch: 329 loss: 2.3031115531921387 grad: 1.1687744306769992\n",
      "epoch: 330 loss: 2.302629232406616 grad: 1.1730104850878613\n",
      "epoch: 331 loss: 2.3024165630340576 grad: 1.1727728649460163\n",
      "epoch: 332 loss: 2.302853584289551 grad: 1.1674848990681181\n",
      "epoch: 333 loss: 2.3027734756469727 grad: 1.1759229962037698\n",
      "epoch: 334 loss: 2.3028454780578613 grad: 1.180806750309698\n",
      "epoch: 335 loss: 2.302734136581421 grad: 1.1736154958683376\n",
      "epoch: 336 loss: 2.3028576374053955 grad: 1.171059147752304\n",
      "epoch: 337 loss: 2.302757978439331 grad: 1.1725881687025466\n",
      "epoch: 338 loss: 2.3024795055389404 grad: 1.182753939562226\n",
      "epoch: 339 loss: 2.30264949798584 grad: 1.1683549670417541\n",
      "epoch: 340 loss: 2.302335262298584 grad: 1.178400318990166\n",
      "epoch: 341 loss: 2.3024072647094727 grad: 1.176463459222947\n",
      "epoch: 342 loss: 2.30260968208313 grad: 1.1720545680524546\n",
      "epoch: 343 loss: 2.3027119636535645 grad: 1.171023183217686\n",
      "epoch: 344 loss: 2.3024888038635254 grad: 1.1827284408906948\n",
      "epoch: 345 loss: 2.3031005859375 grad: 1.1701108803270415\n",
      "epoch: 346 loss: 2.3022491931915283 grad: 1.1819633442191555\n",
      "epoch: 347 loss: 2.3025636672973633 grad: 1.1825588496645825\n",
      "epoch: 348 loss: 2.302600622177124 grad: 1.1679511274994603\n",
      "epoch: 349 loss: 2.3029611110687256 grad: 1.1640225806853748\n",
      "epoch: 350 loss: 2.3033246994018555 grad: 1.1690367435581894\n",
      "epoch: 351 loss: 2.302847385406494 grad: 1.1692495366580606\n",
      "epoch: 352 loss: 2.3027071952819824 grad: 1.1755061956115127\n",
      "epoch: 353 loss: 2.3026628494262695 grad: 1.1731465685510238\n",
      "epoch: 354 loss: 2.3030755519866943 grad: 1.1698065993158029\n",
      "epoch: 355 loss: 2.3024439811706543 grad: 1.1709082420168828\n",
      "epoch: 356 loss: 2.3020265102386475 grad: 1.1879065080956068\n",
      "epoch: 357 loss: 2.3026983737945557 grad: 1.1719501754952713\n",
      "epoch: 358 loss: 2.3023200035095215 grad: 1.180991635735457\n",
      "epoch: 359 loss: 2.3025596141815186 grad: 1.1782198056360589\n",
      "epoch: 360 loss: 2.302537441253662 grad: 1.1738452790748506\n",
      "epoch: 361 loss: 2.3025994300842285 grad: 1.176262308102441\n",
      "epoch: 362 loss: 2.302597999572754 grad: 1.1694499368332179\n",
      "epoch: 363 loss: 2.3028624057769775 grad: 1.168092820301859\n",
      "epoch: 364 loss: 2.3028483390808105 grad: 1.1741613920977605\n",
      "epoch: 365 loss: 2.302767276763916 grad: 1.1703623692663978\n",
      "epoch: 366 loss: 2.3027310371398926 grad: 1.1591229954982059\n",
      "epoch: 367 loss: 2.302429676055908 grad: 1.1727961709053951\n",
      "epoch: 368 loss: 2.303051710128784 grad: 1.1714222091342514\n",
      "epoch: 369 loss: 2.302577018737793 grad: 1.182327330103218\n",
      "epoch: 370 loss: 2.3026716709136963 grad: 1.1707981475554998\n",
      "epoch: 371 loss: 2.3026251792907715 grad: 1.1708761423009462\n",
      "epoch: 372 loss: 2.302582263946533 grad: 1.170707995047985\n",
      "epoch: 373 loss: 2.3025965690612793 grad: 1.1808969730692398\n",
      "epoch: 374 loss: 2.30198335647583 grad: 1.1839470019146416\n",
      "epoch: 375 loss: 2.302851676940918 grad: 1.1662290576357572\n",
      "epoch: 376 loss: 2.302907943725586 grad: 1.1645059943853302\n",
      "epoch: 377 loss: 2.30243182182312 grad: 1.1717941574604502\n",
      "epoch: 378 loss: 2.302267074584961 grad: 1.1835663223598478\n",
      "epoch: 379 loss: 2.302535057067871 grad: 1.180807584194496\n",
      "epoch: 380 loss: 2.302549123764038 grad: 1.1747515863380469\n",
      "epoch: 381 loss: 2.302825689315796 grad: 1.1687112892811586\n",
      "epoch: 382 loss: 2.302375555038452 grad: 1.1720748937241585\n",
      "epoch: 383 loss: 2.3021841049194336 grad: 1.1783293559167918\n",
      "epoch: 384 loss: 2.30269193649292 grad: 1.1660918683268218\n",
      "epoch: 385 loss: 2.3030171394348145 grad: 1.1602514157836725\n",
      "epoch: 386 loss: 2.3028292655944824 grad: 1.1679982231534456\n",
      "epoch: 387 loss: 2.3028626441955566 grad: 1.1766581683149857\n",
      "epoch: 388 loss: 2.302555799484253 grad: 1.1758580253060376\n",
      "epoch: 389 loss: 2.3022689819335938 grad: 1.1758267672359204\n",
      "epoch: 390 loss: 2.302523612976074 grad: 1.1815276941051707\n",
      "epoch: 391 loss: 2.302722215652466 grad: 1.1730184851764953\n",
      "epoch: 392 loss: 2.3025689125061035 grad: 1.1641873430076337\n",
      "epoch: 393 loss: 2.30255389213562 grad: 1.1712354025064362\n",
      "epoch: 394 loss: 2.302886724472046 grad: 1.1711580399479273\n",
      "epoch: 395 loss: 2.3023288249969482 grad: 1.178307322829607\n",
      "epoch: 396 loss: 2.3025219440460205 grad: 1.1773083079366073\n",
      "epoch: 397 loss: 2.302497625350952 grad: 1.1828172136549024\n",
      "epoch: 398 loss: 2.302457332611084 grad: 1.1748803958004814\n",
      "epoch: 399 loss: 2.3022103309631348 grad: 1.1753165758314676\n",
      "epoch: 400 loss: 2.3023788928985596 grad: 1.1720960531254403\n",
      "epoch: 401 loss: 2.3025362491607666 grad: 1.1729396691689977\n",
      "epoch: 402 loss: 2.302680730819702 grad: 1.1660242713969349\n",
      "epoch: 403 loss: 2.302677631378174 grad: 1.1758402104929297\n",
      "epoch: 404 loss: 2.3026533126831055 grad: 1.161621623593087\n",
      "epoch: 405 loss: 2.30222225189209 grad: 1.1718743681844825\n",
      "epoch: 406 loss: 2.3021397590637207 grad: 1.175669005624802\n",
      "epoch: 407 loss: 2.3026986122131348 grad: 1.1725246977811266\n",
      "epoch: 408 loss: 2.302578926086426 grad: 1.171579402496314\n",
      "epoch: 409 loss: 2.302948236465454 grad: 1.1694602965329226\n",
      "epoch: 410 loss: 2.3024179935455322 grad: 1.180575398358679\n",
      "epoch: 411 loss: 2.3021836280822754 grad: 1.182000022935903\n",
      "epoch: 412 loss: 2.3027851581573486 grad: 1.1647651740165044\n",
      "epoch: 413 loss: 2.3023431301116943 grad: 1.1761715234375545\n",
      "epoch: 414 loss: 2.3027234077453613 grad: 1.1748720231144467\n",
      "epoch: 415 loss: 2.3026599884033203 grad: 1.1711246554651076\n",
      "epoch: 416 loss: 2.302537202835083 grad: 1.1734299506264043\n",
      "epoch: 417 loss: 2.3026857376098633 grad: 1.167938143656116\n",
      "epoch: 418 loss: 2.3026912212371826 grad: 1.1600570026692743\n",
      "epoch: 419 loss: 2.302403450012207 grad: 1.1719599502726592\n",
      "epoch: 420 loss: 2.3027923107147217 grad: 1.166615470068618\n",
      "epoch: 421 loss: 2.3025331497192383 grad: 1.1661424414081025\n",
      "epoch: 422 loss: 2.3023242950439453 grad: 1.1781592354499957\n",
      "epoch: 423 loss: 2.302299737930298 grad: 1.1658480300970877\n",
      "epoch: 424 loss: 2.302218437194824 grad: 1.1723366947973974\n",
      "epoch: 425 loss: 2.3025476932525635 grad: 1.1721040120270725\n",
      "epoch: 426 loss: 2.3027029037475586 grad: 1.1641279438469885\n",
      "epoch: 427 loss: 2.302288293838501 grad: 1.1722840028223656\n",
      "epoch: 428 loss: 2.302471160888672 grad: 1.1759627981994685\n",
      "epoch: 429 loss: 2.3024089336395264 grad: 1.1746357430053491\n",
      "epoch: 430 loss: 2.302921772003174 grad: 1.1614210311367752\n",
      "epoch: 431 loss: 2.302140712738037 grad: 1.1793799511145888\n",
      "epoch: 432 loss: 2.3032712936401367 grad: 1.1675596451017236\n",
      "epoch: 433 loss: 2.3021461963653564 grad: 1.1842218437564693\n",
      "epoch: 434 loss: 2.3025059700012207 grad: 1.1740757109382973\n",
      "epoch: 435 loss: 2.3022520542144775 grad: 1.1682209484316113\n",
      "epoch: 436 loss: 2.302459955215454 grad: 1.1709572889727526\n",
      "epoch: 437 loss: 2.302243232727051 grad: 1.1793096357003032\n",
      "epoch: 438 loss: 2.302722215652466 grad: 1.1677767393042495\n",
      "epoch: 439 loss: 2.302489995956421 grad: 1.171799922349035\n",
      "epoch: 440 loss: 2.302469253540039 grad: 1.1678233258463147\n",
      "epoch: 441 loss: 2.3023743629455566 grad: 1.175022515231773\n",
      "epoch: 442 loss: 2.302325963973999 grad: 1.1699747470510562\n",
      "epoch: 443 loss: 2.302546977996826 grad: 1.1652813327742653\n",
      "epoch: 444 loss: 2.3027689456939697 grad: 1.166094162431176\n",
      "epoch: 445 loss: 2.3026070594787598 grad: 1.1698186426693278\n",
      "epoch: 446 loss: 2.3018105030059814 grad: 1.1805866290889089\n",
      "epoch: 447 loss: 2.30247163772583 grad: 1.1608229138452324\n",
      "epoch: 448 loss: 2.3021702766418457 grad: 1.1754381814565036\n",
      "epoch: 449 loss: 2.3019626140594482 grad: 1.1868744871028447\n",
      "epoch: 450 loss: 2.303101062774658 grad: 1.1642077636631532\n",
      "epoch: 451 loss: 2.302699565887451 grad: 1.1675113357071365\n",
      "epoch: 452 loss: 2.3020806312561035 grad: 1.1674683123608933\n",
      "epoch: 453 loss: 2.3018999099731445 grad: 1.1787758641358879\n",
      "epoch: 454 loss: 2.3025851249694824 grad: 1.176334706297706\n",
      "epoch: 455 loss: 2.302640438079834 grad: 1.1717290114592909\n",
      "epoch: 456 loss: 2.3025994300842285 grad: 1.1792686156326135\n",
      "epoch: 457 loss: 2.3025872707366943 grad: 1.1727145950047535\n",
      "epoch: 458 loss: 2.3025472164154053 grad: 1.1784436156481712\n",
      "epoch: 459 loss: 2.3022079467773438 grad: 1.1771549410094315\n",
      "epoch: 460 loss: 2.3017749786376953 grad: 1.1873375310078411\n",
      "epoch: 461 loss: 2.302065134048462 grad: 1.1761414272847424\n",
      "epoch: 462 loss: 2.302762508392334 grad: 1.1688521556678184\n",
      "epoch: 463 loss: 2.3019514083862305 grad: 1.172062846139029\n",
      "epoch: 464 loss: 2.302250862121582 grad: 1.1761766587003386\n",
      "epoch: 465 loss: 2.3026387691497803 grad: 1.1614779546775573\n",
      "epoch: 466 loss: 2.3027050495147705 grad: 1.1693866046345127\n",
      "epoch: 467 loss: 2.302534341812134 grad: 1.1720428478050355\n",
      "epoch: 468 loss: 2.3029279708862305 grad: 1.1672006729299143\n",
      "epoch: 469 loss: 2.3022983074188232 grad: 1.1726861978448662\n",
      "epoch: 470 loss: 2.302391767501831 grad: 1.1709317406768807\n",
      "epoch: 471 loss: 2.302550792694092 grad: 1.1803447104461993\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 472 loss: 2.3025052547454834 grad: 1.170194812281619\n",
      "epoch: 473 loss: 2.3020100593566895 grad: 1.1771639588026566\n",
      "epoch: 474 loss: 2.3029441833496094 grad: 1.1713558752588662\n",
      "epoch: 475 loss: 2.302798271179199 grad: 1.162120446790054\n",
      "epoch: 476 loss: 2.3024637699127197 grad: 1.1702701281645291\n",
      "epoch: 477 loss: 2.3018898963928223 grad: 1.1700360494802544\n",
      "epoch: 478 loss: 2.3023486137390137 grad: 1.1764505458219598\n",
      "epoch: 479 loss: 2.302090883255005 grad: 1.1775127004865291\n",
      "epoch: 480 loss: 2.3024585247039795 grad: 1.1717159296644644\n",
      "epoch: 481 loss: 2.302263021469116 grad: 1.1805527304033083\n",
      "epoch: 482 loss: 2.302562952041626 grad: 1.168362168994333\n",
      "epoch: 483 loss: 2.302403450012207 grad: 1.172851184070746\n",
      "epoch: 484 loss: 2.302338123321533 grad: 1.1724742797244014\n",
      "epoch: 485 loss: 2.3022444248199463 grad: 1.1767529996281991\n",
      "epoch: 486 loss: 2.3025851249694824 grad: 1.1788577456082705\n",
      "epoch: 487 loss: 2.302467107772827 grad: 1.1726892765884893\n",
      "epoch: 488 loss: 2.3027143478393555 grad: 1.1718112611976852\n",
      "epoch: 489 loss: 2.302811861038208 grad: 1.177020255173187\n",
      "epoch: 490 loss: 2.3022968769073486 grad: 1.1790909014645934\n",
      "epoch: 491 loss: 2.3027942180633545 grad: 1.1697793136007109\n",
      "epoch: 492 loss: 2.3024613857269287 grad: 1.1703726473848322\n",
      "epoch: 493 loss: 2.302455425262451 grad: 1.1765867026175358\n",
      "epoch: 494 loss: 2.3019416332244873 grad: 1.1786543235408202\n",
      "epoch: 495 loss: 2.302478790283203 grad: 1.1751929544067632\n",
      "epoch: 496 loss: 2.302635908126831 grad: 1.164179389921224\n",
      "epoch: 497 loss: 2.3022775650024414 grad: 1.166716947068741\n",
      "epoch: 498 loss: 2.3026938438415527 grad: 1.169094991123688\n",
      "epoch: 499 loss: 2.301778793334961 grad: 1.1780640086499117\n",
      "2.3017251640558243\n",
      "epoch: 0 loss: 2.3034634590148926 grad: 1.2155378778993582\n",
      "epoch: 1 loss: 2.3025553226470947 grad: 1.2052247209921627\n",
      "epoch: 2 loss: 2.302126407623291 grad: 1.1929900923629277\n",
      "epoch: 3 loss: 2.301884412765503 grad: 1.1876253859557595\n",
      "epoch: 4 loss: 2.2990026473999023 grad: 1.307007027446248\n",
      "epoch: 5 loss: 2.2784976959228516 grad: 1.8024021091885747\n",
      "epoch: 6 loss: 2.249645233154297 grad: 1.4603922344348763\n",
      "epoch: 7 loss: 2.2412357330322266 grad: 1.2970921380097964\n",
      "epoch: 8 loss: 2.2404654026031494 grad: 1.2719817745401376\n",
      "epoch: 9 loss: 2.2349586486816406 grad: 1.1905449654293498\n",
      "epoch: 10 loss: 2.2334744930267334 grad: 1.1224265403783185\n",
      "epoch: 11 loss: 2.231114387512207 grad: 1.1093398286602534\n",
      "epoch: 12 loss: 2.2306315898895264 grad: 1.1875695268344504\n",
      "epoch: 13 loss: 2.2282745838165283 grad: 1.173589223080189\n",
      "epoch: 14 loss: 2.2274672985076904 grad: 1.0551618399737877\n",
      "epoch: 15 loss: 2.2257192134857178 grad: 1.2291555132251233\n",
      "epoch: 16 loss: 2.2256860733032227 grad: 1.2235962212240945\n",
      "epoch: 17 loss: 2.2253074645996094 grad: 1.2270160551443474\n",
      "epoch: 18 loss: 2.2235331535339355 grad: 1.212640459496816\n",
      "epoch: 19 loss: 2.2225019931793213 grad: 1.2608491110741087\n",
      "epoch: 20 loss: 2.2220237255096436 grad: 1.1573311283543248\n",
      "epoch: 21 loss: 2.2196567058563232 grad: 1.0856017207889448\n",
      "epoch: 22 loss: 2.2209184169769287 grad: 1.1847372282553272\n",
      "epoch: 23 loss: 2.2193961143493652 grad: 1.1577275158331124\n",
      "epoch: 24 loss: 2.220151901245117 grad: 1.2136141913056018\n",
      "epoch: 25 loss: 2.2182533740997314 grad: 1.2770901272454047\n",
      "epoch: 26 loss: 2.218571424484253 grad: 1.2827184880946925\n",
      "epoch: 27 loss: 2.2195494174957275 grad: 1.1985246280082575\n",
      "epoch: 28 loss: 2.217419385910034 grad: 1.3528425835751159\n",
      "epoch: 29 loss: 2.216850757598877 grad: 1.2013988118112413\n",
      "epoch: 30 loss: 2.216825008392334 grad: 1.2519680817855434\n",
      "epoch: 31 loss: 2.2185957431793213 grad: 1.3776047556247148\n",
      "epoch: 32 loss: 2.2176713943481445 grad: 1.2518394673123054\n",
      "epoch: 33 loss: 2.2167739868164062 grad: 1.288621202797725\n",
      "epoch: 34 loss: 2.216636896133423 grad: 1.3879424060772483\n",
      "epoch: 35 loss: 2.2159759998321533 grad: 1.2989862890607338\n",
      "epoch: 36 loss: 2.215881824493408 grad: 1.2139620791015673\n",
      "epoch: 37 loss: 2.2151119709014893 grad: 1.42638437775895\n",
      "epoch: 38 loss: 2.214411497116089 grad: 1.4688321246787728\n",
      "epoch: 39 loss: 2.2145683765411377 grad: 1.4839887661149813\n",
      "epoch: 40 loss: 2.2128262519836426 grad: 1.4675488743657572\n",
      "epoch: 41 loss: 2.212474822998047 grad: 1.4959233249417536\n",
      "epoch: 42 loss: 2.2124481201171875 grad: 1.6085621345703238\n",
      "epoch: 43 loss: 2.2106878757476807 grad: 1.7332484344286578\n",
      "epoch: 44 loss: 2.211935043334961 grad: 1.7394407943338304\n",
      "epoch: 45 loss: 2.208866834640503 grad: 1.7987103056447167\n",
      "epoch: 46 loss: 2.209808111190796 grad: 1.8777269908792473\n",
      "epoch: 47 loss: 2.2080674171447754 grad: 1.8942846981235706\n",
      "epoch: 48 loss: 2.20624041557312 grad: 2.1256949977675776\n",
      "epoch: 49 loss: 2.2052290439605713 grad: 2.2497268906103387\n",
      "epoch: 50 loss: 2.203885078430176 grad: 2.2154529634105513\n",
      "epoch: 51 loss: 2.2041988372802734 grad: 2.2247488372589626\n",
      "epoch: 52 loss: 2.2012383937835693 grad: 2.367252278912236\n",
      "epoch: 53 loss: 2.201691150665283 grad: 2.4514973787775647\n",
      "epoch: 54 loss: 2.198913812637329 grad: 2.6329279896980595\n",
      "epoch: 55 loss: 2.199500560760498 grad: 2.617043552508149\n",
      "epoch: 56 loss: 2.1968040466308594 grad: 2.770010831762135\n",
      "epoch: 57 loss: 2.195909023284912 grad: 2.80827447960508\n",
      "epoch: 58 loss: 2.1971523761749268 grad: 2.7636954400518405\n",
      "epoch: 59 loss: 2.1929802894592285 grad: 2.8862188215855333\n",
      "epoch: 60 loss: 2.195378303527832 grad: 2.961204425394831\n",
      "epoch: 61 loss: 2.1919708251953125 grad: 2.8849152047630575\n",
      "epoch: 62 loss: 2.193448781967163 grad: 3.115407352372708\n",
      "epoch: 63 loss: 2.193315267562866 grad: 3.02700863528021\n",
      "epoch: 64 loss: 2.1876332759857178 grad: 3.1086503924683684\n",
      "epoch: 65 loss: 2.1869683265686035 grad: 3.248077457748531\n",
      "epoch: 66 loss: 2.187060594558716 grad: 3.1604820561063076\n",
      "epoch: 67 loss: 2.18556547164917 grad: 3.224826503770485\n",
      "epoch: 68 loss: 2.185560464859009 grad: 3.1447732568836755\n",
      "epoch: 69 loss: 2.185514450073242 grad: 3.186360032693113\n",
      "epoch: 70 loss: 2.182036876678467 grad: 3.3558018564852694\n",
      "epoch: 71 loss: 2.1851837635040283 grad: 3.330974583750561\n",
      "epoch: 72 loss: 2.180830240249634 grad: 3.351466397337231\n",
      "epoch: 73 loss: 2.1813395023345947 grad: 3.518588746709394\n",
      "epoch: 74 loss: 2.1793336868286133 grad: 3.325271381205687\n",
      "epoch: 75 loss: 2.175377607345581 grad: 3.444259370137597\n",
      "epoch: 76 loss: 2.176123857498169 grad: 3.7596087887410135\n",
      "epoch: 77 loss: 2.1798574924468994 grad: 3.6320407951975033\n",
      "epoch: 78 loss: 2.1753692626953125 grad: 3.458466802908492\n",
      "epoch: 79 loss: 2.1761884689331055 grad: 3.6510141021572053\n",
      "epoch: 80 loss: 2.1778130531311035 grad: 3.61449250368224\n",
      "epoch: 81 loss: 2.1744394302368164 grad: 3.696941684613684\n",
      "epoch: 82 loss: 2.174560785293579 grad: 3.7537256644425234\n",
      "epoch: 83 loss: 2.174323558807373 grad: 3.667385975427423\n",
      "epoch: 84 loss: 2.1736137866973877 grad: 3.864555291502574\n",
      "epoch: 85 loss: 2.169149398803711 grad: 3.8005982067524675\n",
      "epoch: 86 loss: 2.1663331985473633 grad: 3.791932456402315\n",
      "epoch: 87 loss: 2.16827130317688 grad: 3.828557377023297\n",
      "epoch: 88 loss: 2.1681604385375977 grad: 3.8365629610405967\n",
      "epoch: 89 loss: 2.1660878658294678 grad: 3.6452581658072414\n",
      "epoch: 90 loss: 2.163405656814575 grad: 3.8098520904794215\n",
      "epoch: 91 loss: 2.165264844894409 grad: 3.849618377866194\n",
      "epoch: 92 loss: 2.1622138023376465 grad: 3.885980462740427\n",
      "epoch: 93 loss: 2.1610028743743896 grad: 3.684506330598471\n",
      "epoch: 94 loss: 2.1566004753112793 grad: 3.7927042338849297\n",
      "epoch: 95 loss: 2.158785343170166 grad: 3.6936021197979\n",
      "epoch: 96 loss: 2.15661883354187 grad: 4.031517749201388\n",
      "epoch: 97 loss: 2.157273769378662 grad: 3.971108496192813\n",
      "epoch: 98 loss: 2.1577975749969482 grad: 3.87912714936667\n",
      "epoch: 99 loss: 2.156402826309204 grad: 3.932630030508523\n",
      "epoch: 100 loss: 2.1534180641174316 grad: 3.8443802736056525\n",
      "epoch: 101 loss: 2.153489112854004 grad: 4.276592287042784\n",
      "epoch: 102 loss: 2.1537232398986816 grad: 3.9687224009761675\n",
      "epoch: 103 loss: 2.1483047008514404 grad: 3.9179488719951006\n",
      "epoch: 104 loss: 2.1533966064453125 grad: 4.070605101263417\n",
      "epoch: 105 loss: 2.1521084308624268 grad: 3.989896317618707\n",
      "epoch: 106 loss: 2.1486518383026123 grad: 3.995819008838947\n",
      "epoch: 107 loss: 2.1464755535125732 grad: 4.16897482141882\n",
      "epoch: 108 loss: 2.1456706523895264 grad: 3.9845293447308774\n",
      "epoch: 109 loss: 2.145632743835449 grad: 4.134123305904693\n",
      "epoch: 110 loss: 2.144404172897339 grad: 4.08689173527195\n",
      "epoch: 111 loss: 2.145800828933716 grad: 4.3985547892128425\n",
      "epoch: 112 loss: 2.139660596847534 grad: 4.109176622685193\n",
      "epoch: 113 loss: 2.1429858207702637 grad: 4.255971319034755\n",
      "epoch: 114 loss: 2.141663074493408 grad: 4.438285406752829\n",
      "epoch: 115 loss: 2.138983964920044 grad: 4.087991939672816\n",
      "epoch: 116 loss: 2.137753963470459 grad: 4.187825638579116\n",
      "epoch: 117 loss: 2.1360042095184326 grad: 4.186196923743756\n",
      "epoch: 118 loss: 2.1366395950317383 grad: 4.269539887185341\n",
      "epoch: 119 loss: 2.138965606689453 grad: 4.432793227002202\n",
      "epoch: 120 loss: 2.1366324424743652 grad: 4.560130360831935\n",
      "epoch: 121 loss: 2.12873911857605 grad: 4.373721171273953\n",
      "epoch: 122 loss: 2.1323800086975098 grad: 4.657322825302208\n",
      "epoch: 123 loss: 2.1281561851501465 grad: 4.624526887241426\n",
      "epoch: 124 loss: 2.1281700134277344 grad: 4.730900724011931\n",
      "epoch: 125 loss: 2.126878261566162 grad: 4.543986871616826\n",
      "epoch: 126 loss: 2.124746799468994 grad: 4.691325749558884\n",
      "epoch: 127 loss: 2.121152877807617 grad: 4.634425519736454\n",
      "epoch: 128 loss: 2.123704671859741 grad: 4.6983682949997725\n",
      "epoch: 129 loss: 2.12245774269104 grad: 4.86251641359062\n",
      "epoch: 130 loss: 2.1219120025634766 grad: 5.0875855443540905\n",
      "epoch: 131 loss: 2.1144773960113525 grad: 4.656429962920291\n",
      "epoch: 132 loss: 2.1172003746032715 grad: 4.875727587571693\n",
      "epoch: 133 loss: 2.119966506958008 grad: 4.9754278663516285\n",
      "epoch: 134 loss: 2.1110050678253174 grad: 5.098851813587346\n",
      "epoch: 135 loss: 2.1124773025512695 grad: 5.234194450427792\n",
      "epoch: 136 loss: 2.108692169189453 grad: 4.899832395925408\n",
      "epoch: 137 loss: 2.1094322204589844 grad: 5.028926636846292\n",
      "epoch: 138 loss: 2.106989622116089 grad: 5.338755795355176\n",
      "epoch: 139 loss: 2.106351852416992 grad: 4.994020604720665\n",
      "epoch: 140 loss: 2.1069254875183105 grad: 5.313467935422465\n",
      "epoch: 141 loss: 2.103825807571411 grad: 5.332531883543919\n",
      "epoch: 142 loss: 2.1034324169158936 grad: 5.4883657866748905\n",
      "epoch: 143 loss: 2.1108791828155518 grad: 5.719561026719886\n",
      "epoch: 144 loss: 2.0980160236358643 grad: 5.5184800514714825\n",
      "epoch: 145 loss: 2.0959315299987793 grad: 5.548978848656314\n",
      "epoch: 146 loss: 2.095649003982544 grad: 5.3971596525331575\n",
      "epoch: 147 loss: 2.093174457550049 grad: 5.880035321102551\n",
      "epoch: 148 loss: 2.092477798461914 grad: 5.503322613225984\n",
      "epoch: 149 loss: 2.0911738872528076 grad: 6.070270162275327\n",
      "epoch: 150 loss: 2.091970682144165 grad: 5.967284043526484\n",
      "epoch: 151 loss: 2.0948071479797363 grad: 5.806122918140202\n",
      "epoch: 152 loss: 2.09085750579834 grad: 5.7420819795483515\n",
      "epoch: 153 loss: 2.0841331481933594 grad: 5.776102692842306\n",
      "epoch: 154 loss: 2.084383010864258 grad: 5.8526237666281675\n",
      "epoch: 155 loss: 2.0857462882995605 grad: 6.120124094653875\n",
      "epoch: 156 loss: 2.079669713973999 grad: 5.596483204587702\n",
      "epoch: 157 loss: 2.0862088203430176 grad: 6.120649637129631\n",
      "epoch: 158 loss: 2.0808002948760986 grad: 6.087920324108194\n",
      "epoch: 159 loss: 2.0771729946136475 grad: 6.212380504316931\n",
      "epoch: 160 loss: 2.0797512531280518 grad: 6.217959577424659\n",
      "epoch: 161 loss: 2.080329656600952 grad: 6.293587003967592\n",
      "epoch: 162 loss: 2.076169013977051 grad: 6.45692963918878\n",
      "epoch: 163 loss: 2.070594549179077 grad: 6.482850207178484\n",
      "epoch: 164 loss: 2.0734944343566895 grad: 6.536337963290631\n",
      "epoch: 165 loss: 2.071359395980835 grad: 6.684786873130453\n",
      "epoch: 166 loss: 2.0706281661987305 grad: 6.607206516795689\n",
      "epoch: 167 loss: 2.071918249130249 grad: 6.700410662987639\n",
      "epoch: 168 loss: 2.071741819381714 grad: 6.473531903632518\n",
      "epoch: 169 loss: 2.061481475830078 grad: 6.787763590976182\n",
      "epoch: 170 loss: 2.0643210411071777 grad: 6.627503729861466\n",
      "epoch: 171 loss: 2.063173770904541 grad: 6.867576916753832\n",
      "epoch: 172 loss: 2.0664544105529785 grad: 6.819675207980687\n",
      "epoch: 173 loss: 2.056516408920288 grad: 6.948500197720787\n",
      "epoch: 174 loss: 2.0652575492858887 grad: 6.923507634860774\n",
      "epoch: 175 loss: 2.071375608444214 grad: 7.043838037362707\n",
      "epoch: 176 loss: 2.0623247623443604 grad: 7.049569647419193\n",
      "epoch: 177 loss: 2.049020290374756 grad: 7.112970691869065\n",
      "epoch: 178 loss: 2.0503294467926025 grad: 7.418030502769859\n",
      "epoch: 179 loss: 2.055891275405884 grad: 6.932722001026074\n",
      "epoch: 180 loss: 2.0434443950653076 grad: 7.066958943367123\n",
      "epoch: 181 loss: 2.047781467437744 grad: 7.549278879020777\n",
      "epoch: 182 loss: 2.0570602416992188 grad: 7.533777004344359\n",
      "epoch: 183 loss: 2.0468714237213135 grad: 7.212521741395846\n",
      "epoch: 184 loss: 2.051966667175293 grad: 7.463175696483444\n",
      "epoch: 185 loss: 2.0368497371673584 grad: 7.742385524265941\n",
      "epoch: 186 loss: 2.0466229915618896 grad: 7.81196717810004\n",
      "epoch: 187 loss: 2.044130563735962 grad: 7.593492943660489\n",
      "epoch: 188 loss: 2.0407986640930176 grad: 7.700130514312713\n",
      "epoch: 189 loss: 2.0413870811462402 grad: 8.04280009453318\n",
      "epoch: 190 loss: 2.041562795639038 grad: 7.8142508729361\n",
      "epoch: 191 loss: 2.039794683456421 grad: 7.783965065750102\n",
      "epoch: 192 loss: 2.0394680500030518 grad: 7.9029661750361795\n",
      "epoch: 193 loss: 2.0248167514801025 grad: 7.786239037541525\n",
      "epoch: 194 loss: 2.0320675373077393 grad: 8.252276630362584\n",
      "epoch: 195 loss: 2.038304090499878 grad: 8.107183817907103\n",
      "epoch: 196 loss: 2.0292112827301025 grad: 8.13289048145747\n",
      "epoch: 197 loss: 2.028099536895752 grad: 8.471651033040077\n",
      "epoch: 198 loss: 2.0242059230804443 grad: 7.928084467227261\n",
      "epoch: 199 loss: 2.0254766941070557 grad: 8.759508650927316\n",
      "epoch: 200 loss: 2.0283401012420654 grad: 8.846563202742901\n",
      "epoch: 201 loss: 2.0263888835906982 grad: 8.241567633986946\n",
      "epoch: 202 loss: 2.018744945526123 grad: 8.158031772733445\n",
      "epoch: 203 loss: 2.021530866622925 grad: 8.651936711255638\n",
      "epoch: 204 loss: 2.02001953125 grad: 8.946998536571979\n",
      "epoch: 205 loss: 2.023731231689453 grad: 8.377990534573438\n",
      "epoch: 206 loss: 2.0210070610046387 grad: 9.023340132294429\n",
      "epoch: 207 loss: 2.0173075199127197 grad: 8.640225233924058\n",
      "epoch: 208 loss: 2.0235471725463867 grad: 8.555851804787322\n",
      "epoch: 209 loss: 2.0130603313446045 grad: 8.807610642556693\n",
      "epoch: 210 loss: 2.0095505714416504 grad: 8.752589975217623\n",
      "epoch: 211 loss: 2.0101051330566406 grad: 9.111541584326279\n",
      "epoch: 212 loss: 2.0111868381500244 grad: 8.61917216454204\n",
      "epoch: 213 loss: 2.0041399002075195 grad: 8.995928239801692\n",
      "epoch: 214 loss: 2.0090389251708984 grad: 8.64447850083548\n",
      "epoch: 215 loss: 2.008653402328491 grad: 9.186895968200314\n",
      "epoch: 216 loss: 2.012256383895874 grad: 8.858710777214062\n",
      "epoch: 217 loss: 2.0093119144439697 grad: 9.001799055966474\n",
      "epoch: 218 loss: 2.0058305263519287 grad: 8.616152755443066\n",
      "epoch: 219 loss: 2.003903865814209 grad: 9.017014172519483\n",
      "epoch: 220 loss: 1.9997888803482056 grad: 8.919936367487978\n",
      "epoch: 221 loss: 2.009824514389038 grad: 9.202190794627226\n",
      "epoch: 222 loss: 2.007497549057007 grad: 8.950253450407809\n",
      "epoch: 223 loss: 1.9983869791030884 grad: 9.032379996534141\n",
      "epoch: 224 loss: 2.006753444671631 grad: 8.958686350696972\n",
      "epoch: 225 loss: 2.002690315246582 grad: 9.125847381938781\n",
      "epoch: 226 loss: 2.002793788909912 grad: 8.972853592729994\n",
      "epoch: 227 loss: 1.997883677482605 grad: 9.211935900063033\n",
      "epoch: 228 loss: 2.003920316696167 grad: 9.071128704762529\n",
      "epoch: 229 loss: 2.0062952041625977 grad: 9.799573650539276\n",
      "epoch: 230 loss: 1.9961267709732056 grad: 9.242277704925824\n",
      "epoch: 231 loss: 1.9914320707321167 grad: 9.017644235080787\n",
      "epoch: 232 loss: 2.001682996749878 grad: 9.108823620418589\n",
      "epoch: 233 loss: 1.986102819442749 grad: 9.232236902916892\n",
      "epoch: 234 loss: 1.9942808151245117 grad: 8.783334880830749\n",
      "epoch: 235 loss: 1.9905074834823608 grad: 9.040154287428965\n",
      "epoch: 236 loss: 1.9860150814056396 grad: 9.287469610971\n",
      "epoch: 237 loss: 1.9926780462265015 grad: 8.967088142720362\n",
      "epoch: 238 loss: 1.996409296989441 grad: 9.734411703467014\n",
      "epoch: 239 loss: 1.9899089336395264 grad: 9.164811338371937\n",
      "epoch: 240 loss: 1.9875344038009644 grad: 8.61584308560169\n",
      "epoch: 241 loss: 1.9844257831573486 grad: 8.984410048891155\n",
      "epoch: 242 loss: 1.986379861831665 grad: 9.515845637044144\n",
      "epoch: 243 loss: 1.9862366914749146 grad: 9.212776169979147\n",
      "epoch: 244 loss: 1.98377525806427 grad: 9.379887831057347\n",
      "epoch: 245 loss: 1.9866464138031006 grad: 9.670659119943304\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 246 loss: 1.9854466915130615 grad: 9.292293413290901\n",
      "epoch: 247 loss: 1.9826579093933105 grad: 9.290603997777142\n",
      "epoch: 248 loss: 1.981444001197815 grad: 9.792020789022365\n",
      "epoch: 249 loss: 1.9797695875167847 grad: 9.559708174879825\n",
      "epoch: 250 loss: 1.985790491104126 grad: 9.018974320238662\n",
      "epoch: 251 loss: 1.981129765510559 grad: 8.815740909227836\n",
      "epoch: 252 loss: 1.977516531944275 grad: 9.055563619463808\n",
      "epoch: 253 loss: 1.9808274507522583 grad: 9.67751423257684\n",
      "epoch: 254 loss: 1.9770145416259766 grad: 9.287141408364747\n",
      "epoch: 255 loss: 1.9709787368774414 grad: 8.877143770574577\n",
      "epoch: 256 loss: 1.9726486206054688 grad: 9.427816727627365\n",
      "epoch: 257 loss: 1.9782519340515137 grad: 9.431088819434601\n",
      "epoch: 258 loss: 1.9750397205352783 grad: 8.849605653612386\n",
      "epoch: 259 loss: 1.9791381359100342 grad: 9.71796780343478\n",
      "epoch: 260 loss: 1.9717482328414917 grad: 9.625509345667465\n",
      "epoch: 261 loss: 1.9733864068984985 grad: 9.259583842393662\n",
      "epoch: 262 loss: 1.97344172000885 grad: 9.638723206174161\n",
      "epoch: 263 loss: 1.9679105281829834 grad: 9.570976335747492\n",
      "epoch: 264 loss: 1.9694899320602417 grad: 9.85367185047399\n",
      "epoch: 265 loss: 1.9706701040267944 grad: 9.472272885061564\n",
      "epoch: 266 loss: 1.9676674604415894 grad: 9.546058619927082\n",
      "epoch: 267 loss: 1.9707428216934204 grad: 9.184148363473396\n",
      "epoch: 268 loss: 1.974023461341858 grad: 9.655174514263987\n",
      "epoch: 269 loss: 1.963489294052124 grad: 9.772792333530056\n",
      "epoch: 270 loss: 1.9652503728866577 grad: 9.679974821425738\n",
      "epoch: 271 loss: 1.965481162071228 grad: 9.613420635787032\n",
      "epoch: 272 loss: 1.9730780124664307 grad: 9.853817495916571\n",
      "epoch: 273 loss: 1.9545564651489258 grad: 9.612390326217763\n",
      "epoch: 274 loss: 1.9607030153274536 grad: 9.546311362321296\n",
      "epoch: 275 loss: 1.969305396080017 grad: 10.028380670865614\n",
      "epoch: 276 loss: 1.9682691097259521 grad: 9.498557128943503\n",
      "epoch: 277 loss: 1.962050437927246 grad: 9.704211997548265\n",
      "epoch: 278 loss: 1.9639769792556763 grad: 9.202818818161235\n",
      "epoch: 279 loss: 1.9663747549057007 grad: 9.539007451754832\n",
      "epoch: 280 loss: 1.9539378881454468 grad: 9.596913006526256\n",
      "epoch: 281 loss: 1.9545096158981323 grad: 9.78295053442615\n",
      "epoch: 282 loss: 1.9509459733963013 grad: 9.604528536487903\n",
      "epoch: 283 loss: 1.9591237306594849 grad: 9.762355571110097\n",
      "epoch: 284 loss: 1.9636402130126953 grad: 9.873395014960792\n",
      "epoch: 285 loss: 1.9417636394500732 grad: 9.529856492543505\n",
      "epoch: 286 loss: 1.9570342302322388 grad: 9.840017411798712\n",
      "epoch: 287 loss: 1.9524171352386475 grad: 9.308790883714599\n",
      "epoch: 288 loss: 1.9380152225494385 grad: 9.248766317120975\n",
      "epoch: 289 loss: 1.9521006345748901 grad: 9.572009568479622\n",
      "epoch: 290 loss: 1.952003002166748 grad: 10.306564073048769\n",
      "epoch: 291 loss: 1.944913387298584 grad: 8.840968258797176\n",
      "epoch: 292 loss: 1.9494080543518066 grad: 9.94466253269523\n",
      "epoch: 293 loss: 1.9521702527999878 grad: 10.072709272231256\n",
      "epoch: 294 loss: 1.9517611265182495 grad: 9.365690522154587\n",
      "epoch: 295 loss: 1.9435749053955078 grad: 10.40561540792918\n",
      "epoch: 296 loss: 1.9461770057678223 grad: 9.330669345201127\n",
      "epoch: 297 loss: 1.9564749002456665 grad: 9.653723151984787\n",
      "epoch: 298 loss: 1.9456799030303955 grad: 9.943808236366344\n",
      "epoch: 299 loss: 1.9438574314117432 grad: 9.595306203929736\n",
      "epoch: 300 loss: 1.9481892585754395 grad: 10.027189459089959\n",
      "epoch: 301 loss: 1.9409667253494263 grad: 9.85851830323892\n",
      "epoch: 302 loss: 1.9478179216384888 grad: 9.516471044374777\n",
      "epoch: 303 loss: 1.94706130027771 grad: 10.139198970995725\n",
      "epoch: 304 loss: 1.9431818723678589 grad: 9.62578670241471\n",
      "epoch: 305 loss: 1.9467841386795044 grad: 10.066087333248957\n",
      "epoch: 306 loss: 1.9433696269989014 grad: 9.638876961470242\n",
      "epoch: 307 loss: 1.9543873071670532 grad: 9.7220007994227\n",
      "epoch: 308 loss: 1.9408591985702515 grad: 10.451273951856862\n",
      "epoch: 309 loss: 1.9446918964385986 grad: 9.906641878527664\n",
      "epoch: 310 loss: 1.9397027492523193 grad: 9.97338403548513\n",
      "epoch: 311 loss: 1.943892240524292 grad: 9.405669075629067\n",
      "epoch: 312 loss: 1.9393268823623657 grad: 9.941584151031243\n",
      "epoch: 313 loss: 1.9389417171478271 grad: 10.785858175865123\n",
      "epoch: 314 loss: 1.9374196529388428 grad: 9.437228976039304\n",
      "epoch: 315 loss: 1.9359701871871948 grad: 10.087845398187046\n",
      "epoch: 316 loss: 1.9340786933898926 grad: 10.18507829574602\n",
      "epoch: 317 loss: 1.9381649494171143 grad: 9.999752527428052\n",
      "epoch: 318 loss: 1.9338772296905518 grad: 9.277450290479003\n",
      "epoch: 319 loss: 1.92987060546875 grad: 10.04550333170309\n",
      "epoch: 320 loss: 1.9270532131195068 grad: 10.085860108845823\n",
      "epoch: 321 loss: 1.9311776161193848 grad: 9.786545741918777\n",
      "epoch: 322 loss: 1.9359866380691528 grad: 10.065890427065334\n",
      "epoch: 323 loss: 1.9315294027328491 grad: 9.819722441912052\n",
      "epoch: 324 loss: 1.9286173582077026 grad: 9.704616144240376\n",
      "epoch: 325 loss: 1.9330154657363892 grad: 9.567054692744499\n",
      "epoch: 326 loss: 1.9319936037063599 grad: 10.146507026243304\n",
      "epoch: 327 loss: 1.9240875244140625 grad: 9.716465448857182\n",
      "epoch: 328 loss: 1.9308722019195557 grad: 10.214743946708502\n",
      "epoch: 329 loss: 1.9339303970336914 grad: 9.933996864505822\n",
      "epoch: 330 loss: 1.9252909421920776 grad: 9.91917594911028\n",
      "epoch: 331 loss: 1.9297319650650024 grad: 10.47666678707751\n",
      "epoch: 332 loss: 1.9279253482818604 grad: 10.2692231107651\n",
      "epoch: 333 loss: 1.9209831953048706 grad: 10.318315703067041\n",
      "epoch: 334 loss: 1.9198026657104492 grad: 10.40166915058794\n",
      "epoch: 335 loss: 1.9326395988464355 grad: 9.950812713790034\n",
      "epoch: 336 loss: 1.9261959791183472 grad: 10.075649265429034\n",
      "epoch: 337 loss: 1.9254710674285889 grad: 9.972765125925578\n",
      "epoch: 338 loss: 1.9248300790786743 grad: 9.887921343853195\n",
      "epoch: 339 loss: 1.9279282093048096 grad: 10.924651419418671\n",
      "epoch: 340 loss: 1.9234868288040161 grad: 10.348440110313868\n",
      "epoch: 341 loss: 1.9300448894500732 grad: 10.674906664941874\n",
      "epoch: 342 loss: 1.9381343126296997 grad: 10.481662135659938\n",
      "epoch: 343 loss: 1.9203184843063354 grad: 10.287340698453287\n",
      "epoch: 344 loss: 1.9250380992889404 grad: 9.959724352473305\n",
      "epoch: 345 loss: 1.925535798072815 grad: 10.005923498244513\n",
      "epoch: 346 loss: 1.92341947555542 grad: 9.826732838334191\n",
      "epoch: 347 loss: 1.918383240699768 grad: 9.719236514634556\n",
      "epoch: 348 loss: 1.9272575378417969 grad: 9.329214642075675\n",
      "epoch: 349 loss: 1.9328213930130005 grad: 10.275983661827114\n",
      "epoch: 350 loss: 1.9207059144973755 grad: 9.971415631103492\n",
      "epoch: 351 loss: 1.9134159088134766 grad: 9.999070042995589\n",
      "epoch: 352 loss: 1.9209504127502441 grad: 9.9592067658576\n",
      "epoch: 353 loss: 1.915404200553894 grad: 9.945093466619413\n",
      "epoch: 354 loss: 1.9314006567001343 grad: 10.166376881360534\n",
      "epoch: 355 loss: 1.9174951314926147 grad: 10.211817415564187\n",
      "epoch: 356 loss: 1.911616563796997 grad: 9.786889579405802\n",
      "epoch: 357 loss: 1.9160263538360596 grad: 10.509248831508947\n",
      "epoch: 358 loss: 1.915281057357788 grad: 9.912325850614007\n",
      "epoch: 359 loss: 1.913893222808838 grad: 10.252459345961965\n",
      "epoch: 360 loss: 1.9112484455108643 grad: 9.768511642110608\n",
      "epoch: 361 loss: 1.9188964366912842 grad: 10.297256111847384\n",
      "epoch: 362 loss: 1.917714238166809 grad: 10.117208044266416\n",
      "epoch: 363 loss: 1.9182260036468506 grad: 9.515640230756992\n",
      "epoch: 364 loss: 1.9141206741333008 grad: 10.056630129955472\n",
      "epoch: 365 loss: 1.9135953187942505 grad: 10.073146685070935\n",
      "epoch: 366 loss: 1.910202145576477 grad: 10.44572298627879\n",
      "epoch: 367 loss: 1.9244043827056885 grad: 10.676930055857474\n",
      "epoch: 368 loss: 1.9133051633834839 grad: 10.29117848092897\n",
      "epoch: 369 loss: 1.9059786796569824 grad: 10.408275967478634\n",
      "epoch: 370 loss: 1.909456729888916 grad: 10.012551020136074\n",
      "epoch: 371 loss: 1.9044573307037354 grad: 10.54822746925943\n",
      "epoch: 372 loss: 1.909472942352295 grad: 9.737992900364574\n",
      "epoch: 373 loss: 1.8996021747589111 grad: 9.868107160398116\n",
      "epoch: 374 loss: 1.908551573753357 grad: 10.241665889220755\n",
      "epoch: 375 loss: 1.9199974536895752 grad: 10.80031257714071\n",
      "epoch: 376 loss: 1.9032788276672363 grad: 10.152950497905886\n",
      "epoch: 377 loss: 1.8994802236557007 grad: 10.433365448052802\n",
      "epoch: 378 loss: 1.9163844585418701 grad: 10.647449136992533\n",
      "epoch: 379 loss: 1.912135124206543 grad: 10.269187249908489\n",
      "epoch: 380 loss: 1.9030890464782715 grad: 10.19874374688204\n",
      "epoch: 381 loss: 1.9021375179290771 grad: 10.290174144852374\n",
      "epoch: 382 loss: 1.9084854125976562 grad: 9.835519187514567\n",
      "epoch: 383 loss: 1.9112460613250732 grad: 11.087501249926548\n",
      "epoch: 384 loss: 1.9068084955215454 grad: 10.523635571837307\n",
      "epoch: 385 loss: 1.9014241695404053 grad: 10.677145670685503\n",
      "epoch: 386 loss: 1.909300446510315 grad: 10.051375455282155\n",
      "epoch: 387 loss: 1.9071335792541504 grad: 10.430077477328716\n",
      "epoch: 388 loss: 1.9039069414138794 grad: 10.54297414124899\n",
      "epoch: 389 loss: 1.9038887023925781 grad: 9.64136013119585\n",
      "epoch: 390 loss: 1.9103893041610718 grad: 10.515070872425678\n",
      "epoch: 391 loss: 1.9025958776474 grad: 10.4690743232412\n",
      "epoch: 392 loss: 1.902100682258606 grad: 10.119176788728625\n",
      "epoch: 393 loss: 1.8941482305526733 grad: 10.407721010938523\n",
      "epoch: 394 loss: 1.9050776958465576 grad: 9.697033815691986\n",
      "epoch: 395 loss: 1.905330777168274 grad: 10.400961596710932\n",
      "epoch: 396 loss: 1.9043128490447998 grad: 10.715952877494846\n",
      "epoch: 397 loss: 1.902328372001648 grad: 10.383757857310156\n",
      "epoch: 398 loss: 1.8940396308898926 grad: 10.913097114146998\n",
      "epoch: 399 loss: 1.9032669067382812 grad: 10.183265160717484\n",
      "epoch: 400 loss: 1.9002001285552979 grad: 10.643831456227907\n",
      "epoch: 401 loss: 1.8983569145202637 grad: 10.011140399405527\n",
      "epoch: 402 loss: 1.8945807218551636 grad: 10.411269565748553\n",
      "epoch: 403 loss: 1.8965203762054443 grad: 10.219282990447171\n",
      "epoch: 404 loss: 1.8953394889831543 grad: 10.317958234735425\n",
      "epoch: 405 loss: 1.8954719305038452 grad: 10.433615190302215\n",
      "epoch: 406 loss: 1.894309639930725 grad: 10.516817571661834\n",
      "epoch: 407 loss: 1.88532292842865 grad: 10.386788385491522\n",
      "epoch: 408 loss: 1.8989131450653076 grad: 10.881255461176533\n",
      "epoch: 409 loss: 1.8955845832824707 grad: 10.379386484379037\n",
      "epoch: 410 loss: 1.8969513177871704 grad: 9.796104910546942\n",
      "epoch: 411 loss: 1.891068458557129 grad: 10.688984696324619\n",
      "epoch: 412 loss: 1.893545150756836 grad: 10.45480808153719\n",
      "epoch: 413 loss: 1.8994345664978027 grad: 11.050903904576979\n",
      "epoch: 414 loss: 1.894618034362793 grad: 10.37461656694197\n",
      "epoch: 415 loss: 1.8802975416183472 grad: 10.28755122800875\n",
      "epoch: 416 loss: 1.8834835290908813 grad: 11.187016531263316\n",
      "epoch: 417 loss: 1.8980392217636108 grad: 10.840782916195513\n",
      "epoch: 418 loss: 1.890584111213684 grad: 9.935464810136528\n",
      "epoch: 419 loss: 1.8862688541412354 grad: 10.800048769651246\n",
      "epoch: 420 loss: 1.8933024406433105 grad: 10.550344327612528\n",
      "epoch: 421 loss: 1.8907544612884521 grad: 10.736951975403207\n",
      "epoch: 422 loss: 1.8853060007095337 grad: 10.251499646875475\n",
      "epoch: 423 loss: 1.9004034996032715 grad: 11.130295182031299\n",
      "epoch: 424 loss: 1.8891286849975586 grad: 10.082573019130717\n",
      "epoch: 425 loss: 1.8824831247329712 grad: 10.429343085285158\n",
      "epoch: 426 loss: 1.88699209690094 grad: 10.966414553586334\n",
      "epoch: 427 loss: 1.8880748748779297 grad: 10.941416752739025\n",
      "epoch: 428 loss: 1.883089303970337 grad: 10.695714935098612\n",
      "epoch: 429 loss: 1.885754108428955 grad: 10.848630604230696\n",
      "epoch: 430 loss: 1.8877959251403809 grad: 10.223048690322136\n",
      "epoch: 431 loss: 1.8819360733032227 grad: 10.342743688543875\n",
      "epoch: 432 loss: 1.8951634168624878 grad: 11.555728013139396\n",
      "epoch: 433 loss: 1.8840404748916626 grad: 10.883132793231024\n",
      "epoch: 434 loss: 1.8967010974884033 grad: 11.504570555193203\n",
      "epoch: 435 loss: 1.8887715339660645 grad: 10.901890114792401\n",
      "epoch: 436 loss: 1.883971929550171 grad: 11.06567498111713\n",
      "epoch: 437 loss: 1.886542558670044 grad: 10.958085817935329\n",
      "epoch: 438 loss: 1.8749151229858398 grad: 11.047467698446578\n",
      "epoch: 439 loss: 1.883758544921875 grad: 10.115102092957212\n",
      "epoch: 440 loss: 1.8918776512145996 grad: 10.583047999601279\n",
      "epoch: 441 loss: 1.8804808855056763 grad: 10.40595917465786\n",
      "epoch: 442 loss: 1.8857446908950806 grad: 10.849523866342174\n",
      "epoch: 443 loss: 1.8808249235153198 grad: 10.309093188494444\n",
      "epoch: 444 loss: 1.894018292427063 grad: 10.680140786745127\n",
      "epoch: 445 loss: 1.8840556144714355 grad: 10.761277428887311\n",
      "epoch: 446 loss: 1.8802317380905151 grad: 10.106442106562474\n",
      "epoch: 447 loss: 1.8860222101211548 grad: 10.659625291321722\n",
      "epoch: 448 loss: 1.8760167360305786 grad: 10.859058314638714\n",
      "epoch: 449 loss: 1.8848538398742676 grad: 10.483574705035796\n",
      "epoch: 450 loss: 1.87519109249115 grad: 11.026761782747354\n",
      "epoch: 451 loss: 1.8863269090652466 grad: 10.276859974089477\n",
      "epoch: 452 loss: 1.8865021467208862 grad: 11.007931641066476\n",
      "epoch: 453 loss: 1.8883283138275146 grad: 11.151712377910458\n",
      "epoch: 454 loss: 1.8829134702682495 grad: 10.570808392461567\n",
      "epoch: 455 loss: 1.878529667854309 grad: 11.113759116136603\n",
      "epoch: 456 loss: 1.8851083517074585 grad: 11.019099352644785\n",
      "epoch: 457 loss: 1.8755173683166504 grad: 10.345484961371218\n",
      "epoch: 458 loss: 1.8799631595611572 grad: 10.367459843142164\n",
      "epoch: 459 loss: 1.8818435668945312 grad: 10.814017252782213\n",
      "epoch: 460 loss: 1.8737115859985352 grad: 10.121035749033567\n",
      "epoch: 461 loss: 1.8731502294540405 grad: 10.661148682029712\n",
      "epoch: 462 loss: 1.8728574514389038 grad: 10.346717440759734\n",
      "epoch: 463 loss: 1.8689225912094116 grad: 10.678739957703602\n",
      "epoch: 464 loss: 1.876217246055603 grad: 10.08461145240636\n",
      "epoch: 465 loss: 1.878700852394104 grad: 10.412377262473225\n",
      "epoch: 466 loss: 1.8700698614120483 grad: 10.810829398355313\n",
      "epoch: 467 loss: 1.8752905130386353 grad: 10.900647551013481\n",
      "epoch: 468 loss: 1.872076153755188 grad: 10.909539649174327\n",
      "epoch: 469 loss: 1.8774901628494263 grad: 11.19581986000643\n",
      "epoch: 470 loss: 1.8737565279006958 grad: 11.185283423283153\n",
      "epoch: 471 loss: 1.8770380020141602 grad: 10.86679565107509\n",
      "epoch: 472 loss: 1.87996244430542 grad: 11.269199787698213\n",
      "epoch: 473 loss: 1.8751978874206543 grad: 10.981893966092713\n",
      "epoch: 474 loss: 1.871789574623108 grad: 11.167280981442817\n",
      "epoch: 475 loss: 1.8701800107955933 grad: 10.69408636374606\n",
      "epoch: 476 loss: 1.8797067403793335 grad: 10.625213006747858\n",
      "epoch: 477 loss: 1.8746711015701294 grad: 11.353356337448258\n",
      "epoch: 478 loss: 1.8747652769088745 grad: 10.899422232416415\n",
      "epoch: 479 loss: 1.8656171560287476 grad: 10.842082395107441\n",
      "epoch: 480 loss: 1.8704887628555298 grad: 11.057414007824033\n",
      "epoch: 481 loss: 1.8731975555419922 grad: 10.456467472815088\n",
      "epoch: 482 loss: 1.8774118423461914 grad: 11.454454723124703\n",
      "epoch: 483 loss: 1.8729513883590698 grad: 10.975182510261972\n",
      "epoch: 484 loss: 1.8715232610702515 grad: 10.475092872696381\n",
      "epoch: 485 loss: 1.8615459203720093 grad: 11.204901606347116\n",
      "epoch: 486 loss: 1.8731876611709595 grad: 10.314532525926118\n",
      "epoch: 487 loss: 1.865987777709961 grad: 10.614104058223939\n",
      "epoch: 488 loss: 1.8631929159164429 grad: 10.890115295847258\n",
      "epoch: 489 loss: 1.858890175819397 grad: 10.504251491721897\n",
      "epoch: 490 loss: 1.8678957223892212 grad: 11.293167845966915\n",
      "epoch: 491 loss: 1.8683871030807495 grad: 11.187810318448419\n",
      "epoch: 492 loss: 1.8705995082855225 grad: 10.982401176178385\n",
      "epoch: 493 loss: 1.8700438737869263 grad: 11.485985673712714\n",
      "epoch: 494 loss: 1.872580647468567 grad: 11.92928851414324\n",
      "epoch: 495 loss: 1.8635560274124146 grad: 10.677469589429656\n",
      "epoch: 496 loss: 1.8568642139434814 grad: 10.824958413528899\n",
      "epoch: 497 loss: 1.8624322414398193 grad: 10.243113680387891\n",
      "epoch: 498 loss: 1.8636077642440796 grad: 11.337751878610264\n",
      "epoch: 499 loss: 1.8585326671600342 grad: 10.415252139954458\n",
      "2.050126940011978\n",
      "epoch: 0 loss: 2.3044815063476562 grad: 1.046929034628048\n",
      "epoch: 1 loss: 2.296785354614258 grad: 0.977580428834901\n",
      "epoch: 2 loss: 2.2607500553131104 grad: 1.7451660882474647\n",
      "epoch: 3 loss: 2.224384307861328 grad: 2.2833445608913383\n",
      "epoch: 4 loss: 2.173961639404297 grad: 2.924469869691021\n",
      "epoch: 5 loss: 2.1164960861206055 grad: 3.801818981226201\n",
      "epoch: 6 loss: 2.052605628967285 grad: 4.372294421166843\n",
      "epoch: 7 loss: 2.0172486305236816 grad: 4.476915025924672\n",
      "epoch: 8 loss: 1.9779986143112183 grad: 4.46628207552232\n",
      "epoch: 9 loss: 1.9931501150131226 grad: 5.167954015785769\n",
      "epoch: 10 loss: 1.9668482542037964 grad: 4.880534035814298\n",
      "epoch: 11 loss: 1.952714443206787 grad: 5.399435148683436\n",
      "epoch: 12 loss: 1.9437029361724854 grad: 4.74416756997091\n",
      "epoch: 13 loss: 1.9361109733581543 grad: 5.394346729215209\n",
      "epoch: 14 loss: 1.9251165390014648 grad: 4.595813368722919\n",
      "epoch: 15 loss: 1.9188205003738403 grad: 5.123300288252751\n",
      "epoch: 16 loss: 1.9067357778549194 grad: 5.480231883641358\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 17 loss: 1.9143670797348022 grad: 5.810827698759986\n",
      "epoch: 18 loss: 1.9171308279037476 grad: 5.475553843165038\n",
      "epoch: 19 loss: 1.885361909866333 grad: 5.319420087824313\n",
      "epoch: 20 loss: 1.8861831426620483 grad: 5.3578120505341165\n",
      "epoch: 21 loss: 1.8841145038604736 grad: 5.928185548914674\n",
      "epoch: 22 loss: 1.8751229047775269 grad: 5.9836919368369434\n",
      "epoch: 23 loss: 1.8691705465316772 grad: 5.838572727395259\n",
      "epoch: 24 loss: 1.865867018699646 grad: 6.711295923541969\n",
      "epoch: 25 loss: 1.8648450374603271 grad: 6.304454405105115\n",
      "epoch: 26 loss: 1.856680989265442 grad: 5.743452120616215\n",
      "epoch: 27 loss: 1.8367671966552734 grad: 5.996933872287396\n",
      "epoch: 28 loss: 1.865563154220581 grad: 6.317840265306932\n",
      "epoch: 29 loss: 1.8289457559585571 grad: 5.692129272617407\n",
      "epoch: 30 loss: 1.8178093433380127 grad: 6.528623876570251\n",
      "epoch: 31 loss: 1.824171543121338 grad: 7.213917290042099\n",
      "epoch: 32 loss: 1.8055344820022583 grad: 7.2163159196890545\n",
      "epoch: 33 loss: 1.808992862701416 grad: 7.329447616967151\n",
      "epoch: 34 loss: 1.8187508583068848 grad: 6.786748981255288\n",
      "epoch: 35 loss: 1.7922883033752441 grad: 7.0151572514044505\n",
      "epoch: 36 loss: 1.7816606760025024 grad: 7.42566670711653\n",
      "epoch: 37 loss: 1.7773417234420776 grad: 7.3305638637673205\n",
      "epoch: 38 loss: 1.7576910257339478 grad: 7.1748991543611895\n",
      "epoch: 39 loss: 1.7656735181808472 grad: 7.838460970088832\n",
      "epoch: 40 loss: 1.7577532529830933 grad: 7.825625402457912\n",
      "epoch: 41 loss: 1.7777142524719238 grad: 7.666077463095592\n",
      "epoch: 42 loss: 1.7805360555648804 grad: 7.247172775325395\n",
      "epoch: 43 loss: 1.7482428550720215 grad: 6.9261770147704596\n",
      "epoch: 44 loss: 1.7436891794204712 grad: 7.038871839097636\n",
      "epoch: 45 loss: 1.7293775081634521 grad: 7.390859144157268\n",
      "epoch: 46 loss: 1.74088716506958 grad: 7.836183372657239\n",
      "epoch: 47 loss: 1.7118459939956665 grad: 7.382067464581702\n",
      "epoch: 48 loss: 1.7216955423355103 grad: 6.790922811667972\n",
      "epoch: 49 loss: 1.7157102823257446 grad: 8.386429088132221\n",
      "epoch: 50 loss: 1.7276780605316162 grad: 7.072122452393939\n",
      "epoch: 51 loss: 1.7309819459915161 grad: 6.850398854423908\n",
      "epoch: 52 loss: 1.7278921604156494 grad: 8.069255288784108\n",
      "epoch: 53 loss: 1.709859013557434 grad: 8.029154425547901\n",
      "epoch: 54 loss: 1.7280220985412598 grad: 6.986480568367471\n",
      "epoch: 55 loss: 1.699729084968567 grad: 6.273265412167738\n",
      "epoch: 56 loss: 1.684858798980713 grad: 6.24737966327077\n",
      "epoch: 57 loss: 1.7093020677566528 grad: 8.37025059462573\n",
      "epoch: 58 loss: 1.7153767347335815 grad: 7.520423618367492\n",
      "epoch: 59 loss: 1.7025527954101562 grad: 7.493417620897017\n",
      "epoch: 60 loss: 1.6882139444351196 grad: 7.126723131099309\n",
      "epoch: 61 loss: 1.686584711074829 grad: 6.579211763745878\n",
      "epoch: 62 loss: 1.6959850788116455 grad: 6.8065246008361955\n",
      "epoch: 63 loss: 1.6828569173812866 grad: 6.919245564169065\n",
      "epoch: 64 loss: 1.6770894527435303 grad: 6.61332465764835\n",
      "epoch: 65 loss: 1.697465419769287 grad: 6.75153449724894\n",
      "epoch: 66 loss: 1.6727131605148315 grad: 7.146937707471684\n",
      "epoch: 67 loss: 1.6624115705490112 grad: 6.636693516420709\n",
      "epoch: 68 loss: 1.6660001277923584 grad: 7.117917675783073\n",
      "epoch: 69 loss: 1.6731879711151123 grad: 6.570154422139269\n",
      "epoch: 70 loss: 1.6867880821228027 grad: 7.617229603212475\n",
      "epoch: 71 loss: 1.6789902448654175 grad: 7.43216535772427\n",
      "epoch: 72 loss: 1.664140224456787 grad: 7.724673569415505\n",
      "epoch: 73 loss: 1.6817015409469604 grad: 6.984663711577129\n",
      "epoch: 74 loss: 1.6645361185073853 grad: 6.916906671381891\n",
      "epoch: 75 loss: 1.656481385231018 grad: 6.3790853015966675\n",
      "epoch: 76 loss: 1.6617826223373413 grad: 6.836875265343729\n",
      "epoch: 77 loss: 1.647586703300476 grad: 6.619059817816523\n",
      "epoch: 78 loss: 1.6691538095474243 grad: 7.19993361215789\n",
      "epoch: 79 loss: 1.6565546989440918 grad: 6.251639937641725\n",
      "epoch: 80 loss: 1.6527373790740967 grad: 6.892784338368478\n",
      "epoch: 81 loss: 1.6379954814910889 grad: 6.438661482555622\n",
      "epoch: 82 loss: 1.6406681537628174 grad: 6.490001433391987\n",
      "epoch: 83 loss: 1.6298631429672241 grad: 6.80933594392529\n",
      "epoch: 84 loss: 1.6497108936309814 grad: 6.227992735661535\n",
      "epoch: 85 loss: 1.6612892150878906 grad: 6.918834728880606\n",
      "epoch: 86 loss: 1.6427416801452637 grad: 6.6193361736353955\n",
      "epoch: 87 loss: 1.6687196493148804 grad: 8.30612285471002\n",
      "epoch: 88 loss: 1.6617295742034912 grad: 6.70026078887537\n",
      "epoch: 89 loss: 1.647828459739685 grad: 5.148400791781439\n",
      "epoch: 90 loss: 1.6384227275848389 grad: 6.64331804011292\n",
      "epoch: 91 loss: 1.6499310731887817 grad: 6.790551418259196\n",
      "epoch: 92 loss: 1.6507043838500977 grad: 7.595069970511498\n",
      "epoch: 93 loss: 1.6566537618637085 grad: 6.3532886427077875\n",
      "epoch: 94 loss: 1.6365705728530884 grad: 6.612329451358944\n",
      "epoch: 95 loss: 1.6427686214447021 grad: 6.426892053712869\n",
      "epoch: 96 loss: 1.6186741590499878 grad: 5.48865186555835\n",
      "epoch: 97 loss: 1.6331197023391724 grad: 6.519564526331066\n",
      "epoch: 98 loss: 1.630539059638977 grad: 6.673474913592751\n",
      "epoch: 99 loss: 1.6224015951156616 grad: 6.495496867779511\n",
      "epoch: 100 loss: 1.6281027793884277 grad: 6.23877915011967\n",
      "epoch: 101 loss: 1.6217867136001587 grad: 6.0480871074899385\n",
      "epoch: 102 loss: 1.6286094188690186 grad: 5.514702535244497\n",
      "epoch: 103 loss: 1.6307859420776367 grad: 6.659407202822574\n",
      "epoch: 104 loss: 1.6357743740081787 grad: 6.6999280549620925\n",
      "epoch: 105 loss: 1.638748049736023 grad: 6.4017903741036175\n",
      "epoch: 106 loss: 1.6126352548599243 grad: 5.4882877186237815\n",
      "epoch: 107 loss: 1.623326301574707 grad: 6.4436922230354305\n",
      "epoch: 108 loss: 1.6353695392608643 grad: 7.087687858084258\n",
      "epoch: 109 loss: 1.6185564994812012 grad: 5.649694954164304\n",
      "epoch: 110 loss: 1.6411927938461304 grad: 6.33757625040633\n",
      "epoch: 111 loss: 1.613944411277771 grad: 6.6868855036093935\n",
      "epoch: 112 loss: 1.6152899265289307 grad: 5.499810616683034\n",
      "epoch: 113 loss: 1.6049352884292603 grad: 4.8906305582542755\n",
      "epoch: 114 loss: 1.6075146198272705 grad: 6.085550747865902\n",
      "epoch: 115 loss: 1.6272021532058716 grad: 6.070609233277667\n",
      "epoch: 116 loss: 1.616768479347229 grad: 6.072421909362472\n",
      "epoch: 117 loss: 1.608445167541504 grad: 4.857579737311613\n",
      "epoch: 118 loss: 1.6176562309265137 grad: 6.172049133586482\n",
      "epoch: 119 loss: 1.6163113117218018 grad: 6.051525718178637\n",
      "epoch: 120 loss: 1.6123130321502686 grad: 5.8533856351388085\n",
      "epoch: 121 loss: 1.6147489547729492 grad: 6.096475620796391\n",
      "epoch: 122 loss: 1.6204032897949219 grad: 5.414600206079264\n",
      "epoch: 123 loss: 1.6226425170898438 grad: 6.061327061714687\n",
      "epoch: 124 loss: 1.6223686933517456 grad: 6.481188657216528\n",
      "epoch: 125 loss: 1.6217776536941528 grad: 5.078560273788074\n",
      "epoch: 126 loss: 1.6184682846069336 grad: 7.092358047545949\n",
      "epoch: 127 loss: 1.6256314516067505 grad: 6.376144686166703\n",
      "epoch: 128 loss: 1.6343451738357544 grad: 6.138505144601772\n",
      "epoch: 129 loss: 1.618173599243164 grad: 6.707776377299033\n",
      "epoch: 130 loss: 1.600705623626709 grad: 5.01900794152537\n",
      "epoch: 131 loss: 1.6163201332092285 grad: 7.090446451104967\n",
      "epoch: 132 loss: 1.644444227218628 grad: 7.227160802510658\n",
      "epoch: 133 loss: 1.6280579566955566 grad: 6.162295922202565\n",
      "epoch: 134 loss: 1.6187540292739868 grad: 5.199576671916879\n",
      "epoch: 135 loss: 1.6236276626586914 grad: 6.030075045510842\n",
      "epoch: 136 loss: 1.6112362146377563 grad: 5.896204083278448\n",
      "epoch: 137 loss: 1.6123504638671875 grad: 5.380629929219573\n",
      "epoch: 138 loss: 1.6063027381896973 grad: 5.657275563248609\n",
      "epoch: 139 loss: 1.6098034381866455 grad: 6.726831965705579\n",
      "epoch: 140 loss: 1.6062471866607666 grad: 5.94994263552011\n",
      "epoch: 141 loss: 1.6162248849868774 grad: 5.9992871733887565\n",
      "epoch: 142 loss: 1.6039658784866333 grad: 5.13799794259354\n",
      "epoch: 143 loss: 1.5997891426086426 grad: 5.645144416202951\n",
      "epoch: 144 loss: 1.6013727188110352 grad: 5.746511403767697\n",
      "epoch: 145 loss: 1.5880876779556274 grad: 5.901437623101419\n",
      "epoch: 146 loss: 1.5932012796401978 grad: 4.980103895612249\n",
      "epoch: 147 loss: 1.6080714464187622 grad: 4.929813444968875\n",
      "epoch: 148 loss: 1.591257929801941 grad: 5.408233674903083\n",
      "epoch: 149 loss: 1.5932748317718506 grad: 5.432501041520149\n",
      "epoch: 150 loss: 1.6142909526824951 grad: 6.285662189742941\n",
      "epoch: 151 loss: 1.6211199760437012 grad: 5.9283320435146925\n",
      "epoch: 152 loss: 1.6069706678390503 grad: 6.068760293068364\n",
      "epoch: 153 loss: 1.6085420846939087 grad: 5.101229119327413\n",
      "epoch: 154 loss: 1.5881699323654175 grad: 4.707780361166182\n",
      "epoch: 155 loss: 1.6028107404708862 grad: 5.701263161672152\n",
      "epoch: 156 loss: 1.5964443683624268 grad: 5.5795306982699335\n",
      "epoch: 157 loss: 1.5968035459518433 grad: 5.5945192929947885\n",
      "epoch: 158 loss: 1.5863306522369385 grad: 5.457379839408171\n",
      "epoch: 159 loss: 1.602832555770874 grad: 5.409331953355564\n",
      "epoch: 160 loss: 1.597988247871399 grad: 5.121525784067168\n",
      "epoch: 161 loss: 1.6049729585647583 grad: 5.417861982979669\n",
      "epoch: 162 loss: 1.5942796468734741 grad: 5.060448323136414\n",
      "epoch: 163 loss: 1.6051901578903198 grad: 5.813408684089009\n",
      "epoch: 164 loss: 1.6132186651229858 grad: 6.047165644058854\n",
      "epoch: 165 loss: 1.5933483839035034 grad: 4.149999972386352\n",
      "epoch: 166 loss: 1.5997064113616943 grad: 6.593592080994832\n",
      "epoch: 167 loss: 1.6036453247070312 grad: 6.670778052468666\n",
      "epoch: 168 loss: 1.6449360847473145 grad: 4.967169846295624\n",
      "epoch: 169 loss: 1.602318286895752 grad: 4.922094669601443\n",
      "epoch: 170 loss: 1.5976682901382446 grad: 5.134214313526562\n",
      "epoch: 171 loss: 1.5907354354858398 grad: 5.174758206130998\n",
      "epoch: 172 loss: 1.5887423753738403 grad: 4.450744943800027\n",
      "epoch: 173 loss: 1.5852863788604736 grad: 4.560467767384883\n",
      "epoch: 174 loss: 1.5897159576416016 grad: 4.588341573189202\n",
      "epoch: 175 loss: 1.5795183181762695 grad: 4.350576763283871\n",
      "epoch: 176 loss: 1.6062644720077515 grad: 5.623525785152876\n",
      "epoch: 177 loss: 1.5987975597381592 grad: 5.423282235293664\n",
      "epoch: 178 loss: 1.5880910158157349 grad: 4.178232061518627\n",
      "epoch: 179 loss: 1.5995551347732544 grad: 5.033821676196163\n",
      "epoch: 180 loss: 1.5854209661483765 grad: 4.427771097945128\n",
      "epoch: 181 loss: 1.5910122394561768 grad: 6.259266261277541\n",
      "epoch: 182 loss: 1.6027995347976685 grad: 6.948385970233709\n",
      "epoch: 183 loss: 1.600526213645935 grad: 5.109616448779266\n",
      "epoch: 184 loss: 1.5964785814285278 grad: 4.456117148895456\n",
      "epoch: 185 loss: 1.5986628532409668 grad: 5.142035485239597\n",
      "epoch: 186 loss: 1.5963525772094727 grad: 4.834081716969871\n",
      "epoch: 187 loss: 1.5705546140670776 grad: 4.550627740275039\n",
      "epoch: 188 loss: 1.6042019128799438 grad: 5.572589940148133\n",
      "epoch: 189 loss: 1.598850965499878 grad: 5.285419666190714\n",
      "epoch: 190 loss: 1.6109964847564697 grad: 5.7363508317231595\n",
      "epoch: 191 loss: 1.574582815170288 grad: 4.760942507495569\n",
      "epoch: 192 loss: 1.5899512767791748 grad: 4.7244001121304775\n",
      "epoch: 193 loss: 1.5918545722961426 grad: 4.719713694682563\n",
      "epoch: 194 loss: 1.5920460224151611 grad: 5.27946873718693\n",
      "epoch: 195 loss: 1.598262906074524 grad: 5.679275767613129\n",
      "epoch: 196 loss: 1.58188796043396 grad: 5.231981054049306\n",
      "epoch: 197 loss: 1.5771352052688599 grad: 4.681565640744767\n",
      "epoch: 198 loss: 1.580800175666809 grad: 4.908311571944368\n",
      "epoch: 199 loss: 1.6032567024230957 grad: 4.810451267054813\n",
      "epoch: 200 loss: 1.586914300918579 grad: 5.859980762870114\n",
      "epoch: 201 loss: 1.5921374559402466 grad: 5.128166424150824\n",
      "epoch: 202 loss: 1.581098198890686 grad: 5.765249316277248\n",
      "epoch: 203 loss: 1.6031215190887451 grad: 4.326565456569201\n",
      "epoch: 204 loss: 1.5837042331695557 grad: 5.09427560497551\n",
      "epoch: 205 loss: 1.6007375717163086 grad: 5.606515338137862\n",
      "epoch: 206 loss: 1.611851692199707 grad: 6.02185004891567\n",
      "epoch: 207 loss: 1.5985032320022583 grad: 5.578077252259181\n",
      "epoch: 208 loss: 1.581149935722351 grad: 3.5614932829104244\n",
      "epoch: 209 loss: 1.5696622133255005 grad: 4.0210886427236385\n",
      "epoch: 210 loss: 1.5956376791000366 grad: 5.362495544322507\n",
      "epoch: 211 loss: 1.5892678499221802 grad: 3.420241299028979\n",
      "epoch: 212 loss: 1.5979958772659302 grad: 5.720924706755636\n",
      "epoch: 213 loss: 1.5841362476348877 grad: 5.473461909416427\n",
      "epoch: 214 loss: 1.6026816368103027 grad: 5.708038551008673\n",
      "epoch: 215 loss: 1.5917959213256836 grad: 5.5435121886765515\n",
      "epoch: 216 loss: 1.5932164192199707 grad: 5.84578601049987\n",
      "epoch: 217 loss: 1.576833963394165 grad: 4.6690180649611674\n",
      "epoch: 218 loss: 1.5799410343170166 grad: 4.841623628546074\n",
      "epoch: 219 loss: 1.5937801599502563 grad: 6.1495486984868215\n",
      "epoch: 220 loss: 1.5942462682724 grad: 5.508857063209026\n",
      "epoch: 221 loss: 1.5660279989242554 grad: 3.9899068894812304\n",
      "epoch: 222 loss: 1.572932481765747 grad: 4.366873813128172\n",
      "epoch: 223 loss: 1.5739314556121826 grad: 5.203663019942407\n",
      "epoch: 224 loss: 1.572736382484436 grad: 3.9881147228860327\n",
      "epoch: 225 loss: 1.573958158493042 grad: 4.0235329860869085\n",
      "epoch: 226 loss: 1.5727732181549072 grad: 5.047903119665209\n",
      "epoch: 227 loss: 1.5716814994812012 grad: 3.5133615633794997\n",
      "epoch: 228 loss: 1.6017277240753174 grad: 5.193642921795104\n",
      "epoch: 229 loss: 1.596516489982605 grad: 4.097583730369721\n",
      "epoch: 230 loss: 1.589445948600769 grad: 4.95453942523312\n",
      "epoch: 231 loss: 1.582175612449646 grad: 5.540148724191989\n",
      "epoch: 232 loss: 1.565505027770996 grad: 4.452735293637924\n",
      "epoch: 233 loss: 1.590823769569397 grad: 5.117662639405174\n",
      "epoch: 234 loss: 1.584443211555481 grad: 5.055543488942373\n",
      "epoch: 235 loss: 1.5881303548812866 grad: 5.418223016702454\n",
      "epoch: 236 loss: 1.5741207599639893 grad: 4.581812160710248\n",
      "epoch: 237 loss: 1.588397741317749 grad: 3.6882299424559104\n",
      "epoch: 238 loss: 1.5788583755493164 grad: 5.777273218326158\n",
      "epoch: 239 loss: 1.5771217346191406 grad: 4.743298875596893\n",
      "epoch: 240 loss: 1.5898531675338745 grad: 4.252899123809014\n",
      "epoch: 241 loss: 1.5819849967956543 grad: 3.7467102384336206\n",
      "epoch: 242 loss: 1.5651615858078003 grad: 4.90163249579189\n",
      "epoch: 243 loss: 1.5834364891052246 grad: 4.351865744461663\n",
      "epoch: 244 loss: 1.58516526222229 grad: 4.279470919028025\n",
      "epoch: 245 loss: 1.5937777757644653 grad: 4.571010445951602\n",
      "epoch: 246 loss: 1.5762298107147217 grad: 5.3319488209904335\n",
      "epoch: 247 loss: 1.6058895587921143 grad: 6.267861397018438\n",
      "epoch: 248 loss: 1.585329532623291 grad: 4.916788986522879\n",
      "epoch: 249 loss: 1.588102102279663 grad: 3.1913091009511296\n",
      "epoch: 250 loss: 1.5906082391738892 grad: 5.525088073246955\n",
      "epoch: 251 loss: 1.5847669839859009 grad: 5.2341638554021594\n",
      "epoch: 252 loss: 1.6017687320709229 grad: 4.5556381840463\n",
      "epoch: 253 loss: 1.5824050903320312 grad: 4.860350091119982\n",
      "epoch: 254 loss: 1.5813478231430054 grad: 5.126146813199989\n",
      "epoch: 255 loss: 1.5777746438980103 grad: 3.9609258615280756\n",
      "epoch: 256 loss: 1.56510329246521 grad: 3.6554780964777134\n",
      "epoch: 257 loss: 1.5719377994537354 grad: 3.196641316038924\n",
      "epoch: 258 loss: 1.5634647607803345 grad: 3.935062922696923\n",
      "epoch: 259 loss: 1.584502100944519 grad: 4.020967137603696\n",
      "epoch: 260 loss: 1.594010353088379 grad: 5.700122745995372\n",
      "epoch: 261 loss: 1.588592767715454 grad: 5.43476019540793\n",
      "epoch: 262 loss: 1.5927280187606812 grad: 5.345885639418059\n",
      "epoch: 263 loss: 1.586961269378662 grad: 4.110582952330181\n",
      "epoch: 264 loss: 1.5829966068267822 grad: 5.162081661547399\n",
      "epoch: 265 loss: 1.600399136543274 grad: 5.1604952563450155\n",
      "epoch: 266 loss: 1.5780274868011475 grad: 4.052288744906501\n",
      "epoch: 267 loss: 1.5701119899749756 grad: 4.5429761858228925\n",
      "epoch: 268 loss: 1.5839258432388306 grad: 4.871102684913799\n",
      "epoch: 269 loss: 1.5605266094207764 grad: 4.299027758009783\n",
      "epoch: 270 loss: 1.5734338760375977 grad: 4.461322815070335\n",
      "epoch: 271 loss: 1.5785800218582153 grad: 5.313193001458324\n",
      "epoch: 272 loss: 1.562354564666748 grad: 4.514630828923245\n",
      "epoch: 273 loss: 1.5569616556167603 grad: 4.1960980906628755\n",
      "epoch: 274 loss: 1.5463311672210693 grad: 4.094752802454168\n",
      "epoch: 275 loss: 1.5613585710525513 grad: 4.734584069293536\n",
      "epoch: 276 loss: 1.5649281740188599 grad: 5.8695563610227985\n",
      "epoch: 277 loss: 1.5673774480819702 grad: 4.60955573058964\n",
      "epoch: 278 loss: 1.5641134977340698 grad: 4.374814389126805\n",
      "epoch: 279 loss: 1.5685843229293823 grad: 5.161387423361771\n",
      "epoch: 280 loss: 1.5825928449630737 grad: 4.881684120215184\n",
      "epoch: 281 loss: 1.567621111869812 grad: 4.63003429119945\n",
      "epoch: 282 loss: 1.5718134641647339 grad: 3.47705305118262\n",
      "epoch: 283 loss: 1.5701897144317627 grad: 3.792913717838087\n",
      "epoch: 284 loss: 1.5606156587600708 grad: 4.315079586174501\n",
      "epoch: 285 loss: 1.5646138191223145 grad: 4.291083530640221\n",
      "epoch: 286 loss: 1.5583335161209106 grad: 3.6612781627213162\n",
      "epoch: 287 loss: 1.5678322315216064 grad: 3.222790062280663\n",
      "epoch: 288 loss: 1.565709114074707 grad: 3.5828567791917973\n",
      "epoch: 289 loss: 1.5660855770111084 grad: 4.118532802121591\n",
      "epoch: 290 loss: 1.5767112970352173 grad: 3.283935453276067\n",
      "epoch: 291 loss: 1.5744948387145996 grad: 4.535322713221857\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 292 loss: 1.5680105686187744 grad: 4.248309039215405\n",
      "epoch: 293 loss: 1.5602673292160034 grad: 3.7468317728556597\n",
      "epoch: 294 loss: 1.5683307647705078 grad: 4.174749712785233\n",
      "epoch: 295 loss: 1.565904974937439 grad: 3.5457928358553104\n",
      "epoch: 296 loss: 1.57333242893219 grad: 4.529997983229059\n",
      "epoch: 297 loss: 1.5751742124557495 grad: 4.617000721729781\n",
      "epoch: 298 loss: 1.5666056871414185 grad: 4.385799337817052\n",
      "epoch: 299 loss: 1.5569690465927124 grad: 3.654188337167924\n",
      "epoch: 300 loss: 1.5705302953720093 grad: 3.9836020211633456\n",
      "epoch: 301 loss: 1.562606692314148 grad: 4.545445664142657\n",
      "epoch: 302 loss: 1.5825774669647217 grad: 5.355167517860708\n",
      "epoch: 303 loss: 1.5754432678222656 grad: 5.127629873161373\n",
      "epoch: 304 loss: 1.555469036102295 grad: 3.428587353120985\n",
      "epoch: 305 loss: 1.5543748140335083 grad: 4.049205414844443\n",
      "epoch: 306 loss: 1.5596847534179688 grad: 2.9630310787143035\n",
      "epoch: 307 loss: 1.5489259958267212 grad: 3.849697229436416\n",
      "epoch: 308 loss: 1.548413634300232 grad: 3.2161152477093746\n",
      "epoch: 309 loss: 1.5585695505142212 grad: 3.9140760998666275\n",
      "epoch: 310 loss: 1.5411875247955322 grad: 2.6985124231380224\n",
      "epoch: 311 loss: 1.5608772039413452 grad: 3.7620122764887243\n",
      "epoch: 312 loss: 1.5659316778182983 grad: 4.761091349450097\n",
      "epoch: 313 loss: 1.5588468313217163 grad: 3.8872312346054074\n",
      "epoch: 314 loss: 1.578347086906433 grad: 4.362809717064073\n",
      "epoch: 315 loss: 1.559303879737854 grad: 3.0552635413021685\n",
      "epoch: 316 loss: 1.5545265674591064 grad: 4.046794842388046\n",
      "epoch: 317 loss: 1.6230133771896362 grad: 5.298778660369351\n",
      "epoch: 318 loss: 1.6130465269088745 grad: 5.236961412404067\n",
      "epoch: 319 loss: 1.5670039653778076 grad: 4.949262790000778\n",
      "epoch: 320 loss: 1.5742286443710327 grad: 4.799614438849732\n",
      "epoch: 321 loss: 1.5562074184417725 grad: 2.9535021765169343\n",
      "epoch: 322 loss: 1.568799614906311 grad: 4.955096824259672\n",
      "epoch: 323 loss: 1.5826855897903442 grad: 5.67256050736423\n",
      "epoch: 324 loss: 1.5888086557388306 grad: 5.761608561253954\n",
      "epoch: 325 loss: 1.5916846990585327 grad: 5.852186491688216\n",
      "epoch: 326 loss: 1.6038085222244263 grad: 5.182245635256391\n",
      "epoch: 327 loss: 1.5604708194732666 grad: 3.690472559185331\n",
      "epoch: 328 loss: 1.5645867586135864 grad: 3.8865804569725584\n",
      "epoch: 329 loss: 1.5555689334869385 grad: 3.4619585571625717\n",
      "epoch: 330 loss: 1.5578175783157349 grad: 3.8624158960037693\n",
      "epoch: 331 loss: 1.5599473714828491 grad: 3.615163271823444\n",
      "epoch: 332 loss: 1.553363561630249 grad: 3.297710134284207\n",
      "epoch: 333 loss: 1.5644404888153076 grad: 3.8852002644342463\n",
      "epoch: 334 loss: 1.5663981437683105 grad: 3.1475567285161947\n",
      "epoch: 335 loss: 1.5515973567962646 grad: 3.026599208659289\n",
      "epoch: 336 loss: 1.5501060485839844 grad: 3.6252855371735793\n",
      "epoch: 337 loss: 1.5626617670059204 grad: 3.279921460614514\n",
      "epoch: 338 loss: 1.5774937868118286 grad: 4.647194505855299\n",
      "epoch: 339 loss: 1.5795992612838745 grad: 5.425984903592042\n",
      "epoch: 340 loss: 1.5632946491241455 grad: 4.728919882801204\n",
      "epoch: 341 loss: 1.5595251321792603 grad: 3.473349448631298\n",
      "epoch: 342 loss: 1.5563626289367676 grad: 3.181748827169537\n",
      "epoch: 343 loss: 1.559411644935608 grad: 2.439276177327295\n",
      "epoch: 344 loss: 1.5589544773101807 grad: 4.3246423126818225\n",
      "epoch: 345 loss: 1.5600690841674805 grad: 3.448019780049808\n",
      "epoch: 346 loss: 1.5693161487579346 grad: 4.100332508007131\n",
      "epoch: 347 loss: 1.5603151321411133 grad: 4.758340100324583\n",
      "epoch: 348 loss: 1.5701972246170044 grad: 4.139657157038849\n",
      "epoch: 349 loss: 1.5692105293273926 grad: 3.748728982946074\n",
      "epoch: 350 loss: 1.5762847661972046 grad: 3.9423181237590055\n",
      "epoch: 351 loss: 1.5692249536514282 grad: 5.89231259289905\n",
      "epoch: 352 loss: 1.567071795463562 grad: 3.417348203564671\n",
      "epoch: 353 loss: 1.561303973197937 grad: 4.576518580089034\n",
      "epoch: 354 loss: 1.5512100458145142 grad: 2.774771443158976\n",
      "epoch: 355 loss: 1.5472365617752075 grad: 3.0077196953948295\n",
      "epoch: 356 loss: 1.553399682044983 grad: 3.6911476416291875\n",
      "epoch: 357 loss: 1.5603587627410889 grad: 4.670904393700046\n",
      "epoch: 358 loss: 1.5597366094589233 grad: 4.473457413103725\n",
      "epoch: 359 loss: 1.5676755905151367 grad: 3.884460737144377\n",
      "epoch: 360 loss: 1.5736268758773804 grad: 4.0243112912780585\n",
      "epoch: 361 loss: 1.5627503395080566 grad: 4.190487975729362\n",
      "epoch: 362 loss: 1.5572113990783691 grad: 4.673294312358303\n",
      "epoch: 363 loss: 1.5728254318237305 grad: 5.214030975616516\n",
      "epoch: 364 loss: 1.558427095413208 grad: 3.843570954486306\n",
      "epoch: 365 loss: 1.5624489784240723 grad: 4.420602029712195\n",
      "epoch: 366 loss: 1.5658738613128662 grad: 4.45063605981664\n",
      "epoch: 367 loss: 1.5638010501861572 grad: 4.468319003477234\n",
      "epoch: 368 loss: 1.5531715154647827 grad: 3.9412220712792703\n",
      "epoch: 369 loss: 1.5577094554901123 grad: 4.664344133192138\n",
      "epoch: 370 loss: 1.5617114305496216 grad: 4.340738973754544\n",
      "epoch: 371 loss: 1.5683238506317139 grad: 3.683143450171296\n",
      "epoch: 372 loss: 1.5570427179336548 grad: 3.778279848447788\n",
      "epoch: 373 loss: 1.5801076889038086 grad: 5.945836811686861\n",
      "epoch: 374 loss: 1.5565687417984009 grad: 3.0393814756397606\n",
      "epoch: 375 loss: 1.5743638277053833 grad: 3.6934009369872816\n",
      "epoch: 376 loss: 1.561201810836792 grad: 4.276614522048837\n",
      "epoch: 377 loss: 1.5617605447769165 grad: 3.773713962037053\n",
      "epoch: 378 loss: 1.5557647943496704 grad: 4.295113060698178\n",
      "epoch: 379 loss: 1.5702072381973267 grad: 3.866225969415317\n",
      "epoch: 380 loss: 1.5630104541778564 grad: 3.0366591469399182\n",
      "epoch: 381 loss: 1.5792603492736816 grad: 4.866619972987492\n",
      "epoch: 382 loss: 1.6159963607788086 grad: 4.739507166729974\n",
      "epoch: 383 loss: 1.5593388080596924 grad: 4.0546428993424986\n",
      "epoch: 384 loss: 1.561959981918335 grad: 3.7589615348874488\n",
      "epoch: 385 loss: 1.571885108947754 grad: 4.572764685395352\n",
      "epoch: 386 loss: 1.5833889245986938 grad: 2.507854104484321\n",
      "epoch: 387 loss: 1.555379033088684 grad: 1.9719810512422857\n",
      "epoch: 388 loss: 1.5411279201507568 grad: 2.817685682257591\n",
      "epoch: 389 loss: 1.5974971055984497 grad: 4.750012251673152\n",
      "epoch: 390 loss: 1.5906567573547363 grad: 5.690023751743126\n",
      "epoch: 391 loss: 1.5613791942596436 grad: 4.056420328099201\n",
      "epoch: 392 loss: 1.5487669706344604 grad: 2.5821198822299665\n",
      "epoch: 393 loss: 1.564734935760498 grad: 3.650276168424518\n",
      "epoch: 394 loss: 1.5561343431472778 grad: 3.826858819392411\n",
      "epoch: 395 loss: 1.5746188163757324 grad: 4.289036702777284\n",
      "epoch: 396 loss: 1.561664342880249 grad: 3.9928415803698383\n",
      "epoch: 397 loss: 1.5619072914123535 grad: 4.075325315325377\n",
      "epoch: 398 loss: 1.55670964717865 grad: 3.951655310208541\n",
      "epoch: 399 loss: 1.565708041191101 grad: 4.37947890546634\n",
      "epoch: 400 loss: 1.5520416498184204 grad: 3.7133968992526833\n",
      "epoch: 401 loss: 1.54693603515625 grad: 3.037638185266405\n",
      "epoch: 402 loss: 1.5492806434631348 grad: 4.325849155380795\n",
      "epoch: 403 loss: 1.5577210187911987 grad: 3.5848931643082387\n",
      "epoch: 404 loss: 1.5486946105957031 grad: 3.3258990404982542\n",
      "epoch: 405 loss: 1.5661852359771729 grad: 4.465043854924761\n",
      "epoch: 406 loss: 1.5477837324142456 grad: 3.5731552795337693\n",
      "epoch: 407 loss: 1.545225977897644 grad: 3.0788795942311133\n",
      "epoch: 408 loss: 1.5617328882217407 grad: 4.173759076048096\n",
      "epoch: 409 loss: 1.551976203918457 grad: 2.6164058825746803\n",
      "epoch: 410 loss: 1.542647123336792 grad: 3.4269029496694174\n",
      "epoch: 411 loss: 1.541310429573059 grad: 2.734320874915609\n",
      "epoch: 412 loss: 1.5515080690383911 grad: 3.4720851690476002\n",
      "epoch: 413 loss: 1.5592888593673706 grad: 4.071432197871085\n",
      "epoch: 414 loss: 1.5405575037002563 grad: 3.259947768507704\n",
      "epoch: 415 loss: 1.555163860321045 grad: 4.661530548077037\n",
      "epoch: 416 loss: 1.579378366470337 grad: 5.329851438345334\n",
      "epoch: 417 loss: 1.5546491146087646 grad: 4.489981836053072\n",
      "epoch: 418 loss: 1.5616662502288818 grad: 2.8203189906318165\n",
      "epoch: 419 loss: 1.5684248208999634 grad: 4.126913654622134\n",
      "epoch: 420 loss: 1.5544832944869995 grad: 3.1154367840184967\n",
      "epoch: 421 loss: 1.5589534044265747 grad: 4.215380078511733\n",
      "epoch: 422 loss: 1.545358419418335 grad: 3.1240228254685287\n",
      "epoch: 423 loss: 1.5611463785171509 grad: 3.991266936735442\n",
      "epoch: 424 loss: 1.5544843673706055 grad: 3.8915764640149106\n",
      "epoch: 425 loss: 1.547215461730957 grad: 3.4324458274933947\n",
      "epoch: 426 loss: 1.5555769205093384 grad: 2.932742082701795\n",
      "epoch: 427 loss: 1.5472302436828613 grad: 3.378141237210852\n",
      "epoch: 428 loss: 1.5432426929473877 grad: 3.773662415037161\n",
      "epoch: 429 loss: 1.5589118003845215 grad: 4.065550732715741\n",
      "epoch: 430 loss: 1.5712591409683228 grad: 4.744248639495741\n",
      "epoch: 431 loss: 1.556351900100708 grad: 3.9297727172923884\n",
      "epoch: 432 loss: 1.5684410333633423 grad: 5.17645324098058\n",
      "epoch: 433 loss: 1.5660386085510254 grad: 4.359494846156868\n",
      "epoch: 434 loss: 1.5658425092697144 grad: 4.2522669261890895\n",
      "epoch: 435 loss: 1.5585992336273193 grad: 3.7956727782265487\n",
      "epoch: 436 loss: 1.5390188694000244 grad: 3.3766861225373046\n",
      "epoch: 437 loss: 1.5435889959335327 grad: 2.8127178851452186\n",
      "epoch: 438 loss: 1.554945707321167 grad: 2.887310095816225\n",
      "epoch: 439 loss: 1.5465705394744873 grad: 2.8262404355660893\n",
      "epoch: 440 loss: 1.5418916940689087 grad: 2.958952544464505\n",
      "epoch: 441 loss: 1.5621131658554077 grad: 4.123376369708642\n",
      "epoch: 442 loss: 1.560497760772705 grad: 4.342858126363058\n",
      "epoch: 443 loss: 1.5470082759857178 grad: 2.8943268063056116\n",
      "epoch: 444 loss: 1.5484411716461182 grad: 3.463454758769359\n",
      "epoch: 445 loss: 1.5497323274612427 grad: 3.09397350357352\n",
      "epoch: 446 loss: 1.545693278312683 grad: 3.7832384825622163\n",
      "epoch: 447 loss: 1.5575172901153564 grad: 3.67210596989205\n",
      "epoch: 448 loss: 1.5494076013565063 grad: 3.356135192425086\n",
      "epoch: 449 loss: 1.5484288930892944 grad: 2.722811909708059\n",
      "epoch: 450 loss: 1.5560251474380493 grad: 4.313102825033071\n",
      "epoch: 451 loss: 1.561609148979187 grad: 4.146446007363274\n",
      "epoch: 452 loss: 1.5600826740264893 grad: 3.9050016503414784\n",
      "epoch: 453 loss: 1.5739113092422485 grad: 6.126355924507216\n",
      "epoch: 454 loss: 1.5694717168807983 grad: 3.561599661448706\n",
      "epoch: 455 loss: 1.5710880756378174 grad: 3.5330235440182642\n",
      "epoch: 456 loss: 1.552372694015503 grad: 3.8964321854260464\n",
      "epoch: 457 loss: 1.5477840900421143 grad: 4.263590682653359\n",
      "epoch: 458 loss: 1.5589174032211304 grad: 4.572693489312126\n",
      "epoch: 459 loss: 1.5571266412734985 grad: 3.1684784389457965\n",
      "epoch: 460 loss: 1.5523041486740112 grad: 4.677080054318788\n",
      "epoch: 461 loss: 1.5612760782241821 grad: 3.2919938161783\n",
      "epoch: 462 loss: 1.5485389232635498 grad: 4.263286396606824\n",
      "epoch: 463 loss: 1.5641567707061768 grad: 3.790303513531077\n",
      "epoch: 464 loss: 1.5789282321929932 grad: 3.769368252232326\n",
      "epoch: 465 loss: 1.5580790042877197 grad: 4.434080749908135\n",
      "epoch: 466 loss: 1.5596855878829956 grad: 3.107417349914162\n",
      "epoch: 467 loss: 1.5612921714782715 grad: 4.6283408243105075\n",
      "epoch: 468 loss: 1.5540368556976318 grad: 3.6660379300728745\n",
      "epoch: 469 loss: 1.5393258333206177 grad: 3.299943254394878\n",
      "epoch: 470 loss: 1.5435216426849365 grad: 2.3564127936471753\n",
      "epoch: 471 loss: 1.5423420667648315 grad: 3.860773765506371\n",
      "epoch: 472 loss: 1.5485378503799438 grad: 3.147760451001789\n",
      "epoch: 473 loss: 1.5425761938095093 grad: 3.3408433819367738\n",
      "epoch: 474 loss: 1.5331076383590698 grad: 3.3649724588274337\n",
      "epoch: 475 loss: 1.5518276691436768 grad: 4.401446160359085\n",
      "epoch: 476 loss: 1.5416392087936401 grad: 3.4164630744757747\n",
      "epoch: 477 loss: 1.5490728616714478 grad: 4.743488777364361\n",
      "epoch: 478 loss: 1.5564464330673218 grad: 3.6303435606695804\n",
      "epoch: 479 loss: 1.5671131610870361 grad: 3.708914683329158\n",
      "epoch: 480 loss: 1.5414704084396362 grad: 3.206701421710057\n",
      "epoch: 481 loss: 1.5432718992233276 grad: 2.9147200437590626\n",
      "epoch: 482 loss: 1.544641375541687 grad: 4.234979389516374\n",
      "epoch: 483 loss: 1.5413399934768677 grad: 2.752331137859602\n",
      "epoch: 484 loss: 1.541099190711975 grad: 3.021157625011272\n",
      "epoch: 485 loss: 1.5500417947769165 grad: 3.5776161446865617\n",
      "epoch: 486 loss: 1.544625163078308 grad: 3.4268088096927354\n",
      "epoch: 487 loss: 1.5519412755966187 grad: 4.457034466760002\n",
      "epoch: 488 loss: 1.5768901109695435 grad: 4.619270523819816\n",
      "epoch: 489 loss: 1.5470457077026367 grad: 1.9848104335820052\n",
      "epoch: 490 loss: 1.5524120330810547 grad: 3.9891093469674033\n",
      "epoch: 491 loss: 1.5764399766921997 grad: 3.4246671998126805\n",
      "epoch: 492 loss: 1.5623679161071777 grad: 2.671170090631554\n",
      "epoch: 493 loss: 1.555382251739502 grad: 3.162067227439293\n",
      "epoch: 494 loss: 1.5438833236694336 grad: 2.775052469477475\n",
      "epoch: 495 loss: 1.554428219795227 grad: 3.1569323621696905\n",
      "epoch: 496 loss: 1.562333106994629 grad: 3.6016760520455224\n",
      "epoch: 497 loss: 1.5750948190689087 grad: 5.111406032888691\n",
      "epoch: 498 loss: 1.5515443086624146 grad: 4.271834581930487\n",
      "epoch: 499 loss: 1.5422966480255127 grad: 2.773660000980598\n",
      "1.9210520461201668\n",
      "epoch: 0 loss: 2.3028688430786133 grad: 1.3682983129466366\n",
      "epoch: 1 loss: 2.3023085594177246 grad: 1.3719511643211018\n",
      "epoch: 2 loss: 2.3027918338775635 grad: 1.3609702497691152\n",
      "epoch: 3 loss: 2.3033275604248047 grad: 1.359668637089993\n",
      "epoch: 4 loss: 2.3026392459869385 grad: 1.3547902043044036\n",
      "epoch: 5 loss: 2.3030405044555664 grad: 1.3596500182498454\n",
      "epoch: 6 loss: 2.3020882606506348 grad: 1.378273650408826\n",
      "epoch: 7 loss: 2.302929162979126 grad: 1.3641554761829504\n",
      "epoch: 8 loss: 2.3025193214416504 grad: 1.378421983642814\n",
      "epoch: 9 loss: 2.3022208213806152 grad: 1.364088123904482\n",
      "epoch: 10 loss: 2.3029556274414062 grad: 1.3664448251578187\n",
      "epoch: 11 loss: 2.302988290786743 grad: 1.365226776159871\n",
      "epoch: 12 loss: 2.3030686378479004 grad: 1.355114488138093\n",
      "epoch: 13 loss: 2.3032615184783936 grad: 1.3702284138509264\n",
      "epoch: 14 loss: 2.30248761177063 grad: 1.3659199413784322\n",
      "epoch: 15 loss: 2.3032913208007812 grad: 1.3631484493140191\n",
      "epoch: 16 loss: 2.3025894165039062 grad: 1.366590022227712\n",
      "epoch: 17 loss: 2.302731990814209 grad: 1.3801635518662692\n",
      "epoch: 18 loss: 2.3036255836486816 grad: 1.355194374283273\n",
      "epoch: 19 loss: 2.302659034729004 grad: 1.3708945153029783\n",
      "epoch: 20 loss: 2.3032147884368896 grad: 1.3602070963353894\n",
      "epoch: 21 loss: 2.3026866912841797 grad: 1.359366162672698\n",
      "epoch: 22 loss: 2.3031444549560547 grad: 1.3557722928142915\n",
      "epoch: 23 loss: 2.302652359008789 grad: 1.3710036034740152\n",
      "epoch: 24 loss: 2.3021605014801025 grad: 1.3712056297771928\n",
      "epoch: 25 loss: 2.3030824661254883 grad: 1.3607574363335198\n",
      "epoch: 26 loss: 2.3030316829681396 grad: 1.3627336110165786\n",
      "epoch: 27 loss: 2.3027985095977783 grad: 1.368499998812608\n",
      "epoch: 28 loss: 2.302403211593628 grad: 1.3709667192786814\n",
      "epoch: 29 loss: 2.3024983406066895 grad: 1.3721649688613113\n",
      "epoch: 30 loss: 2.30277156829834 grad: 1.3725059869965273\n",
      "epoch: 31 loss: 2.3030169010162354 grad: 1.361594239940926\n",
      "epoch: 32 loss: 2.3026394844055176 grad: 1.3690876703365662\n",
      "epoch: 33 loss: 2.302978038787842 grad: 1.358393341877557\n",
      "epoch: 34 loss: 2.3030097484588623 grad: 1.3545213891525887\n",
      "epoch: 35 loss: 2.3022782802581787 grad: 1.3790965186605704\n",
      "epoch: 36 loss: 2.302125930786133 grad: 1.3700783307967146\n",
      "epoch: 37 loss: 2.3030312061309814 grad: 1.3662141564464758\n",
      "epoch: 38 loss: 2.3027610778808594 grad: 1.3637088194215996\n",
      "epoch: 39 loss: 2.3022313117980957 grad: 1.3741618213539442\n",
      "epoch: 40 loss: 2.3023717403411865 grad: 1.3702156800270406\n",
      "epoch: 41 loss: 2.303605794906616 grad: 1.3454711917318434\n",
      "epoch: 42 loss: 2.3029122352600098 grad: 1.3582457008786382\n",
      "epoch: 43 loss: 2.3027029037475586 grad: 1.3587437523177839\n",
      "epoch: 44 loss: 2.302833318710327 grad: 1.365580345019846\n",
      "epoch: 45 loss: 2.302138328552246 grad: 1.3684059197659648\n",
      "epoch: 46 loss: 2.302400827407837 grad: 1.3679840591355479\n",
      "epoch: 47 loss: 2.302520751953125 grad: 1.3698501007442938\n",
      "epoch: 48 loss: 2.3027853965759277 grad: 1.357927216697366\n",
      "epoch: 49 loss: 2.3023576736450195 grad: 1.3822621148752257\n",
      "epoch: 50 loss: 2.3021023273468018 grad: 1.3723679904785333\n",
      "epoch: 51 loss: 2.3024418354034424 grad: 1.3687627160559512\n",
      "epoch: 52 loss: 2.302755355834961 grad: 1.3759234701800678\n",
      "epoch: 53 loss: 2.302844762802124 grad: 1.3592987589885495\n",
      "epoch: 54 loss: 2.3027918338775635 grad: 1.3576837629079819\n",
      "epoch: 55 loss: 2.302489757537842 grad: 1.3656174540187098\n",
      "epoch: 56 loss: 2.302673101425171 grad: 1.36029306409644\n",
      "epoch: 57 loss: 2.302427291870117 grad: 1.3644318683331624\n",
      "epoch: 58 loss: 2.3029727935791016 grad: 1.357258347883111\n",
      "epoch: 59 loss: 2.303661346435547 grad: 1.352379400623105\n",
      "epoch: 60 loss: 2.302818536758423 grad: 1.3710415450309121\n",
      "epoch: 61 loss: 2.3029000759124756 grad: 1.3568931875754118\n",
      "epoch: 62 loss: 2.3029234409332275 grad: 1.3551827409888604\n",
      "epoch: 63 loss: 2.3032069206237793 grad: 1.3577710814193809\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 64 loss: 2.3022286891937256 grad: 1.376965292518781\n",
      "epoch: 65 loss: 2.303286075592041 grad: 1.346126798122737\n",
      "epoch: 66 loss: 2.3024096488952637 grad: 1.3583712758097266\n",
      "epoch: 67 loss: 2.3025753498077393 grad: 1.3549181044726293\n",
      "epoch: 68 loss: 2.3024044036865234 grad: 1.3702344678782135\n",
      "epoch: 69 loss: 2.3024630546569824 grad: 1.3642340571756313\n",
      "epoch: 70 loss: 2.302332639694214 grad: 1.3746691872846217\n",
      "epoch: 71 loss: 2.3027665615081787 grad: 1.3549286524972155\n",
      "epoch: 72 loss: 2.3032097816467285 grad: 1.3446627379605725\n",
      "epoch: 73 loss: 2.3022842407226562 grad: 1.3619486934039742\n",
      "epoch: 74 loss: 2.3026347160339355 grad: 1.360355142433758\n",
      "epoch: 75 loss: 2.302896499633789 grad: 1.3597513582365262\n",
      "epoch: 76 loss: 2.302903652191162 grad: 1.3561941387227898\n",
      "epoch: 77 loss: 2.302551746368408 grad: 1.3686112223492404\n",
      "epoch: 78 loss: 2.3023695945739746 grad: 1.3665940601818471\n",
      "epoch: 79 loss: 2.3025383949279785 grad: 1.3663362792548945\n",
      "epoch: 80 loss: 2.3028318881988525 grad: 1.354086489318722\n",
      "epoch: 81 loss: 2.3028581142425537 grad: 1.361831076151233\n",
      "epoch: 82 loss: 2.302428722381592 grad: 1.3717713986767368\n",
      "epoch: 83 loss: 2.3028459548950195 grad: 1.351552290642368\n",
      "epoch: 84 loss: 2.3021950721740723 grad: 1.3708170436744003\n",
      "epoch: 85 loss: 2.3021152019500732 grad: 1.3659971283974186\n",
      "epoch: 86 loss: 2.302551031112671 grad: 1.372068157922181\n",
      "epoch: 87 loss: 2.302130699157715 grad: 1.3721575724914492\n",
      "epoch: 88 loss: 2.302615165710449 grad: 1.3644394992725066\n",
      "epoch: 89 loss: 2.3018620014190674 grad: 1.3720681790709643\n",
      "epoch: 90 loss: 2.302635669708252 grad: 1.3540602084526436\n",
      "epoch: 91 loss: 2.302496910095215 grad: 1.3615160321258748\n",
      "epoch: 92 loss: 2.302574872970581 grad: 1.367877935229372\n",
      "epoch: 93 loss: 2.303098201751709 grad: 1.3562289716358045\n",
      "epoch: 94 loss: 2.302640676498413 grad: 1.3664431712601246\n",
      "epoch: 95 loss: 2.3026599884033203 grad: 1.362254414548506\n",
      "epoch: 96 loss: 2.3021533489227295 grad: 1.361204222945999\n",
      "epoch: 97 loss: 2.3022444248199463 grad: 1.3642213221543307\n",
      "epoch: 98 loss: 2.3021340370178223 grad: 1.3768824549938834\n",
      "epoch: 99 loss: 2.3025147914886475 grad: 1.355816115728683\n",
      "epoch: 100 loss: 2.302520990371704 grad: 1.3612791141938596\n",
      "epoch: 101 loss: 2.3026511669158936 grad: 1.3694522001370344\n",
      "epoch: 102 loss: 2.302736282348633 grad: 1.3540910067912635\n",
      "epoch: 103 loss: 2.3032965660095215 grad: 1.3566960139377486\n",
      "epoch: 104 loss: 2.3026797771453857 grad: 1.3628264845788687\n",
      "epoch: 105 loss: 2.302079439163208 grad: 1.3768392366242581\n",
      "epoch: 106 loss: 2.3019347190856934 grad: 1.3771115907612035\n",
      "epoch: 107 loss: 2.3024637699127197 grad: 1.3635248568274878\n",
      "epoch: 108 loss: 2.3025474548339844 grad: 1.3589768912901894\n",
      "epoch: 109 loss: 2.3024494647979736 grad: 1.3805618707445406\n",
      "epoch: 110 loss: 2.302480697631836 grad: 1.3698431962273188\n",
      "epoch: 111 loss: 2.302635669708252 grad: 1.3666086095451777\n",
      "epoch: 112 loss: 2.3027095794677734 grad: 1.3577911718286544\n",
      "epoch: 113 loss: 2.3022336959838867 grad: 1.35410364788203\n",
      "epoch: 114 loss: 2.3026719093322754 grad: 1.3595491044190047\n",
      "epoch: 115 loss: 2.3016529083251953 grad: 1.3697579247019593\n",
      "epoch: 116 loss: 2.301332712173462 grad: 1.3817012772640391\n",
      "epoch: 117 loss: 2.3022868633270264 grad: 1.3626702684716927\n",
      "epoch: 118 loss: 2.3017947673797607 grad: 1.3671987277847375\n",
      "epoch: 119 loss: 2.3019070625305176 grad: 1.3711742327108771\n",
      "epoch: 120 loss: 2.3024890422821045 grad: 1.3608111203685107\n",
      "epoch: 121 loss: 2.302211046218872 grad: 1.368316201493144\n",
      "epoch: 122 loss: 2.301894187927246 grad: 1.3820513118472364\n",
      "epoch: 123 loss: 2.301985025405884 grad: 1.3773931281988523\n",
      "epoch: 124 loss: 2.30228328704834 grad: 1.37346197717217\n",
      "epoch: 125 loss: 2.3024117946624756 grad: 1.3607918853051073\n",
      "epoch: 126 loss: 2.302032947540283 grad: 1.3746858117104108\n",
      "epoch: 127 loss: 2.3020412921905518 grad: 1.377502061768494\n",
      "epoch: 128 loss: 2.3021535873413086 grad: 1.3804984788986898\n",
      "epoch: 129 loss: 2.3023767471313477 grad: 1.3650003706182663\n",
      "epoch: 130 loss: 2.302638530731201 grad: 1.3753933776465674\n",
      "epoch: 131 loss: 2.3021199703216553 grad: 1.3750460018950796\n",
      "epoch: 132 loss: 2.301393747329712 grad: 1.3879151043836915\n",
      "epoch: 133 loss: 2.302589178085327 grad: 1.363427742748403\n",
      "epoch: 134 loss: 2.302570343017578 grad: 1.3687810645852652\n",
      "epoch: 135 loss: 2.302189826965332 grad: 1.3732668779871708\n",
      "epoch: 136 loss: 2.3024251461029053 grad: 1.376301584321828\n",
      "epoch: 137 loss: 2.3021183013916016 grad: 1.3801601825888077\n",
      "epoch: 138 loss: 2.301938056945801 grad: 1.3827125373340787\n",
      "epoch: 139 loss: 2.30222749710083 grad: 1.3731808148856675\n",
      "epoch: 140 loss: 2.3020100593566895 grad: 1.3800565790725015\n",
      "epoch: 141 loss: 2.3019473552703857 grad: 1.3644885439074612\n",
      "epoch: 142 loss: 2.3022313117980957 grad: 1.3726241473673977\n",
      "epoch: 143 loss: 2.3022687435150146 grad: 1.3740161360825398\n",
      "epoch: 144 loss: 2.3015506267547607 grad: 1.3917293728380982\n",
      "epoch: 145 loss: 2.3020551204681396 grad: 1.3843129519096\n",
      "epoch: 146 loss: 2.3024864196777344 grad: 1.361479709011739\n",
      "epoch: 147 loss: 2.3019614219665527 grad: 1.3771051242060603\n",
      "epoch: 148 loss: 2.3027191162109375 grad: 1.3697309204329189\n",
      "epoch: 149 loss: 2.3018815517425537 grad: 1.3720982729656888\n",
      "epoch: 150 loss: 2.3024606704711914 grad: 1.3630971123080051\n",
      "epoch: 151 loss: 2.3025498390197754 grad: 1.3689602695050693\n",
      "epoch: 152 loss: 2.3028969764709473 grad: 1.3716017513883314\n",
      "epoch: 153 loss: 2.302029848098755 grad: 1.3752523455103594\n",
      "epoch: 154 loss: 2.3017170429229736 grad: 1.3791605575039747\n",
      "epoch: 155 loss: 2.302110433578491 grad: 1.3831296926216474\n",
      "epoch: 156 loss: 2.302368402481079 grad: 1.3737865103859572\n",
      "epoch: 157 loss: 2.301891326904297 grad: 1.3682566479380642\n",
      "epoch: 158 loss: 2.301412582397461 grad: 1.3953884142591426\n",
      "epoch: 159 loss: 2.3026275634765625 grad: 1.363438398348138\n",
      "epoch: 160 loss: 2.30245304107666 grad: 1.3770518688418503\n",
      "epoch: 161 loss: 2.3018245697021484 grad: 1.376685364086861\n",
      "epoch: 162 loss: 2.301823854446411 grad: 1.3789700749884581\n",
      "epoch: 163 loss: 2.3021886348724365 grad: 1.3826760954356618\n",
      "epoch: 164 loss: 2.302448272705078 grad: 1.3730436436377378\n",
      "epoch: 165 loss: 2.3022732734680176 grad: 1.3718080968884308\n",
      "epoch: 166 loss: 2.3021793365478516 grad: 1.3799382976167613\n",
      "epoch: 167 loss: 2.30228590965271 grad: 1.3805261811016067\n",
      "epoch: 168 loss: 2.302579641342163 grad: 1.3796577716065157\n",
      "epoch: 169 loss: 2.302546501159668 grad: 1.3791564548099857\n",
      "epoch: 170 loss: 2.3018603324890137 grad: 1.3817350415601617\n",
      "epoch: 171 loss: 2.3021419048309326 grad: 1.381992587195118\n",
      "epoch: 172 loss: 2.302098035812378 grad: 1.3875605321696236\n",
      "epoch: 173 loss: 2.302888870239258 grad: 1.3677289250365916\n",
      "epoch: 174 loss: 2.30236554145813 grad: 1.3820632680851435\n",
      "epoch: 175 loss: 2.3023464679718018 grad: 1.3867528213498492\n",
      "epoch: 176 loss: 2.3014023303985596 grad: 1.3917000658240997\n",
      "epoch: 177 loss: 2.3025121688842773 grad: 1.3775852465861669\n",
      "epoch: 178 loss: 2.3023126125335693 grad: 1.371100750690814\n",
      "epoch: 179 loss: 2.302093505859375 grad: 1.3810617215857501\n",
      "epoch: 180 loss: 2.3021068572998047 grad: 1.3733815795682844\n",
      "epoch: 181 loss: 2.3023555278778076 grad: 1.3681706093078005\n",
      "epoch: 182 loss: 2.301874876022339 grad: 1.3894443673392136\n",
      "epoch: 183 loss: 2.301729917526245 grad: 1.3945042026997914\n",
      "epoch: 184 loss: 2.3017501831054688 grad: 1.379572154493958\n",
      "epoch: 185 loss: 2.3019983768463135 grad: 1.3875521145103173\n",
      "epoch: 186 loss: 2.3016042709350586 grad: 1.3941317116250358\n",
      "epoch: 187 loss: 2.301828384399414 grad: 1.3927160420636129\n",
      "epoch: 188 loss: 2.3015167713165283 grad: 1.3877014699576806\n",
      "epoch: 189 loss: 2.301647186279297 grad: 1.388442592904164\n",
      "epoch: 190 loss: 2.3017449378967285 grad: 1.4033241675878387\n",
      "epoch: 191 loss: 2.3012664318084717 grad: 1.4067487773552005\n",
      "epoch: 192 loss: 2.301501512527466 grad: 1.4126252982828265\n",
      "epoch: 193 loss: 2.3013641834259033 grad: 1.3943692513349806\n",
      "epoch: 194 loss: 2.302105188369751 grad: 1.3823580565596265\n",
      "epoch: 195 loss: 2.301978588104248 grad: 1.3999319337474714\n",
      "epoch: 196 loss: 2.3018925189971924 grad: 1.3860688631123463\n",
      "epoch: 197 loss: 2.3021433353424072 grad: 1.394557774591718\n",
      "epoch: 198 loss: 2.301708221435547 grad: 1.3855061601618275\n",
      "epoch: 199 loss: 2.302396059036255 grad: 1.3876440157422736\n",
      "epoch: 200 loss: 2.302253246307373 grad: 1.3847248329880781\n",
      "epoch: 201 loss: 2.3016180992126465 grad: 1.3995329812150596\n",
      "epoch: 202 loss: 2.301323413848877 grad: 1.4105188653541965\n",
      "epoch: 203 loss: 2.3023877143859863 grad: 1.383349888662379\n",
      "epoch: 204 loss: 2.301985502243042 grad: 1.3943877644293632\n",
      "epoch: 205 loss: 2.300874948501587 grad: 1.4062297283579404\n",
      "epoch: 206 loss: 2.3022258281707764 grad: 1.38246730395541\n",
      "epoch: 207 loss: 2.3013226985931396 grad: 1.406456003560581\n",
      "epoch: 208 loss: 2.300987482070923 grad: 1.4081029585185683\n",
      "epoch: 209 loss: 2.30258846282959 grad: 1.389589062228518\n",
      "epoch: 210 loss: 2.3020262718200684 grad: 1.3863075963232578\n",
      "epoch: 211 loss: 2.301417827606201 grad: 1.412472724293669\n",
      "epoch: 212 loss: 2.301804542541504 grad: 1.4058204277156157\n",
      "epoch: 213 loss: 2.301466464996338 grad: 1.4183953194121373\n",
      "epoch: 214 loss: 2.302746295928955 grad: 1.3928339646035244\n",
      "epoch: 215 loss: 2.3026912212371826 grad: 1.3846405241897122\n",
      "epoch: 216 loss: 2.30149507522583 grad: 1.4080497799589047\n",
      "epoch: 217 loss: 2.302135944366455 grad: 1.3917012507768556\n",
      "epoch: 218 loss: 2.3010025024414062 grad: 1.40776032136221\n",
      "epoch: 219 loss: 2.3021888732910156 grad: 1.4019637817871713\n",
      "epoch: 220 loss: 2.3011720180511475 grad: 1.416284539875397\n",
      "epoch: 221 loss: 2.3010032176971436 grad: 1.4161124900279065\n",
      "epoch: 222 loss: 2.3016252517700195 grad: 1.4118355005621053\n",
      "epoch: 223 loss: 2.301354169845581 grad: 1.4027020717409278\n",
      "epoch: 224 loss: 2.3015894889831543 grad: 1.4124105473544213\n",
      "epoch: 225 loss: 2.3007307052612305 grad: 1.4212606848653642\n",
      "epoch: 226 loss: 2.3019158840179443 grad: 1.405993679715764\n",
      "epoch: 227 loss: 2.301189422607422 grad: 1.406461455576521\n",
      "epoch: 228 loss: 2.3013927936553955 grad: 1.420264128442218\n",
      "epoch: 229 loss: 2.3012678623199463 grad: 1.4144726921102062\n",
      "epoch: 230 loss: 2.3018808364868164 grad: 1.4182561121969706\n",
      "epoch: 231 loss: 2.3014681339263916 grad: 1.4111323089704715\n",
      "epoch: 232 loss: 2.3006880283355713 grad: 1.4352628582467635\n",
      "epoch: 233 loss: 2.301703691482544 grad: 1.4122107453599928\n",
      "epoch: 234 loss: 2.3013510704040527 grad: 1.428891531971564\n",
      "epoch: 235 loss: 2.3015694618225098 grad: 1.425148860307499\n",
      "epoch: 236 loss: 2.301194190979004 grad: 1.427115013824761\n",
      "epoch: 237 loss: 2.301240921020508 grad: 1.445233465514205\n",
      "epoch: 238 loss: 2.3019630908966064 grad: 1.4195036816407025\n",
      "epoch: 239 loss: 2.301081418991089 grad: 1.429364200640795\n",
      "epoch: 240 loss: 2.301218032836914 grad: 1.4326395713687239\n",
      "epoch: 241 loss: 2.301098108291626 grad: 1.4323445136717978\n",
      "epoch: 242 loss: 2.300839424133301 grad: 1.4553463482020779\n",
      "epoch: 243 loss: 2.301729917526245 grad: 1.4132416315454368\n",
      "epoch: 244 loss: 2.300949811935425 grad: 1.4446650302214992\n",
      "epoch: 245 loss: 2.3014211654663086 grad: 1.4482165565899026\n",
      "epoch: 246 loss: 2.3018362522125244 grad: 1.4230766114926645\n",
      "epoch: 247 loss: 2.3006250858306885 grad: 1.453637142118717\n",
      "epoch: 248 loss: 2.301051139831543 grad: 1.4466446989182649\n",
      "epoch: 249 loss: 2.301499605178833 grad: 1.441205886137184\n",
      "epoch: 250 loss: 2.301783561706543 grad: 1.4416349328692175\n",
      "epoch: 251 loss: 2.3003287315368652 grad: 1.4528758527788643\n",
      "epoch: 252 loss: 2.3013405799865723 grad: 1.4276214359339239\n",
      "epoch: 253 loss: 2.301011323928833 grad: 1.4399452602439042\n",
      "epoch: 254 loss: 2.301243543624878 grad: 1.442495926468086\n",
      "epoch: 255 loss: 2.3007349967956543 grad: 1.4479569796313871\n",
      "epoch: 256 loss: 2.30086350440979 grad: 1.4367172357345384\n",
      "epoch: 257 loss: 2.3007099628448486 grad: 1.4505983107752862\n",
      "epoch: 258 loss: 2.300546646118164 grad: 1.4402564404059262\n",
      "epoch: 259 loss: 2.3011834621429443 grad: 1.4526180326606013\n",
      "epoch: 260 loss: 2.3002395629882812 grad: 1.4642986593313427\n",
      "epoch: 261 loss: 2.3008131980895996 grad: 1.46177031463086\n",
      "epoch: 262 loss: 2.300387144088745 grad: 1.4571167430138245\n",
      "epoch: 263 loss: 2.3010900020599365 grad: 1.4572211343957673\n",
      "epoch: 264 loss: 2.300919532775879 grad: 1.4550934896937437\n",
      "epoch: 265 loss: 2.301110029220581 grad: 1.4566988517633743\n",
      "epoch: 266 loss: 2.3006246089935303 grad: 1.471061837334659\n",
      "epoch: 267 loss: 2.3010332584381104 grad: 1.4702098149111464\n",
      "epoch: 268 loss: 2.301063060760498 grad: 1.460235008860879\n",
      "epoch: 269 loss: 2.300187826156616 grad: 1.4835188371491514\n",
      "epoch: 270 loss: 2.300867795944214 grad: 1.4687697045534613\n",
      "epoch: 271 loss: 2.3013055324554443 grad: 1.4676157891351198\n",
      "epoch: 272 loss: 2.3000385761260986 grad: 1.4886054530266732\n",
      "epoch: 273 loss: 2.300790786743164 grad: 1.4704000415864387\n",
      "epoch: 274 loss: 2.3008921146392822 grad: 1.483699046197303\n",
      "epoch: 275 loss: 2.3006861209869385 grad: 1.48422715055298\n",
      "epoch: 276 loss: 2.2998476028442383 grad: 1.488238277985522\n",
      "epoch: 277 loss: 2.301184892654419 grad: 1.457907022841807\n",
      "epoch: 278 loss: 2.2999250888824463 grad: 1.4882221987419244\n",
      "epoch: 279 loss: 2.300816774368286 grad: 1.4643896016151836\n",
      "epoch: 280 loss: 2.300656318664551 grad: 1.4835336960238656\n",
      "epoch: 281 loss: 2.300114870071411 grad: 1.4975687001743132\n",
      "epoch: 282 loss: 2.3006887435913086 grad: 1.4869593974417223\n",
      "epoch: 283 loss: 2.3003695011138916 grad: 1.4846053902015446\n",
      "epoch: 284 loss: 2.3008999824523926 grad: 1.4836495815746722\n",
      "epoch: 285 loss: 2.300811290740967 grad: 1.4984001315139708\n",
      "epoch: 286 loss: 2.2999985218048096 grad: 1.4963053799112371\n",
      "epoch: 287 loss: 2.300863742828369 grad: 1.4765714400130072\n",
      "epoch: 288 loss: 2.2997798919677734 grad: 1.5052798451996217\n",
      "epoch: 289 loss: 2.3005800247192383 grad: 1.496907218008317\n",
      "epoch: 290 loss: 2.3003180027008057 grad: 1.5074102814745394\n",
      "epoch: 291 loss: 2.3000781536102295 grad: 1.5184726619072968\n",
      "epoch: 292 loss: 2.3005621433258057 grad: 1.4964287221073247\n",
      "epoch: 293 loss: 2.300299644470215 grad: 1.5239362090656032\n",
      "epoch: 294 loss: 2.300356149673462 grad: 1.5228986796435147\n",
      "epoch: 295 loss: 2.3003716468811035 grad: 1.5107452414360725\n",
      "epoch: 296 loss: 2.300140857696533 grad: 1.5102463694888033\n",
      "epoch: 297 loss: 2.300044536590576 grad: 1.4980110314615545\n",
      "epoch: 298 loss: 2.29994535446167 grad: 1.514066099898801\n",
      "epoch: 299 loss: 2.300574541091919 grad: 1.519320862369597\n",
      "epoch: 300 loss: 2.2999467849731445 grad: 1.5042827285637723\n",
      "epoch: 301 loss: 2.300114393234253 grad: 1.5237301128051643\n",
      "epoch: 302 loss: 2.3002102375030518 grad: 1.5147972598797568\n",
      "epoch: 303 loss: 2.300565242767334 grad: 1.5245871616579179\n",
      "epoch: 304 loss: 2.3006021976470947 grad: 1.528851001431042\n",
      "epoch: 305 loss: 2.2998766899108887 grad: 1.5418004771834979\n",
      "epoch: 306 loss: 2.299936056137085 grad: 1.5366905153699455\n",
      "epoch: 307 loss: 2.3000354766845703 grad: 1.5316103532030765\n",
      "epoch: 308 loss: 2.3000986576080322 grad: 1.53878574557085\n",
      "epoch: 309 loss: 2.300567626953125 grad: 1.5326789362089974\n",
      "epoch: 310 loss: 2.3003973960876465 grad: 1.5109655109256328\n",
      "epoch: 311 loss: 2.300083875656128 grad: 1.540492222411558\n",
      "epoch: 312 loss: 2.299910068511963 grad: 1.529081224330834\n",
      "epoch: 313 loss: 2.2996602058410645 grad: 1.5482643475600828\n",
      "epoch: 314 loss: 2.2993550300598145 grad: 1.5454770083860716\n",
      "epoch: 315 loss: 2.2998762130737305 grad: 1.5565219268180608\n",
      "epoch: 316 loss: 2.299715042114258 grad: 1.5491820276781385\n",
      "epoch: 317 loss: 2.300041675567627 grad: 1.541947357373179\n",
      "epoch: 318 loss: 2.299119472503662 grad: 1.565706534503353\n",
      "epoch: 319 loss: 2.299528121948242 grad: 1.5717801767039217\n",
      "epoch: 320 loss: 2.299574613571167 grad: 1.5513082661052486\n",
      "epoch: 321 loss: 2.2987568378448486 grad: 1.5851526309806292\n",
      "epoch: 322 loss: 2.2999720573425293 grad: 1.5539402757542178\n",
      "epoch: 323 loss: 2.2986772060394287 grad: 1.6069912665656634\n",
      "epoch: 324 loss: 2.3000712394714355 grad: 1.551031932020412\n",
      "epoch: 325 loss: 2.3005292415618896 grad: 1.5486272149054068\n",
      "epoch: 326 loss: 2.299670696258545 grad: 1.5777228273828292\n",
      "epoch: 327 loss: 2.2989742755889893 grad: 1.5876441498708336\n",
      "epoch: 328 loss: 2.299191474914551 grad: 1.5962342227003463\n",
      "epoch: 329 loss: 2.300096035003662 grad: 1.5738939879913\n",
      "epoch: 330 loss: 2.298985481262207 grad: 1.5803575433849815\n",
      "epoch: 331 loss: 2.2998366355895996 grad: 1.5741639983108533\n",
      "epoch: 332 loss: 2.2992935180664062 grad: 1.579560242103605\n",
      "epoch: 333 loss: 2.300034999847412 grad: 1.5664054704312649\n",
      "epoch: 334 loss: 2.299208402633667 grad: 1.5983464609229168\n",
      "epoch: 335 loss: 2.298982858657837 grad: 1.616189751877553\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 336 loss: 2.299412965774536 grad: 1.612311189805734\n",
      "epoch: 337 loss: 2.2982888221740723 grad: 1.6145697544894315\n",
      "epoch: 338 loss: 2.2992565631866455 grad: 1.6108147333753073\n",
      "epoch: 339 loss: 2.2990972995758057 grad: 1.6019101191555993\n",
      "epoch: 340 loss: 2.2990057468414307 grad: 1.6138605470843022\n",
      "epoch: 341 loss: 2.2983596324920654 grad: 1.6223850677950338\n",
      "epoch: 342 loss: 2.2991740703582764 grad: 1.635853323279806\n",
      "epoch: 343 loss: 2.2989420890808105 grad: 1.6265649627118062\n",
      "epoch: 344 loss: 2.298692464828491 grad: 1.6149233203429345\n",
      "epoch: 345 loss: 2.2980244159698486 grad: 1.653739916907239\n",
      "epoch: 346 loss: 2.2986857891082764 grad: 1.644165737487908\n",
      "epoch: 347 loss: 2.2989110946655273 grad: 1.653148040012826\n",
      "epoch: 348 loss: 2.299669027328491 grad: 1.6163319321404699\n",
      "epoch: 349 loss: 2.2987422943115234 grad: 1.6285303710065486\n",
      "epoch: 350 loss: 2.2986061573028564 grad: 1.625448493102181\n",
      "epoch: 351 loss: 2.2989449501037598 grad: 1.630511368905741\n",
      "epoch: 352 loss: 2.2984158992767334 grad: 1.6306652810224997\n",
      "epoch: 353 loss: 2.299433469772339 grad: 1.6218299844730941\n",
      "epoch: 354 loss: 2.2981936931610107 grad: 1.660410181523138\n",
      "epoch: 355 loss: 2.297612190246582 grad: 1.6628242254493728\n",
      "epoch: 356 loss: 2.2972748279571533 grad: 1.6901112524903423\n",
      "epoch: 357 loss: 2.298027992248535 grad: 1.6790394204934793\n",
      "epoch: 358 loss: 2.298250675201416 grad: 1.670569720899775\n",
      "epoch: 359 loss: 2.2983205318450928 grad: 1.6629350668388523\n",
      "epoch: 360 loss: 2.2982492446899414 grad: 1.6878938380894917\n",
      "epoch: 361 loss: 2.29758620262146 grad: 1.664234086069175\n",
      "epoch: 362 loss: 2.2989203929901123 grad: 1.6668525889242394\n",
      "epoch: 363 loss: 2.298267126083374 grad: 1.6647091627505326\n",
      "epoch: 364 loss: 2.2997145652770996 grad: 1.637878432725778\n",
      "epoch: 365 loss: 2.2977817058563232 grad: 1.6623820708916774\n",
      "epoch: 366 loss: 2.298557758331299 grad: 1.6721505713612137\n",
      "epoch: 367 loss: 2.296410322189331 grad: 1.7306836781217643\n",
      "epoch: 368 loss: 2.297797679901123 grad: 1.6842827318284277\n",
      "epoch: 369 loss: 2.297379732131958 grad: 1.6956967454780603\n",
      "epoch: 370 loss: 2.2983312606811523 grad: 1.6770583809989075\n",
      "epoch: 371 loss: 2.298468589782715 grad: 1.6579683543670745\n",
      "epoch: 372 loss: 2.297393560409546 grad: 1.7030540578296438\n",
      "epoch: 373 loss: 2.297471523284912 grad: 1.7065272644653708\n",
      "epoch: 374 loss: 2.297741413116455 grad: 1.701917932073157\n",
      "epoch: 375 loss: 2.2961065769195557 grad: 1.744485586419672\n",
      "epoch: 376 loss: 2.2976369857788086 grad: 1.7309264711414774\n",
      "epoch: 377 loss: 2.298332691192627 grad: 1.701891706713165\n",
      "epoch: 378 loss: 2.2967634201049805 grad: 1.7383908889448596\n",
      "epoch: 379 loss: 2.2970399856567383 grad: 1.7580328397674574\n",
      "epoch: 380 loss: 2.297678232192993 grad: 1.7150253405173619\n",
      "epoch: 381 loss: 2.2976651191711426 grad: 1.7194468622014576\n",
      "epoch: 382 loss: 2.2967851161956787 grad: 1.7448121903571374\n",
      "epoch: 383 loss: 2.298124313354492 grad: 1.7235968296253492\n",
      "epoch: 384 loss: 2.2973828315734863 grad: 1.7265793121242452\n",
      "epoch: 385 loss: 2.2975013256073 grad: 1.7084871181065129\n",
      "epoch: 386 loss: 2.2966372966766357 grad: 1.7445233219177536\n",
      "epoch: 387 loss: 2.2966432571411133 grad: 1.7649756964251755\n",
      "epoch: 388 loss: 2.2969484329223633 grad: 1.7345902226654635\n",
      "epoch: 389 loss: 2.296509265899658 grad: 1.7413951327972528\n",
      "epoch: 390 loss: 2.2964282035827637 grad: 1.7451839474702462\n",
      "epoch: 391 loss: 2.2964353561401367 grad: 1.7457981092544894\n",
      "epoch: 392 loss: 2.295778512954712 grad: 1.7913159974887671\n",
      "epoch: 393 loss: 2.296215534210205 grad: 1.7656227006070642\n",
      "epoch: 394 loss: 2.297135591506958 grad: 1.7590040485928988\n",
      "epoch: 395 loss: 2.2968342304229736 grad: 1.7491087841779172\n",
      "epoch: 396 loss: 2.296574354171753 grad: 1.7693716893582383\n",
      "epoch: 397 loss: 2.295757293701172 grad: 1.7876745285872844\n",
      "epoch: 398 loss: 2.296544313430786 grad: 1.7561977576327672\n",
      "epoch: 399 loss: 2.2965285778045654 grad: 1.7748200654399595\n",
      "epoch: 400 loss: 2.2965826988220215 grad: 1.764622365993019\n",
      "epoch: 401 loss: 2.2955095767974854 grad: 1.806274229542367\n",
      "epoch: 402 loss: 2.2969534397125244 grad: 1.7810271613536373\n",
      "epoch: 403 loss: 2.297106981277466 grad: 1.770949367589007\n",
      "epoch: 404 loss: 2.295503616333008 grad: 1.8146839117934366\n",
      "epoch: 405 loss: 2.296741008758545 grad: 1.7593666699914527\n",
      "epoch: 406 loss: 2.296689033508301 grad: 1.7750003673099277\n",
      "epoch: 407 loss: 2.2970306873321533 grad: 1.779538828931335\n",
      "epoch: 408 loss: 2.2967028617858887 grad: 1.7445750242867877\n",
      "epoch: 409 loss: 2.296048164367676 grad: 1.7988009664178308\n",
      "epoch: 410 loss: 2.296598196029663 grad: 1.7960828873217993\n",
      "epoch: 411 loss: 2.295546293258667 grad: 1.7967222607269557\n",
      "epoch: 412 loss: 2.297104597091675 grad: 1.7586419249234337\n",
      "epoch: 413 loss: 2.295893669128418 grad: 1.7848183597800218\n",
      "epoch: 414 loss: 2.296031951904297 grad: 1.784765679718158\n",
      "epoch: 415 loss: 2.295440196990967 grad: 1.7890182717200664\n",
      "epoch: 416 loss: 2.296675205230713 grad: 1.7832921638637633\n",
      "epoch: 417 loss: 2.2964437007904053 grad: 1.7709150076067697\n",
      "epoch: 418 loss: 2.2954113483428955 grad: 1.8016928218024235\n",
      "epoch: 419 loss: 2.295778512954712 grad: 1.7906637236823342\n",
      "epoch: 420 loss: 2.294823169708252 grad: 1.8205029555829242\n",
      "epoch: 421 loss: 2.294562816619873 grad: 1.8277895763324248\n",
      "epoch: 422 loss: 2.2951104640960693 grad: 1.8053115352781282\n",
      "epoch: 423 loss: 2.2979345321655273 grad: 1.7606906830961446\n",
      "epoch: 424 loss: 2.2963814735412598 grad: 1.7948466491837438\n",
      "epoch: 425 loss: 2.2953834533691406 grad: 1.7966640576117834\n",
      "epoch: 426 loss: 2.2955493927001953 grad: 1.8097350594240227\n",
      "epoch: 427 loss: 2.2950644493103027 grad: 1.8116275707503693\n",
      "epoch: 428 loss: 2.2962138652801514 grad: 1.7846552735649137\n",
      "epoch: 429 loss: 2.295090436935425 grad: 1.8284928860135437\n",
      "epoch: 430 loss: 2.2947161197662354 grad: 1.8166848142402217\n",
      "epoch: 431 loss: 2.2942943572998047 grad: 1.8387442013222932\n",
      "epoch: 432 loss: 2.2954306602478027 grad: 1.8093264855200513\n",
      "epoch: 433 loss: 2.295767307281494 grad: 1.812047994813867\n",
      "epoch: 434 loss: 2.2944138050079346 grad: 1.8199818226534665\n",
      "epoch: 435 loss: 2.294703722000122 grad: 1.8049862733524706\n",
      "epoch: 436 loss: 2.293832302093506 grad: 1.8313575338513133\n",
      "epoch: 437 loss: 2.2937803268432617 grad: 1.8276115688014893\n",
      "epoch: 438 loss: 2.293964147567749 grad: 1.799572590978757\n",
      "epoch: 439 loss: 2.2945008277893066 grad: 1.7948726620155548\n",
      "epoch: 440 loss: 2.2951419353485107 grad: 1.80284564656442\n",
      "epoch: 441 loss: 2.293762683868408 grad: 1.8376691349198124\n",
      "epoch: 442 loss: 2.2940309047698975 grad: 1.8070965198733444\n",
      "epoch: 443 loss: 2.2936103343963623 grad: 1.8059871116494168\n",
      "epoch: 444 loss: 2.2929646968841553 grad: 1.8473959997118938\n",
      "epoch: 445 loss: 2.293680191040039 grad: 1.8443140817052197\n",
      "epoch: 446 loss: 2.2940261363983154 grad: 1.8368549358269701\n",
      "epoch: 447 loss: 2.293696165084839 grad: 1.8503831441898548\n",
      "epoch: 448 loss: 2.2937724590301514 grad: 1.828455482448806\n",
      "epoch: 449 loss: 2.2939646244049072 grad: 1.8009942001533799\n",
      "epoch: 450 loss: 2.293320655822754 grad: 1.8429094165312274\n",
      "epoch: 451 loss: 2.2932450771331787 grad: 1.8571066627545016\n",
      "epoch: 452 loss: 2.2938971519470215 grad: 1.8498231449334452\n",
      "epoch: 453 loss: 2.2938170433044434 grad: 1.8294223430049088\n",
      "epoch: 454 loss: 2.2924134731292725 grad: 1.8445919681477199\n",
      "epoch: 455 loss: 2.293736696243286 grad: 1.8469181010270461\n",
      "epoch: 456 loss: 2.292720317840576 grad: 1.8410930572029587\n",
      "epoch: 457 loss: 2.2917280197143555 grad: 1.862176945536501\n",
      "epoch: 458 loss: 2.2930376529693604 grad: 1.8600624795034824\n",
      "epoch: 459 loss: 2.2925870418548584 grad: 1.8666984526780508\n",
      "epoch: 460 loss: 2.292170524597168 grad: 1.8339116624094516\n",
      "epoch: 461 loss: 2.292283058166504 grad: 1.8520230104248705\n",
      "epoch: 462 loss: 2.2924461364746094 grad: 1.8459775428701606\n",
      "epoch: 463 loss: 2.2920310497283936 grad: 1.857507171345845\n",
      "epoch: 464 loss: 2.292073965072632 grad: 1.883204519192481\n",
      "epoch: 465 loss: 2.291025161743164 grad: 1.8598958921899635\n",
      "epoch: 466 loss: 2.2915680408477783 grad: 1.8755527005091102\n",
      "epoch: 467 loss: 2.2913851737976074 grad: 1.8837202379391307\n",
      "epoch: 468 loss: 2.290867805480957 grad: 1.8857967108007638\n",
      "epoch: 469 loss: 2.2915375232696533 grad: 1.8843318711493224\n",
      "epoch: 470 loss: 2.2912726402282715 grad: 1.876295103909566\n",
      "epoch: 471 loss: 2.290832042694092 grad: 1.891239908987671\n",
      "epoch: 472 loss: 2.2917215824127197 grad: 1.8829341961296335\n",
      "epoch: 473 loss: 2.2910830974578857 grad: 1.8848305263848502\n",
      "epoch: 474 loss: 2.289766311645508 grad: 1.953572816919491\n",
      "epoch: 475 loss: 2.289850950241089 grad: 1.9173176616082885\n",
      "epoch: 476 loss: 2.2903761863708496 grad: 1.9121932728282576\n",
      "epoch: 477 loss: 2.2891151905059814 grad: 1.944745768837276\n",
      "epoch: 478 loss: 2.288567066192627 grad: 1.9392093190505717\n",
      "epoch: 479 loss: 2.289844512939453 grad: 1.9537121745580364\n",
      "epoch: 480 loss: 2.2898452281951904 grad: 1.983745330065075\n",
      "epoch: 481 loss: 2.287628650665283 grad: 1.9579410284724352\n",
      "epoch: 482 loss: 2.2891626358032227 grad: 1.980109191155948\n",
      "epoch: 483 loss: 2.2891674041748047 grad: 1.9631435847915117\n",
      "epoch: 484 loss: 2.2875750064849854 grad: 2.011566292102789\n",
      "epoch: 485 loss: 2.286020040512085 grad: 2.031908982298485\n",
      "epoch: 486 loss: 2.285890817642212 grad: 2.0449275308979735\n",
      "epoch: 487 loss: 2.2878735065460205 grad: 2.006837409277934\n",
      "epoch: 488 loss: 2.285369873046875 grad: 2.068310296124158\n",
      "epoch: 489 loss: 2.2833611965179443 grad: 2.0372064774708143\n",
      "epoch: 490 loss: 2.283432960510254 grad: 2.057429427029713\n",
      "epoch: 491 loss: 2.284794807434082 grad: 2.1187118849539686\n",
      "epoch: 492 loss: 2.2830398082733154 grad: 2.0865464562103004\n",
      "epoch: 493 loss: 2.2828261852264404 grad: 2.0828359632804574\n",
      "epoch: 494 loss: 2.2809550762176514 grad: 2.1018967507462505\n",
      "epoch: 495 loss: 2.281334638595581 grad: 2.1041208957377378\n",
      "epoch: 496 loss: 2.28098464012146 grad: 2.121474436678303\n",
      "epoch: 497 loss: 2.279341220855713 grad: 2.0993756437637208\n",
      "epoch: 498 loss: 2.277554750442505 grad: 2.1178269007442787\n",
      "epoch: 499 loss: 2.277665853500366 grad: 2.159424032980857\n",
      "2.296451196074486\n",
      "epoch: 0 loss: 2.3032922744750977 grad: 1.2491427280030967\n",
      "epoch: 1 loss: 2.302992343902588 grad: 1.2364334755037572\n",
      "epoch: 2 loss: 2.3021998405456543 grad: 1.2558979533690338\n",
      "epoch: 3 loss: 2.301459312438965 grad: 1.2815385178758925\n",
      "epoch: 4 loss: 2.300764560699463 grad: 1.3330962972748759\n",
      "epoch: 5 loss: 2.300318956375122 grad: 1.369007084825416\n",
      "epoch: 6 loss: 2.297541856765747 grad: 1.4394875500584021\n",
      "epoch: 7 loss: 2.296780824661255 grad: 1.4531459495635881\n",
      "epoch: 8 loss: 2.2939682006835938 grad: 1.525996182339325\n",
      "epoch: 9 loss: 2.290950059890747 grad: 1.6164060239107274\n",
      "epoch: 10 loss: 2.2880399227142334 grad: 1.656390120404669\n",
      "epoch: 11 loss: 2.281820297241211 grad: 1.775434828243248\n",
      "epoch: 12 loss: 2.2647128105163574 grad: 1.8690506397923898\n",
      "epoch: 13 loss: 2.252230167388916 grad: 1.7019369471337764\n",
      "epoch: 14 loss: 2.245231866836548 grad: 1.5141384628775072\n",
      "epoch: 15 loss: 2.2417569160461426 grad: 1.4918227298942852\n",
      "epoch: 16 loss: 2.237179756164551 grad: 1.4015245429121903\n",
      "epoch: 17 loss: 2.235684633255005 grad: 1.3899000342011392\n",
      "epoch: 18 loss: 2.2314977645874023 grad: 1.3651826876873476\n",
      "epoch: 19 loss: 2.2292118072509766 grad: 1.3102347589142265\n",
      "epoch: 20 loss: 2.2294375896453857 grad: 1.328406867733787\n",
      "epoch: 21 loss: 2.229008674621582 grad: 1.4099989295308848\n",
      "epoch: 22 loss: 2.2265706062316895 grad: 1.446061291652436\n",
      "epoch: 23 loss: 2.2255287170410156 grad: 1.5449696594483353\n",
      "epoch: 24 loss: 2.224003314971924 grad: 1.5063140134231026\n",
      "epoch: 25 loss: 2.2241737842559814 grad: 1.5588246033404998\n",
      "epoch: 26 loss: 2.222694158554077 grad: 1.5696271692406356\n",
      "epoch: 27 loss: 2.220957040786743 grad: 1.6241181594253118\n",
      "epoch: 28 loss: 2.217325448989868 grad: 1.6039902064653615\n",
      "epoch: 29 loss: 2.2160701751708984 grad: 1.6203684336006907\n",
      "epoch: 30 loss: 2.214993715286255 grad: 1.843548147020758\n",
      "epoch: 31 loss: 2.2131285667419434 grad: 1.9702949367116191\n",
      "epoch: 32 loss: 2.2113592624664307 grad: 1.97480691366622\n",
      "epoch: 33 loss: 2.2070608139038086 grad: 2.1126357453232187\n",
      "epoch: 34 loss: 2.2059831619262695 grad: 2.2867384370534665\n",
      "epoch: 35 loss: 2.2051398754119873 grad: 2.1453591353862382\n",
      "epoch: 36 loss: 2.204012632369995 grad: 2.410529304500891\n",
      "epoch: 37 loss: 2.2003557682037354 grad: 2.2009715758400805\n",
      "epoch: 38 loss: 2.198899269104004 grad: 2.3497824512998617\n",
      "epoch: 39 loss: 2.1974451541900635 grad: 2.4218507210413613\n",
      "epoch: 40 loss: 2.194211006164551 grad: 2.4321515029610414\n",
      "epoch: 41 loss: 2.19380521774292 grad: 2.5104169586787948\n",
      "epoch: 42 loss: 2.1885828971862793 grad: 2.501268724548734\n",
      "epoch: 43 loss: 2.189115524291992 grad: 2.634831058299391\n",
      "epoch: 44 loss: 2.185502529144287 grad: 2.625814488336873\n",
      "epoch: 45 loss: 2.18324875831604 grad: 2.8843200701946716\n",
      "epoch: 46 loss: 2.1808767318725586 grad: 3.0165273820231153\n",
      "epoch: 47 loss: 2.18257737159729 grad: 3.102372612501125\n",
      "epoch: 48 loss: 2.1738007068634033 grad: 3.2072001517092485\n",
      "epoch: 49 loss: 2.173250198364258 grad: 3.2662961010355502\n",
      "epoch: 50 loss: 2.1748206615448 grad: 3.5815976031442425\n",
      "epoch: 51 loss: 2.1666622161865234 grad: 3.5295690881228814\n",
      "epoch: 52 loss: 2.163919687271118 grad: 3.465055949945328\n",
      "epoch: 53 loss: 2.16341233253479 grad: 3.7667772279098806\n",
      "epoch: 54 loss: 2.1563093662261963 grad: 3.948074717351812\n",
      "epoch: 55 loss: 2.1585466861724854 grad: 4.193234009860409\n",
      "epoch: 56 loss: 2.1523168087005615 grad: 3.9364801897105597\n",
      "epoch: 57 loss: 2.148951530456543 grad: 4.2105151291470975\n",
      "epoch: 58 loss: 2.1427316665649414 grad: 4.209685688465094\n",
      "epoch: 59 loss: 2.1442878246307373 grad: 4.177847311133519\n",
      "epoch: 60 loss: 2.144740343093872 grad: 4.6238610022036095\n",
      "epoch: 61 loss: 2.142049789428711 grad: 4.461039650564392\n",
      "epoch: 62 loss: 2.140040874481201 grad: 4.428727476798471\n",
      "epoch: 63 loss: 2.139627456665039 grad: 4.482705984308961\n",
      "epoch: 64 loss: 2.1357860565185547 grad: 4.724864769723296\n",
      "epoch: 65 loss: 2.1323740482330322 grad: 4.429235149463195\n",
      "epoch: 66 loss: 2.127821445465088 grad: 4.893868645283556\n",
      "epoch: 67 loss: 2.1271989345550537 grad: 5.104742814121502\n",
      "epoch: 68 loss: 2.1235711574554443 grad: 4.6545288247122825\n",
      "epoch: 69 loss: 2.119340658187866 grad: 4.860318625508438\n",
      "epoch: 70 loss: 2.1192216873168945 grad: 4.66602937251492\n",
      "epoch: 71 loss: 2.116342782974243 grad: 5.022679008735669\n",
      "epoch: 72 loss: 2.1146020889282227 grad: 4.577523263666542\n",
      "epoch: 73 loss: 2.1130595207214355 grad: 4.939544175093668\n",
      "epoch: 74 loss: 2.1117749214172363 grad: 5.104219011433925\n",
      "epoch: 75 loss: 2.1079342365264893 grad: 4.803675074777049\n",
      "epoch: 76 loss: 2.1073789596557617 grad: 4.9918399373409414\n",
      "epoch: 77 loss: 2.1098763942718506 grad: 5.075923252351848\n",
      "epoch: 78 loss: 2.1053569316864014 grad: 5.035271431899644\n",
      "epoch: 79 loss: 2.1018450260162354 grad: 5.323099560791715\n",
      "epoch: 80 loss: 2.100032329559326 grad: 5.35313429183785\n",
      "epoch: 81 loss: 2.097581624984741 grad: 5.3364992389485\n",
      "epoch: 82 loss: 2.0952799320220947 grad: 5.027840372914123\n",
      "epoch: 83 loss: 2.098716974258423 grad: 5.60756550047044\n",
      "epoch: 84 loss: 2.093480110168457 grad: 5.163974801344531\n",
      "epoch: 85 loss: 2.0913190841674805 grad: 5.096274377290337\n",
      "epoch: 86 loss: 2.088564395904541 grad: 5.165504985034377\n",
      "epoch: 87 loss: 2.0854439735412598 grad: 5.427954074897109\n",
      "epoch: 88 loss: 2.0930674076080322 grad: 5.507651386072948\n",
      "epoch: 89 loss: 2.091247797012329 grad: 5.491225283940337\n",
      "epoch: 90 loss: 2.086291790008545 grad: 5.4878981922206185\n",
      "epoch: 91 loss: 2.085768222808838 grad: 5.7202320631061285\n",
      "epoch: 92 loss: 2.0845119953155518 grad: 5.460809653129665\n",
      "epoch: 93 loss: 2.0806045532226562 grad: 5.837471942542979\n",
      "epoch: 94 loss: 2.0847363471984863 grad: 5.754024995660912\n",
      "epoch: 95 loss: 2.0743629932403564 grad: 5.562449143541651\n",
      "epoch: 96 loss: 2.071263551712036 grad: 5.493687712136538\n",
      "epoch: 97 loss: 2.080970287322998 grad: 6.078292452937199\n",
      "epoch: 98 loss: 2.07018780708313 grad: 6.06184060845731\n",
      "epoch: 99 loss: 2.0819668769836426 grad: 6.038088934422131\n",
      "epoch: 100 loss: 2.076204538345337 grad: 5.8157024752599975\n",
      "epoch: 101 loss: 2.0781750679016113 grad: 6.017645917611108\n",
      "epoch: 102 loss: 2.070611000061035 grad: 6.066122105256433\n",
      "epoch: 103 loss: 2.0702335834503174 grad: 5.695756817857425\n",
      "epoch: 104 loss: 2.0699007511138916 grad: 5.966610488407905\n",
      "epoch: 105 loss: 2.0685408115386963 grad: 5.704816440393823\n",
      "epoch: 106 loss: 2.0637457370758057 grad: 5.852143603391827\n",
      "epoch: 107 loss: 2.073997735977173 grad: 6.010280819395409\n",
      "epoch: 108 loss: 2.0661509037017822 grad: 5.614083585225874\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 109 loss: 2.0610299110412598 grad: 6.100516179266076\n",
      "epoch: 110 loss: 2.0644168853759766 grad: 6.119186477403024\n",
      "epoch: 111 loss: 2.0639326572418213 grad: 6.034857330622063\n",
      "epoch: 112 loss: 2.059696912765503 grad: 6.21068373471055\n",
      "epoch: 113 loss: 2.063225746154785 grad: 6.163940273860972\n",
      "epoch: 114 loss: 2.059701919555664 grad: 6.582506008889704\n",
      "epoch: 115 loss: 2.0588979721069336 grad: 5.672753377366693\n",
      "epoch: 116 loss: 2.055976152420044 grad: 5.941438113139676\n",
      "epoch: 117 loss: 2.0657272338867188 grad: 6.289689764040449\n",
      "epoch: 118 loss: 2.053581476211548 grad: 5.787265393919947\n",
      "epoch: 119 loss: 2.0483481884002686 grad: 6.192261750551148\n",
      "epoch: 120 loss: 2.0533835887908936 grad: 5.605281312395597\n",
      "epoch: 121 loss: 2.05072021484375 grad: 6.053466630101736\n",
      "epoch: 122 loss: 2.0556538105010986 grad: 6.160420704159945\n",
      "epoch: 123 loss: 2.0537405014038086 grad: 5.994828120834889\n",
      "epoch: 124 loss: 2.0559864044189453 grad: 5.901981731466505\n",
      "epoch: 125 loss: 2.0520973205566406 grad: 6.117206651961342\n",
      "epoch: 126 loss: 2.0486855506896973 grad: 6.452691778444523\n",
      "epoch: 127 loss: 2.051232099533081 grad: 6.410815155244476\n",
      "epoch: 128 loss: 2.0473744869232178 grad: 6.004229123497175\n",
      "epoch: 129 loss: 2.046665668487549 grad: 6.1325218528065655\n",
      "epoch: 130 loss: 2.0508134365081787 grad: 6.058255955724726\n",
      "epoch: 131 loss: 2.0483551025390625 grad: 6.267209347352267\n",
      "epoch: 132 loss: 2.041257381439209 grad: 5.988773197142614\n",
      "epoch: 133 loss: 2.042456865310669 grad: 6.2446220080249955\n",
      "epoch: 134 loss: 2.044933557510376 grad: 6.019565472844988\n",
      "epoch: 135 loss: 2.0390844345092773 grad: 6.564204089018324\n",
      "epoch: 136 loss: 2.0395348072052 grad: 5.8720700152085294\n",
      "epoch: 137 loss: 2.0429937839508057 grad: 6.552367422737122\n",
      "epoch: 138 loss: 2.040011405944824 grad: 6.138208817261907\n",
      "epoch: 139 loss: 2.0398147106170654 grad: 6.41927652910263\n",
      "epoch: 140 loss: 2.041348695755005 grad: 6.14354730704208\n",
      "epoch: 141 loss: 2.039041042327881 grad: 6.0881544327777295\n",
      "epoch: 142 loss: 2.0411243438720703 grad: 6.421350009584178\n",
      "epoch: 143 loss: 2.0327794551849365 grad: 6.289646553356082\n",
      "epoch: 144 loss: 2.0374948978424072 grad: 6.3146159690730865\n",
      "epoch: 145 loss: 2.039543628692627 grad: 6.379843094275289\n",
      "epoch: 146 loss: 2.038347005844116 grad: 6.284300252972614\n",
      "epoch: 147 loss: 2.035191774368286 grad: 6.572796284161981\n",
      "epoch: 148 loss: 2.035153865814209 grad: 6.647764825949534\n",
      "epoch: 149 loss: 2.0328853130340576 grad: 6.368930749240375\n",
      "epoch: 150 loss: 2.033945322036743 grad: 6.794078757927295\n",
      "epoch: 151 loss: 2.026029109954834 grad: 6.434790812129717\n",
      "epoch: 152 loss: 2.030125379562378 grad: 6.833369370986013\n",
      "epoch: 153 loss: 2.0220470428466797 grad: 6.7337129173194255\n",
      "epoch: 154 loss: 2.031111240386963 grad: 6.714457789192065\n",
      "epoch: 155 loss: 2.0277254581451416 grad: 6.793212700221273\n",
      "epoch: 156 loss: 2.0193967819213867 grad: 6.614964596513245\n",
      "epoch: 157 loss: 2.0314979553222656 grad: 6.64452138660653\n",
      "epoch: 158 loss: 2.018190383911133 grad: 7.115226019055597\n",
      "epoch: 159 loss: 2.018850803375244 grad: 6.634623277998928\n",
      "epoch: 160 loss: 2.02536940574646 grad: 6.680868787040549\n",
      "epoch: 161 loss: 2.0249874591827393 grad: 7.133082024560916\n",
      "epoch: 162 loss: 2.0191688537597656 grad: 6.842529568392488\n",
      "epoch: 163 loss: 2.0120627880096436 grad: 6.449312892690715\n",
      "epoch: 164 loss: 2.0142269134521484 grad: 6.614283431846175\n",
      "epoch: 165 loss: 2.008178472518921 grad: 6.955135092560557\n",
      "epoch: 166 loss: 2.0131499767303467 grad: 7.130578426792035\n",
      "epoch: 167 loss: 2.0117533206939697 grad: 7.046981565691235\n",
      "epoch: 168 loss: 2.0094783306121826 grad: 7.497705533597914\n",
      "epoch: 169 loss: 2.0033857822418213 grad: 7.145820805935988\n",
      "epoch: 170 loss: 2.0009028911590576 grad: 6.7859547874476345\n",
      "epoch: 171 loss: 1.9976191520690918 grad: 6.608757673282295\n",
      "epoch: 172 loss: 1.9977060556411743 grad: 6.937746888750957\n",
      "epoch: 173 loss: 2.004023551940918 grad: 7.083611567135131\n",
      "epoch: 174 loss: 2.0024545192718506 grad: 7.395888113076725\n",
      "epoch: 175 loss: 1.9986610412597656 grad: 7.169377092079865\n",
      "epoch: 176 loss: 1.992700457572937 grad: 7.463028466979426\n",
      "epoch: 177 loss: 2.000229597091675 grad: 7.474357539595711\n",
      "epoch: 178 loss: 1.9989441633224487 grad: 7.314329300097944\n",
      "epoch: 179 loss: 1.994475245475769 grad: 7.508194917679897\n",
      "epoch: 180 loss: 1.9884649515151978 grad: 7.434510924705555\n",
      "epoch: 181 loss: 1.9892489910125732 grad: 7.266606535910378\n",
      "epoch: 182 loss: 1.9852465391159058 grad: 7.260257107989182\n",
      "epoch: 183 loss: 1.985417127609253 grad: 7.628946109748785\n",
      "epoch: 184 loss: 1.9799432754516602 grad: 7.761737668029372\n",
      "epoch: 185 loss: 1.988625168800354 grad: 7.609399969696939\n",
      "epoch: 186 loss: 1.9863775968551636 grad: 7.171970775291797\n",
      "epoch: 187 loss: 1.9808169603347778 grad: 7.57057154370797\n",
      "epoch: 188 loss: 1.979875922203064 grad: 7.832602843095268\n",
      "epoch: 189 loss: 1.9825321435928345 grad: 7.449779690465047\n",
      "epoch: 190 loss: 1.9714653491973877 grad: 7.523672516997312\n",
      "epoch: 191 loss: 1.975779414176941 grad: 8.14489007431511\n",
      "epoch: 192 loss: 1.9738761186599731 grad: 8.245124676028295\n",
      "epoch: 193 loss: 1.9752475023269653 grad: 7.834198905879425\n",
      "epoch: 194 loss: 1.978237271308899 grad: 8.32091191674154\n",
      "epoch: 195 loss: 1.9690371751785278 grad: 7.446030139716135\n",
      "epoch: 196 loss: 1.969430923461914 grad: 7.705424990039319\n",
      "epoch: 197 loss: 1.9695760011672974 grad: 7.738877232851727\n",
      "epoch: 198 loss: 1.9739805459976196 grad: 8.015652849161555\n",
      "epoch: 199 loss: 1.970290184020996 grad: 8.07318762154688\n",
      "epoch: 200 loss: 1.9643114805221558 grad: 8.529374962332584\n",
      "epoch: 201 loss: 1.9641691446304321 grad: 8.123555144243356\n",
      "epoch: 202 loss: 1.9733295440673828 grad: 8.08925352177568\n",
      "epoch: 203 loss: 1.960517406463623 grad: 8.348307517771092\n",
      "epoch: 204 loss: 1.9615422487258911 grad: 8.400018490037866\n",
      "epoch: 205 loss: 1.9640778303146362 grad: 8.132738282386628\n",
      "epoch: 206 loss: 1.9700928926467896 grad: 8.580060260725164\n",
      "epoch: 207 loss: 1.9638769626617432 grad: 7.976922412846415\n",
      "epoch: 208 loss: 1.9605720043182373 grad: 8.038383049816485\n",
      "epoch: 209 loss: 1.9592158794403076 grad: 7.661790244517818\n",
      "epoch: 210 loss: 1.9543734788894653 grad: 8.639671757728571\n",
      "epoch: 211 loss: 1.9561192989349365 grad: 8.062977189102048\n",
      "epoch: 212 loss: 1.946824550628662 grad: 8.119842012139362\n",
      "epoch: 213 loss: 1.9465532302856445 grad: 7.999640518282023\n",
      "epoch: 214 loss: 1.9538928270339966 grad: 8.43553691988604\n",
      "epoch: 215 loss: 1.9510293006896973 grad: 8.096038846225138\n",
      "epoch: 216 loss: 1.9480531215667725 grad: 8.242499916119472\n",
      "epoch: 217 loss: 1.9490878582000732 grad: 8.319992394437866\n",
      "epoch: 218 loss: 1.9507414102554321 grad: 8.087614189345567\n",
      "epoch: 219 loss: 1.9513726234436035 grad: 8.560874903057185\n",
      "epoch: 220 loss: 1.9571243524551392 grad: 8.176790651347902\n",
      "epoch: 221 loss: 1.9532196521759033 grad: 8.442246602611645\n",
      "epoch: 222 loss: 1.9554117918014526 grad: 8.464597323776356\n",
      "epoch: 223 loss: 1.942015290260315 grad: 8.647751766715258\n",
      "epoch: 224 loss: 1.946950912475586 grad: 8.960296546449028\n",
      "epoch: 225 loss: 1.941675066947937 grad: 8.198176844030737\n",
      "epoch: 226 loss: 1.9473390579223633 grad: 8.492219786115346\n",
      "epoch: 227 loss: 1.944880723953247 grad: 8.796713856507152\n",
      "epoch: 228 loss: 1.938604712486267 grad: 8.523801939894579\n",
      "epoch: 229 loss: 1.9410289525985718 grad: 8.006544311220447\n",
      "epoch: 230 loss: 1.9434913396835327 grad: 8.600152997033936\n",
      "epoch: 231 loss: 1.9386584758758545 grad: 8.681589738377149\n",
      "epoch: 232 loss: 1.9424868822097778 grad: 8.579743414984218\n",
      "epoch: 233 loss: 1.9359328746795654 grad: 8.605547586928994\n",
      "epoch: 234 loss: 1.941603183746338 grad: 8.901409862311704\n",
      "epoch: 235 loss: 1.9427250623703003 grad: 8.939543019876712\n",
      "epoch: 236 loss: 1.9378182888031006 grad: 8.70715698633816\n",
      "epoch: 237 loss: 1.929460048675537 grad: 8.374169588902049\n",
      "epoch: 238 loss: 1.9349677562713623 grad: 8.756184705592219\n",
      "epoch: 239 loss: 1.932739019393921 grad: 8.958463027895917\n",
      "epoch: 240 loss: 1.93351411819458 grad: 9.016768523758012\n",
      "epoch: 241 loss: 1.9359809160232544 grad: 9.089622194154394\n",
      "epoch: 242 loss: 1.930172324180603 grad: 8.825143947266042\n",
      "epoch: 243 loss: 1.9278022050857544 grad: 9.332684305023461\n",
      "epoch: 244 loss: 1.934459924697876 grad: 8.37654255904139\n",
      "epoch: 245 loss: 1.938862681388855 grad: 9.080639687736356\n",
      "epoch: 246 loss: 1.9274097681045532 grad: 9.213510660617242\n",
      "epoch: 247 loss: 1.9242570400238037 grad: 8.539717685194715\n",
      "epoch: 248 loss: 1.9275248050689697 grad: 9.231294269008297\n",
      "epoch: 249 loss: 1.9179095029830933 grad: 8.60366866467077\n",
      "epoch: 250 loss: 1.932707667350769 grad: 8.886142064418111\n",
      "epoch: 251 loss: 1.9094547033309937 grad: 8.614366159715232\n",
      "epoch: 252 loss: 1.9295884370803833 grad: 9.629541037293771\n",
      "epoch: 253 loss: 1.9204909801483154 grad: 9.01972551136795\n",
      "epoch: 254 loss: 1.9202046394348145 grad: 8.713948699224385\n",
      "epoch: 255 loss: 1.920243263244629 grad: 9.277387490377777\n",
      "epoch: 256 loss: 1.9238768815994263 grad: 8.776975601009788\n",
      "epoch: 257 loss: 1.9309931993484497 grad: 9.547733455881595\n",
      "epoch: 258 loss: 1.9150182008743286 grad: 8.730508370295404\n",
      "epoch: 259 loss: 1.916072964668274 grad: 8.936355499521135\n",
      "epoch: 260 loss: 1.9218140840530396 grad: 8.755876328707451\n",
      "epoch: 261 loss: 1.9185075759887695 grad: 9.549640257680228\n",
      "epoch: 262 loss: 1.9207050800323486 grad: 9.072714625724725\n",
      "epoch: 263 loss: 1.923346757888794 grad: 9.040446784036854\n",
      "epoch: 264 loss: 1.9143357276916504 grad: 9.113344759443804\n",
      "epoch: 265 loss: 1.9203296899795532 grad: 9.076559821823759\n",
      "epoch: 266 loss: 1.9088575839996338 grad: 8.864776744182029\n",
      "epoch: 267 loss: 1.9180164337158203 grad: 8.79950846895753\n",
      "epoch: 268 loss: 1.925039529800415 grad: 9.085981404068805\n",
      "epoch: 269 loss: 1.9172340631484985 grad: 9.195224788956462\n",
      "epoch: 270 loss: 1.9111658334732056 grad: 9.280959537659314\n",
      "epoch: 271 loss: 1.9166905879974365 grad: 8.812025843424694\n",
      "epoch: 272 loss: 1.9103280305862427 grad: 9.002287186948317\n",
      "epoch: 273 loss: 1.9071272611618042 grad: 9.360865666486678\n",
      "epoch: 274 loss: 1.917029619216919 grad: 9.411758246003753\n",
      "epoch: 275 loss: 1.9042397737503052 grad: 9.4698064072235\n",
      "epoch: 276 loss: 1.90671968460083 grad: 10.075030187514448\n",
      "epoch: 277 loss: 1.9125491380691528 grad: 8.942583119614966\n",
      "epoch: 278 loss: 1.8984143733978271 grad: 9.460194153873811\n",
      "epoch: 279 loss: 1.910046100616455 grad: 9.181965995372998\n",
      "epoch: 280 loss: 1.90957510471344 grad: 9.16697133440406\n",
      "epoch: 281 loss: 1.911948561668396 grad: 9.795029224384399\n",
      "epoch: 282 loss: 1.904112696647644 grad: 9.002669350776289\n",
      "epoch: 283 loss: 1.9066137075424194 grad: 9.015132187215228\n",
      "epoch: 284 loss: 1.9125338792800903 grad: 9.87430572444721\n",
      "epoch: 285 loss: 1.9086793661117554 grad: 9.167691106952372\n",
      "epoch: 286 loss: 1.903860330581665 grad: 9.531720145546373\n",
      "epoch: 287 loss: 1.8971291780471802 grad: 8.916195378757067\n",
      "epoch: 288 loss: 1.8972088098526 grad: 9.990527136650469\n",
      "epoch: 289 loss: 1.9100228548049927 grad: 9.32773503514805\n",
      "epoch: 290 loss: 1.9083644151687622 grad: 10.224593677144084\n",
      "epoch: 291 loss: 1.9050357341766357 grad: 9.234390357982308\n",
      "epoch: 292 loss: 1.8921804428100586 grad: 8.994399038069542\n",
      "epoch: 293 loss: 1.9005674123764038 grad: 9.080692593023063\n",
      "epoch: 294 loss: 1.9031697511672974 grad: 9.73897083788105\n",
      "epoch: 295 loss: 1.9049822092056274 grad: 9.078990619895714\n",
      "epoch: 296 loss: 1.8945780992507935 grad: 9.518381693149133\n",
      "epoch: 297 loss: 1.8986178636550903 grad: 9.22708374302509\n",
      "epoch: 298 loss: 1.9000647068023682 grad: 9.427714551895088\n",
      "epoch: 299 loss: 1.9042789936065674 grad: 10.044202106990038\n",
      "epoch: 300 loss: 1.8985786437988281 grad: 9.85356809493036\n",
      "epoch: 301 loss: 1.8987658023834229 grad: 9.91501361625417\n",
      "epoch: 302 loss: 1.8956482410430908 grad: 9.384374041006797\n",
      "epoch: 303 loss: 1.9034600257873535 grad: 10.030810979490598\n",
      "epoch: 304 loss: 1.8938698768615723 grad: 10.24655135230176\n",
      "epoch: 305 loss: 1.8995225429534912 grad: 9.842212350455128\n",
      "epoch: 306 loss: 1.8942791223526 grad: 9.54988753225004\n",
      "epoch: 307 loss: 1.8983122110366821 grad: 9.564423878292834\n",
      "epoch: 308 loss: 1.8970813751220703 grad: 9.610118125506219\n",
      "epoch: 309 loss: 1.8900151252746582 grad: 9.253829519796584\n",
      "epoch: 310 loss: 1.8908088207244873 grad: 9.729139753986919\n",
      "epoch: 311 loss: 1.8835904598236084 grad: 9.061284768661219\n",
      "epoch: 312 loss: 1.8897558450698853 grad: 9.75781244250931\n",
      "epoch: 313 loss: 1.903839349746704 grad: 10.706427405307453\n",
      "epoch: 314 loss: 1.8857927322387695 grad: 9.29274172238296\n",
      "epoch: 315 loss: 1.8902196884155273 grad: 9.342716421192836\n",
      "epoch: 316 loss: 1.8956098556518555 grad: 10.240334363107289\n",
      "epoch: 317 loss: 1.8964577913284302 grad: 9.573141974463526\n",
      "epoch: 318 loss: 1.886056900024414 grad: 9.907815462022665\n",
      "epoch: 319 loss: 1.8910751342773438 grad: 9.570832370351704\n",
      "epoch: 320 loss: 1.8833369016647339 grad: 9.816876790988895\n",
      "epoch: 321 loss: 1.8842629194259644 grad: 10.051723231162343\n",
      "epoch: 322 loss: 1.8917726278305054 grad: 9.824035388846246\n",
      "epoch: 323 loss: 1.8865597248077393 grad: 9.747492820756245\n",
      "epoch: 324 loss: 1.892496943473816 grad: 8.893463904821566\n",
      "epoch: 325 loss: 1.8787517547607422 grad: 9.761100547787334\n",
      "epoch: 326 loss: 1.8871206045150757 grad: 9.957563737762117\n",
      "epoch: 327 loss: 1.8886088132858276 grad: 9.731939306024403\n",
      "epoch: 328 loss: 1.8843556642532349 grad: 10.467146275343286\n",
      "epoch: 329 loss: 1.8879295587539673 grad: 10.057054783794142\n",
      "epoch: 330 loss: 1.8821982145309448 grad: 10.017013127235549\n",
      "epoch: 331 loss: 1.8946986198425293 grad: 10.244960757001998\n",
      "epoch: 332 loss: 1.887897253036499 grad: 10.25710634767477\n",
      "epoch: 333 loss: 1.8723398447036743 grad: 9.516174741503265\n",
      "epoch: 334 loss: 1.882558822631836 grad: 9.493137026220442\n",
      "epoch: 335 loss: 1.8895827531814575 grad: 10.209642672955635\n",
      "epoch: 336 loss: 1.8868069648742676 grad: 10.282580753241385\n",
      "epoch: 337 loss: 1.8800040483474731 grad: 9.822488669313431\n",
      "epoch: 338 loss: 1.8907585144042969 grad: 10.327178146601433\n",
      "epoch: 339 loss: 1.8783609867095947 grad: 9.663724551066046\n",
      "epoch: 340 loss: 1.8776798248291016 grad: 10.397842582714345\n",
      "epoch: 341 loss: 1.883628487586975 grad: 10.166316369149301\n",
      "epoch: 342 loss: 1.8776195049285889 grad: 9.88780176389726\n",
      "epoch: 343 loss: 1.878341794013977 grad: 10.129966979491568\n",
      "epoch: 344 loss: 1.8787882328033447 grad: 9.75435379282054\n",
      "epoch: 345 loss: 1.8741871118545532 grad: 10.647427350120058\n",
      "epoch: 346 loss: 1.8769581317901611 grad: 9.789385615271472\n",
      "epoch: 347 loss: 1.8624507188796997 grad: 9.582477834445262\n",
      "epoch: 348 loss: 1.8673746585845947 grad: 10.420525993486601\n",
      "epoch: 349 loss: 1.8791120052337646 grad: 10.031683412779655\n",
      "epoch: 350 loss: 1.8726961612701416 grad: 10.896306351329835\n",
      "epoch: 351 loss: 1.8739107847213745 grad: 10.943981013423393\n",
      "epoch: 352 loss: 1.875311255455017 grad: 10.18672031418435\n",
      "epoch: 353 loss: 1.8629266023635864 grad: 9.937391806260816\n",
      "epoch: 354 loss: 1.878045916557312 grad: 10.778468160845694\n",
      "epoch: 355 loss: 1.875522494316101 grad: 10.723420605979978\n",
      "epoch: 356 loss: 1.8759633302688599 grad: 10.45630741131211\n",
      "epoch: 357 loss: 1.8733608722686768 grad: 11.123479049031934\n",
      "epoch: 358 loss: 1.8739382028579712 grad: 9.876878513318916\n",
      "epoch: 359 loss: 1.8720914125442505 grad: 10.25659727142562\n",
      "epoch: 360 loss: 1.8745695352554321 grad: 10.596636642021911\n",
      "epoch: 361 loss: 1.8638190031051636 grad: 10.30302655166163\n",
      "epoch: 362 loss: 1.871250867843628 grad: 9.984150021396104\n",
      "epoch: 363 loss: 1.8677691221237183 grad: 9.98571256659038\n",
      "epoch: 364 loss: 1.8741527795791626 grad: 10.961031743251379\n",
      "epoch: 365 loss: 1.8739477396011353 grad: 10.14527056395771\n",
      "epoch: 366 loss: 1.864586353302002 grad: 9.83914252707646\n",
      "epoch: 367 loss: 1.868936538696289 grad: 10.74386293235575\n",
      "epoch: 368 loss: 1.8641539812088013 grad: 10.267063927363663\n",
      "epoch: 369 loss: 1.8572570085525513 grad: 10.531966502852146\n",
      "epoch: 370 loss: 1.8677752017974854 grad: 10.787150976928098\n",
      "epoch: 371 loss: 1.8596172332763672 grad: 10.47801122876505\n",
      "epoch: 372 loss: 1.8612133264541626 grad: 11.33115349717379\n",
      "epoch: 373 loss: 1.8615776300430298 grad: 10.651685573885011\n",
      "epoch: 374 loss: 1.866758108139038 grad: 11.084219715306682\n",
      "epoch: 375 loss: 1.8640720844268799 grad: 10.63982202353636\n",
      "epoch: 376 loss: 1.8682050704956055 grad: 11.143609949890228\n",
      "epoch: 377 loss: 1.8615338802337646 grad: 10.648393448885708\n",
      "epoch: 378 loss: 1.859055995941162 grad: 10.70358599750473\n",
      "epoch: 379 loss: 1.8604713678359985 grad: 10.731962912597709\n",
      "epoch: 380 loss: 1.8551489114761353 grad: 10.770122701065644\n",
      "epoch: 381 loss: 1.8576748371124268 grad: 10.823197726648123\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 382 loss: 1.8559165000915527 grad: 10.464736634333219\n",
      "epoch: 383 loss: 1.85763680934906 grad: 11.108011984192427\n",
      "epoch: 384 loss: 1.8575444221496582 grad: 10.948249570892326\n",
      "epoch: 385 loss: 1.8599932193756104 grad: 11.291732440273913\n",
      "epoch: 386 loss: 1.849992275238037 grad: 10.59267227527582\n",
      "epoch: 387 loss: 1.8654859066009521 grad: 10.708923957901932\n",
      "epoch: 388 loss: 1.8638274669647217 grad: 10.54301387416051\n",
      "epoch: 389 loss: 1.8550032377243042 grad: 11.058724407195335\n",
      "epoch: 390 loss: 1.8560500144958496 grad: 11.041992924028328\n",
      "epoch: 391 loss: 1.8522741794586182 grad: 10.485195572014957\n",
      "epoch: 392 loss: 1.8508354425430298 grad: 11.261363332825047\n",
      "epoch: 393 loss: 1.854504108428955 grad: 11.00170683637557\n",
      "epoch: 394 loss: 1.8531967401504517 grad: 10.539212712988494\n",
      "epoch: 395 loss: 1.8563486337661743 grad: 10.96315276718861\n",
      "epoch: 396 loss: 1.8622468709945679 grad: 10.291247356106483\n",
      "epoch: 397 loss: 1.8611701726913452 grad: 11.070244478268755\n",
      "epoch: 398 loss: 1.853270411491394 grad: 11.223492083701467\n",
      "epoch: 399 loss: 1.846754550933838 grad: 11.029251615265531\n",
      "epoch: 400 loss: 1.845594048500061 grad: 10.860584686672876\n",
      "epoch: 401 loss: 1.8482762575149536 grad: 11.639056780360757\n",
      "epoch: 402 loss: 1.8551102876663208 grad: 10.805133233807744\n",
      "epoch: 403 loss: 1.851248025894165 grad: 11.934197492513155\n",
      "epoch: 404 loss: 1.8466181755065918 grad: 11.74779332303516\n",
      "epoch: 405 loss: 1.8515843152999878 grad: 11.185139491163667\n",
      "epoch: 406 loss: 1.8462477922439575 grad: 11.785980830604712\n",
      "epoch: 407 loss: 1.8522474765777588 grad: 11.634194422291504\n",
      "epoch: 408 loss: 1.841536045074463 grad: 11.509385496629255\n",
      "epoch: 409 loss: 1.8357529640197754 grad: 12.237520105560266\n",
      "epoch: 410 loss: 1.8522228002548218 grad: 12.03491490918197\n",
      "epoch: 411 loss: 1.8422727584838867 grad: 12.095049384670952\n",
      "epoch: 412 loss: 1.8430564403533936 grad: 11.023741253888206\n",
      "epoch: 413 loss: 1.8522329330444336 grad: 12.009525314424305\n",
      "epoch: 414 loss: 1.8436298370361328 grad: 10.91151989076937\n",
      "epoch: 415 loss: 1.8456593751907349 grad: 11.498128223351188\n",
      "epoch: 416 loss: 1.8406493663787842 grad: 11.101611228378873\n",
      "epoch: 417 loss: 1.8424593210220337 grad: 11.70319115212335\n",
      "epoch: 418 loss: 1.8383731842041016 grad: 11.45872167384045\n",
      "epoch: 419 loss: 1.8424817323684692 grad: 11.634751236790585\n",
      "epoch: 420 loss: 1.8409322500228882 grad: 11.818871747170176\n",
      "epoch: 421 loss: 1.8270751237869263 grad: 11.326905471716254\n",
      "epoch: 422 loss: 1.8372493982315063 grad: 11.692980030344593\n",
      "epoch: 423 loss: 1.8326294422149658 grad: 11.981483157398918\n",
      "epoch: 424 loss: 1.8357945680618286 grad: 11.732255728723157\n",
      "epoch: 425 loss: 1.8398959636688232 grad: 12.627335929843996\n",
      "epoch: 426 loss: 1.8432725667953491 grad: 12.503134223869042\n",
      "epoch: 427 loss: 1.8289600610733032 grad: 11.805406885753785\n",
      "epoch: 428 loss: 1.8340191841125488 grad: 12.551466810546579\n",
      "epoch: 429 loss: 1.8326780796051025 grad: 11.712800794946295\n",
      "epoch: 430 loss: 1.8227518796920776 grad: 11.32855902748212\n",
      "epoch: 431 loss: 1.8264278173446655 grad: 12.361765783930581\n",
      "epoch: 432 loss: 1.8365477323532104 grad: 12.380963819870164\n",
      "epoch: 433 loss: 1.8210928440093994 grad: 11.493506758444248\n",
      "epoch: 434 loss: 1.8310880661010742 grad: 12.31769815906291\n",
      "epoch: 435 loss: 1.8210519552230835 grad: 11.932439254678135\n",
      "epoch: 436 loss: 1.838985562324524 grad: 12.70746082870201\n",
      "epoch: 437 loss: 1.8310424089431763 grad: 11.729178817883607\n",
      "epoch: 438 loss: 1.8206989765167236 grad: 11.261022292195804\n",
      "epoch: 439 loss: 1.83101224899292 grad: 12.087718685142814\n",
      "epoch: 440 loss: 1.8262157440185547 grad: 12.318052976613952\n",
      "epoch: 441 loss: 1.8311058282852173 grad: 12.573272445741745\n",
      "epoch: 442 loss: 1.8191789388656616 grad: 12.135032344387756\n",
      "epoch: 443 loss: 1.8267580270767212 grad: 12.255165432121546\n",
      "epoch: 444 loss: 1.8215361833572388 grad: 12.257863740540213\n",
      "epoch: 445 loss: 1.819350242614746 grad: 11.614351264570677\n",
      "epoch: 446 loss: 1.8226914405822754 grad: 12.408296747280964\n",
      "epoch: 447 loss: 1.8260995149612427 grad: 11.912501119239817\n",
      "epoch: 448 loss: 1.8235526084899902 grad: 13.200917538151973\n",
      "epoch: 449 loss: 1.8282963037490845 grad: 12.771737067147143\n",
      "epoch: 450 loss: 1.8202948570251465 grad: 12.625178204465007\n",
      "epoch: 451 loss: 1.8190306425094604 grad: 12.861409257313916\n",
      "epoch: 452 loss: 1.8168150186538696 grad: 12.497283339529993\n",
      "epoch: 453 loss: 1.823340892791748 grad: 12.775358452683403\n",
      "epoch: 454 loss: 1.81973135471344 grad: 12.748425625796829\n",
      "epoch: 455 loss: 1.8185712099075317 grad: 12.395992576484643\n",
      "epoch: 456 loss: 1.8214701414108276 grad: 12.717285201249142\n",
      "epoch: 457 loss: 1.8198130130767822 grad: 12.947832266947934\n",
      "epoch: 458 loss: 1.812369465827942 grad: 12.48557736974446\n",
      "epoch: 459 loss: 1.8194563388824463 grad: 12.475964384818715\n",
      "epoch: 460 loss: 1.814466118812561 grad: 12.529908769660526\n",
      "epoch: 461 loss: 1.820644736289978 grad: 12.77988521802047\n",
      "epoch: 462 loss: 1.8107143640518188 grad: 13.068574171099398\n",
      "epoch: 463 loss: 1.806357741355896 grad: 12.324096204284283\n",
      "epoch: 464 loss: 1.8069368600845337 grad: 12.231814180205147\n",
      "epoch: 465 loss: 1.8102086782455444 grad: 12.397173917556684\n",
      "epoch: 466 loss: 1.8180674314498901 grad: 12.794142899665212\n",
      "epoch: 467 loss: 1.8088549375534058 grad: 12.580039560366126\n",
      "epoch: 468 loss: 1.8152456283569336 grad: 12.558492672230516\n",
      "epoch: 469 loss: 1.8018954992294312 grad: 12.645044727369196\n",
      "epoch: 470 loss: 1.8165414333343506 grad: 12.99252799505161\n",
      "epoch: 471 loss: 1.8139959573745728 grad: 12.899724611672498\n",
      "epoch: 472 loss: 1.7994309663772583 grad: 12.232959451316486\n",
      "epoch: 473 loss: 1.8028782606124878 grad: 12.876282327734526\n",
      "epoch: 474 loss: 1.8135130405426025 grad: 12.754580233320002\n",
      "epoch: 475 loss: 1.8059958219528198 grad: 12.766836264215055\n",
      "epoch: 476 loss: 1.80314302444458 grad: 13.217561623392006\n",
      "epoch: 477 loss: 1.8075590133666992 grad: 13.814420830000133\n",
      "epoch: 478 loss: 1.8092185258865356 grad: 12.694375727118718\n",
      "epoch: 479 loss: 1.8089629411697388 grad: 13.096453577472221\n",
      "epoch: 480 loss: 1.8105002641677856 grad: 13.608211097662293\n",
      "epoch: 481 loss: 1.8009839057922363 grad: 13.115201975869399\n",
      "epoch: 482 loss: 1.7966341972351074 grad: 13.09622444519921\n",
      "epoch: 483 loss: 1.8014273643493652 grad: 13.584967232176236\n",
      "epoch: 484 loss: 1.7933268547058105 grad: 13.35864761689057\n",
      "epoch: 485 loss: 1.799312949180603 grad: 12.777983910389363\n",
      "epoch: 486 loss: 1.8095834255218506 grad: 13.811857441780232\n",
      "epoch: 487 loss: 1.803018569946289 grad: 13.096131830520573\n",
      "epoch: 488 loss: 1.7973580360412598 grad: 13.12135519140533\n",
      "epoch: 489 loss: 1.7958725690841675 grad: 13.22411235549029\n",
      "epoch: 490 loss: 1.8122202157974243 grad: 12.976837929308651\n",
      "epoch: 491 loss: 1.8011194467544556 grad: 13.199888468099138\n",
      "epoch: 492 loss: 1.7990787029266357 grad: 14.158976303376553\n",
      "epoch: 493 loss: 1.8017323017120361 grad: 13.470267126573221\n",
      "epoch: 494 loss: 1.7968690395355225 grad: 13.649519953122805\n",
      "epoch: 495 loss: 1.7933433055877686 grad: 13.665752136000684\n",
      "epoch: 496 loss: 1.7855432033538818 grad: 12.968903265006485\n",
      "epoch: 497 loss: 1.794995903968811 grad: 12.725883614449273\n",
      "epoch: 498 loss: 1.7854257822036743 grad: 12.636968455735653\n",
      "epoch: 499 loss: 1.8003507852554321 grad: 12.943962966365415\n",
      "2.043798103928566\n",
      "epoch: 0 loss: 2.304994821548462 grad: 0.8212080366229491\n",
      "epoch: 1 loss: 2.301306962966919 grad: 0.7845194611304794\n",
      "epoch: 2 loss: 2.2684898376464844 grad: 1.282578425543357\n",
      "epoch: 3 loss: 2.2304766178131104 grad: 1.740116574352936\n",
      "epoch: 4 loss: 2.183103322982788 grad: 2.4528103469527283\n",
      "epoch: 5 loss: 2.1201748847961426 grad: 3.338833681136806\n",
      "epoch: 6 loss: 2.096946954727173 grad: 3.5244558035961484\n",
      "epoch: 7 loss: 2.051865816116333 grad: 4.300011158304563\n",
      "epoch: 8 loss: 2.0164170265197754 grad: 4.778783999223609\n",
      "epoch: 9 loss: 1.9943302869796753 grad: 4.902348343725501\n",
      "epoch: 10 loss: 1.9518860578536987 grad: 4.980408697424176\n",
      "epoch: 11 loss: 1.9450249671936035 grad: 5.141991760759127\n",
      "epoch: 12 loss: 1.9298266172409058 grad: 5.489365532146102\n",
      "epoch: 13 loss: 1.9126474857330322 grad: 5.572656974857969\n",
      "epoch: 14 loss: 1.8924753665924072 grad: 5.5426185021014325\n",
      "epoch: 15 loss: 1.9003907442092896 grad: 5.970513389601986\n",
      "epoch: 16 loss: 1.8739949464797974 grad: 5.879798871518616\n",
      "epoch: 17 loss: 1.8975118398666382 grad: 5.828888112109983\n",
      "epoch: 18 loss: 1.8456979990005493 grad: 5.613806953040203\n",
      "epoch: 19 loss: 1.8466838598251343 grad: 5.85010602294157\n",
      "epoch: 20 loss: 1.8614493608474731 grad: 6.909319582690913\n",
      "epoch: 21 loss: 1.8428293466567993 grad: 6.195437930893922\n",
      "epoch: 22 loss: 1.8226203918457031 grad: 6.256967150573877\n",
      "epoch: 23 loss: 1.8164420127868652 grad: 5.70255426483761\n",
      "epoch: 24 loss: 1.8017224073410034 grad: 5.931038800049536\n",
      "epoch: 25 loss: 1.8018114566802979 grad: 5.9289803776170755\n",
      "epoch: 26 loss: 1.7885935306549072 grad: 6.1978053722880775\n",
      "epoch: 27 loss: 1.7928293943405151 grad: 6.073305957266481\n",
      "epoch: 28 loss: 1.7882429361343384 grad: 5.442000181234714\n",
      "epoch: 29 loss: 1.8069665431976318 grad: 6.57994104444746\n",
      "epoch: 30 loss: 1.7837835550308228 grad: 5.764307060858719\n",
      "epoch: 31 loss: 1.7835701704025269 grad: 6.923950613676367\n",
      "epoch: 32 loss: 1.774189829826355 grad: 5.626213398975476\n",
      "epoch: 33 loss: 1.7757488489151 grad: 6.421065394301891\n",
      "epoch: 34 loss: 1.8049031496047974 grad: 6.340735235319857\n",
      "epoch: 35 loss: 1.7745459079742432 grad: 5.805285523869171\n",
      "epoch: 36 loss: 1.7638514041900635 grad: 6.055915586580846\n",
      "epoch: 37 loss: 1.7597941160202026 grad: 5.464809724606254\n",
      "epoch: 38 loss: 1.7653164863586426 grad: 6.054675019023841\n",
      "epoch: 39 loss: 1.7616914510726929 grad: 5.960777849171704\n",
      "epoch: 40 loss: 1.7659841775894165 grad: 6.289675012818031\n",
      "epoch: 41 loss: 1.7490023374557495 grad: 6.455044860093963\n",
      "epoch: 42 loss: 1.7612991333007812 grad: 6.084273335244183\n",
      "epoch: 43 loss: 1.717579960823059 grad: 4.748733628770597\n",
      "epoch: 44 loss: 1.7197935581207275 grad: 5.191314060055736\n",
      "epoch: 45 loss: 1.7308392524719238 grad: 5.531115206614361\n",
      "epoch: 46 loss: 1.7490015029907227 grad: 6.160284666036854\n",
      "epoch: 47 loss: 1.730162262916565 grad: 5.799232199145499\n",
      "epoch: 48 loss: 1.7366821765899658 grad: 5.732287699152717\n",
      "epoch: 49 loss: 1.7366942167282104 grad: 5.361880233904577\n",
      "epoch: 50 loss: 1.740354299545288 grad: 4.588085151235212\n",
      "epoch: 51 loss: 1.7313801050186157 grad: 5.573142931293068\n",
      "epoch: 52 loss: 1.7195760011672974 grad: 5.3192953929429345\n",
      "epoch: 53 loss: 1.7358773946762085 grad: 5.744047828767627\n",
      "epoch: 54 loss: 1.718611717224121 grad: 5.600743723856188\n",
      "epoch: 55 loss: 1.7170374393463135 grad: 5.760401167130315\n",
      "epoch: 56 loss: 1.7428510189056396 grad: 5.524205797108672\n",
      "epoch: 57 loss: 1.7149453163146973 grad: 5.368329915161927\n",
      "epoch: 58 loss: 1.7214949131011963 grad: 5.649745301877215\n",
      "epoch: 59 loss: 1.7191928625106812 grad: 4.89622668135659\n",
      "epoch: 60 loss: 1.720557689666748 grad: 5.713429628489971\n",
      "epoch: 61 loss: 1.7063462734222412 grad: 4.353425534461488\n",
      "epoch: 62 loss: 1.709975242614746 grad: 5.375601439634112\n",
      "epoch: 63 loss: 1.716640591621399 grad: 5.1233818259528245\n",
      "epoch: 64 loss: 1.7212029695510864 grad: 5.16096549284795\n",
      "epoch: 65 loss: 1.7198915481567383 grad: 4.900375732145697\n",
      "epoch: 66 loss: 1.7258267402648926 grad: 6.105341800579077\n",
      "epoch: 67 loss: 1.7159088850021362 grad: 5.054162620151709\n",
      "epoch: 68 loss: 1.7268292903900146 grad: 5.712470241529258\n",
      "epoch: 69 loss: 1.7125474214553833 grad: 4.331071483571462\n",
      "epoch: 70 loss: 1.7131214141845703 grad: 5.232012183549448\n",
      "epoch: 71 loss: 1.7158563137054443 grad: 5.670986688846911\n",
      "epoch: 72 loss: 1.712074875831604 grad: 4.069255681708455\n",
      "epoch: 73 loss: 1.7226704359054565 grad: 5.847214444681456\n",
      "epoch: 74 loss: 1.7095986604690552 grad: 5.7246114930804035\n",
      "epoch: 75 loss: 1.7068709135055542 grad: 5.019298589481171\n",
      "epoch: 76 loss: 1.691250205039978 grad: 4.0057271873755536\n",
      "epoch: 77 loss: 1.6995595693588257 grad: 4.4513160199574715\n",
      "epoch: 78 loss: 1.7045056819915771 grad: 4.484172581857748\n",
      "epoch: 79 loss: 1.6954196691513062 grad: 3.918354459862178\n",
      "epoch: 80 loss: 1.7116756439208984 grad: 4.695085048999317\n",
      "epoch: 81 loss: 1.701890230178833 grad: 4.146688470847501\n",
      "epoch: 82 loss: 1.7045968770980835 grad: 4.585933026594758\n",
      "epoch: 83 loss: 1.6963279247283936 grad: 4.353188225942075\n",
      "epoch: 84 loss: 1.691203236579895 grad: 5.036716968949645\n",
      "epoch: 85 loss: 1.6939163208007812 grad: 4.855442440638154\n",
      "epoch: 86 loss: 1.7227113246917725 grad: 4.479709182224507\n",
      "epoch: 87 loss: 1.6983627080917358 grad: 4.279487507849303\n",
      "epoch: 88 loss: 1.6910145282745361 grad: 4.496105166533847\n",
      "epoch: 89 loss: 1.6916544437408447 grad: 4.686720357587258\n",
      "epoch: 90 loss: 1.6914899349212646 grad: 4.558584548597811\n",
      "epoch: 91 loss: 1.7566652297973633 grad: 5.081128016488543\n",
      "epoch: 92 loss: 1.7087067365646362 grad: 5.793773432751001\n",
      "epoch: 93 loss: 1.6884219646453857 grad: 4.526969044188797\n",
      "epoch: 94 loss: 1.7243515253067017 grad: 4.646588625431399\n",
      "epoch: 95 loss: 1.7266451120376587 grad: 5.054492463340625\n",
      "epoch: 96 loss: 1.6955857276916504 grad: 4.889370813778608\n",
      "epoch: 97 loss: 1.6859276294708252 grad: 4.562441046485219\n",
      "epoch: 98 loss: 1.6831541061401367 grad: 3.6473397300336265\n",
      "epoch: 99 loss: 1.6935739517211914 grad: 5.405343105814287\n",
      "epoch: 100 loss: 1.6972904205322266 grad: 5.14780665823217\n",
      "epoch: 101 loss: 1.6844011545181274 grad: 4.92827395832905\n",
      "epoch: 102 loss: 1.6967867612838745 grad: 4.676322247110312\n",
      "epoch: 103 loss: 1.695779800415039 grad: 5.44001149465313\n",
      "epoch: 104 loss: 1.6969159841537476 grad: 5.2164672036711375\n",
      "epoch: 105 loss: 1.6963021755218506 grad: 4.135526820070005\n",
      "epoch: 106 loss: 1.7052663564682007 grad: 5.255440174086967\n",
      "epoch: 107 loss: 1.6992435455322266 grad: 3.52465899338504\n",
      "epoch: 108 loss: 1.6787241697311401 grad: 4.1440106455559995\n",
      "epoch: 109 loss: 1.708592414855957 grad: 4.212404271189573\n",
      "epoch: 110 loss: 1.6998977661132812 grad: 5.254283192251831\n",
      "epoch: 111 loss: 1.6945881843566895 grad: 4.340884730740097\n",
      "epoch: 112 loss: 1.6877864599227905 grad: 4.91304311364309\n",
      "epoch: 113 loss: 1.6985834836959839 grad: 4.5230449455549016\n",
      "epoch: 114 loss: 1.70503830909729 grad: 5.682895593110797\n",
      "epoch: 115 loss: 1.7211174964904785 grad: 4.3700509952632345\n",
      "epoch: 116 loss: 1.6892516613006592 grad: 4.3614245413997805\n",
      "epoch: 117 loss: 1.6865808963775635 grad: 3.968499607092723\n",
      "epoch: 118 loss: 1.6846287250518799 grad: 4.5617535266189035\n",
      "epoch: 119 loss: 1.6932443380355835 grad: 4.077850431155856\n",
      "epoch: 120 loss: 1.6761682033538818 grad: 4.2360635326208325\n",
      "epoch: 121 loss: 1.6738227605819702 grad: 4.257721160971587\n",
      "epoch: 122 loss: 1.6921881437301636 grad: 4.28545896976355\n",
      "epoch: 123 loss: 1.6909072399139404 grad: 5.0588222197336785\n",
      "epoch: 124 loss: 1.6937850713729858 grad: 5.083396448132946\n",
      "epoch: 125 loss: 1.706756353378296 grad: 5.049789984821733\n",
      "epoch: 126 loss: 1.6797306537628174 grad: 4.292530908231004\n",
      "epoch: 127 loss: 1.671869158744812 grad: 3.302338286677811\n",
      "epoch: 128 loss: 1.6777185201644897 grad: 3.5931481270230767\n",
      "epoch: 129 loss: 1.6639161109924316 grad: 3.188748244052231\n",
      "epoch: 130 loss: 1.6678942441940308 grad: 4.036990323816478\n",
      "epoch: 131 loss: 1.672349452972412 grad: 3.842658007268746\n",
      "epoch: 132 loss: 1.7045836448669434 grad: 5.544243470444642\n",
      "epoch: 133 loss: 1.7036187648773193 grad: 4.475095613808604\n",
      "epoch: 134 loss: 1.7091294527053833 grad: 5.2074231139588285\n",
      "epoch: 135 loss: 1.684300184249878 grad: 4.305693976032397\n",
      "epoch: 136 loss: 1.66966712474823 grad: 4.400587361341162\n",
      "epoch: 137 loss: 1.6823266744613647 grad: 4.666677698323815\n",
      "epoch: 138 loss: 1.6745392084121704 grad: 3.646426418726163\n",
      "epoch: 139 loss: 1.6871328353881836 grad: 4.238019721659507\n",
      "epoch: 140 loss: 1.673909306526184 grad: 3.875948439537146\n",
      "epoch: 141 loss: 1.6774636507034302 grad: 3.2339004452090423\n",
      "epoch: 142 loss: 1.6872162818908691 grad: 4.108402226841419\n",
      "epoch: 143 loss: 1.6719318628311157 grad: 3.5270195246012297\n",
      "epoch: 144 loss: 1.6844019889831543 grad: 5.072228482706109\n",
      "epoch: 145 loss: 1.6783690452575684 grad: 4.684722351195154\n",
      "epoch: 146 loss: 1.6949620246887207 grad: 4.360435627848\n",
      "epoch: 147 loss: 1.6903057098388672 grad: 3.2501065762471555\n",
      "epoch: 148 loss: 1.6834535598754883 grad: 4.886455017533331\n",
      "epoch: 149 loss: 1.6800751686096191 grad: 4.210370613187195\n",
      "epoch: 150 loss: 1.6900827884674072 grad: 4.379981815116408\n",
      "epoch: 151 loss: 1.6961066722869873 grad: 4.593201344741554\n",
      "epoch: 152 loss: 1.6902951002120972 grad: 4.99200555834841\n",
      "epoch: 153 loss: 1.6732038259506226 grad: 2.98625025375712\n",
      "epoch: 154 loss: 1.6896520853042603 grad: 4.0846711266271125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 155 loss: 1.6989810466766357 grad: 3.688573288686042\n",
      "epoch: 156 loss: 1.670580506324768 grad: 3.9444944900438164\n",
      "epoch: 157 loss: 1.669272780418396 grad: 3.609235872494484\n",
      "epoch: 158 loss: 1.6759763956069946 grad: 2.9980317712348237\n",
      "epoch: 159 loss: 1.6643620729446411 grad: 3.5519020918247755\n",
      "epoch: 160 loss: 1.6888905763626099 grad: 4.770949924692111\n",
      "epoch: 161 loss: 1.6725919246673584 grad: 3.3241248747433474\n",
      "epoch: 162 loss: 1.6802747249603271 grad: 4.617643884680792\n",
      "epoch: 163 loss: 1.6786192655563354 grad: 3.8313047906403863\n",
      "epoch: 164 loss: 1.6749682426452637 grad: 4.049773454951777\n",
      "epoch: 165 loss: 1.690575122833252 grad: 4.50374747163626\n",
      "epoch: 166 loss: 1.6864897012710571 grad: 4.701265484507822\n",
      "epoch: 167 loss: 1.6726394891738892 grad: 3.363786024884927\n",
      "epoch: 168 loss: 1.68824303150177 grad: 4.192807778563054\n",
      "epoch: 169 loss: 1.6690378189086914 grad: 2.9282237626962737\n",
      "epoch: 170 loss: 1.665853500366211 grad: 3.486275995417308\n",
      "epoch: 171 loss: 1.6900814771652222 grad: 5.328705297106842\n",
      "epoch: 172 loss: 1.6792867183685303 grad: 3.5110440545785107\n",
      "epoch: 173 loss: 1.672646403312683 grad: 3.576261614629708\n",
      "epoch: 174 loss: 1.677498698234558 grad: 3.8357835855629503\n",
      "epoch: 175 loss: 1.6802068948745728 grad: 5.197555583548995\n",
      "epoch: 176 loss: 1.6640467643737793 grad: 3.0177052514788953\n",
      "epoch: 177 loss: 1.6661537885665894 grad: 3.8481421562448417\n",
      "epoch: 178 loss: 1.6626574993133545 grad: 3.7584403917318188\n",
      "epoch: 179 loss: 1.679895281791687 grad: 5.333571660487421\n",
      "epoch: 180 loss: 1.6738051176071167 grad: 4.216838801731535\n",
      "epoch: 181 loss: 1.686596155166626 grad: 3.716978000807931\n",
      "epoch: 182 loss: 1.6769752502441406 grad: 5.587081921382623\n",
      "epoch: 183 loss: 1.6750175952911377 grad: 3.7650409939700844\n",
      "epoch: 184 loss: 1.667023777961731 grad: 3.2561375763855556\n",
      "epoch: 185 loss: 1.6666816473007202 grad: 4.637501147599446\n",
      "epoch: 186 loss: 1.6762140989303589 grad: 4.971727728937237\n",
      "epoch: 187 loss: 1.6607139110565186 grad: 2.697405088073644\n",
      "epoch: 188 loss: 1.6677449941635132 grad: 3.6370403774749103\n",
      "epoch: 189 loss: 1.6653788089752197 grad: 2.7881648169352347\n",
      "epoch: 190 loss: 1.652931809425354 grad: 3.497880207581171\n",
      "epoch: 191 loss: 1.6787221431732178 grad: 3.718798839246841\n",
      "epoch: 192 loss: 1.6638773679733276 grad: 3.2283736740184\n",
      "epoch: 193 loss: 1.6839816570281982 grad: 4.420707634215934\n",
      "epoch: 194 loss: 1.6805899143218994 grad: 4.361320215933766\n",
      "epoch: 195 loss: 1.676299810409546 grad: 3.718830415736005\n",
      "epoch: 196 loss: 1.6792936325073242 grad: 3.7793979974507046\n",
      "epoch: 197 loss: 1.6759873628616333 grad: 3.62283856439385\n",
      "epoch: 198 loss: 1.6713382005691528 grad: 3.9090705456219585\n",
      "epoch: 199 loss: 1.6676106452941895 grad: 3.722422524929703\n",
      "epoch: 200 loss: 1.675054907798767 grad: 3.5510083410782314\n",
      "epoch: 201 loss: 1.6760083436965942 grad: 4.908764669647961\n",
      "epoch: 202 loss: 1.673633098602295 grad: 4.124112882520542\n",
      "epoch: 203 loss: 1.6756505966186523 grad: 3.5733310288086946\n",
      "epoch: 204 loss: 1.6688963174819946 grad: 4.040198559422533\n",
      "epoch: 205 loss: 1.6713706254959106 grad: 3.63808389237649\n",
      "epoch: 206 loss: 1.677824854850769 grad: 3.4211793456846986\n",
      "epoch: 207 loss: 1.6716418266296387 grad: 4.860086625526289\n",
      "epoch: 208 loss: 1.6769144535064697 grad: 3.437011639666332\n",
      "epoch: 209 loss: 1.6526403427124023 grad: 2.819422371725324\n",
      "epoch: 210 loss: 1.6609529256820679 grad: 3.334353506594241\n",
      "epoch: 211 loss: 1.6604433059692383 grad: 3.947695110972796\n",
      "epoch: 212 loss: 1.6617791652679443 grad: 3.3226306074073344\n",
      "epoch: 213 loss: 1.6643402576446533 grad: 4.042852649263283\n",
      "epoch: 214 loss: 1.6782708168029785 grad: 3.8018822678446202\n",
      "epoch: 215 loss: 1.6592077016830444 grad: 2.592037361663325\n",
      "epoch: 216 loss: 1.6677379608154297 grad: 3.1483808118263896\n",
      "epoch: 217 loss: 1.6716910600662231 grad: 3.928699149983031\n",
      "epoch: 218 loss: 1.666029930114746 grad: 2.785735489862242\n",
      "epoch: 219 loss: 1.6640822887420654 grad: 3.7148178838220858\n",
      "epoch: 220 loss: 1.6597120761871338 grad: 3.77941311086329\n",
      "epoch: 221 loss: 1.6663323640823364 grad: 3.710645770340619\n",
      "epoch: 222 loss: 1.6879444122314453 grad: 3.9505436142145904\n",
      "epoch: 223 loss: 1.6608268022537231 grad: 3.0466518932889377\n",
      "epoch: 224 loss: 1.6549159288406372 grad: 3.28607086962927\n",
      "epoch: 225 loss: 1.704361081123352 grad: 5.031714361334192\n",
      "epoch: 226 loss: 1.6610575914382935 grad: 3.3107813507622392\n",
      "epoch: 227 loss: 1.6776111125946045 grad: 3.884068864097553\n",
      "epoch: 228 loss: 1.6644428968429565 grad: 3.636241517446233\n",
      "epoch: 229 loss: 1.6748961210250854 grad: 3.3385612893987067\n",
      "epoch: 230 loss: 1.6706701517105103 grad: 3.104060336680112\n",
      "epoch: 231 loss: 1.6594961881637573 grad: 2.4159465162478795\n",
      "epoch: 232 loss: 1.655339241027832 grad: 2.475843381853103\n",
      "epoch: 233 loss: 1.6623857021331787 grad: 3.3342878836279035\n",
      "epoch: 234 loss: 1.6619662046432495 grad: 3.717523375796657\n",
      "epoch: 235 loss: 1.6616084575653076 grad: 4.070316889119518\n",
      "epoch: 236 loss: 1.6606097221374512 grad: 2.594331279164391\n",
      "epoch: 237 loss: 1.6590462923049927 grad: 3.370136086951882\n",
      "epoch: 238 loss: 1.6719576120376587 grad: 2.9623241948888177\n",
      "epoch: 239 loss: 1.654078722000122 grad: 2.284876452252141\n",
      "epoch: 240 loss: 1.6568663120269775 grad: 3.5527275818382256\n",
      "epoch: 241 loss: 1.671690583229065 grad: 3.86109781978098\n",
      "epoch: 242 loss: 1.670306921005249 grad: 3.5254118159010384\n",
      "epoch: 243 loss: 1.6723233461380005 grad: 3.1572447026431703\n",
      "epoch: 244 loss: 1.6701416969299316 grad: 3.611074927532834\n",
      "epoch: 245 loss: 1.667671799659729 grad: 4.103551559236457\n",
      "epoch: 246 loss: 1.67500638961792 grad: 4.049328038204969\n",
      "epoch: 247 loss: 1.6754649877548218 grad: 3.6012973889902993\n",
      "epoch: 248 loss: 1.6691317558288574 grad: 3.789597125007414\n",
      "epoch: 249 loss: 1.6537853479385376 grad: 2.8479743774663158\n",
      "epoch: 250 loss: 1.6606379747390747 grad: 3.1397384994643085\n",
      "epoch: 251 loss: 1.6710577011108398 grad: 3.687922492502609\n",
      "epoch: 252 loss: 1.6869847774505615 grad: 4.129864099217541\n",
      "epoch: 253 loss: 1.667344093322754 grad: 3.505182007415116\n",
      "epoch: 254 loss: 1.6666827201843262 grad: 2.8020778210343273\n",
      "epoch: 255 loss: 1.6694697141647339 grad: 4.006378136199167\n",
      "epoch: 256 loss: 1.6701613664627075 grad: 3.6112833161924676\n",
      "epoch: 257 loss: 1.6618943214416504 grad: 3.144212727497989\n",
      "epoch: 258 loss: 1.6600663661956787 grad: 3.081129586731605\n",
      "epoch: 259 loss: 1.6597541570663452 grad: 3.2990828917954156\n",
      "epoch: 260 loss: 1.6770426034927368 grad: 3.220596502765642\n",
      "epoch: 261 loss: 1.683591604232788 grad: 3.46185348015974\n",
      "epoch: 262 loss: 1.669377088546753 grad: 3.316029861353932\n",
      "epoch: 263 loss: 1.6663753986358643 grad: 3.797691712130034\n",
      "epoch: 264 loss: 1.6761157512664795 grad: 3.5934201761811524\n",
      "epoch: 265 loss: 1.6713241338729858 grad: 3.632925915800732\n",
      "epoch: 266 loss: 1.658382534980774 grad: 3.534579338152381\n",
      "epoch: 267 loss: 1.670932412147522 grad: 3.553219543255056\n",
      "epoch: 268 loss: 1.6688977479934692 grad: 3.689715768774222\n",
      "epoch: 269 loss: 1.6654667854309082 grad: 3.7911633327451666\n",
      "epoch: 270 loss: 1.652947187423706 grad: 2.705721168101635\n",
      "epoch: 271 loss: 1.6593660116195679 grad: 3.3654631823894943\n",
      "epoch: 272 loss: 1.6579715013504028 grad: 3.234494345361933\n",
      "epoch: 273 loss: 1.6481506824493408 grad: 3.352070660050475\n",
      "epoch: 274 loss: 1.6639412641525269 grad: 4.321929139668943\n",
      "epoch: 275 loss: 1.6731722354888916 grad: 3.5376020315973493\n",
      "epoch: 276 loss: 1.6457419395446777 grad: 3.9260996592698674\n",
      "epoch: 277 loss: 1.65513277053833 grad: 3.8244846198836417\n",
      "epoch: 278 loss: 1.6351847648620605 grad: 3.4323616264795196\n",
      "epoch: 279 loss: 1.632243275642395 grad: 3.5753565478281732\n",
      "epoch: 280 loss: 1.6370774507522583 grad: 3.1750659923210947\n",
      "epoch: 281 loss: 1.650207757949829 grad: 4.152919569762781\n",
      "epoch: 282 loss: 1.6527990102767944 grad: 3.323649192627816\n",
      "epoch: 283 loss: 1.6529117822647095 grad: 5.029074312550497\n",
      "epoch: 284 loss: 1.6572128534317017 grad: 3.7961185999691094\n",
      "epoch: 285 loss: 1.6419706344604492 grad: 4.4229519820268255\n",
      "epoch: 286 loss: 1.6413501501083374 grad: 3.935188151940565\n",
      "epoch: 287 loss: 1.6546335220336914 grad: 3.5017028143236013\n",
      "epoch: 288 loss: 1.6423170566558838 grad: 3.2255413524873555\n",
      "epoch: 289 loss: 1.645519733428955 grad: 3.8476216832116785\n",
      "epoch: 290 loss: 1.6496553421020508 grad: 3.932940302691448\n",
      "epoch: 291 loss: 1.6495932340621948 grad: 3.9360473928145687\n",
      "epoch: 292 loss: 1.6466946601867676 grad: 3.107197837125326\n",
      "epoch: 293 loss: 1.6496741771697998 grad: 3.705036228637349\n",
      "epoch: 294 loss: 1.6536024808883667 grad: 3.849113128505865\n",
      "epoch: 295 loss: 1.6365323066711426 grad: 3.7009062669394073\n",
      "epoch: 296 loss: 1.6588616371154785 grad: 3.403174741930524\n",
      "epoch: 297 loss: 1.6517585515975952 grad: 3.6916600979492036\n",
      "epoch: 298 loss: 1.6433217525482178 grad: 3.5938265332935204\n",
      "epoch: 299 loss: 1.6477257013320923 grad: 4.2061084731918\n",
      "epoch: 300 loss: 1.6398475170135498 grad: 3.4044562253225297\n",
      "epoch: 301 loss: 1.6422024965286255 grad: 4.00404698974128\n",
      "epoch: 302 loss: 1.6305394172668457 grad: 4.091629476164414\n",
      "epoch: 303 loss: 1.6345051527023315 grad: 2.536272640198369\n",
      "epoch: 304 loss: 1.6475365161895752 grad: 3.298555827443144\n",
      "epoch: 305 loss: 1.641031265258789 grad: 4.176077926459371\n",
      "epoch: 306 loss: 1.6395014524459839 grad: 4.612868277634466\n",
      "epoch: 307 loss: 1.6535042524337769 grad: 5.025089537373961\n",
      "epoch: 308 loss: 1.6190413236618042 grad: 5.023311124023427\n",
      "epoch: 309 loss: 1.62891685962677 grad: 5.141530179298198\n",
      "epoch: 310 loss: 1.6381769180297852 grad: 5.469578313562103\n",
      "epoch: 311 loss: 1.6189526319503784 grad: 3.519781895255582\n",
      "epoch: 312 loss: 1.622833013534546 grad: 4.52707899242142\n",
      "epoch: 313 loss: 1.6227284669876099 grad: 4.855994993555979\n",
      "epoch: 314 loss: 1.6066778898239136 grad: 5.0227542499755655\n",
      "epoch: 315 loss: 1.609034776687622 grad: 4.968804015796902\n",
      "epoch: 316 loss: 1.6252427101135254 grad: 4.556205702273506\n",
      "epoch: 317 loss: 1.613476276397705 grad: 4.3773210769237725\n",
      "epoch: 318 loss: 1.605620265007019 grad: 5.0548826537972555\n",
      "epoch: 319 loss: 1.609869122505188 grad: 3.7444549665584015\n",
      "epoch: 320 loss: 1.6145033836364746 grad: 5.2877920614163525\n",
      "epoch: 321 loss: 1.605424404144287 grad: 5.045086434736948\n",
      "epoch: 322 loss: 1.5881885290145874 grad: 4.774539204497929\n",
      "epoch: 323 loss: 1.601473331451416 grad: 4.621698929401361\n",
      "epoch: 324 loss: 1.5904375314712524 grad: 4.25259816750677\n",
      "epoch: 325 loss: 1.6012918949127197 grad: 4.683789532403697\n",
      "epoch: 326 loss: 1.5910221338272095 grad: 4.349735295215487\n",
      "epoch: 327 loss: 1.6122931241989136 grad: 4.7659739081980605\n",
      "epoch: 328 loss: 1.5886125564575195 grad: 3.909889714170745\n",
      "epoch: 329 loss: 1.5858209133148193 grad: 3.5201098100791195\n",
      "epoch: 330 loss: 1.5672003030776978 grad: 3.4514275904656104\n",
      "epoch: 331 loss: 1.596969723701477 grad: 5.279984580868546\n",
      "epoch: 332 loss: 1.5791665315628052 grad: 3.7471899930929586\n",
      "epoch: 333 loss: 1.5863797664642334 grad: 3.2746130316493023\n",
      "epoch: 334 loss: 1.5828900337219238 grad: 5.830485874463886\n",
      "epoch: 335 loss: 1.6189820766448975 grad: 4.745884745625315\n",
      "epoch: 336 loss: 1.5838512182235718 grad: 4.570306433598969\n",
      "epoch: 337 loss: 1.6081247329711914 grad: 4.649373557496628\n",
      "epoch: 338 loss: 1.57211172580719 grad: 3.880170678595247\n",
      "epoch: 339 loss: 1.599790096282959 grad: 5.106559839490981\n",
      "epoch: 340 loss: 1.5825169086456299 grad: 3.9444075509631364\n",
      "epoch: 341 loss: 1.579649567604065 grad: 4.52786078309698\n",
      "epoch: 342 loss: 1.5733228921890259 grad: 4.069793545563721\n",
      "epoch: 343 loss: 1.5662373304367065 grad: 4.201013261149762\n",
      "epoch: 344 loss: 1.577160358428955 grad: 4.460152533022798\n",
      "epoch: 345 loss: 1.5656189918518066 grad: 3.3638357297458636\n",
      "epoch: 346 loss: 1.5801365375518799 grad: 4.6131355817398285\n",
      "epoch: 347 loss: 1.5739508867263794 grad: 3.706470873706458\n",
      "epoch: 348 loss: 1.5713335275650024 grad: 4.756288447867331\n",
      "epoch: 349 loss: 1.5835180282592773 grad: 4.582833383308146\n",
      "epoch: 350 loss: 1.589590311050415 grad: 4.014185973236412\n",
      "epoch: 351 loss: 1.566141963005066 grad: 3.3730494596665612\n",
      "epoch: 352 loss: 1.5743985176086426 grad: 4.1858210991002\n",
      "epoch: 353 loss: 1.564258337020874 grad: 4.217694214037332\n",
      "epoch: 354 loss: 1.6071430444717407 grad: 3.870910808931799\n",
      "epoch: 355 loss: 1.5670957565307617 grad: 3.515564562828915\n",
      "epoch: 356 loss: 1.5734773874282837 grad: 4.351965448858171\n",
      "epoch: 357 loss: 1.5611463785171509 grad: 3.135362201289289\n",
      "epoch: 358 loss: 1.5744017362594604 grad: 4.65656394705315\n",
      "epoch: 359 loss: 1.5667163133621216 grad: 3.8455702228653195\n",
      "epoch: 360 loss: 1.579322338104248 grad: 4.159543318501091\n",
      "epoch: 361 loss: 1.5813164710998535 grad: 4.068939814139274\n",
      "epoch: 362 loss: 1.5798845291137695 grad: 6.272940503871456\n",
      "epoch: 363 loss: 1.5774353742599487 grad: 4.314838047586623\n",
      "epoch: 364 loss: 1.5763390064239502 grad: 3.7728447912184326\n",
      "epoch: 365 loss: 1.5801687240600586 grad: 4.962357583617759\n",
      "epoch: 366 loss: 1.5896984338760376 grad: 4.06003178351012\n",
      "epoch: 367 loss: 1.5907998085021973 grad: 4.271070266998432\n",
      "epoch: 368 loss: 1.5707788467407227 grad: 4.74745527270707\n",
      "epoch: 369 loss: 1.584545373916626 grad: 5.390396231462216\n",
      "epoch: 370 loss: 1.577483892440796 grad: 2.5010606519916907\n",
      "epoch: 371 loss: 1.5750592947006226 grad: 4.824769507483163\n",
      "epoch: 372 loss: 1.5818308591842651 grad: 4.845317733520792\n",
      "epoch: 373 loss: 1.5744922161102295 grad: 3.6836976517821522\n",
      "epoch: 374 loss: 1.5688189268112183 grad: 3.8354602569503182\n",
      "epoch: 375 loss: 1.5662504434585571 grad: 3.4980940762684822\n",
      "epoch: 376 loss: 1.5682790279388428 grad: 3.6698928242140587\n",
      "epoch: 377 loss: 1.5678564310073853 grad: 3.4591311106758353\n",
      "epoch: 378 loss: 1.5660208463668823 grad: 3.9479626026480394\n",
      "epoch: 379 loss: 1.5557708740234375 grad: 3.67319815820593\n",
      "epoch: 380 loss: 1.5679214000701904 grad: 4.688683017822909\n",
      "epoch: 381 loss: 1.5582810640335083 grad: 4.088801980508231\n",
      "epoch: 382 loss: 1.5733956098556519 grad: 4.272940922955434\n",
      "epoch: 383 loss: 1.5716617107391357 grad: 3.6477415516597906\n",
      "epoch: 384 loss: 1.5648151636123657 grad: 4.436596102777582\n",
      "epoch: 385 loss: 1.566314458847046 grad: 3.8777373797985693\n",
      "epoch: 386 loss: 1.5618571043014526 grad: 3.727253366652223\n",
      "epoch: 387 loss: 1.5742723941802979 grad: 2.8705057856188305\n",
      "epoch: 388 loss: 1.5699355602264404 grad: 3.5216049708627657\n",
      "epoch: 389 loss: 1.5635055303573608 grad: 3.7552068802019223\n",
      "epoch: 390 loss: 1.5872368812561035 grad: 4.43864660530639\n",
      "epoch: 391 loss: 1.564300775527954 grad: 4.1359392370216765\n",
      "epoch: 392 loss: 1.5557634830474854 grad: 2.7231318503835933\n",
      "epoch: 393 loss: 1.5556572675704956 grad: 3.669144833875745\n",
      "epoch: 394 loss: 1.5663548707962036 grad: 3.5093904466336125\n",
      "epoch: 395 loss: 1.5545954704284668 grad: 3.981509469580226\n",
      "epoch: 396 loss: 1.561896562576294 grad: 4.627029632962214\n",
      "epoch: 397 loss: 1.5606095790863037 grad: 3.579317177952103\n",
      "epoch: 398 loss: 1.5654475688934326 grad: 5.388387873639752\n",
      "epoch: 399 loss: 1.5656236410140991 grad: 4.449176159931806\n",
      "epoch: 400 loss: 1.5661267042160034 grad: 3.735306228847822\n",
      "epoch: 401 loss: 1.5740363597869873 grad: 4.343178126607575\n",
      "epoch: 402 loss: 1.5914061069488525 grad: 5.181357321245936\n",
      "epoch: 403 loss: 1.573297381401062 grad: 3.896933636250793\n",
      "epoch: 404 loss: 1.5611035823822021 grad: 5.3647738318751825\n",
      "epoch: 405 loss: 1.6044657230377197 grad: 5.712609272587516\n",
      "epoch: 406 loss: 1.5635312795639038 grad: 4.126797380975157\n",
      "epoch: 407 loss: 1.5631589889526367 grad: 5.068282540273304\n",
      "epoch: 408 loss: 1.5715075731277466 grad: 4.084214810954345\n",
      "epoch: 409 loss: 1.5784724950790405 grad: 4.077112104908432\n",
      "epoch: 410 loss: 1.578598141670227 grad: 5.5461646246281155\n",
      "epoch: 411 loss: 1.5694546699523926 grad: 5.100967744302517\n",
      "epoch: 412 loss: 1.5547171831130981 grad: 3.285211243299842\n",
      "epoch: 413 loss: 1.5631521940231323 grad: 3.8946729191817377\n",
      "epoch: 414 loss: 1.5594974756240845 grad: 3.834856679182543\n",
      "epoch: 415 loss: 1.5605181455612183 grad: 4.402266336599691\n",
      "epoch: 416 loss: 1.5567286014556885 grad: 3.897857067721305\n",
      "epoch: 417 loss: 1.5565603971481323 grad: 4.660054951653141\n",
      "epoch: 418 loss: 1.5726709365844727 grad: 4.228056970937153\n",
      "epoch: 419 loss: 1.5576660633087158 grad: 4.181502628395026\n",
      "epoch: 420 loss: 1.5488828420639038 grad: 3.608805311411321\n",
      "epoch: 421 loss: 1.5540987253189087 grad: 3.5942060294676437\n",
      "epoch: 422 loss: 1.5643701553344727 grad: 4.67588583917853\n",
      "epoch: 423 loss: 1.5672820806503296 grad: 4.586448804262686\n",
      "epoch: 424 loss: 1.563711404800415 grad: 3.1055982431273415\n",
      "epoch: 425 loss: 1.5490020513534546 grad: 3.3007624154817754\n",
      "epoch: 426 loss: 1.5533567667007446 grad: 3.54033206781744\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 427 loss: 1.5637177228927612 grad: 4.438861217669089\n",
      "epoch: 428 loss: 1.556054949760437 grad: 3.8224590117437462\n",
      "epoch: 429 loss: 1.586193323135376 grad: 5.0553772660962775\n",
      "epoch: 430 loss: 1.5629009008407593 grad: 2.7666306537528005\n",
      "epoch: 431 loss: 1.5591164827346802 grad: 3.5580968808841935\n",
      "epoch: 432 loss: 1.5668166875839233 grad: 4.320584140875934\n",
      "epoch: 433 loss: 1.5645910501480103 grad: 4.74062649970134\n",
      "epoch: 434 loss: 1.554800271987915 grad: 3.8637549086306375\n",
      "epoch: 435 loss: 1.561623215675354 grad: 5.086659930013867\n",
      "epoch: 436 loss: 1.5504891872406006 grad: 3.2640765689282114\n",
      "epoch: 437 loss: 1.5723007917404175 grad: 5.211224609118736\n",
      "epoch: 438 loss: 1.571282982826233 grad: 4.835587971653166\n",
      "epoch: 439 loss: 1.5551881790161133 grad: 3.3448484584420393\n",
      "epoch: 440 loss: 1.5552021265029907 grad: 2.953554035558133\n",
      "epoch: 441 loss: 1.544842004776001 grad: 3.4109233389620015\n",
      "epoch: 442 loss: 1.5491530895233154 grad: 3.7433034263986174\n",
      "epoch: 443 loss: 1.5515477657318115 grad: 4.07165496758678\n",
      "epoch: 444 loss: 1.5442123413085938 grad: 4.087471020702086\n",
      "epoch: 445 loss: 1.5471460819244385 grad: 3.093771703332076\n",
      "epoch: 446 loss: 1.5597327947616577 grad: 4.571675669833272\n",
      "epoch: 447 loss: 1.5579125881195068 grad: 3.5060908392952315\n",
      "epoch: 448 loss: 1.5427054166793823 grad: 3.8092009878756588\n",
      "epoch: 449 loss: 1.5604801177978516 grad: 3.5426025662273144\n",
      "epoch: 450 loss: 1.5619049072265625 grad: 3.679932816508207\n",
      "epoch: 451 loss: 1.5548419952392578 grad: 3.452689318210324\n",
      "epoch: 452 loss: 1.549675703048706 grad: 2.9304424494025145\n",
      "epoch: 453 loss: 1.5466437339782715 grad: 3.007327623510711\n",
      "epoch: 454 loss: 1.5656379461288452 grad: 4.586749715165165\n",
      "epoch: 455 loss: 1.5522528886795044 grad: 2.9341833743019685\n",
      "epoch: 456 loss: 1.5785651206970215 grad: 3.7168734476308942\n",
      "epoch: 457 loss: 1.5686047077178955 grad: 4.759279967122682\n",
      "epoch: 458 loss: 1.5614240169525146 grad: 4.080309584635781\n",
      "epoch: 459 loss: 1.5559331178665161 grad: 3.902218749671786\n",
      "epoch: 460 loss: 1.5514605045318604 grad: 4.1512946039327066\n",
      "epoch: 461 loss: 1.5616302490234375 grad: 4.770375984232461\n",
      "epoch: 462 loss: 1.5670392513275146 grad: 3.9914530189494775\n",
      "epoch: 463 loss: 1.5536189079284668 grad: 3.044809474158286\n",
      "epoch: 464 loss: 1.5437251329421997 grad: 2.225279961251029\n",
      "epoch: 465 loss: 1.5634030103683472 grad: 4.098651406882855\n",
      "epoch: 466 loss: 1.5675745010375977 grad: 4.435124335329857\n",
      "epoch: 467 loss: 1.5464962720870972 grad: 3.708899235137939\n",
      "epoch: 468 loss: 1.5481849908828735 grad: 4.220379544337498\n",
      "epoch: 469 loss: 1.5593138933181763 grad: 4.741442217148053\n",
      "epoch: 470 loss: 1.5506304502487183 grad: 3.6588302137749324\n",
      "epoch: 471 loss: 1.5730676651000977 grad: 4.481837479039431\n",
      "epoch: 472 loss: 1.558298945426941 grad: 4.298426559852426\n",
      "epoch: 473 loss: 1.5524214506149292 grad: 4.2294598916208965\n",
      "epoch: 474 loss: 1.5520411729812622 grad: 2.5495160132409462\n",
      "epoch: 475 loss: 1.5338404178619385 grad: 3.4649080156576373\n",
      "epoch: 476 loss: 1.5570801496505737 grad: 4.418601818641101\n",
      "epoch: 477 loss: 1.5514500141143799 grad: 3.0182429241464765\n",
      "epoch: 478 loss: 1.558690071105957 grad: 3.5378280933127817\n",
      "epoch: 479 loss: 1.5569231510162354 grad: 2.6456313952605366\n",
      "epoch: 480 loss: 1.5605629682540894 grad: 4.732339415457171\n",
      "epoch: 481 loss: 1.5555267333984375 grad: 3.206178113587437\n",
      "epoch: 482 loss: 1.5560133457183838 grad: 3.938954569644925\n",
      "epoch: 483 loss: 1.544974446296692 grad: 3.4926333522193307\n",
      "epoch: 484 loss: 1.5673573017120361 grad: 4.741094719577255\n",
      "epoch: 485 loss: 1.5467920303344727 grad: 3.380373959452879\n",
      "epoch: 486 loss: 1.5418663024902344 grad: 2.5834110183898407\n",
      "epoch: 487 loss: 1.5397214889526367 grad: 3.3796030675833593\n",
      "epoch: 488 loss: 1.5416966676712036 grad: 3.494870589864384\n",
      "epoch: 489 loss: 1.5429333448410034 grad: 3.5539304622489873\n",
      "epoch: 490 loss: 1.5480672121047974 grad: 2.8825553840504234\n",
      "epoch: 491 loss: 1.5415273904800415 grad: 3.413696368688003\n",
      "epoch: 492 loss: 1.5430153608322144 grad: 3.2861113902389265\n",
      "epoch: 493 loss: 1.5404433012008667 grad: 3.664593288369961\n",
      "epoch: 494 loss: 1.5512664318084717 grad: 4.04634031094651\n",
      "epoch: 495 loss: 1.54270339012146 grad: 4.198961180939731\n",
      "epoch: 496 loss: 1.5527877807617188 grad: 3.8375437936333854\n",
      "epoch: 497 loss: 1.555226445198059 grad: 4.688850389369897\n",
      "epoch: 498 loss: 1.5672905445098877 grad: 4.556738175804759\n",
      "epoch: 499 loss: 1.5673227310180664 grad: 3.2511971786237175\n",
      "1.9006889835000038\n",
      "epoch: 0 loss: 2.3026058673858643 grad: 1.3710755521490696\n",
      "epoch: 1 loss: 2.3031299114227295 grad: 1.359347474576521\n",
      "epoch: 2 loss: 2.3025739192962646 grad: 1.3693038139377707\n",
      "epoch: 3 loss: 2.3023624420166016 grad: 1.368957615152578\n",
      "epoch: 4 loss: 2.302811622619629 grad: 1.361563818399898\n",
      "epoch: 5 loss: 2.303361177444458 grad: 1.352226960199279\n",
      "epoch: 6 loss: 2.3025259971618652 grad: 1.3614669904474996\n",
      "epoch: 7 loss: 2.302767276763916 grad: 1.3759867315631478\n",
      "epoch: 8 loss: 2.3032329082489014 grad: 1.366698060212435\n",
      "epoch: 9 loss: 2.3028066158294678 grad: 1.3626596160816946\n",
      "epoch: 10 loss: 2.302471160888672 grad: 1.377309915594875\n",
      "epoch: 11 loss: 2.3028202056884766 grad: 1.3665569756542228\n",
      "epoch: 12 loss: 2.3033506870269775 grad: 1.3667884759220577\n",
      "epoch: 13 loss: 2.3022994995117188 grad: 1.3735306597155859\n",
      "epoch: 14 loss: 2.3024492263793945 grad: 1.369587323238467\n",
      "epoch: 15 loss: 2.303148031234741 grad: 1.3670625840369168\n",
      "epoch: 16 loss: 2.3027029037475586 grad: 1.3714270598868588\n",
      "epoch: 17 loss: 2.302793502807617 grad: 1.3714164616650946\n",
      "epoch: 18 loss: 2.3026599884033203 grad: 1.3681106452482739\n",
      "epoch: 19 loss: 2.302455186843872 grad: 1.3716817960837886\n",
      "epoch: 20 loss: 2.3026974201202393 grad: 1.3690065753679457\n",
      "epoch: 21 loss: 2.3022618293762207 grad: 1.370218149914835\n",
      "epoch: 22 loss: 2.3029351234436035 grad: 1.3661343345958148\n",
      "epoch: 23 loss: 2.3032174110412598 grad: 1.3700566693497378\n",
      "epoch: 24 loss: 2.3022565841674805 grad: 1.3747829862977452\n",
      "epoch: 25 loss: 2.3026037216186523 grad: 1.3698242928496458\n",
      "epoch: 26 loss: 2.302429676055908 grad: 1.3757123792884014\n",
      "epoch: 27 loss: 2.3024744987487793 grad: 1.3724082358336698\n",
      "epoch: 28 loss: 2.3022987842559814 grad: 1.3727933789366886\n",
      "epoch: 29 loss: 2.3024120330810547 grad: 1.3714649218082842\n",
      "epoch: 30 loss: 2.302072525024414 grad: 1.38176706261445\n",
      "epoch: 31 loss: 2.3028502464294434 grad: 1.363986308364907\n",
      "epoch: 32 loss: 2.3020923137664795 grad: 1.3778288777777186\n",
      "epoch: 33 loss: 2.302396774291992 grad: 1.3667059920262545\n",
      "epoch: 34 loss: 2.302222728729248 grad: 1.3736390979324897\n",
      "epoch: 35 loss: 2.3027710914611816 grad: 1.3646409541575446\n",
      "epoch: 36 loss: 2.3022496700286865 grad: 1.3795334837059416\n",
      "epoch: 37 loss: 2.302553415298462 grad: 1.367962650182317\n",
      "epoch: 38 loss: 2.3024933338165283 grad: 1.357102224178287\n",
      "epoch: 39 loss: 2.3026106357574463 grad: 1.3684754115603273\n",
      "epoch: 40 loss: 2.302377223968506 grad: 1.378851477226745\n",
      "epoch: 41 loss: 2.303013801574707 grad: 1.3679008050988029\n",
      "epoch: 42 loss: 2.3028244972229004 grad: 1.3774216685939344\n",
      "epoch: 43 loss: 2.30283522605896 grad: 1.366579332019365\n",
      "epoch: 44 loss: 2.302942991256714 grad: 1.369188499141721\n",
      "epoch: 45 loss: 2.3027005195617676 grad: 1.3633763417361364\n",
      "epoch: 46 loss: 2.3029844760894775 grad: 1.3661488561395791\n",
      "epoch: 47 loss: 2.302462100982666 grad: 1.371395639321279\n",
      "epoch: 48 loss: 2.3020682334899902 grad: 1.367915437841374\n",
      "epoch: 49 loss: 2.302600860595703 grad: 1.3790377971276433\n",
      "epoch: 50 loss: 2.3028664588928223 grad: 1.3592702191736963\n",
      "epoch: 51 loss: 2.302551507949829 grad: 1.374828384769711\n",
      "epoch: 52 loss: 2.3025412559509277 grad: 1.3702557071163837\n",
      "epoch: 53 loss: 2.302745819091797 grad: 1.3666441123452155\n",
      "epoch: 54 loss: 2.3023746013641357 grad: 1.3601291497821906\n",
      "epoch: 55 loss: 2.3029704093933105 grad: 1.3700290978609009\n",
      "epoch: 56 loss: 2.3025622367858887 grad: 1.3735857840427863\n",
      "epoch: 57 loss: 2.3023769855499268 grad: 1.378460650358142\n",
      "epoch: 58 loss: 2.3031113147735596 grad: 1.3697184356491243\n",
      "epoch: 59 loss: 2.3030176162719727 grad: 1.357280930945842\n",
      "epoch: 60 loss: 2.3024709224700928 grad: 1.3620427577859826\n",
      "epoch: 61 loss: 2.3019864559173584 grad: 1.3758331784195015\n",
      "epoch: 62 loss: 2.302926778793335 grad: 1.3680918270459634\n",
      "epoch: 63 loss: 2.3024725914001465 grad: 1.3637521128901946\n",
      "epoch: 64 loss: 2.3020288944244385 grad: 1.3748978981508002\n",
      "epoch: 65 loss: 2.3027148246765137 grad: 1.3615860302677556\n",
      "epoch: 66 loss: 2.303114891052246 grad: 1.364201108233944\n",
      "epoch: 67 loss: 2.3027775287628174 grad: 1.357916744276216\n",
      "epoch: 68 loss: 2.302229166030884 grad: 1.3748689084092067\n",
      "epoch: 69 loss: 2.302415370941162 grad: 1.377231136603754\n",
      "epoch: 70 loss: 2.302710771560669 grad: 1.3767777169252642\n",
      "epoch: 71 loss: 2.3026375770568848 grad: 1.3706167113065484\n",
      "epoch: 72 loss: 2.3023667335510254 grad: 1.3773218456744438\n",
      "epoch: 73 loss: 2.302574396133423 grad: 1.3681149909768018\n",
      "epoch: 74 loss: 2.302407741546631 grad: 1.3802220091105453\n",
      "epoch: 75 loss: 2.3025596141815186 grad: 1.3652155485876378\n",
      "epoch: 76 loss: 2.3029966354370117 grad: 1.3649668747943544\n",
      "epoch: 77 loss: 2.302222490310669 grad: 1.3702755700094655\n",
      "epoch: 78 loss: 2.3024423122406006 grad: 1.377314620446192\n",
      "epoch: 79 loss: 2.3024730682373047 grad: 1.36998752292083\n",
      "epoch: 80 loss: 2.3024110794067383 grad: 1.375325411428801\n",
      "epoch: 81 loss: 2.302990198135376 grad: 1.3715232260994583\n",
      "epoch: 82 loss: 2.30228853225708 grad: 1.3743934159957996\n",
      "epoch: 83 loss: 2.302729368209839 grad: 1.3641287790600298\n",
      "epoch: 84 loss: 2.3026185035705566 grad: 1.3627270618268836\n",
      "epoch: 85 loss: 2.3025624752044678 grad: 1.359414804606728\n",
      "epoch: 86 loss: 2.302361488342285 grad: 1.3839687295886318\n",
      "epoch: 87 loss: 2.3027265071868896 grad: 1.3722871412663529\n",
      "epoch: 88 loss: 2.3030078411102295 grad: 1.367753605864617\n",
      "epoch: 89 loss: 2.302449941635132 grad: 1.3653838002799257\n",
      "epoch: 90 loss: 2.3026697635650635 grad: 1.3688409557373868\n",
      "epoch: 91 loss: 2.3028481006622314 grad: 1.3764554902741184\n",
      "epoch: 92 loss: 2.302638292312622 grad: 1.3596816120525113\n",
      "epoch: 93 loss: 2.302558422088623 grad: 1.3764472389076319\n",
      "epoch: 94 loss: 2.3025670051574707 grad: 1.3722736480172784\n",
      "epoch: 95 loss: 2.302194595336914 grad: 1.3727018993037443\n",
      "epoch: 96 loss: 2.30206298828125 grad: 1.3837779430184691\n",
      "epoch: 97 loss: 2.3027615547180176 grad: 1.3645138208724794\n",
      "epoch: 98 loss: 2.3027660846710205 grad: 1.364969653864613\n",
      "epoch: 99 loss: 2.302640438079834 grad: 1.367317622047036\n",
      "epoch: 100 loss: 2.302915573120117 grad: 1.3573953121205762\n",
      "epoch: 101 loss: 2.302220106124878 grad: 1.3687211925141691\n",
      "epoch: 102 loss: 2.302610397338867 grad: 1.374563782954485\n",
      "epoch: 103 loss: 2.3028576374053955 grad: 1.3536633680729817\n",
      "epoch: 104 loss: 2.3029019832611084 grad: 1.3627477231350476\n",
      "epoch: 105 loss: 2.3026833534240723 grad: 1.3699384993090042\n",
      "epoch: 106 loss: 2.302046775817871 grad: 1.364027377284531\n",
      "epoch: 107 loss: 2.302243947982788 grad: 1.3647524702421847\n",
      "epoch: 108 loss: 2.302729368209839 grad: 1.3699632420404149\n",
      "epoch: 109 loss: 2.3024511337280273 grad: 1.3629620425432685\n",
      "epoch: 110 loss: 2.302783250808716 grad: 1.367572699643908\n",
      "epoch: 111 loss: 2.3028056621551514 grad: 1.36653700870617\n",
      "epoch: 112 loss: 2.30273175239563 grad: 1.3701811740932512\n",
      "epoch: 113 loss: 2.302276611328125 grad: 1.3794513900139709\n",
      "epoch: 114 loss: 2.3023059368133545 grad: 1.3751886619184728\n",
      "epoch: 115 loss: 2.3021061420440674 grad: 1.364733611695498\n",
      "epoch: 116 loss: 2.302645683288574 grad: 1.3722168883855737\n",
      "epoch: 117 loss: 2.302774667739868 grad: 1.3627726067086712\n",
      "epoch: 118 loss: 2.302093267440796 grad: 1.3741319116485853\n",
      "epoch: 119 loss: 2.3025972843170166 grad: 1.367702410489853\n",
      "epoch: 120 loss: 2.3028924465179443 grad: 1.3679186863425588\n",
      "epoch: 121 loss: 2.3025174140930176 grad: 1.3700741850068823\n",
      "epoch: 122 loss: 2.302354574203491 grad: 1.3774918464367234\n",
      "epoch: 123 loss: 2.302020311355591 grad: 1.373817806653235\n",
      "epoch: 124 loss: 2.303180456161499 grad: 1.3570631703783183\n",
      "epoch: 125 loss: 2.3024563789367676 grad: 1.3650740621600388\n",
      "epoch: 126 loss: 2.302877187728882 grad: 1.360931770863115\n",
      "epoch: 127 loss: 2.302152156829834 grad: 1.3762034229742037\n",
      "epoch: 128 loss: 2.302412748336792 grad: 1.3656235311498186\n",
      "epoch: 129 loss: 2.3028714656829834 grad: 1.3722805210374414\n",
      "epoch: 130 loss: 2.3026037216186523 grad: 1.3595596252412105\n",
      "epoch: 131 loss: 2.302504062652588 grad: 1.3612765282252064\n",
      "epoch: 132 loss: 2.302666425704956 grad: 1.3570366875261128\n",
      "epoch: 133 loss: 2.3025193214416504 grad: 1.3690905280851036\n",
      "epoch: 134 loss: 2.302018404006958 grad: 1.3627160790391148\n",
      "epoch: 135 loss: 2.30214786529541 grad: 1.3704339569242345\n",
      "epoch: 136 loss: 2.3028969764709473 grad: 1.3643445963195215\n",
      "epoch: 137 loss: 2.302154064178467 grad: 1.3633594196289778\n",
      "epoch: 138 loss: 2.302273750305176 grad: 1.3709716901297695\n",
      "epoch: 139 loss: 2.3025877475738525 grad: 1.369709883175332\n",
      "epoch: 140 loss: 2.3031041622161865 grad: 1.3560494943706702\n",
      "epoch: 141 loss: 2.3025856018066406 grad: 1.364454038618576\n",
      "epoch: 142 loss: 2.303086280822754 grad: 1.3627658779437224\n",
      "epoch: 143 loss: 2.3023929595947266 grad: 1.3762767929047908\n",
      "epoch: 144 loss: 2.30238938331604 grad: 1.3735535271975787\n",
      "epoch: 145 loss: 2.302654504776001 grad: 1.3675039324554659\n",
      "epoch: 146 loss: 2.30338454246521 grad: 1.3596426264127894\n",
      "epoch: 147 loss: 2.3023386001586914 grad: 1.3617310318874107\n",
      "epoch: 148 loss: 2.301851749420166 grad: 1.3859836722276957\n",
      "epoch: 149 loss: 2.302194356918335 grad: 1.3716890490188869\n",
      "epoch: 150 loss: 2.302187919616699 grad: 1.3787858941156181\n",
      "epoch: 151 loss: 2.30254864692688 grad: 1.370108633089648\n",
      "epoch: 152 loss: 2.302511692047119 grad: 1.3608188611743528\n",
      "epoch: 153 loss: 2.3027429580688477 grad: 1.3603170074814457\n",
      "epoch: 154 loss: 2.3026044368743896 grad: 1.3677260512818716\n",
      "epoch: 155 loss: 2.3027148246765137 grad: 1.356871876333441\n",
      "epoch: 156 loss: 2.3027243614196777 grad: 1.3579488132474204\n",
      "epoch: 157 loss: 2.3025922775268555 grad: 1.359863794752441\n",
      "epoch: 158 loss: 2.3024675846099854 grad: 1.374050731718954\n",
      "epoch: 159 loss: 2.302396059036255 grad: 1.3750940187989424\n",
      "epoch: 160 loss: 2.302109718322754 grad: 1.3640740006156857\n",
      "epoch: 161 loss: 2.302649736404419 grad: 1.3600118437538011\n",
      "epoch: 162 loss: 2.3018369674682617 grad: 1.3790986474921247\n",
      "epoch: 163 loss: 2.3026106357574463 grad: 1.3580346605518745\n",
      "epoch: 164 loss: 2.3024699687957764 grad: 1.3627849404094001\n",
      "epoch: 165 loss: 2.3025362491607666 grad: 1.3633508191347892\n",
      "epoch: 166 loss: 2.3023808002471924 grad: 1.372717093469368\n",
      "epoch: 167 loss: 2.3022568225860596 grad: 1.3682175094191547\n",
      "epoch: 168 loss: 2.302222490310669 grad: 1.3709691536062145\n",
      "epoch: 169 loss: 2.3019325733184814 grad: 1.3730253719111225\n",
      "epoch: 170 loss: 2.302375555038452 grad: 1.3691253727967185\n",
      "epoch: 171 loss: 2.30256724357605 grad: 1.3611118382116454\n",
      "epoch: 172 loss: 2.301870822906494 grad: 1.3788727163411085\n",
      "epoch: 173 loss: 2.302908182144165 grad: 1.3675495553743242\n",
      "epoch: 174 loss: 2.3024325370788574 grad: 1.3664337213350726\n",
      "epoch: 175 loss: 2.3019254207611084 grad: 1.3675112110481316\n",
      "epoch: 176 loss: 2.30258846282959 grad: 1.3729564740603406\n",
      "epoch: 177 loss: 2.3027353286743164 grad: 1.3702221503111696\n",
      "epoch: 178 loss: 2.3024752140045166 grad: 1.3540019049246366\n",
      "epoch: 179 loss: 2.302691698074341 grad: 1.3745089335152731\n",
      "epoch: 180 loss: 2.302618980407715 grad: 1.3645521346461176\n",
      "epoch: 181 loss: 2.3023335933685303 grad: 1.3721716706973635\n",
      "epoch: 182 loss: 2.3024957180023193 grad: 1.3632114628839882\n",
      "epoch: 183 loss: 2.3022382259368896 grad: 1.3708078580398468\n",
      "epoch: 184 loss: 2.303032875061035 grad: 1.357359937447611\n",
      "epoch: 185 loss: 2.3023898601531982 grad: 1.3800115995515612\n",
      "epoch: 186 loss: 2.302570104598999 grad: 1.3705288592267721\n",
      "epoch: 187 loss: 2.302290201187134 grad: 1.3674494327094022\n",
      "epoch: 188 loss: 2.3023946285247803 grad: 1.3740628764314193\n",
      "epoch: 189 loss: 2.3019609451293945 grad: 1.3783497049229307\n",
      "epoch: 190 loss: 2.3029208183288574 grad: 1.3611334955489764\n",
      "epoch: 191 loss: 2.302548408508301 grad: 1.3679099806680506\n",
      "epoch: 192 loss: 2.302253246307373 grad: 1.371630180070901\n",
      "epoch: 193 loss: 2.303083896636963 grad: 1.3581157520151002\n",
      "epoch: 194 loss: 2.3028011322021484 grad: 1.3713420310227702\n",
      "epoch: 195 loss: 2.3027610778808594 grad: 1.3644700569640253\n",
      "epoch: 196 loss: 2.3027236461639404 grad: 1.374412475445766\n",
      "epoch: 197 loss: 2.3026621341705322 grad: 1.356247232707646\n",
      "epoch: 198 loss: 2.302931070327759 grad: 1.3633034827468533\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 199 loss: 2.3014872074127197 grad: 1.3753544315215318\n",
      "epoch: 200 loss: 2.302356481552124 grad: 1.3691202988958961\n",
      "epoch: 201 loss: 2.3022406101226807 grad: 1.380880995276606\n",
      "epoch: 202 loss: 2.302504301071167 grad: 1.3700193215239171\n",
      "epoch: 203 loss: 2.3023743629455566 grad: 1.3705364162848879\n",
      "epoch: 204 loss: 2.3023970127105713 grad: 1.3670891422320097\n",
      "epoch: 205 loss: 2.3020401000976562 grad: 1.3808772272304706\n",
      "epoch: 206 loss: 2.301907539367676 grad: 1.376909029919521\n",
      "epoch: 207 loss: 2.3018994331359863 grad: 1.3793012645864298\n",
      "epoch: 208 loss: 2.3024954795837402 grad: 1.3715802791181007\n",
      "epoch: 209 loss: 2.3020052909851074 grad: 1.3865559161529832\n",
      "epoch: 210 loss: 2.3032238483428955 grad: 1.3612242396699177\n",
      "epoch: 211 loss: 2.3019816875457764 grad: 1.3662893589815155\n",
      "epoch: 212 loss: 2.3017208576202393 grad: 1.3754529139500051\n",
      "epoch: 213 loss: 2.302490711212158 grad: 1.3713855600106486\n",
      "epoch: 214 loss: 2.3025801181793213 grad: 1.357230922168431\n",
      "epoch: 215 loss: 2.303205966949463 grad: 1.3598874126050977\n",
      "epoch: 216 loss: 2.3020308017730713 grad: 1.3725535733041367\n",
      "epoch: 217 loss: 2.302104949951172 grad: 1.3684733292172915\n",
      "epoch: 218 loss: 2.3027570247650146 grad: 1.36168759042168\n",
      "epoch: 219 loss: 2.302048683166504 grad: 1.3775884705828503\n",
      "epoch: 220 loss: 2.302629232406616 grad: 1.3604975628171352\n",
      "epoch: 221 loss: 2.302049398422241 grad: 1.379548920470009\n",
      "epoch: 222 loss: 2.3029801845550537 grad: 1.362493308083642\n",
      "epoch: 223 loss: 2.3027429580688477 grad: 1.3684488663464667\n",
      "epoch: 224 loss: 2.3020029067993164 grad: 1.3751730044771517\n",
      "epoch: 225 loss: 2.302090883255005 grad: 1.3696058997034377\n",
      "epoch: 226 loss: 2.3023722171783447 grad: 1.3594842089602488\n",
      "epoch: 227 loss: 2.302366256713867 grad: 1.3700687063650951\n",
      "epoch: 228 loss: 2.30207896232605 grad: 1.3820713859509737\n",
      "epoch: 229 loss: 2.3026721477508545 grad: 1.3677610717233388\n",
      "epoch: 230 loss: 2.303112030029297 grad: 1.3553693933349604\n",
      "epoch: 231 loss: 2.302258253097534 grad: 1.365564881849827\n",
      "epoch: 232 loss: 2.3023228645324707 grad: 1.3672638925213723\n",
      "epoch: 233 loss: 2.302351474761963 grad: 1.3705941951863232\n",
      "epoch: 234 loss: 2.302516222000122 grad: 1.3720174310544122\n",
      "epoch: 235 loss: 2.302487850189209 grad: 1.3602820677194922\n",
      "epoch: 236 loss: 2.302849769592285 grad: 1.3617317712799246\n",
      "epoch: 237 loss: 2.301966667175293 grad: 1.3787298848841427\n",
      "epoch: 238 loss: 2.3024659156799316 grad: 1.3645440405456437\n",
      "epoch: 239 loss: 2.302530288696289 grad: 1.3686350485908665\n",
      "epoch: 240 loss: 2.3020355701446533 grad: 1.3722614135800137\n",
      "epoch: 241 loss: 2.3023428916931152 grad: 1.3674163537521271\n",
      "epoch: 242 loss: 2.3028805255889893 grad: 1.3725829733228903\n",
      "epoch: 243 loss: 2.302910804748535 grad: 1.3663928885999623\n",
      "epoch: 244 loss: 2.30267333984375 grad: 1.3622668748277993\n",
      "epoch: 245 loss: 2.3022348880767822 grad: 1.3758923057300438\n",
      "epoch: 246 loss: 2.301945924758911 grad: 1.3747694458191593\n",
      "epoch: 247 loss: 2.3024213314056396 grad: 1.3755269804193329\n",
      "epoch: 248 loss: 2.3018319606781006 grad: 1.38489951003742\n",
      "epoch: 249 loss: 2.3022327423095703 grad: 1.3684383337921833\n",
      "epoch: 250 loss: 2.301490068435669 grad: 1.3898234339375493\n",
      "epoch: 251 loss: 2.3023858070373535 grad: 1.3639050257126135\n",
      "epoch: 252 loss: 2.3029818534851074 grad: 1.3643234476838852\n",
      "epoch: 253 loss: 2.3020808696746826 grad: 1.3721891105515025\n",
      "epoch: 254 loss: 2.3021481037139893 grad: 1.3713295916797563\n",
      "epoch: 255 loss: 2.3022286891937256 grad: 1.3693200059878152\n",
      "epoch: 256 loss: 2.3026793003082275 grad: 1.3609635687085786\n",
      "epoch: 257 loss: 2.302340030670166 grad: 1.371538534642212\n",
      "epoch: 258 loss: 2.3027985095977783 grad: 1.3678601533063643\n",
      "epoch: 259 loss: 2.3029329776763916 grad: 1.3607984605330294\n",
      "epoch: 260 loss: 2.3026840686798096 grad: 1.3602905210369962\n",
      "epoch: 261 loss: 2.302959442138672 grad: 1.3573727270843283\n",
      "epoch: 262 loss: 2.3026785850524902 grad: 1.3607277204393453\n",
      "epoch: 263 loss: 2.302119255065918 grad: 1.3750221613380644\n",
      "epoch: 264 loss: 2.302324056625366 grad: 1.3701047207421018\n",
      "epoch: 265 loss: 2.3015589714050293 grad: 1.3777413884887384\n",
      "epoch: 266 loss: 2.301740884780884 grad: 1.388902002239659\n",
      "epoch: 267 loss: 2.3024566173553467 grad: 1.3768755925564273\n",
      "epoch: 268 loss: 2.302471876144409 grad: 1.366610840129267\n",
      "epoch: 269 loss: 2.3020334243774414 grad: 1.3763203489860254\n",
      "epoch: 270 loss: 2.3027098178863525 grad: 1.36295229291159\n",
      "epoch: 271 loss: 2.301962375640869 grad: 1.3804967894573652\n",
      "epoch: 272 loss: 2.3022866249084473 grad: 1.3657140146778335\n",
      "epoch: 273 loss: 2.301992893218994 grad: 1.3785143031845875\n",
      "epoch: 274 loss: 2.3024702072143555 grad: 1.3609523697541879\n",
      "epoch: 275 loss: 2.302056074142456 grad: 1.3679851513311623\n",
      "epoch: 276 loss: 2.301490306854248 grad: 1.3804831522302554\n",
      "epoch: 277 loss: 2.302377939224243 grad: 1.3671123145798605\n",
      "epoch: 278 loss: 2.302436590194702 grad: 1.3681691795816675\n",
      "epoch: 279 loss: 2.302018642425537 grad: 1.3785274990350156\n",
      "epoch: 280 loss: 2.301849365234375 grad: 1.3755752020700287\n",
      "epoch: 281 loss: 2.302720785140991 grad: 1.366340244052163\n",
      "epoch: 282 loss: 2.302189826965332 grad: 1.3771655476145772\n",
      "epoch: 283 loss: 2.301734685897827 grad: 1.3804316773367602\n",
      "epoch: 284 loss: 2.302194356918335 grad: 1.3707498399363387\n",
      "epoch: 285 loss: 2.302388906478882 grad: 1.3607403753502738\n",
      "epoch: 286 loss: 2.3020553588867188 grad: 1.376025354678166\n",
      "epoch: 287 loss: 2.30218243598938 grad: 1.3718867900056972\n",
      "epoch: 288 loss: 2.301879644393921 grad: 1.3708496280162343\n",
      "epoch: 289 loss: 2.302196741104126 grad: 1.3819206581369692\n",
      "epoch: 290 loss: 2.302393913269043 grad: 1.3743413391020445\n",
      "epoch: 291 loss: 2.302555561065674 grad: 1.3683743922147042\n",
      "epoch: 292 loss: 2.3016605377197266 grad: 1.3872644579766082\n",
      "epoch: 293 loss: 2.302002191543579 grad: 1.3748268785309934\n",
      "epoch: 294 loss: 2.3018319606781006 grad: 1.3814183332539711\n",
      "epoch: 295 loss: 2.301445245742798 grad: 1.3866365813716715\n",
      "epoch: 296 loss: 2.3024356365203857 grad: 1.3663379168507481\n",
      "epoch: 297 loss: 2.3024508953094482 grad: 1.3766591530699757\n",
      "epoch: 298 loss: 2.3018405437469482 grad: 1.3798318498930524\n",
      "epoch: 299 loss: 2.3020179271698 grad: 1.3862485743962998\n",
      "epoch: 300 loss: 2.3023626804351807 grad: 1.3846075811889023\n",
      "epoch: 301 loss: 2.3025214672088623 grad: 1.3687815932494158\n",
      "epoch: 302 loss: 2.3024909496307373 grad: 1.3669953940173847\n",
      "epoch: 303 loss: 2.3027658462524414 grad: 1.3711632990226563\n",
      "epoch: 304 loss: 2.301713705062866 grad: 1.3720844307736981\n",
      "epoch: 305 loss: 2.3018956184387207 grad: 1.3915283370408273\n",
      "epoch: 306 loss: 2.3021647930145264 grad: 1.3726004005358037\n",
      "epoch: 307 loss: 2.3026578426361084 grad: 1.3756941793050381\n",
      "epoch: 308 loss: 2.3025152683258057 grad: 1.36700664447724\n",
      "epoch: 309 loss: 2.3019907474517822 grad: 1.3816411644996454\n",
      "epoch: 310 loss: 2.3021159172058105 grad: 1.3792496221287855\n",
      "epoch: 311 loss: 2.3017613887786865 grad: 1.3760951817375682\n",
      "epoch: 312 loss: 2.3025612831115723 grad: 1.376465243279993\n",
      "epoch: 313 loss: 2.3021697998046875 grad: 1.3725212525487656\n",
      "epoch: 314 loss: 2.3020105361938477 grad: 1.3830460878458644\n",
      "epoch: 315 loss: 2.301939010620117 grad: 1.3877796347286286\n",
      "epoch: 316 loss: 2.301832437515259 grad: 1.3811328053430079\n",
      "epoch: 317 loss: 2.302436351776123 grad: 1.3702401105972333\n",
      "epoch: 318 loss: 2.3021023273468018 grad: 1.3749793268821484\n",
      "epoch: 319 loss: 2.30271315574646 grad: 1.3684662820896991\n",
      "epoch: 320 loss: 2.302561044692993 grad: 1.3742314677090488\n",
      "epoch: 321 loss: 2.3029112815856934 grad: 1.3582072852009406\n",
      "epoch: 322 loss: 2.302474021911621 grad: 1.3740759644572371\n",
      "epoch: 323 loss: 2.3022196292877197 grad: 1.3842712570765308\n",
      "epoch: 324 loss: 2.3027071952819824 grad: 1.376553918072392\n",
      "epoch: 325 loss: 2.3025143146514893 grad: 1.3787148476777864\n",
      "epoch: 326 loss: 2.3025166988372803 grad: 1.370685010664313\n",
      "epoch: 327 loss: 2.3019514083862305 grad: 1.382545208013321\n",
      "epoch: 328 loss: 2.3025481700897217 grad: 1.3729419355532007\n",
      "epoch: 329 loss: 2.302456855773926 grad: 1.3792006756744482\n",
      "epoch: 330 loss: 2.3026604652404785 grad: 1.374452359588181\n",
      "epoch: 331 loss: 2.301935911178589 grad: 1.3790157338851945\n",
      "epoch: 332 loss: 2.3023924827575684 grad: 1.380706246591188\n",
      "epoch: 333 loss: 2.302417516708374 grad: 1.3703022516620833\n",
      "epoch: 334 loss: 2.3024840354919434 grad: 1.3745095865017483\n",
      "epoch: 335 loss: 2.302020788192749 grad: 1.3835204794175096\n",
      "epoch: 336 loss: 2.3027145862579346 grad: 1.374265438958352\n",
      "epoch: 337 loss: 2.3022706508636475 grad: 1.3722456254320041\n",
      "epoch: 338 loss: 2.3023617267608643 grad: 1.3739913402879167\n",
      "epoch: 339 loss: 2.302297830581665 grad: 1.3853411133334572\n",
      "epoch: 340 loss: 2.302452325820923 grad: 1.379727204230481\n",
      "epoch: 341 loss: 2.3019299507141113 grad: 1.3857229470722525\n",
      "epoch: 342 loss: 2.3022499084472656 grad: 1.3706837104973457\n",
      "epoch: 343 loss: 2.3018672466278076 grad: 1.3746739024710324\n",
      "epoch: 344 loss: 2.3022146224975586 grad: 1.3725330059468333\n",
      "epoch: 345 loss: 2.3020219802856445 grad: 1.3881884242171452\n",
      "epoch: 346 loss: 2.302449941635132 grad: 1.3740587985431332\n",
      "epoch: 347 loss: 2.3017537593841553 grad: 1.384083912013069\n",
      "epoch: 348 loss: 2.3015546798706055 grad: 1.3945710669301215\n",
      "epoch: 349 loss: 2.3021154403686523 grad: 1.3816031128230934\n",
      "epoch: 350 loss: 2.3025619983673096 grad: 1.3769395188631726\n",
      "epoch: 351 loss: 2.3021187782287598 grad: 1.3797462795905413\n",
      "epoch: 352 loss: 2.302816390991211 grad: 1.3685206122666833\n",
      "epoch: 353 loss: 2.3026068210601807 grad: 1.3767689642688585\n",
      "epoch: 354 loss: 2.3021907806396484 grad: 1.370838667155199\n",
      "epoch: 355 loss: 2.3025882244110107 grad: 1.368932152913499\n",
      "epoch: 356 loss: 2.3021671772003174 grad: 1.3787730387375055\n",
      "epoch: 357 loss: 2.301738739013672 grad: 1.3857927031977664\n",
      "epoch: 358 loss: 2.3019449710845947 grad: 1.376048909383826\n",
      "epoch: 359 loss: 2.302452802658081 grad: 1.3704498483067644\n",
      "epoch: 360 loss: 2.302173614501953 grad: 1.3647086297398403\n",
      "epoch: 361 loss: 2.3022515773773193 grad: 1.3669303930179764\n",
      "epoch: 362 loss: 2.30196475982666 grad: 1.3746788455173373\n",
      "epoch: 363 loss: 2.3021624088287354 grad: 1.3717243209470151\n",
      "epoch: 364 loss: 2.30198073387146 grad: 1.3794244358755856\n",
      "epoch: 365 loss: 2.302731513977051 grad: 1.3748862873208487\n",
      "epoch: 366 loss: 2.3021793365478516 grad: 1.3771925392109783\n",
      "epoch: 367 loss: 2.301985263824463 grad: 1.3864448387711679\n",
      "epoch: 368 loss: 2.3021814823150635 grad: 1.373406291165064\n",
      "epoch: 369 loss: 2.302098035812378 grad: 1.3786013342536216\n",
      "epoch: 370 loss: 2.3021700382232666 grad: 1.3814279119121946\n",
      "epoch: 371 loss: 2.301513671875 grad: 1.3774145177883348\n",
      "epoch: 372 loss: 2.301753044128418 grad: 1.392135394097764\n",
      "epoch: 373 loss: 2.301805257797241 grad: 1.3839931003730892\n",
      "epoch: 374 loss: 2.3021817207336426 grad: 1.384474945038424\n",
      "epoch: 375 loss: 2.3018248081207275 grad: 1.3856498419310868\n",
      "epoch: 376 loss: 2.301936626434326 grad: 1.3845022832013902\n",
      "epoch: 377 loss: 2.301755666732788 grad: 1.3940013479385969\n",
      "epoch: 378 loss: 2.3022854328155518 grad: 1.3760854015829012\n",
      "epoch: 379 loss: 2.301616907119751 grad: 1.3821036537355256\n",
      "epoch: 380 loss: 2.301676034927368 grad: 1.3913548186214433\n",
      "epoch: 381 loss: 2.3021223545074463 grad: 1.3776451535947947\n",
      "epoch: 382 loss: 2.3017165660858154 grad: 1.3903704033425404\n",
      "epoch: 383 loss: 2.3025479316711426 grad: 1.3717159600263196\n",
      "epoch: 384 loss: 2.301759958267212 grad: 1.3751098349901094\n",
      "epoch: 385 loss: 2.3010594844818115 grad: 1.3944795851998533\n",
      "epoch: 386 loss: 2.3020834922790527 grad: 1.3801273710042652\n",
      "epoch: 387 loss: 2.301659107208252 grad: 1.3843788805709678\n",
      "epoch: 388 loss: 2.301947832107544 grad: 1.3797030000326533\n",
      "epoch: 389 loss: 2.302117109298706 grad: 1.3865422692874239\n",
      "epoch: 390 loss: 2.3021881580352783 grad: 1.3848966460172383\n",
      "epoch: 391 loss: 2.301950454711914 grad: 1.37589256503501\n",
      "epoch: 392 loss: 2.3022172451019287 grad: 1.3796803208238015\n",
      "epoch: 393 loss: 2.301835775375366 grad: 1.3904647283174747\n",
      "epoch: 394 loss: 2.3018455505371094 grad: 1.3880924922488038\n",
      "epoch: 395 loss: 2.301560163497925 grad: 1.3950480160854077\n",
      "epoch: 396 loss: 2.302314043045044 grad: 1.3867784630588538\n",
      "epoch: 397 loss: 2.3021321296691895 grad: 1.3816079896919073\n",
      "epoch: 398 loss: 2.3028194904327393 grad: 1.375357666346688\n",
      "epoch: 399 loss: 2.302263021469116 grad: 1.3718140964407386\n",
      "epoch: 400 loss: 2.3015682697296143 grad: 1.3895548459859417\n",
      "epoch: 401 loss: 2.301527738571167 grad: 1.4002780996093025\n",
      "epoch: 402 loss: 2.3020691871643066 grad: 1.3783170676989747\n",
      "epoch: 403 loss: 2.30179762840271 grad: 1.3954455998748363\n",
      "epoch: 404 loss: 2.3013017177581787 grad: 1.3974271196786994\n",
      "epoch: 405 loss: 2.302022933959961 grad: 1.3959567093157343\n",
      "epoch: 406 loss: 2.302269697189331 grad: 1.3897413231935056\n",
      "epoch: 407 loss: 2.3017830848693848 grad: 1.3860959240719528\n",
      "epoch: 408 loss: 2.3021130561828613 grad: 1.3866427389125058\n",
      "epoch: 409 loss: 2.302067279815674 grad: 1.3922908942414713\n",
      "epoch: 410 loss: 2.3016083240509033 grad: 1.3980309314220138\n",
      "epoch: 411 loss: 2.301645517349243 grad: 1.3899294365722212\n",
      "epoch: 412 loss: 2.3016600608825684 grad: 1.3920868282605494\n",
      "epoch: 413 loss: 2.3019895553588867 grad: 1.3868460797109745\n",
      "epoch: 414 loss: 2.301687479019165 grad: 1.3961917310343346\n",
      "epoch: 415 loss: 2.3018624782562256 grad: 1.3802891918827618\n",
      "epoch: 416 loss: 2.3017380237579346 grad: 1.3908915400859856\n",
      "epoch: 417 loss: 2.302172899246216 grad: 1.3887068827983937\n",
      "epoch: 418 loss: 2.30218768119812 grad: 1.3797072412664189\n",
      "epoch: 419 loss: 2.3019778728485107 grad: 1.3959755060458852\n",
      "epoch: 420 loss: 2.3018481731414795 grad: 1.3916082659529314\n",
      "epoch: 421 loss: 2.301945924758911 grad: 1.3930786612059272\n",
      "epoch: 422 loss: 2.3018836975097656 grad: 1.3934845659615738\n",
      "epoch: 423 loss: 2.3017826080322266 grad: 1.3899828394863842\n",
      "epoch: 424 loss: 2.3016793727874756 grad: 1.3936051848078412\n",
      "epoch: 425 loss: 2.3023977279663086 grad: 1.3929012808302004\n",
      "epoch: 426 loss: 2.3017656803131104 grad: 1.3914594892116765\n",
      "epoch: 427 loss: 2.3025026321411133 grad: 1.3809087802267943\n",
      "epoch: 428 loss: 2.301633358001709 grad: 1.3964876364731778\n",
      "epoch: 429 loss: 2.30198073387146 grad: 1.3838391739815947\n",
      "epoch: 430 loss: 2.3020925521850586 grad: 1.3855927373071955\n",
      "epoch: 431 loss: 2.302018165588379 grad: 1.393091609812386\n",
      "epoch: 432 loss: 2.301828384399414 grad: 1.3888106697261156\n",
      "epoch: 433 loss: 2.3015103340148926 grad: 1.4044816319309619\n",
      "epoch: 434 loss: 2.3015782833099365 grad: 1.4023712965962847\n",
      "epoch: 435 loss: 2.3017122745513916 grad: 1.3999934206653888\n",
      "epoch: 436 loss: 2.3019840717315674 grad: 1.3924369295053776\n",
      "epoch: 437 loss: 2.3018152713775635 grad: 1.3979058375061002\n",
      "epoch: 438 loss: 2.3019659519195557 grad: 1.3861273392048177\n",
      "epoch: 439 loss: 2.3018600940704346 grad: 1.4017574697925104\n",
      "epoch: 440 loss: 2.3018760681152344 grad: 1.3809132124629937\n",
      "epoch: 441 loss: 2.3022241592407227 grad: 1.3931612177596737\n",
      "epoch: 442 loss: 2.301525592803955 grad: 1.3887814963273408\n",
      "epoch: 443 loss: 2.3013901710510254 grad: 1.4064342482736156\n",
      "epoch: 444 loss: 2.301492214202881 grad: 1.403344447876046\n",
      "epoch: 445 loss: 2.3018417358398438 grad: 1.39369956534245\n",
      "epoch: 446 loss: 2.301501750946045 grad: 1.4054320666805975\n",
      "epoch: 447 loss: 2.301715612411499 grad: 1.388382701458232\n",
      "epoch: 448 loss: 2.3015267848968506 grad: 1.4047110789411126\n",
      "epoch: 449 loss: 2.302049160003662 grad: 1.39752947454459\n",
      "epoch: 450 loss: 2.301987409591675 grad: 1.4024509095572053\n",
      "epoch: 451 loss: 2.3018832206726074 grad: 1.3964060111588517\n",
      "epoch: 452 loss: 2.3011996746063232 grad: 1.415512271351107\n",
      "epoch: 453 loss: 2.301764488220215 grad: 1.391745250402314\n",
      "epoch: 454 loss: 2.3014185428619385 grad: 1.4094510159163278\n",
      "epoch: 455 loss: 2.301262617111206 grad: 1.4173126021466618\n",
      "epoch: 456 loss: 2.301950693130493 grad: 1.394463154444811\n",
      "epoch: 457 loss: 2.3018226623535156 grad: 1.3993804968897223\n",
      "epoch: 458 loss: 2.302051544189453 grad: 1.3853370252154058\n",
      "epoch: 459 loss: 2.302095890045166 grad: 1.4059208140021102\n",
      "epoch: 460 loss: 2.300928831100464 grad: 1.4157978900604777\n",
      "epoch: 461 loss: 2.301370620727539 grad: 1.408770027884563\n",
      "epoch: 462 loss: 2.3024802207946777 grad: 1.3931115103944662\n",
      "epoch: 463 loss: 2.3018739223480225 grad: 1.395936098892153\n",
      "epoch: 464 loss: 2.301755666732788 grad: 1.405182331076099\n",
      "epoch: 465 loss: 2.3018267154693604 grad: 1.4013771806725315\n",
      "epoch: 466 loss: 2.3022897243499756 grad: 1.3907674448121161\n",
      "epoch: 467 loss: 2.301054000854492 grad: 1.4203151660354159\n",
      "epoch: 468 loss: 2.3018100261688232 grad: 1.4120332480016504\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 469 loss: 2.30202579498291 grad: 1.398933199204741\n",
      "epoch: 470 loss: 2.301366090774536 grad: 1.4041113021657876\n",
      "epoch: 471 loss: 2.300708770751953 grad: 1.423697565944629\n",
      "epoch: 472 loss: 2.3019261360168457 grad: 1.405077693442489\n",
      "epoch: 473 loss: 2.301786184310913 grad: 1.410772312144261\n",
      "epoch: 474 loss: 2.3012094497680664 grad: 1.4127771192200718\n",
      "epoch: 475 loss: 2.301790952682495 grad: 1.408229664921583\n",
      "epoch: 476 loss: 2.3012726306915283 grad: 1.4158185523923574\n",
      "epoch: 477 loss: 2.301382541656494 grad: 1.405525953058035\n",
      "epoch: 478 loss: 2.3018994331359863 grad: 1.395815139532917\n",
      "epoch: 479 loss: 2.3016579151153564 grad: 1.407533695960107\n",
      "epoch: 480 loss: 2.3015522956848145 grad: 1.417753495978162\n",
      "epoch: 481 loss: 2.301286458969116 grad: 1.4197142711389692\n",
      "epoch: 482 loss: 2.3021111488342285 grad: 1.4126450542068583\n",
      "epoch: 483 loss: 2.3017590045928955 grad: 1.3976424771327791\n",
      "epoch: 484 loss: 2.3011271953582764 grad: 1.4243242096798938\n",
      "epoch: 485 loss: 2.301311731338501 grad: 1.4164206517494418\n",
      "epoch: 486 loss: 2.301924467086792 grad: 1.39890745901207\n",
      "epoch: 487 loss: 2.3017942905426025 grad: 1.416398774041602\n",
      "epoch: 488 loss: 2.3011996746063232 grad: 1.423582674815349\n",
      "epoch: 489 loss: 2.301936388015747 grad: 1.4009298310108809\n",
      "epoch: 490 loss: 2.301743507385254 grad: 1.4211451656680318\n",
      "epoch: 491 loss: 2.301964282989502 grad: 1.408523392390519\n",
      "epoch: 492 loss: 2.301737070083618 grad: 1.42079149280113\n",
      "epoch: 493 loss: 2.3014473915100098 grad: 1.4121312848218377\n",
      "epoch: 494 loss: 2.3010854721069336 grad: 1.4295054365777307\n",
      "epoch: 495 loss: 2.301327705383301 grad: 1.4128801437678733\n",
      "epoch: 496 loss: 2.301622152328491 grad: 1.4073838799164469\n",
      "epoch: 497 loss: 2.301466464996338 grad: 1.426872400051382\n",
      "epoch: 498 loss: 2.3014965057373047 grad: 1.4186945801087107\n",
      "epoch: 499 loss: 2.3012313842773438 grad: 1.4280351701613871\n",
      "2.303410515189171\n",
      "epoch: 0 loss: 2.302797555923462 grad: 1.3088898121652799\n",
      "epoch: 1 loss: 2.3023555278778076 grad: 1.2774176320194133\n",
      "epoch: 2 loss: 2.3023691177368164 grad: 1.2810977204898668\n",
      "epoch: 3 loss: 2.3030340671539307 grad: 1.2587778517654875\n",
      "epoch: 4 loss: 2.3031911849975586 grad: 1.2473866460412475\n",
      "epoch: 5 loss: 2.302682876586914 grad: 1.241122375593506\n",
      "epoch: 6 loss: 2.303227663040161 grad: 1.2124478991424281\n",
      "epoch: 7 loss: 2.302367925643921 grad: 1.2289343005497126\n",
      "epoch: 8 loss: 2.3022584915161133 grad: 1.230610605116771\n",
      "epoch: 9 loss: 2.3028740882873535 grad: 1.2100797539968635\n",
      "epoch: 10 loss: 2.3028151988983154 grad: 1.2166613364400016\n",
      "epoch: 11 loss: 2.3025729656219482 grad: 1.218428534368748\n",
      "epoch: 12 loss: 2.3028066158294678 grad: 1.209946198071102\n",
      "epoch: 13 loss: 2.3035130500793457 grad: 1.2030844967091634\n",
      "epoch: 14 loss: 2.302844524383545 grad: 1.2123704515896472\n",
      "epoch: 15 loss: 2.302337408065796 grad: 1.2068283638809734\n",
      "epoch: 16 loss: 2.302819013595581 grad: 1.2222324559531574\n",
      "epoch: 17 loss: 2.3031318187713623 grad: 1.2118979731208779\n",
      "epoch: 18 loss: 2.3024463653564453 grad: 1.2111402727637648\n",
      "epoch: 19 loss: 2.302517890930176 grad: 1.2107540147567524\n",
      "epoch: 20 loss: 2.3024799823760986 grad: 1.19780820055813\n",
      "epoch: 21 loss: 2.302227258682251 grad: 1.210290027150352\n",
      "epoch: 22 loss: 2.3024849891662598 grad: 1.1950716996853727\n",
      "epoch: 23 loss: 2.3023571968078613 grad: 1.2009648075678372\n",
      "epoch: 24 loss: 2.3026998043060303 grad: 1.193707711362679\n",
      "epoch: 25 loss: 2.302609443664551 grad: 1.1970287469928966\n",
      "epoch: 26 loss: 2.3020567893981934 grad: 1.2032800110533746\n",
      "epoch: 27 loss: 2.3025009632110596 grad: 1.2076750416437991\n",
      "epoch: 28 loss: 2.302410364151001 grad: 1.1943287862601528\n",
      "epoch: 29 loss: 2.30167293548584 grad: 1.2157282303752643\n",
      "epoch: 30 loss: 2.3024158477783203 grad: 1.1986260819526033\n",
      "epoch: 31 loss: 2.3021485805511475 grad: 1.2020171101607884\n",
      "epoch: 32 loss: 2.302100896835327 grad: 1.213024692022286\n",
      "epoch: 33 loss: 2.3024044036865234 grad: 1.2112146385017752\n",
      "epoch: 34 loss: 2.3016793727874756 grad: 1.218860354134074\n",
      "epoch: 35 loss: 2.301774024963379 grad: 1.2196794868805372\n",
      "epoch: 36 loss: 2.3020026683807373 grad: 1.2062836527447438\n",
      "epoch: 37 loss: 2.301901340484619 grad: 1.2300966340523687\n",
      "epoch: 38 loss: 2.3012495040893555 grad: 1.2339282217879026\n",
      "epoch: 39 loss: 2.3014414310455322 grad: 1.2316123005612531\n",
      "epoch: 40 loss: 2.300912857055664 grad: 1.2395861518221893\n",
      "epoch: 41 loss: 2.3011527061462402 grad: 1.261998797704037\n",
      "epoch: 42 loss: 2.3008062839508057 grad: 1.2443798957817582\n",
      "epoch: 43 loss: 2.3008062839508057 grad: 1.2691731176483223\n",
      "epoch: 44 loss: 2.3012735843658447 grad: 1.265385638802342\n",
      "epoch: 45 loss: 2.3001906871795654 grad: 1.2964931500221912\n",
      "epoch: 46 loss: 2.2996864318847656 grad: 1.2980266183980607\n",
      "epoch: 47 loss: 2.3001797199249268 grad: 1.3180171033323167\n",
      "epoch: 48 loss: 2.2994723320007324 grad: 1.3315953768841509\n",
      "epoch: 49 loss: 2.3001415729522705 grad: 1.334311137720573\n",
      "epoch: 50 loss: 2.2991344928741455 grad: 1.3704496265170978\n",
      "epoch: 51 loss: 2.3000340461730957 grad: 1.3562426731001498\n",
      "epoch: 52 loss: 2.2990856170654297 grad: 1.374759818663791\n",
      "epoch: 53 loss: 2.298860549926758 grad: 1.4062972951159325\n",
      "epoch: 54 loss: 2.2979373931884766 grad: 1.4585872100544206\n",
      "epoch: 55 loss: 2.297755002975464 grad: 1.453010521738583\n",
      "epoch: 56 loss: 2.2977893352508545 grad: 1.4825941696707603\n",
      "epoch: 57 loss: 2.297173500061035 grad: 1.4901070472496074\n",
      "epoch: 58 loss: 2.297171115875244 grad: 1.4878685116538748\n",
      "epoch: 59 loss: 2.2966089248657227 grad: 1.5116535537111173\n",
      "epoch: 60 loss: 2.2953574657440186 grad: 1.5213430014749367\n",
      "epoch: 61 loss: 2.293527603149414 grad: 1.643872120694834\n",
      "epoch: 62 loss: 2.2949090003967285 grad: 1.5930074767231763\n",
      "epoch: 63 loss: 2.2950246334075928 grad: 1.6536251189933706\n",
      "epoch: 64 loss: 2.294110059738159 grad: 1.6558716961271351\n",
      "epoch: 65 loss: 2.2926182746887207 grad: 1.6764935921870232\n",
      "epoch: 66 loss: 2.2929766178131104 grad: 1.6959663348970935\n",
      "epoch: 67 loss: 2.293998956680298 grad: 1.6948961572119197\n",
      "epoch: 68 loss: 2.2921879291534424 grad: 1.7102959333652896\n",
      "epoch: 69 loss: 2.2922585010528564 grad: 1.651768250555347\n",
      "epoch: 70 loss: 2.2914037704467773 grad: 1.6818233542088863\n",
      "epoch: 71 loss: 2.29313063621521 grad: 1.6976707526113068\n",
      "epoch: 72 loss: 2.291249990463257 grad: 1.712003341358569\n",
      "epoch: 73 loss: 2.2900373935699463 grad: 1.7294905256546502\n",
      "epoch: 74 loss: 2.2893171310424805 grad: 1.705762178910571\n",
      "epoch: 75 loss: 2.2907583713531494 grad: 1.7515214851277598\n",
      "epoch: 76 loss: 2.2897379398345947 grad: 1.7195759085746156\n",
      "epoch: 77 loss: 2.289433717727661 grad: 1.6994716074143994\n",
      "epoch: 78 loss: 2.2904281616210938 grad: 1.7467119377014035\n",
      "epoch: 79 loss: 2.2894668579101562 grad: 1.6935052686566783\n",
      "epoch: 80 loss: 2.2897303104400635 grad: 1.680612838270867\n",
      "epoch: 81 loss: 2.2870242595672607 grad: 1.7300302441719742\n",
      "epoch: 82 loss: 2.289703130722046 grad: 1.7227910718056447\n",
      "epoch: 83 loss: 2.2888784408569336 grad: 1.7322912954740108\n",
      "epoch: 84 loss: 2.287376880645752 grad: 1.7500873156730825\n",
      "epoch: 85 loss: 2.286424160003662 grad: 1.7138029315715864\n",
      "epoch: 86 loss: 2.28682017326355 grad: 1.7285117551477418\n",
      "epoch: 87 loss: 2.2858376502990723 grad: 1.7833366873378436\n",
      "epoch: 88 loss: 2.2856040000915527 grad: 1.7342025942154347\n",
      "epoch: 89 loss: 2.2848918437957764 grad: 1.7938488240793555\n",
      "epoch: 90 loss: 2.284609317779541 grad: 1.7354070588203503\n",
      "epoch: 91 loss: 2.2848780155181885 grad: 1.8074165520180638\n",
      "epoch: 92 loss: 2.2848119735717773 grad: 1.8142616860919618\n",
      "epoch: 93 loss: 2.282851219177246 grad: 1.7872817684685633\n",
      "epoch: 94 loss: 2.2855072021484375 grad: 1.7995444478297105\n",
      "epoch: 95 loss: 2.2827353477478027 grad: 1.8456144573625237\n",
      "epoch: 96 loss: 2.282247304916382 grad: 1.8106570686084322\n",
      "epoch: 97 loss: 2.2800633907318115 grad: 1.888888557502512\n",
      "epoch: 98 loss: 2.281055212020874 grad: 1.8787002389740555\n",
      "epoch: 99 loss: 2.2816848754882812 grad: 1.8425277719932003\n",
      "epoch: 100 loss: 2.2820467948913574 grad: 1.9488399248488897\n",
      "epoch: 101 loss: 2.276914358139038 grad: 1.956376579706557\n",
      "epoch: 102 loss: 2.2759034633636475 grad: 2.014469659754208\n",
      "epoch: 103 loss: 2.273966073989868 grad: 1.985096239198428\n",
      "epoch: 104 loss: 2.2774271965026855 grad: 2.0533117013650815\n",
      "epoch: 105 loss: 2.2750425338745117 grad: 2.2111234160764734\n",
      "epoch: 106 loss: 2.269777536392212 grad: 2.3567594946990353\n",
      "epoch: 107 loss: 2.269266366958618 grad: 2.4343378532489406\n",
      "epoch: 108 loss: 2.260909080505371 grad: 2.622260893591576\n",
      "epoch: 109 loss: 2.256991147994995 grad: 2.562384369860714\n",
      "epoch: 110 loss: 2.2556843757629395 grad: 2.5509326033523334\n",
      "epoch: 111 loss: 2.2504382133483887 grad: 2.4889707368528766\n",
      "epoch: 112 loss: 2.249856948852539 grad: 2.4701383315610683\n",
      "epoch: 113 loss: 2.245993137359619 grad: 2.3444353889097416\n",
      "epoch: 114 loss: 2.2465028762817383 grad: 2.42217089673726\n",
      "epoch: 115 loss: 2.2433667182922363 grad: 2.225410541465935\n",
      "epoch: 116 loss: 2.242323637008667 grad: 2.222995872228658\n",
      "epoch: 117 loss: 2.2424681186676025 grad: 2.169912979537104\n",
      "epoch: 118 loss: 2.2400286197662354 grad: 2.1002381822031495\n",
      "epoch: 119 loss: 2.238053560256958 grad: 2.087021049080668\n",
      "epoch: 120 loss: 2.2396185398101807 grad: 2.149272784293215\n",
      "epoch: 121 loss: 2.2340569496154785 grad: 2.027767042171151\n",
      "epoch: 122 loss: 2.2356488704681396 grad: 2.182798303497423\n",
      "epoch: 123 loss: 2.2365150451660156 grad: 2.1655013339708575\n",
      "epoch: 124 loss: 2.234301805496216 grad: 2.201271658273606\n",
      "epoch: 125 loss: 2.234053373336792 grad: 2.2117179136553275\n",
      "epoch: 126 loss: 2.2335801124572754 grad: 2.130056100306175\n",
      "epoch: 127 loss: 2.2353415489196777 grad: 2.2858582726062555\n",
      "epoch: 128 loss: 2.2359697818756104 grad: 2.1335835367005083\n",
      "epoch: 129 loss: 2.2316980361938477 grad: 2.146364608725962\n",
      "epoch: 130 loss: 2.233609437942505 grad: 2.261473480857805\n",
      "epoch: 131 loss: 2.2305054664611816 grad: 2.1635075045697807\n",
      "epoch: 132 loss: 2.2300639152526855 grad: 2.2173014553910537\n",
      "epoch: 133 loss: 2.228576421737671 grad: 2.3175050114348\n",
      "epoch: 134 loss: 2.2276599407196045 grad: 2.416106381137589\n",
      "epoch: 135 loss: 2.2298810482025146 grad: 2.4719232702812564\n",
      "epoch: 136 loss: 2.2273595333099365 grad: 2.38937859270086\n",
      "epoch: 137 loss: 2.227611541748047 grad: 2.487021096000847\n",
      "epoch: 138 loss: 2.2271602153778076 grad: 2.389525060351598\n",
      "epoch: 139 loss: 2.22406268119812 grad: 2.467397647774926\n",
      "epoch: 140 loss: 2.221792221069336 grad: 2.5156003938847413\n",
      "epoch: 141 loss: 2.2222795486450195 grad: 2.5130818638477534\n",
      "epoch: 142 loss: 2.224259614944458 grad: 2.6859836112670896\n",
      "epoch: 143 loss: 2.222078323364258 grad: 2.7046276229315453\n",
      "epoch: 144 loss: 2.224973678588867 grad: 2.6522645147402755\n",
      "epoch: 145 loss: 2.2197916507720947 grad: 2.751015137851475\n",
      "epoch: 146 loss: 2.2167088985443115 grad: 2.6897022661897134\n",
      "epoch: 147 loss: 2.217696189880371 grad: 2.815199271225119\n",
      "epoch: 148 loss: 2.2196762561798096 grad: 2.879367421148345\n",
      "epoch: 149 loss: 2.216113805770874 grad: 2.9510485984288923\n",
      "epoch: 150 loss: 2.2169041633605957 grad: 2.9309042155380465\n",
      "epoch: 151 loss: 2.2177419662475586 grad: 2.9525505733631907\n",
      "epoch: 152 loss: 2.2124180793762207 grad: 2.992452430501876\n",
      "epoch: 153 loss: 2.2122156620025635 grad: 3.0818936134732904\n",
      "epoch: 154 loss: 2.2113308906555176 grad: 3.047398852866276\n",
      "epoch: 155 loss: 2.210317611694336 grad: 3.090750164533448\n",
      "epoch: 156 loss: 2.2133147716522217 grad: 2.9873256191744337\n",
      "epoch: 157 loss: 2.21162748336792 grad: 3.126997127929436\n",
      "epoch: 158 loss: 2.2100162506103516 grad: 3.2033192770304306\n",
      "epoch: 159 loss: 2.204257011413574 grad: 3.3038899702914355\n",
      "epoch: 160 loss: 2.209442377090454 grad: 3.3405250485594724\n",
      "epoch: 161 loss: 2.206028461456299 grad: 3.2189486640512883\n",
      "epoch: 162 loss: 2.2067832946777344 grad: 3.282763737996685\n",
      "epoch: 163 loss: 2.1998403072357178 grad: 3.4441704901105297\n",
      "epoch: 164 loss: 2.203511953353882 grad: 3.36481404465638\n",
      "epoch: 165 loss: 2.200056552886963 grad: 3.259386856286299\n",
      "epoch: 166 loss: 2.201364755630493 grad: 3.226897579909761\n",
      "epoch: 167 loss: 2.198486804962158 grad: 3.300327653870992\n",
      "epoch: 168 loss: 2.2015299797058105 grad: 3.3767391881639406\n",
      "epoch: 169 loss: 2.200577735900879 grad: 3.4153955924243387\n",
      "epoch: 170 loss: 2.1970341205596924 grad: 3.3642260869595386\n",
      "epoch: 171 loss: 2.19454288482666 grad: 3.3764256834392508\n",
      "epoch: 172 loss: 2.1948137283325195 grad: 3.4603014151188765\n",
      "epoch: 173 loss: 2.197082281112671 grad: 3.4377721173407894\n",
      "epoch: 174 loss: 2.1931402683258057 grad: 3.462352060202864\n",
      "epoch: 175 loss: 2.1921846866607666 grad: 3.5209654701563218\n",
      "epoch: 176 loss: 2.192168712615967 grad: 3.628346262643823\n",
      "epoch: 177 loss: 2.190685987472534 grad: 3.623034872295749\n",
      "epoch: 178 loss: 2.1902828216552734 grad: 3.539331664756266\n",
      "epoch: 179 loss: 2.1923108100891113 grad: 3.7304897025626684\n",
      "epoch: 180 loss: 2.190187931060791 grad: 3.3370396734717938\n",
      "epoch: 181 loss: 2.1905319690704346 grad: 3.6009111268970644\n",
      "epoch: 182 loss: 2.184034585952759 grad: 3.504905908368528\n",
      "epoch: 183 loss: 2.1835317611694336 grad: 3.456823167949176\n",
      "epoch: 184 loss: 2.186091661453247 grad: 3.5687912890820632\n",
      "epoch: 185 loss: 2.183384418487549 grad: 3.667620840279149\n",
      "epoch: 186 loss: 2.178900718688965 grad: 3.841207890575456\n",
      "epoch: 187 loss: 2.1844332218170166 grad: 3.767882422281666\n",
      "epoch: 188 loss: 2.186673402786255 grad: 3.736355546584708\n",
      "epoch: 189 loss: 2.179152250289917 grad: 3.7886095825538395\n",
      "epoch: 190 loss: 2.17596173286438 grad: 3.5442323357620764\n",
      "epoch: 191 loss: 2.1796987056732178 grad: 3.6548153394981036\n",
      "epoch: 192 loss: 2.182929515838623 grad: 3.8136334603778015\n",
      "epoch: 193 loss: 2.178304433822632 grad: 3.7214151124602983\n",
      "epoch: 194 loss: 2.1842355728149414 grad: 3.981759214008759\n",
      "epoch: 195 loss: 2.177215814590454 grad: 3.6807682347033053\n",
      "epoch: 196 loss: 2.1786208152770996 grad: 3.879437336908831\n",
      "epoch: 197 loss: 2.1778554916381836 grad: 3.760562139315649\n",
      "epoch: 198 loss: 2.174238681793213 grad: 3.94292530048609\n",
      "epoch: 199 loss: 2.177839517593384 grad: 3.7530515000948474\n",
      "epoch: 200 loss: 2.1745834350585938 grad: 4.067389301881786\n",
      "epoch: 201 loss: 2.1744842529296875 grad: 4.047939826301964\n",
      "epoch: 202 loss: 2.178772211074829 grad: 3.8918405999799095\n",
      "epoch: 203 loss: 2.168238639831543 grad: 3.927931107218481\n",
      "epoch: 204 loss: 2.166902542114258 grad: 3.772871618417816\n",
      "epoch: 205 loss: 2.170590400695801 grad: 3.991814578853784\n",
      "epoch: 206 loss: 2.1681253910064697 grad: 3.900651699785764\n",
      "epoch: 207 loss: 2.169426918029785 grad: 4.003122376037821\n",
      "epoch: 208 loss: 2.166041374206543 grad: 3.9406105670819267\n",
      "epoch: 209 loss: 2.170328140258789 grad: 4.143609426789991\n",
      "epoch: 210 loss: 2.169067621231079 grad: 4.127771986374957\n",
      "epoch: 211 loss: 2.1702826023101807 grad: 3.9996225723834145\n",
      "epoch: 212 loss: 2.1663501262664795 grad: 4.208844324304087\n",
      "epoch: 213 loss: 2.167276620864868 grad: 4.276132810498691\n",
      "epoch: 214 loss: 2.1628024578094482 grad: 4.228611400631803\n",
      "epoch: 215 loss: 2.1672167778015137 grad: 4.325782458541826\n",
      "epoch: 216 loss: 2.1685895919799805 grad: 4.178968122879428\n",
      "epoch: 217 loss: 2.164848804473877 grad: 4.333255033459633\n",
      "epoch: 218 loss: 2.161160707473755 grad: 4.444305924207179\n",
      "epoch: 219 loss: 2.1603407859802246 grad: 4.396849728958119\n",
      "epoch: 220 loss: 2.1584274768829346 grad: 4.446974728677777\n",
      "epoch: 221 loss: 2.1599485874176025 grad: 4.419118389649879\n",
      "epoch: 222 loss: 2.159198760986328 grad: 4.308173278453833\n",
      "epoch: 223 loss: 2.16335391998291 grad: 4.324047836589641\n",
      "epoch: 224 loss: 2.160492420196533 grad: 4.621140100804734\n",
      "epoch: 225 loss: 2.154308319091797 grad: 4.615846923116358\n",
      "epoch: 226 loss: 2.1599981784820557 grad: 4.363282281683669\n",
      "epoch: 227 loss: 2.154590129852295 grad: 4.40064613023285\n",
      "epoch: 228 loss: 2.1594958305358887 grad: 4.458848331334247\n",
      "epoch: 229 loss: 2.1537575721740723 grad: 4.6240299518501\n",
      "epoch: 230 loss: 2.1549415588378906 grad: 4.588795178924643\n",
      "epoch: 231 loss: 2.1563642024993896 grad: 4.903460357171882\n",
      "epoch: 232 loss: 2.1549549102783203 grad: 4.586311974773361\n",
      "epoch: 233 loss: 2.1496968269348145 grad: 4.515989514359731\n",
      "epoch: 234 loss: 2.154472827911377 grad: 4.751976850143235\n",
      "epoch: 235 loss: 2.15382719039917 grad: 4.847652657149685\n",
      "epoch: 236 loss: 2.1508336067199707 grad: 4.590642709802422\n",
      "epoch: 237 loss: 2.152491807937622 grad: 4.59855976171555\n",
      "epoch: 238 loss: 2.147019147872925 grad: 4.8854743070893045\n",
      "epoch: 239 loss: 2.1484498977661133 grad: 4.717911304780356\n",
      "epoch: 240 loss: 2.1492936611175537 grad: 5.014672351036487\n",
      "epoch: 241 loss: 2.150543451309204 grad: 4.974950825403784\n",
      "epoch: 242 loss: 2.1521191596984863 grad: 5.19512136863722\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 243 loss: 2.1474478244781494 grad: 4.708123102972639\n",
      "epoch: 244 loss: 2.146329164505005 grad: 4.864278749474103\n",
      "epoch: 245 loss: 2.1481499671936035 grad: 5.096250651485567\n",
      "epoch: 246 loss: 2.1470746994018555 grad: 5.05728025221458\n",
      "epoch: 247 loss: 2.1458663940429688 grad: 4.855259791615286\n",
      "epoch: 248 loss: 2.1450610160827637 grad: 4.927941138808069\n",
      "epoch: 249 loss: 2.146648406982422 grad: 5.170194753671124\n",
      "epoch: 250 loss: 2.1453640460968018 grad: 5.041651433932462\n",
      "epoch: 251 loss: 2.1452887058258057 grad: 5.143699509209939\n",
      "epoch: 252 loss: 2.142695903778076 grad: 5.216645753905473\n",
      "epoch: 253 loss: 2.1390764713287354 grad: 5.554109378422182\n",
      "epoch: 254 loss: 2.1448569297790527 grad: 5.128682777825151\n",
      "epoch: 255 loss: 2.140716552734375 grad: 5.244326194910895\n",
      "epoch: 256 loss: 2.1396563053131104 grad: 5.541254028034884\n",
      "epoch: 257 loss: 2.1441471576690674 grad: 5.141369241493059\n",
      "epoch: 258 loss: 2.1385674476623535 grad: 5.478422145780531\n",
      "epoch: 259 loss: 2.1386513710021973 grad: 5.304525263370976\n",
      "epoch: 260 loss: 2.1355443000793457 grad: 5.16109517525645\n",
      "epoch: 261 loss: 2.138526201248169 grad: 5.191574556871303\n",
      "epoch: 262 loss: 2.1376829147338867 grad: 5.155454980538389\n",
      "epoch: 263 loss: 2.13480281829834 grad: 5.392463305861586\n",
      "epoch: 264 loss: 2.1428725719451904 grad: 5.49662134189543\n",
      "epoch: 265 loss: 2.1314685344696045 grad: 5.204925244577998\n",
      "epoch: 266 loss: 2.1344926357269287 grad: 5.094417106803684\n",
      "epoch: 267 loss: 2.1405391693115234 grad: 5.399377555268566\n",
      "epoch: 268 loss: 2.1318063735961914 grad: 5.2036960025887105\n",
      "epoch: 269 loss: 2.1329219341278076 grad: 5.324237091001123\n",
      "epoch: 270 loss: 2.127000331878662 grad: 5.581079951080952\n",
      "epoch: 271 loss: 2.136776924133301 grad: 5.469003804116731\n",
      "epoch: 272 loss: 2.128157615661621 grad: 5.554722516997052\n",
      "epoch: 273 loss: 2.139986276626587 grad: 5.608766132440891\n",
      "epoch: 274 loss: 2.132495880126953 grad: 5.19360729417808\n",
      "epoch: 275 loss: 2.1320345401763916 grad: 5.520550249587922\n",
      "epoch: 276 loss: 2.1351006031036377 grad: 5.130379380843055\n",
      "epoch: 277 loss: 2.133192539215088 grad: 5.465337228392148\n",
      "epoch: 278 loss: 2.1254098415374756 grad: 5.619570722389552\n",
      "epoch: 279 loss: 2.1341404914855957 grad: 5.461519057596369\n",
      "epoch: 280 loss: 2.1320548057556152 grad: 5.432342499176721\n",
      "epoch: 281 loss: 2.1387007236480713 grad: 5.459937752157982\n",
      "epoch: 282 loss: 2.133143424987793 grad: 5.892874325610816\n",
      "epoch: 283 loss: 2.1317074298858643 grad: 5.5338138523807245\n",
      "epoch: 284 loss: 2.128178119659424 grad: 5.710938313658098\n",
      "epoch: 285 loss: 2.129633903503418 grad: 5.428550838256284\n",
      "epoch: 286 loss: 2.127758026123047 grad: 5.821055766860289\n",
      "epoch: 287 loss: 2.1276745796203613 grad: 5.732329843750608\n",
      "epoch: 288 loss: 2.1266028881073 grad: 5.8394299777232055\n",
      "epoch: 289 loss: 2.124631881713867 grad: 5.5497180936444135\n",
      "epoch: 290 loss: 2.1309475898742676 grad: 5.883949443232268\n",
      "epoch: 291 loss: 2.132852077484131 grad: 5.566278492440543\n",
      "epoch: 292 loss: 2.1298465728759766 grad: 5.874579682702287\n",
      "epoch: 293 loss: 2.13315486907959 grad: 5.649657319536403\n",
      "epoch: 294 loss: 2.124333143234253 grad: 5.390314915801384\n",
      "epoch: 295 loss: 2.122548818588257 grad: 5.70740302572293\n",
      "epoch: 296 loss: 2.1282691955566406 grad: 6.09525815300673\n",
      "epoch: 297 loss: 2.1274595260620117 grad: 5.34908641557697\n",
      "epoch: 298 loss: 2.1250107288360596 grad: 5.597313872457201\n",
      "epoch: 299 loss: 2.1201391220092773 grad: 5.723720250946898\n",
      "epoch: 300 loss: 2.1198649406433105 grad: 6.136836322771001\n",
      "epoch: 301 loss: 2.1212804317474365 grad: 5.64780979970884\n",
      "epoch: 302 loss: 2.124798536300659 grad: 5.583995092275833\n",
      "epoch: 303 loss: 2.115873098373413 grad: 5.589746566725865\n",
      "epoch: 304 loss: 2.119311809539795 grad: 5.527146451940228\n",
      "epoch: 305 loss: 2.1234750747680664 grad: 5.999062298856202\n",
      "epoch: 306 loss: 2.122441530227661 grad: 5.633603916799147\n",
      "epoch: 307 loss: 2.117161989212036 grad: 6.003174203618001\n",
      "epoch: 308 loss: 2.125077724456787 grad: 6.076109788816659\n",
      "epoch: 309 loss: 2.1250202655792236 grad: 5.828079615165258\n",
      "epoch: 310 loss: 2.1199464797973633 grad: 5.618118794524067\n",
      "epoch: 311 loss: 2.122922658920288 grad: 6.300248118546156\n",
      "epoch: 312 loss: 2.1164021492004395 grad: 5.712902439684267\n",
      "epoch: 313 loss: 2.1135520935058594 grad: 6.0576889440343376\n",
      "epoch: 314 loss: 2.121454954147339 grad: 5.909541090809932\n",
      "epoch: 315 loss: 2.120577335357666 grad: 5.87802123592516\n",
      "epoch: 316 loss: 2.1183321475982666 grad: 6.23842830505843\n",
      "epoch: 317 loss: 2.1201281547546387 grad: 5.807665142023729\n",
      "epoch: 318 loss: 2.1233043670654297 grad: 5.8342081321595565\n",
      "epoch: 319 loss: 2.119729995727539 grad: 5.784561597424308\n",
      "epoch: 320 loss: 2.1120290756225586 grad: 5.719090799291042\n",
      "epoch: 321 loss: 2.120384931564331 grad: 5.887099563247627\n",
      "epoch: 322 loss: 2.1100893020629883 grad: 6.1205064029477185\n",
      "epoch: 323 loss: 2.1127028465270996 grad: 5.880531931591649\n",
      "epoch: 324 loss: 2.1171412467956543 grad: 6.285154046017736\n",
      "epoch: 325 loss: 2.1176695823669434 grad: 5.691917762322913\n",
      "epoch: 326 loss: 2.1172268390655518 grad: 5.794313239717176\n",
      "epoch: 327 loss: 2.12149715423584 grad: 6.318662194431656\n",
      "epoch: 328 loss: 2.1130168437957764 grad: 5.814019443962486\n",
      "epoch: 329 loss: 2.117199659347534 grad: 5.976850810689881\n",
      "epoch: 330 loss: 2.1062116622924805 grad: 5.881129326254484\n",
      "epoch: 331 loss: 2.1096608638763428 grad: 6.056671127617832\n",
      "epoch: 332 loss: 2.1128902435302734 grad: 6.073491628281772\n",
      "epoch: 333 loss: 2.1171231269836426 grad: 6.176748856081671\n",
      "epoch: 334 loss: 2.1117045879364014 grad: 5.965910651846715\n",
      "epoch: 335 loss: 2.1125800609588623 grad: 5.9479790006261615\n",
      "epoch: 336 loss: 2.1164262294769287 grad: 5.9674345221488725\n",
      "epoch: 337 loss: 2.115208387374878 grad: 6.464056269731373\n",
      "epoch: 338 loss: 2.1129703521728516 grad: 6.28194183055755\n",
      "epoch: 339 loss: 2.1152734756469727 grad: 5.804900466656638\n",
      "epoch: 340 loss: 2.1082587242126465 grad: 6.172611854238702\n",
      "epoch: 341 loss: 2.1142396926879883 grad: 6.401691507200696\n",
      "epoch: 342 loss: 2.113658905029297 grad: 5.535459618638491\n",
      "epoch: 343 loss: 2.1086108684539795 grad: 6.093315098663822\n",
      "epoch: 344 loss: 2.1070053577423096 grad: 6.212807139670033\n",
      "epoch: 345 loss: 2.112288475036621 grad: 6.313635505100209\n",
      "epoch: 346 loss: 2.104499101638794 grad: 6.048828372432451\n",
      "epoch: 347 loss: 2.106095314025879 grad: 6.487367929521179\n",
      "epoch: 348 loss: 2.108100414276123 grad: 5.960706613203954\n",
      "epoch: 349 loss: 2.108821392059326 grad: 5.848789998781054\n",
      "epoch: 350 loss: 2.1050708293914795 grad: 6.110623422692279\n",
      "epoch: 351 loss: 2.1072676181793213 grad: 6.064220523151259\n",
      "epoch: 352 loss: 2.1076738834381104 grad: 5.825288012764225\n",
      "epoch: 353 loss: 2.1012682914733887 grad: 5.893210849392095\n",
      "epoch: 354 loss: 2.1120128631591797 grad: 6.4400946293839265\n",
      "epoch: 355 loss: 2.100346088409424 grad: 6.339768317365457\n",
      "epoch: 356 loss: 2.1060845851898193 grad: 6.226377017862562\n",
      "epoch: 357 loss: 2.106600761413574 grad: 6.3213156265029244\n",
      "epoch: 358 loss: 2.103717088699341 grad: 6.115155360713187\n",
      "epoch: 359 loss: 2.1023786067962646 grad: 5.915520778871954\n",
      "epoch: 360 loss: 2.1036767959594727 grad: 6.373810694139037\n",
      "epoch: 361 loss: 2.103256940841675 grad: 6.318553150572356\n",
      "epoch: 362 loss: 2.1020731925964355 grad: 5.7873166536779275\n",
      "epoch: 363 loss: 2.1132798194885254 grad: 6.126012090948366\n",
      "epoch: 364 loss: 2.1097517013549805 grad: 6.290489670458353\n",
      "epoch: 365 loss: 2.109584331512451 grad: 6.282494155083975\n",
      "epoch: 366 loss: 2.1020848751068115 grad: 6.236885438244494\n",
      "epoch: 367 loss: 2.112816333770752 grad: 6.164370317278164\n",
      "epoch: 368 loss: 2.106314182281494 grad: 5.904572547154708\n",
      "epoch: 369 loss: 2.1069767475128174 grad: 6.19689306442345\n",
      "epoch: 370 loss: 2.096141815185547 grad: 6.222735659492808\n",
      "epoch: 371 loss: 2.104996919631958 grad: 6.040311870069081\n",
      "epoch: 372 loss: 2.103731870651245 grad: 6.13690439278319\n",
      "epoch: 373 loss: 2.106208086013794 grad: 5.97303852802586\n",
      "epoch: 374 loss: 2.099727153778076 grad: 6.121202637759288\n",
      "epoch: 375 loss: 2.1011242866516113 grad: 6.194374546275607\n",
      "epoch: 376 loss: 2.105264902114868 grad: 6.294902241692716\n",
      "epoch: 377 loss: 2.1000545024871826 grad: 5.942701801095927\n",
      "epoch: 378 loss: 2.100093364715576 grad: 6.466712371431409\n",
      "epoch: 379 loss: 2.1004700660705566 grad: 6.300847808298256\n",
      "epoch: 380 loss: 2.096203565597534 grad: 6.061470297771314\n",
      "epoch: 381 loss: 2.093700647354126 grad: 6.208556958407696\n",
      "epoch: 382 loss: 2.099118947982788 grad: 6.2096711737177674\n",
      "epoch: 383 loss: 2.0996601581573486 grad: 6.329100848382546\n",
      "epoch: 384 loss: 2.1000242233276367 grad: 5.991228177663057\n",
      "epoch: 385 loss: 2.10083270072937 grad: 6.412042197246578\n",
      "epoch: 386 loss: 2.099510669708252 grad: 6.195159789780894\n",
      "epoch: 387 loss: 2.0968425273895264 grad: 6.245481519390726\n",
      "epoch: 388 loss: 2.0987391471862793 grad: 6.482401635601288\n",
      "epoch: 389 loss: 2.099564790725708 grad: 6.577776269913311\n",
      "epoch: 390 loss: 2.1014511585235596 grad: 6.174428845474881\n",
      "epoch: 391 loss: 2.096773624420166 grad: 6.6252462819203854\n",
      "epoch: 392 loss: 2.1027257442474365 grad: 6.143152086803364\n",
      "epoch: 393 loss: 2.0922787189483643 grad: 6.195030072873961\n",
      "epoch: 394 loss: 2.091352701187134 grad: 6.406106533009618\n",
      "epoch: 395 loss: 2.1023054122924805 grad: 6.116139792585893\n",
      "epoch: 396 loss: 2.0855813026428223 grad: 6.655187597978742\n",
      "epoch: 397 loss: 2.0915377140045166 grad: 6.41717446522255\n",
      "epoch: 398 loss: 2.091853380203247 grad: 6.807072421343672\n",
      "epoch: 399 loss: 2.0991342067718506 grad: 6.6110547413487755\n",
      "epoch: 400 loss: 2.08876371383667 grad: 6.221335876496538\n",
      "epoch: 401 loss: 2.0952248573303223 grad: 5.84096434985524\n",
      "epoch: 402 loss: 2.1009392738342285 grad: 6.22398006394949\n",
      "epoch: 403 loss: 2.086937189102173 grad: 6.038017885678167\n",
      "epoch: 404 loss: 2.094759225845337 grad: 6.487427257141838\n",
      "epoch: 405 loss: 2.0895631313323975 grad: 6.347023560436413\n",
      "epoch: 406 loss: 2.0962934494018555 grad: 6.601882001991192\n",
      "epoch: 407 loss: 2.0880303382873535 grad: 6.409960617847179\n",
      "epoch: 408 loss: 2.0940353870391846 grad: 6.168338098260205\n",
      "epoch: 409 loss: 2.0922114849090576 grad: 6.063894212378988\n",
      "epoch: 410 loss: 2.1021695137023926 grad: 6.607531815708157\n",
      "epoch: 411 loss: 2.098350763320923 grad: 6.835322306861007\n",
      "epoch: 412 loss: 2.0907528400421143 grad: 6.646127132632371\n",
      "epoch: 413 loss: 2.0923218727111816 grad: 6.200516796079538\n",
      "epoch: 414 loss: 2.095302104949951 grad: 6.204174215698408\n",
      "epoch: 415 loss: 2.0875258445739746 grad: 6.552954071142253\n",
      "epoch: 416 loss: 2.0840072631835938 grad: 7.046434797065717\n",
      "epoch: 417 loss: 2.0860447883605957 grad: 6.161771476246594\n",
      "epoch: 418 loss: 2.0896220207214355 grad: 6.554994812516111\n",
      "epoch: 419 loss: 2.0904994010925293 grad: 6.397321480001131\n",
      "epoch: 420 loss: 2.09470272064209 grad: 6.747317685169124\n",
      "epoch: 421 loss: 2.086520195007324 grad: 6.303023131431213\n",
      "epoch: 422 loss: 2.090665578842163 grad: 6.280462947563224\n",
      "epoch: 423 loss: 2.088442802429199 grad: 6.304558844719496\n",
      "epoch: 424 loss: 2.090195417404175 grad: 6.772682380581659\n",
      "epoch: 425 loss: 2.085148572921753 grad: 6.303782036224942\n",
      "epoch: 426 loss: 2.0834527015686035 grad: 6.261942253034148\n",
      "epoch: 427 loss: 2.083899736404419 grad: 6.241799461943585\n",
      "epoch: 428 loss: 2.092590570449829 grad: 6.466367309432595\n",
      "epoch: 429 loss: 2.0785763263702393 grad: 6.606604935475699\n",
      "epoch: 430 loss: 2.0848288536071777 grad: 6.686833571864381\n",
      "epoch: 431 loss: 2.085304021835327 grad: 7.059749839258277\n",
      "epoch: 432 loss: 2.083125114440918 grad: 6.685954090533039\n",
      "epoch: 433 loss: 2.0828347206115723 grad: 6.169890177805746\n",
      "epoch: 434 loss: 2.0866944789886475 grad: 6.240483730077921\n",
      "epoch: 435 loss: 2.087902784347534 grad: 6.874111563248175\n",
      "epoch: 436 loss: 2.0828635692596436 grad: 6.311634518228294\n",
      "epoch: 437 loss: 2.086103677749634 grad: 6.663599143617801\n",
      "epoch: 438 loss: 2.088230848312378 grad: 6.545292203092859\n",
      "epoch: 439 loss: 2.0856966972351074 grad: 6.334106830983526\n",
      "epoch: 440 loss: 2.0853376388549805 grad: 6.822273954874762\n",
      "epoch: 441 loss: 2.0835554599761963 grad: 6.7554984695411155\n",
      "epoch: 442 loss: 2.0775153636932373 grad: 6.454903438931242\n",
      "epoch: 443 loss: 2.0867984294891357 grad: 6.5884414200286665\n",
      "epoch: 444 loss: 2.0835585594177246 grad: 6.529518159365074\n",
      "epoch: 445 loss: 2.082468032836914 grad: 6.809649741011007\n",
      "epoch: 446 loss: 2.075359582901001 grad: 6.620884417474921\n",
      "epoch: 447 loss: 2.0892410278320312 grad: 6.54681717809881\n",
      "epoch: 448 loss: 2.0848488807678223 grad: 7.024588819452753\n",
      "epoch: 449 loss: 2.0804080963134766 grad: 6.8605385287221345\n",
      "epoch: 450 loss: 2.0839743614196777 grad: 6.945424191328505\n",
      "epoch: 451 loss: 2.0883378982543945 grad: 6.6757819458975325\n",
      "epoch: 452 loss: 2.0858237743377686 grad: 7.039451320012588\n",
      "epoch: 453 loss: 2.081411838531494 grad: 6.46349887329612\n",
      "epoch: 454 loss: 2.083590507507324 grad: 6.337559632313925\n",
      "epoch: 455 loss: 2.0798888206481934 grad: 6.832807471014796\n",
      "epoch: 456 loss: 2.0822081565856934 grad: 6.518839996633312\n",
      "epoch: 457 loss: 2.083888292312622 grad: 6.399395709864736\n",
      "epoch: 458 loss: 2.0854315757751465 grad: 7.035196242750519\n",
      "epoch: 459 loss: 2.08213210105896 grad: 6.726209625313502\n",
      "epoch: 460 loss: 2.078519105911255 grad: 6.466012591643939\n",
      "epoch: 461 loss: 2.0786943435668945 grad: 6.638943863404353\n",
      "epoch: 462 loss: 2.073479175567627 grad: 6.57285511575728\n",
      "epoch: 463 loss: 2.0730044841766357 grad: 6.659681957311159\n",
      "epoch: 464 loss: 2.078413486480713 grad: 6.882166068025288\n",
      "epoch: 465 loss: 2.0822274684906006 grad: 7.007048749172735\n",
      "epoch: 466 loss: 2.083061695098877 grad: 6.658525466845031\n",
      "epoch: 467 loss: 2.0822293758392334 grad: 6.703635360520806\n",
      "epoch: 468 loss: 2.074087381362915 grad: 6.694546914511611\n",
      "epoch: 469 loss: 2.0823113918304443 grad: 6.87739150373206\n",
      "epoch: 470 loss: 2.074808120727539 grad: 7.216869085613224\n",
      "epoch: 471 loss: 2.0739548206329346 grad: 6.385487347841263\n",
      "epoch: 472 loss: 2.0762951374053955 grad: 6.644056069701614\n",
      "epoch: 473 loss: 2.079887866973877 grad: 7.142267004313273\n",
      "epoch: 474 loss: 2.070972204208374 grad: 6.631661259864885\n",
      "epoch: 475 loss: 2.0764036178588867 grad: 7.1833355140074024\n",
      "epoch: 476 loss: 2.074143409729004 grad: 6.670160950272388\n",
      "epoch: 477 loss: 2.0744147300720215 grad: 6.89522367636008\n",
      "epoch: 478 loss: 2.067309617996216 grad: 6.75371532747522\n",
      "epoch: 479 loss: 2.0745246410369873 grad: 7.03995849271231\n",
      "epoch: 480 loss: 2.080556631088257 grad: 6.539240187758373\n",
      "epoch: 481 loss: 2.0758044719696045 grad: 6.837512550986416\n",
      "epoch: 482 loss: 2.069718599319458 grad: 6.589989292561003\n",
      "epoch: 483 loss: 2.0685079097747803 grad: 7.2718748410587155\n",
      "epoch: 484 loss: 2.0752203464508057 grad: 6.959663817171185\n",
      "epoch: 485 loss: 2.0735764503479004 grad: 6.782656861772199\n",
      "epoch: 486 loss: 2.069683074951172 grad: 6.872109846906766\n",
      "epoch: 487 loss: 2.074169874191284 grad: 6.466068985724141\n",
      "epoch: 488 loss: 2.0697598457336426 grad: 6.439642574763783\n",
      "epoch: 489 loss: 2.072439193725586 grad: 7.292407223888274\n",
      "epoch: 490 loss: 2.0756752490997314 grad: 7.132841027519178\n",
      "epoch: 491 loss: 2.071246385574341 grad: 7.151732772743951\n",
      "epoch: 492 loss: 2.06595778465271 grad: 6.939166138536253\n",
      "epoch: 493 loss: 2.0755043029785156 grad: 7.214216228079287\n",
      "epoch: 494 loss: 2.0707950592041016 grad: 7.0322580027896615\n",
      "epoch: 495 loss: 2.074195146560669 grad: 6.866213998188162\n",
      "epoch: 496 loss: 2.076176643371582 grad: 6.905945581184434\n",
      "epoch: 497 loss: 2.0730996131896973 grad: 6.964131805291843\n",
      "epoch: 498 loss: 2.071336507797241 grad: 7.0092104411654415\n",
      "epoch: 499 loss: 2.071427345275879 grad: 6.618121878480509\n",
      "2.195990279316902\n",
      "epoch: 0 loss: 2.303577184677124 grad: 0.9673685254870973\n",
      "epoch: 1 loss: 2.2593674659729004 grad: 1.108073662764149\n",
      "epoch: 2 loss: 2.224046230316162 grad: 0.9665980082955064\n",
      "epoch: 3 loss: 2.2183151245117188 grad: 0.9861462108242521\n",
      "epoch: 4 loss: 2.2145273685455322 grad: 1.4158225381637863\n",
      "epoch: 5 loss: 2.2088000774383545 grad: 2.170204457993682\n",
      "epoch: 6 loss: 2.2004425525665283 grad: 2.125051663988704\n",
      "epoch: 7 loss: 2.186880111694336 grad: 2.2633505961210982\n",
      "epoch: 8 loss: 2.165987730026245 grad: 2.651643165982225\n",
      "epoch: 9 loss: 2.1559362411499023 grad: 2.5920212302067767\n",
      "epoch: 10 loss: 2.161271810531616 grad: 2.6567346947951362\n",
      "epoch: 11 loss: 2.151404619216919 grad: 2.9363815408982594\n",
      "epoch: 12 loss: 2.1484405994415283 grad: 2.9809647008974385\n",
      "epoch: 13 loss: 2.1323373317718506 grad: 2.8306847513955464\n",
      "epoch: 14 loss: 2.1355631351470947 grad: 3.074505853434352\n",
      "epoch: 15 loss: 2.127307891845703 grad: 3.137454376785576\n",
      "epoch: 16 loss: 2.121037721633911 grad: 3.191034375067656\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 17 loss: 2.100353240966797 grad: 3.586405907488947\n",
      "epoch: 18 loss: 2.0871331691741943 grad: 3.6271707147465175\n",
      "epoch: 19 loss: 2.074324369430542 grad: 3.6713153418705113\n",
      "epoch: 20 loss: 2.083522319793701 grad: 3.7265082840269086\n",
      "epoch: 21 loss: 2.063748598098755 grad: 3.9168575352218578\n",
      "epoch: 22 loss: 2.0475566387176514 grad: 3.745617517614312\n",
      "epoch: 23 loss: 2.0591752529144287 grad: 4.45233895353851\n",
      "epoch: 24 loss: 2.0361602306365967 grad: 4.461046358568608\n",
      "epoch: 25 loss: 2.0351688861846924 grad: 4.584538545066838\n",
      "epoch: 26 loss: 2.0066049098968506 grad: 4.178128888682713\n",
      "epoch: 27 loss: 2.0013177394866943 grad: 4.513362251633283\n",
      "epoch: 28 loss: 2.0013785362243652 grad: 4.527346844798775\n",
      "epoch: 29 loss: 2.0035057067871094 grad: 5.050123587406854\n",
      "epoch: 30 loss: 1.9830448627471924 grad: 4.492117439666467\n",
      "epoch: 31 loss: 1.9873216152191162 grad: 4.610104037825728\n",
      "epoch: 32 loss: 1.9775323867797852 grad: 4.829245059279769\n",
      "epoch: 33 loss: 1.9811489582061768 grad: 4.555413955822587\n",
      "epoch: 34 loss: 1.9917066097259521 grad: 4.711715506578219\n",
      "epoch: 35 loss: 1.9798390865325928 grad: 5.382996616719683\n",
      "epoch: 36 loss: 1.9838836193084717 grad: 5.071604561396054\n",
      "epoch: 37 loss: 1.96379554271698 grad: 5.037853544915653\n",
      "epoch: 38 loss: 1.9751806259155273 grad: 4.600913317928586\n",
      "epoch: 39 loss: 1.9659318923950195 grad: 4.5849843873362435\n",
      "epoch: 40 loss: 1.9665697813034058 grad: 4.947650523953295\n",
      "epoch: 41 loss: 1.9617369174957275 grad: 5.258958112971399\n",
      "epoch: 42 loss: 1.958680510520935 grad: 4.9762003649878945\n",
      "epoch: 43 loss: 1.9536492824554443 grad: 4.847939422302362\n",
      "epoch: 44 loss: 1.9783649444580078 grad: 4.940919320446453\n",
      "epoch: 45 loss: 1.9605361223220825 grad: 5.4448391495897095\n",
      "epoch: 46 loss: 1.9503663778305054 grad: 4.625329603118607\n",
      "epoch: 47 loss: 1.9491615295410156 grad: 5.733366224693969\n",
      "epoch: 48 loss: 1.94769287109375 grad: 5.467156776821144\n",
      "epoch: 49 loss: 1.9440020322799683 grad: 5.649958623138012\n",
      "epoch: 50 loss: 1.9290045499801636 grad: 5.193091017932313\n",
      "epoch: 51 loss: 1.9240403175354004 grad: 5.585601844772187\n",
      "epoch: 52 loss: 1.9265687465667725 grad: 5.26400517499248\n",
      "epoch: 53 loss: 1.928418755531311 grad: 4.685692743725321\n",
      "epoch: 54 loss: 1.941412329673767 grad: 5.788130484118555\n",
      "epoch: 55 loss: 1.9343469142913818 grad: 4.800669945690537\n",
      "epoch: 56 loss: 1.9153923988342285 grad: 5.28354913628261\n",
      "epoch: 57 loss: 1.9226456880569458 grad: 5.354845586078545\n",
      "epoch: 58 loss: 1.9194839000701904 grad: 5.5548255173193795\n",
      "epoch: 59 loss: 1.9219356775283813 grad: 5.154256806638654\n",
      "epoch: 60 loss: 1.922438144683838 grad: 5.088225181622889\n",
      "epoch: 61 loss: 1.927707314491272 grad: 5.8229139611182275\n",
      "epoch: 62 loss: 1.9405394792556763 grad: 4.761229045798592\n",
      "epoch: 63 loss: 1.9097858667373657 grad: 5.85383120339848\n",
      "epoch: 64 loss: 1.9245145320892334 grad: 5.907279313806193\n",
      "epoch: 65 loss: 1.9071241617202759 grad: 5.388369696129794\n",
      "epoch: 66 loss: 1.9009729623794556 grad: 4.89507406433889\n",
      "epoch: 67 loss: 1.9085471630096436 grad: 4.906388186323013\n",
      "epoch: 68 loss: 1.9030777215957642 grad: 5.185663443168677\n",
      "epoch: 69 loss: 1.9101239442825317 grad: 5.787510890327487\n",
      "epoch: 70 loss: 1.907556176185608 grad: 5.443256938192506\n",
      "epoch: 71 loss: 1.9122487306594849 grad: 5.813062193250516\n",
      "epoch: 72 loss: 1.9187736511230469 grad: 5.516288437918919\n",
      "epoch: 73 loss: 1.9141148328781128 grad: 5.0927982949630985\n",
      "epoch: 74 loss: 1.9125186204910278 grad: 5.382152142310848\n",
      "epoch: 75 loss: 1.9038982391357422 grad: 5.421502641674283\n",
      "epoch: 76 loss: 1.8967927694320679 grad: 5.598288364782338\n",
      "epoch: 77 loss: 1.8880937099456787 grad: 5.374440596374269\n",
      "epoch: 78 loss: 1.8976542949676514 grad: 4.809822442240104\n",
      "epoch: 79 loss: 1.906335711479187 grad: 5.318807508114593\n",
      "epoch: 80 loss: 1.9109541177749634 grad: 5.405987385065861\n",
      "epoch: 81 loss: 1.9035013914108276 grad: 5.548663429232196\n",
      "epoch: 82 loss: 1.8921470642089844 grad: 5.161710477970903\n",
      "epoch: 83 loss: 1.8992691040039062 grad: 5.233964419401702\n",
      "epoch: 84 loss: 1.8968955278396606 grad: 5.087453678427708\n",
      "epoch: 85 loss: 1.8945063352584839 grad: 4.734917461942319\n",
      "epoch: 86 loss: 1.8934128284454346 grad: 6.010391139626754\n",
      "epoch: 87 loss: 1.896883487701416 grad: 5.0845519404434265\n",
      "epoch: 88 loss: 1.8913705348968506 grad: 5.56956358198058\n",
      "epoch: 89 loss: 1.874975562095642 grad: 4.999121357042607\n",
      "epoch: 90 loss: 1.8961904048919678 grad: 5.442173290524691\n",
      "epoch: 91 loss: 1.882051706314087 grad: 4.706212070060983\n",
      "epoch: 92 loss: 1.8923524618148804 grad: 5.295758240375324\n",
      "epoch: 93 loss: 1.8872716426849365 grad: 5.62554072651498\n",
      "epoch: 94 loss: 1.886667251586914 grad: 5.274614591478548\n",
      "epoch: 95 loss: 1.8807928562164307 grad: 4.838475747595242\n",
      "epoch: 96 loss: 1.8726835250854492 grad: 5.217588346483397\n",
      "epoch: 97 loss: 1.8901630640029907 grad: 5.073118411761243\n",
      "epoch: 98 loss: 1.883647084236145 grad: 5.172887949098367\n",
      "epoch: 99 loss: 1.8859338760375977 grad: 5.361501202356377\n",
      "epoch: 100 loss: 1.8667422533035278 grad: 5.090693654527607\n",
      "epoch: 101 loss: 1.8745529651641846 grad: 4.640811361822426\n",
      "epoch: 102 loss: 1.8875757455825806 grad: 4.83095367528112\n",
      "epoch: 103 loss: 1.8902814388275146 grad: 5.131893380414805\n",
      "epoch: 104 loss: 1.8740431070327759 grad: 5.7737519448329255\n",
      "epoch: 105 loss: 1.8808624744415283 grad: 5.635309064653166\n",
      "epoch: 106 loss: 1.8834161758422852 grad: 5.558473563767389\n",
      "epoch: 107 loss: 1.8880037069320679 grad: 5.461984767245003\n",
      "epoch: 108 loss: 1.8929396867752075 grad: 5.0243907065700375\n",
      "epoch: 109 loss: 1.8701155185699463 grad: 5.230281345606763\n",
      "epoch: 110 loss: 1.87107253074646 grad: 4.656730133498924\n",
      "epoch: 111 loss: 1.8781756162643433 grad: 5.2198504992002634\n",
      "epoch: 112 loss: 1.878944754600525 grad: 5.306280539326725\n",
      "epoch: 113 loss: 1.8928091526031494 grad: 5.073437183795279\n",
      "epoch: 114 loss: 1.869678258895874 grad: 5.031641321032241\n",
      "epoch: 115 loss: 1.8700889348983765 grad: 6.015462515896948\n",
      "epoch: 116 loss: 1.8715600967407227 grad: 4.823404340560378\n",
      "epoch: 117 loss: 1.8749052286148071 grad: 4.7007650214179035\n",
      "epoch: 118 loss: 1.8731385469436646 grad: 5.627481522090319\n",
      "epoch: 119 loss: 1.8641546964645386 grad: 4.93566918704522\n",
      "epoch: 120 loss: 1.87863028049469 grad: 4.730672763509487\n",
      "epoch: 121 loss: 1.8686243295669556 grad: 4.394836726928516\n",
      "epoch: 122 loss: 1.8723398447036743 grad: 5.278114178340369\n",
      "epoch: 123 loss: 1.8599764108657837 grad: 4.489744039104109\n",
      "epoch: 124 loss: 1.8798760175704956 grad: 4.54041002722021\n",
      "epoch: 125 loss: 1.8725742101669312 grad: 4.597833132805554\n",
      "epoch: 126 loss: 1.8701525926589966 grad: 5.543327964478291\n",
      "epoch: 127 loss: 1.868723750114441 grad: 5.042926945002927\n",
      "epoch: 128 loss: 1.8570741415023804 grad: 5.496428143114566\n",
      "epoch: 129 loss: 1.8720258474349976 grad: 5.07118625441956\n",
      "epoch: 130 loss: 1.8740655183792114 grad: 5.11801705338266\n",
      "epoch: 131 loss: 1.8613461256027222 grad: 5.18168093789404\n",
      "epoch: 132 loss: 1.8521206378936768 grad: 5.027805478808226\n",
      "epoch: 133 loss: 1.8634004592895508 grad: 5.245675806545131\n",
      "epoch: 134 loss: 1.8692048788070679 grad: 4.395860629650997\n",
      "epoch: 135 loss: 1.8617072105407715 grad: 5.241008949894061\n",
      "epoch: 136 loss: 1.8684604167938232 grad: 5.5559310800190795\n",
      "epoch: 137 loss: 1.853085994720459 grad: 5.258995322332281\n",
      "epoch: 138 loss: 1.8575690984725952 grad: 4.623729026779146\n",
      "epoch: 139 loss: 1.8485257625579834 grad: 5.029752590199692\n",
      "epoch: 140 loss: 1.8562703132629395 grad: 5.287987572549831\n",
      "epoch: 141 loss: 1.8732866048812866 grad: 5.2678650518299985\n",
      "epoch: 142 loss: 1.8698890209197998 grad: 5.56825821377944\n",
      "epoch: 143 loss: 1.8620028495788574 grad: 5.439322202044654\n",
      "epoch: 144 loss: 1.875178337097168 grad: 5.458934022404257\n",
      "epoch: 145 loss: 1.8657299280166626 grad: 4.989807970170486\n",
      "epoch: 146 loss: 1.8611538410186768 grad: 5.03214318729015\n",
      "epoch: 147 loss: 1.8589487075805664 grad: 5.671640311587705\n",
      "epoch: 148 loss: 1.8764280080795288 grad: 5.160467694926728\n",
      "epoch: 149 loss: 1.8634240627288818 grad: 5.180986340043236\n",
      "epoch: 150 loss: 1.8473294973373413 grad: 5.013643136186551\n",
      "epoch: 151 loss: 1.8598482608795166 grad: 4.888811343693218\n",
      "epoch: 152 loss: 1.8605700731277466 grad: 5.688947152077047\n",
      "epoch: 153 loss: 1.8651238679885864 grad: 4.4072430969640015\n",
      "epoch: 154 loss: 1.8590604066848755 grad: 5.337171793088875\n",
      "epoch: 155 loss: 1.840423583984375 grad: 4.468201191857733\n",
      "epoch: 156 loss: 1.8380358219146729 grad: 4.775438863034767\n",
      "epoch: 157 loss: 1.8482937812805176 grad: 5.1479588463590185\n",
      "epoch: 158 loss: 1.847672700881958 grad: 4.562809469807343\n",
      "epoch: 159 loss: 1.846394658088684 grad: 4.736659919254649\n",
      "epoch: 160 loss: 1.860400676727295 grad: 5.262915099752718\n",
      "epoch: 161 loss: 1.8580963611602783 grad: 5.60683418445692\n",
      "epoch: 162 loss: 1.860049843788147 grad: 5.8547464376001335\n",
      "epoch: 163 loss: 1.8572132587432861 grad: 5.7207159530807985\n",
      "epoch: 164 loss: 1.8508585691452026 grad: 4.9889451864231855\n",
      "epoch: 165 loss: 1.871978521347046 grad: 5.120453024959831\n",
      "epoch: 166 loss: 1.8381246328353882 grad: 5.1623434606486365\n",
      "epoch: 167 loss: 1.8551026582717896 grad: 5.277417103902692\n",
      "epoch: 168 loss: 1.837396264076233 grad: 4.891974900403598\n",
      "epoch: 169 loss: 1.8533939123153687 grad: 5.680909884865128\n",
      "epoch: 170 loss: 1.8565276861190796 grad: 4.778932597946435\n",
      "epoch: 171 loss: 1.8667670488357544 grad: 5.5392601615337576\n",
      "epoch: 172 loss: 1.8630403280258179 grad: 5.241467338549791\n",
      "epoch: 173 loss: 1.839302659034729 grad: 5.101975893034481\n",
      "epoch: 174 loss: 1.8541855812072754 grad: 4.6985769267817625\n",
      "epoch: 175 loss: 1.8408377170562744 grad: 5.53224025566883\n",
      "epoch: 176 loss: 1.8574351072311401 grad: 5.304013269735613\n",
      "epoch: 177 loss: 1.8499410152435303 grad: 4.769337488697992\n",
      "epoch: 178 loss: 1.8413031101226807 grad: 4.91731969654257\n",
      "epoch: 179 loss: 1.8531067371368408 grad: 4.993112407920148\n",
      "epoch: 180 loss: 1.853198766708374 grad: 5.477622153442113\n",
      "epoch: 181 loss: 1.8368207216262817 grad: 4.779837096736989\n",
      "epoch: 182 loss: 1.8406823873519897 grad: 4.808970965985311\n",
      "epoch: 183 loss: 1.843272089958191 grad: 4.330569054277952\n",
      "epoch: 184 loss: 1.8401275873184204 grad: 5.481997213306992\n",
      "epoch: 185 loss: 1.845062494277954 grad: 4.837591812071402\n",
      "epoch: 186 loss: 1.846668004989624 grad: 5.297500436165599\n",
      "epoch: 187 loss: 1.8435322046279907 grad: 4.43092498124627\n",
      "epoch: 188 loss: 1.8223055601119995 grad: 5.0755849538559445\n",
      "epoch: 189 loss: 1.8431155681610107 grad: 5.458022129100134\n",
      "epoch: 190 loss: 1.8363001346588135 grad: 6.103557124473376\n",
      "epoch: 191 loss: 1.8411046266555786 grad: 5.306410039619622\n",
      "epoch: 192 loss: 1.8331544399261475 grad: 4.9921122240332245\n",
      "epoch: 193 loss: 1.8405349254608154 grad: 5.80440219553485\n",
      "epoch: 194 loss: 1.8319587707519531 grad: 5.836796228215838\n",
      "epoch: 195 loss: 1.8294838666915894 grad: 5.565501701315433\n",
      "epoch: 196 loss: 1.8438701629638672 grad: 6.608589517814662\n",
      "epoch: 197 loss: 1.8406527042388916 grad: 5.882072343482241\n",
      "epoch: 198 loss: 1.840627908706665 grad: 5.686829962922188\n",
      "epoch: 199 loss: 1.8406189680099487 grad: 6.4305957388334924\n",
      "epoch: 200 loss: 1.8282383680343628 grad: 5.383998703676168\n",
      "epoch: 201 loss: 1.8379982709884644 grad: 5.1172243251866245\n",
      "epoch: 202 loss: 1.839760184288025 grad: 4.76367905458744\n",
      "epoch: 203 loss: 1.8439067602157593 grad: 6.428017859465428\n",
      "epoch: 204 loss: 1.849244236946106 grad: 6.3383796527424625\n",
      "epoch: 205 loss: 1.8384968042373657 grad: 5.595578612662234\n",
      "epoch: 206 loss: 1.8296053409576416 grad: 4.897385958855993\n",
      "epoch: 207 loss: 1.836848497390747 grad: 5.453287115108521\n",
      "epoch: 208 loss: 1.8338496685028076 grad: 5.354614647889754\n",
      "epoch: 209 loss: 1.8487861156463623 grad: 5.817135987946087\n",
      "epoch: 210 loss: 1.8475524187088013 grad: 5.2838782557858694\n",
      "epoch: 211 loss: 1.8170087337493896 grad: 5.072455753959527\n",
      "epoch: 212 loss: 1.8383142948150635 grad: 6.2836237405011035\n",
      "epoch: 213 loss: 1.8349583148956299 grad: 6.28339360795115\n",
      "epoch: 214 loss: 1.8278368711471558 grad: 6.319232672662659\n",
      "epoch: 215 loss: 1.820674180984497 grad: 4.652331689075153\n",
      "epoch: 216 loss: 1.825271487236023 grad: 5.049519850468468\n",
      "epoch: 217 loss: 1.8139556646347046 grad: 6.2971752792969165\n",
      "epoch: 218 loss: 1.834113597869873 grad: 5.7445153447329105\n",
      "epoch: 219 loss: 1.82748544216156 grad: 5.612036624812477\n",
      "epoch: 220 loss: 1.830946445465088 grad: 5.839431361749626\n",
      "epoch: 221 loss: 1.8367451429367065 grad: 5.064931248562523\n",
      "epoch: 222 loss: 1.815859317779541 grad: 5.765751709031137\n",
      "epoch: 223 loss: 1.820401668548584 grad: 5.602895372118505\n",
      "epoch: 224 loss: 1.8100049495697021 grad: 5.219627473113452\n",
      "epoch: 225 loss: 1.8308740854263306 grad: 5.485149303609403\n",
      "epoch: 226 loss: 1.8386906385421753 grad: 6.264489561385412\n",
      "epoch: 227 loss: 1.834896445274353 grad: 6.001217908965098\n",
      "epoch: 228 loss: 1.83018159866333 grad: 6.175258211283353\n",
      "epoch: 229 loss: 1.8311781883239746 grad: 5.5650322426732775\n",
      "epoch: 230 loss: 1.8614373207092285 grad: 5.671423123258541\n",
      "epoch: 231 loss: 1.8330384492874146 grad: 6.639715063763553\n",
      "epoch: 232 loss: 1.8323954343795776 grad: 6.1376959112057525\n",
      "epoch: 233 loss: 1.8409847021102905 grad: 5.480493514378655\n",
      "epoch: 234 loss: 1.8165830373764038 grad: 4.913107434423023\n",
      "epoch: 235 loss: 1.8261269330978394 grad: 6.232322704125499\n",
      "epoch: 236 loss: 1.8222081661224365 grad: 5.632393437294042\n",
      "epoch: 237 loss: 1.8151708841323853 grad: 5.828926785703747\n",
      "epoch: 238 loss: 1.8447667360305786 grad: 5.618824381019092\n",
      "epoch: 239 loss: 1.8119475841522217 grad: 5.339864082666325\n",
      "epoch: 240 loss: 1.8105610609054565 grad: 5.610942208961148\n",
      "epoch: 241 loss: 1.8202261924743652 grad: 6.670543050922875\n",
      "epoch: 242 loss: 1.8215583562850952 grad: 6.034054939506325\n",
      "epoch: 243 loss: 1.8159209489822388 grad: 6.335816051518093\n",
      "epoch: 244 loss: 1.8100755214691162 grad: 5.900446637891628\n",
      "epoch: 245 loss: 1.8157590627670288 grad: 4.769101343233377\n",
      "epoch: 246 loss: 1.8232522010803223 grad: 5.3511526605228905\n",
      "epoch: 247 loss: 1.820478916168213 grad: 5.481820089474139\n",
      "epoch: 248 loss: 1.8150266408920288 grad: 5.136213553447363\n",
      "epoch: 249 loss: 1.8167219161987305 grad: 5.625489741106451\n",
      "epoch: 250 loss: 1.8156309127807617 grad: 5.746440868408027\n",
      "epoch: 251 loss: 1.8218520879745483 grad: 6.343089509933692\n",
      "epoch: 252 loss: 1.8183239698410034 grad: 5.5467235886423465\n",
      "epoch: 253 loss: 1.8061929941177368 grad: 5.072900285439876\n",
      "epoch: 254 loss: 1.8148670196533203 grad: 5.948193025862103\n",
      "epoch: 255 loss: 1.8235546350479126 grad: 5.702405137224271\n",
      "epoch: 256 loss: 1.8068087100982666 grad: 5.645095633662542\n",
      "epoch: 257 loss: 1.8265424966812134 grad: 5.822030611846241\n",
      "epoch: 258 loss: 1.8226104974746704 grad: 5.455333581651397\n",
      "epoch: 259 loss: 1.813024878501892 grad: 5.156981328096692\n",
      "epoch: 260 loss: 1.8245892524719238 grad: 6.124730143274295\n",
      "epoch: 261 loss: 1.8125718832015991 grad: 5.962565383769822\n",
      "epoch: 262 loss: 1.794645071029663 grad: 6.483142999415808\n",
      "epoch: 263 loss: 1.8124580383300781 grad: 6.667533037291991\n",
      "epoch: 264 loss: 1.8480509519577026 grad: 6.4295575877860385\n",
      "epoch: 265 loss: 1.8302394151687622 grad: 5.692400108236821\n",
      "epoch: 266 loss: 1.8177053928375244 grad: 4.762719091881688\n",
      "epoch: 267 loss: 1.8145878314971924 grad: 5.382588882358202\n",
      "epoch: 268 loss: 1.8150774240493774 grad: 4.967854419056133\n",
      "epoch: 269 loss: 1.8120073080062866 grad: 5.265765501058287\n",
      "epoch: 270 loss: 1.8101646900177002 grad: 5.423940606111761\n",
      "epoch: 271 loss: 1.8085397481918335 grad: 5.398641004576579\n",
      "epoch: 272 loss: 1.8002547025680542 grad: 5.437202118846587\n",
      "epoch: 273 loss: 1.8130912780761719 grad: 5.3572648804629495\n",
      "epoch: 274 loss: 1.8087352514266968 grad: 6.476494018896668\n",
      "epoch: 275 loss: 1.805747389793396 grad: 6.187423149509991\n",
      "epoch: 276 loss: 1.8207728862762451 grad: 6.066383146679968\n",
      "epoch: 277 loss: 1.8085501194000244 grad: 5.921217613685128\n",
      "epoch: 278 loss: 1.8058629035949707 grad: 6.523016201106541\n",
      "epoch: 279 loss: 1.828626275062561 grad: 5.958128416844476\n",
      "epoch: 280 loss: 1.8180192708969116 grad: 5.557209991896618\n",
      "epoch: 281 loss: 1.799256443977356 grad: 5.204701778667403\n",
      "epoch: 282 loss: 1.8042205572128296 grad: 5.914730536891541\n",
      "epoch: 283 loss: 1.823717713356018 grad: 5.214478880910772\n",
      "epoch: 284 loss: 1.8149490356445312 grad: 5.059325941264447\n",
      "epoch: 285 loss: 1.8201910257339478 grad: 6.029411475280381\n",
      "epoch: 286 loss: 1.8129280805587769 grad: 5.594407760518412\n",
      "epoch: 287 loss: 1.8240350484848022 grad: 4.79766022444632\n",
      "epoch: 288 loss: 1.8146764039993286 grad: 4.7299109439241755\n",
      "epoch: 289 loss: 1.8111145496368408 grad: 5.534250086162328\n",
      "epoch: 290 loss: 1.817252278327942 grad: 5.218517466445995\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 291 loss: 1.8012731075286865 grad: 5.833153683916732\n",
      "epoch: 292 loss: 1.7870484590530396 grad: 5.960198219920765\n",
      "epoch: 293 loss: 1.8259482383728027 grad: 6.141913313722369\n",
      "epoch: 294 loss: 1.8132598400115967 grad: 6.055450233224075\n",
      "epoch: 295 loss: 1.7992784976959229 grad: 6.278960507083361\n",
      "epoch: 296 loss: 1.824326515197754 grad: 5.116542319203117\n",
      "epoch: 297 loss: 1.801087737083435 grad: 5.375554718271208\n",
      "epoch: 298 loss: 1.8115085363388062 grad: 6.408985436445085\n",
      "epoch: 299 loss: 1.8091344833374023 grad: 6.208845956520351\n",
      "epoch: 300 loss: 1.8118643760681152 grad: 5.11794087889171\n",
      "epoch: 301 loss: 1.7946746349334717 grad: 5.433049279120164\n",
      "epoch: 302 loss: 1.7966642379760742 grad: 6.671320389699614\n",
      "epoch: 303 loss: 1.8070240020751953 grad: 5.5346541193978895\n",
      "epoch: 304 loss: 1.8033517599105835 grad: 6.891058233417829\n",
      "epoch: 305 loss: 1.809446096420288 grad: 5.972296894321473\n",
      "epoch: 306 loss: 1.8049432039260864 grad: 6.639296851988229\n",
      "epoch: 307 loss: 1.8013331890106201 grad: 5.536899775137759\n",
      "epoch: 308 loss: 1.8234410285949707 grad: 6.476575789642834\n",
      "epoch: 309 loss: 1.8058806657791138 grad: 4.970382206845753\n",
      "epoch: 310 loss: 1.8185349702835083 grad: 5.825659194703182\n",
      "epoch: 311 loss: 1.8041942119598389 grad: 6.212707614034737\n",
      "epoch: 312 loss: 1.805295705795288 grad: 5.827300291451614\n",
      "epoch: 313 loss: 1.8004025220870972 grad: 5.792283080858946\n",
      "epoch: 314 loss: 1.8032927513122559 grad: 5.136988790556701\n",
      "epoch: 315 loss: 1.8037303686141968 grad: 6.160180560607899\n",
      "epoch: 316 loss: 1.814835548400879 grad: 4.56214568585745\n",
      "epoch: 317 loss: 1.805672526359558 grad: 5.895783639793716\n",
      "epoch: 318 loss: 1.7931352853775024 grad: 6.3150112534102165\n",
      "epoch: 319 loss: 1.810868501663208 grad: 5.595120577129978\n",
      "epoch: 320 loss: 1.7973923683166504 grad: 7.120390775750229\n",
      "epoch: 321 loss: 1.8124490976333618 grad: 5.530804361246636\n",
      "epoch: 322 loss: 1.802925705909729 grad: 5.152576248924662\n",
      "epoch: 323 loss: 1.777599573135376 grad: 5.476915871414161\n",
      "epoch: 324 loss: 1.7871623039245605 grad: 6.363869116937816\n",
      "epoch: 325 loss: 1.7993313074111938 grad: 5.352763525643414\n",
      "epoch: 326 loss: 1.8201996088027954 grad: 6.349626172169034\n",
      "epoch: 327 loss: 1.8188931941986084 grad: 6.5414989557822185\n",
      "epoch: 328 loss: 1.804358720779419 grad: 6.203019497569571\n",
      "epoch: 329 loss: 1.8069146871566772 grad: 6.176135098544552\n",
      "epoch: 330 loss: 1.7994168996810913 grad: 7.032051543549252\n",
      "epoch: 331 loss: 1.8391876220703125 grad: 6.433844832996589\n",
      "epoch: 332 loss: 1.802991271018982 grad: 5.209006283175219\n",
      "epoch: 333 loss: 1.7978678941726685 grad: 6.395636688421407\n",
      "epoch: 334 loss: 1.806545615196228 grad: 6.121378001188749\n",
      "epoch: 335 loss: 1.8108118772506714 grad: 6.949586411330356\n",
      "epoch: 336 loss: 1.793365478515625 grad: 5.074424829274023\n",
      "epoch: 337 loss: 1.8126248121261597 grad: 6.885182559153893\n",
      "epoch: 338 loss: 1.8098435401916504 grad: 6.584241164222938\n",
      "epoch: 339 loss: 1.7820353507995605 grad: 5.900144812971063\n",
      "epoch: 340 loss: 1.8093057870864868 grad: 6.318353654146435\n",
      "epoch: 341 loss: 1.7963472604751587 grad: 5.531262098711667\n",
      "epoch: 342 loss: 1.7896350622177124 grad: 5.424714782426005\n",
      "epoch: 343 loss: 1.7951774597167969 grad: 6.897930014330389\n",
      "epoch: 344 loss: 1.8093090057373047 grad: 5.741036189406591\n",
      "epoch: 345 loss: 1.7911176681518555 grad: 6.581863927800441\n",
      "epoch: 346 loss: 1.7853598594665527 grad: 5.377197049964693\n",
      "epoch: 347 loss: 1.7854934930801392 grad: 6.601463017002278\n",
      "epoch: 348 loss: 1.8037163019180298 grad: 5.190768872293004\n",
      "epoch: 349 loss: 1.7977714538574219 grad: 5.3202148563972775\n",
      "epoch: 350 loss: 1.7978912591934204 grad: 4.860665266930958\n",
      "epoch: 351 loss: 1.7994611263275146 grad: 5.368529106282689\n",
      "epoch: 352 loss: 1.7980241775512695 grad: 6.965957940276504\n",
      "epoch: 353 loss: 1.8093513250350952 grad: 6.582972681170629\n",
      "epoch: 354 loss: 1.789013147354126 grad: 6.595131015530136\n",
      "epoch: 355 loss: 1.7861896753311157 grad: 5.6398756672574635\n",
      "epoch: 356 loss: 1.7907581329345703 grad: 5.555919357114434\n",
      "epoch: 357 loss: 1.7796343564987183 grad: 5.584233854162795\n",
      "epoch: 358 loss: 1.783495306968689 grad: 6.197428839521423\n",
      "epoch: 359 loss: 1.7828199863433838 grad: 5.575312384713297\n",
      "epoch: 360 loss: 1.784822940826416 grad: 4.712259806092911\n",
      "epoch: 361 loss: 1.7844877243041992 grad: 5.6216285465726825\n",
      "epoch: 362 loss: 1.7796028852462769 grad: 7.341547787325763\n",
      "epoch: 363 loss: 1.8079502582550049 grad: 5.249323254974678\n",
      "epoch: 364 loss: 1.782678246498108 grad: 5.820498944547869\n",
      "epoch: 365 loss: 1.7850978374481201 grad: 5.519794246194376\n",
      "epoch: 366 loss: 1.7840596437454224 grad: 5.891636612448016\n",
      "epoch: 367 loss: 1.8026063442230225 grad: 6.674115081165043\n",
      "epoch: 368 loss: 1.7989990711212158 grad: 5.680331198840577\n",
      "epoch: 369 loss: 1.7883573770523071 grad: 6.54128475786124\n",
      "epoch: 370 loss: 1.8034687042236328 grad: 5.251673840965633\n",
      "epoch: 371 loss: 1.7993841171264648 grad: 5.97887258276029\n",
      "epoch: 372 loss: 1.7732477188110352 grad: 5.111698733889503\n",
      "epoch: 373 loss: 1.7881569862365723 grad: 6.783130060710911\n",
      "epoch: 374 loss: 1.7705233097076416 grad: 5.7185931368595835\n",
      "epoch: 375 loss: 1.7756403684616089 grad: 6.118356588910689\n",
      "epoch: 376 loss: 1.7828084230422974 grad: 4.750072015416143\n",
      "epoch: 377 loss: 1.7786847352981567 grad: 4.607275941255683\n",
      "epoch: 378 loss: 1.7614808082580566 grad: 5.191414543119973\n",
      "epoch: 379 loss: 1.7796305418014526 grad: 6.5316425329727075\n",
      "epoch: 380 loss: 1.8120399713516235 grad: 5.99496288927687\n",
      "epoch: 381 loss: 1.785773754119873 grad: 5.2523581000910085\n",
      "epoch: 382 loss: 1.780694603919983 grad: 6.82645635939497\n",
      "epoch: 383 loss: 1.7708146572113037 grad: 4.786001455108312\n",
      "epoch: 384 loss: 1.7819130420684814 grad: 5.739721618913534\n",
      "epoch: 385 loss: 1.7936513423919678 grad: 5.927998025133713\n",
      "epoch: 386 loss: 1.7826985120773315 grad: 6.102608335483739\n",
      "epoch: 387 loss: 1.7699004411697388 grad: 5.439186690672253\n",
      "epoch: 388 loss: 1.7822823524475098 grad: 4.741475167910274\n",
      "epoch: 389 loss: 1.790622591972351 grad: 5.397741755926716\n",
      "epoch: 390 loss: 1.7920982837677002 grad: 5.160540238690807\n",
      "epoch: 391 loss: 1.7786142826080322 grad: 5.733653299075307\n",
      "epoch: 392 loss: 1.7843180894851685 grad: 6.205200296607689\n",
      "epoch: 393 loss: 1.7709012031555176 grad: 5.803215004891142\n",
      "epoch: 394 loss: 1.7801704406738281 grad: 6.153835593324084\n",
      "epoch: 395 loss: 1.7998055219650269 grad: 6.870614377271739\n",
      "epoch: 396 loss: 1.808948040008545 grad: 6.137009003245372\n",
      "epoch: 397 loss: 1.770264983177185 grad: 5.66318802909368\n",
      "epoch: 398 loss: 1.7922852039337158 grad: 5.287993667579795\n",
      "epoch: 399 loss: 1.7966868877410889 grad: 5.518150869485474\n",
      "epoch: 400 loss: 1.7894185781478882 grad: 5.474520779070493\n",
      "epoch: 401 loss: 1.7762463092803955 grad: 4.884241394894406\n",
      "epoch: 402 loss: 1.7827810049057007 grad: 5.530862871581034\n",
      "epoch: 403 loss: 1.7858943939208984 grad: 6.358029365463269\n",
      "epoch: 404 loss: 1.8066141605377197 grad: 6.009285355801579\n",
      "epoch: 405 loss: 1.7866696119308472 grad: 5.896648463464873\n",
      "epoch: 406 loss: 1.7862366437911987 grad: 6.715288266730828\n",
      "epoch: 407 loss: 1.7835493087768555 grad: 5.447389928262777\n",
      "epoch: 408 loss: 1.809761643409729 grad: 5.937042497484649\n",
      "epoch: 409 loss: 1.7716867923736572 grad: 4.724191746216439\n",
      "epoch: 410 loss: 1.7924022674560547 grad: 6.057036928583185\n",
      "epoch: 411 loss: 1.7971235513687134 grad: 5.076985813715192\n",
      "epoch: 412 loss: 1.786240816116333 grad: 4.591820483152535\n",
      "epoch: 413 loss: 1.7798290252685547 grad: 6.244002908937719\n",
      "epoch: 414 loss: 1.7696541547775269 grad: 5.353130307995791\n",
      "epoch: 415 loss: 1.7839449644088745 grad: 5.629874749042857\n",
      "epoch: 416 loss: 1.7724946737289429 grad: 5.23747332056715\n",
      "epoch: 417 loss: 1.7647227048873901 grad: 5.720538793427136\n",
      "epoch: 418 loss: 1.782913088798523 grad: 5.851179264552908\n",
      "epoch: 419 loss: 1.7715250253677368 grad: 6.559249752449446\n",
      "epoch: 420 loss: 1.7689632177352905 grad: 5.031212775633061\n",
      "epoch: 421 loss: 1.7750928401947021 grad: 4.787184646701101\n",
      "epoch: 422 loss: 1.7990604639053345 grad: 6.330550195079461\n",
      "epoch: 423 loss: 1.7904359102249146 grad: 6.516809447711687\n",
      "epoch: 424 loss: 1.779693603515625 grad: 6.22943748471141\n",
      "epoch: 425 loss: 1.7952409982681274 grad: 6.535456608226043\n",
      "epoch: 426 loss: 1.777684211730957 grad: 6.997503967969337\n",
      "epoch: 427 loss: 1.7830524444580078 grad: 6.5077917905220515\n",
      "epoch: 428 loss: 1.8025280237197876 grad: 6.723476810085274\n",
      "epoch: 429 loss: 1.787945032119751 grad: 5.259082551121133\n",
      "epoch: 430 loss: 1.7731873989105225 grad: 5.061854930489235\n",
      "epoch: 431 loss: 1.771496295928955 grad: 5.766384134258433\n",
      "epoch: 432 loss: 1.7730889320373535 grad: 6.176744900366972\n",
      "epoch: 433 loss: 1.7908899784088135 grad: 6.329817409590298\n",
      "epoch: 434 loss: 1.809113621711731 grad: 6.263721993273181\n",
      "epoch: 435 loss: 1.779256820678711 grad: 6.087027954497437\n",
      "epoch: 436 loss: 1.7729058265686035 grad: 5.524459395266979\n",
      "epoch: 437 loss: 1.770222783088684 grad: 5.69765781441582\n",
      "epoch: 438 loss: 1.773723840713501 grad: 5.56636709431728\n",
      "epoch: 439 loss: 1.762487769126892 grad: 5.706585761039995\n",
      "epoch: 440 loss: 1.779085636138916 grad: 6.343405425343326\n",
      "epoch: 441 loss: 1.7743964195251465 grad: 5.904923987626038\n",
      "epoch: 442 loss: 1.7794098854064941 grad: 6.679753216914024\n",
      "epoch: 443 loss: 1.8101223707199097 grad: 5.715366954101646\n",
      "epoch: 444 loss: 1.7744067907333374 grad: 5.178915838281336\n",
      "epoch: 445 loss: 1.7527416944503784 grad: 5.41515024093147\n",
      "epoch: 446 loss: 1.7723369598388672 grad: 5.887390800345187\n",
      "epoch: 447 loss: 1.7669832706451416 grad: 5.951328732643084\n",
      "epoch: 448 loss: 1.7643208503723145 grad: 4.9959012761680945\n",
      "epoch: 449 loss: 1.7688860893249512 grad: 5.907496165426213\n",
      "epoch: 450 loss: 1.7763948440551758 grad: 7.104654885833923\n",
      "epoch: 451 loss: 1.8062175512313843 grad: 5.335530246033881\n",
      "epoch: 452 loss: 1.7812713384628296 grad: 5.505613646747796\n",
      "epoch: 453 loss: 1.7930482625961304 grad: 5.05135590751663\n",
      "epoch: 454 loss: 1.763870358467102 grad: 5.572095608226875\n",
      "epoch: 455 loss: 1.7764357328414917 grad: 5.443784232811133\n",
      "epoch: 456 loss: 1.7717543840408325 grad: 5.981424605675408\n",
      "epoch: 457 loss: 1.760014295578003 grad: 5.403469236973078\n",
      "epoch: 458 loss: 1.7832300662994385 grad: 5.972586704469399\n",
      "epoch: 459 loss: 1.7679576873779297 grad: 7.47560128237519\n",
      "epoch: 460 loss: 1.796970248222351 grad: 6.534992268241434\n",
      "epoch: 461 loss: 1.7801928520202637 grad: 6.1259308756950865\n",
      "epoch: 462 loss: 1.7611030340194702 grad: 4.826952287425922\n",
      "epoch: 463 loss: 1.7748137712478638 grad: 5.985606685972766\n",
      "epoch: 464 loss: 1.7684330940246582 grad: 5.193090741273611\n",
      "epoch: 465 loss: 1.7689247131347656 grad: 6.103910000620147\n",
      "epoch: 466 loss: 1.7568926811218262 grad: 4.155230689885063\n",
      "epoch: 467 loss: 1.7620755434036255 grad: 5.770085994052539\n",
      "epoch: 468 loss: 1.764073133468628 grad: 6.129900351704366\n",
      "epoch: 469 loss: 1.7696031332015991 grad: 5.729749056191986\n",
      "epoch: 470 loss: 1.7594268321990967 grad: 6.115573861442427\n",
      "epoch: 471 loss: 1.7701936960220337 grad: 5.601947178752443\n",
      "epoch: 472 loss: 1.7511910200119019 grad: 5.8192554492682875\n",
      "epoch: 473 loss: 1.7722409963607788 grad: 5.349293733188013\n",
      "epoch: 474 loss: 1.758955478668213 grad: 5.767007678785405\n",
      "epoch: 475 loss: 1.785972237586975 grad: 5.6844232558574905\n",
      "epoch: 476 loss: 1.7584010362625122 grad: 5.66468271922176\n",
      "epoch: 477 loss: 1.7691222429275513 grad: 5.570487466316081\n",
      "epoch: 478 loss: 1.7545942068099976 grad: 5.0717541426398265\n",
      "epoch: 479 loss: 1.7371046543121338 grad: 4.777100403240761\n",
      "epoch: 480 loss: 1.7630518674850464 grad: 5.4486478762038235\n",
      "epoch: 481 loss: 1.7701770067214966 grad: 7.096665842474197\n",
      "epoch: 482 loss: 1.76771879196167 grad: 5.766493821816217\n",
      "epoch: 483 loss: 1.760705828666687 grad: 5.485666670935369\n",
      "epoch: 484 loss: 1.7687193155288696 grad: 6.285766996800775\n",
      "epoch: 485 loss: 1.7562156915664673 grad: 6.39720811489332\n",
      "epoch: 486 loss: 1.749271035194397 grad: 4.2897648413948675\n",
      "epoch: 487 loss: 1.7622390985488892 grad: 7.276611354501588\n",
      "epoch: 488 loss: 1.7560688257217407 grad: 5.166097712544768\n",
      "epoch: 489 loss: 1.767012357711792 grad: 5.879963642897131\n",
      "epoch: 490 loss: 1.7541749477386475 grad: 6.0502583338637645\n",
      "epoch: 491 loss: 1.7515181303024292 grad: 6.110338662201511\n",
      "epoch: 492 loss: 1.7694727182388306 grad: 4.772464767571826\n",
      "epoch: 493 loss: 1.7579312324523926 grad: 6.560510404264191\n",
      "epoch: 494 loss: 1.7493724822998047 grad: 4.710446710426555\n",
      "epoch: 495 loss: 1.7628628015518188 grad: 6.576398140425746\n",
      "epoch: 496 loss: 1.7536410093307495 grad: 4.602985529535646\n",
      "epoch: 497 loss: 1.758055329322815 grad: 5.770631300390498\n",
      "epoch: 498 loss: 1.7760515213012695 grad: 4.996361509565672\n",
      "epoch: 499 loss: 1.7670605182647705 grad: 5.7070411746769265\n",
      "2.087987907230854\n",
      "epoch: 0 loss: 2.3031938076019287 grad: 1.254270766859889\n",
      "epoch: 1 loss: 2.303743362426758 grad: 1.240159212110845\n",
      "epoch: 2 loss: 2.3025929927825928 grad: 1.2582291721159384\n",
      "epoch: 3 loss: 2.303065776824951 grad: 1.2676735516851916\n",
      "epoch: 4 loss: 2.303143262863159 grad: 1.2605182959454222\n",
      "epoch: 5 loss: 2.303621530532837 grad: 1.2436214776779895\n",
      "epoch: 6 loss: 2.3024730682373047 grad: 1.2728503465075933\n",
      "epoch: 7 loss: 2.303368330001831 grad: 1.2494109517650767\n",
      "epoch: 8 loss: 2.3030319213867188 grad: 1.2411146487186973\n",
      "epoch: 9 loss: 2.3022921085357666 grad: 1.267571134396666\n",
      "epoch: 10 loss: 2.302633285522461 grad: 1.2539681064127575\n",
      "epoch: 11 loss: 2.3032262325286865 grad: 1.2517345382181544\n",
      "epoch: 12 loss: 2.3036012649536133 grad: 1.2528614188333795\n",
      "epoch: 13 loss: 2.302927017211914 grad: 1.2521871133977251\n",
      "epoch: 14 loss: 2.302682399749756 grad: 1.2587571834539255\n",
      "epoch: 15 loss: 2.3031885623931885 grad: 1.2617030222530639\n",
      "epoch: 16 loss: 2.302440881729126 grad: 1.271246538652728\n",
      "epoch: 17 loss: 2.3033156394958496 grad: 1.2520269564748372\n",
      "epoch: 18 loss: 2.30267071723938 grad: 1.2561650851072508\n",
      "epoch: 19 loss: 2.3027985095977783 grad: 1.2602069798638926\n",
      "epoch: 20 loss: 2.302517890930176 grad: 1.2591196498316195\n",
      "epoch: 21 loss: 2.3024353981018066 grad: 1.260489716314681\n",
      "epoch: 22 loss: 2.3028531074523926 grad: 1.2531977441875146\n",
      "epoch: 23 loss: 2.3033242225646973 grad: 1.2541851605610213\n",
      "epoch: 24 loss: 2.302839994430542 grad: 1.255481514030151\n",
      "epoch: 25 loss: 2.302722454071045 grad: 1.25399145661735\n",
      "epoch: 26 loss: 2.3028604984283447 grad: 1.2511551085349528\n",
      "epoch: 27 loss: 2.302778482437134 grad: 1.2452783549559259\n",
      "epoch: 28 loss: 2.3027350902557373 grad: 1.2568690260901811\n",
      "epoch: 29 loss: 2.3020358085632324 grad: 1.257737533043375\n",
      "epoch: 30 loss: 2.302769184112549 grad: 1.2550799986661694\n",
      "epoch: 31 loss: 2.3031795024871826 grad: 1.2476206060705914\n",
      "epoch: 32 loss: 2.302720308303833 grad: 1.2523146108631784\n",
      "epoch: 33 loss: 2.303011894226074 grad: 1.2604145233608073\n",
      "epoch: 34 loss: 2.3023688793182373 grad: 1.2717963918574184\n",
      "epoch: 35 loss: 2.303161859512329 grad: 1.242783462698941\n",
      "epoch: 36 loss: 2.3023738861083984 grad: 1.267025189124979\n",
      "epoch: 37 loss: 2.3029086589813232 grad: 1.246505705264604\n",
      "epoch: 38 loss: 2.303276777267456 grad: 1.241931810973227\n",
      "epoch: 39 loss: 2.303171396255493 grad: 1.2344083254602516\n",
      "epoch: 40 loss: 2.302804470062256 grad: 1.2618761365227993\n",
      "epoch: 41 loss: 2.3033640384674072 grad: 1.2419508930354837\n",
      "epoch: 42 loss: 2.3025591373443604 grad: 1.245921393095087\n",
      "epoch: 43 loss: 2.3025782108306885 grad: 1.256413195293308\n",
      "epoch: 44 loss: 2.3027665615081787 grad: 1.2567421170006994\n",
      "epoch: 45 loss: 2.302239418029785 grad: 1.2599701707450939\n",
      "epoch: 46 loss: 2.3024864196777344 grad: 1.2631951921309035\n",
      "epoch: 47 loss: 2.302891254425049 grad: 1.2501876656638666\n",
      "epoch: 48 loss: 2.3031115531921387 grad: 1.243232935598667\n",
      "epoch: 49 loss: 2.3029890060424805 grad: 1.2499403152041995\n",
      "epoch: 50 loss: 2.3033297061920166 grad: 1.2369984981921753\n",
      "epoch: 51 loss: 2.3031129837036133 grad: 1.2429892777997469\n",
      "epoch: 52 loss: 2.302920341491699 grad: 1.2452975599158054\n",
      "epoch: 53 loss: 2.303107738494873 grad: 1.2462218136744692\n",
      "epoch: 54 loss: 2.303032159805298 grad: 1.2474633209011887\n",
      "epoch: 55 loss: 2.3031558990478516 grad: 1.250909879033099\n",
      "epoch: 56 loss: 2.302959442138672 grad: 1.2538852176762052\n",
      "epoch: 57 loss: 2.303602695465088 grad: 1.2395589394099449\n",
      "epoch: 58 loss: 2.302696704864502 grad: 1.2518778002916997\n",
      "epoch: 59 loss: 2.3023860454559326 grad: 1.2520359790946787\n",
      "epoch: 60 loss: 2.3036162853240967 grad: 1.2404640744928093\n",
      "epoch: 61 loss: 2.3032641410827637 grad: 1.245523108415202\n",
      "epoch: 62 loss: 2.3030195236206055 grad: 1.2481322396428338\n",
      "epoch: 63 loss: 2.3030433654785156 grad: 1.2454474962257323\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 64 loss: 2.3030667304992676 grad: 1.2488225419425392\n",
      "epoch: 65 loss: 2.3024399280548096 grad: 1.250732284455028\n",
      "epoch: 66 loss: 2.3022212982177734 grad: 1.2556743580748193\n",
      "epoch: 67 loss: 2.3028082847595215 grad: 1.2507731719053394\n",
      "epoch: 68 loss: 2.3031907081604004 grad: 1.236915234674049\n",
      "epoch: 69 loss: 2.3026773929595947 grad: 1.2490908054871455\n",
      "epoch: 70 loss: 2.303302049636841 grad: 1.236325942731965\n",
      "epoch: 71 loss: 2.30325984954834 grad: 1.243901312497208\n",
      "epoch: 72 loss: 2.302387237548828 grad: 1.2533507083509383\n",
      "epoch: 73 loss: 2.3026652336120605 grad: 1.2503625647966854\n",
      "epoch: 74 loss: 2.3031415939331055 grad: 1.2448590925732066\n",
      "epoch: 75 loss: 2.302985668182373 grad: 1.2425082174096522\n",
      "epoch: 76 loss: 2.302886724472046 grad: 1.2476860334383442\n",
      "epoch: 77 loss: 2.302748441696167 grad: 1.2475458306005403\n",
      "epoch: 78 loss: 2.302635669708252 grad: 1.241540857939981\n",
      "epoch: 79 loss: 2.3024818897247314 grad: 1.2398818933205413\n",
      "epoch: 80 loss: 2.303072929382324 grad: 1.231435520875652\n",
      "epoch: 81 loss: 2.302349090576172 grad: 1.2553569528289021\n",
      "epoch: 82 loss: 2.3028528690338135 grad: 1.2357366186777308\n",
      "epoch: 83 loss: 2.302960157394409 grad: 1.2560021336474974\n",
      "epoch: 84 loss: 2.3022384643554688 grad: 1.2477935104028484\n",
      "epoch: 85 loss: 2.302734613418579 grad: 1.2512192664194912\n",
      "epoch: 86 loss: 2.3029849529266357 grad: 1.2463170559651824\n",
      "epoch: 87 loss: 2.3025553226470947 grad: 1.2425960678780925\n",
      "epoch: 88 loss: 2.3027098178863525 grad: 1.2457906139316037\n",
      "epoch: 89 loss: 2.3030056953430176 grad: 1.2240185292238104\n",
      "epoch: 90 loss: 2.302929401397705 grad: 1.246918445421634\n",
      "epoch: 91 loss: 2.3033065795898438 grad: 1.2306852986840235\n",
      "epoch: 92 loss: 2.303704261779785 grad: 1.2354511803234114\n",
      "epoch: 93 loss: 2.3029959201812744 grad: 1.2483729609077618\n",
      "epoch: 94 loss: 2.3031699657440186 grad: 1.2316805786205574\n",
      "epoch: 95 loss: 2.303004741668701 grad: 1.234570389911015\n",
      "epoch: 96 loss: 2.3030941486358643 grad: 1.2347352853126174\n",
      "epoch: 97 loss: 2.303213119506836 grad: 1.2418308712723147\n",
      "epoch: 98 loss: 2.3030662536621094 grad: 1.232298190400581\n",
      "epoch: 99 loss: 2.3026461601257324 grad: 1.2513628742317595\n",
      "epoch: 100 loss: 2.302654504776001 grad: 1.2428213921892974\n",
      "epoch: 101 loss: 2.302546977996826 grad: 1.2409029832010023\n",
      "epoch: 102 loss: 2.3031468391418457 grad: 1.2562792450559164\n",
      "epoch: 103 loss: 2.302734613418579 grad: 1.2315374550442877\n",
      "epoch: 104 loss: 2.3030691146850586 grad: 1.2369489732682557\n",
      "epoch: 105 loss: 2.302868366241455 grad: 1.2381952316925255\n",
      "epoch: 106 loss: 2.3031232357025146 grad: 1.2365805775699545\n",
      "epoch: 107 loss: 2.3032138347625732 grad: 1.2223637898153226\n",
      "epoch: 108 loss: 2.3031115531921387 grad: 1.226077290789579\n",
      "epoch: 109 loss: 2.3029122352600098 grad: 1.2367229133360236\n",
      "epoch: 110 loss: 2.302396297454834 grad: 1.2473469875856407\n",
      "epoch: 111 loss: 2.303312063217163 grad: 1.2322505776537582\n",
      "epoch: 112 loss: 2.3033018112182617 grad: 1.2268137525460343\n",
      "epoch: 113 loss: 2.302687644958496 grad: 1.236672237844369\n",
      "epoch: 114 loss: 2.3032028675079346 grad: 1.2262007822227177\n",
      "epoch: 115 loss: 2.3031718730926514 grad: 1.2314224988351472\n",
      "epoch: 116 loss: 2.3030052185058594 grad: 1.2354319079442777\n",
      "epoch: 117 loss: 2.30291485786438 grad: 1.2332421789307975\n",
      "epoch: 118 loss: 2.303833246231079 grad: 1.2086782749457698\n",
      "epoch: 119 loss: 2.303316593170166 grad: 1.2238306779846815\n",
      "epoch: 120 loss: 2.303130626678467 grad: 1.2303570090804161\n",
      "epoch: 121 loss: 2.3035619258880615 grad: 1.2281423744871207\n",
      "epoch: 122 loss: 2.3028030395507812 grad: 1.2460312219299672\n",
      "epoch: 123 loss: 2.3023602962493896 grad: 1.2390171341239549\n",
      "epoch: 124 loss: 2.302595615386963 grad: 1.233948833538249\n",
      "epoch: 125 loss: 2.3034145832061768 grad: 1.228781470010752\n",
      "epoch: 126 loss: 2.3029592037200928 grad: 1.2378898133091363\n",
      "epoch: 127 loss: 2.3029134273529053 grad: 1.247790223625045\n",
      "epoch: 128 loss: 2.3027262687683105 grad: 1.2333650578973845\n",
      "epoch: 129 loss: 2.303372859954834 grad: 1.232235864704726\n",
      "epoch: 130 loss: 2.302827835083008 grad: 1.2300387181171646\n",
      "epoch: 131 loss: 2.3026785850524902 grad: 1.2407314640281366\n",
      "epoch: 132 loss: 2.3030343055725098 grad: 1.2301115662225388\n",
      "epoch: 133 loss: 2.3027288913726807 grad: 1.2389974646761805\n",
      "epoch: 134 loss: 2.3030917644500732 grad: 1.2311266072220095\n",
      "epoch: 135 loss: 2.303006172180176 grad: 1.2279567467307464\n",
      "epoch: 136 loss: 2.3027102947235107 grad: 1.2441436179252046\n",
      "epoch: 137 loss: 2.3033883571624756 grad: 1.2237453921513248\n",
      "epoch: 138 loss: 2.3027114868164062 grad: 1.2307428744906146\n",
      "epoch: 139 loss: 2.303145408630371 grad: 1.2442743940563459\n",
      "epoch: 140 loss: 2.302834987640381 grad: 1.237904725941859\n",
      "epoch: 141 loss: 2.302321195602417 grad: 1.245177260901232\n",
      "epoch: 142 loss: 2.3027868270874023 grad: 1.229898336947718\n",
      "epoch: 143 loss: 2.3033204078674316 grad: 1.2319754886732894\n",
      "epoch: 144 loss: 2.30289363861084 grad: 1.2290797208302788\n",
      "epoch: 145 loss: 2.303248405456543 grad: 1.2327369683725198\n",
      "epoch: 146 loss: 2.30271315574646 grad: 1.2322188837764163\n",
      "epoch: 147 loss: 2.302248954772949 grad: 1.2339909089792018\n",
      "epoch: 148 loss: 2.302825927734375 grad: 1.239495704879999\n",
      "epoch: 149 loss: 2.302769660949707 grad: 1.2297831754170594\n",
      "epoch: 150 loss: 2.3034753799438477 grad: 1.2316379724033473\n",
      "epoch: 151 loss: 2.303234100341797 grad: 1.2268306498511856\n",
      "epoch: 152 loss: 2.3022866249084473 grad: 1.2413287433049094\n",
      "epoch: 153 loss: 2.303041696548462 grad: 1.2315775236310733\n",
      "epoch: 154 loss: 2.3031346797943115 grad: 1.2235254188759312\n",
      "epoch: 155 loss: 2.302583694458008 grad: 1.2375691171018555\n",
      "epoch: 156 loss: 2.302898406982422 grad: 1.2239860341244835\n",
      "epoch: 157 loss: 2.303118944168091 grad: 1.2242654777919164\n",
      "epoch: 158 loss: 2.303269147872925 grad: 1.2292996825694682\n",
      "epoch: 159 loss: 2.3026301860809326 grad: 1.2274528711716393\n",
      "epoch: 160 loss: 2.3027968406677246 grad: 1.226668441490758\n",
      "epoch: 161 loss: 2.3023734092712402 grad: 1.2345260473426491\n",
      "epoch: 162 loss: 2.3019626140594482 grad: 1.2302261481490282\n",
      "epoch: 163 loss: 2.3030431270599365 grad: 1.225199212066992\n",
      "epoch: 164 loss: 2.3018136024475098 grad: 1.2487940835962368\n",
      "epoch: 165 loss: 2.3029086589813232 grad: 1.2344965116575448\n",
      "epoch: 166 loss: 2.3026225566864014 grad: 1.229309146891215\n",
      "epoch: 167 loss: 2.3024561405181885 grad: 1.2437705333097024\n",
      "epoch: 168 loss: 2.302403211593628 grad: 1.2369563197624678\n",
      "epoch: 169 loss: 2.302372455596924 grad: 1.225450517214273\n",
      "epoch: 170 loss: 2.3027398586273193 grad: 1.2265125929196883\n",
      "epoch: 171 loss: 2.302896499633789 grad: 1.225705822031679\n",
      "epoch: 172 loss: 2.303062915802002 grad: 1.2277613516549566\n",
      "epoch: 173 loss: 2.302896738052368 grad: 1.2407925499987507\n",
      "epoch: 174 loss: 2.3030638694763184 grad: 1.2348485330659305\n",
      "epoch: 175 loss: 2.3028135299682617 grad: 1.2242709560936966\n",
      "epoch: 176 loss: 2.3029301166534424 grad: 1.2287436855369291\n",
      "epoch: 177 loss: 2.3024661540985107 grad: 1.239762422600983\n",
      "epoch: 178 loss: 2.3027613162994385 grad: 1.2239294158339145\n",
      "epoch: 179 loss: 2.3023271560668945 grad: 1.235738992410165\n",
      "epoch: 180 loss: 2.3028597831726074 grad: 1.2241439648168457\n",
      "epoch: 181 loss: 2.302537202835083 grad: 1.2251446622623396\n",
      "epoch: 182 loss: 2.303077459335327 grad: 1.2116747765934892\n",
      "epoch: 183 loss: 2.3023905754089355 grad: 1.234747503717829\n",
      "epoch: 184 loss: 2.3033297061920166 grad: 1.2179611849687284\n",
      "epoch: 185 loss: 2.3022875785827637 grad: 1.2361535347429\n",
      "epoch: 186 loss: 2.303332805633545 grad: 1.2235683284511434\n",
      "epoch: 187 loss: 2.3027215003967285 grad: 1.2281154100672298\n",
      "epoch: 188 loss: 2.3027329444885254 grad: 1.223449683862753\n",
      "epoch: 189 loss: 2.302354335784912 grad: 1.2272828654737198\n",
      "epoch: 190 loss: 2.302978992462158 grad: 1.2284391983338292\n",
      "epoch: 191 loss: 2.3027775287628174 grad: 1.2292877705287306\n",
      "epoch: 192 loss: 2.302661418914795 grad: 1.2242872366600388\n",
      "epoch: 193 loss: 2.3028757572174072 grad: 1.2281610800160303\n",
      "epoch: 194 loss: 2.302906036376953 grad: 1.226144291595408\n",
      "epoch: 195 loss: 2.302372694015503 grad: 1.2239704474378081\n",
      "epoch: 196 loss: 2.303147077560425 grad: 1.2091124133328863\n",
      "epoch: 197 loss: 2.3022851943969727 grad: 1.2363430893858007\n",
      "epoch: 198 loss: 2.3027191162109375 grad: 1.2290858933443412\n",
      "epoch: 199 loss: 2.301931381225586 grad: 1.2396449751556955\n",
      "epoch: 200 loss: 2.3026034832000732 grad: 1.226085047965633\n",
      "epoch: 201 loss: 2.3026020526885986 grad: 1.2336579452228127\n",
      "epoch: 202 loss: 2.3025033473968506 grad: 1.2346161386341832\n",
      "epoch: 203 loss: 2.302802562713623 grad: 1.236485964193615\n",
      "epoch: 204 loss: 2.3027896881103516 grad: 1.2299866691797174\n",
      "epoch: 205 loss: 2.303166389465332 grad: 1.2207446870382963\n",
      "epoch: 206 loss: 2.3025617599487305 grad: 1.2227835477817626\n",
      "epoch: 207 loss: 2.30240797996521 grad: 1.2392724669660398\n",
      "epoch: 208 loss: 2.3032491207122803 grad: 1.2203199713812432\n",
      "epoch: 209 loss: 2.3032267093658447 grad: 1.2211352316015918\n",
      "epoch: 210 loss: 2.3027310371398926 grad: 1.228513642168042\n",
      "epoch: 211 loss: 2.3029165267944336 grad: 1.210527342725693\n",
      "epoch: 212 loss: 2.303184747695923 grad: 1.218250571057156\n",
      "epoch: 213 loss: 2.302438497543335 grad: 1.2289237903157575\n",
      "epoch: 214 loss: 2.3029916286468506 grad: 1.2306073624917881\n",
      "epoch: 215 loss: 2.302978277206421 grad: 1.2247211382029548\n",
      "epoch: 216 loss: 2.3030805587768555 grad: 1.2256936869909247\n",
      "epoch: 217 loss: 2.3032374382019043 grad: 1.2069264342250776\n",
      "epoch: 218 loss: 2.3033952713012695 grad: 1.2311856997280664\n",
      "epoch: 219 loss: 2.3031046390533447 grad: 1.2208549572960548\n",
      "epoch: 220 loss: 2.3031580448150635 grad: 1.2263921877435808\n",
      "epoch: 221 loss: 2.3026442527770996 grad: 1.2246720787814065\n",
      "epoch: 222 loss: 2.302008867263794 grad: 1.232364075637186\n",
      "epoch: 223 loss: 2.3026692867279053 grad: 1.2261572986645328\n",
      "epoch: 224 loss: 2.302572011947632 grad: 1.224309358991579\n",
      "epoch: 225 loss: 2.302795171737671 grad: 1.2175368578265613\n",
      "epoch: 226 loss: 2.3025598526000977 grad: 1.2240882541611051\n",
      "epoch: 227 loss: 2.3027055263519287 grad: 1.227115318119999\n",
      "epoch: 228 loss: 2.3026041984558105 grad: 1.2264421462147896\n",
      "epoch: 229 loss: 2.302755355834961 grad: 1.2231537107570423\n",
      "epoch: 230 loss: 2.3028969764709473 grad: 1.2155408728424282\n",
      "epoch: 231 loss: 2.302035331726074 grad: 1.2354219203615295\n",
      "epoch: 232 loss: 2.3027658462524414 grad: 1.2190314101550492\n",
      "epoch: 233 loss: 2.302509069442749 grad: 1.2242525289489312\n",
      "epoch: 234 loss: 2.302541732788086 grad: 1.2217328940307544\n",
      "epoch: 235 loss: 2.3027493953704834 grad: 1.2222024627946435\n",
      "epoch: 236 loss: 2.302422523498535 grad: 1.2241565942716237\n",
      "epoch: 237 loss: 2.302433490753174 grad: 1.2320811724999832\n",
      "epoch: 238 loss: 2.303553342819214 grad: 1.2023138893317313\n",
      "epoch: 239 loss: 2.3035006523132324 grad: 1.2165454206988215\n",
      "epoch: 240 loss: 2.302673101425171 grad: 1.2236660645964246\n",
      "epoch: 241 loss: 2.3028249740600586 grad: 1.2133839616629605\n",
      "epoch: 242 loss: 2.302870750427246 grad: 1.2213042955069493\n",
      "epoch: 243 loss: 2.3025381565093994 grad: 1.213178928865726\n",
      "epoch: 244 loss: 2.302873134613037 grad: 1.2281390328499828\n",
      "epoch: 245 loss: 2.302945852279663 grad: 1.219624965998625\n",
      "epoch: 246 loss: 2.3023643493652344 grad: 1.2317211592666035\n",
      "epoch: 247 loss: 2.302154302597046 grad: 1.234539111342562\n",
      "epoch: 248 loss: 2.302736282348633 grad: 1.2167823398171642\n",
      "epoch: 249 loss: 2.3027167320251465 grad: 1.219408964656944\n",
      "epoch: 250 loss: 2.302813768386841 grad: 1.218606490111496\n",
      "epoch: 251 loss: 2.3031482696533203 grad: 1.2199328216032996\n",
      "epoch: 252 loss: 2.302818536758423 grad: 1.2225762126886004\n",
      "epoch: 253 loss: 2.3026463985443115 grad: 1.225181151480813\n",
      "epoch: 254 loss: 2.303392171859741 grad: 1.210725853827575\n",
      "epoch: 255 loss: 2.302621841430664 grad: 1.2143413877643143\n",
      "epoch: 256 loss: 2.3026363849639893 grad: 1.2175484808265336\n",
      "epoch: 257 loss: 2.3025898933410645 grad: 1.2152383246362979\n",
      "epoch: 258 loss: 2.303050994873047 grad: 1.2080958802437793\n",
      "epoch: 259 loss: 2.3031675815582275 grad: 1.2204217661064976\n",
      "epoch: 260 loss: 2.302739143371582 grad: 1.2210540149068934\n",
      "epoch: 261 loss: 2.3029682636260986 grad: 1.2244588292928205\n",
      "epoch: 262 loss: 2.302685499191284 grad: 1.2246852997424347\n",
      "epoch: 263 loss: 2.302185297012329 grad: 1.2171471918108947\n",
      "epoch: 264 loss: 2.3025999069213867 grad: 1.2284811223942107\n",
      "epoch: 265 loss: 2.3030028343200684 grad: 1.219076863153734\n",
      "epoch: 266 loss: 2.3022377490997314 grad: 1.2252282835543156\n",
      "epoch: 267 loss: 2.302046060562134 grad: 1.2371607943389948\n",
      "epoch: 268 loss: 2.3026537895202637 grad: 1.2172149921682411\n",
      "epoch: 269 loss: 2.303219795227051 grad: 1.2165131600396264\n",
      "epoch: 270 loss: 2.302157402038574 grad: 1.235043959483312\n",
      "epoch: 271 loss: 2.3031795024871826 grad: 1.2131807898829086\n",
      "epoch: 272 loss: 2.302427053451538 grad: 1.2216762471703873\n",
      "epoch: 273 loss: 2.3025567531585693 grad: 1.2238779092126244\n",
      "epoch: 274 loss: 2.3027806282043457 grad: 1.2120952534892167\n",
      "epoch: 275 loss: 2.3031668663024902 grad: 1.2207628041117762\n",
      "epoch: 276 loss: 2.303337574005127 grad: 1.1989743933432722\n",
      "epoch: 277 loss: 2.3024966716766357 grad: 1.2169555081756755\n",
      "epoch: 278 loss: 2.303338050842285 grad: 1.206297981669195\n",
      "epoch: 279 loss: 2.302907705307007 grad: 1.2091031061108446\n",
      "epoch: 280 loss: 2.302947998046875 grad: 1.2270669810536747\n",
      "epoch: 281 loss: 2.302628755569458 grad: 1.2259462124960023\n",
      "epoch: 282 loss: 2.3028688430786133 grad: 1.2165434050987223\n",
      "epoch: 283 loss: 2.3028340339660645 grad: 1.2143255672325188\n",
      "epoch: 284 loss: 2.3025264739990234 grad: 1.213651573425898\n",
      "epoch: 285 loss: 2.302548885345459 grad: 1.2149473530839063\n",
      "epoch: 286 loss: 2.302672863006592 grad: 1.219293026830114\n",
      "epoch: 287 loss: 2.3026580810546875 grad: 1.2127892933360906\n",
      "epoch: 288 loss: 2.3029747009277344 grad: 1.2238934967086637\n",
      "epoch: 289 loss: 2.30300235748291 grad: 1.2165091894696363\n",
      "epoch: 290 loss: 2.302678346633911 grad: 1.2121957979397848\n",
      "epoch: 291 loss: 2.3026785850524902 grad: 1.2110475727379144\n",
      "epoch: 292 loss: 2.3023645877838135 grad: 1.2187375056756926\n",
      "epoch: 293 loss: 2.303040027618408 grad: 1.2126322951785007\n",
      "epoch: 294 loss: 2.3030292987823486 grad: 1.2065688790568698\n",
      "epoch: 295 loss: 2.302581310272217 grad: 1.2224747917359873\n",
      "epoch: 296 loss: 2.302818536758423 grad: 1.2225198394689147\n",
      "epoch: 297 loss: 2.3019092082977295 grad: 1.2270609032961406\n",
      "epoch: 298 loss: 2.3018929958343506 grad: 1.2170729813561405\n",
      "epoch: 299 loss: 2.30189847946167 grad: 1.225320447483913\n",
      "epoch: 300 loss: 2.302795648574829 grad: 1.216215696095282\n",
      "epoch: 301 loss: 2.3029370307922363 grad: 1.2115863078340356\n",
      "epoch: 302 loss: 2.3029322624206543 grad: 1.2054662195455639\n",
      "epoch: 303 loss: 2.3025128841400146 grad: 1.221661449859052\n",
      "epoch: 304 loss: 2.3027451038360596 grad: 1.2128567198062286\n",
      "epoch: 305 loss: 2.3029041290283203 grad: 1.2152721829719781\n",
      "epoch: 306 loss: 2.3026888370513916 grad: 1.2238250047389774\n",
      "epoch: 307 loss: 2.3032639026641846 grad: 1.2128639448958907\n",
      "epoch: 308 loss: 2.302645444869995 grad: 1.216309593992293\n",
      "epoch: 309 loss: 2.3025307655334473 grad: 1.2241325120678141\n",
      "epoch: 310 loss: 2.3020739555358887 grad: 1.2259614268347385\n",
      "epoch: 311 loss: 2.3022654056549072 grad: 1.2225744013881519\n",
      "epoch: 312 loss: 2.302494525909424 grad: 1.220423961298481\n",
      "epoch: 313 loss: 2.3029158115386963 grad: 1.2091626575686008\n",
      "epoch: 314 loss: 2.302513599395752 grad: 1.219491818178785\n",
      "epoch: 315 loss: 2.303483009338379 grad: 1.2186664418864346\n",
      "epoch: 316 loss: 2.3026905059814453 grad: 1.2124025824217362\n",
      "epoch: 317 loss: 2.3030450344085693 grad: 1.2133760184663096\n",
      "epoch: 318 loss: 2.30232572555542 grad: 1.2186779676093942\n",
      "epoch: 319 loss: 2.3031606674194336 grad: 1.205147550236212\n",
      "epoch: 320 loss: 2.3024518489837646 grad: 1.2128891032373916\n",
      "epoch: 321 loss: 2.3030447959899902 grad: 1.210138620376321\n",
      "epoch: 322 loss: 2.302398920059204 grad: 1.2264241664799758\n",
      "epoch: 323 loss: 2.3032429218292236 grad: 1.2088434514922224\n",
      "epoch: 324 loss: 2.3020730018615723 grad: 1.240090460669885\n",
      "epoch: 325 loss: 2.302421808242798 grad: 1.2125653784079033\n",
      "epoch: 326 loss: 2.302989959716797 grad: 1.2064820292187737\n",
      "epoch: 327 loss: 2.3025524616241455 grad: 1.2218082017331784\n",
      "epoch: 328 loss: 2.3027069568634033 grad: 1.2164212918160335\n",
      "epoch: 329 loss: 2.3029799461364746 grad: 1.2082291956499427\n",
      "epoch: 330 loss: 2.3029301166534424 grad: 1.2064576998559966\n",
      "epoch: 331 loss: 2.3031668663024902 grad: 1.211865775667811\n",
      "epoch: 332 loss: 2.3028881549835205 grad: 1.210261916780534\n",
      "epoch: 333 loss: 2.3021795749664307 grad: 1.2157392607879869\n",
      "epoch: 334 loss: 2.302940845489502 grad: 1.2151884404731736\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 335 loss: 2.3029322624206543 grad: 1.2065921001273046\n",
      "epoch: 336 loss: 2.303183078765869 grad: 1.204094630695643\n",
      "epoch: 337 loss: 2.3026015758514404 grad: 1.230787209713728\n",
      "epoch: 338 loss: 2.301891326904297 grad: 1.2260396932066966\n",
      "epoch: 339 loss: 2.3030309677124023 grad: 1.2060788901326882\n",
      "epoch: 340 loss: 2.3027217388153076 grad: 1.205266322284597\n",
      "epoch: 341 loss: 2.3021912574768066 grad: 1.2298365037829158\n",
      "epoch: 342 loss: 2.302544593811035 grad: 1.2183946222399495\n",
      "epoch: 343 loss: 2.3023264408111572 grad: 1.2250087444119835\n",
      "epoch: 344 loss: 2.302507162094116 grad: 1.2218402754681716\n",
      "epoch: 345 loss: 2.302281379699707 grad: 1.2238663311175528\n",
      "epoch: 346 loss: 2.302691698074341 grad: 1.2186444502929965\n",
      "epoch: 347 loss: 2.3026010990142822 grad: 1.2222626504233285\n",
      "epoch: 348 loss: 2.303148031234741 grad: 1.2081015246535933\n",
      "epoch: 349 loss: 2.302579879760742 grad: 1.2209540714716747\n",
      "epoch: 350 loss: 2.3026514053344727 grad: 1.2160915867407023\n",
      "epoch: 351 loss: 2.3026368618011475 grad: 1.215731885583539\n",
      "epoch: 352 loss: 2.3018157482147217 grad: 1.2291711237141123\n",
      "epoch: 353 loss: 2.303023099899292 grad: 1.2182530735708064\n",
      "epoch: 354 loss: 2.3028125762939453 grad: 1.2148533752539181\n",
      "epoch: 355 loss: 2.3027844429016113 grad: 1.2097162143974047\n",
      "epoch: 356 loss: 2.3024468421936035 grad: 1.2108706401805172\n",
      "epoch: 357 loss: 2.3025262355804443 grad: 1.2225116734755122\n",
      "epoch: 358 loss: 2.301837921142578 grad: 1.2265223620980534\n",
      "epoch: 359 loss: 2.3020660877227783 grad: 1.228274042494521\n",
      "epoch: 360 loss: 2.30259108543396 grad: 1.2256649119413592\n",
      "epoch: 361 loss: 2.303171396255493 grad: 1.2137049495552976\n",
      "epoch: 362 loss: 2.302746057510376 grad: 1.211885745555813\n",
      "epoch: 363 loss: 2.302839517593384 grad: 1.2024026888474408\n",
      "epoch: 364 loss: 2.30356764793396 grad: 1.2058722270719175\n",
      "epoch: 365 loss: 2.3034486770629883 grad: 1.2025423504075863\n",
      "epoch: 366 loss: 2.303345203399658 grad: 1.2030789735320482\n",
      "epoch: 367 loss: 2.302182674407959 grad: 1.2206424183788753\n",
      "epoch: 368 loss: 2.302311420440674 grad: 1.2177301821306288\n",
      "epoch: 369 loss: 2.3022677898406982 grad: 1.2180152004935765\n",
      "epoch: 370 loss: 2.3023569583892822 grad: 1.2223735393564557\n",
      "epoch: 371 loss: 2.3025450706481934 grad: 1.208935143756828\n",
      "epoch: 372 loss: 2.3025553226470947 grad: 1.2290523823180666\n",
      "epoch: 373 loss: 2.3029956817626953 grad: 1.203996794756561\n",
      "epoch: 374 loss: 2.3031163215637207 grad: 1.213401105343586\n",
      "epoch: 375 loss: 2.3027541637420654 grad: 1.220065672913315\n",
      "epoch: 376 loss: 2.3023977279663086 grad: 1.2158152630944397\n",
      "epoch: 377 loss: 2.3021397590637207 grad: 1.2107862693106106\n",
      "epoch: 378 loss: 2.302813768386841 grad: 1.2217518954356719\n",
      "epoch: 379 loss: 2.303035259246826 grad: 1.1982855572631317\n",
      "epoch: 380 loss: 2.302783250808716 grad: 1.2067655392345928\n",
      "epoch: 381 loss: 2.302342653274536 grad: 1.2093360196329683\n",
      "epoch: 382 loss: 2.3027212619781494 grad: 1.2212633256789385\n",
      "epoch: 383 loss: 2.302806854248047 grad: 1.206199891589922\n",
      "epoch: 384 loss: 2.3023276329040527 grad: 1.2135708312067899\n",
      "epoch: 385 loss: 2.303035259246826 grad: 1.2148907781719038\n",
      "epoch: 386 loss: 2.302140951156616 grad: 1.2262969642031258\n",
      "epoch: 387 loss: 2.302319049835205 grad: 1.214764719176668\n",
      "epoch: 388 loss: 2.303130865097046 grad: 1.2034949112613316\n",
      "epoch: 389 loss: 2.3022830486297607 grad: 1.2159145231051962\n",
      "epoch: 390 loss: 2.30218768119812 grad: 1.217354281302837\n",
      "epoch: 391 loss: 2.3027825355529785 grad: 1.2138370310089417\n",
      "epoch: 392 loss: 2.302967071533203 grad: 1.2081834060335828\n",
      "epoch: 393 loss: 2.3026316165924072 grad: 1.21633731629256\n",
      "epoch: 394 loss: 2.3027851581573486 grad: 1.2216392069175426\n",
      "epoch: 395 loss: 2.302299976348877 grad: 1.2214076514374317\n",
      "epoch: 396 loss: 2.302267074584961 grad: 1.2239176436375443\n",
      "epoch: 397 loss: 2.303158760070801 grad: 1.2076258525965617\n",
      "epoch: 398 loss: 2.3031883239746094 grad: 1.2041190527250163\n",
      "epoch: 399 loss: 2.303006172180176 grad: 1.2051901546332777\n",
      "epoch: 400 loss: 2.3029775619506836 grad: 1.2152283779873942\n",
      "epoch: 401 loss: 2.3029592037200928 grad: 1.207478812845823\n",
      "epoch: 402 loss: 2.3025999069213867 grad: 1.2163331283622287\n",
      "epoch: 403 loss: 2.302828788757324 grad: 1.2115271794480376\n",
      "epoch: 404 loss: 2.302363634109497 grad: 1.2136238209759107\n",
      "epoch: 405 loss: 2.302257537841797 grad: 1.2155586338661137\n",
      "epoch: 406 loss: 2.3024678230285645 grad: 1.2094334399675033\n",
      "epoch: 407 loss: 2.302708387374878 grad: 1.208750878505054\n",
      "epoch: 408 loss: 2.3019886016845703 grad: 1.2235372720400817\n",
      "epoch: 409 loss: 2.3021657466888428 grad: 1.2243706773826113\n",
      "epoch: 410 loss: 2.302520275115967 grad: 1.2126383551540563\n",
      "epoch: 411 loss: 2.302206039428711 grad: 1.225471353636951\n",
      "epoch: 412 loss: 2.3026819229125977 grad: 1.2183949839386587\n",
      "epoch: 413 loss: 2.3016302585601807 grad: 1.231207984959751\n",
      "epoch: 414 loss: 2.302804470062256 grad: 1.2097860916909422\n",
      "epoch: 415 loss: 2.3024685382843018 grad: 1.2171343410117847\n",
      "epoch: 416 loss: 2.3031270503997803 grad: 1.1971206725464159\n",
      "epoch: 417 loss: 2.302804708480835 grad: 1.2109767098944368\n",
      "epoch: 418 loss: 2.302109718322754 grad: 1.2075277667137838\n",
      "epoch: 419 loss: 2.3028790950775146 grad: 1.2058744095653917\n",
      "epoch: 420 loss: 2.303004264831543 grad: 1.207565740451202\n",
      "epoch: 421 loss: 2.302347421646118 grad: 1.2133900512615958\n",
      "epoch: 422 loss: 2.302884578704834 grad: 1.2082154129073763\n",
      "epoch: 423 loss: 2.3027234077453613 grad: 1.2171246431590546\n",
      "epoch: 424 loss: 2.3033335208892822 grad: 1.2032260162153443\n",
      "epoch: 425 loss: 2.3025710582733154 grad: 1.2134443450818904\n",
      "epoch: 426 loss: 2.302229642868042 grad: 1.2139322580307692\n",
      "epoch: 427 loss: 2.302987575531006 grad: 1.208116923460722\n",
      "epoch: 428 loss: 2.303178548812866 grad: 1.207881383636656\n",
      "epoch: 429 loss: 2.3026039600372314 grad: 1.2146449931490693\n",
      "epoch: 430 loss: 2.3018035888671875 grad: 1.2264514815520555\n",
      "epoch: 431 loss: 2.3029074668884277 grad: 1.2036433138954823\n",
      "epoch: 432 loss: 2.301907539367676 grad: 1.2114842395124483\n",
      "epoch: 433 loss: 2.3026890754699707 grad: 1.2159454620938512\n",
      "epoch: 434 loss: 2.3014895915985107 grad: 1.231266934260179\n",
      "epoch: 435 loss: 2.303032875061035 grad: 1.2072121692795514\n",
      "epoch: 436 loss: 2.303666353225708 grad: 1.2018137363243908\n",
      "epoch: 437 loss: 2.303088665008545 grad: 1.2094863899151929\n",
      "epoch: 438 loss: 2.302716016769409 grad: 1.224235662480905\n",
      "epoch: 439 loss: 2.302442789077759 grad: 1.2237361236918896\n",
      "epoch: 440 loss: 2.3028295040130615 grad: 1.2004574883030728\n",
      "epoch: 441 loss: 2.3027260303497314 grad: 1.2084633342696294\n",
      "epoch: 442 loss: 2.3030664920806885 grad: 1.2115468286931337\n",
      "epoch: 443 loss: 2.302387237548828 grad: 1.206750547310101\n",
      "epoch: 444 loss: 2.3022098541259766 grad: 1.2217647140302386\n",
      "epoch: 445 loss: 2.3030660152435303 grad: 1.2093165597420126\n",
      "epoch: 446 loss: 2.3027122020721436 grad: 1.2163636542926912\n",
      "epoch: 447 loss: 2.302398920059204 grad: 1.2149586581000467\n",
      "epoch: 448 loss: 2.302558183670044 grad: 1.225082728355783\n",
      "epoch: 449 loss: 2.3027024269104004 grad: 1.215462562820268\n",
      "epoch: 450 loss: 2.3022165298461914 grad: 1.2192662016891445\n",
      "epoch: 451 loss: 2.302774667739868 grad: 1.2092501946654732\n",
      "epoch: 452 loss: 2.3024203777313232 grad: 1.2149103085865223\n",
      "epoch: 453 loss: 2.302687644958496 grad: 1.2130814400401764\n",
      "epoch: 454 loss: 2.3017992973327637 grad: 1.2335052081468767\n",
      "epoch: 455 loss: 2.3026700019836426 grad: 1.2101215670580074\n",
      "epoch: 456 loss: 2.3034017086029053 grad: 1.2032061674805832\n",
      "epoch: 457 loss: 2.3023364543914795 grad: 1.2220511291054121\n",
      "epoch: 458 loss: 2.302647113800049 grad: 1.206959835776601\n",
      "epoch: 459 loss: 2.3025193214416504 grad: 1.211302733647504\n",
      "epoch: 460 loss: 2.3024685382843018 grad: 1.2002434760151017\n",
      "epoch: 461 loss: 2.3031039237976074 grad: 1.20833063154437\n",
      "epoch: 462 loss: 2.3028581142425537 grad: 1.2098559723346538\n",
      "epoch: 463 loss: 2.301852226257324 grad: 1.223527565810992\n",
      "epoch: 464 loss: 2.302654504776001 grad: 1.209644144055404\n",
      "epoch: 465 loss: 2.301978349685669 grad: 1.2200397758112689\n",
      "epoch: 466 loss: 2.303013324737549 grad: 1.191725997986006\n",
      "epoch: 467 loss: 2.3033673763275146 grad: 1.2061217642585111\n",
      "epoch: 468 loss: 2.3023641109466553 grad: 1.210625234723372\n",
      "epoch: 469 loss: 2.3029329776763916 grad: 1.2111203015397585\n",
      "epoch: 470 loss: 2.3029568195343018 grad: 1.1969659334484724\n",
      "epoch: 471 loss: 2.302807331085205 grad: 1.2120530237868754\n",
      "epoch: 472 loss: 2.3027727603912354 grad: 1.2103758709919121\n",
      "epoch: 473 loss: 2.3031020164489746 grad: 1.2007917093320026\n",
      "epoch: 474 loss: 2.3028199672698975 grad: 1.208227206078831\n",
      "epoch: 475 loss: 2.3023810386657715 grad: 1.2152974896007291\n",
      "epoch: 476 loss: 2.302751064300537 grad: 1.2239394954457465\n",
      "epoch: 477 loss: 2.302762746810913 grad: 1.209553291609082\n",
      "epoch: 478 loss: 2.302448034286499 grad: 1.2055824115587812\n",
      "epoch: 479 loss: 2.30197811126709 grad: 1.219203539763666\n",
      "epoch: 480 loss: 2.302449941635132 grad: 1.2066398984309108\n",
      "epoch: 481 loss: 2.3021082878112793 grad: 1.2195766752249457\n",
      "epoch: 482 loss: 2.3031201362609863 grad: 1.2068549063636935\n",
      "epoch: 483 loss: 2.302489995956421 grad: 1.2126040370979656\n",
      "epoch: 484 loss: 2.3026394844055176 grad: 1.1953854113817215\n",
      "epoch: 485 loss: 2.30287504196167 grad: 1.2121860689616628\n",
      "epoch: 486 loss: 2.302206516265869 grad: 1.21877672168101\n",
      "epoch: 487 loss: 2.302722930908203 grad: 1.212769065146512\n",
      "epoch: 488 loss: 2.3018553256988525 grad: 1.2215252467542\n",
      "epoch: 489 loss: 2.3029561042785645 grad: 1.2038152166457463\n",
      "epoch: 490 loss: 2.302833318710327 grad: 1.2035329333979576\n",
      "epoch: 491 loss: 2.3027429580688477 grad: 1.218855938271782\n",
      "epoch: 492 loss: 2.30258846282959 grad: 1.2128732835667\n",
      "epoch: 493 loss: 2.301844835281372 grad: 1.2274112481816066\n",
      "epoch: 494 loss: 2.302232503890991 grad: 1.2175972973355018\n",
      "epoch: 495 loss: 2.3026723861694336 grad: 1.2127004849857517\n",
      "epoch: 496 loss: 2.3030972480773926 grad: 1.2005862525464701\n",
      "epoch: 497 loss: 2.302427053451538 grad: 1.2198808673558579\n",
      "epoch: 498 loss: 2.3019654750823975 grad: 1.222187766446806\n",
      "epoch: 499 loss: 2.3026509284973145 grad: 1.2161387003429736\n",
      "2.302160695195198\n",
      "epoch: 0 loss: 2.303600311279297 grad: 1.1153187682863237\n",
      "epoch: 1 loss: 2.3030664920806885 grad: 1.0775568324643823\n",
      "epoch: 2 loss: 2.302551507949829 grad: 1.0875718551336802\n",
      "epoch: 3 loss: 2.3032515048980713 grad: 1.090955181413197\n",
      "epoch: 4 loss: 2.3028643131256104 grad: 1.0738161911463573\n",
      "epoch: 5 loss: 2.302908182144165 grad: 1.0613950981558966\n",
      "epoch: 6 loss: 2.303123712539673 grad: 1.0491608451878178\n",
      "epoch: 7 loss: 2.302942991256714 grad: 1.059376252042721\n",
      "epoch: 8 loss: 2.3030104637145996 grad: 1.0466555865621934\n",
      "epoch: 9 loss: 2.302497625350952 grad: 1.044542141709595\n",
      "epoch: 10 loss: 2.303248882293701 grad: 1.0368856372984334\n",
      "epoch: 11 loss: 2.3025097846984863 grad: 1.0446120339782081\n",
      "epoch: 12 loss: 2.302297353744507 grad: 1.0363377309385835\n",
      "epoch: 13 loss: 2.302668571472168 grad: 1.029704420612977\n",
      "epoch: 14 loss: 2.3023526668548584 grad: 1.0288097401101526\n",
      "epoch: 15 loss: 2.3028383255004883 grad: 1.0265394002827446\n",
      "epoch: 16 loss: 2.3021979331970215 grad: 1.0388685796938335\n",
      "epoch: 17 loss: 2.3022186756134033 grad: 1.0431256532938855\n",
      "epoch: 18 loss: 2.301560163497925 grad: 1.0497368683055457\n",
      "epoch: 19 loss: 2.301966667175293 grad: 1.0497114235731138\n",
      "epoch: 20 loss: 2.3025081157684326 grad: 1.0396460300396448\n",
      "epoch: 21 loss: 2.3021512031555176 grad: 1.0468759909845031\n",
      "epoch: 22 loss: 2.301999568939209 grad: 1.0515991723227744\n",
      "epoch: 23 loss: 2.302959680557251 grad: 1.0540888888229216\n",
      "epoch: 24 loss: 2.302525281906128 grad: 1.0465621925901534\n",
      "epoch: 25 loss: 2.301887035369873 grad: 1.0609613223285932\n",
      "epoch: 26 loss: 2.301947593688965 grad: 1.0662545164407689\n",
      "epoch: 27 loss: 2.302182674407959 grad: 1.0532142278010261\n",
      "epoch: 28 loss: 2.3016510009765625 grad: 1.0733900250042863\n",
      "epoch: 29 loss: 2.302075147628784 grad: 1.0674575580143562\n",
      "epoch: 30 loss: 2.301574230194092 grad: 1.0787071922150928\n",
      "epoch: 31 loss: 2.302163600921631 grad: 1.0857962565459607\n",
      "epoch: 32 loss: 2.301973581314087 grad: 1.0934517707727436\n",
      "epoch: 33 loss: 2.3015830516815186 grad: 1.0889017474634337\n",
      "epoch: 34 loss: 2.301299571990967 grad: 1.1024731715923057\n",
      "epoch: 35 loss: 2.301729917526245 grad: 1.1061255160464152\n",
      "epoch: 36 loss: 2.3013484477996826 grad: 1.1194346279704146\n",
      "epoch: 37 loss: 2.301522970199585 grad: 1.1254584610403058\n",
      "epoch: 38 loss: 2.300238847732544 grad: 1.1550221175236244\n",
      "epoch: 39 loss: 2.3007264137268066 grad: 1.1556388534557458\n",
      "epoch: 40 loss: 2.3008718490600586 grad: 1.1588898495057716\n",
      "epoch: 41 loss: 2.3001575469970703 grad: 1.1829397058158757\n",
      "epoch: 42 loss: 2.300333023071289 grad: 1.1961768585966812\n",
      "epoch: 43 loss: 2.3003203868865967 grad: 1.1998991977131468\n",
      "epoch: 44 loss: 2.299311876296997 grad: 1.2203729990038223\n",
      "epoch: 45 loss: 2.299177646636963 grad: 1.2448469790803742\n",
      "epoch: 46 loss: 2.3002538681030273 grad: 1.2204100581085575\n",
      "epoch: 47 loss: 2.299729347229004 grad: 1.2532800194836917\n",
      "epoch: 48 loss: 2.299044132232666 grad: 1.2905703702967406\n",
      "epoch: 49 loss: 2.2992029190063477 grad: 1.3103239184323077\n",
      "epoch: 50 loss: 2.2982773780822754 grad: 1.3409960117239121\n",
      "epoch: 51 loss: 2.2973697185516357 grad: 1.3990636313027363\n",
      "epoch: 52 loss: 2.2977616786956787 grad: 1.3854905504563322\n",
      "epoch: 53 loss: 2.2971885204315186 grad: 1.4102463024827312\n",
      "epoch: 54 loss: 2.2967376708984375 grad: 1.4546422579007903\n",
      "epoch: 55 loss: 2.2962422370910645 grad: 1.4742952055937153\n",
      "epoch: 56 loss: 2.295909881591797 grad: 1.4864516873559397\n",
      "epoch: 57 loss: 2.296705961227417 grad: 1.4946058532648114\n",
      "epoch: 58 loss: 2.2958767414093018 grad: 1.5364416626352255\n",
      "epoch: 59 loss: 2.2947912216186523 grad: 1.5330129614458345\n",
      "epoch: 60 loss: 2.29575252532959 grad: 1.567331540474062\n",
      "epoch: 61 loss: 2.2968897819519043 grad: 1.5079997549857205\n",
      "epoch: 62 loss: 2.2942473888397217 grad: 1.5569041914487671\n",
      "epoch: 63 loss: 2.2938461303710938 grad: 1.5812026651701816\n",
      "epoch: 64 loss: 2.2939555644989014 grad: 1.5699602453248753\n",
      "epoch: 65 loss: 2.2949044704437256 grad: 1.5592707927386824\n",
      "epoch: 66 loss: 2.292649745941162 grad: 1.6481080999605298\n",
      "epoch: 67 loss: 2.293971300125122 grad: 1.5987723193977708\n",
      "epoch: 68 loss: 2.293221950531006 grad: 1.5745528814630465\n",
      "epoch: 69 loss: 2.2942326068878174 grad: 1.5953869125048172\n",
      "epoch: 70 loss: 2.2932159900665283 grad: 1.5630521963143513\n",
      "epoch: 71 loss: 2.2925944328308105 grad: 1.561283912372938\n",
      "epoch: 72 loss: 2.2928659915924072 grad: 1.5762559491974701\n",
      "epoch: 73 loss: 2.2920196056365967 grad: 1.5773957095216102\n",
      "epoch: 74 loss: 2.291722297668457 grad: 1.588094467409916\n",
      "epoch: 75 loss: 2.2911248207092285 grad: 1.606255171369643\n",
      "epoch: 76 loss: 2.290644645690918 grad: 1.6131947368756676\n",
      "epoch: 77 loss: 2.291346549987793 grad: 1.6032881241454373\n",
      "epoch: 78 loss: 2.2913618087768555 grad: 1.6081831686195016\n",
      "epoch: 79 loss: 2.290753126144409 grad: 1.5962015805121081\n",
      "epoch: 80 loss: 2.2913458347320557 grad: 1.6299947845187808\n",
      "epoch: 81 loss: 2.291422128677368 grad: 1.5700509444891757\n",
      "epoch: 82 loss: 2.2900586128234863 grad: 1.5719388432150323\n",
      "epoch: 83 loss: 2.2883787155151367 grad: 1.6035829656461755\n",
      "epoch: 84 loss: 2.2899181842803955 grad: 1.5781588278385619\n",
      "epoch: 85 loss: 2.290022850036621 grad: 1.5382862463944578\n",
      "epoch: 86 loss: 2.2871921062469482 grad: 1.6104251953407325\n",
      "epoch: 87 loss: 2.288133144378662 grad: 1.570656941531019\n",
      "epoch: 88 loss: 2.2883825302124023 grad: 1.6184524954481434\n",
      "epoch: 89 loss: 2.28808856010437 grad: 1.5760769931763958\n",
      "epoch: 90 loss: 2.2874162197113037 grad: 1.6119449954167644\n",
      "epoch: 91 loss: 2.2880518436431885 grad: 1.6231378174519964\n",
      "epoch: 92 loss: 2.2852585315704346 grad: 1.6140230121589931\n",
      "epoch: 93 loss: 2.2890260219573975 grad: 1.5854373966484139\n",
      "epoch: 94 loss: 2.2860634326934814 grad: 1.5944934864177382\n",
      "epoch: 95 loss: 2.2865004539489746 grad: 1.595507546503555\n",
      "epoch: 96 loss: 2.284653902053833 grad: 1.6096990884305717\n",
      "epoch: 97 loss: 2.2862017154693604 grad: 1.6522597698975237\n",
      "epoch: 98 loss: 2.2859535217285156 grad: 1.6258691539415084\n",
      "epoch: 99 loss: 2.2845256328582764 grad: 1.6181023282845253\n",
      "epoch: 100 loss: 2.2854437828063965 grad: 1.6510381648586767\n",
      "epoch: 101 loss: 2.2833526134490967 grad: 1.6504640041957683\n",
      "epoch: 102 loss: 2.2842493057250977 grad: 1.6351151225223606\n",
      "epoch: 103 loss: 2.28263258934021 grad: 1.678872178024095\n",
      "epoch: 104 loss: 2.2825722694396973 grad: 1.6849434903420006\n",
      "epoch: 105 loss: 2.283400058746338 grad: 1.6871452722051699\n",
      "epoch: 106 loss: 2.284644365310669 grad: 1.7010302506941593\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 107 loss: 2.282156467437744 grad: 1.7307409766714075\n",
      "epoch: 108 loss: 2.281796455383301 grad: 1.6881404134356195\n",
      "epoch: 109 loss: 2.280975103378296 grad: 1.7051559676626875\n",
      "epoch: 110 loss: 2.2819881439208984 grad: 1.6976692787157224\n",
      "epoch: 111 loss: 2.281802177429199 grad: 1.6995911960571355\n",
      "epoch: 112 loss: 2.2809154987335205 grad: 1.7631010771858402\n",
      "epoch: 113 loss: 2.280963897705078 grad: 1.708673486369662\n",
      "epoch: 114 loss: 2.282022714614868 grad: 1.7285685723181814\n",
      "epoch: 115 loss: 2.2800047397613525 grad: 1.7517535010323164\n",
      "epoch: 116 loss: 2.279864549636841 grad: 1.771867730198354\n",
      "epoch: 117 loss: 2.276031732559204 grad: 1.76761783860136\n",
      "epoch: 118 loss: 2.2769203186035156 grad: 1.7698731038198319\n",
      "epoch: 119 loss: 2.2747857570648193 grad: 1.7761461483795078\n",
      "epoch: 120 loss: 2.2751176357269287 grad: 1.78633335636123\n",
      "epoch: 121 loss: 2.2753100395202637 grad: 1.7964002750259602\n",
      "epoch: 122 loss: 2.2744181156158447 grad: 1.856621198267454\n",
      "epoch: 123 loss: 2.2740628719329834 grad: 1.8626551761990413\n",
      "epoch: 124 loss: 2.2731988430023193 grad: 1.8647470799965844\n",
      "epoch: 125 loss: 2.2731406688690186 grad: 1.8781522668875932\n",
      "epoch: 126 loss: 2.267361640930176 grad: 1.8874532543751041\n",
      "epoch: 127 loss: 2.267796277999878 grad: 1.8592261945965538\n",
      "epoch: 128 loss: 2.2720084190368652 grad: 1.9646166621463461\n",
      "epoch: 129 loss: 2.2688398361206055 grad: 1.977774161102605\n",
      "epoch: 130 loss: 2.267686128616333 grad: 1.969022329957668\n",
      "epoch: 131 loss: 2.2653274536132812 grad: 2.0129457240857715\n",
      "epoch: 132 loss: 2.2639036178588867 grad: 2.0634451931553137\n",
      "epoch: 133 loss: 2.2660701274871826 grad: 2.07355308557661\n",
      "epoch: 134 loss: 2.264291763305664 grad: 2.054092943648039\n",
      "epoch: 135 loss: 2.2629523277282715 grad: 2.066740385155075\n",
      "epoch: 136 loss: 2.2579147815704346 grad: 2.114837749317909\n",
      "epoch: 137 loss: 2.2566568851470947 grad: 2.1784062634392214\n",
      "epoch: 138 loss: 2.255760669708252 grad: 2.233988142104834\n",
      "epoch: 139 loss: 2.25819730758667 grad: 2.266355810938255\n",
      "epoch: 140 loss: 2.254201889038086 grad: 2.261216120598542\n",
      "epoch: 141 loss: 2.2505977153778076 grad: 2.317738299263597\n",
      "epoch: 142 loss: 2.2499120235443115 grad: 2.384385142710045\n",
      "epoch: 143 loss: 2.2516045570373535 grad: 2.33841572167714\n",
      "epoch: 144 loss: 2.2453184127807617 grad: 2.366067121635073\n",
      "epoch: 145 loss: 2.2430419921875 grad: 2.343652431618437\n",
      "epoch: 146 loss: 2.242161989212036 grad: 2.370377243696047\n",
      "epoch: 147 loss: 2.2416489124298096 grad: 2.2736786224136485\n",
      "epoch: 148 loss: 2.24015212059021 grad: 2.2785095043465615\n",
      "epoch: 149 loss: 2.236332654953003 grad: 2.2935482828678295\n",
      "epoch: 150 loss: 2.234752655029297 grad: 2.224592898778307\n",
      "epoch: 151 loss: 2.234184980392456 grad: 2.343604164138909\n",
      "epoch: 152 loss: 2.2330691814422607 grad: 2.1786697091689953\n",
      "epoch: 153 loss: 2.2323009967803955 grad: 2.167866727013865\n",
      "epoch: 154 loss: 2.2323830127716064 grad: 2.1720450579757906\n",
      "epoch: 155 loss: 2.226902723312378 grad: 2.0900485284722574\n",
      "epoch: 156 loss: 2.227722406387329 grad: 2.1749116258440715\n",
      "epoch: 157 loss: 2.2265844345092773 grad: 2.150011147071223\n",
      "epoch: 158 loss: 2.230557441711426 grad: 2.18214739104622\n",
      "epoch: 159 loss: 2.2268314361572266 grad: 2.1001143331661645\n",
      "epoch: 160 loss: 2.2274162769317627 grad: 2.110560622997582\n",
      "epoch: 161 loss: 2.225341796875 grad: 2.136878619057363\n",
      "epoch: 162 loss: 2.2254650592803955 grad: 2.1022099326919053\n",
      "epoch: 163 loss: 2.2256555557250977 grad: 2.1074011283242955\n",
      "epoch: 164 loss: 2.2253310680389404 grad: 2.133372218322216\n",
      "epoch: 165 loss: 2.224445343017578 grad: 2.074730195330515\n",
      "epoch: 166 loss: 2.221940040588379 grad: 2.0968253819737583\n",
      "epoch: 167 loss: 2.2202603816986084 grad: 2.146135727869391\n",
      "epoch: 168 loss: 2.2197353839874268 grad: 2.1388846318799235\n",
      "epoch: 169 loss: 2.223801612854004 grad: 2.1940925108002767\n",
      "epoch: 170 loss: 2.2230987548828125 grad: 2.1508247598041117\n",
      "epoch: 171 loss: 2.2173657417297363 grad: 2.1647828166827647\n",
      "epoch: 172 loss: 2.221128225326538 grad: 2.2304534051541447\n",
      "epoch: 173 loss: 2.2180681228637695 grad: 2.1405387792481285\n",
      "epoch: 174 loss: 2.21604585647583 grad: 2.2430442375434\n",
      "epoch: 175 loss: 2.2148988246917725 grad: 2.193097314806581\n",
      "epoch: 176 loss: 2.214569568634033 grad: 2.3615383026873813\n",
      "epoch: 177 loss: 2.213381052017212 grad: 2.2950234721536704\n",
      "epoch: 178 loss: 2.217801809310913 grad: 2.3295433657790814\n",
      "epoch: 179 loss: 2.2121739387512207 grad: 2.32818044349736\n",
      "epoch: 180 loss: 2.21293306350708 grad: 2.432213480325623\n",
      "epoch: 181 loss: 2.2134644985198975 grad: 2.423487068418162\n",
      "epoch: 182 loss: 2.2143280506134033 grad: 2.375214478355788\n",
      "epoch: 183 loss: 2.211846351623535 grad: 2.483813142865926\n",
      "epoch: 184 loss: 2.2106707096099854 grad: 2.5068824060412775\n",
      "epoch: 185 loss: 2.215489625930786 grad: 2.5722337554925905\n",
      "epoch: 186 loss: 2.2114994525909424 grad: 2.4845739482007625\n",
      "epoch: 187 loss: 2.2104456424713135 grad: 2.3828243043177597\n",
      "epoch: 188 loss: 2.2074360847473145 grad: 2.524889624104761\n",
      "epoch: 189 loss: 2.2079598903656006 grad: 2.582465579742492\n",
      "epoch: 190 loss: 2.2067015171051025 grad: 2.5867980489329923\n",
      "epoch: 191 loss: 2.2075212001800537 grad: 2.7346462306126744\n",
      "epoch: 192 loss: 2.20228910446167 grad: 2.6088234539077217\n",
      "epoch: 193 loss: 2.204622983932495 grad: 2.6577317582125524\n",
      "epoch: 194 loss: 2.202024459838867 grad: 2.6266171719217377\n",
      "epoch: 195 loss: 2.2044432163238525 grad: 2.7903271346715175\n",
      "epoch: 196 loss: 2.202507972717285 grad: 2.715351483463088\n",
      "epoch: 197 loss: 2.2020561695098877 grad: 2.816340534594871\n",
      "epoch: 198 loss: 2.202077865600586 grad: 2.7398585497497745\n",
      "epoch: 199 loss: 2.203219413757324 grad: 2.808242347191221\n",
      "epoch: 200 loss: 2.2023732662200928 grad: 2.863311930204786\n",
      "epoch: 201 loss: 2.1972527503967285 grad: 2.7810123605867996\n",
      "epoch: 202 loss: 2.2003965377807617 grad: 2.8386675845960982\n",
      "epoch: 203 loss: 2.1999263763427734 grad: 2.9650581273793555\n",
      "epoch: 204 loss: 2.194864511489868 grad: 2.859750851694982\n",
      "epoch: 205 loss: 2.1947238445281982 grad: 2.8040164240029832\n",
      "epoch: 206 loss: 2.196431875228882 grad: 3.0098046466065127\n",
      "epoch: 207 loss: 2.196995496749878 grad: 2.975784315164053\n",
      "epoch: 208 loss: 2.1907665729522705 grad: 3.022761194826296\n",
      "epoch: 209 loss: 2.192387104034424 grad: 2.9814495077201477\n",
      "epoch: 210 loss: 2.197291851043701 grad: 3.0363282053971603\n",
      "epoch: 211 loss: 2.1933774948120117 grad: 3.0808074552905818\n",
      "epoch: 212 loss: 2.1924612522125244 grad: 3.10863376539644\n",
      "epoch: 213 loss: 2.18794846534729 grad: 3.1334497999466424\n",
      "epoch: 214 loss: 2.1916515827178955 grad: 3.1206288450094504\n",
      "epoch: 215 loss: 2.1873157024383545 grad: 3.271104372269104\n",
      "epoch: 216 loss: 2.1884572505950928 grad: 3.2764681454005076\n",
      "epoch: 217 loss: 2.191502332687378 grad: 3.3315697508006696\n",
      "epoch: 218 loss: 2.187856912612915 grad: 3.1553516444816654\n",
      "epoch: 219 loss: 2.189340114593506 grad: 3.352969820866184\n",
      "epoch: 220 loss: 2.1902806758880615 grad: 3.1521397993515525\n",
      "epoch: 221 loss: 2.1852598190307617 grad: 3.4100548399553174\n",
      "epoch: 222 loss: 2.1850876808166504 grad: 3.2175835950100526\n",
      "epoch: 223 loss: 2.181912422180176 grad: 3.324865801640535\n",
      "epoch: 224 loss: 2.183518886566162 grad: 3.3781215896818875\n",
      "epoch: 225 loss: 2.1832902431488037 grad: 3.356518538038631\n",
      "epoch: 226 loss: 2.1875009536743164 grad: 3.5085534869567563\n",
      "epoch: 227 loss: 2.182370901107788 grad: 3.4874932496061932\n",
      "epoch: 228 loss: 2.181579113006592 grad: 3.5531411118960627\n",
      "epoch: 229 loss: 2.1759860515594482 grad: 3.4708536211105567\n",
      "epoch: 230 loss: 2.1808435916900635 grad: 3.411534288905502\n",
      "epoch: 231 loss: 2.179241418838501 grad: 3.3923780993957604\n",
      "epoch: 232 loss: 2.1813337802886963 grad: 3.457312651824886\n",
      "epoch: 233 loss: 2.172609806060791 grad: 3.451392712914163\n",
      "epoch: 234 loss: 2.176517963409424 grad: 3.455327212252462\n",
      "epoch: 235 loss: 2.172818422317505 grad: 3.5651877947587756\n",
      "epoch: 236 loss: 2.175058126449585 grad: 3.5695388040631006\n",
      "epoch: 237 loss: 2.178818941116333 grad: 3.715081037964583\n",
      "epoch: 238 loss: 2.1751644611358643 grad: 3.8599412586643465\n",
      "epoch: 239 loss: 2.1766557693481445 grad: 3.788858088080786\n",
      "epoch: 240 loss: 2.1698801517486572 grad: 3.842341258648842\n",
      "epoch: 241 loss: 2.174532413482666 grad: 3.68817666187025\n",
      "epoch: 242 loss: 2.164863109588623 grad: 3.8180655140562783\n",
      "epoch: 243 loss: 2.17008900642395 grad: 3.711500738666112\n",
      "epoch: 244 loss: 2.166698455810547 grad: 3.9350592119079675\n",
      "epoch: 245 loss: 2.1694142818450928 grad: 3.829922361750274\n",
      "epoch: 246 loss: 2.1711301803588867 grad: 3.826489625007121\n",
      "epoch: 247 loss: 2.17327880859375 grad: 3.8429670919043324\n",
      "epoch: 248 loss: 2.169079303741455 grad: 3.7794791693717893\n",
      "epoch: 249 loss: 2.1664161682128906 grad: 3.9058992116830296\n",
      "epoch: 250 loss: 2.1726877689361572 grad: 4.057859707579372\n",
      "epoch: 251 loss: 2.162687301635742 grad: 3.8812587245899652\n",
      "epoch: 252 loss: 2.1671223640441895 grad: 3.671329040375967\n",
      "epoch: 253 loss: 2.1621716022491455 grad: 3.8787617704180617\n",
      "epoch: 254 loss: 2.162858486175537 grad: 4.074654709411016\n",
      "epoch: 255 loss: 2.164538860321045 grad: 3.886749102564026\n",
      "epoch: 256 loss: 2.159832239151001 grad: 3.970381308140026\n",
      "epoch: 257 loss: 2.1623449325561523 grad: 4.050164925511039\n",
      "epoch: 258 loss: 2.1583173274993896 grad: 4.082672048286195\n",
      "epoch: 259 loss: 2.165555477142334 grad: 3.964223052116318\n",
      "epoch: 260 loss: 2.159519910812378 grad: 3.877434499088734\n",
      "epoch: 261 loss: 2.158905506134033 grad: 4.043908083375307\n",
      "epoch: 262 loss: 2.161015272140503 grad: 4.077335309300069\n",
      "epoch: 263 loss: 2.1548502445220947 grad: 4.0044239539697415\n",
      "epoch: 264 loss: 2.159701108932495 grad: 4.108856881591713\n",
      "epoch: 265 loss: 2.1622138023376465 grad: 4.2771394144270625\n",
      "epoch: 266 loss: 2.157175302505493 grad: 4.173558342651213\n",
      "epoch: 267 loss: 2.1571364402770996 grad: 4.157653565555515\n",
      "epoch: 268 loss: 2.157926082611084 grad: 4.106323273671377\n",
      "epoch: 269 loss: 2.1599137783050537 grad: 4.283962779061218\n",
      "epoch: 270 loss: 2.1590282917022705 grad: 4.323044946515149\n",
      "epoch: 271 loss: 2.1537160873413086 grad: 4.207316128496406\n",
      "epoch: 272 loss: 2.156933546066284 grad: 4.180325609177262\n",
      "epoch: 273 loss: 2.1545345783233643 grad: 4.200157298270376\n",
      "epoch: 274 loss: 2.153024673461914 grad: 4.1871577440687116\n",
      "epoch: 275 loss: 2.1574819087982178 grad: 4.346512426200899\n",
      "epoch: 276 loss: 2.151197910308838 grad: 4.461385323285376\n",
      "epoch: 277 loss: 2.153442621231079 grad: 4.499444278821882\n",
      "epoch: 278 loss: 2.155656576156616 grad: 4.394715504752221\n",
      "epoch: 279 loss: 2.1456539630889893 grad: 4.3833516426310535\n",
      "epoch: 280 loss: 2.1538100242614746 grad: 4.48005497298159\n",
      "epoch: 281 loss: 2.1461448669433594 grad: 4.580549481406157\n",
      "epoch: 282 loss: 2.149787187576294 grad: 4.39520943682966\n",
      "epoch: 283 loss: 2.1543734073638916 grad: 4.455386529432698\n",
      "epoch: 284 loss: 2.1449337005615234 grad: 4.397048911497381\n",
      "epoch: 285 loss: 2.146462917327881 grad: 4.594687674756324\n",
      "epoch: 286 loss: 2.1470553874969482 grad: 4.3106914584613625\n",
      "epoch: 287 loss: 2.1486976146698 grad: 4.577260124818643\n",
      "epoch: 288 loss: 2.147325277328491 grad: 4.719311258001697\n",
      "epoch: 289 loss: 2.143583059310913 grad: 4.51520924507049\n",
      "epoch: 290 loss: 2.1488142013549805 grad: 4.67836397793144\n",
      "epoch: 291 loss: 2.14699649810791 grad: 4.650805195789814\n",
      "epoch: 292 loss: 2.150320529937744 grad: 4.731629760156105\n",
      "epoch: 293 loss: 2.1449034214019775 grad: 4.640084962427084\n",
      "epoch: 294 loss: 2.143695831298828 grad: 4.403354347653924\n",
      "epoch: 295 loss: 2.1437268257141113 grad: 4.5214847664844005\n",
      "epoch: 296 loss: 2.1438581943511963 grad: 4.697742350259056\n",
      "epoch: 297 loss: 2.138988733291626 grad: 4.44692004682304\n",
      "epoch: 298 loss: 2.144002914428711 grad: 4.529068545349652\n",
      "epoch: 299 loss: 2.1357030868530273 grad: 4.4185168778908155\n",
      "epoch: 300 loss: 2.1454310417175293 grad: 4.623638123284937\n",
      "epoch: 301 loss: 2.147726535797119 grad: 4.67003759116097\n",
      "epoch: 302 loss: 2.1393585205078125 grad: 4.570352066581743\n",
      "epoch: 303 loss: 2.1349921226501465 grad: 4.57257789754427\n",
      "epoch: 304 loss: 2.1390912532806396 grad: 4.682215685479432\n",
      "epoch: 305 loss: 2.136078119277954 grad: 4.697996510122533\n",
      "epoch: 306 loss: 2.142831563949585 grad: 4.723169124504137\n",
      "epoch: 307 loss: 2.144880533218384 grad: 4.647220656105746\n",
      "epoch: 308 loss: 2.1443686485290527 grad: 4.647569759209301\n",
      "epoch: 309 loss: 2.133477210998535 grad: 4.619902701752763\n",
      "epoch: 310 loss: 2.140003204345703 grad: 4.5916110988492\n",
      "epoch: 311 loss: 2.1378283500671387 grad: 4.680851408638918\n",
      "epoch: 312 loss: 2.1370551586151123 grad: 4.981869287792564\n",
      "epoch: 313 loss: 2.137242317199707 grad: 4.656446688246751\n",
      "epoch: 314 loss: 2.1399009227752686 grad: 4.832822519365609\n",
      "epoch: 315 loss: 2.136849880218506 grad: 5.106534456298317\n",
      "epoch: 316 loss: 2.1355841159820557 grad: 4.767643116617812\n",
      "epoch: 317 loss: 2.131413698196411 grad: 4.63892387915107\n",
      "epoch: 318 loss: 2.136120080947876 grad: 4.700679786592012\n",
      "epoch: 319 loss: 2.1351611614227295 grad: 4.735669472191986\n",
      "epoch: 320 loss: 2.1322007179260254 grad: 4.932759259468949\n",
      "epoch: 321 loss: 2.1370975971221924 grad: 4.77831391675309\n",
      "epoch: 322 loss: 2.1332345008850098 grad: 4.877407515986955\n",
      "epoch: 323 loss: 2.1325936317443848 grad: 4.740588480207537\n",
      "epoch: 324 loss: 2.14070987701416 grad: 5.021699855403442\n",
      "epoch: 325 loss: 2.132956027984619 grad: 4.621112916212056\n",
      "epoch: 326 loss: 2.134042978286743 grad: 5.017510227345315\n",
      "epoch: 327 loss: 2.1338014602661133 grad: 4.894946113542934\n",
      "epoch: 328 loss: 2.1349422931671143 grad: 5.346951922168955\n",
      "epoch: 329 loss: 2.1296744346618652 grad: 4.995647594225519\n",
      "epoch: 330 loss: 2.1302154064178467 grad: 4.862745125567363\n",
      "epoch: 331 loss: 2.130573272705078 grad: 4.7257650413343475\n",
      "epoch: 332 loss: 2.1301462650299072 grad: 5.208631511696334\n",
      "epoch: 333 loss: 2.1285057067871094 grad: 4.921326885321399\n",
      "epoch: 334 loss: 2.1314890384674072 grad: 4.59512561990229\n",
      "epoch: 335 loss: 2.1304221153259277 grad: 4.954218433308784\n",
      "epoch: 336 loss: 2.1267426013946533 grad: 4.897474172946421\n",
      "epoch: 337 loss: 2.1263203620910645 grad: 5.05475022589847\n",
      "epoch: 338 loss: 2.125784397125244 grad: 5.0220125615042415\n",
      "epoch: 339 loss: 2.1218721866607666 grad: 5.052811164516098\n",
      "epoch: 340 loss: 2.12261700630188 grad: 5.2336641607791305\n",
      "epoch: 341 loss: 2.125452995300293 grad: 4.975101273728623\n",
      "epoch: 342 loss: 2.124319314956665 grad: 5.269045881302436\n",
      "epoch: 343 loss: 2.127552032470703 grad: 5.020456376322914\n",
      "epoch: 344 loss: 2.1219875812530518 grad: 5.129094379983606\n",
      "epoch: 345 loss: 2.126980781555176 grad: 5.023691441874862\n",
      "epoch: 346 loss: 2.127702236175537 grad: 5.0371346706598406\n",
      "epoch: 347 loss: 2.131960868835449 grad: 5.3288014459401545\n",
      "epoch: 348 loss: 2.1250081062316895 grad: 5.119264156650012\n",
      "epoch: 349 loss: 2.1201229095458984 grad: 4.8654415532835715\n",
      "epoch: 350 loss: 2.1183414459228516 grad: 4.836266475744427\n",
      "epoch: 351 loss: 2.12461519241333 grad: 4.878463215660304\n",
      "epoch: 352 loss: 2.1229097843170166 grad: 5.146197467247793\n",
      "epoch: 353 loss: 2.119135856628418 grad: 5.4008108540696815\n",
      "epoch: 354 loss: 2.117489814758301 grad: 5.040480619063601\n",
      "epoch: 355 loss: 2.122645616531372 grad: 5.103755652845379\n",
      "epoch: 356 loss: 2.123044729232788 grad: 5.294135794032454\n",
      "epoch: 357 loss: 2.120009660720825 grad: 4.8581474849119015\n",
      "epoch: 358 loss: 2.123448133468628 grad: 5.189421775115151\n",
      "epoch: 359 loss: 2.1158816814422607 grad: 4.97069265016739\n",
      "epoch: 360 loss: 2.119079828262329 grad: 5.330857318870368\n",
      "epoch: 361 loss: 2.114960193634033 grad: 5.118723553087976\n",
      "epoch: 362 loss: 2.121000051498413 grad: 5.35913393668653\n",
      "epoch: 363 loss: 2.1152291297912598 grad: 5.07914756350441\n",
      "epoch: 364 loss: 2.1164562702178955 grad: 5.193226361203761\n",
      "epoch: 365 loss: 2.1173932552337646 grad: 4.9792883570512965\n",
      "epoch: 366 loss: 2.1219451427459717 grad: 5.391654049548956\n",
      "epoch: 367 loss: 2.1153903007507324 grad: 5.341723632407448\n",
      "epoch: 368 loss: 2.120518684387207 grad: 5.178165246030345\n",
      "epoch: 369 loss: 2.1186139583587646 grad: 5.09097550822688\n",
      "epoch: 370 loss: 2.1189510822296143 grad: 5.227576037329282\n",
      "epoch: 371 loss: 2.1194465160369873 grad: 5.007246291516201\n",
      "epoch: 372 loss: 2.119453191757202 grad: 5.235356761844799\n",
      "epoch: 373 loss: 2.1135456562042236 grad: 5.362751152044872\n",
      "epoch: 374 loss: 2.1178576946258545 grad: 5.351937927120912\n",
      "epoch: 375 loss: 2.11338472366333 grad: 4.989098427455044\n",
      "epoch: 376 loss: 2.1137900352478027 grad: 5.347522133081737\n",
      "epoch: 377 loss: 2.1103227138519287 grad: 4.971883985018062\n",
      "epoch: 378 loss: 2.1147847175598145 grad: 5.3474140466479145\n",
      "epoch: 379 loss: 2.115429639816284 grad: 5.322396487932623\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 380 loss: 2.108213186264038 grad: 5.275106404471906\n",
      "epoch: 381 loss: 2.1151394844055176 grad: 5.295463833263114\n",
      "epoch: 382 loss: 2.1061201095581055 grad: 5.42058516841101\n",
      "epoch: 383 loss: 2.116708755493164 grad: 5.400335308463712\n",
      "epoch: 384 loss: 2.110908031463623 grad: 5.289098444132371\n",
      "epoch: 385 loss: 2.110567808151245 grad: 5.405048102339996\n",
      "epoch: 386 loss: 2.113759756088257 grad: 5.377907121631627\n",
      "epoch: 387 loss: 2.105419635772705 grad: 5.250546130776731\n",
      "epoch: 388 loss: 2.1073474884033203 grad: 5.202095553751976\n",
      "epoch: 389 loss: 2.1060259342193604 grad: 5.098947090081989\n",
      "epoch: 390 loss: 2.1145741939544678 grad: 5.2683470715576455\n",
      "epoch: 391 loss: 2.110553026199341 grad: 5.669603808916041\n",
      "epoch: 392 loss: 2.10847544670105 grad: 5.060256898950135\n",
      "epoch: 393 loss: 2.1050145626068115 grad: 5.433130436780168\n",
      "epoch: 394 loss: 2.111546039581299 grad: 5.552307676106307\n",
      "epoch: 395 loss: 2.1063005924224854 grad: 5.407697141370071\n",
      "epoch: 396 loss: 2.107489585876465 grad: 5.369982576212062\n",
      "epoch: 397 loss: 2.1027779579162598 grad: 5.459416127161285\n",
      "epoch: 398 loss: 2.1046130657196045 grad: 5.6036428717955475\n",
      "epoch: 399 loss: 2.1050844192504883 grad: 5.460545021109283\n",
      "epoch: 400 loss: 2.106140613555908 grad: 5.537336346545508\n",
      "epoch: 401 loss: 2.1058287620544434 grad: 5.4781003542436615\n",
      "epoch: 402 loss: 2.105259656906128 grad: 5.8157371001628535\n",
      "epoch: 403 loss: 2.1045055389404297 grad: 5.430563666702558\n",
      "epoch: 404 loss: 2.1066336631774902 grad: 5.664429990578413\n",
      "epoch: 405 loss: 2.1046767234802246 grad: 5.235157138520171\n",
      "epoch: 406 loss: 2.1036252975463867 grad: 5.784418002968388\n",
      "epoch: 407 loss: 2.1068077087402344 grad: 5.306438557981026\n",
      "epoch: 408 loss: 2.1089975833892822 grad: 6.172414718606022\n",
      "epoch: 409 loss: 2.1052134037017822 grad: 5.348261320072832\n",
      "epoch: 410 loss: 2.0989010334014893 grad: 5.142632135404422\n",
      "epoch: 411 loss: 2.105058431625366 grad: 5.33527214129618\n",
      "epoch: 412 loss: 2.1074368953704834 grad: 5.745069658923303\n",
      "epoch: 413 loss: 2.105281352996826 grad: 5.718180568515515\n",
      "epoch: 414 loss: 2.105058193206787 grad: 5.876420102274371\n",
      "epoch: 415 loss: 2.100071430206299 grad: 5.541016598084261\n",
      "epoch: 416 loss: 2.101611375808716 grad: 5.422774948726689\n",
      "epoch: 417 loss: 2.097217082977295 grad: 5.695653467941733\n",
      "epoch: 418 loss: 2.1014609336853027 grad: 5.730690966175485\n",
      "epoch: 419 loss: 2.09887957572937 grad: 5.723768976590936\n",
      "epoch: 420 loss: 2.10191011428833 grad: 5.421448933374551\n",
      "epoch: 421 loss: 2.0974109172821045 grad: 5.598121668892129\n",
      "epoch: 422 loss: 2.1065127849578857 grad: 5.891749712372465\n",
      "epoch: 423 loss: 2.0961709022521973 grad: 5.695759946971925\n",
      "epoch: 424 loss: 2.1016502380371094 grad: 5.85112284324945\n",
      "epoch: 425 loss: 2.099707841873169 grad: 6.028850359790441\n",
      "epoch: 426 loss: 2.1009304523468018 grad: 6.019095585326708\n",
      "epoch: 427 loss: 2.092895030975342 grad: 5.800331551892062\n",
      "epoch: 428 loss: 2.0961754322052 grad: 6.114918372231639\n",
      "epoch: 429 loss: 2.101529121398926 grad: 5.722546014602163\n",
      "epoch: 430 loss: 2.1007273197174072 grad: 5.361086473238492\n",
      "epoch: 431 loss: 2.1028950214385986 grad: 5.995116348141834\n",
      "epoch: 432 loss: 2.0979039669036865 grad: 5.659767738269967\n",
      "epoch: 433 loss: 2.09323787689209 grad: 5.624996190554359\n",
      "epoch: 434 loss: 2.097517728805542 grad: 5.973588651386163\n",
      "epoch: 435 loss: 2.0950677394866943 grad: 5.555702177685729\n",
      "epoch: 436 loss: 2.093005895614624 grad: 5.767774155481704\n",
      "epoch: 437 loss: 2.094688653945923 grad: 5.512994104874364\n",
      "epoch: 438 loss: 2.090801954269409 grad: 5.674607727558366\n",
      "epoch: 439 loss: 2.0932741165161133 grad: 5.831170392828802\n",
      "epoch: 440 loss: 2.08836030960083 grad: 5.527045304310464\n",
      "epoch: 441 loss: 2.0922322273254395 grad: 5.709747041893443\n",
      "epoch: 442 loss: 2.0941312313079834 grad: 5.89476333893392\n",
      "epoch: 443 loss: 2.096060276031494 grad: 5.897280892985504\n",
      "epoch: 444 loss: 2.096911907196045 grad: 5.716416978439878\n",
      "epoch: 445 loss: 2.0903916358947754 grad: 5.717259685989351\n",
      "epoch: 446 loss: 2.0969762802124023 grad: 6.245708237538883\n",
      "epoch: 447 loss: 2.0911309719085693 grad: 5.819353071599459\n",
      "epoch: 448 loss: 2.0972394943237305 grad: 5.9005969045462\n",
      "epoch: 449 loss: 2.0917675495147705 grad: 6.032462398310946\n",
      "epoch: 450 loss: 2.0877082347869873 grad: 5.592835274524987\n",
      "epoch: 451 loss: 2.090756416320801 grad: 5.903458264970501\n",
      "epoch: 452 loss: 2.092848777770996 grad: 6.0843562914043785\n",
      "epoch: 453 loss: 2.0927932262420654 grad: 6.515707328752984\n",
      "epoch: 454 loss: 2.0924746990203857 grad: 6.037997676998318\n",
      "epoch: 455 loss: 2.085294246673584 grad: 5.9888028017548285\n",
      "epoch: 456 loss: 2.0979654788970947 grad: 5.82363224743555\n",
      "epoch: 457 loss: 2.094447612762451 grad: 5.865088839268696\n",
      "epoch: 458 loss: 2.0906996726989746 grad: 5.764422409509915\n",
      "epoch: 459 loss: 2.0910825729370117 grad: 5.83419980649792\n",
      "epoch: 460 loss: 2.090823173522949 grad: 6.057665887222226\n",
      "epoch: 461 loss: 2.0865795612335205 grad: 5.679897797101783\n",
      "epoch: 462 loss: 2.084573984146118 grad: 5.746744823390766\n",
      "epoch: 463 loss: 2.082144021987915 grad: 6.067278596587361\n",
      "epoch: 464 loss: 2.08239483833313 grad: 6.039409148410732\n",
      "epoch: 465 loss: 2.087810754776001 grad: 5.720399955272793\n",
      "epoch: 466 loss: 2.0924651622772217 grad: 6.170789293848747\n",
      "epoch: 467 loss: 2.085141181945801 grad: 6.000265280804818\n",
      "epoch: 468 loss: 2.086744546890259 grad: 6.10590181073233\n",
      "epoch: 469 loss: 2.0885767936706543 grad: 6.116056305311975\n",
      "epoch: 470 loss: 2.0871469974517822 grad: 6.126355036062056\n",
      "epoch: 471 loss: 2.075352191925049 grad: 6.063079124516142\n",
      "epoch: 472 loss: 2.084038257598877 grad: 6.294352401824047\n",
      "epoch: 473 loss: 2.087913751602173 grad: 6.238162238232141\n",
      "epoch: 474 loss: 2.080725908279419 grad: 6.119263741734718\n",
      "epoch: 475 loss: 2.0819342136383057 grad: 6.419136513970674\n",
      "epoch: 476 loss: 2.081179618835449 grad: 6.290149488508524\n",
      "epoch: 477 loss: 2.077294111251831 grad: 6.2666903526285695\n",
      "epoch: 478 loss: 2.0834221839904785 grad: 5.747544824005296\n",
      "epoch: 479 loss: 2.0828988552093506 grad: 6.206970059845064\n",
      "epoch: 480 loss: 2.0856032371520996 grad: 6.391239453506257\n",
      "epoch: 481 loss: 2.07865834236145 grad: 6.434405650876995\n",
      "epoch: 482 loss: 2.082029342651367 grad: 6.7049755883173985\n",
      "epoch: 483 loss: 2.0922751426696777 grad: 6.686723298001443\n",
      "epoch: 484 loss: 2.084319591522217 grad: 6.548544671696921\n",
      "epoch: 485 loss: 2.087106466293335 grad: 6.232074630025419\n",
      "epoch: 486 loss: 2.083237409591675 grad: 6.408244390218031\n",
      "epoch: 487 loss: 2.0798287391662598 grad: 6.136151214987631\n",
      "epoch: 488 loss: 2.0740249156951904 grad: 6.836228108218324\n",
      "epoch: 489 loss: 2.0833895206451416 grad: 6.154429916617652\n",
      "epoch: 490 loss: 2.079399824142456 grad: 6.421431208413745\n",
      "epoch: 491 loss: 2.0774765014648438 grad: 5.9751856493586235\n",
      "epoch: 492 loss: 2.0778403282165527 grad: 6.38131030747253\n",
      "epoch: 493 loss: 2.078146457672119 grad: 6.375159487926534\n",
      "epoch: 494 loss: 2.0763909816741943 grad: 6.166280365172064\n",
      "epoch: 495 loss: 2.075582981109619 grad: 6.659490824130083\n",
      "epoch: 496 loss: 2.077866554260254 grad: 6.481897276560111\n",
      "epoch: 497 loss: 2.0677616596221924 grad: 6.175442661084826\n",
      "epoch: 498 loss: 2.0690836906433105 grad: 6.488904728088528\n",
      "epoch: 499 loss: 2.081019401550293 grad: 6.3520320165340625\n",
      "2.2049312442541122\n",
      "epoch: 0 loss: 2.305094003677368 grad: 0.9876017662399035\n",
      "epoch: 1 loss: 2.3023693561553955 grad: 0.8879514237263403\n",
      "epoch: 2 loss: 2.290952205657959 grad: 1.144972581060193\n",
      "epoch: 3 loss: 2.2595481872558594 grad: 1.5341508857095578\n",
      "epoch: 4 loss: 2.210477828979492 grad: 1.9291408481542944\n",
      "epoch: 5 loss: 2.1786916255950928 grad: 2.191831673070463\n",
      "epoch: 6 loss: 2.1474406719207764 grad: 2.8691821286264467\n",
      "epoch: 7 loss: 2.1163811683654785 grad: 2.9812118370364984\n",
      "epoch: 8 loss: 2.1035101413726807 grad: 3.8337451896356742\n",
      "epoch: 9 loss: 2.075920343399048 grad: 3.909348790451611\n",
      "epoch: 10 loss: 2.045238971710205 grad: 4.81105590058862\n",
      "epoch: 11 loss: 2.023674964904785 grad: 5.255949214086979\n",
      "epoch: 12 loss: 2.0025243759155273 grad: 5.0614862917018835\n",
      "epoch: 13 loss: 1.9978210926055908 grad: 5.072004610354761\n",
      "epoch: 14 loss: 1.9823075532913208 grad: 5.54391559569021\n",
      "epoch: 15 loss: 1.9752284288406372 grad: 5.343705528847216\n",
      "epoch: 16 loss: 1.9823765754699707 grad: 5.713251017483547\n",
      "epoch: 17 loss: 1.9611161947250366 grad: 5.681557891860379\n",
      "epoch: 18 loss: 1.9657691717147827 grad: 5.912022049273623\n",
      "epoch: 19 loss: 1.9514609575271606 grad: 5.766817831722576\n",
      "epoch: 20 loss: 1.9444385766983032 grad: 5.377609384977462\n",
      "epoch: 21 loss: 1.9355671405792236 grad: 5.163628857486719\n",
      "epoch: 22 loss: 1.9258629083633423 grad: 5.287863078515142\n",
      "epoch: 23 loss: 1.9345439672470093 grad: 5.317953219181315\n",
      "epoch: 24 loss: 1.9363775253295898 grad: 5.6216581722574555\n",
      "epoch: 25 loss: 1.922066569328308 grad: 5.200027849577646\n",
      "epoch: 26 loss: 1.9215610027313232 grad: 5.527655154481412\n",
      "epoch: 27 loss: 1.9233728647232056 grad: 5.125431295082626\n",
      "epoch: 28 loss: 1.8969496488571167 grad: 5.363051354524306\n",
      "epoch: 29 loss: 1.908132791519165 grad: 5.605173022375166\n",
      "epoch: 30 loss: 1.908233880996704 grad: 5.787955087841958\n",
      "epoch: 31 loss: 1.9088828563690186 grad: 5.839368372194013\n",
      "epoch: 32 loss: 1.9074209928512573 grad: 5.709880942498872\n",
      "epoch: 33 loss: 1.9081978797912598 grad: 5.619638098940384\n",
      "epoch: 34 loss: 1.9035145044326782 grad: 5.002450036772643\n",
      "epoch: 35 loss: 1.9062910079956055 grad: 5.357558078269658\n",
      "epoch: 36 loss: 1.8990681171417236 grad: 5.130542164295635\n",
      "epoch: 37 loss: 1.903010368347168 grad: 5.843778411630959\n",
      "epoch: 38 loss: 1.9088085889816284 grad: 5.7178840456814095\n",
      "epoch: 39 loss: 1.8923004865646362 grad: 5.832283757905113\n",
      "epoch: 40 loss: 1.896364688873291 grad: 6.177536731563686\n",
      "epoch: 41 loss: 1.8799623250961304 grad: 5.414727539726762\n",
      "epoch: 42 loss: 1.9152568578720093 grad: 6.789731157699689\n",
      "epoch: 43 loss: 1.892109751701355 grad: 6.179419856120755\n",
      "epoch: 44 loss: 1.89437735080719 grad: 5.9824976556235\n",
      "epoch: 45 loss: 1.8951715230941772 grad: 5.5651193538318955\n",
      "epoch: 46 loss: 1.8834731578826904 grad: 5.823890946027758\n",
      "epoch: 47 loss: 1.8815537691116333 grad: 6.187754429021937\n",
      "epoch: 48 loss: 1.9013320207595825 grad: 5.5714204139300225\n",
      "epoch: 49 loss: 1.8832275867462158 grad: 5.169172966227745\n",
      "epoch: 50 loss: 1.879577398300171 grad: 6.020336721976665\n",
      "epoch: 51 loss: 1.8844088315963745 grad: 5.411984267178923\n",
      "epoch: 52 loss: 1.871581792831421 grad: 5.373465584327942\n",
      "epoch: 53 loss: 1.8704442977905273 grad: 5.854303956114953\n",
      "epoch: 54 loss: 1.8812345266342163 grad: 5.819691060241663\n",
      "epoch: 55 loss: 1.8711769580841064 grad: 5.517972653849043\n",
      "epoch: 56 loss: 1.8726956844329834 grad: 5.715838377562163\n",
      "epoch: 57 loss: 1.878203272819519 grad: 5.494964334752045\n",
      "epoch: 58 loss: 1.864315390586853 grad: 5.1631642750739015\n",
      "epoch: 59 loss: 1.870548129081726 grad: 5.8039353922527335\n",
      "epoch: 60 loss: 1.8701153993606567 grad: 5.8925330409344046\n",
      "epoch: 61 loss: 1.8808739185333252 grad: 6.060128809393814\n",
      "epoch: 62 loss: 1.8686575889587402 grad: 5.643673625564487\n",
      "epoch: 63 loss: 1.8661936521530151 grad: 5.518713284578264\n",
      "epoch: 64 loss: 1.869778037071228 grad: 5.3197528974941095\n",
      "epoch: 65 loss: 1.8555513620376587 grad: 5.475110810524798\n",
      "epoch: 66 loss: 1.855463981628418 grad: 6.2064610473764965\n",
      "epoch: 67 loss: 1.8683600425720215 grad: 5.052980492948076\n",
      "epoch: 68 loss: 1.8685555458068848 grad: 5.838589352311886\n",
      "epoch: 69 loss: 1.8804162740707397 grad: 5.431656045092654\n",
      "epoch: 70 loss: 1.8740613460540771 grad: 6.16335373941905\n",
      "epoch: 71 loss: 1.861765742301941 grad: 5.830615290141266\n",
      "epoch: 72 loss: 1.8623020648956299 grad: 5.255269117666998\n",
      "epoch: 73 loss: 1.845185399055481 grad: 5.3919743036217005\n",
      "epoch: 74 loss: 1.8480980396270752 grad: 4.937447652757068\n",
      "epoch: 75 loss: 1.8406853675842285 grad: 5.258493073814732\n",
      "epoch: 76 loss: 1.8677877187728882 grad: 5.4635659075272365\n",
      "epoch: 77 loss: 1.856339454650879 grad: 5.411341671955828\n",
      "epoch: 78 loss: 1.8448699712753296 grad: 4.5808305245726455\n",
      "epoch: 79 loss: 1.8475297689437866 grad: 5.438743159691281\n",
      "epoch: 80 loss: 1.8558788299560547 grad: 6.503313964548787\n",
      "epoch: 81 loss: 1.8588292598724365 grad: 5.463515545459929\n",
      "epoch: 82 loss: 1.8507884740829468 grad: 5.551807438197145\n",
      "epoch: 83 loss: 1.844886302947998 grad: 5.1574609304109815\n",
      "epoch: 84 loss: 1.8611098527908325 grad: 5.815241015276461\n",
      "epoch: 85 loss: 1.856869101524353 grad: 5.5440445191657455\n",
      "epoch: 86 loss: 1.8651652336120605 grad: 5.261453665879792\n",
      "epoch: 87 loss: 1.8564562797546387 grad: 5.594594062856419\n",
      "epoch: 88 loss: 1.8346036672592163 grad: 5.589919178341035\n",
      "epoch: 89 loss: 1.8329797983169556 grad: 5.213497416163071\n",
      "epoch: 90 loss: 1.8345471620559692 grad: 4.700056405387249\n",
      "epoch: 91 loss: 1.8407522439956665 grad: 5.97087567574035\n",
      "epoch: 92 loss: 1.8666640520095825 grad: 5.155422402579129\n",
      "epoch: 93 loss: 1.8666918277740479 grad: 7.416097095977868\n",
      "epoch: 94 loss: 1.8775438070297241 grad: 5.359627472852668\n",
      "epoch: 95 loss: 1.8461358547210693 grad: 4.837586114803026\n",
      "epoch: 96 loss: 1.8421854972839355 grad: 5.224049207383475\n",
      "epoch: 97 loss: 1.8512636423110962 grad: 5.781909383847787\n",
      "epoch: 98 loss: 1.851285457611084 grad: 5.0924972678640765\n",
      "epoch: 99 loss: 1.8366867303848267 grad: 5.038728745202539\n",
      "epoch: 100 loss: 1.8488273620605469 grad: 6.565410395457302\n",
      "epoch: 101 loss: 1.8370298147201538 grad: 5.115574797439978\n",
      "epoch: 102 loss: 1.8191173076629639 grad: 4.878047732220217\n",
      "epoch: 103 loss: 1.8420931100845337 grad: 4.932676371195518\n",
      "epoch: 104 loss: 1.8528242111206055 grad: 5.334461441060118\n",
      "epoch: 105 loss: 1.8532994985580444 grad: 5.875233146755486\n",
      "epoch: 106 loss: 1.8349604606628418 grad: 5.209501351190002\n",
      "epoch: 107 loss: 1.8171899318695068 grad: 5.072360003116392\n",
      "epoch: 108 loss: 1.8603345155715942 grad: 5.757534438151832\n",
      "epoch: 109 loss: 1.8498692512512207 grad: 6.193523447895016\n",
      "epoch: 110 loss: 1.8458173274993896 grad: 6.5012947372017065\n",
      "epoch: 111 loss: 1.8248604536056519 grad: 5.189408165556776\n",
      "epoch: 112 loss: 1.8350813388824463 grad: 4.534399049399196\n",
      "epoch: 113 loss: 1.8248281478881836 grad: 4.301627980652454\n",
      "epoch: 114 loss: 1.8412171602249146 grad: 6.429612641163182\n",
      "epoch: 115 loss: 1.845094084739685 grad: 5.218047030217436\n",
      "epoch: 116 loss: 1.8148109912872314 grad: 4.967667193333563\n",
      "epoch: 117 loss: 1.830505609512329 grad: 5.810937919339816\n",
      "epoch: 118 loss: 1.8444125652313232 grad: 6.261554057612744\n",
      "epoch: 119 loss: 1.8346024751663208 grad: 5.240385053560391\n",
      "epoch: 120 loss: 1.8246269226074219 grad: 5.200372516869157\n",
      "epoch: 121 loss: 1.8214023113250732 grad: 5.125501430878002\n",
      "epoch: 122 loss: 1.8364967107772827 grad: 4.857689279436258\n",
      "epoch: 123 loss: 1.8278290033340454 grad: 5.892149012188181\n",
      "epoch: 124 loss: 1.8248029947280884 grad: 5.006806477170487\n",
      "epoch: 125 loss: 1.8307843208312988 grad: 5.537495451654116\n",
      "epoch: 126 loss: 1.8316246271133423 grad: 5.768087358798348\n",
      "epoch: 127 loss: 1.8276087045669556 grad: 5.3567339290031875\n",
      "epoch: 128 loss: 1.8449574708938599 grad: 6.280728334784119\n",
      "epoch: 129 loss: 1.846334457397461 grad: 6.146891826451229\n",
      "epoch: 130 loss: 1.8371120691299438 grad: 4.933961615470282\n",
      "epoch: 131 loss: 1.8293486833572388 grad: 4.926294660748566\n",
      "epoch: 132 loss: 1.815635323524475 grad: 5.710542643375072\n",
      "epoch: 133 loss: 1.8234636783599854 grad: 4.895226511335505\n",
      "epoch: 134 loss: 1.8280411958694458 grad: 4.979838845930534\n",
      "epoch: 135 loss: 1.8363456726074219 grad: 5.333586384254136\n",
      "epoch: 136 loss: 1.8294517993927002 grad: 5.270024851527798\n",
      "epoch: 137 loss: 1.8139684200286865 grad: 5.337816888649185\n",
      "epoch: 138 loss: 1.8352265357971191 grad: 5.579097993671779\n",
      "epoch: 139 loss: 1.8414806127548218 grad: 5.48928439949931\n",
      "epoch: 140 loss: 1.8273011445999146 grad: 5.762878271452012\n",
      "epoch: 141 loss: 1.8257744312286377 grad: 5.4637209219604665\n",
      "epoch: 142 loss: 1.812649130821228 grad: 5.1492273554516625\n",
      "epoch: 143 loss: 1.8327902555465698 grad: 5.439011543085462\n",
      "epoch: 144 loss: 1.822744607925415 grad: 4.806186252347014\n",
      "epoch: 145 loss: 1.8138210773468018 grad: 5.043581545152818\n",
      "epoch: 146 loss: 1.8142294883728027 grad: 5.023366013366733\n",
      "epoch: 147 loss: 1.8231828212738037 grad: 5.808924858333841\n",
      "epoch: 148 loss: 1.8224103450775146 grad: 6.027416243967309\n",
      "epoch: 149 loss: 1.81686532497406 grad: 6.2324367013404425\n",
      "epoch: 150 loss: 1.8169291019439697 grad: 4.997667057695296\n",
      "epoch: 151 loss: 1.8332513570785522 grad: 5.9470677792343185\n",
      "epoch: 152 loss: 1.8131614923477173 grad: 4.868142390574952\n",
      "epoch: 153 loss: 1.8209354877471924 grad: 4.801257116616022\n",
      "epoch: 154 loss: 1.8167972564697266 grad: 5.783115122026449\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 155 loss: 1.8292206525802612 grad: 5.8566835774314345\n",
      "epoch: 156 loss: 1.815913200378418 grad: 4.841464115246044\n",
      "epoch: 157 loss: 1.824156403541565 grad: 5.351833710807605\n",
      "epoch: 158 loss: 1.8416132926940918 grad: 5.383869456364274\n",
      "epoch: 159 loss: 1.823651671409607 grad: 4.882256068821464\n",
      "epoch: 160 loss: 1.8210194110870361 grad: 5.778266054922637\n",
      "epoch: 161 loss: 1.8188848495483398 grad: 5.106222418368599\n",
      "epoch: 162 loss: 1.8007698059082031 grad: 5.883664026330042\n",
      "epoch: 163 loss: 1.8095463514328003 grad: 5.466898241636781\n",
      "epoch: 164 loss: 1.807104229927063 grad: 4.612093660803906\n",
      "epoch: 165 loss: 1.8036599159240723 grad: 5.569531753688641\n",
      "epoch: 166 loss: 1.8196121454238892 grad: 4.394085671153002\n",
      "epoch: 167 loss: 1.817996621131897 grad: 5.744912075234064\n",
      "epoch: 168 loss: 1.816555380821228 grad: 6.131788113061615\n",
      "epoch: 169 loss: 1.80809485912323 grad: 5.530536409679847\n",
      "epoch: 170 loss: 1.8118014335632324 grad: 5.510910943080302\n",
      "epoch: 171 loss: 1.8168104887008667 grad: 5.236762157627492\n",
      "epoch: 172 loss: 1.809680700302124 grad: 5.228365357541088\n",
      "epoch: 173 loss: 1.8231018781661987 grad: 5.3731469187147765\n",
      "epoch: 174 loss: 1.809431791305542 grad: 5.61674221130081\n",
      "epoch: 175 loss: 1.8251346349716187 grad: 5.372030405793108\n",
      "epoch: 176 loss: 1.8127663135528564 grad: 4.953418385574575\n",
      "epoch: 177 loss: 1.8162354230880737 grad: 5.923741540120289\n",
      "epoch: 178 loss: 1.8142813444137573 grad: 4.830078909913907\n",
      "epoch: 179 loss: 1.8110815286636353 grad: 5.661902822799762\n",
      "epoch: 180 loss: 1.817922830581665 grad: 5.1616357543703595\n",
      "epoch: 181 loss: 1.8070143461227417 grad: 5.103898576505575\n",
      "epoch: 182 loss: 1.8177251815795898 grad: 6.256578913798508\n",
      "epoch: 183 loss: 1.8186228275299072 grad: 5.325310160710947\n",
      "epoch: 184 loss: 1.8141930103302002 grad: 5.429944685553589\n",
      "epoch: 185 loss: 1.8117879629135132 grad: 5.660225960812062\n",
      "epoch: 186 loss: 1.8208125829696655 grad: 4.358351036389707\n",
      "epoch: 187 loss: 1.8112008571624756 grad: 6.3879439329742285\n",
      "epoch: 188 loss: 1.8133755922317505 grad: 6.026256787106081\n",
      "epoch: 189 loss: 1.807268500328064 grad: 5.179567562654454\n",
      "epoch: 190 loss: 1.8095848560333252 grad: 5.417689762961619\n",
      "epoch: 191 loss: 1.8103361129760742 grad: 6.1794428361250855\n",
      "epoch: 192 loss: 1.814889669418335 grad: 5.081656210588653\n",
      "epoch: 193 loss: 1.8093602657318115 grad: 5.053925712251103\n",
      "epoch: 194 loss: 1.793637752532959 grad: 5.839701906938682\n",
      "epoch: 195 loss: 1.8206826448440552 grad: 5.112445036011599\n",
      "epoch: 196 loss: 1.815167784690857 grad: 4.857362835298628\n",
      "epoch: 197 loss: 1.8094332218170166 grad: 4.702720030588338\n",
      "epoch: 198 loss: 1.8008681535720825 grad: 5.698545892948171\n",
      "epoch: 199 loss: 1.8256702423095703 grad: 4.911962304905746\n",
      "epoch: 200 loss: 1.816362738609314 grad: 5.055707703758792\n",
      "epoch: 201 loss: 1.8075569868087769 grad: 5.197072940627448\n",
      "epoch: 202 loss: 1.7976897954940796 grad: 4.530069067220283\n",
      "epoch: 203 loss: 1.8082964420318604 grad: 4.1976390741057825\n",
      "epoch: 204 loss: 1.8295410871505737 grad: 5.557393991591476\n",
      "epoch: 205 loss: 1.8140901327133179 grad: 5.301251234878966\n",
      "epoch: 206 loss: 1.8138891458511353 grad: 4.801210391100078\n",
      "epoch: 207 loss: 1.8079862594604492 grad: 4.792836517944774\n",
      "epoch: 208 loss: 1.7898060083389282 grad: 5.109855898801759\n",
      "epoch: 209 loss: 1.8256474733352661 grad: 4.500333965509078\n",
      "epoch: 210 loss: 1.8072668313980103 grad: 4.451045393120911\n",
      "epoch: 211 loss: 1.795762062072754 grad: 4.88528710456897\n",
      "epoch: 212 loss: 1.8230681419372559 grad: 5.519611526440294\n",
      "epoch: 213 loss: 1.7926161289215088 grad: 5.438518204862327\n",
      "epoch: 214 loss: 1.806065320968628 grad: 4.597029721648719\n",
      "epoch: 215 loss: 1.7984126806259155 grad: 5.590967894060062\n",
      "epoch: 216 loss: 1.7983535528182983 grad: 5.896168679439258\n",
      "epoch: 217 loss: 1.8009240627288818 grad: 5.6808649958278234\n",
      "epoch: 218 loss: 1.8088595867156982 grad: 5.994231591132438\n",
      "epoch: 219 loss: 1.8248577117919922 grad: 5.347614467964926\n",
      "epoch: 220 loss: 1.803916573524475 grad: 5.723621880022013\n",
      "epoch: 221 loss: 1.8206723928451538 grad: 4.57642809620999\n",
      "epoch: 222 loss: 1.8055585622787476 grad: 4.1100678834563515\n",
      "epoch: 223 loss: 1.8043863773345947 grad: 5.231537442265368\n",
      "epoch: 224 loss: 1.8041449785232544 grad: 5.450974016319378\n",
      "epoch: 225 loss: 1.7957606315612793 grad: 5.586156543153641\n",
      "epoch: 226 loss: 1.8088972568511963 grad: 5.3196854187896125\n",
      "epoch: 227 loss: 1.823327898979187 grad: 6.023032788242211\n",
      "epoch: 228 loss: 1.8234113454818726 grad: 6.419905145185199\n",
      "epoch: 229 loss: 1.8188936710357666 grad: 6.069032731520276\n",
      "epoch: 230 loss: 1.8138415813446045 grad: 5.563669566714207\n",
      "epoch: 231 loss: 1.808974266052246 grad: 5.376041180447669\n",
      "epoch: 232 loss: 1.8010666370391846 grad: 5.7440882541671145\n",
      "epoch: 233 loss: 1.801901936531067 grad: 6.814209874809147\n",
      "epoch: 234 loss: 1.8016388416290283 grad: 5.110435256743846\n",
      "epoch: 235 loss: 1.80132257938385 grad: 5.756194373842254\n",
      "epoch: 236 loss: 1.8016445636749268 grad: 5.863395339065247\n",
      "epoch: 237 loss: 1.8048899173736572 grad: 6.488516868283951\n",
      "epoch: 238 loss: 1.7927719354629517 grad: 5.309855287689725\n",
      "epoch: 239 loss: 1.7970691919326782 grad: 5.027670778328276\n",
      "epoch: 240 loss: 1.7873122692108154 grad: 5.88482470442046\n",
      "epoch: 241 loss: 1.7914435863494873 grad: 6.894624347647984\n",
      "epoch: 242 loss: 1.8058074712753296 grad: 5.335042256076757\n",
      "epoch: 243 loss: 1.798323392868042 grad: 5.279020134908009\n",
      "epoch: 244 loss: 1.7865533828735352 grad: 4.844202556876033\n",
      "epoch: 245 loss: 1.7823861837387085 grad: 5.252670262010406\n",
      "epoch: 246 loss: 1.7803871631622314 grad: 6.493668280408215\n",
      "epoch: 247 loss: 1.7857568264007568 grad: 5.4447982083227195\n",
      "epoch: 248 loss: 1.7798882722854614 grad: 5.376668699682918\n",
      "epoch: 249 loss: 1.784709095954895 grad: 5.411689071322245\n",
      "epoch: 250 loss: 1.7895214557647705 grad: 6.40628898018027\n",
      "epoch: 251 loss: 1.7774957418441772 grad: 5.76090591747717\n",
      "epoch: 252 loss: 1.7674543857574463 grad: 5.401750684312483\n",
      "epoch: 253 loss: 1.780195951461792 grad: 5.700578700879261\n",
      "epoch: 254 loss: 1.7737431526184082 grad: 5.995443940177788\n",
      "epoch: 255 loss: 1.789600133895874 grad: 5.965275521625108\n",
      "epoch: 256 loss: 1.782117486000061 grad: 5.915783572077341\n",
      "epoch: 257 loss: 1.774038553237915 grad: 5.31880299803275\n",
      "epoch: 258 loss: 1.7772986888885498 grad: 6.553390744560082\n",
      "epoch: 259 loss: 1.7626001834869385 grad: 5.762090722714631\n",
      "epoch: 260 loss: 1.7822738885879517 grad: 6.109871086711907\n",
      "epoch: 261 loss: 1.782260775566101 grad: 5.839208562432297\n",
      "epoch: 262 loss: 1.765424132347107 grad: 5.765700948101608\n",
      "epoch: 263 loss: 1.7694116830825806 grad: 5.6865898193102025\n",
      "epoch: 264 loss: 1.765742301940918 grad: 6.307480058224096\n",
      "epoch: 265 loss: 1.7433607578277588 grad: 6.011941776160841\n",
      "epoch: 266 loss: 1.783398151397705 grad: 6.110178955697905\n",
      "epoch: 267 loss: 1.7599260807037354 grad: 5.724837501976896\n",
      "epoch: 268 loss: 1.769901990890503 grad: 5.385523185003371\n",
      "epoch: 269 loss: 1.752752661705017 grad: 6.6547246901543495\n",
      "epoch: 270 loss: 1.7611470222473145 grad: 5.608663184152979\n",
      "epoch: 271 loss: 1.7652453184127808 grad: 6.460432894629674\n",
      "epoch: 272 loss: 1.7804360389709473 grad: 6.649376132095558\n",
      "epoch: 273 loss: 1.7724785804748535 grad: 5.978334716089785\n",
      "epoch: 274 loss: 1.7568576335906982 grad: 6.046757658633902\n",
      "epoch: 275 loss: 1.7571401596069336 grad: 5.898576973547779\n",
      "epoch: 276 loss: 1.7689204216003418 grad: 5.954487434784766\n",
      "epoch: 277 loss: 1.753515362739563 grad: 6.26240717692062\n",
      "epoch: 278 loss: 1.7623904943466187 grad: 6.195325879311101\n",
      "epoch: 279 loss: 1.7467083930969238 grad: 5.688794100203686\n",
      "epoch: 280 loss: 1.753589391708374 grad: 5.6584667819867995\n",
      "epoch: 281 loss: 1.751550555229187 grad: 6.387765925919262\n",
      "epoch: 282 loss: 1.7715489864349365 grad: 6.178929514102781\n",
      "epoch: 283 loss: 1.7608078718185425 grad: 6.17501279836148\n",
      "epoch: 284 loss: 1.763145923614502 grad: 5.18871137480603\n",
      "epoch: 285 loss: 1.7492554187774658 grad: 5.953524121118313\n",
      "epoch: 286 loss: 1.7556883096694946 grad: 5.431934005166921\n",
      "epoch: 287 loss: 1.733067512512207 grad: 5.486683617082842\n",
      "epoch: 288 loss: 1.7300046682357788 grad: 6.067480115821545\n",
      "epoch: 289 loss: 1.7682151794433594 grad: 6.939774548678845\n",
      "epoch: 290 loss: 1.7453227043151855 grad: 5.974477496816429\n",
      "epoch: 291 loss: 1.758522391319275 grad: 6.201044096677386\n",
      "epoch: 292 loss: 1.7549359798431396 grad: 6.172739110347965\n",
      "epoch: 293 loss: 1.7327481508255005 grad: 5.54867381335244\n",
      "epoch: 294 loss: 1.739869475364685 grad: 5.564898826379032\n",
      "epoch: 295 loss: 1.7430198192596436 grad: 6.139071931436543\n",
      "epoch: 296 loss: 1.7535582780838013 grad: 6.578239128284998\n",
      "epoch: 297 loss: 1.7548564672470093 grad: 5.769748329018613\n",
      "epoch: 298 loss: 1.7586525678634644 grad: 5.748804382598748\n",
      "epoch: 299 loss: 1.7318522930145264 grad: 5.651189082074722\n",
      "epoch: 300 loss: 1.7253767251968384 grad: 6.293783976450608\n",
      "epoch: 301 loss: 1.7407243251800537 grad: 6.006479505312503\n",
      "epoch: 302 loss: 1.7304445505142212 grad: 5.533084997571317\n",
      "epoch: 303 loss: 1.7444465160369873 grad: 6.115661211818824\n",
      "epoch: 304 loss: 1.7264817953109741 grad: 5.0329071350167816\n",
      "epoch: 305 loss: 1.7319985628128052 grad: 6.098786654144085\n",
      "epoch: 306 loss: 1.7482020854949951 grad: 6.067758984046945\n",
      "epoch: 307 loss: 1.745306372642517 grad: 6.695247792731116\n",
      "epoch: 308 loss: 1.745905876159668 grad: 6.338612723973422\n",
      "epoch: 309 loss: 1.7451181411743164 grad: 6.0802911565248605\n",
      "epoch: 310 loss: 1.754887342453003 grad: 6.128659077407353\n",
      "epoch: 311 loss: 1.7374889850616455 grad: 7.229710719946554\n",
      "epoch: 312 loss: 1.7413806915283203 grad: 6.635283253541549\n",
      "epoch: 313 loss: 1.723881483078003 grad: 7.010567164999307\n",
      "epoch: 314 loss: 1.7559350728988647 grad: 6.8364163915763445\n",
      "epoch: 315 loss: 1.711432695388794 grad: 6.46265312425659\n",
      "epoch: 316 loss: 1.736682653427124 grad: 5.810482780531265\n",
      "epoch: 317 loss: 1.7298874855041504 grad: 6.320872984132461\n",
      "epoch: 318 loss: 1.7013850212097168 grad: 5.188191270207065\n",
      "epoch: 319 loss: 1.7234054803848267 grad: 7.080009345715077\n",
      "epoch: 320 loss: 1.7150497436523438 grad: 6.188253276167834\n",
      "epoch: 321 loss: 1.7277662754058838 grad: 5.678776831023033\n",
      "epoch: 322 loss: 1.7372713088989258 grad: 7.274193058370541\n",
      "epoch: 323 loss: 1.7482694387435913 grad: 7.11496235486381\n",
      "epoch: 324 loss: 1.7510416507720947 grad: 5.960200582257347\n",
      "epoch: 325 loss: 1.716220736503601 grad: 7.785236189961281\n",
      "epoch: 326 loss: 1.749430775642395 grad: 6.597434745589381\n",
      "epoch: 327 loss: 1.7324879169464111 grad: 6.453768963101942\n",
      "epoch: 328 loss: 1.7398409843444824 grad: 5.36806546425855\n",
      "epoch: 329 loss: 1.7273240089416504 grad: 5.866665495221472\n",
      "epoch: 330 loss: 1.7357087135314941 grad: 5.897104754555859\n",
      "epoch: 331 loss: 1.7215564250946045 grad: 5.992017230235837\n",
      "epoch: 332 loss: 1.7253578901290894 grad: 6.166413655009617\n",
      "epoch: 333 loss: 1.739227533340454 grad: 7.453257779256842\n",
      "epoch: 334 loss: 1.7123663425445557 grad: 5.520322006722749\n",
      "epoch: 335 loss: 1.720748782157898 grad: 4.274051682042689\n",
      "epoch: 336 loss: 1.7184900045394897 grad: 4.991291771258739\n",
      "epoch: 337 loss: 1.710196852684021 grad: 5.323852008462915\n",
      "epoch: 338 loss: 1.7170697450637817 grad: 6.579535205720002\n",
      "epoch: 339 loss: 1.709383249282837 grad: 5.919176896417209\n",
      "epoch: 340 loss: 1.7005008459091187 grad: 6.495059414852597\n",
      "epoch: 341 loss: 1.7256653308868408 grad: 6.709355236165201\n",
      "epoch: 342 loss: 1.73778235912323 grad: 6.4411977159784115\n",
      "epoch: 343 loss: 1.7023910284042358 grad: 5.836145476368121\n",
      "epoch: 344 loss: 1.7082600593566895 grad: 5.8418969063507875\n",
      "epoch: 345 loss: 1.7064483165740967 grad: 7.222014297117124\n",
      "epoch: 346 loss: 1.709525465965271 grad: 5.260228360794697\n",
      "epoch: 347 loss: 1.703444004058838 grad: 5.400522612003255\n",
      "epoch: 348 loss: 1.7091777324676514 grad: 5.490514942706391\n",
      "epoch: 349 loss: 1.7015771865844727 grad: 4.882451190002867\n",
      "epoch: 350 loss: 1.6952451467514038 grad: 5.446383020444042\n",
      "epoch: 351 loss: 1.703819990158081 grad: 7.192044764498225\n",
      "epoch: 352 loss: 1.7081348896026611 grad: 6.63331758512027\n",
      "epoch: 353 loss: 1.7168525457382202 grad: 6.424634859263495\n",
      "epoch: 354 loss: 1.715754747390747 grad: 6.025134334766783\n",
      "epoch: 355 loss: 1.6977499723434448 grad: 5.993871974795516\n",
      "epoch: 356 loss: 1.6894440650939941 grad: 4.83503369254605\n",
      "epoch: 357 loss: 1.7086843252182007 grad: 5.163330360680974\n",
      "epoch: 358 loss: 1.6980555057525635 grad: 4.996271710346278\n",
      "epoch: 359 loss: 1.7028801441192627 grad: 6.117288484667947\n",
      "epoch: 360 loss: 1.7073837518692017 grad: 6.934752062508553\n",
      "epoch: 361 loss: 1.711842656135559 grad: 6.1576798922774865\n",
      "epoch: 362 loss: 1.7131322622299194 grad: 7.921874550895154\n",
      "epoch: 363 loss: 1.7192896604537964 grad: 6.243493657444242\n",
      "epoch: 364 loss: 1.7080330848693848 grad: 6.204551483054866\n",
      "epoch: 365 loss: 1.6856505870819092 grad: 6.110168749706963\n",
      "epoch: 366 loss: 1.720038652420044 grad: 6.830446020623929\n",
      "epoch: 367 loss: 1.7009239196777344 grad: 5.877660816768415\n",
      "epoch: 368 loss: 1.7009390592575073 grad: 5.858465101168501\n",
      "epoch: 369 loss: 1.6891474723815918 grad: 5.507095269468707\n",
      "epoch: 370 loss: 1.7148526906967163 grad: 7.279361806269749\n",
      "epoch: 371 loss: 1.6779224872589111 grad: 6.222760069102757\n",
      "epoch: 372 loss: 1.7076042890548706 grad: 6.177234136346669\n",
      "epoch: 373 loss: 1.70720374584198 grad: 5.344719895388903\n",
      "epoch: 374 loss: 1.7109191417694092 grad: 5.68116091537923\n",
      "epoch: 375 loss: 1.707784652709961 grad: 5.197830492406624\n",
      "epoch: 376 loss: 1.7031798362731934 grad: 6.401474570005539\n",
      "epoch: 377 loss: 1.7098952531814575 grad: 6.033847709560181\n",
      "epoch: 378 loss: 1.7062492370605469 grad: 5.700910938590549\n",
      "epoch: 379 loss: 1.704108715057373 grad: 6.66614867948823\n",
      "epoch: 380 loss: 1.691270112991333 grad: 6.6287497040861965\n",
      "epoch: 381 loss: 1.7012159824371338 grad: 5.896821270763111\n",
      "epoch: 382 loss: 1.706413984298706 grad: 6.079356316407188\n",
      "epoch: 383 loss: 1.729249119758606 grad: 5.0843444879690445\n",
      "epoch: 384 loss: 1.7124074697494507 grad: 5.310737942238149\n",
      "epoch: 385 loss: 1.7104190587997437 grad: 7.200550359125373\n",
      "epoch: 386 loss: 1.7060014009475708 grad: 4.857979366345962\n",
      "epoch: 387 loss: 1.686605453491211 grad: 5.474968513907481\n",
      "epoch: 388 loss: 1.6955492496490479 grad: 6.869124004378049\n",
      "epoch: 389 loss: 1.7045742273330688 grad: 5.603848036674684\n",
      "epoch: 390 loss: 1.6997196674346924 grad: 5.675779224894353\n",
      "epoch: 391 loss: 1.7077795267105103 grad: 6.496159268800093\n",
      "epoch: 392 loss: 1.7064125537872314 grad: 6.300700450347543\n",
      "epoch: 393 loss: 1.6930663585662842 grad: 5.38653632457887\n",
      "epoch: 394 loss: 1.7009235620498657 grad: 5.475870723932443\n",
      "epoch: 395 loss: 1.704132080078125 grad: 5.287880094435351\n",
      "epoch: 396 loss: 1.6973768472671509 grad: 6.655971693807361\n",
      "epoch: 397 loss: 1.6857285499572754 grad: 4.410658073503884\n",
      "epoch: 398 loss: 1.7086936235427856 grad: 6.312147575246389\n",
      "epoch: 399 loss: 1.691269040107727 grad: 5.104121065431988\n",
      "epoch: 400 loss: 1.707517385482788 grad: 5.132326506535214\n",
      "epoch: 401 loss: 1.7080398797988892 grad: 6.5818625699594415\n",
      "epoch: 402 loss: 1.7045643329620361 grad: 5.177454458137567\n",
      "epoch: 403 loss: 1.6877377033233643 grad: 7.116621576642155\n",
      "epoch: 404 loss: 1.7087398767471313 grad: 5.946911658836374\n",
      "epoch: 405 loss: 1.6981812715530396 grad: 6.561640920365515\n",
      "epoch: 406 loss: 1.6985692977905273 grad: 5.406747308656325\n",
      "epoch: 407 loss: 1.6971840858459473 grad: 6.535431800327489\n",
      "epoch: 408 loss: 1.6896220445632935 grad: 6.94794553457157\n",
      "epoch: 409 loss: 1.729410171508789 grad: 6.421628457098522\n",
      "epoch: 410 loss: 1.6844298839569092 grad: 6.348947069035805\n",
      "epoch: 411 loss: 1.6939119100570679 grad: 5.546425887354041\n",
      "epoch: 412 loss: 1.704927682876587 grad: 7.213188657096272\n",
      "epoch: 413 loss: 1.6898069381713867 grad: 6.077042530295171\n",
      "epoch: 414 loss: 1.6803637742996216 grad: 5.733200363641593\n",
      "epoch: 415 loss: 1.7027642726898193 grad: 5.608271259697797\n",
      "epoch: 416 loss: 1.6902806758880615 grad: 5.096222729144294\n",
      "epoch: 417 loss: 1.6846295595169067 grad: 6.191551046640453\n",
      "epoch: 418 loss: 1.6829761266708374 grad: 5.553114855699685\n",
      "epoch: 419 loss: 1.6964048147201538 grad: 5.061735340601343\n",
      "epoch: 420 loss: 1.7183490991592407 grad: 6.636274070349611\n",
      "epoch: 421 loss: 1.6913635730743408 grad: 7.722364053802981\n",
      "epoch: 422 loss: 1.6911134719848633 grad: 6.626030374664576\n",
      "epoch: 423 loss: 1.6852588653564453 grad: 6.664655432241968\n",
      "epoch: 424 loss: 1.6980012655258179 grad: 6.592568865476045\n",
      "epoch: 425 loss: 1.682043433189392 grad: 5.812393434247483\n",
      "epoch: 426 loss: 1.7029454708099365 grad: 6.445870167395119\n",
      "epoch: 427 loss: 1.680420160293579 grad: 4.45526408631103\n",
      "epoch: 428 loss: 1.7063816785812378 grad: 8.427636256502598\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 429 loss: 1.6896811723709106 grad: 5.619006980645772\n",
      "epoch: 430 loss: 1.68373703956604 grad: 7.324647956747636\n",
      "epoch: 431 loss: 1.6842254400253296 grad: 5.499111403667943\n",
      "epoch: 432 loss: 1.6762641668319702 grad: 5.991765146957776\n",
      "epoch: 433 loss: 1.702815055847168 grad: 5.570923022400608\n",
      "epoch: 434 loss: 1.6803028583526611 grad: 5.750368616438151\n",
      "epoch: 435 loss: 1.6965676546096802 grad: 5.606042806873192\n",
      "epoch: 436 loss: 1.6978739500045776 grad: 7.037556079549895\n",
      "epoch: 437 loss: 1.683562159538269 grad: 6.160183697818418\n",
      "epoch: 438 loss: 1.6799132823944092 grad: 6.413038350610285\n",
      "epoch: 439 loss: 1.6686792373657227 grad: 5.061368890899635\n",
      "epoch: 440 loss: 1.6960794925689697 grad: 6.835068938965306\n",
      "epoch: 441 loss: 1.6747963428497314 grad: 7.332426021002361\n",
      "epoch: 442 loss: 1.6880340576171875 grad: 6.157899186948831\n",
      "epoch: 443 loss: 1.6792137622833252 grad: 5.70899834804492\n",
      "epoch: 444 loss: 1.6719826459884644 grad: 6.261740751153902\n",
      "epoch: 445 loss: 1.6785619258880615 grad: 5.147388099956566\n",
      "epoch: 446 loss: 1.6835005283355713 grad: 4.876106619347649\n",
      "epoch: 447 loss: 1.693983554840088 grad: 7.2167302147389\n",
      "epoch: 448 loss: 1.6887081861495972 grad: 6.130330468117343\n",
      "epoch: 449 loss: 1.692477822303772 grad: 6.117930598520248\n",
      "epoch: 450 loss: 1.6867562532424927 grad: 7.365957919190603\n",
      "epoch: 451 loss: 1.6809545755386353 grad: 5.270934600112332\n",
      "epoch: 452 loss: 1.6881402730941772 grad: 7.121819248231454\n",
      "epoch: 453 loss: 1.6879637241363525 grad: 4.411431966720518\n",
      "epoch: 454 loss: 1.6870218515396118 grad: 4.961845377702438\n",
      "epoch: 455 loss: 1.677544355392456 grad: 6.24320639019194\n",
      "epoch: 456 loss: 1.675096035003662 grad: 4.854523254564165\n",
      "epoch: 457 loss: 1.6640270948410034 grad: 7.302652787544546\n",
      "epoch: 458 loss: 1.6949008703231812 grad: 5.985044342563006\n",
      "epoch: 459 loss: 1.6794482469558716 grad: 5.3856229831793\n",
      "epoch: 460 loss: 1.6705596446990967 grad: 5.204169396551786\n",
      "epoch: 461 loss: 1.683720588684082 grad: 5.7464449566294435\n",
      "epoch: 462 loss: 1.685479760169983 grad: 5.7589995042319515\n",
      "epoch: 463 loss: 1.6762441396713257 grad: 6.00516917334757\n",
      "epoch: 464 loss: 1.665065884590149 grad: 6.52704583031339\n",
      "epoch: 465 loss: 1.6601125001907349 grad: 6.126107551926969\n",
      "epoch: 466 loss: 1.6723706722259521 grad: 5.683106993829615\n",
      "epoch: 467 loss: 1.683536410331726 grad: 6.343833925661033\n",
      "epoch: 468 loss: 1.69651198387146 grad: 7.772631047050203\n",
      "epoch: 469 loss: 1.6926106214523315 grad: 6.9599510462199605\n",
      "epoch: 470 loss: 1.6805522441864014 grad: 4.9798357957687225\n",
      "epoch: 471 loss: 1.6707050800323486 grad: 5.831906567076051\n",
      "epoch: 472 loss: 1.6588101387023926 grad: 4.806923129368871\n",
      "epoch: 473 loss: 1.6616590023040771 grad: 5.027619193886515\n",
      "epoch: 474 loss: 1.6515508890151978 grad: 5.417960483454921\n",
      "epoch: 475 loss: 1.6785534620285034 grad: 6.638381020297092\n",
      "epoch: 476 loss: 1.6859838962554932 grad: 4.827857015173871\n",
      "epoch: 477 loss: 1.6674718856811523 grad: 5.830326019384099\n",
      "epoch: 478 loss: 1.6553319692611694 grad: 5.3165175030467005\n",
      "epoch: 479 loss: 1.6664243936538696 grad: 4.9759653145533305\n",
      "epoch: 480 loss: 1.673171043395996 grad: 4.5908519958800404\n",
      "epoch: 481 loss: 1.6559672355651855 grad: 4.838595636244163\n",
      "epoch: 482 loss: 1.6753761768341064 grad: 5.781053124909193\n",
      "epoch: 483 loss: 1.6716578006744385 grad: 6.190576595252972\n",
      "epoch: 484 loss: 1.6789796352386475 grad: 5.291635535697246\n",
      "epoch: 485 loss: 1.690956950187683 grad: 7.131734319618975\n",
      "epoch: 486 loss: 1.6790616512298584 grad: 5.7899605540063686\n",
      "epoch: 487 loss: 1.6780756711959839 grad: 5.63911356260865\n",
      "epoch: 488 loss: 1.6966958045959473 grad: 7.070414385443713\n",
      "epoch: 489 loss: 1.6887905597686768 grad: 6.8020212927096715\n",
      "epoch: 490 loss: 1.6710429191589355 grad: 5.41109394149836\n",
      "epoch: 491 loss: 1.667551040649414 grad: 5.93338483249402\n",
      "epoch: 492 loss: 1.6723949909210205 grad: 4.947790560439321\n",
      "epoch: 493 loss: 1.6798357963562012 grad: 6.851916519066071\n",
      "epoch: 494 loss: 1.6621116399765015 grad: 4.799015398266647\n",
      "epoch: 495 loss: 1.6641876697540283 grad: 5.5260159448120945\n",
      "epoch: 496 loss: 1.670669436454773 grad: 6.896067369804639\n",
      "epoch: 497 loss: 1.6924067735671997 grad: 6.0884043079588785\n",
      "epoch: 498 loss: 1.6700191497802734 grad: 6.02577500529643\n",
      "epoch: 499 loss: 1.6718230247497559 grad: 4.059378010698063\n",
      "2.0033717826008797\n",
      "epoch: 0 loss: 2.3032195568084717 grad: 1.2663565195804936\n",
      "epoch: 1 loss: 2.3029801845550537 grad: 1.2696583062864928\n",
      "epoch: 2 loss: 2.3032758235931396 grad: 1.2734126627910882\n",
      "epoch: 3 loss: 2.302664279937744 grad: 1.2668377241463444\n",
      "epoch: 4 loss: 2.3024652004241943 grad: 1.2719948347713355\n",
      "epoch: 5 loss: 2.3029770851135254 grad: 1.2668517766195158\n",
      "epoch: 6 loss: 2.303189754486084 grad: 1.2646451565060055\n",
      "epoch: 7 loss: 2.3033382892608643 grad: 1.2547892146052733\n",
      "epoch: 8 loss: 2.3033368587493896 grad: 1.2597595921214966\n",
      "epoch: 9 loss: 2.3028178215026855 grad: 1.2693108364732728\n",
      "epoch: 10 loss: 2.302751064300537 grad: 1.2731311222120736\n",
      "epoch: 11 loss: 2.3029916286468506 grad: 1.2722760832550684\n",
      "epoch: 12 loss: 2.3024423122406006 grad: 1.2747899030135679\n",
      "epoch: 13 loss: 2.3032097816467285 grad: 1.2658310033295983\n",
      "epoch: 14 loss: 2.3031301498413086 grad: 1.2618378776011043\n",
      "epoch: 15 loss: 2.302830934524536 grad: 1.2679264242797794\n",
      "epoch: 16 loss: 2.3031179904937744 grad: 1.2593898339832703\n",
      "epoch: 17 loss: 2.3030667304992676 grad: 1.2617731780989008\n",
      "epoch: 18 loss: 2.3030622005462646 grad: 1.272527689746182\n",
      "epoch: 19 loss: 2.3030571937561035 grad: 1.2624767157803511\n",
      "epoch: 20 loss: 2.303236722946167 grad: 1.2615288085126806\n",
      "epoch: 21 loss: 2.30379056930542 grad: 1.2619467879726833\n",
      "epoch: 22 loss: 2.302567958831787 grad: 1.2737221119108624\n",
      "epoch: 23 loss: 2.3029799461364746 grad: 1.2649542010880799\n",
      "epoch: 24 loss: 2.3033106327056885 grad: 1.2595037580393846\n",
      "epoch: 25 loss: 2.3031411170959473 grad: 1.2737686146265044\n",
      "epoch: 26 loss: 2.3028244972229004 grad: 1.2653584328151146\n",
      "epoch: 27 loss: 2.3026092052459717 grad: 1.2702760722669255\n",
      "epoch: 28 loss: 2.3026232719421387 grad: 1.2705632472865371\n",
      "epoch: 29 loss: 2.3029186725616455 grad: 1.2659977159023077\n",
      "epoch: 30 loss: 2.3032209873199463 grad: 1.2511837930725296\n",
      "epoch: 31 loss: 2.3030779361724854 grad: 1.2694009843592842\n",
      "epoch: 32 loss: 2.3029096126556396 grad: 1.266519865484923\n",
      "epoch: 33 loss: 2.303798198699951 grad: 1.2537040573633498\n",
      "epoch: 34 loss: 2.3031673431396484 grad: 1.2620548958546438\n",
      "epoch: 35 loss: 2.3029422760009766 grad: 1.2789644545723966\n",
      "epoch: 36 loss: 2.30243182182312 grad: 1.2757040938244215\n",
      "epoch: 37 loss: 2.3030333518981934 grad: 1.2634002113740683\n",
      "epoch: 38 loss: 2.3033478260040283 grad: 1.257755087021487\n",
      "epoch: 39 loss: 2.3028059005737305 grad: 1.2741050484113483\n",
      "epoch: 40 loss: 2.303354501724243 grad: 1.2631070703426968\n",
      "epoch: 41 loss: 2.302980422973633 grad: 1.2563261650890734\n",
      "epoch: 42 loss: 2.3031766414642334 grad: 1.2580629037489879\n",
      "epoch: 43 loss: 2.302734375 grad: 1.263761528183721\n",
      "epoch: 44 loss: 2.303377628326416 grad: 1.2584376193468445\n",
      "epoch: 45 loss: 2.303121566772461 grad: 1.265240798785632\n",
      "epoch: 46 loss: 2.3028743267059326 grad: 1.2670531690246352\n",
      "epoch: 47 loss: 2.3028392791748047 grad: 1.248854209807524\n",
      "epoch: 48 loss: 2.3024673461914062 grad: 1.27325177528075\n",
      "epoch: 49 loss: 2.303192615509033 grad: 1.2537739615599137\n",
      "epoch: 50 loss: 2.302689790725708 grad: 1.263716967504782\n",
      "epoch: 51 loss: 2.302516222000122 grad: 1.275741800431177\n",
      "epoch: 52 loss: 2.303386926651001 grad: 1.2548672339309834\n",
      "epoch: 53 loss: 2.3026535511016846 grad: 1.2693548004035764\n",
      "epoch: 54 loss: 2.302551746368408 grad: 1.2648769686061387\n",
      "epoch: 55 loss: 2.302910089492798 grad: 1.2641620048624833\n",
      "epoch: 56 loss: 2.3028059005737305 grad: 1.265390366755633\n",
      "epoch: 57 loss: 2.3029115200042725 grad: 1.2621149764754735\n",
      "epoch: 58 loss: 2.3032360076904297 grad: 1.2588457013572758\n",
      "epoch: 59 loss: 2.3031957149505615 grad: 1.2548997179505281\n",
      "epoch: 60 loss: 2.302518367767334 grad: 1.2766500413159116\n",
      "epoch: 61 loss: 2.303398847579956 grad: 1.2675611116731214\n",
      "epoch: 62 loss: 2.3029441833496094 grad: 1.2580105099930532\n",
      "epoch: 63 loss: 2.302401304244995 grad: 1.2748123185047584\n",
      "epoch: 64 loss: 2.3031129837036133 grad: 1.2618236021815046\n",
      "epoch: 65 loss: 2.3025858402252197 grad: 1.2725271842856374\n",
      "epoch: 66 loss: 2.302858591079712 grad: 1.2584844849124137\n",
      "epoch: 67 loss: 2.3033008575439453 grad: 1.2509233822070418\n",
      "epoch: 68 loss: 2.3030195236206055 grad: 1.2559031902975033\n",
      "epoch: 69 loss: 2.3032214641571045 grad: 1.2590630367815878\n",
      "epoch: 70 loss: 2.302706718444824 grad: 1.266541766838008\n",
      "epoch: 71 loss: 2.302729606628418 grad: 1.264200072360432\n",
      "epoch: 72 loss: 2.3037264347076416 grad: 1.2472524626036396\n",
      "epoch: 73 loss: 2.302727222442627 grad: 1.2623638492447162\n",
      "epoch: 74 loss: 2.3027093410491943 grad: 1.2693359082812326\n",
      "epoch: 75 loss: 2.302903890609741 grad: 1.2558740633114847\n",
      "epoch: 76 loss: 2.302802324295044 grad: 1.2559645496852074\n",
      "epoch: 77 loss: 2.3029801845550537 grad: 1.2613010051778504\n",
      "epoch: 78 loss: 2.3023440837860107 grad: 1.2765346794252446\n",
      "epoch: 79 loss: 2.302419662475586 grad: 1.268891225757432\n",
      "epoch: 80 loss: 2.3029701709747314 grad: 1.256288492004387\n",
      "epoch: 81 loss: 2.3020124435424805 grad: 1.2773440058901167\n",
      "epoch: 82 loss: 2.3027384281158447 grad: 1.2619228101620037\n",
      "epoch: 83 loss: 2.3026998043060303 grad: 1.2689922398292564\n",
      "epoch: 84 loss: 2.303770065307617 grad: 1.242063866375709\n",
      "epoch: 85 loss: 2.303178310394287 grad: 1.2573402678678995\n",
      "epoch: 86 loss: 2.303516149520874 grad: 1.2563755980781501\n",
      "epoch: 87 loss: 2.302608013153076 grad: 1.2617519450991133\n",
      "epoch: 88 loss: 2.303255081176758 grad: 1.2558687901039356\n",
      "epoch: 89 loss: 2.302953004837036 grad: 1.2654608541781762\n",
      "epoch: 90 loss: 2.3031363487243652 grad: 1.2629989849011753\n",
      "epoch: 91 loss: 2.3026909828186035 grad: 1.2602990352168\n",
      "epoch: 92 loss: 2.302947759628296 grad: 1.260868194684874\n",
      "epoch: 93 loss: 2.302297830581665 grad: 1.2582074566633397\n",
      "epoch: 94 loss: 2.3026251792907715 grad: 1.2726110718841295\n",
      "epoch: 95 loss: 2.302006721496582 grad: 1.2786610787235466\n",
      "epoch: 96 loss: 2.303189992904663 grad: 1.2530282559945056\n",
      "epoch: 97 loss: 2.303523063659668 grad: 1.2545684580580287\n",
      "epoch: 98 loss: 2.3034098148345947 grad: 1.251708429005544\n",
      "epoch: 99 loss: 2.302560567855835 grad: 1.2648446081531426\n",
      "epoch: 100 loss: 2.3034589290618896 grad: 1.2542723112144611\n",
      "epoch: 101 loss: 2.3033907413482666 grad: 1.2629528558251286\n",
      "epoch: 102 loss: 2.3030848503112793 grad: 1.268618040599875\n",
      "epoch: 103 loss: 2.3032383918762207 grad: 1.2498936943103751\n",
      "epoch: 104 loss: 2.3032381534576416 grad: 1.2549360532956642\n",
      "epoch: 105 loss: 2.303210496902466 grad: 1.271785306186223\n",
      "epoch: 106 loss: 2.3028650283813477 grad: 1.2574881209219466\n",
      "epoch: 107 loss: 2.3026673793792725 grad: 1.261158773660778\n",
      "epoch: 108 loss: 2.302579641342163 grad: 1.2719619233800572\n",
      "epoch: 109 loss: 2.3029890060424805 grad: 1.2623061173177872\n",
      "epoch: 110 loss: 2.3026554584503174 grad: 1.2702652941539234\n",
      "epoch: 111 loss: 2.3029346466064453 grad: 1.25485705147453\n",
      "epoch: 112 loss: 2.303039073944092 grad: 1.2551675989950402\n",
      "epoch: 113 loss: 2.3024420738220215 grad: 1.265311753007746\n",
      "epoch: 114 loss: 2.302964448928833 grad: 1.2652926084397005\n",
      "epoch: 115 loss: 2.3022916316986084 grad: 1.2756291825716044\n",
      "epoch: 116 loss: 2.3030149936676025 grad: 1.2576423662082692\n",
      "epoch: 117 loss: 2.302682638168335 grad: 1.2620867268618432\n",
      "epoch: 118 loss: 2.303406238555908 grad: 1.2483740706044797\n",
      "epoch: 119 loss: 2.302936315536499 grad: 1.266678700814881\n",
      "epoch: 120 loss: 2.3028836250305176 grad: 1.2647039092548693\n",
      "epoch: 121 loss: 2.3024401664733887 grad: 1.2616042175685012\n",
      "epoch: 122 loss: 2.3030574321746826 grad: 1.2683255460338727\n",
      "epoch: 123 loss: 2.3025519847869873 grad: 1.2563614773578824\n",
      "epoch: 124 loss: 2.3029184341430664 grad: 1.254603054124995\n",
      "epoch: 125 loss: 2.3034720420837402 grad: 1.2489452488657589\n",
      "epoch: 126 loss: 2.3025944232940674 grad: 1.2622639710575134\n",
      "epoch: 127 loss: 2.3024778366088867 grad: 1.2662175925141792\n",
      "epoch: 128 loss: 2.3021605014801025 grad: 1.2720212092907686\n",
      "epoch: 129 loss: 2.3027255535125732 grad: 1.2667504074828078\n",
      "epoch: 130 loss: 2.302067518234253 grad: 1.2677156962214098\n",
      "epoch: 131 loss: 2.3025567531585693 grad: 1.2651305113298197\n",
      "epoch: 132 loss: 2.3033101558685303 grad: 1.2604734224511223\n",
      "epoch: 133 loss: 2.3029396533966064 grad: 1.2624794668573442\n",
      "epoch: 134 loss: 2.3032596111297607 grad: 1.2548377817230565\n",
      "epoch: 135 loss: 2.302772283554077 grad: 1.267387336365775\n",
      "epoch: 136 loss: 2.3028619289398193 grad: 1.2563594038365409\n",
      "epoch: 137 loss: 2.3029258251190186 grad: 1.255717576655101\n",
      "epoch: 138 loss: 2.3032145500183105 grad: 1.2532788672103798\n",
      "epoch: 139 loss: 2.30311918258667 grad: 1.2596968555793402\n",
      "epoch: 140 loss: 2.3025717735290527 grad: 1.2709459696973984\n",
      "epoch: 141 loss: 2.3031978607177734 grad: 1.2620891262610843\n",
      "epoch: 142 loss: 2.302621364593506 grad: 1.268630582323697\n",
      "epoch: 143 loss: 2.302978038787842 grad: 1.253974110462762\n",
      "epoch: 144 loss: 2.3023855686187744 grad: 1.266031859437048\n",
      "epoch: 145 loss: 2.302581548690796 grad: 1.2628570144186684\n",
      "epoch: 146 loss: 2.302988290786743 grad: 1.2641823992598802\n",
      "epoch: 147 loss: 2.3019604682922363 grad: 1.2745406489527327\n",
      "epoch: 148 loss: 2.3027846813201904 grad: 1.2734473474575059\n",
      "epoch: 149 loss: 2.30263352394104 grad: 1.262826137156004\n",
      "epoch: 150 loss: 2.3027594089508057 grad: 1.2504529726288711\n",
      "epoch: 151 loss: 2.3025710582733154 grad: 1.2614943452903793\n",
      "epoch: 152 loss: 2.3024728298187256 grad: 1.2542298738696864\n",
      "epoch: 153 loss: 2.302701711654663 grad: 1.2685668348807781\n",
      "epoch: 154 loss: 2.3027658462524414 grad: 1.2592335514306638\n",
      "epoch: 155 loss: 2.3021326065063477 grad: 1.2781660672709612\n",
      "epoch: 156 loss: 2.303032875061035 grad: 1.261264222348848\n",
      "epoch: 157 loss: 2.3031582832336426 grad: 1.2621475913310571\n",
      "epoch: 158 loss: 2.3027188777923584 grad: 1.2580912037150165\n",
      "epoch: 159 loss: 2.3030412197113037 grad: 1.2496576681954874\n",
      "epoch: 160 loss: 2.3026132583618164 grad: 1.2685131211543368\n",
      "epoch: 161 loss: 2.3022572994232178 grad: 1.2707779797252328\n",
      "epoch: 162 loss: 2.3027915954589844 grad: 1.2601615378156392\n",
      "epoch: 163 loss: 2.302584648132324 grad: 1.2684296848407637\n",
      "epoch: 164 loss: 2.302753210067749 grad: 1.2559847269865079\n",
      "epoch: 165 loss: 2.302924394607544 grad: 1.2667017212296496\n",
      "epoch: 166 loss: 2.3026442527770996 grad: 1.261801675669775\n",
      "epoch: 167 loss: 2.302487373352051 grad: 1.2664103860660116\n",
      "epoch: 168 loss: 2.30153226852417 grad: 1.272010106410432\n",
      "epoch: 169 loss: 2.303218126296997 grad: 1.2607421687090887\n",
      "epoch: 170 loss: 2.3026390075683594 grad: 1.2655145007311293\n",
      "epoch: 171 loss: 2.3025269508361816 grad: 1.2760519902240337\n",
      "epoch: 172 loss: 2.3025758266448975 grad: 1.2656863470292015\n",
      "epoch: 173 loss: 2.3024420738220215 grad: 1.2656369699823065\n",
      "epoch: 174 loss: 2.302727460861206 grad: 1.2562236833637432\n",
      "epoch: 175 loss: 2.302896499633789 grad: 1.2548463536382077\n",
      "epoch: 176 loss: 2.3027124404907227 grad: 1.260102529588732\n",
      "epoch: 177 loss: 2.302273988723755 grad: 1.2745357667214223\n",
      "epoch: 178 loss: 2.303919553756714 grad: 1.250618977995131\n",
      "epoch: 179 loss: 2.30299711227417 grad: 1.2633088050883203\n",
      "epoch: 180 loss: 2.302663564682007 grad: 1.26562698022832\n",
      "epoch: 181 loss: 2.3030881881713867 grad: 1.2613077513145519\n",
      "epoch: 182 loss: 2.302330255508423 grad: 1.2655182065689818\n",
      "epoch: 183 loss: 2.302377700805664 grad: 1.26722189089069\n",
      "epoch: 184 loss: 2.302943468093872 grad: 1.2533122163953347\n",
      "epoch: 185 loss: 2.302960157394409 grad: 1.2644640247333825\n",
      "epoch: 186 loss: 2.3029332160949707 grad: 1.2566065911281232\n",
      "epoch: 187 loss: 2.302748203277588 grad: 1.26272969211023\n",
      "epoch: 188 loss: 2.3033251762390137 grad: 1.250923336997244\n",
      "epoch: 189 loss: 2.3029532432556152 grad: 1.2609564550350316\n",
      "epoch: 190 loss: 2.3030519485473633 grad: 1.2649529910838557\n",
      "epoch: 191 loss: 2.3026442527770996 grad: 1.261628563942698\n",
      "epoch: 192 loss: 2.3023171424865723 grad: 1.2728590498297727\n",
      "epoch: 193 loss: 2.3034191131591797 grad: 1.2622960799277598\n",
      "epoch: 194 loss: 2.302520275115967 grad: 1.2694461599069957\n",
      "epoch: 195 loss: 2.302126169204712 grad: 1.283234945818087\n",
      "epoch: 196 loss: 2.302586078643799 grad: 1.2644161655113013\n",
      "epoch: 197 loss: 2.302673578262329 grad: 1.2659015357494354\n",
      "epoch: 198 loss: 2.3029379844665527 grad: 1.2544186504886647\n",
      "epoch: 199 loss: 2.3026981353759766 grad: 1.2681661364603936\n",
      "epoch: 200 loss: 2.3029978275299072 grad: 1.2616964477180903\n",
      "epoch: 201 loss: 2.3029863834381104 grad: 1.2610574589972015\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 202 loss: 2.3028204441070557 grad: 1.258317119033549\n",
      "epoch: 203 loss: 2.303010940551758 grad: 1.2589360773138376\n",
      "epoch: 204 loss: 2.302241325378418 grad: 1.263398712914851\n",
      "epoch: 205 loss: 2.303030490875244 grad: 1.252679128449277\n",
      "epoch: 206 loss: 2.3033008575439453 grad: 1.255363789510854\n",
      "epoch: 207 loss: 2.302682638168335 grad: 1.25919661719522\n",
      "epoch: 208 loss: 2.3023619651794434 grad: 1.2720037047078625\n",
      "epoch: 209 loss: 2.3022186756134033 grad: 1.2657996863902856\n",
      "epoch: 210 loss: 2.3033037185668945 grad: 1.2543266288463086\n",
      "epoch: 211 loss: 2.303236722946167 grad: 1.2640351837312447\n",
      "epoch: 212 loss: 2.302356481552124 grad: 1.2670176620003841\n",
      "epoch: 213 loss: 2.3030195236206055 grad: 1.2586049732423226\n",
      "epoch: 214 loss: 2.3030965328216553 grad: 1.2467572006160423\n",
      "epoch: 215 loss: 2.3033556938171387 grad: 1.2472488949470784\n",
      "epoch: 216 loss: 2.303356409072876 grad: 1.247850456045911\n",
      "epoch: 217 loss: 2.3030426502227783 grad: 1.2569399904348844\n",
      "epoch: 218 loss: 2.303114891052246 grad: 1.2400080420867732\n",
      "epoch: 219 loss: 2.302746295928955 grad: 1.2650663844468664\n",
      "epoch: 220 loss: 2.30268931388855 grad: 1.2662627893677425\n",
      "epoch: 221 loss: 2.3028767108917236 grad: 1.255646904869493\n",
      "epoch: 222 loss: 2.303248882293701 grad: 1.2532622130432476\n",
      "epoch: 223 loss: 2.302205801010132 grad: 1.2654072230936781\n",
      "epoch: 224 loss: 2.302626371383667 grad: 1.2677863607098097\n",
      "epoch: 225 loss: 2.30329966545105 grad: 1.2494070483464008\n",
      "epoch: 226 loss: 2.3028929233551025 grad: 1.2640317023181105\n",
      "epoch: 227 loss: 2.3025054931640625 grad: 1.2622497920445832\n",
      "epoch: 228 loss: 2.302907705307007 grad: 1.257512416568629\n",
      "epoch: 229 loss: 2.302485704421997 grad: 1.2609484955180614\n",
      "epoch: 230 loss: 2.3020145893096924 grad: 1.2687491894596152\n",
      "epoch: 231 loss: 2.302971601486206 grad: 1.2573428907014046\n",
      "epoch: 232 loss: 2.3030173778533936 grad: 1.2565191315324415\n",
      "epoch: 233 loss: 2.3024044036865234 grad: 1.2661513235264767\n",
      "epoch: 234 loss: 2.3024139404296875 grad: 1.2760385779833923\n",
      "epoch: 235 loss: 2.3025968074798584 grad: 1.2642976474940837\n",
      "epoch: 236 loss: 2.3024771213531494 grad: 1.2568569177732107\n",
      "epoch: 237 loss: 2.302583932876587 grad: 1.2655082062563106\n",
      "epoch: 238 loss: 2.3038833141326904 grad: 1.252159316007728\n",
      "epoch: 239 loss: 2.3023264408111572 grad: 1.2638307086742735\n",
      "epoch: 240 loss: 2.3022868633270264 grad: 1.267704519925506\n",
      "epoch: 241 loss: 2.3026535511016846 grad: 1.2620275805737557\n",
      "epoch: 242 loss: 2.3027451038360596 grad: 1.2553357956764688\n",
      "epoch: 243 loss: 2.3025686740875244 grad: 1.2646109488060964\n",
      "epoch: 244 loss: 2.3027734756469727 grad: 1.2589350107425292\n",
      "epoch: 245 loss: 2.30314040184021 grad: 1.255672065934743\n",
      "epoch: 246 loss: 2.302783489227295 grad: 1.2545256193778995\n",
      "epoch: 247 loss: 2.302621364593506 grad: 1.254386925181034\n",
      "epoch: 248 loss: 2.3025171756744385 grad: 1.2697720009379\n",
      "epoch: 249 loss: 2.3027796745300293 grad: 1.261690198619377\n",
      "epoch: 250 loss: 2.3027374744415283 grad: 1.2639382167142772\n",
      "epoch: 251 loss: 2.302262783050537 grad: 1.2686369885757034\n",
      "epoch: 252 loss: 2.302488088607788 grad: 1.2748946125548895\n",
      "epoch: 253 loss: 2.3032023906707764 grad: 1.2546401983995492\n",
      "epoch: 254 loss: 2.302820920944214 grad: 1.2552226456418072\n",
      "epoch: 255 loss: 2.302335262298584 grad: 1.267966503573079\n",
      "epoch: 256 loss: 2.303443193435669 grad: 1.2480143091312448\n",
      "epoch: 257 loss: 2.302405595779419 grad: 1.2569233986312554\n",
      "epoch: 258 loss: 2.303105354309082 grad: 1.26100032513089\n",
      "epoch: 259 loss: 2.3025128841400146 grad: 1.2694247643433747\n",
      "epoch: 260 loss: 2.3030054569244385 grad: 1.2542565454052583\n",
      "epoch: 261 loss: 2.3030271530151367 grad: 1.2600252820023645\n",
      "epoch: 262 loss: 2.302065849304199 grad: 1.2646186992282136\n",
      "epoch: 263 loss: 2.3026418685913086 grad: 1.2587550962565555\n",
      "epoch: 264 loss: 2.302450180053711 grad: 1.2681074532336511\n",
      "epoch: 265 loss: 2.302612066268921 grad: 1.2561386480524634\n",
      "epoch: 266 loss: 2.302480697631836 grad: 1.2568991605639606\n",
      "epoch: 267 loss: 2.3024580478668213 grad: 1.265607990219169\n",
      "epoch: 268 loss: 2.3027498722076416 grad: 1.2643035399442952\n",
      "epoch: 269 loss: 2.3026444911956787 grad: 1.268099167495079\n",
      "epoch: 270 loss: 2.3019702434539795 grad: 1.2730037601265525\n",
      "epoch: 271 loss: 2.302680015563965 grad: 1.2645769735838892\n",
      "epoch: 272 loss: 2.3026514053344727 grad: 1.2600402969308937\n",
      "epoch: 273 loss: 2.302988290786743 grad: 1.261723154414785\n",
      "epoch: 274 loss: 2.3023152351379395 grad: 1.270333750421063\n",
      "epoch: 275 loss: 2.303061008453369 grad: 1.255650690224554\n",
      "epoch: 276 loss: 2.3032963275909424 grad: 1.2658623846022352\n",
      "epoch: 277 loss: 2.3028626441955566 grad: 1.2660266170093406\n",
      "epoch: 278 loss: 2.3027267456054688 grad: 1.2680629434633173\n",
      "epoch: 279 loss: 2.3025245666503906 grad: 1.2614572483783824\n",
      "epoch: 280 loss: 2.3025684356689453 grad: 1.2648309706895065\n",
      "epoch: 281 loss: 2.302673578262329 grad: 1.2693645564233145\n",
      "epoch: 282 loss: 2.3029165267944336 grad: 1.2547802081690096\n",
      "epoch: 283 loss: 2.3027732372283936 grad: 1.2666489960854903\n",
      "epoch: 284 loss: 2.302830457687378 grad: 1.2593771594831542\n",
      "epoch: 285 loss: 2.3025782108306885 grad: 1.2612539959779483\n",
      "epoch: 286 loss: 2.3028504848480225 grad: 1.2551373962020975\n",
      "epoch: 287 loss: 2.302417755126953 grad: 1.2707131911523728\n",
      "epoch: 288 loss: 2.302854299545288 grad: 1.2592370031634346\n",
      "epoch: 289 loss: 2.3029396533966064 grad: 1.2652156918553548\n",
      "epoch: 290 loss: 2.3026907444000244 grad: 1.253251246110137\n",
      "epoch: 291 loss: 2.30234432220459 grad: 1.2572352700323488\n",
      "epoch: 292 loss: 2.303636074066162 grad: 1.2493278351760218\n",
      "epoch: 293 loss: 2.302003860473633 grad: 1.2785478231500804\n",
      "epoch: 294 loss: 2.3027536869049072 grad: 1.2616140688603212\n",
      "epoch: 295 loss: 2.302504301071167 grad: 1.2670969425733867\n",
      "epoch: 296 loss: 2.3026630878448486 grad: 1.25494509876617\n",
      "epoch: 297 loss: 2.3026516437530518 grad: 1.2577541118214233\n",
      "epoch: 298 loss: 2.3027963638305664 grad: 1.259093852205542\n",
      "epoch: 299 loss: 2.302464485168457 grad: 1.2468060704783375\n",
      "epoch: 300 loss: 2.3025436401367188 grad: 1.2640017876142844\n",
      "epoch: 301 loss: 2.3026411533355713 grad: 1.2689746556016395\n",
      "epoch: 302 loss: 2.3022050857543945 grad: 1.2642129665122381\n",
      "epoch: 303 loss: 2.302910804748535 grad: 1.2671093285113337\n",
      "epoch: 304 loss: 2.302729606628418 grad: 1.2548718789910218\n",
      "epoch: 305 loss: 2.3023135662078857 grad: 1.2661718459049653\n",
      "epoch: 306 loss: 2.302901268005371 grad: 1.2666849909583107\n",
      "epoch: 307 loss: 2.3020482063293457 grad: 1.269835321737143\n",
      "epoch: 308 loss: 2.3022446632385254 grad: 1.2701219575708762\n",
      "epoch: 309 loss: 2.302401065826416 grad: 1.2620855380821647\n",
      "epoch: 310 loss: 2.301992893218994 grad: 1.279351206549946\n",
      "epoch: 311 loss: 2.3026065826416016 grad: 1.25954306298416\n",
      "epoch: 312 loss: 2.302968740463257 grad: 1.2531919383225845\n",
      "epoch: 313 loss: 2.3028783798217773 grad: 1.2656225165378094\n",
      "epoch: 314 loss: 2.3019514083862305 grad: 1.2675517427638943\n",
      "epoch: 315 loss: 2.302635669708252 grad: 1.2652822580125684\n",
      "epoch: 316 loss: 2.3036065101623535 grad: 1.2473560170370288\n",
      "epoch: 317 loss: 2.3021819591522217 grad: 1.268782647749749\n",
      "epoch: 318 loss: 2.302703857421875 grad: 1.2639462898618408\n",
      "epoch: 319 loss: 2.3025131225585938 grad: 1.2668190313048573\n",
      "epoch: 320 loss: 2.3029656410217285 grad: 1.2677412672330521\n",
      "epoch: 321 loss: 2.3031251430511475 grad: 1.2629549517684306\n",
      "epoch: 322 loss: 2.303154230117798 grad: 1.2601862761971823\n",
      "epoch: 323 loss: 2.3024747371673584 grad: 1.263389764324067\n",
      "epoch: 324 loss: 2.302030086517334 grad: 1.2695077164024706\n",
      "epoch: 325 loss: 2.3022923469543457 grad: 1.269904324406063\n",
      "epoch: 326 loss: 2.3024415969848633 grad: 1.265442134989869\n",
      "epoch: 327 loss: 2.3027830123901367 grad: 1.259545932538689\n",
      "epoch: 328 loss: 2.3026957511901855 grad: 1.272043593863528\n",
      "epoch: 329 loss: 2.3025739192962646 grad: 1.2641207876722402\n",
      "epoch: 330 loss: 2.3028318881988525 grad: 1.264124924965602\n",
      "epoch: 331 loss: 2.302607536315918 grad: 1.261904361406489\n",
      "epoch: 332 loss: 2.302643060684204 grad: 1.2692433746646172\n",
      "epoch: 333 loss: 2.3028371334075928 grad: 1.2598164035543238\n",
      "epoch: 334 loss: 2.302978038787842 grad: 1.2544464808445246\n",
      "epoch: 335 loss: 2.3028202056884766 grad: 1.2681476110093561\n",
      "epoch: 336 loss: 2.303084373474121 grad: 1.264026321343235\n",
      "epoch: 337 loss: 2.3025174140930176 grad: 1.2606245856824523\n",
      "epoch: 338 loss: 2.3020172119140625 grad: 1.2665426965769646\n",
      "epoch: 339 loss: 2.3024868965148926 grad: 1.270461602522696\n",
      "epoch: 340 loss: 2.302248239517212 grad: 1.2686679900572118\n",
      "epoch: 341 loss: 2.3028719425201416 grad: 1.26073004408843\n",
      "epoch: 342 loss: 2.3033504486083984 grad: 1.2608251503358285\n",
      "epoch: 343 loss: 2.3027007579803467 grad: 1.258973685418448\n",
      "epoch: 344 loss: 2.3029885292053223 grad: 1.2731900096590083\n",
      "epoch: 345 loss: 2.303053379058838 grad: 1.257723988638082\n",
      "epoch: 346 loss: 2.3026745319366455 grad: 1.2699673235349889\n",
      "epoch: 347 loss: 2.302673816680908 grad: 1.2745090676878121\n",
      "epoch: 348 loss: 2.302863121032715 grad: 1.2584415071788022\n",
      "epoch: 349 loss: 2.302316188812256 grad: 1.2637344158738704\n",
      "epoch: 350 loss: 2.3026487827301025 grad: 1.2598804908449805\n",
      "epoch: 351 loss: 2.302703857421875 grad: 1.2701751575805247\n",
      "epoch: 352 loss: 2.3021883964538574 grad: 1.2687723157439559\n",
      "epoch: 353 loss: 2.3024823665618896 grad: 1.2678107548032016\n",
      "epoch: 354 loss: 2.302623987197876 grad: 1.262760824285492\n",
      "epoch: 355 loss: 2.3029565811157227 grad: 1.2558848089113506\n",
      "epoch: 356 loss: 2.3023176193237305 grad: 1.2665054059757421\n",
      "epoch: 357 loss: 2.3023810386657715 grad: 1.265664675424526\n",
      "epoch: 358 loss: 2.302485227584839 grad: 1.2715622359251102\n",
      "epoch: 359 loss: 2.30253267288208 grad: 1.2731280980783233\n",
      "epoch: 360 loss: 2.3024275302886963 grad: 1.2721290401633947\n",
      "epoch: 361 loss: 2.3026797771453857 grad: 1.2685713016830886\n",
      "epoch: 362 loss: 2.302241802215576 grad: 1.2736034436624437\n",
      "epoch: 363 loss: 2.3029537200927734 grad: 1.2638930262118164\n",
      "epoch: 364 loss: 2.302034378051758 grad: 1.27229473448085\n",
      "epoch: 365 loss: 2.3024730682373047 grad: 1.264105874738316\n",
      "epoch: 366 loss: 2.3027560710906982 grad: 1.2690102449426102\n",
      "epoch: 367 loss: 2.303222179412842 grad: 1.25837931755398\n",
      "epoch: 368 loss: 2.3031458854675293 grad: 1.254139555255986\n",
      "epoch: 369 loss: 2.302968740463257 grad: 1.2658298718354974\n",
      "epoch: 370 loss: 2.301881790161133 grad: 1.2805840724243944\n",
      "epoch: 371 loss: 2.302213668823242 grad: 1.2677760995159457\n",
      "epoch: 372 loss: 2.302870035171509 grad: 1.2542193061228664\n",
      "epoch: 373 loss: 2.30283260345459 grad: 1.2658733004530418\n",
      "epoch: 374 loss: 2.302405834197998 grad: 1.271583415752661\n",
      "epoch: 375 loss: 2.3023502826690674 grad: 1.2775526864247189\n",
      "epoch: 376 loss: 2.303217887878418 grad: 1.2658646916693432\n",
      "epoch: 377 loss: 2.3028790950775146 grad: 1.2597939207177935\n",
      "epoch: 378 loss: 2.3022491931915283 grad: 1.2644174618180841\n",
      "epoch: 379 loss: 2.3024423122406006 grad: 1.2665387164184174\n",
      "epoch: 380 loss: 2.302171230316162 grad: 1.2702977015315333\n",
      "epoch: 381 loss: 2.301513433456421 grad: 1.2878545089920481\n",
      "epoch: 382 loss: 2.3026227951049805 grad: 1.2681781010580293\n",
      "epoch: 383 loss: 2.3022243976593018 grad: 1.2754049785878687\n",
      "epoch: 384 loss: 2.3029959201812744 grad: 1.2665851788174005\n",
      "epoch: 385 loss: 2.3031458854675293 grad: 1.2628312557603099\n",
      "epoch: 386 loss: 2.302236557006836 grad: 1.2738428468786416\n",
      "epoch: 387 loss: 2.30269193649292 grad: 1.2628655679937866\n",
      "epoch: 388 loss: 2.3027560710906982 grad: 1.248984185392998\n",
      "epoch: 389 loss: 2.302225112915039 grad: 1.272394365106251\n",
      "epoch: 390 loss: 2.3027942180633545 grad: 1.2630161929927353\n",
      "epoch: 391 loss: 2.3028228282928467 grad: 1.2685083012237022\n",
      "epoch: 392 loss: 2.3025619983673096 grad: 1.2660094209233417\n",
      "epoch: 393 loss: 2.3029065132141113 grad: 1.249497554636383\n",
      "epoch: 394 loss: 2.302699565887451 grad: 1.2728154803903418\n",
      "epoch: 395 loss: 2.3025918006896973 grad: 1.2707067414497335\n",
      "epoch: 396 loss: 2.3020761013031006 grad: 1.2729188613501186\n",
      "epoch: 397 loss: 2.302426815032959 grad: 1.2737813035473375\n",
      "epoch: 398 loss: 2.303157091140747 grad: 1.2557447527679393\n",
      "epoch: 399 loss: 2.3023035526275635 grad: 1.2745205996528504\n",
      "epoch: 400 loss: 2.3026926517486572 grad: 1.2704955581908248\n",
      "epoch: 401 loss: 2.302557945251465 grad: 1.2638876870762379\n",
      "epoch: 402 loss: 2.301759958267212 grad: 1.2791563622073256\n",
      "epoch: 403 loss: 2.3025312423706055 grad: 1.267803747439757\n",
      "epoch: 404 loss: 2.3027942180633545 grad: 1.2713131031099085\n",
      "epoch: 405 loss: 2.302265167236328 grad: 1.2806809039099054\n",
      "epoch: 406 loss: 2.302767276763916 grad: 1.2670866719554252\n",
      "epoch: 407 loss: 2.302168846130371 grad: 1.276292825710871\n",
      "epoch: 408 loss: 2.3030149936676025 grad: 1.2605186748662076\n",
      "epoch: 409 loss: 2.3025598526000977 grad: 1.2678448038752235\n",
      "epoch: 410 loss: 2.303088903427124 grad: 1.2580621445751083\n",
      "epoch: 411 loss: 2.3031105995178223 grad: 1.2635863380181411\n",
      "epoch: 412 loss: 2.3026163578033447 grad: 1.270036753934128\n",
      "epoch: 413 loss: 2.3022074699401855 grad: 1.2750042604822074\n",
      "epoch: 414 loss: 2.3021059036254883 grad: 1.2781133692460283\n",
      "epoch: 415 loss: 2.3020949363708496 grad: 1.2577058047920997\n",
      "epoch: 416 loss: 2.3026299476623535 grad: 1.2723927496976795\n",
      "epoch: 417 loss: 2.30293345451355 grad: 1.2682501392250525\n",
      "epoch: 418 loss: 2.3023087978363037 grad: 1.2696288921020276\n",
      "epoch: 419 loss: 2.3019297122955322 grad: 1.2805950527859202\n",
      "epoch: 420 loss: 2.3021674156188965 grad: 1.2874697959364674\n",
      "epoch: 421 loss: 2.302708387374878 grad: 1.2670502234102479\n",
      "epoch: 422 loss: 2.301879405975342 grad: 1.2870829574955953\n",
      "epoch: 423 loss: 2.3028693199157715 grad: 1.2735845483784076\n",
      "epoch: 424 loss: 2.3034629821777344 grad: 1.2596591010501252\n",
      "epoch: 425 loss: 2.3023481369018555 grad: 1.2701056047143149\n",
      "epoch: 426 loss: 2.302781343460083 grad: 1.2634990526869567\n",
      "epoch: 427 loss: 2.301990270614624 grad: 1.2781275986594014\n",
      "epoch: 428 loss: 2.301776647567749 grad: 1.28488237957751\n",
      "epoch: 429 loss: 2.302316904067993 grad: 1.2736589321737282\n",
      "epoch: 430 loss: 2.303199291229248 grad: 1.2645412761965649\n",
      "epoch: 431 loss: 2.302495002746582 grad: 1.2695102844875128\n",
      "epoch: 432 loss: 2.302880048751831 grad: 1.2556162653158285\n",
      "epoch: 433 loss: 2.3023533821105957 grad: 1.2695103847709972\n",
      "epoch: 434 loss: 2.302730083465576 grad: 1.2672745490941915\n",
      "epoch: 435 loss: 2.3025550842285156 grad: 1.266701620973883\n",
      "epoch: 436 loss: 2.3029537200927734 grad: 1.2621967577752435\n",
      "epoch: 437 loss: 2.3022801876068115 grad: 1.280519420986936\n",
      "epoch: 438 loss: 2.3022966384887695 grad: 1.2570980354415489\n",
      "epoch: 439 loss: 2.3017282485961914 grad: 1.2874262192922215\n",
      "epoch: 440 loss: 2.3024134635925293 grad: 1.2688371774200942\n",
      "epoch: 441 loss: 2.3022334575653076 grad: 1.2759779816500783\n",
      "epoch: 442 loss: 2.3018240928649902 grad: 1.282035932319963\n",
      "epoch: 443 loss: 2.3024113178253174 grad: 1.2678187945968515\n",
      "epoch: 444 loss: 2.30206561088562 grad: 1.2872646615696361\n",
      "epoch: 445 loss: 2.3023152351379395 grad: 1.27215578369168\n",
      "epoch: 446 loss: 2.3026371002197266 grad: 1.272951080874052\n",
      "epoch: 447 loss: 2.3025197982788086 grad: 1.2724241026148702\n",
      "epoch: 448 loss: 2.302424907684326 grad: 1.2776081179294527\n",
      "epoch: 449 loss: 2.302424907684326 grad: 1.2756262225753052\n",
      "epoch: 450 loss: 2.3019204139709473 grad: 1.2771612066675775\n",
      "epoch: 451 loss: 2.30263352394104 grad: 1.2633324806848245\n",
      "epoch: 452 loss: 2.301835298538208 grad: 1.279069551813697\n",
      "epoch: 453 loss: 2.3022053241729736 grad: 1.2721184311870721\n",
      "epoch: 454 loss: 2.302272319793701 grad: 1.2723933703558046\n",
      "epoch: 455 loss: 2.302522897720337 grad: 1.2665610065801987\n",
      "epoch: 456 loss: 2.302422046661377 grad: 1.2754025393191517\n",
      "epoch: 457 loss: 2.3023531436920166 grad: 1.2837025449437547\n",
      "epoch: 458 loss: 2.3023273944854736 grad: 1.2808446965294904\n",
      "epoch: 459 loss: 2.302807331085205 grad: 1.272562742185232\n",
      "epoch: 460 loss: 2.302492141723633 grad: 1.2753127418414114\n",
      "epoch: 461 loss: 2.3027255535125732 grad: 1.2769218076885278\n",
      "epoch: 462 loss: 2.3024909496307373 grad: 1.28578073574814\n",
      "epoch: 463 loss: 2.3020706176757812 grad: 1.2867388712216377\n",
      "epoch: 464 loss: 2.3026416301727295 grad: 1.265797698740951\n",
      "epoch: 465 loss: 2.3020856380462646 grad: 1.2808785601519048\n",
      "epoch: 466 loss: 2.3021857738494873 grad: 1.2861444520863838\n",
      "epoch: 467 loss: 2.302448272705078 grad: 1.2742523784132025\n",
      "epoch: 468 loss: 2.302541494369507 grad: 1.2752155994586203\n",
      "epoch: 469 loss: 2.302246570587158 grad: 1.27886438839108\n",
      "epoch: 470 loss: 2.302600860595703 grad: 1.2759468566722398\n",
      "epoch: 471 loss: 2.3027026653289795 grad: 1.2628426797991057\n",
      "epoch: 472 loss: 2.302419424057007 grad: 1.2757739332589573\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 473 loss: 2.302663803100586 grad: 1.2885673651785872\n",
      "epoch: 474 loss: 2.302187442779541 grad: 1.2849210155832151\n",
      "epoch: 475 loss: 2.3019936084747314 grad: 1.2914475975909256\n",
      "epoch: 476 loss: 2.302521228790283 grad: 1.2809473582938875\n",
      "epoch: 477 loss: 2.3023037910461426 grad: 1.2677126469086886\n",
      "epoch: 478 loss: 2.3026838302612305 grad: 1.2610037975708053\n",
      "epoch: 479 loss: 2.3027944564819336 grad: 1.2723924635672972\n",
      "epoch: 480 loss: 2.302391290664673 grad: 1.2855751251391623\n",
      "epoch: 481 loss: 2.302277088165283 grad: 1.2794366948350908\n",
      "epoch: 482 loss: 2.3025035858154297 grad: 1.2808830676552292\n",
      "epoch: 483 loss: 2.302333116531372 grad: 1.2715397992666575\n",
      "epoch: 484 loss: 2.302642345428467 grad: 1.2740533804458136\n",
      "epoch: 485 loss: 2.3026187419891357 grad: 1.2692431732310012\n",
      "epoch: 486 loss: 2.302173376083374 grad: 1.2873651042270164\n",
      "epoch: 487 loss: 2.302156448364258 grad: 1.2825426688669102\n",
      "epoch: 488 loss: 2.3026492595672607 grad: 1.272068932040831\n",
      "epoch: 489 loss: 2.302623987197876 grad: 1.2707353170392\n",
      "epoch: 490 loss: 2.302056312561035 grad: 1.2875951924194982\n",
      "epoch: 491 loss: 2.3032002449035645 grad: 1.2648024726437317\n",
      "epoch: 492 loss: 2.3025259971618652 grad: 1.274940338346087\n",
      "epoch: 493 loss: 2.302691698074341 grad: 1.2849175302175035\n",
      "epoch: 494 loss: 2.3033649921417236 grad: 1.2636429341047972\n",
      "epoch: 495 loss: 2.3023860454559326 grad: 1.2712084973094215\n",
      "epoch: 496 loss: 2.3020596504211426 grad: 1.283366625032772\n",
      "epoch: 497 loss: 2.3027853965759277 grad: 1.2623381107687093\n",
      "epoch: 498 loss: 2.3023219108581543 grad: 1.2733558564066207\n",
      "epoch: 499 loss: 2.3017427921295166 grad: 1.282865730356351\n",
      "2.302170068025589\n",
      "epoch: 0 loss: 2.3038735389709473 grad: 1.2068328885989825\n",
      "epoch: 1 loss: 2.303086996078491 grad: 1.191225015268188\n",
      "epoch: 2 loss: 2.3026769161224365 grad: 1.1836477874349507\n",
      "epoch: 3 loss: 2.302529811859131 grad: 1.187239248470019\n",
      "epoch: 4 loss: 2.302464008331299 grad: 1.171103223165985\n",
      "epoch: 5 loss: 2.3025596141815186 grad: 1.1827991817900467\n",
      "epoch: 6 loss: 2.3021721839904785 grad: 1.1779164519578602\n",
      "epoch: 7 loss: 2.30264949798584 grad: 1.1901521383939933\n",
      "epoch: 8 loss: 2.30202054977417 grad: 1.1988637393565909\n",
      "epoch: 9 loss: 2.3019962310791016 grad: 1.2103504820205715\n",
      "epoch: 10 loss: 2.3027193546295166 grad: 1.2073835841738545\n",
      "epoch: 11 loss: 2.302551031112671 grad: 1.209443347232919\n",
      "epoch: 12 loss: 2.3011999130249023 grad: 1.2138814883794458\n",
      "epoch: 13 loss: 2.301985025405884 grad: 1.2229701363341143\n",
      "epoch: 14 loss: 2.3008298873901367 grad: 1.2486600095372913\n",
      "epoch: 15 loss: 2.3011391162872314 grad: 1.2724403076590822\n",
      "epoch: 16 loss: 2.3009326457977295 grad: 1.2950562675417001\n",
      "epoch: 17 loss: 2.3011271953582764 grad: 1.2875041621071952\n",
      "epoch: 18 loss: 2.3010106086730957 grad: 1.30710338188764\n",
      "epoch: 19 loss: 2.3008384704589844 grad: 1.3123365897326804\n",
      "epoch: 20 loss: 2.3003714084625244 grad: 1.3448874297670075\n",
      "epoch: 21 loss: 2.2984492778778076 grad: 1.4277882708720715\n",
      "epoch: 22 loss: 2.3000757694244385 grad: 1.4191196101499604\n",
      "epoch: 23 loss: 2.297797679901123 grad: 1.4724958707737397\n",
      "epoch: 24 loss: 2.2989420890808105 grad: 1.4413320814658488\n",
      "epoch: 25 loss: 2.2977254390716553 grad: 1.5286211376411043\n",
      "epoch: 26 loss: 2.297506809234619 grad: 1.5248333395676805\n",
      "epoch: 27 loss: 2.295985698699951 grad: 1.5840307959809987\n",
      "epoch: 28 loss: 2.295069694519043 grad: 1.6260054912935529\n",
      "epoch: 29 loss: 2.2955942153930664 grad: 1.6452827224422926\n",
      "epoch: 30 loss: 2.2956464290618896 grad: 1.6219706279502826\n",
      "epoch: 31 loss: 2.2960338592529297 grad: 1.6208181111178996\n",
      "epoch: 32 loss: 2.295811891555786 grad: 1.5898402257885282\n",
      "epoch: 33 loss: 2.294138193130493 grad: 1.5963409314549246\n",
      "epoch: 34 loss: 2.295623540878296 grad: 1.5835404585352137\n",
      "epoch: 35 loss: 2.2941431999206543 grad: 1.5976713966256717\n",
      "epoch: 36 loss: 2.2935283184051514 grad: 1.6033557628721207\n",
      "epoch: 37 loss: 2.294280529022217 grad: 1.600796679132766\n",
      "epoch: 38 loss: 2.2930939197540283 grad: 1.5592784849956396\n",
      "epoch: 39 loss: 2.293119192123413 grad: 1.5579171942266088\n",
      "epoch: 40 loss: 2.2917227745056152 grad: 1.5999179676688824\n",
      "epoch: 41 loss: 2.2947404384613037 grad: 1.5759964290810453\n",
      "epoch: 42 loss: 2.291612386703491 grad: 1.5633027030077453\n",
      "epoch: 43 loss: 2.2909295558929443 grad: 1.602256611429362\n",
      "epoch: 44 loss: 2.2891578674316406 grad: 1.590811942971962\n",
      "epoch: 45 loss: 2.2912333011627197 grad: 1.6013467330688846\n",
      "epoch: 46 loss: 2.293231964111328 grad: 1.5558045330135861\n",
      "epoch: 47 loss: 2.28975772857666 grad: 1.5664870534147624\n",
      "epoch: 48 loss: 2.2872395515441895 grad: 1.6264237384274898\n",
      "epoch: 49 loss: 2.290416955947876 grad: 1.6322642919267454\n",
      "epoch: 50 loss: 2.291264295578003 grad: 1.5940456654791468\n",
      "epoch: 51 loss: 2.289294481277466 grad: 1.5934126527835837\n",
      "epoch: 52 loss: 2.289318323135376 grad: 1.5856225813539433\n",
      "epoch: 53 loss: 2.2901527881622314 grad: 1.6094539845639484\n",
      "epoch: 54 loss: 2.287020206451416 grad: 1.5849158335495592\n",
      "epoch: 55 loss: 2.2874746322631836 grad: 1.6103285097642728\n",
      "epoch: 56 loss: 2.283808946609497 grad: 1.6286839012311594\n",
      "epoch: 57 loss: 2.288163900375366 grad: 1.6187297208271625\n",
      "epoch: 58 loss: 2.2869954109191895 grad: 1.6353437357752154\n",
      "epoch: 59 loss: 2.286806583404541 grad: 1.6444535033854966\n",
      "epoch: 60 loss: 2.2868571281433105 grad: 1.610676598234383\n",
      "epoch: 61 loss: 2.285348653793335 grad: 1.6382091855722671\n",
      "epoch: 62 loss: 2.2843520641326904 grad: 1.6588255511356578\n",
      "epoch: 63 loss: 2.282470703125 grad: 1.6527554848931716\n",
      "epoch: 64 loss: 2.284003973007202 grad: 1.6207989522862056\n",
      "epoch: 65 loss: 2.284029483795166 grad: 1.634394391897201\n",
      "epoch: 66 loss: 2.2837705612182617 grad: 1.701802257542676\n",
      "epoch: 67 loss: 2.2799160480499268 grad: 1.6861787700290156\n",
      "epoch: 68 loss: 2.2805986404418945 grad: 1.6476222851520612\n",
      "epoch: 69 loss: 2.2812752723693848 grad: 1.7245153298117368\n",
      "epoch: 70 loss: 2.281680107116699 grad: 1.6893291089735512\n",
      "epoch: 71 loss: 2.2797770500183105 grad: 1.7939043730028004\n",
      "epoch: 72 loss: 2.2799384593963623 grad: 1.7659577426504314\n",
      "epoch: 73 loss: 2.280426025390625 grad: 1.7575346772292895\n",
      "epoch: 74 loss: 2.278298854827881 grad: 1.7577834856578163\n",
      "epoch: 75 loss: 2.2776284217834473 grad: 1.8125138244377301\n",
      "epoch: 76 loss: 2.274876832962036 grad: 1.818379604824937\n",
      "epoch: 77 loss: 2.274890422821045 grad: 1.9345805033494436\n",
      "epoch: 78 loss: 2.2726857662200928 grad: 1.9563624491187048\n",
      "epoch: 79 loss: 2.2717320919036865 grad: 2.030711269741582\n",
      "epoch: 80 loss: 2.2695765495300293 grad: 2.1444798680484323\n",
      "epoch: 81 loss: 2.266474723815918 grad: 2.221051981898084\n",
      "epoch: 82 loss: 2.26139235496521 grad: 2.2917584795671115\n",
      "epoch: 83 loss: 2.2581186294555664 grad: 2.3766366349337327\n",
      "epoch: 84 loss: 2.2540242671966553 grad: 2.353444661618033\n",
      "epoch: 85 loss: 2.247864007949829 grad: 2.3677639672569635\n",
      "epoch: 86 loss: 2.2487313747406006 grad: 2.3834873049885834\n",
      "epoch: 87 loss: 2.246706247329712 grad: 2.3280380881624296\n",
      "epoch: 88 loss: 2.2442150115966797 grad: 2.2665905953396024\n",
      "epoch: 89 loss: 2.2394065856933594 grad: 2.256596588537038\n",
      "epoch: 90 loss: 2.237842321395874 grad: 2.1896544216858547\n",
      "epoch: 91 loss: 2.236909866333008 grad: 2.246520833709159\n",
      "epoch: 92 loss: 2.235507011413574 grad: 2.2277005537494365\n",
      "epoch: 93 loss: 2.2353153228759766 grad: 2.164353774189727\n",
      "epoch: 94 loss: 2.237321376800537 grad: 2.18339942643855\n",
      "epoch: 95 loss: 2.2308948040008545 grad: 2.183222731118948\n",
      "epoch: 96 loss: 2.233665704727173 grad: 2.2527221370366446\n",
      "epoch: 97 loss: 2.232381820678711 grad: 2.250830307054067\n",
      "epoch: 98 loss: 2.226799964904785 grad: 2.197948920869431\n",
      "epoch: 99 loss: 2.2300643920898438 grad: 2.270267359127054\n",
      "epoch: 100 loss: 2.227158546447754 grad: 2.2773655192808264\n",
      "epoch: 101 loss: 2.2273621559143066 grad: 2.235431744953588\n",
      "epoch: 102 loss: 2.2283663749694824 grad: 2.281937188744205\n",
      "epoch: 103 loss: 2.225813150405884 grad: 2.250983955896652\n",
      "epoch: 104 loss: 2.2257637977600098 grad: 2.3294895667035784\n",
      "epoch: 105 loss: 2.224853515625 grad: 2.275325215131503\n",
      "epoch: 106 loss: 2.225651979446411 grad: 2.316897285351944\n",
      "epoch: 107 loss: 2.225290298461914 grad: 2.3787899849223093\n",
      "epoch: 108 loss: 2.2221570014953613 grad: 2.435695168126138\n",
      "epoch: 109 loss: 2.2203996181488037 grad: 2.3881619770674862\n",
      "epoch: 110 loss: 2.2195043563842773 grad: 2.4121192857782017\n",
      "epoch: 111 loss: 2.2251503467559814 grad: 2.3935804263566665\n",
      "epoch: 112 loss: 2.2207188606262207 grad: 2.38688472926151\n",
      "epoch: 113 loss: 2.2180051803588867 grad: 2.4315713019893757\n",
      "epoch: 114 loss: 2.219850778579712 grad: 2.542428977179548\n",
      "epoch: 115 loss: 2.2156620025634766 grad: 2.510654809954946\n",
      "epoch: 116 loss: 2.2164554595947266 grad: 2.542691397896436\n",
      "epoch: 117 loss: 2.2130205631256104 grad: 2.647320810762707\n",
      "epoch: 118 loss: 2.214019536972046 grad: 2.5403502495656354\n",
      "epoch: 119 loss: 2.2143802642822266 grad: 2.6952290463645663\n",
      "epoch: 120 loss: 2.211791753768921 grad: 2.660554644123222\n",
      "epoch: 121 loss: 2.212233066558838 grad: 2.6838347896164847\n",
      "epoch: 122 loss: 2.211151123046875 grad: 2.645294221005373\n",
      "epoch: 123 loss: 2.212153196334839 grad: 2.6930600449901134\n",
      "epoch: 124 loss: 2.2124955654144287 grad: 2.717363806903392\n",
      "epoch: 125 loss: 2.2139618396759033 grad: 2.7527695773354184\n",
      "epoch: 126 loss: 2.208519458770752 grad: 2.750858758445016\n",
      "epoch: 127 loss: 2.209750175476074 grad: 2.8763560238663874\n",
      "epoch: 128 loss: 2.207313060760498 grad: 2.9240086643313545\n",
      "epoch: 129 loss: 2.2089059352874756 grad: 2.724550525604245\n",
      "epoch: 130 loss: 2.2070107460021973 grad: 2.7721317545843442\n",
      "epoch: 131 loss: 2.2069365978240967 grad: 2.9356570643638924\n",
      "epoch: 132 loss: 2.2032086849212646 grad: 2.8640074512296696\n",
      "epoch: 133 loss: 2.206169605255127 grad: 3.026390788603633\n",
      "epoch: 134 loss: 2.20330810546875 grad: 2.9478802640944544\n",
      "epoch: 135 loss: 2.1993277072906494 grad: 2.8686889930949766\n",
      "epoch: 136 loss: 2.2037408351898193 grad: 3.0393436532800218\n",
      "epoch: 137 loss: 2.2005269527435303 grad: 3.0668677014320913\n",
      "epoch: 138 loss: 2.1988582611083984 grad: 2.982129078971902\n",
      "epoch: 139 loss: 2.199881076812744 grad: 2.980800157904418\n",
      "epoch: 140 loss: 2.200291633605957 grad: 3.0187627254238736\n",
      "epoch: 141 loss: 2.1991841793060303 grad: 3.0965524136240314\n",
      "epoch: 142 loss: 2.2007052898406982 grad: 3.0539688500538764\n",
      "epoch: 143 loss: 2.1966044902801514 grad: 3.246992530364041\n",
      "epoch: 144 loss: 2.195653200149536 grad: 2.9415181420285195\n",
      "epoch: 145 loss: 2.190251111984253 grad: 3.0925684292904205\n",
      "epoch: 146 loss: 2.193387508392334 grad: 3.064013190157268\n",
      "epoch: 147 loss: 2.1918914318084717 grad: 3.217158711999507\n",
      "epoch: 148 loss: 2.1903274059295654 grad: 3.2600349840016976\n",
      "epoch: 149 loss: 2.192375421524048 grad: 3.176313413384681\n",
      "epoch: 150 loss: 2.1915178298950195 grad: 3.151106258325781\n",
      "epoch: 151 loss: 2.1905806064605713 grad: 3.320856775563683\n",
      "epoch: 152 loss: 2.191458225250244 grad: 3.3266341929649195\n",
      "epoch: 153 loss: 2.1837716102600098 grad: 3.2178577107399526\n",
      "epoch: 154 loss: 2.187356472015381 grad: 3.4250852407976273\n",
      "epoch: 155 loss: 2.189225912094116 grad: 3.3152904798727603\n",
      "epoch: 156 loss: 2.1874101161956787 grad: 3.3299665338921525\n",
      "epoch: 157 loss: 2.1862642765045166 grad: 3.382110571839832\n",
      "epoch: 158 loss: 2.1851561069488525 grad: 3.3810810319754103\n",
      "epoch: 159 loss: 2.179219961166382 grad: 3.2600671782062225\n",
      "epoch: 160 loss: 2.184947967529297 grad: 3.4585408674079985\n",
      "epoch: 161 loss: 2.185494899749756 grad: 3.396378511422506\n",
      "epoch: 162 loss: 2.1827352046966553 grad: 3.446078577437364\n",
      "epoch: 163 loss: 2.1801555156707764 grad: 3.66661133042108\n",
      "epoch: 164 loss: 2.1781418323516846 grad: 3.5088789114684222\n",
      "epoch: 165 loss: 2.179415702819824 grad: 3.6054719913019135\n",
      "epoch: 166 loss: 2.177042245864868 grad: 3.501028121611665\n",
      "epoch: 167 loss: 2.1760270595550537 grad: 3.577535719270744\n",
      "epoch: 168 loss: 2.1775150299072266 grad: 3.6223309881918664\n",
      "epoch: 169 loss: 2.177689790725708 grad: 3.5717389831385975\n",
      "epoch: 170 loss: 2.176060914993286 grad: 3.7019594416451005\n",
      "epoch: 171 loss: 2.1731576919555664 grad: 3.4497040865114994\n",
      "epoch: 172 loss: 2.172630786895752 grad: 3.7245900420109845\n",
      "epoch: 173 loss: 2.1699211597442627 grad: 3.686889589775265\n",
      "epoch: 174 loss: 2.17682147026062 grad: 3.559618204495766\n",
      "epoch: 175 loss: 2.1752939224243164 grad: 3.7395247741166266\n",
      "epoch: 176 loss: 2.1729111671447754 grad: 3.639600029115432\n",
      "epoch: 177 loss: 2.1701624393463135 grad: 3.7299971847262765\n",
      "epoch: 178 loss: 2.1771349906921387 grad: 3.8721300170402086\n",
      "epoch: 179 loss: 2.168715238571167 grad: 3.8808744307053056\n",
      "epoch: 180 loss: 2.176431655883789 grad: 3.844845821637483\n",
      "epoch: 181 loss: 2.1701157093048096 grad: 3.7726805835947514\n",
      "epoch: 182 loss: 2.1736867427825928 grad: 4.006395912614637\n",
      "epoch: 183 loss: 2.165377616882324 grad: 3.8725364815428973\n",
      "epoch: 184 loss: 2.169407606124878 grad: 4.049318083284778\n",
      "epoch: 185 loss: 2.158609628677368 grad: 3.7519423497049877\n",
      "epoch: 186 loss: 2.1637868881225586 grad: 4.049862625838686\n",
      "epoch: 187 loss: 2.1677656173706055 grad: 4.163254308817346\n",
      "epoch: 188 loss: 2.1653311252593994 grad: 3.7372767953941275\n",
      "epoch: 189 loss: 2.1591312885284424 grad: 3.9544213212073025\n",
      "epoch: 190 loss: 2.16387939453125 grad: 4.049203562627857\n",
      "epoch: 191 loss: 2.1611814498901367 grad: 4.012700761612948\n",
      "epoch: 192 loss: 2.168281078338623 grad: 4.027634326205958\n",
      "epoch: 193 loss: 2.15756893157959 grad: 3.918832564327334\n",
      "epoch: 194 loss: 2.15973162651062 grad: 3.9383227546433255\n",
      "epoch: 195 loss: 2.159615993499756 grad: 4.065092820714834\n",
      "epoch: 196 loss: 2.1606125831604004 grad: 3.884936632396328\n",
      "epoch: 197 loss: 2.1572787761688232 grad: 4.119999300115668\n",
      "epoch: 198 loss: 2.1614370346069336 grad: 4.157020943250418\n",
      "epoch: 199 loss: 2.1582274436950684 grad: 4.142210787184359\n",
      "epoch: 200 loss: 2.15950083732605 grad: 4.345590698303625\n",
      "epoch: 201 loss: 2.1591436862945557 grad: 4.03595061035132\n",
      "epoch: 202 loss: 2.1618990898132324 grad: 4.196674987548104\n",
      "epoch: 203 loss: 2.151103973388672 grad: 4.098547375491185\n",
      "epoch: 204 loss: 2.1533586978912354 grad: 4.095056172234878\n",
      "epoch: 205 loss: 2.15856671333313 grad: 4.189388767860475\n",
      "epoch: 206 loss: 2.1542558670043945 grad: 4.04949800522318\n",
      "epoch: 207 loss: 2.154078960418701 grad: 4.144988076199615\n",
      "epoch: 208 loss: 2.1550018787384033 grad: 4.174669181787601\n",
      "epoch: 209 loss: 2.147329807281494 grad: 4.198924175929278\n",
      "epoch: 210 loss: 2.151624917984009 grad: 4.330816637695072\n",
      "epoch: 211 loss: 2.153031349182129 grad: 4.377791200221206\n",
      "epoch: 212 loss: 2.151381731033325 grad: 4.451309331641015\n",
      "epoch: 213 loss: 2.1516637802124023 grad: 4.136971533187621\n",
      "epoch: 214 loss: 2.1555731296539307 grad: 4.424532866364138\n",
      "epoch: 215 loss: 2.153339147567749 grad: 4.458308932404699\n",
      "epoch: 216 loss: 2.147804021835327 grad: 4.483015461839617\n",
      "epoch: 217 loss: 2.148948907852173 grad: 4.372285773741111\n",
      "epoch: 218 loss: 2.152924060821533 grad: 4.575158172782274\n",
      "epoch: 219 loss: 2.1489920616149902 grad: 4.289674592995277\n",
      "epoch: 220 loss: 2.1498076915740967 grad: 4.263296804586721\n",
      "epoch: 221 loss: 2.14760422706604 grad: 4.530210044286731\n",
      "epoch: 222 loss: 2.1430766582489014 grad: 4.2564696104095745\n",
      "epoch: 223 loss: 2.147423028945923 grad: 4.296388828801731\n",
      "epoch: 224 loss: 2.1528329849243164 grad: 4.378813893626636\n",
      "epoch: 225 loss: 2.145733594894409 grad: 4.5852492459909255\n",
      "epoch: 226 loss: 2.1492955684661865 grad: 4.5434624869450335\n",
      "epoch: 227 loss: 2.147458076477051 grad: 4.887973154078252\n",
      "epoch: 228 loss: 2.1465463638305664 grad: 4.175680881151782\n",
      "epoch: 229 loss: 2.145853281021118 grad: 4.550776969519488\n",
      "epoch: 230 loss: 2.140903949737549 grad: 4.7247126473387375\n",
      "epoch: 231 loss: 2.143326997756958 grad: 4.594771395784817\n",
      "epoch: 232 loss: 2.1460371017456055 grad: 4.552849590305298\n",
      "epoch: 233 loss: 2.1436710357666016 grad: 4.951422191339559\n",
      "epoch: 234 loss: 2.1476802825927734 grad: 4.635602671135631\n",
      "epoch: 235 loss: 2.145718574523926 grad: 4.6211953883813255\n",
      "epoch: 236 loss: 2.1390867233276367 grad: 4.537521746608296\n",
      "epoch: 237 loss: 2.1426665782928467 grad: 4.753164956379416\n",
      "epoch: 238 loss: 2.1421682834625244 grad: 4.777963227684801\n",
      "epoch: 239 loss: 2.144395351409912 grad: 4.832402593234465\n",
      "epoch: 240 loss: 2.1388766765594482 grad: 4.73128963424085\n",
      "epoch: 241 loss: 2.1407113075256348 grad: 4.479605121356952\n",
      "epoch: 242 loss: 2.139092206954956 grad: 4.923360846201254\n",
      "epoch: 243 loss: 2.1390721797943115 grad: 4.834110036119079\n",
      "epoch: 244 loss: 2.13600492477417 grad: 4.843373077396777\n",
      "epoch: 245 loss: 2.1405813694000244 grad: 4.814037863664063\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 246 loss: 2.13204288482666 grad: 4.689706828629983\n",
      "epoch: 247 loss: 2.134129762649536 grad: 4.931171436239744\n",
      "epoch: 248 loss: 2.138986110687256 grad: 4.66092984032418\n",
      "epoch: 249 loss: 2.1343815326690674 grad: 4.844759598307844\n",
      "epoch: 250 loss: 2.1350409984588623 grad: 4.990905797711411\n",
      "epoch: 251 loss: 2.1332085132598877 grad: 4.8775739925506985\n",
      "epoch: 252 loss: 2.1375014781951904 grad: 4.680109770584201\n",
      "epoch: 253 loss: 2.1338155269622803 grad: 5.121659989827239\n",
      "epoch: 254 loss: 2.1328747272491455 grad: 4.904785063853192\n",
      "epoch: 255 loss: 2.135044813156128 grad: 4.668289395825316\n",
      "epoch: 256 loss: 2.13267183303833 grad: 4.945295627140219\n",
      "epoch: 257 loss: 2.131821393966675 grad: 4.82397588729001\n",
      "epoch: 258 loss: 2.1357076168060303 grad: 4.826339803791295\n",
      "epoch: 259 loss: 2.1328773498535156 grad: 5.087398682303342\n",
      "epoch: 260 loss: 2.1262781620025635 grad: 4.865152296691482\n",
      "epoch: 261 loss: 2.130403757095337 grad: 5.0503506857960945\n",
      "epoch: 262 loss: 2.1302947998046875 grad: 4.745003867742886\n",
      "epoch: 263 loss: 2.1407346725463867 grad: 5.069151763981652\n",
      "epoch: 264 loss: 2.1375842094421387 grad: 4.916769121950936\n",
      "epoch: 265 loss: 2.1289806365966797 grad: 5.101255756130235\n",
      "epoch: 266 loss: 2.1339852809906006 grad: 4.892523271116679\n",
      "epoch: 267 loss: 2.1252613067626953 grad: 4.979727328174733\n",
      "epoch: 268 loss: 2.1234495639801025 grad: 4.839847454841855\n",
      "epoch: 269 loss: 2.125654935836792 grad: 5.0118665636132755\n",
      "epoch: 270 loss: 2.1297616958618164 grad: 4.742770622780044\n",
      "epoch: 271 loss: 2.1251327991485596 grad: 5.016940992876207\n",
      "epoch: 272 loss: 2.1268601417541504 grad: 4.929625371223434\n",
      "epoch: 273 loss: 2.128419876098633 grad: 4.978843339637573\n",
      "epoch: 274 loss: 2.123173475265503 grad: 5.012793917408479\n",
      "epoch: 275 loss: 2.1223435401916504 grad: 5.049413392080053\n",
      "epoch: 276 loss: 2.1289401054382324 grad: 5.037303646686413\n",
      "epoch: 277 loss: 2.127958059310913 grad: 4.960588979072839\n",
      "epoch: 278 loss: 2.135636568069458 grad: 4.987220898392566\n",
      "epoch: 279 loss: 2.1273581981658936 grad: 5.079192755182111\n",
      "epoch: 280 loss: 2.1298766136169434 grad: 5.082814922223666\n",
      "epoch: 281 loss: 2.125044822692871 grad: 5.0685979221829225\n",
      "epoch: 282 loss: 2.128854751586914 grad: 5.024998284817215\n",
      "epoch: 283 loss: 2.1201558113098145 grad: 5.197479798044595\n",
      "epoch: 284 loss: 2.120432138442993 grad: 5.260317552169519\n",
      "epoch: 285 loss: 2.121506452560425 grad: 4.899739903194593\n",
      "epoch: 286 loss: 2.1227195262908936 grad: 4.951925283434639\n",
      "epoch: 287 loss: 2.1247000694274902 grad: 5.244408505200039\n",
      "epoch: 288 loss: 2.120596170425415 grad: 4.687989088913633\n",
      "epoch: 289 loss: 2.1215107440948486 grad: 4.982382897908489\n",
      "epoch: 290 loss: 2.123422384262085 grad: 5.02664939987488\n",
      "epoch: 291 loss: 2.1249775886535645 grad: 5.25622321828638\n",
      "epoch: 292 loss: 2.124610185623169 grad: 4.980326554117103\n",
      "epoch: 293 loss: 2.131575345993042 grad: 5.073810354326039\n",
      "epoch: 294 loss: 2.118692398071289 grad: 5.198292946472527\n",
      "epoch: 295 loss: 2.1254870891571045 grad: 5.60260385595676\n",
      "epoch: 296 loss: 2.120804786682129 grad: 5.219319062957925\n",
      "epoch: 297 loss: 2.1226184368133545 grad: 5.185590957853174\n",
      "epoch: 298 loss: 2.1216933727264404 grad: 5.22438711199599\n",
      "epoch: 299 loss: 2.1259350776672363 grad: 5.151361076397792\n",
      "epoch: 300 loss: 2.1174890995025635 grad: 5.028410893654273\n",
      "epoch: 301 loss: 2.1234354972839355 grad: 5.359370285356861\n",
      "epoch: 302 loss: 2.117309331893921 grad: 5.103489006662534\n",
      "epoch: 303 loss: 2.116720676422119 grad: 5.3308625835481855\n",
      "epoch: 304 loss: 2.118034839630127 grad: 5.2883249455397685\n",
      "epoch: 305 loss: 2.1240036487579346 grad: 5.664257739921884\n",
      "epoch: 306 loss: 2.118140697479248 grad: 5.411631359837004\n",
      "epoch: 307 loss: 2.1206133365631104 grad: 5.291259711216544\n",
      "epoch: 308 loss: 2.114720582962036 grad: 5.227125326001514\n",
      "epoch: 309 loss: 2.1219918727874756 grad: 5.578259807604823\n",
      "epoch: 310 loss: 2.1196401119232178 grad: 5.653329048460971\n",
      "epoch: 311 loss: 2.1096675395965576 grad: 5.066170562801528\n",
      "epoch: 312 loss: 2.1176016330718994 grad: 5.462900479564384\n",
      "epoch: 313 loss: 2.1153383255004883 grad: 5.325498731089904\n",
      "epoch: 314 loss: 2.1177635192871094 grad: 5.62509602500451\n",
      "epoch: 315 loss: 2.1109602451324463 grad: 5.3850486592596605\n",
      "epoch: 316 loss: 2.1084060668945312 grad: 5.425667222977306\n",
      "epoch: 317 loss: 2.1121842861175537 grad: 5.358604791888316\n",
      "epoch: 318 loss: 2.116495370864868 grad: 5.519832601630321\n",
      "epoch: 319 loss: 2.1130740642547607 grad: 5.616598663001602\n",
      "epoch: 320 loss: 2.112100601196289 grad: 5.333663787751917\n",
      "epoch: 321 loss: 2.1101367473602295 grad: 5.480868465998875\n",
      "epoch: 322 loss: 2.1073689460754395 grad: 5.850883255742254\n",
      "epoch: 323 loss: 2.1145849227905273 grad: 5.78144138483035\n",
      "epoch: 324 loss: 2.1160941123962402 grad: 5.617122356768786\n",
      "epoch: 325 loss: 2.11643648147583 grad: 5.273203599111487\n",
      "epoch: 326 loss: 2.11124324798584 grad: 5.610432563567652\n",
      "epoch: 327 loss: 2.115985870361328 grad: 5.556659193687318\n",
      "epoch: 328 loss: 2.1119229793548584 grad: 5.18187922848359\n",
      "epoch: 329 loss: 2.108325958251953 grad: 5.390615333241248\n",
      "epoch: 330 loss: 2.104015350341797 grad: 5.520494322144677\n",
      "epoch: 331 loss: 2.1136772632598877 grad: 5.656279853545129\n",
      "epoch: 332 loss: 2.1019747257232666 grad: 5.408299034276593\n",
      "epoch: 333 loss: 2.1035268306732178 grad: 5.517323034981798\n",
      "epoch: 334 loss: 2.1069581508636475 grad: 5.477208425357405\n",
      "epoch: 335 loss: 2.1055214405059814 grad: 5.657840607310867\n",
      "epoch: 336 loss: 2.109938621520996 grad: 5.783827806978176\n",
      "epoch: 337 loss: 2.1077511310577393 grad: 5.734475036476931\n",
      "epoch: 338 loss: 2.1046884059906006 grad: 5.5212442408286275\n",
      "epoch: 339 loss: 2.104721784591675 grad: 5.434001838825347\n",
      "epoch: 340 loss: 2.105107069015503 grad: 5.566913967944741\n",
      "epoch: 341 loss: 2.103095531463623 grad: 5.7113849028338874\n",
      "epoch: 342 loss: 2.0987484455108643 grad: 5.594151318871549\n",
      "epoch: 343 loss: 2.1061904430389404 grad: 5.32790752047939\n",
      "epoch: 344 loss: 2.108008623123169 grad: 5.558197954728726\n",
      "epoch: 345 loss: 2.0993220806121826 grad: 5.8033331159635315\n",
      "epoch: 346 loss: 2.1044702529907227 grad: 5.783621455165779\n",
      "epoch: 347 loss: 2.096853733062744 grad: 5.845559000702841\n",
      "epoch: 348 loss: 2.099844217300415 grad: 5.578425036905895\n",
      "epoch: 349 loss: 2.102663993835449 grad: 5.719558471133785\n",
      "epoch: 350 loss: 2.0959179401397705 grad: 5.711954354530289\n",
      "epoch: 351 loss: 2.101815938949585 grad: 5.911379013779676\n",
      "epoch: 352 loss: 2.099248170852661 grad: 5.727239435708653\n",
      "epoch: 353 loss: 2.0960161685943604 grad: 6.003710820650061\n",
      "epoch: 354 loss: 2.1056509017944336 grad: 6.238331271653315\n",
      "epoch: 355 loss: 2.1035871505737305 grad: 5.778576319756371\n",
      "epoch: 356 loss: 2.1003425121307373 grad: 6.165816839119153\n",
      "epoch: 357 loss: 2.0959556102752686 grad: 5.933442284966568\n",
      "epoch: 358 loss: 2.0941824913024902 grad: 6.135242547455524\n",
      "epoch: 359 loss: 2.098504066467285 grad: 6.30779423710284\n",
      "epoch: 360 loss: 2.1030874252319336 grad: 6.1862073691694865\n",
      "epoch: 361 loss: 2.0971198081970215 grad: 5.887620842609081\n",
      "epoch: 362 loss: 2.095615863800049 grad: 5.981767616522986\n",
      "epoch: 363 loss: 2.096532106399536 grad: 5.9705880662382\n",
      "epoch: 364 loss: 2.096447229385376 grad: 6.350729385028696\n",
      "epoch: 365 loss: 2.09074330329895 grad: 6.095573418869799\n",
      "epoch: 366 loss: 2.0926871299743652 grad: 5.5400300782233005\n",
      "epoch: 367 loss: 2.093961238861084 grad: 6.011900887447631\n",
      "epoch: 368 loss: 2.0964977741241455 grad: 6.554722990648496\n",
      "epoch: 369 loss: 2.0924179553985596 grad: 6.02068017301194\n",
      "epoch: 370 loss: 2.0980825424194336 grad: 5.853855937623257\n",
      "epoch: 371 loss: 2.0928308963775635 grad: 6.081886391184987\n",
      "epoch: 372 loss: 2.0899741649627686 grad: 6.214991259706458\n",
      "epoch: 373 loss: 2.0980985164642334 grad: 6.446773052836458\n",
      "epoch: 374 loss: 2.0976014137268066 grad: 6.251134995400669\n",
      "epoch: 375 loss: 2.085709810256958 grad: 6.14478933552487\n",
      "epoch: 376 loss: 2.096184015274048 grad: 6.316662193992959\n",
      "epoch: 377 loss: 2.0954136848449707 grad: 6.245901086833328\n",
      "epoch: 378 loss: 2.0951621532440186 grad: 6.341742290649563\n",
      "epoch: 379 loss: 2.0879547595977783 grad: 6.4222145808254565\n",
      "epoch: 380 loss: 2.0932374000549316 grad: 6.114115783774722\n",
      "epoch: 381 loss: 2.078660726547241 grad: 5.9563011545614\n",
      "epoch: 382 loss: 2.0918190479278564 grad: 6.511295584806551\n",
      "epoch: 383 loss: 2.084716558456421 grad: 6.266079925998513\n",
      "epoch: 384 loss: 2.0962212085723877 grad: 5.824443014146435\n",
      "epoch: 385 loss: 2.0828824043273926 grad: 6.25402249588025\n",
      "epoch: 386 loss: 2.083097219467163 grad: 6.195183686956408\n",
      "epoch: 387 loss: 2.084972620010376 grad: 6.7329537168751274\n",
      "epoch: 388 loss: 2.082089900970459 grad: 6.176801224667875\n",
      "epoch: 389 loss: 2.0927140712738037 grad: 6.684935352550672\n",
      "epoch: 390 loss: 2.0821762084960938 grad: 6.124654430459948\n",
      "epoch: 391 loss: 2.0829885005950928 grad: 6.571545834571774\n",
      "epoch: 392 loss: 2.0780398845672607 grad: 6.306548610019187\n",
      "epoch: 393 loss: 2.0885565280914307 grad: 6.223219683637754\n",
      "epoch: 394 loss: 2.0799362659454346 grad: 6.319538250661617\n",
      "epoch: 395 loss: 2.0741751194000244 grad: 6.3020518961628635\n",
      "epoch: 396 loss: 2.084735631942749 grad: 6.681936913672539\n",
      "epoch: 397 loss: 2.0840237140655518 grad: 6.989550744449454\n",
      "epoch: 398 loss: 2.077336311340332 grad: 6.678792237769812\n",
      "epoch: 399 loss: 2.0732593536376953 grad: 6.362510109534635\n",
      "epoch: 400 loss: 2.0858168601989746 grad: 6.334848158815432\n",
      "epoch: 401 loss: 2.0700981616973877 grad: 6.668945570594617\n",
      "epoch: 402 loss: 2.0779902935028076 grad: 6.511471609015846\n",
      "epoch: 403 loss: 2.081411123275757 grad: 6.69265683987991\n",
      "epoch: 404 loss: 2.076794385910034 grad: 6.566218497874659\n",
      "epoch: 405 loss: 2.0724189281463623 grad: 6.321806166978878\n",
      "epoch: 406 loss: 2.072195291519165 grad: 6.972444280848971\n",
      "epoch: 407 loss: 2.072340726852417 grad: 6.516515756388092\n",
      "epoch: 408 loss: 2.0792062282562256 grad: 6.622574455245206\n",
      "epoch: 409 loss: 2.0738112926483154 grad: 6.802836077287793\n",
      "epoch: 410 loss: 2.070462703704834 grad: 6.29599212020606\n",
      "epoch: 411 loss: 2.0771400928497314 grad: 6.468226357459253\n",
      "epoch: 412 loss: 2.068096399307251 grad: 6.119684828667059\n",
      "epoch: 413 loss: 2.069913864135742 grad: 6.744967141210855\n",
      "epoch: 414 loss: 2.070146322250366 grad: 6.62799343922072\n",
      "epoch: 415 loss: 2.0699634552001953 grad: 6.3318691240653155\n",
      "epoch: 416 loss: 2.068315029144287 grad: 6.798644315650953\n",
      "epoch: 417 loss: 2.064234972000122 grad: 6.971562608078655\n",
      "epoch: 418 loss: 2.0700631141662598 grad: 6.765002579524344\n",
      "epoch: 419 loss: 2.0769546031951904 grad: 6.939587695213656\n",
      "epoch: 420 loss: 2.074296474456787 grad: 6.905058223369812\n",
      "epoch: 421 loss: 2.077139139175415 grad: 7.197553841448906\n",
      "epoch: 422 loss: 2.0653815269470215 grad: 7.161613751395\n",
      "epoch: 423 loss: 2.063033103942871 grad: 6.85203577400673\n",
      "epoch: 424 loss: 2.0646510124206543 grad: 6.776310786331398\n",
      "epoch: 425 loss: 2.0725936889648438 grad: 6.540375094055125\n",
      "epoch: 426 loss: 2.0607221126556396 grad: 6.596027730202805\n",
      "epoch: 427 loss: 2.067878484725952 grad: 6.877893642943707\n",
      "epoch: 428 loss: 2.0581064224243164 grad: 7.067205450401479\n",
      "epoch: 429 loss: 2.062270402908325 grad: 6.897212446962912\n",
      "epoch: 430 loss: 2.063838005065918 grad: 7.002303542480583\n",
      "epoch: 431 loss: 2.0634877681732178 grad: 6.823055765554605\n",
      "epoch: 432 loss: 2.0619776248931885 grad: 6.667722236616389\n",
      "epoch: 433 loss: 2.06591534614563 grad: 7.0279916317630855\n",
      "epoch: 434 loss: 2.0643229484558105 grad: 7.033853433242748\n",
      "epoch: 435 loss: 2.0652430057525635 grad: 6.8304787072175674\n",
      "epoch: 436 loss: 2.061784505844116 grad: 7.1240047409849625\n",
      "epoch: 437 loss: 2.0657973289489746 grad: 7.051272087139151\n",
      "epoch: 438 loss: 2.0683629512786865 grad: 7.161361930647954\n",
      "epoch: 439 loss: 2.0544865131378174 grad: 6.913864371204187\n",
      "epoch: 440 loss: 2.0598764419555664 grad: 6.840518453224961\n",
      "epoch: 441 loss: 2.04775333404541 grad: 6.937283754186143\n",
      "epoch: 442 loss: 2.0619685649871826 grad: 7.230019482037437\n",
      "epoch: 443 loss: 2.0603959560394287 grad: 6.905534130772428\n",
      "epoch: 444 loss: 2.0544345378875732 grad: 7.418281720204663\n",
      "epoch: 445 loss: 2.0586795806884766 grad: 6.863976222662521\n",
      "epoch: 446 loss: 2.0601139068603516 grad: 7.183111260829878\n",
      "epoch: 447 loss: 2.0500893592834473 grad: 7.319575754075592\n",
      "epoch: 448 loss: 2.0595102310180664 grad: 6.899038018821369\n",
      "epoch: 449 loss: 2.057776927947998 grad: 6.974266259886679\n",
      "epoch: 450 loss: 2.055349588394165 grad: 7.379156468502645\n",
      "epoch: 451 loss: 2.051088333129883 grad: 6.908809549034765\n",
      "epoch: 452 loss: 2.0533647537231445 grad: 7.4469894294346135\n",
      "epoch: 453 loss: 2.0600059032440186 grad: 7.379765638017228\n",
      "epoch: 454 loss: 2.055346965789795 grad: 7.678066344599107\n",
      "epoch: 455 loss: 2.0534605979919434 grad: 7.083523295575842\n",
      "epoch: 456 loss: 2.047402858734131 grad: 6.877277056627449\n",
      "epoch: 457 loss: 2.0501229763031006 grad: 7.511152234164968\n",
      "epoch: 458 loss: 2.0579140186309814 grad: 7.4950673487111334\n",
      "epoch: 459 loss: 2.0541889667510986 grad: 7.269697597708612\n",
      "epoch: 460 loss: 2.0564372539520264 grad: 7.281206279261304\n",
      "epoch: 461 loss: 2.0509846210479736 grad: 7.063347327375104\n",
      "epoch: 462 loss: 2.0503506660461426 grad: 6.951118088992579\n",
      "epoch: 463 loss: 2.042950391769409 grad: 7.466078447481055\n",
      "epoch: 464 loss: 2.047088146209717 grad: 7.2223583864609875\n",
      "epoch: 465 loss: 2.053276538848877 grad: 7.535135149061384\n",
      "epoch: 466 loss: 2.0523760318756104 grad: 6.984459707520843\n",
      "epoch: 467 loss: 2.0570247173309326 grad: 7.440419701341954\n",
      "epoch: 468 loss: 2.040196657180786 grad: 7.376426676096069\n",
      "epoch: 469 loss: 2.049105167388916 grad: 7.4452092182926\n",
      "epoch: 470 loss: 2.0466127395629883 grad: 7.570811377372593\n",
      "epoch: 471 loss: 2.034989356994629 grad: 7.4734535803427065\n",
      "epoch: 472 loss: 2.0451931953430176 grad: 7.531732777606637\n",
      "epoch: 473 loss: 2.048981189727783 grad: 7.466899200106069\n",
      "epoch: 474 loss: 2.0449390411376953 grad: 7.3759552255080685\n",
      "epoch: 475 loss: 2.047403335571289 grad: 7.794541597713731\n",
      "epoch: 476 loss: 2.0425825119018555 grad: 7.607886752387183\n",
      "epoch: 477 loss: 2.038973808288574 grad: 7.053748663049191\n",
      "epoch: 478 loss: 2.0490992069244385 grad: 7.386319159759238\n",
      "epoch: 479 loss: 2.0400285720825195 grad: 7.7706784979691585\n",
      "epoch: 480 loss: 2.0464928150177 grad: 7.431724861929459\n",
      "epoch: 481 loss: 2.034808874130249 grad: 7.613752631189686\n",
      "epoch: 482 loss: 2.048191785812378 grad: 7.405813539178953\n",
      "epoch: 483 loss: 2.0388970375061035 grad: 7.051235453536113\n",
      "epoch: 484 loss: 2.0407040119171143 grad: 7.690039863203844\n",
      "epoch: 485 loss: 2.036979913711548 grad: 7.527544649266121\n",
      "epoch: 486 loss: 2.0424015522003174 grad: 7.7156564969761625\n",
      "epoch: 487 loss: 2.0351779460906982 grad: 7.35051164164814\n",
      "epoch: 488 loss: 2.034825563430786 grad: 7.372617166711106\n",
      "epoch: 489 loss: 2.0372653007507324 grad: 7.426045226236243\n",
      "epoch: 490 loss: 2.040861129760742 grad: 7.802591170598236\n",
      "epoch: 491 loss: 2.034832239151001 grad: 7.902669061330103\n",
      "epoch: 492 loss: 2.0329182147979736 grad: 7.079580795478135\n",
      "epoch: 493 loss: 2.035588502883911 grad: 7.236172016140902\n",
      "epoch: 494 loss: 2.031717538833618 grad: 7.401456671146055\n",
      "epoch: 495 loss: 2.0359044075012207 grad: 7.566477987833972\n",
      "epoch: 496 loss: 2.034391403198242 grad: 7.180200550246925\n",
      "epoch: 497 loss: 2.0409140586853027 grad: 7.862207969746715\n",
      "epoch: 498 loss: 2.0363662242889404 grad: 7.924164341991797\n",
      "epoch: 499 loss: 2.03440523147583 grad: 7.923278562680242\n",
      "2.1633891612291336\n",
      "epoch: 0 loss: 2.304651975631714 grad: 0.9295542447103394\n",
      "epoch: 1 loss: 2.300163984298706 grad: 0.9903289454486517\n",
      "epoch: 2 loss: 2.2609243392944336 grad: 1.2727333021933205\n",
      "epoch: 3 loss: 2.2409114837646484 grad: 1.525716098940595\n",
      "epoch: 4 loss: 2.231074094772339 grad: 1.7825333113414383\n",
      "epoch: 5 loss: 2.2237236499786377 grad: 1.9792199494120377\n",
      "epoch: 6 loss: 2.2189321517944336 grad: 2.0169732987826197\n",
      "epoch: 7 loss: 2.2024307250976562 grad: 2.2750043597623026\n",
      "epoch: 8 loss: 2.16863751411438 grad: 3.129692547869617\n",
      "epoch: 9 loss: 2.1573128700256348 grad: 3.2255232847366844\n",
      "epoch: 10 loss: 2.1387367248535156 grad: 3.481573084022828\n",
      "epoch: 11 loss: 2.135291576385498 grad: 3.503301912649823\n",
      "epoch: 12 loss: 2.128801107406616 grad: 3.5063073300051553\n",
      "epoch: 13 loss: 2.1195428371429443 grad: 3.527722805924621\n",
      "epoch: 14 loss: 2.1078414916992188 grad: 3.5319250981325268\n",
      "epoch: 15 loss: 2.087827444076538 grad: 3.626372535887178\n",
      "epoch: 16 loss: 2.095993995666504 grad: 3.826016438764147\n",
      "epoch: 17 loss: 2.079890251159668 grad: 4.220740264097768\n",
      "epoch: 18 loss: 2.079843044281006 grad: 4.542950869475063\n",
      "epoch: 19 loss: 2.06544828414917 grad: 5.018972919396003\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 20 loss: 2.0757017135620117 grad: 4.539801576706518\n",
      "epoch: 21 loss: 2.0605669021606445 grad: 5.324735447726053\n",
      "epoch: 22 loss: 2.0601742267608643 grad: 4.8525329994318165\n",
      "epoch: 23 loss: 2.0603485107421875 grad: 4.342765949512666\n",
      "epoch: 24 loss: 2.050293445587158 grad: 4.792006700183727\n",
      "epoch: 25 loss: 2.0289928913116455 grad: 4.8342696819329705\n",
      "epoch: 26 loss: 2.0294699668884277 grad: 5.1295259096387165\n",
      "epoch: 27 loss: 2.0405290126800537 grad: 4.598301064860563\n",
      "epoch: 28 loss: 2.014686107635498 grad: 4.597227967577979\n",
      "epoch: 29 loss: 2.023930788040161 grad: 5.078860482925342\n",
      "epoch: 30 loss: 2.0239737033843994 grad: 5.093284830885259\n",
      "epoch: 31 loss: 2.0194172859191895 grad: 5.271675769448935\n",
      "epoch: 32 loss: 2.0236310958862305 grad: 5.060231253546099\n",
      "epoch: 33 loss: 2.0281612873077393 grad: 4.830901861914696\n",
      "epoch: 34 loss: 2.0063157081604004 grad: 4.4460719858251405\n",
      "epoch: 35 loss: 2.0214028358459473 grad: 4.68923352066786\n",
      "epoch: 36 loss: 2.0059874057769775 grad: 4.590617816053546\n",
      "epoch: 37 loss: 1.9988577365875244 grad: 5.118542235015729\n",
      "epoch: 38 loss: 1.9991015195846558 grad: 5.102432203047404\n",
      "epoch: 39 loss: 1.9935150146484375 grad: 4.8210998699923655\n",
      "epoch: 40 loss: 2.0054569244384766 grad: 4.631245266653307\n",
      "epoch: 41 loss: 2.0092475414276123 grad: 5.224080757911978\n",
      "epoch: 42 loss: 2.0051255226135254 grad: 4.926337672185452\n",
      "epoch: 43 loss: 2.000056266784668 grad: 4.997949458977221\n",
      "epoch: 44 loss: 1.9970186948776245 grad: 5.359891867003402\n",
      "epoch: 45 loss: 2.0033068656921387 grad: 5.592225915606255\n",
      "epoch: 46 loss: 1.9777709245681763 grad: 5.041264663904301\n",
      "epoch: 47 loss: 1.9943374395370483 grad: 4.409440814072104\n",
      "epoch: 48 loss: 1.9816045761108398 grad: 4.974362346576296\n",
      "epoch: 49 loss: 1.9862762689590454 grad: 5.128010220760997\n",
      "epoch: 50 loss: 1.9680296182632446 grad: 4.924971720551155\n",
      "epoch: 51 loss: 1.9830210208892822 grad: 4.937609022412549\n",
      "epoch: 52 loss: 1.9947360754013062 grad: 5.256132611150471\n",
      "epoch: 53 loss: 1.9783916473388672 grad: 5.000697928079818\n",
      "epoch: 54 loss: 1.9910361766815186 grad: 5.406964103951366\n",
      "epoch: 55 loss: 1.9709705114364624 grad: 4.824755427116456\n",
      "epoch: 56 loss: 1.9657008647918701 grad: 5.48000695773757\n",
      "epoch: 57 loss: 1.964123010635376 grad: 4.715780962207184\n",
      "epoch: 58 loss: 1.9674642086029053 grad: 5.588935515840098\n",
      "epoch: 59 loss: 1.9898790121078491 grad: 5.264379764197021\n",
      "epoch: 60 loss: 1.9688799381256104 grad: 5.831808104140994\n",
      "epoch: 61 loss: 1.967008113861084 grad: 5.5170086659024475\n",
      "epoch: 62 loss: 1.9435170888900757 grad: 5.361789747587099\n",
      "epoch: 63 loss: 1.9751551151275635 grad: 6.011691370443072\n",
      "epoch: 64 loss: 1.9572522640228271 grad: 6.36375726868781\n",
      "epoch: 65 loss: 1.9617409706115723 grad: 5.2726016411518986\n",
      "epoch: 66 loss: 1.9424662590026855 grad: 5.912111945310793\n",
      "epoch: 67 loss: 1.9317560195922852 grad: 5.48273824330046\n",
      "epoch: 68 loss: 1.9452239274978638 grad: 5.720916431646661\n",
      "epoch: 69 loss: 1.9475146532058716 grad: 6.479092597382583\n",
      "epoch: 70 loss: 1.93044912815094 grad: 5.6791784869844655\n",
      "epoch: 71 loss: 1.9199620485305786 grad: 5.301536756855692\n",
      "epoch: 72 loss: 1.9287647008895874 grad: 5.427183553346411\n",
      "epoch: 73 loss: 1.9278711080551147 grad: 5.961514176263812\n",
      "epoch: 74 loss: 1.939847469329834 grad: 5.304839223475908\n",
      "epoch: 75 loss: 1.9187300205230713 grad: 5.26593345239558\n",
      "epoch: 76 loss: 1.9352108240127563 grad: 6.706166871248685\n",
      "epoch: 77 loss: 1.9242172241210938 grad: 5.599206741222472\n",
      "epoch: 78 loss: 1.9173442125320435 grad: 5.466479841407919\n",
      "epoch: 79 loss: 1.9255247116088867 grad: 5.301206854830814\n",
      "epoch: 80 loss: 1.930828332901001 grad: 5.635913215058353\n",
      "epoch: 81 loss: 1.912501573562622 grad: 5.3518323876620375\n",
      "epoch: 82 loss: 1.907553791999817 grad: 6.392594745641829\n",
      "epoch: 83 loss: 1.9340403079986572 grad: 6.519811758767843\n",
      "epoch: 84 loss: 1.918952226638794 grad: 5.7351922744705846\n",
      "epoch: 85 loss: 1.910060167312622 grad: 6.425469461475298\n",
      "epoch: 86 loss: 1.9084968566894531 grad: 5.845029938153208\n",
      "epoch: 87 loss: 1.9150975942611694 grad: 5.353836036885493\n",
      "epoch: 88 loss: 1.91695237159729 grad: 6.906004245143979\n",
      "epoch: 89 loss: 1.9039604663848877 grad: 6.009830032778573\n",
      "epoch: 90 loss: 1.8913826942443848 grad: 5.570289655543757\n",
      "epoch: 91 loss: 1.9014281034469604 grad: 6.12316532219166\n",
      "epoch: 92 loss: 1.892822265625 grad: 5.758828488994151\n",
      "epoch: 93 loss: 1.8810722827911377 grad: 6.583471096937068\n",
      "epoch: 94 loss: 1.8928519487380981 grad: 5.814856977015826\n",
      "epoch: 95 loss: 1.8960814476013184 grad: 6.658388872837393\n",
      "epoch: 96 loss: 1.9088058471679688 grad: 5.925898553604918\n",
      "epoch: 97 loss: 1.8688883781433105 grad: 5.880117368686664\n",
      "epoch: 98 loss: 1.8701374530792236 grad: 5.994648110859363\n",
      "epoch: 99 loss: 1.8669885396957397 grad: 6.927999315310791\n",
      "epoch: 100 loss: 1.8771196603775024 grad: 6.281440159836498\n",
      "epoch: 101 loss: 1.8922319412231445 grad: 6.14207389339387\n",
      "epoch: 102 loss: 1.876853585243225 grad: 5.352929470308323\n",
      "epoch: 103 loss: 1.8657091856002808 grad: 6.535442345399278\n",
      "epoch: 104 loss: 1.886139988899231 grad: 6.557592792089083\n",
      "epoch: 105 loss: 1.8888858556747437 grad: 5.787116448986963\n",
      "epoch: 106 loss: 1.8710346221923828 grad: 5.550692884126629\n",
      "epoch: 107 loss: 1.868528962135315 grad: 6.27264758802226\n",
      "epoch: 108 loss: 1.8625166416168213 grad: 5.671615390726531\n",
      "epoch: 109 loss: 1.882741928100586 grad: 7.16517183892378\n",
      "epoch: 110 loss: 1.8667361736297607 grad: 5.99866539534987\n",
      "epoch: 111 loss: 1.863966941833496 grad: 6.183031675011513\n",
      "epoch: 112 loss: 1.8785573244094849 grad: 6.166565989438996\n",
      "epoch: 113 loss: 1.8686957359313965 grad: 4.693370550095255\n",
      "epoch: 114 loss: 1.8601773977279663 grad: 6.059599709463775\n",
      "epoch: 115 loss: 1.8638522624969482 grad: 6.524609902575667\n",
      "epoch: 116 loss: 1.8705683946609497 grad: 6.23746457021422\n",
      "epoch: 117 loss: 1.8629181385040283 grad: 6.838793346670129\n",
      "epoch: 118 loss: 1.8492540121078491 grad: 5.986730383547154\n",
      "epoch: 119 loss: 1.8391460180282593 grad: 5.884582162835397\n",
      "epoch: 120 loss: 1.8502100706100464 grad: 6.553496020431224\n",
      "epoch: 121 loss: 1.8460863828659058 grad: 6.3749468347999185\n",
      "epoch: 122 loss: 1.846667766571045 grad: 6.606458556513572\n",
      "epoch: 123 loss: 1.8543108701705933 grad: 6.3399012001502255\n",
      "epoch: 124 loss: 1.8665024042129517 grad: 5.723166879396313\n",
      "epoch: 125 loss: 1.8499343395233154 grad: 6.813448380583727\n",
      "epoch: 126 loss: 1.832004189491272 grad: 5.807157836673367\n",
      "epoch: 127 loss: 1.8488342761993408 grad: 6.828076935262375\n",
      "epoch: 128 loss: 1.8646949529647827 grad: 6.674615218262058\n",
      "epoch: 129 loss: 1.8619656562805176 grad: 6.120698196446663\n",
      "epoch: 130 loss: 1.836530089378357 grad: 5.924011957252376\n",
      "epoch: 131 loss: 1.8379123210906982 grad: 6.619268220337246\n",
      "epoch: 132 loss: 1.841400384902954 grad: 6.443146060866263\n",
      "epoch: 133 loss: 1.848903775215149 grad: 6.472575666153543\n",
      "epoch: 134 loss: 1.8435183763504028 grad: 6.463808811779479\n",
      "epoch: 135 loss: 1.8374297618865967 grad: 5.932338671394049\n",
      "epoch: 136 loss: 1.8635543584823608 grad: 7.024166867342992\n",
      "epoch: 137 loss: 1.8343652486801147 grad: 7.291697471377639\n",
      "epoch: 138 loss: 1.8360857963562012 grad: 5.947355612067946\n",
      "epoch: 139 loss: 1.8266932964324951 grad: 6.541481518923926\n",
      "epoch: 140 loss: 1.8175368309020996 grad: 5.954327034613853\n",
      "epoch: 141 loss: 1.822435736656189 grad: 6.132387497325128\n",
      "epoch: 142 loss: 1.8360633850097656 grad: 6.896058062445797\n",
      "epoch: 143 loss: 1.8115942478179932 grad: 6.3682082325380875\n",
      "epoch: 144 loss: 1.8361554145812988 grad: 6.7256792947859685\n",
      "epoch: 145 loss: 1.803296685218811 grad: 6.673466840605778\n",
      "epoch: 146 loss: 1.8158406019210815 grad: 7.392472021868877\n",
      "epoch: 147 loss: 1.8280001878738403 grad: 7.1164136446706605\n",
      "epoch: 148 loss: 1.8187414407730103 grad: 6.759174967137542\n",
      "epoch: 149 loss: 1.8116233348846436 grad: 5.943047839124784\n",
      "epoch: 150 loss: 1.8137357234954834 grad: 7.060413403810734\n",
      "epoch: 151 loss: 1.8334434032440186 grad: 6.532810762224559\n",
      "epoch: 152 loss: 1.7933186292648315 grad: 6.415531276226772\n",
      "epoch: 153 loss: 1.8186486959457397 grad: 6.461406063397936\n",
      "epoch: 154 loss: 1.8012058734893799 grad: 6.430039448670522\n",
      "epoch: 155 loss: 1.821775197982788 grad: 7.721517387683326\n",
      "epoch: 156 loss: 1.8239611387252808 grad: 6.055571977335762\n",
      "epoch: 157 loss: 1.8146566152572632 grad: 6.173196851762311\n",
      "epoch: 158 loss: 1.8178035020828247 grad: 6.6726973832096155\n",
      "epoch: 159 loss: 1.814275860786438 grad: 7.159496600639643\n",
      "epoch: 160 loss: 1.8349343538284302 grad: 6.976589549282965\n",
      "epoch: 161 loss: 1.7899560928344727 grad: 6.6641240224497675\n",
      "epoch: 162 loss: 1.8124788999557495 grad: 7.469247986927964\n",
      "epoch: 163 loss: 1.809031367301941 grad: 7.15514432103581\n",
      "epoch: 164 loss: 1.8127834796905518 grad: 7.17025555364625\n",
      "epoch: 165 loss: 1.7936326265335083 grad: 7.711727857190237\n",
      "epoch: 166 loss: 1.804972529411316 grad: 6.6779018749385\n",
      "epoch: 167 loss: 1.795400857925415 grad: 7.808875715877447\n",
      "epoch: 168 loss: 1.8256949186325073 grad: 7.107958980900419\n",
      "epoch: 169 loss: 1.7992349863052368 grad: 5.8074356532423055\n",
      "epoch: 170 loss: 1.7876442670822144 grad: 6.719159166518477\n",
      "epoch: 171 loss: 1.7823697328567505 grad: 7.328469108707698\n",
      "epoch: 172 loss: 1.7870891094207764 grad: 6.183345173651423\n",
      "epoch: 173 loss: 1.795159935951233 grad: 7.430470479123797\n",
      "epoch: 174 loss: 1.7920787334442139 grad: 6.762661445003542\n",
      "epoch: 175 loss: 1.7822357416152954 grad: 7.020038441100272\n",
      "epoch: 176 loss: 1.8111565113067627 grad: 7.919188967651165\n",
      "epoch: 177 loss: 1.7798528671264648 grad: 6.9273992893727225\n",
      "epoch: 178 loss: 1.7819623947143555 grad: 6.713337507795789\n",
      "epoch: 179 loss: 1.7842515707015991 grad: 6.170873606152969\n",
      "epoch: 180 loss: 1.769934892654419 grad: 6.612747966121773\n",
      "epoch: 181 loss: 1.784252405166626 grad: 6.588805982401172\n",
      "epoch: 182 loss: 1.7671236991882324 grad: 6.3134172146255585\n",
      "epoch: 183 loss: 1.7672442197799683 grad: 6.496766559813829\n",
      "epoch: 184 loss: 1.7582420110702515 grad: 6.492433149417463\n",
      "epoch: 185 loss: 1.777006983757019 grad: 6.673277662269169\n",
      "epoch: 186 loss: 1.7828840017318726 grad: 7.662735056348162\n",
      "epoch: 187 loss: 1.7807178497314453 grad: 6.925026771520073\n",
      "epoch: 188 loss: 1.7716264724731445 grad: 7.188833842643016\n",
      "epoch: 189 loss: 1.7780412435531616 grad: 7.7520089671572405\n",
      "epoch: 190 loss: 1.7709764242172241 grad: 7.42816083665405\n",
      "epoch: 191 loss: 1.7664397954940796 grad: 6.712239986788417\n",
      "epoch: 192 loss: 1.7909296751022339 grad: 8.095353356107866\n",
      "epoch: 193 loss: 1.764441728591919 grad: 6.173165597900354\n",
      "epoch: 194 loss: 1.7616297006607056 grad: 6.5362369551740045\n",
      "epoch: 195 loss: 1.7562414407730103 grad: 6.860186779036349\n",
      "epoch: 196 loss: 1.756238579750061 grad: 6.405043456422319\n",
      "epoch: 197 loss: 1.7563276290893555 grad: 6.463759117903435\n",
      "epoch: 198 loss: 1.757940649986267 grad: 7.318106181635928\n",
      "epoch: 199 loss: 1.7471020221710205 grad: 6.549851312112113\n",
      "epoch: 200 loss: 1.761816143989563 grad: 7.049831325715382\n",
      "epoch: 201 loss: 1.7697832584381104 grad: 8.383094688175044\n",
      "epoch: 202 loss: 1.7400319576263428 grad: 6.7317923767883\n",
      "epoch: 203 loss: 1.7537509202957153 grad: 6.775304440975777\n",
      "epoch: 204 loss: 1.773107886314392 grad: 6.892810713802949\n",
      "epoch: 205 loss: 1.7514046430587769 grad: 7.683234465782002\n",
      "epoch: 206 loss: 1.7699576616287231 grad: 6.441855977184397\n",
      "epoch: 207 loss: 1.744565486907959 grad: 6.7326681102147425\n",
      "epoch: 208 loss: 1.7597167491912842 grad: 6.923335327786007\n",
      "epoch: 209 loss: 1.7552043199539185 grad: 6.680307729730437\n",
      "epoch: 210 loss: 1.7495319843292236 grad: 7.5471204997075905\n",
      "epoch: 211 loss: 1.7451084852218628 grad: 6.393573953892984\n",
      "epoch: 212 loss: 1.7542442083358765 grad: 6.893543577620914\n",
      "epoch: 213 loss: 1.7608214616775513 grad: 6.718298670239684\n",
      "epoch: 214 loss: 1.7275028228759766 grad: 6.114582461872718\n",
      "epoch: 215 loss: 1.7402180433273315 grad: 6.5100263622613666\n",
      "epoch: 216 loss: 1.751930594444275 grad: 6.531379156425828\n",
      "epoch: 217 loss: 1.7470179796218872 grad: 7.133951201540878\n",
      "epoch: 218 loss: 1.7766813039779663 grad: 7.0018812208380705\n",
      "epoch: 219 loss: 1.7479366064071655 grad: 6.835558417730868\n",
      "epoch: 220 loss: 1.7528505325317383 grad: 8.00313998817116\n",
      "epoch: 221 loss: 1.7672793865203857 grad: 6.799750943850374\n",
      "epoch: 222 loss: 1.7500674724578857 grad: 7.2621054628867165\n",
      "epoch: 223 loss: 1.7294752597808838 grad: 6.858999393826606\n",
      "epoch: 224 loss: 1.737607717514038 grad: 6.041297233680419\n",
      "epoch: 225 loss: 1.7497104406356812 grad: 7.314199523736866\n",
      "epoch: 226 loss: 1.7338083982467651 grad: 5.980040736159502\n",
      "epoch: 227 loss: 1.725816249847412 grad: 7.6846436319046045\n",
      "epoch: 228 loss: 1.7549211978912354 grad: 7.50112796450389\n",
      "epoch: 229 loss: 1.7459622621536255 grad: 6.24082270747241\n",
      "epoch: 230 loss: 1.7288155555725098 grad: 7.614286086699207\n",
      "epoch: 231 loss: 1.7334535121917725 grad: 8.457493211796862\n",
      "epoch: 232 loss: 1.7383729219436646 grad: 6.40953221947544\n",
      "epoch: 233 loss: 1.7293435335159302 grad: 6.2288217714919325\n",
      "epoch: 234 loss: 1.7344036102294922 grad: 6.14983379435131\n",
      "epoch: 235 loss: 1.7401458024978638 grad: 6.204395380135721\n",
      "epoch: 236 loss: 1.7328976392745972 grad: 6.668954950003397\n",
      "epoch: 237 loss: 1.7204101085662842 grad: 5.7241010983450415\n",
      "epoch: 238 loss: 1.710619330406189 grad: 6.097872048568365\n",
      "epoch: 239 loss: 1.7229264974594116 grad: 5.962093188467753\n",
      "epoch: 240 loss: 1.7243589162826538 grad: 6.799769089761881\n",
      "epoch: 241 loss: 1.7401206493377686 grad: 7.287352052656806\n",
      "epoch: 242 loss: 1.7447500228881836 grad: 7.032866783045017\n",
      "epoch: 243 loss: 1.7308651208877563 grad: 6.533846383504588\n",
      "epoch: 244 loss: 1.7576488256454468 grad: 6.9526926221185725\n",
      "epoch: 245 loss: 1.7605324983596802 grad: 7.407647289503998\n",
      "epoch: 246 loss: 1.736136555671692 grad: 8.04133804508271\n",
      "epoch: 247 loss: 1.721690058708191 grad: 5.942650951585541\n",
      "epoch: 248 loss: 1.7138230800628662 grad: 7.43428096981917\n",
      "epoch: 249 loss: 1.7398757934570312 grad: 7.2808201146727365\n",
      "epoch: 250 loss: 1.728278398513794 grad: 6.953899571781914\n",
      "epoch: 251 loss: 1.731972098350525 grad: 6.375420852716147\n",
      "epoch: 252 loss: 1.7247562408447266 grad: 7.253894050274063\n",
      "epoch: 253 loss: 1.717510461807251 grad: 6.072752304411487\n",
      "epoch: 254 loss: 1.7239556312561035 grad: 5.942457885013561\n",
      "epoch: 255 loss: 1.7210453748703003 grad: 6.860876696693364\n",
      "epoch: 256 loss: 1.7157343626022339 grad: 5.611093427881964\n",
      "epoch: 257 loss: 1.70281982421875 grad: 6.481747015006332\n",
      "epoch: 258 loss: 1.7211261987686157 grad: 6.454738557508487\n",
      "epoch: 259 loss: 1.718807339668274 grad: 7.504854517276567\n",
      "epoch: 260 loss: 1.7263437509536743 grad: 6.666560170564769\n",
      "epoch: 261 loss: 1.7196940183639526 grad: 7.039145359319162\n",
      "epoch: 262 loss: 1.7435578107833862 grad: 6.243588608706916\n",
      "epoch: 263 loss: 1.730814814567566 grad: 6.86030779642204\n",
      "epoch: 264 loss: 1.7238116264343262 grad: 7.637519443288987\n",
      "epoch: 265 loss: 1.7370874881744385 grad: 6.84085644112161\n",
      "epoch: 266 loss: 1.7380571365356445 grad: 6.909542294983978\n",
      "epoch: 267 loss: 1.7312555313110352 grad: 8.036453502260263\n",
      "epoch: 268 loss: 1.7183018922805786 grad: 8.031366857373671\n",
      "epoch: 269 loss: 1.7292159795761108 grad: 7.311374406988819\n",
      "epoch: 270 loss: 1.7224907875061035 grad: 6.711430231832901\n",
      "epoch: 271 loss: 1.7271595001220703 grad: 7.710131306293843\n",
      "epoch: 272 loss: 1.7275394201278687 grad: 7.207501233554568\n",
      "epoch: 273 loss: 1.7345302104949951 grad: 7.000384059523062\n",
      "epoch: 274 loss: 1.717347502708435 grad: 6.149758654520574\n",
      "epoch: 275 loss: 1.7026869058609009 grad: 5.463621110475317\n",
      "epoch: 276 loss: 1.7312870025634766 grad: 7.669704415088269\n",
      "epoch: 277 loss: 1.7144230604171753 grad: 6.9931320815772375\n",
      "epoch: 278 loss: 1.705569863319397 grad: 5.4794350484066925\n",
      "epoch: 279 loss: 1.7069077491760254 grad: 6.644452184417455\n",
      "epoch: 280 loss: 1.7020149230957031 grad: 6.46278048205793\n",
      "epoch: 281 loss: 1.7134653329849243 grad: 6.976995238693942\n",
      "epoch: 282 loss: 1.6987086534500122 grad: 4.978489197809101\n",
      "epoch: 283 loss: 1.6998639106750488 grad: 5.8611078479672925\n",
      "epoch: 284 loss: 1.7109851837158203 grad: 6.137790046646495\n",
      "epoch: 285 loss: 1.7258092164993286 grad: 6.051497517832999\n",
      "epoch: 286 loss: 1.7172950506210327 grad: 6.796415209703218\n",
      "epoch: 287 loss: 1.7000170946121216 grad: 5.3581794985642315\n",
      "epoch: 288 loss: 1.7085973024368286 grad: 6.438868696775956\n",
      "epoch: 289 loss: 1.7102326154708862 grad: 7.292354303577292\n",
      "epoch: 290 loss: 1.7094197273254395 grad: 6.403490938494715\n",
      "epoch: 291 loss: 1.6951881647109985 grad: 5.877635960053614\n",
      "epoch: 292 loss: 1.7010475397109985 grad: 6.364270635730651\n",
      "epoch: 293 loss: 1.7164684534072876 grad: 6.4420605319867175\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 294 loss: 1.7115449905395508 grad: 7.138588425201479\n",
      "epoch: 295 loss: 1.7285510301589966 grad: 6.052552264514931\n",
      "epoch: 296 loss: 1.6961692571640015 grad: 7.49211312418346\n",
      "epoch: 297 loss: 1.7409980297088623 grad: 8.462522349656894\n",
      "epoch: 298 loss: 1.7156723737716675 grad: 6.053759769653778\n",
      "epoch: 299 loss: 1.7078301906585693 grad: 6.831418006605778\n",
      "epoch: 300 loss: 1.6932960748672485 grad: 5.90603354195899\n",
      "epoch: 301 loss: 1.6905386447906494 grad: 6.392038554747174\n",
      "epoch: 302 loss: 1.689910888671875 grad: 6.805419446433151\n",
      "epoch: 303 loss: 1.7017074823379517 grad: 7.0033993864590665\n",
      "epoch: 304 loss: 1.7039039134979248 grad: 6.450478852930823\n",
      "epoch: 305 loss: 1.6993268728256226 grad: 8.015176123138579\n",
      "epoch: 306 loss: 1.7124109268188477 grad: 7.631965430226537\n",
      "epoch: 307 loss: 1.7292488813400269 grad: 7.056338824465269\n",
      "epoch: 308 loss: 1.7018189430236816 grad: 6.918672297164597\n",
      "epoch: 309 loss: 1.7046403884887695 grad: 6.471703825004552\n",
      "epoch: 310 loss: 1.7021242380142212 grad: 5.957378683531152\n",
      "epoch: 311 loss: 1.721218228340149 grad: 6.7800241642976795\n",
      "epoch: 312 loss: 1.726135492324829 grad: 6.957420987099116\n",
      "epoch: 313 loss: 1.6996209621429443 grad: 7.67526659239896\n",
      "epoch: 314 loss: 1.7133581638336182 grad: 7.043061175728802\n",
      "epoch: 315 loss: 1.7079137563705444 grad: 5.870829495025336\n",
      "epoch: 316 loss: 1.7152824401855469 grad: 6.961656217324436\n",
      "epoch: 317 loss: 1.6885356903076172 grad: 5.6048523235565675\n",
      "epoch: 318 loss: 1.6972668170928955 grad: 5.807174464579966\n",
      "epoch: 319 loss: 1.6933386325836182 grad: 6.159951275519248\n",
      "epoch: 320 loss: 1.6882332563400269 grad: 5.84143222916204\n",
      "epoch: 321 loss: 1.6970629692077637 grad: 6.6803258724592895\n",
      "epoch: 322 loss: 1.6869972944259644 grad: 5.791799990490045\n",
      "epoch: 323 loss: 1.70311439037323 grad: 5.752693851784681\n",
      "epoch: 324 loss: 1.6925113201141357 grad: 5.543195545868471\n",
      "epoch: 325 loss: 1.6808310747146606 grad: 5.246428767956945\n",
      "epoch: 326 loss: 1.66572904586792 grad: 5.431089383052971\n",
      "epoch: 327 loss: 1.6893419027328491 grad: 5.836900863957467\n",
      "epoch: 328 loss: 1.6821075677871704 grad: 5.991841028863313\n",
      "epoch: 329 loss: 1.6793285608291626 grad: 6.35258918426694\n",
      "epoch: 330 loss: 1.7083568572998047 grad: 6.75179482886233\n",
      "epoch: 331 loss: 1.6982554197311401 grad: 6.187424604575932\n",
      "epoch: 332 loss: 1.6894274950027466 grad: 5.6033705288504105\n",
      "epoch: 333 loss: 1.6860525608062744 grad: 6.153555557468814\n",
      "epoch: 334 loss: 1.6875827312469482 grad: 7.2756607169923075\n",
      "epoch: 335 loss: 1.695046067237854 grad: 6.3516134943594\n",
      "epoch: 336 loss: 1.687407374382019 grad: 5.657858036964258\n",
      "epoch: 337 loss: 1.6954814195632935 grad: 4.60101217398984\n",
      "epoch: 338 loss: 1.6760289669036865 grad: 5.903515263949019\n",
      "epoch: 339 loss: 1.6990492343902588 grad: 5.394473250793995\n",
      "epoch: 340 loss: 1.6848924160003662 grad: 6.00642376627562\n",
      "epoch: 341 loss: 1.7028119564056396 grad: 6.239450936778985\n",
      "epoch: 342 loss: 1.7096089124679565 grad: 6.7545676987744905\n",
      "epoch: 343 loss: 1.6942797899246216 grad: 6.192152605636938\n",
      "epoch: 344 loss: 1.6811238527297974 grad: 5.874806963710643\n",
      "epoch: 345 loss: 1.683226227760315 grad: 6.0894783560815124\n",
      "epoch: 346 loss: 1.708505630493164 grad: 5.9141984462993795\n",
      "epoch: 347 loss: 1.667019248008728 grad: 5.694799372483733\n",
      "epoch: 348 loss: 1.6944189071655273 grad: 5.800068514726894\n",
      "epoch: 349 loss: 1.6872919797897339 grad: 8.312350072389636\n",
      "epoch: 350 loss: 1.7345789670944214 grad: 7.701483782891002\n",
      "epoch: 351 loss: 1.706781268119812 grad: 6.973958115580418\n",
      "epoch: 352 loss: 1.703445315361023 grad: 6.8926066911113475\n",
      "epoch: 353 loss: 1.7018163204193115 grad: 7.487812380148979\n",
      "epoch: 354 loss: 1.6899681091308594 grad: 7.219945064750925\n",
      "epoch: 355 loss: 1.686265230178833 grad: 5.122674685281781\n",
      "epoch: 356 loss: 1.6876364946365356 grad: 6.051660443647672\n",
      "epoch: 357 loss: 1.6909379959106445 grad: 5.814260799518547\n",
      "epoch: 358 loss: 1.6822601556777954 grad: 6.825264045569384\n",
      "epoch: 359 loss: 1.7045824527740479 grad: 6.943482396230831\n",
      "epoch: 360 loss: 1.6876435279846191 grad: 5.5575621770471955\n",
      "epoch: 361 loss: 1.684723973274231 grad: 6.223304784734556\n",
      "epoch: 362 loss: 1.6765694618225098 grad: 5.856969033013444\n",
      "epoch: 363 loss: 1.6817808151245117 grad: 5.555503106120722\n",
      "epoch: 364 loss: 1.6939107179641724 grad: 5.909364651517997\n",
      "epoch: 365 loss: 1.6779812574386597 grad: 4.416737144473801\n",
      "epoch: 366 loss: 1.6777385473251343 grad: 5.79547950347172\n",
      "epoch: 367 loss: 1.6999428272247314 grad: 6.204396703812\n",
      "epoch: 368 loss: 1.6853638887405396 grad: 6.18818079170948\n",
      "epoch: 369 loss: 1.6828217506408691 grad: 6.898590013205577\n",
      "epoch: 370 loss: 1.6893457174301147 grad: 6.5828023470307855\n",
      "epoch: 371 loss: 1.6849949359893799 grad: 6.7473255792251114\n",
      "epoch: 372 loss: 1.6925231218338013 grad: 5.406127895209899\n",
      "epoch: 373 loss: 1.6725759506225586 grad: 4.984235309719027\n",
      "epoch: 374 loss: 1.662102222442627 grad: 4.474453789463951\n",
      "epoch: 375 loss: 1.6617324352264404 grad: 5.667178729156308\n",
      "epoch: 376 loss: 1.6676267385482788 grad: 6.339529712825064\n",
      "epoch: 377 loss: 1.6844091415405273 grad: 6.729773730526451\n",
      "epoch: 378 loss: 1.6724268198013306 grad: 4.925806283949478\n",
      "epoch: 379 loss: 1.6691370010375977 grad: 6.379968238574581\n",
      "epoch: 380 loss: 1.678513526916504 grad: 5.904493518564819\n",
      "epoch: 381 loss: 1.7060928344726562 grad: 7.127752719687701\n",
      "epoch: 382 loss: 1.6781960725784302 grad: 5.299297419720417\n",
      "epoch: 383 loss: 1.668402910232544 grad: 4.389504797372829\n",
      "epoch: 384 loss: 1.7077869176864624 grad: 6.355636706289217\n",
      "epoch: 385 loss: 1.6854643821716309 grad: 8.03756076241971\n",
      "epoch: 386 loss: 1.7074412107467651 grad: 6.742407761079824\n",
      "epoch: 387 loss: 1.6883854866027832 grad: 5.370496560993872\n",
      "epoch: 388 loss: 1.6708300113677979 grad: 5.570811402872471\n",
      "epoch: 389 loss: 1.6758068799972534 grad: 5.637953415968075\n",
      "epoch: 390 loss: 1.6771419048309326 grad: 6.334749354182003\n",
      "epoch: 391 loss: 1.6950833797454834 grad: 6.155665156547651\n",
      "epoch: 392 loss: 1.6815814971923828 grad: 5.641665477861901\n",
      "epoch: 393 loss: 1.6771000623703003 grad: 6.48374591160872\n",
      "epoch: 394 loss: 1.6726486682891846 grad: 5.746750949777993\n",
      "epoch: 395 loss: 1.6761237382888794 grad: 5.184788628384792\n",
      "epoch: 396 loss: 1.667168378829956 grad: 4.836296743691\n",
      "epoch: 397 loss: 1.6747416257858276 grad: 5.404554150056298\n",
      "epoch: 398 loss: 1.6804131269454956 grad: 6.334008570173735\n",
      "epoch: 399 loss: 1.684739112854004 grad: 5.556761518149263\n",
      "epoch: 400 loss: 1.6771677732467651 grad: 6.021620703590233\n",
      "epoch: 401 loss: 1.6750842332839966 grad: 6.173105860281996\n",
      "epoch: 402 loss: 1.6812019348144531 grad: 4.976992440567142\n",
      "epoch: 403 loss: 1.6839735507965088 grad: 6.582395704119711\n",
      "epoch: 404 loss: 1.680579423904419 grad: 5.396644380830872\n",
      "epoch: 405 loss: 1.6815094947814941 grad: 6.451364481541908\n",
      "epoch: 406 loss: 1.6546992063522339 grad: 5.340454236445892\n",
      "epoch: 407 loss: 1.668725609779358 grad: 6.132480260074569\n",
      "epoch: 408 loss: 1.670708417892456 grad: 6.580523473717149\n",
      "epoch: 409 loss: 1.6585969924926758 grad: 6.37242574800894\n",
      "epoch: 410 loss: 1.6746689081192017 grad: 5.049586033065867\n",
      "epoch: 411 loss: 1.6704516410827637 grad: 5.6960018257263885\n",
      "epoch: 412 loss: 1.7013401985168457 grad: 6.48790941314\n",
      "epoch: 413 loss: 1.6723203659057617 grad: 6.79065881957349\n",
      "epoch: 414 loss: 1.6809723377227783 grad: 5.010293698410893\n",
      "epoch: 415 loss: 1.6573699712753296 grad: 5.847300051285048\n",
      "epoch: 416 loss: 1.6789469718933105 grad: 5.658278011648907\n",
      "epoch: 417 loss: 1.6636695861816406 grad: 5.736738578548818\n",
      "epoch: 418 loss: 1.6762359142303467 grad: 6.043242864675925\n",
      "epoch: 419 loss: 1.6583471298217773 grad: 4.846160955475055\n",
      "epoch: 420 loss: 1.648836374282837 grad: 4.706711552788369\n",
      "epoch: 421 loss: 1.6732593774795532 grad: 5.590597536515845\n",
      "epoch: 422 loss: 1.6743996143341064 grad: 6.427927023617875\n",
      "epoch: 423 loss: 1.6656453609466553 grad: 5.759263915661247\n",
      "epoch: 424 loss: 1.6507550477981567 grad: 5.426486738064366\n",
      "epoch: 425 loss: 1.661985993385315 grad: 6.4227991425368165\n",
      "epoch: 426 loss: 1.6900790929794312 grad: 6.967402212140408\n",
      "epoch: 427 loss: 1.6775151491165161 grad: 6.421484101637274\n",
      "epoch: 428 loss: 1.6709524393081665 grad: 6.612520023390563\n",
      "epoch: 429 loss: 1.6672595739364624 grad: 7.803860143894554\n",
      "epoch: 430 loss: 1.6694071292877197 grad: 5.668003870550675\n",
      "epoch: 431 loss: 1.6635358333587646 grad: 5.128112220048688\n",
      "epoch: 432 loss: 1.6542507410049438 grad: 5.090761698677051\n",
      "epoch: 433 loss: 1.6850948333740234 grad: 7.157616315538226\n",
      "epoch: 434 loss: 1.6729551553726196 grad: 6.49502446682413\n",
      "epoch: 435 loss: 1.659124732017517 grad: 5.9866858312837845\n",
      "epoch: 436 loss: 1.6667866706848145 grad: 5.053407712546774\n",
      "epoch: 437 loss: 1.6880419254302979 grad: 6.181403928829414\n",
      "epoch: 438 loss: 1.6689435243606567 grad: 6.004472353346096\n",
      "epoch: 439 loss: 1.6877238750457764 grad: 5.928291779452752\n",
      "epoch: 440 loss: 1.686856985092163 grad: 5.256431603377144\n",
      "epoch: 441 loss: 1.6737686395645142 grad: 5.005819415836319\n",
      "epoch: 442 loss: 1.6543025970458984 grad: 4.398261007737549\n",
      "epoch: 443 loss: 1.67570161819458 grad: 5.929527849653678\n",
      "epoch: 444 loss: 1.6704740524291992 grad: 6.73529114931813\n",
      "epoch: 445 loss: 1.6806669235229492 grad: 7.774443729355072\n",
      "epoch: 446 loss: 1.678938388824463 grad: 5.01024939041452\n",
      "epoch: 447 loss: 1.6994993686676025 grad: 7.12615744160323\n",
      "epoch: 448 loss: 1.6729766130447388 grad: 5.41780978710856\n",
      "epoch: 449 loss: 1.6738815307617188 grad: 6.098343585534177\n",
      "epoch: 450 loss: 1.6901562213897705 grad: 6.320572310123103\n",
      "epoch: 451 loss: 1.6864815950393677 grad: 5.697705731979084\n",
      "epoch: 452 loss: 1.680885910987854 grad: 5.9445749282275795\n",
      "epoch: 453 loss: 1.6748934984207153 grad: 5.377088324990539\n",
      "epoch: 454 loss: 1.6715673208236694 grad: 5.469369783738171\n",
      "epoch: 455 loss: 1.670244812965393 grad: 6.95311440869516\n",
      "epoch: 456 loss: 1.6671690940856934 grad: 4.743251608774964\n",
      "epoch: 457 loss: 1.6735519170761108 grad: 5.8787511321993335\n",
      "epoch: 458 loss: 1.6572918891906738 grad: 5.632391705856092\n",
      "epoch: 459 loss: 1.6668986082077026 grad: 5.774418547229325\n",
      "epoch: 460 loss: 1.6750025749206543 grad: 6.816282987687228\n",
      "epoch: 461 loss: 1.6759477853775024 grad: 5.11176886422332\n",
      "epoch: 462 loss: 1.6523008346557617 grad: 4.040570472155132\n",
      "epoch: 463 loss: 1.647992730140686 grad: 5.030169566655357\n",
      "epoch: 464 loss: 1.6638221740722656 grad: 5.490627476794825\n",
      "epoch: 465 loss: 1.6371188163757324 grad: 4.458802871582491\n",
      "epoch: 466 loss: 1.6562825441360474 grad: 5.769113640596386\n",
      "epoch: 467 loss: 1.6624186038970947 grad: 7.041636866775257\n",
      "epoch: 468 loss: 1.6660971641540527 grad: 5.954562197610762\n",
      "epoch: 469 loss: 1.686104655265808 grad: 6.198644694056326\n",
      "epoch: 470 loss: 1.6714792251586914 grad: 4.926638321804708\n",
      "epoch: 471 loss: 1.6664992570877075 grad: 7.160104695577686\n",
      "epoch: 472 loss: 1.6574386358261108 grad: 5.887872450045391\n",
      "epoch: 473 loss: 1.6576510667800903 grad: 5.199657849110418\n",
      "epoch: 474 loss: 1.6637115478515625 grad: 4.4811951470365745\n",
      "epoch: 475 loss: 1.6655935049057007 grad: 6.639615874846583\n",
      "epoch: 476 loss: 1.658522129058838 grad: 5.445137575384576\n",
      "epoch: 477 loss: 1.6619893312454224 grad: 6.993860979867447\n",
      "epoch: 478 loss: 1.6665217876434326 grad: 5.755904708037778\n",
      "epoch: 479 loss: 1.6738394498825073 grad: 5.867289857816237\n",
      "epoch: 480 loss: 1.6828035116195679 grad: 6.332726389758078\n",
      "epoch: 481 loss: 1.6467931270599365 grad: 4.703855051753014\n",
      "epoch: 482 loss: 1.6724669933319092 grad: 5.732080150332191\n",
      "epoch: 483 loss: 1.6707895994186401 grad: 5.514735620343605\n",
      "epoch: 484 loss: 1.6611294746398926 grad: 5.691892152829785\n",
      "epoch: 485 loss: 1.6623766422271729 grad: 5.583038183844947\n",
      "epoch: 486 loss: 1.6636261940002441 grad: 5.83691728055584\n",
      "epoch: 487 loss: 1.6662812232971191 grad: 5.244385433953225\n",
      "epoch: 488 loss: 1.6456910371780396 grad: 4.540849193235443\n",
      "epoch: 489 loss: 1.6587802171707153 grad: 5.539363573344431\n",
      "epoch: 490 loss: 1.6472264528274536 grad: 6.212116626959335\n",
      "epoch: 491 loss: 1.6474624872207642 grad: 5.538291692591768\n",
      "epoch: 492 loss: 1.6536997556686401 grad: 6.533931873532729\n",
      "epoch: 493 loss: 1.6578660011291504 grad: 6.031397909800533\n",
      "epoch: 494 loss: 1.6549842357635498 grad: 5.4324144907967575\n",
      "epoch: 495 loss: 1.644835352897644 grad: 5.080989902278043\n",
      "epoch: 496 loss: 1.6437363624572754 grad: 4.90679482529896\n",
      "epoch: 497 loss: 1.6623467206954956 grad: 4.679825637464625\n",
      "epoch: 498 loss: 1.6594268083572388 grad: 4.674417403448316\n",
      "epoch: 499 loss: 1.6524901390075684 grad: 4.515319749147516\n",
      "1.979743354022503\n",
      "epoch: 0 loss: 2.3025546073913574 grad: 1.25612561517979\n",
      "epoch: 1 loss: 2.3029532432556152 grad: 1.250599495157422\n",
      "epoch: 2 loss: 2.302805185317993 grad: 1.265166319633228\n",
      "epoch: 3 loss: 2.3023314476013184 grad: 1.2596355391692162\n",
      "epoch: 4 loss: 2.3025498390197754 grad: 1.2485505306598035\n",
      "epoch: 5 loss: 2.3027026653289795 grad: 1.2552012994807835\n",
      "epoch: 6 loss: 2.302919864654541 grad: 1.2543336229993858\n",
      "epoch: 7 loss: 2.3027005195617676 grad: 1.25425001721467\n",
      "epoch: 8 loss: 2.303452491760254 grad: 1.2425246174864855\n",
      "epoch: 9 loss: 2.303431749343872 grad: 1.2433207310100516\n",
      "epoch: 10 loss: 2.302968740463257 grad: 1.248984720114441\n",
      "epoch: 11 loss: 2.302927017211914 grad: 1.2560880601494795\n",
      "epoch: 12 loss: 2.3029866218566895 grad: 1.2568576922732597\n",
      "epoch: 13 loss: 2.3025598526000977 grad: 1.2541014877931467\n",
      "epoch: 14 loss: 2.302767038345337 grad: 1.2467591408861889\n",
      "epoch: 15 loss: 2.3036677837371826 grad: 1.2453558690797921\n",
      "epoch: 16 loss: 2.302969455718994 grad: 1.2381739749735783\n",
      "epoch: 17 loss: 2.3021812438964844 grad: 1.2600232760203884\n",
      "epoch: 18 loss: 2.3028626441955566 grad: 1.2494541984032987\n",
      "epoch: 19 loss: 2.302861452102661 grad: 1.2575622403750284\n",
      "epoch: 20 loss: 2.303374767303467 grad: 1.2472321300357136\n",
      "epoch: 21 loss: 2.302734613418579 grad: 1.2484263890212224\n",
      "epoch: 22 loss: 2.302616596221924 grad: 1.246194889018726\n",
      "epoch: 23 loss: 2.3025457859039307 grad: 1.2592663469923926\n",
      "epoch: 24 loss: 2.3022143840789795 grad: 1.2517742404403787\n",
      "epoch: 25 loss: 2.3032217025756836 grad: 1.2503758326287395\n",
      "epoch: 26 loss: 2.3025784492492676 grad: 1.2559149309970616\n",
      "epoch: 27 loss: 2.3025009632110596 grad: 1.2598675418486227\n",
      "epoch: 28 loss: 2.302367925643921 grad: 1.2585047755190837\n",
      "epoch: 29 loss: 2.3025975227355957 grad: 1.245745919748313\n",
      "epoch: 30 loss: 2.3029675483703613 grad: 1.2390504284569668\n",
      "epoch: 31 loss: 2.3024661540985107 grad: 1.2510873706057846\n",
      "epoch: 32 loss: 2.3030033111572266 grad: 1.231384680471531\n",
      "epoch: 33 loss: 2.30214786529541 grad: 1.2539829837716376\n",
      "epoch: 34 loss: 2.3029818534851074 grad: 1.2531192992510836\n",
      "epoch: 35 loss: 2.302842140197754 grad: 1.2594446902762033\n",
      "epoch: 36 loss: 2.302347183227539 grad: 1.2532669642167757\n",
      "epoch: 37 loss: 2.302750825881958 grad: 1.2523646276732463\n",
      "epoch: 38 loss: 2.302342176437378 grad: 1.2661976356739326\n",
      "epoch: 39 loss: 2.3034191131591797 grad: 1.2467101205432314\n",
      "epoch: 40 loss: 2.302711248397827 grad: 1.249350317639284\n",
      "epoch: 41 loss: 2.3032777309417725 grad: 1.2461639822438537\n",
      "epoch: 42 loss: 2.302802801132202 grad: 1.246371568042031\n",
      "epoch: 43 loss: 2.3023478984832764 grad: 1.2522076527876336\n",
      "epoch: 44 loss: 2.3025851249694824 grad: 1.248549104764289\n",
      "epoch: 45 loss: 2.302623748779297 grad: 1.2481136017253562\n",
      "epoch: 46 loss: 2.302490711212158 grad: 1.2641285211938094\n",
      "epoch: 47 loss: 2.302968978881836 grad: 1.243154522443619\n",
      "epoch: 48 loss: 2.303273916244507 grad: 1.2419258532657598\n",
      "epoch: 49 loss: 2.3026790618896484 grad: 1.2573696618570784\n",
      "epoch: 50 loss: 2.3027708530426025 grad: 1.2492448685021835\n",
      "epoch: 51 loss: 2.3025619983673096 grad: 1.250026919976956\n",
      "epoch: 52 loss: 2.303372859954834 grad: 1.2448707625292064\n",
      "epoch: 53 loss: 2.302938938140869 grad: 1.2501148021159072\n",
      "epoch: 54 loss: 2.3033804893493652 grad: 1.2463674961962545\n",
      "epoch: 55 loss: 2.302616596221924 grad: 1.2435610467431297\n",
      "epoch: 56 loss: 2.302713632583618 grad: 1.2442027661886568\n",
      "epoch: 57 loss: 2.303011655807495 grad: 1.242490723764243\n",
      "epoch: 58 loss: 2.3026506900787354 grad: 1.2533197511201872\n",
      "epoch: 59 loss: 2.3029956817626953 grad: 1.2359872109031245\n",
      "epoch: 60 loss: 2.3028297424316406 grad: 1.2521948516830832\n",
      "epoch: 61 loss: 2.302445411682129 grad: 1.25043981400178\n",
      "epoch: 62 loss: 2.302258253097534 grad: 1.2535197123116444\n",
      "epoch: 63 loss: 2.3026368618011475 grad: 1.2489722647467658\n",
      "epoch: 64 loss: 2.3021645545959473 grad: 1.2563076040315782\n",
      "epoch: 65 loss: 2.302849054336548 grad: 1.254749114665809\n",
      "epoch: 66 loss: 2.302375316619873 grad: 1.249154976354764\n",
      "epoch: 67 loss: 2.3034772872924805 grad: 1.2425100487058185\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 68 loss: 2.302304267883301 grad: 1.2557477912226218\n",
      "epoch: 69 loss: 2.3033881187438965 grad: 1.2429402422193172\n",
      "epoch: 70 loss: 2.3022680282592773 grad: 1.2473192140441536\n",
      "epoch: 71 loss: 2.3025450706481934 grad: 1.2463641558692509\n",
      "epoch: 72 loss: 2.302631378173828 grad: 1.2525183074952413\n",
      "epoch: 73 loss: 2.302837371826172 grad: 1.2517682780097756\n",
      "epoch: 74 loss: 2.3023531436920166 grad: 1.2501058502765816\n",
      "epoch: 75 loss: 2.3019821643829346 grad: 1.2581711837371428\n",
      "epoch: 76 loss: 2.302419662475586 grad: 1.256874196704418\n",
      "epoch: 77 loss: 2.3026444911956787 grad: 1.24975620866901\n",
      "epoch: 78 loss: 2.3026113510131836 grad: 1.2418485454557138\n",
      "epoch: 79 loss: 2.3030929565429688 grad: 1.2479961209390904\n",
      "epoch: 80 loss: 2.303039789199829 grad: 1.2484158001145318\n",
      "epoch: 81 loss: 2.302297353744507 grad: 1.25484328155428\n",
      "epoch: 82 loss: 2.3023648262023926 grad: 1.260183181273677\n",
      "epoch: 83 loss: 2.3024511337280273 grad: 1.2601585489723623\n",
      "epoch: 84 loss: 2.3024039268493652 grad: 1.2625953501057146\n",
      "epoch: 85 loss: 2.302668333053589 grad: 1.2420555553583812\n",
      "epoch: 86 loss: 2.30271315574646 grad: 1.240318924038937\n",
      "epoch: 87 loss: 2.302917242050171 grad: 1.2395375537638005\n",
      "epoch: 88 loss: 2.3028128147125244 grad: 1.2571433536848793\n",
      "epoch: 89 loss: 2.3026747703552246 grad: 1.2434613520560402\n",
      "epoch: 90 loss: 2.3025870323181152 grad: 1.2454025099120503\n",
      "epoch: 91 loss: 2.303004503250122 grad: 1.2495840840219032\n",
      "epoch: 92 loss: 2.3022773265838623 grad: 1.2522543273027247\n",
      "epoch: 93 loss: 2.302499294281006 grad: 1.250596602754076\n",
      "epoch: 94 loss: 2.3024022579193115 grad: 1.2556298404880282\n",
      "epoch: 95 loss: 2.3027026653289795 grad: 1.247302147875806\n",
      "epoch: 96 loss: 2.302422046661377 grad: 1.2602637759502238\n",
      "epoch: 97 loss: 2.3028078079223633 grad: 1.2506056158463397\n",
      "epoch: 98 loss: 2.3024253845214844 grad: 1.257871813591688\n",
      "epoch: 99 loss: 2.3027212619781494 grad: 1.2568576218918823\n",
      "epoch: 100 loss: 2.302493095397949 grad: 1.2364674198574253\n",
      "epoch: 101 loss: 2.303363800048828 grad: 1.2451480330163909\n",
      "epoch: 102 loss: 2.302530527114868 grad: 1.254533555807679\n",
      "epoch: 103 loss: 2.30265212059021 grad: 1.2497465872715803\n",
      "epoch: 104 loss: 2.303022861480713 grad: 1.243666624328831\n",
      "epoch: 105 loss: 2.3032100200653076 grad: 1.2404458328918924\n",
      "epoch: 106 loss: 2.3023853302001953 grad: 1.252793121059233\n",
      "epoch: 107 loss: 2.302381753921509 grad: 1.2537690220670479\n",
      "epoch: 108 loss: 2.302126169204712 grad: 1.2587536237394763\n",
      "epoch: 109 loss: 2.3027849197387695 grad: 1.2518506575272315\n",
      "epoch: 110 loss: 2.3023314476013184 grad: 1.2533541927816316\n",
      "epoch: 111 loss: 2.3028488159179688 grad: 1.2451412767903614\n",
      "epoch: 112 loss: 2.3025197982788086 grad: 1.2515415661831548\n",
      "epoch: 113 loss: 2.3036210536956787 grad: 1.2358426763380448\n",
      "epoch: 114 loss: 2.3023881912231445 grad: 1.2535191394595637\n",
      "epoch: 115 loss: 2.303002119064331 grad: 1.2461958497297019\n",
      "epoch: 116 loss: 2.3027000427246094 grad: 1.251649018386305\n",
      "epoch: 117 loss: 2.30269455909729 grad: 1.2472263865675481\n",
      "epoch: 118 loss: 2.302330493927002 grad: 1.2477238306568728\n",
      "epoch: 119 loss: 2.3031628131866455 grad: 1.238697297507084\n",
      "epoch: 120 loss: 2.3023924827575684 grad: 1.2533913627913635\n",
      "epoch: 121 loss: 2.302839517593384 grad: 1.2351953673254077\n",
      "epoch: 122 loss: 2.3025097846984863 grad: 1.2569052363054767\n",
      "epoch: 123 loss: 2.302689552307129 grad: 1.2448886928133784\n",
      "epoch: 124 loss: 2.3028476238250732 grad: 1.2488290588112756\n",
      "epoch: 125 loss: 2.3032493591308594 grad: 1.2408959909216575\n",
      "epoch: 126 loss: 2.3026175498962402 grad: 1.2482117269084685\n",
      "epoch: 127 loss: 2.3037965297698975 grad: 1.2321835567912323\n",
      "epoch: 128 loss: 2.303253650665283 grad: 1.2436301057256522\n",
      "epoch: 129 loss: 2.302490472793579 grad: 1.2473114486340255\n",
      "epoch: 130 loss: 2.303041696548462 grad: 1.244758688460385\n",
      "epoch: 131 loss: 2.3031532764434814 grad: 1.241589320904856\n",
      "epoch: 132 loss: 2.3029279708862305 grad: 1.2572181985754194\n",
      "epoch: 133 loss: 2.3022937774658203 grad: 1.2464187803460167\n",
      "epoch: 134 loss: 2.3026881217956543 grad: 1.2398946752701516\n",
      "epoch: 135 loss: 2.3025760650634766 grad: 1.2525986594772558\n",
      "epoch: 136 loss: 2.3028883934020996 grad: 1.2412871824178313\n",
      "epoch: 137 loss: 2.3026812076568604 grad: 1.2471809685193298\n",
      "epoch: 138 loss: 2.3025197982788086 grad: 1.243847617866575\n",
      "epoch: 139 loss: 2.302555561065674 grad: 1.2528749782285313\n",
      "epoch: 140 loss: 2.3026583194732666 grad: 1.230663471293473\n",
      "epoch: 141 loss: 2.3025307655334473 grad: 1.2418873506202732\n",
      "epoch: 142 loss: 2.303225040435791 grad: 1.2289708557590429\n",
      "epoch: 143 loss: 2.303067445755005 grad: 1.246481386148223\n",
      "epoch: 144 loss: 2.3023037910461426 grad: 1.2500189519709064\n",
      "epoch: 145 loss: 2.3029582500457764 grad: 1.239631438280441\n",
      "epoch: 146 loss: 2.302381992340088 grad: 1.253874984028424\n",
      "epoch: 147 loss: 2.3028500080108643 grad: 1.2395343180073217\n",
      "epoch: 148 loss: 2.3021864891052246 grad: 1.258172484332814\n",
      "epoch: 149 loss: 2.30234432220459 grad: 1.253135868189265\n",
      "epoch: 150 loss: 2.3023431301116943 grad: 1.2402179559955138\n",
      "epoch: 151 loss: 2.3029849529266357 grad: 1.2415347617167596\n",
      "epoch: 152 loss: 2.302309989929199 grad: 1.2490421844395025\n",
      "epoch: 153 loss: 2.3030879497528076 grad: 1.2317353178514168\n",
      "epoch: 154 loss: 2.3027334213256836 grad: 1.241282893732811\n",
      "epoch: 155 loss: 2.302823781967163 grad: 1.2404879846162946\n",
      "epoch: 156 loss: 2.3023648262023926 grad: 1.2479582322051836\n",
      "epoch: 157 loss: 2.3027610778808594 grad: 1.245940159209856\n",
      "epoch: 158 loss: 2.3023903369903564 grad: 1.2453664410378902\n",
      "epoch: 159 loss: 2.3031704425811768 grad: 1.2509514881641648\n",
      "epoch: 160 loss: 2.3025898933410645 grad: 1.2452001054069057\n",
      "epoch: 161 loss: 2.3024091720581055 grad: 1.2435363204632368\n",
      "epoch: 162 loss: 2.3026492595672607 grad: 1.2453019442609585\n",
      "epoch: 163 loss: 2.3025100231170654 grad: 1.2453890051434024\n",
      "epoch: 164 loss: 2.3029792308807373 grad: 1.2418851880412105\n",
      "epoch: 165 loss: 2.30285382270813 grad: 1.2515643078885559\n",
      "epoch: 166 loss: 2.303358316421509 grad: 1.232146045435146\n",
      "epoch: 167 loss: 2.302452564239502 grad: 1.2386590538154696\n",
      "epoch: 168 loss: 2.303079128265381 grad: 1.2342887255954482\n",
      "epoch: 169 loss: 2.303104877471924 grad: 1.235109445942004\n",
      "epoch: 170 loss: 2.3027186393737793 grad: 1.2395729237154776\n",
      "epoch: 171 loss: 2.302682399749756 grad: 1.2354389941523087\n",
      "epoch: 172 loss: 2.302868127822876 grad: 1.2510056875328281\n",
      "epoch: 173 loss: 2.3028671741485596 grad: 1.2415980548590482\n",
      "epoch: 174 loss: 2.3024892807006836 grad: 1.2555695283596242\n",
      "epoch: 175 loss: 2.3026957511901855 grad: 1.2413227655315062\n",
      "epoch: 176 loss: 2.3030097484588623 grad: 1.2431093044172499\n",
      "epoch: 177 loss: 2.3026041984558105 grad: 1.2408903139026186\n",
      "epoch: 178 loss: 2.3030788898468018 grad: 1.2295877829301245\n",
      "epoch: 179 loss: 2.3025622367858887 grad: 1.243443011040134\n",
      "epoch: 180 loss: 2.302494764328003 grad: 1.2412060087506054\n",
      "epoch: 181 loss: 2.3030691146850586 grad: 1.2361307174543894\n",
      "epoch: 182 loss: 2.3028128147125244 grad: 1.239522513382817\n",
      "epoch: 183 loss: 2.3024020195007324 grad: 1.2374532993066139\n",
      "epoch: 184 loss: 2.3022377490997314 grad: 1.2487888560271896\n",
      "epoch: 185 loss: 2.302412271499634 grad: 1.247324894490977\n",
      "epoch: 186 loss: 2.3029909133911133 grad: 1.2305350486957838\n",
      "epoch: 187 loss: 2.3023412227630615 grad: 1.248051525485362\n",
      "epoch: 188 loss: 2.30271315574646 grad: 1.2429643582186796\n",
      "epoch: 189 loss: 2.3026604652404785 grad: 1.2450659111094113\n",
      "epoch: 190 loss: 2.3023242950439453 grad: 1.2466572859612781\n",
      "epoch: 191 loss: 2.3032631874084473 grad: 1.2389796297952889\n",
      "epoch: 192 loss: 2.3026599884033203 grad: 1.2289940960749628\n",
      "epoch: 193 loss: 2.3028459548950195 grad: 1.2403065478484634\n",
      "epoch: 194 loss: 2.302600383758545 grad: 1.2455905454181548\n",
      "epoch: 195 loss: 2.3027560710906982 grad: 1.2432799493147444\n",
      "epoch: 196 loss: 2.3021390438079834 grad: 1.2498104842841655\n",
      "epoch: 197 loss: 2.302929639816284 grad: 1.241553550602735\n",
      "epoch: 198 loss: 2.302481174468994 grad: 1.2426303550342306\n",
      "epoch: 199 loss: 2.302497625350952 grad: 1.2499717891046276\n",
      "epoch: 200 loss: 2.3024415969848633 grad: 1.244631478605452\n",
      "epoch: 201 loss: 2.3025577068328857 grad: 1.247290555337843\n",
      "epoch: 202 loss: 2.302898406982422 grad: 1.2501205230087398\n",
      "epoch: 203 loss: 2.3028383255004883 grad: 1.245773302624002\n",
      "epoch: 204 loss: 2.3021559715270996 grad: 1.2450215376059834\n",
      "epoch: 205 loss: 2.3024184703826904 grad: 1.2482766847436626\n",
      "epoch: 206 loss: 2.302495002746582 grad: 1.2491475081437133\n",
      "epoch: 207 loss: 2.302365303039551 grad: 1.2445941545339005\n",
      "epoch: 208 loss: 2.302218437194824 grad: 1.2514891509883224\n",
      "epoch: 209 loss: 2.3025569915771484 grad: 1.2468147369892528\n",
      "epoch: 210 loss: 2.303075075149536 grad: 1.2371964184548854\n",
      "epoch: 211 loss: 2.303154706954956 grad: 1.2385287908763285\n",
      "epoch: 212 loss: 2.302528142929077 grad: 1.2410798793148605\n",
      "epoch: 213 loss: 2.3031885623931885 grad: 1.2391143039844574\n",
      "epoch: 214 loss: 2.3034634590148926 grad: 1.2283171405867925\n",
      "epoch: 215 loss: 2.3028039932250977 grad: 1.237175445687691\n",
      "epoch: 216 loss: 2.302858829498291 grad: 1.229357989105795\n",
      "epoch: 217 loss: 2.302487373352051 grad: 1.2407337261921918\n",
      "epoch: 218 loss: 2.302521228790283 grad: 1.2480290175031221\n",
      "epoch: 219 loss: 2.303091526031494 grad: 1.2333988934249012\n",
      "epoch: 220 loss: 2.3029680252075195 grad: 1.2402939684781438\n",
      "epoch: 221 loss: 2.3031678199768066 grad: 1.2273900403995954\n",
      "epoch: 222 loss: 2.3027918338775635 grad: 1.2457110030717025\n",
      "epoch: 223 loss: 2.3027288913726807 grad: 1.2403608643013748\n",
      "epoch: 224 loss: 2.3024964332580566 grad: 1.240943353338581\n",
      "epoch: 225 loss: 2.3028221130371094 grad: 1.2400027907117166\n",
      "epoch: 226 loss: 2.302807569503784 grad: 1.235056987143166\n",
      "epoch: 227 loss: 2.30244779586792 grad: 1.2470663313639336\n",
      "epoch: 228 loss: 2.3023300170898438 grad: 1.2386439351350187\n",
      "epoch: 229 loss: 2.3029916286468506 grad: 1.2324726560674164\n",
      "epoch: 230 loss: 2.3029067516326904 grad: 1.2390766346952804\n",
      "epoch: 231 loss: 2.302705764770508 grad: 1.2408013776543416\n",
      "epoch: 232 loss: 2.3026366233825684 grad: 1.2409467915782617\n",
      "epoch: 233 loss: 2.3025808334350586 grad: 1.2411424635118613\n",
      "epoch: 234 loss: 2.3029704093933105 grad: 1.2380306777499972\n",
      "epoch: 235 loss: 2.3022570610046387 grad: 1.240504308803273\n",
      "epoch: 236 loss: 2.3025968074798584 grad: 1.2360003766648116\n",
      "epoch: 237 loss: 2.3024203777313232 grad: 1.2478838646987689\n",
      "epoch: 238 loss: 2.302305221557617 grad: 1.236646021671948\n",
      "epoch: 239 loss: 2.3023996353149414 grad: 1.2382405160682364\n",
      "epoch: 240 loss: 2.3027989864349365 grad: 1.2286218734262215\n",
      "epoch: 241 loss: 2.3027374744415283 grad: 1.2460271747346732\n",
      "epoch: 242 loss: 2.301990270614624 grad: 1.2515442704870587\n",
      "epoch: 243 loss: 2.3029470443725586 grad: 1.2444803621527547\n",
      "epoch: 244 loss: 2.302952289581299 grad: 1.2380949496956808\n",
      "epoch: 245 loss: 2.302952289581299 grad: 1.2377695628212735\n",
      "epoch: 246 loss: 2.3017947673797607 grad: 1.2484605644297386\n",
      "epoch: 247 loss: 2.3025753498077393 grad: 1.2401279076187324\n",
      "epoch: 248 loss: 2.301990032196045 grad: 1.2535033127669954\n",
      "epoch: 249 loss: 2.3031692504882812 grad: 1.225593282467878\n",
      "epoch: 250 loss: 2.3028035163879395 grad: 1.2303561957678684\n",
      "epoch: 251 loss: 2.302300214767456 grad: 1.247350520871964\n",
      "epoch: 252 loss: 2.3029425144195557 grad: 1.2412802370760354\n",
      "epoch: 253 loss: 2.3026483058929443 grad: 1.2470356915552643\n",
      "epoch: 254 loss: 2.302295684814453 grad: 1.2368601513472164\n",
      "epoch: 255 loss: 2.3027102947235107 grad: 1.2269588983820987\n",
      "epoch: 256 loss: 2.3026835918426514 grad: 1.242365096643981\n",
      "epoch: 257 loss: 2.3027093410491943 grad: 1.2315256762621363\n",
      "epoch: 258 loss: 2.3023488521575928 grad: 1.2416394195770697\n",
      "epoch: 259 loss: 2.3028383255004883 grad: 1.2418480795117035\n",
      "epoch: 260 loss: 2.301971912384033 grad: 1.2614473437572578\n",
      "epoch: 261 loss: 2.3027026653289795 grad: 1.2398907301470725\n",
      "epoch: 262 loss: 2.302676200866699 grad: 1.2393641728456946\n",
      "epoch: 263 loss: 2.302781581878662 grad: 1.2274514804557262\n",
      "epoch: 264 loss: 2.303013801574707 grad: 1.22867439156546\n",
      "epoch: 265 loss: 2.3025758266448975 grad: 1.2391623644221073\n",
      "epoch: 266 loss: 2.302748441696167 grad: 1.236242044613593\n",
      "epoch: 267 loss: 2.3025286197662354 grad: 1.24197562855284\n",
      "epoch: 268 loss: 2.303159475326538 grad: 1.235877541426037\n",
      "epoch: 269 loss: 2.3026065826416016 grad: 1.2349386345262505\n",
      "epoch: 270 loss: 2.302135944366455 grad: 1.2375090673717388\n",
      "epoch: 271 loss: 2.3024208545684814 grad: 1.237402121785895\n",
      "epoch: 272 loss: 2.3023488521575928 grad: 1.2452152519383364\n",
      "epoch: 273 loss: 2.3028759956359863 grad: 1.2372514131157437\n",
      "epoch: 274 loss: 2.3026773929595947 grad: 1.2372183107645325\n",
      "epoch: 275 loss: 2.303133726119995 grad: 1.218605585261396\n",
      "epoch: 276 loss: 2.301901340484619 grad: 1.237839539343166\n",
      "epoch: 277 loss: 2.3027725219726562 grad: 1.2373744311653787\n",
      "epoch: 278 loss: 2.3027076721191406 grad: 1.230746923154959\n",
      "epoch: 279 loss: 2.303025722503662 grad: 1.2316275716977312\n",
      "epoch: 280 loss: 2.303273916244507 grad: 1.2227000633239864\n",
      "epoch: 281 loss: 2.3030309677124023 grad: 1.231638002172408\n",
      "epoch: 282 loss: 2.3028323650360107 grad: 1.2315872456926469\n",
      "epoch: 283 loss: 2.302292823791504 grad: 1.2455684340462858\n",
      "epoch: 284 loss: 2.302602529525757 grad: 1.2356158261342596\n",
      "epoch: 285 loss: 2.3026022911071777 grad: 1.2348051204028287\n",
      "epoch: 286 loss: 2.302826404571533 grad: 1.2334952416094316\n",
      "epoch: 287 loss: 2.3024849891662598 grad: 1.2449210634739656\n",
      "epoch: 288 loss: 2.3026602268218994 grad: 1.238467321503863\n",
      "epoch: 289 loss: 2.3021981716156006 grad: 1.2433354548134266\n",
      "epoch: 290 loss: 2.302309274673462 grad: 1.2397312826499165\n",
      "epoch: 291 loss: 2.3025195598602295 grad: 1.2380161032760664\n",
      "epoch: 292 loss: 2.3031673431396484 grad: 1.2316228826992244\n",
      "epoch: 293 loss: 2.302544116973877 grad: 1.239334641926227\n",
      "epoch: 294 loss: 2.3029026985168457 grad: 1.2374160771576008\n",
      "epoch: 295 loss: 2.302170991897583 grad: 1.2410997105448225\n",
      "epoch: 296 loss: 2.302361011505127 grad: 1.2377574936198514\n",
      "epoch: 297 loss: 2.3027608394622803 grad: 1.2388421500061033\n",
      "epoch: 298 loss: 2.3038153648376465 grad: 1.2217760449293853\n",
      "epoch: 299 loss: 2.3025543689727783 grad: 1.2397057114627272\n",
      "epoch: 300 loss: 2.302527904510498 grad: 1.2381216602192984\n",
      "epoch: 301 loss: 2.3032538890838623 grad: 1.227942400238669\n",
      "epoch: 302 loss: 2.3022103309631348 grad: 1.237525196352397\n",
      "epoch: 303 loss: 2.3022871017456055 grad: 1.2384293867397078\n",
      "epoch: 304 loss: 2.3030731678009033 grad: 1.2391852586371233\n",
      "epoch: 305 loss: 2.3025331497192383 grad: 1.2269170737126842\n",
      "epoch: 306 loss: 2.3026652336120605 grad: 1.23867635717172\n",
      "epoch: 307 loss: 2.303008556365967 grad: 1.235849420349705\n",
      "epoch: 308 loss: 2.3024120330810547 grad: 1.2359094833567117\n",
      "epoch: 309 loss: 2.3026628494262695 grad: 1.2429875638280508\n",
      "epoch: 310 loss: 2.3029110431671143 grad: 1.2287284990676517\n",
      "epoch: 311 loss: 2.302605390548706 grad: 1.2423181851590348\n",
      "epoch: 312 loss: 2.3020052909851074 grad: 1.2451838586398118\n",
      "epoch: 313 loss: 2.3025448322296143 grad: 1.236302160432503\n",
      "epoch: 314 loss: 2.3029658794403076 grad: 1.2368311853026084\n",
      "epoch: 315 loss: 2.303050994873047 grad: 1.2322038680810246\n",
      "epoch: 316 loss: 2.3030829429626465 grad: 1.2281747917932946\n",
      "epoch: 317 loss: 2.302849531173706 grad: 1.2460547738675294\n",
      "epoch: 318 loss: 2.3026905059814453 grad: 1.2367263302458302\n",
      "epoch: 319 loss: 2.3027002811431885 grad: 1.2402072178055754\n",
      "epoch: 320 loss: 2.302809000015259 grad: 1.2329668106219274\n",
      "epoch: 321 loss: 2.3028154373168945 grad: 1.2342394893926139\n",
      "epoch: 322 loss: 2.30226469039917 grad: 1.2415226558740768\n",
      "epoch: 323 loss: 2.302517890930176 grad: 1.2353670983575284\n",
      "epoch: 324 loss: 2.3024563789367676 grad: 1.2444193935380243\n",
      "epoch: 325 loss: 2.302490711212158 grad: 1.231478925204895\n",
      "epoch: 326 loss: 2.3024237155914307 grad: 1.242230569993678\n",
      "epoch: 327 loss: 2.3032119274139404 grad: 1.2271358354334971\n",
      "epoch: 328 loss: 2.30216121673584 grad: 1.2430759783083987\n",
      "epoch: 329 loss: 2.302950143814087 grad: 1.2251978115962139\n",
      "epoch: 330 loss: 2.302319288253784 grad: 1.2381824474146088\n",
      "epoch: 331 loss: 2.3030307292938232 grad: 1.2281417315881256\n",
      "epoch: 332 loss: 2.302293300628662 grad: 1.2319429851384716\n",
      "epoch: 333 loss: 2.302797794342041 grad: 1.2282775860937638\n",
      "epoch: 334 loss: 2.3028645515441895 grad: 1.2340383279333187\n",
      "epoch: 335 loss: 2.30242657661438 grad: 1.2384545488896528\n",
      "epoch: 336 loss: 2.3025715351104736 grad: 1.234393529721447\n",
      "epoch: 337 loss: 2.303413152694702 grad: 1.223988918862897\n",
      "epoch: 338 loss: 2.3025760650634766 grad: 1.2385727973481166\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 339 loss: 2.302469253540039 grad: 1.2427845140808218\n",
      "epoch: 340 loss: 2.3029189109802246 grad: 1.2278407623451795\n",
      "epoch: 341 loss: 2.3029632568359375 grad: 1.2317447616729797\n",
      "epoch: 342 loss: 2.302964687347412 grad: 1.2227363772487032\n",
      "epoch: 343 loss: 2.302739143371582 grad: 1.23578570789421\n",
      "epoch: 344 loss: 2.302690267562866 grad: 1.2397558390133319\n",
      "epoch: 345 loss: 2.302560329437256 grad: 1.2443747019842415\n",
      "epoch: 346 loss: 2.302471160888672 grad: 1.2278300425156006\n",
      "epoch: 347 loss: 2.302839517593384 grad: 1.2290954068968338\n",
      "epoch: 348 loss: 2.303027391433716 grad: 1.2246918114704184\n",
      "epoch: 349 loss: 2.3029704093933105 grad: 1.2273471149179849\n",
      "epoch: 350 loss: 2.3032021522521973 grad: 1.23166227459331\n",
      "epoch: 351 loss: 2.30265212059021 grad: 1.2397132272340565\n",
      "epoch: 352 loss: 2.302461624145508 grad: 1.2330117301113668\n",
      "epoch: 353 loss: 2.3023769855499268 grad: 1.2381320048145772\n",
      "epoch: 354 loss: 2.3026065826416016 grad: 1.236515245160147\n",
      "epoch: 355 loss: 2.3020315170288086 grad: 1.249892028780388\n",
      "epoch: 356 loss: 2.302320718765259 grad: 1.2407610357095975\n",
      "epoch: 357 loss: 2.3027760982513428 grad: 1.238119354704395\n",
      "epoch: 358 loss: 2.302222490310669 grad: 1.2437601317023297\n",
      "epoch: 359 loss: 2.302598237991333 grad: 1.2351197408926156\n",
      "epoch: 360 loss: 2.3028416633605957 grad: 1.2392743432059115\n",
      "epoch: 361 loss: 2.30283260345459 grad: 1.230910697667342\n",
      "epoch: 362 loss: 2.3030569553375244 grad: 1.2352450570232043\n",
      "epoch: 363 loss: 2.301953077316284 grad: 1.2290420509941344\n",
      "epoch: 364 loss: 2.3021702766418457 grad: 1.253528467721365\n",
      "epoch: 365 loss: 2.3020098209381104 grad: 1.2435265547496133\n",
      "epoch: 366 loss: 2.3028759956359863 grad: 1.2263443458489038\n",
      "epoch: 367 loss: 2.302990674972534 grad: 1.2354887058045567\n",
      "epoch: 368 loss: 2.302682638168335 grad: 1.233548293963799\n",
      "epoch: 369 loss: 2.302631378173828 grad: 1.2335029782187785\n",
      "epoch: 370 loss: 2.302513360977173 grad: 1.2429016126663468\n",
      "epoch: 371 loss: 2.3026411533355713 grad: 1.2263310993929202\n",
      "epoch: 372 loss: 2.302402973175049 grad: 1.2264921089619516\n",
      "epoch: 373 loss: 2.3028621673583984 grad: 1.2269649707050698\n",
      "epoch: 374 loss: 2.302910804748535 grad: 1.2251347633270873\n",
      "epoch: 375 loss: 2.303295850753784 grad: 1.2209619471917874\n",
      "epoch: 376 loss: 2.30328106880188 grad: 1.2212982215560115\n",
      "epoch: 377 loss: 2.303392171859741 grad: 1.2334159627734196\n",
      "epoch: 378 loss: 2.302825450897217 grad: 1.2316811570365513\n",
      "epoch: 379 loss: 2.302058219909668 grad: 1.246573364798216\n",
      "epoch: 380 loss: 2.3026227951049805 grad: 1.232690955493747\n",
      "epoch: 381 loss: 2.302441120147705 grad: 1.2390766623910399\n",
      "epoch: 382 loss: 2.3026061058044434 grad: 1.2315383159004831\n",
      "epoch: 383 loss: 2.302851676940918 grad: 1.227264256236912\n",
      "epoch: 384 loss: 2.30236554145813 grad: 1.239133930434325\n",
      "epoch: 385 loss: 2.3023552894592285 grad: 1.2339195519434436\n",
      "epoch: 386 loss: 2.3023841381073 grad: 1.2369442560843058\n",
      "epoch: 387 loss: 2.302511215209961 grad: 1.2412575187516355\n",
      "epoch: 388 loss: 2.3025994300842285 grad: 1.2416887304945183\n",
      "epoch: 389 loss: 2.302156686782837 grad: 1.238868836825344\n",
      "epoch: 390 loss: 2.302635669708252 grad: 1.2359497331744356\n",
      "epoch: 391 loss: 2.302947759628296 grad: 1.2243076366860242\n",
      "epoch: 392 loss: 2.3027734756469727 grad: 1.2353340073004513\n",
      "epoch: 393 loss: 2.303138256072998 grad: 1.2224411784268414\n",
      "epoch: 394 loss: 2.303067445755005 grad: 1.22454390530881\n",
      "epoch: 395 loss: 2.3028247356414795 grad: 1.2341026826244261\n",
      "epoch: 396 loss: 2.302919387817383 grad: 1.2277700375573384\n",
      "epoch: 397 loss: 2.3026716709136963 grad: 1.225725222098094\n",
      "epoch: 398 loss: 2.303065061569214 grad: 1.2305512883005634\n",
      "epoch: 399 loss: 2.3030128479003906 grad: 1.2326081815962902\n",
      "epoch: 400 loss: 2.303156852722168 grad: 1.2212659932898418\n",
      "epoch: 401 loss: 2.3029139041900635 grad: 1.2277644119014786\n",
      "epoch: 402 loss: 2.3029348850250244 grad: 1.2238412237179184\n",
      "epoch: 403 loss: 2.3024039268493652 grad: 1.2392716074292178\n",
      "epoch: 404 loss: 2.303055763244629 grad: 1.2295841736689446\n",
      "epoch: 405 loss: 2.303410053253174 grad: 1.223027737001844\n",
      "epoch: 406 loss: 2.302421808242798 grad: 1.2300210102084315\n",
      "epoch: 407 loss: 2.3022677898406982 grad: 1.2313677283236757\n",
      "epoch: 408 loss: 2.3025641441345215 grad: 1.2367687339650555\n",
      "epoch: 409 loss: 2.3025951385498047 grad: 1.2366388466242435\n",
      "epoch: 410 loss: 2.3023767471313477 grad: 1.2408448953998261\n",
      "epoch: 411 loss: 2.30289363861084 grad: 1.2225651524569248\n",
      "epoch: 412 loss: 2.3027584552764893 grad: 1.2239017736791293\n",
      "epoch: 413 loss: 2.3021693229675293 grad: 1.2339122370643067\n",
      "epoch: 414 loss: 2.302567958831787 grad: 1.2358440133088844\n",
      "epoch: 415 loss: 2.302959442138672 grad: 1.2305128134986651\n",
      "epoch: 416 loss: 2.302675485610962 grad: 1.2360820068815161\n",
      "epoch: 417 loss: 2.3028032779693604 grad: 1.2332035859784347\n",
      "epoch: 418 loss: 2.3021738529205322 grad: 1.2343840360427127\n",
      "epoch: 419 loss: 2.3025240898132324 grad: 1.2343808701298835\n",
      "epoch: 420 loss: 2.3025448322296143 grad: 1.231180867021312\n",
      "epoch: 421 loss: 2.3025624752044678 grad: 1.2317714911057718\n",
      "epoch: 422 loss: 2.3022220134735107 grad: 1.238161724554153\n",
      "epoch: 423 loss: 2.3030848503112793 grad: 1.2270869833624198\n",
      "epoch: 424 loss: 2.3026530742645264 grad: 1.2371669068954707\n",
      "epoch: 425 loss: 2.303507089614868 grad: 1.2252796307217242\n",
      "epoch: 426 loss: 2.3024966716766357 grad: 1.2280273031321398\n",
      "epoch: 427 loss: 2.302532196044922 grad: 1.2257175250902832\n",
      "epoch: 428 loss: 2.3028695583343506 grad: 1.2310056260247375\n",
      "epoch: 429 loss: 2.302417755126953 grad: 1.2374726518090549\n",
      "epoch: 430 loss: 2.302669048309326 grad: 1.228950434706233\n",
      "epoch: 431 loss: 2.3019649982452393 grad: 1.247682789128111\n",
      "epoch: 432 loss: 2.302480459213257 grad: 1.235711090700952\n",
      "epoch: 433 loss: 2.3022844791412354 grad: 1.2368389407453675\n",
      "epoch: 434 loss: 2.3024771213531494 grad: 1.242621292840571\n",
      "epoch: 435 loss: 2.302750825881958 grad: 1.2340839162047597\n",
      "epoch: 436 loss: 2.302445650100708 grad: 1.2389828169271202\n",
      "epoch: 437 loss: 2.3021230697631836 grad: 1.236207045420694\n",
      "epoch: 438 loss: 2.3030333518981934 grad: 1.2299739518978943\n",
      "epoch: 439 loss: 2.3027138710021973 grad: 1.2283410383499271\n",
      "epoch: 440 loss: 2.3022429943084717 grad: 1.2316857910759391\n",
      "epoch: 441 loss: 2.3029184341430664 grad: 1.2265362368013326\n",
      "epoch: 442 loss: 2.301501750946045 grad: 1.236080944519638\n",
      "epoch: 443 loss: 2.302504062652588 grad: 1.2296579804415593\n",
      "epoch: 444 loss: 2.302615165710449 grad: 1.230472592381938\n",
      "epoch: 445 loss: 2.3026227951049805 grad: 1.237081066899312\n",
      "epoch: 446 loss: 2.30293869972229 grad: 1.235203742565188\n",
      "epoch: 447 loss: 2.3027076721191406 grad: 1.2291358962621806\n",
      "epoch: 448 loss: 2.3024847507476807 grad: 1.2367898736829086\n",
      "epoch: 449 loss: 2.3026256561279297 grad: 1.2333889457652167\n",
      "epoch: 450 loss: 2.3029236793518066 grad: 1.2270183300429454\n",
      "epoch: 451 loss: 2.3031094074249268 grad: 1.2283935761300935\n",
      "epoch: 452 loss: 2.302699565887451 grad: 1.2357654629685428\n",
      "epoch: 453 loss: 2.3029439449310303 grad: 1.232554869500861\n",
      "epoch: 454 loss: 2.3020265102386475 grad: 1.2450308944505182\n",
      "epoch: 455 loss: 2.302253246307373 grad: 1.2323740953283886\n",
      "epoch: 456 loss: 2.302703380584717 grad: 1.2297600325148936\n",
      "epoch: 457 loss: 2.3019049167633057 grad: 1.2455495159688688\n",
      "epoch: 458 loss: 2.3029727935791016 grad: 1.2161827621656278\n",
      "epoch: 459 loss: 2.302663803100586 grad: 1.2341770129241345\n",
      "epoch: 460 loss: 2.302583932876587 grad: 1.2300842907224294\n",
      "epoch: 461 loss: 2.302884578704834 grad: 1.2309389083520583\n",
      "epoch: 462 loss: 2.3023440837860107 grad: 1.2214859763219479\n",
      "epoch: 463 loss: 2.3024537563323975 grad: 1.2288746697576864\n",
      "epoch: 464 loss: 2.30244517326355 grad: 1.2285176905552073\n",
      "epoch: 465 loss: 2.3026976585388184 grad: 1.2197610336644131\n",
      "epoch: 466 loss: 2.3027868270874023 grad: 1.2303680697592745\n",
      "epoch: 467 loss: 2.3026015758514404 grad: 1.2166919902443798\n",
      "epoch: 468 loss: 2.302395820617676 grad: 1.234108329355155\n",
      "epoch: 469 loss: 2.302616834640503 grad: 1.2262751910417888\n",
      "epoch: 470 loss: 2.3025143146514893 grad: 1.2337776466849304\n",
      "epoch: 471 loss: 2.3024675846099854 grad: 1.2280323160479643\n",
      "epoch: 472 loss: 2.3023269176483154 grad: 1.2373088133421593\n",
      "epoch: 473 loss: 2.302469491958618 grad: 1.2298440255394707\n",
      "epoch: 474 loss: 2.3027215003967285 grad: 1.2301504091500113\n",
      "epoch: 475 loss: 2.302563190460205 grad: 1.2349662602775626\n",
      "epoch: 476 loss: 2.303217887878418 grad: 1.223390552808442\n",
      "epoch: 477 loss: 2.3027825355529785 grad: 1.2225002413597106\n",
      "epoch: 478 loss: 2.3024778366088867 grad: 1.2402093132222367\n",
      "epoch: 479 loss: 2.3026773929595947 grad: 1.2283024047187248\n",
      "epoch: 480 loss: 2.3022212982177734 grad: 1.239125729771331\n",
      "epoch: 481 loss: 2.3028855323791504 grad: 1.2353848979553386\n",
      "epoch: 482 loss: 2.3020734786987305 grad: 1.2512610769656944\n",
      "epoch: 483 loss: 2.3031527996063232 grad: 1.2318253287849652\n",
      "epoch: 484 loss: 2.3030879497528076 grad: 1.2187123241841733\n",
      "epoch: 485 loss: 2.3030288219451904 grad: 1.228744933202434\n",
      "epoch: 486 loss: 2.3028299808502197 grad: 1.2325247449390146\n",
      "epoch: 487 loss: 2.302734136581421 grad: 1.2254075030094043\n",
      "epoch: 488 loss: 2.302664279937744 grad: 1.233017503607294\n",
      "epoch: 489 loss: 2.3021717071533203 grad: 1.2363777673999143\n",
      "epoch: 490 loss: 2.3028478622436523 grad: 1.2274031112144244\n",
      "epoch: 491 loss: 2.3026201725006104 grad: 1.23972773070388\n",
      "epoch: 492 loss: 2.302696704864502 grad: 1.2319441764700478\n",
      "epoch: 493 loss: 2.302556037902832 grad: 1.225713112062612\n",
      "epoch: 494 loss: 2.3027594089508057 grad: 1.223294612371348\n",
      "epoch: 495 loss: 2.30279803276062 grad: 1.224820046323455\n",
      "epoch: 496 loss: 2.3030638694763184 grad: 1.2217835770820134\n",
      "epoch: 497 loss: 2.3026678562164307 grad: 1.2275209145524377\n",
      "epoch: 498 loss: 2.3022143840789795 grad: 1.2221332206039703\n",
      "epoch: 499 loss: 2.3024210929870605 grad: 1.2440412578742124\n",
      "2.302459269762039\n",
      "epoch: 0 loss: 2.303253173828125 grad: 1.2331200889644347\n",
      "epoch: 1 loss: 2.303269624710083 grad: 1.2146358810834557\n",
      "epoch: 2 loss: 2.302497148513794 grad: 1.2292333070488115\n",
      "epoch: 3 loss: 2.3031766414642334 grad: 1.2117021726019355\n",
      "epoch: 4 loss: 2.3020825386047363 grad: 1.2292990007526463\n",
      "epoch: 5 loss: 2.302408456802368 grad: 1.2357983127040493\n",
      "epoch: 6 loss: 2.3023898601531982 grad: 1.2423410978120204\n",
      "epoch: 7 loss: 2.30232310295105 grad: 1.22994280880731\n",
      "epoch: 8 loss: 2.3021411895751953 grad: 1.2453173828821273\n",
      "epoch: 9 loss: 2.3026511669158936 grad: 1.2365920107889299\n",
      "epoch: 10 loss: 2.301748037338257 grad: 1.2601905500789778\n",
      "epoch: 11 loss: 2.302082061767578 grad: 1.2553817703248193\n",
      "epoch: 12 loss: 2.3008642196655273 grad: 1.2990707163514186\n",
      "epoch: 13 loss: 2.3024017810821533 grad: 1.285801500671484\n",
      "epoch: 14 loss: 2.301455497741699 grad: 1.299612684136567\n",
      "epoch: 15 loss: 2.301764726638794 grad: 1.3063529828186369\n",
      "epoch: 16 loss: 2.3016014099121094 grad: 1.3295211870286112\n",
      "epoch: 17 loss: 2.301196813583374 grad: 1.3411024733915895\n",
      "epoch: 18 loss: 2.3010637760162354 grad: 1.3775947904861015\n",
      "epoch: 19 loss: 2.300320863723755 grad: 1.3957971677697811\n",
      "epoch: 20 loss: 2.299192190170288 grad: 1.4428172388099252\n",
      "epoch: 21 loss: 2.299114227294922 grad: 1.4985779835362105\n",
      "epoch: 22 loss: 2.2997143268585205 grad: 1.5307454514291345\n",
      "epoch: 23 loss: 2.2981197834014893 grad: 1.645094026781855\n",
      "epoch: 24 loss: 2.2951977252960205 grad: 1.7828916228756988\n",
      "epoch: 25 loss: 2.2940962314605713 grad: 1.881148794649302\n",
      "epoch: 26 loss: 2.2898645401000977 grad: 2.008536500887694\n",
      "epoch: 27 loss: 2.2817797660827637 grad: 2.113064351179341\n",
      "epoch: 28 loss: 2.2746708393096924 grad: 2.1838942451979078\n",
      "epoch: 29 loss: 2.2684247493743896 grad: 2.0984891434772943\n",
      "epoch: 30 loss: 2.2616734504699707 grad: 1.8755416128255928\n",
      "epoch: 31 loss: 2.256944417953491 grad: 1.7810993162538147\n",
      "epoch: 32 loss: 2.2561004161834717 grad: 1.720325720184187\n",
      "epoch: 33 loss: 2.2520663738250732 grad: 1.6189372380373128\n",
      "epoch: 34 loss: 2.2510132789611816 grad: 1.5454914944675116\n",
      "epoch: 35 loss: 2.246274471282959 grad: 1.4377682468436275\n",
      "epoch: 36 loss: 2.2470662593841553 grad: 1.512005116682433\n",
      "epoch: 37 loss: 2.2463600635528564 grad: 1.5280308087877486\n",
      "epoch: 38 loss: 2.245556354522705 grad: 1.4482768244268964\n",
      "epoch: 39 loss: 2.241795539855957 grad: 1.3990861947208435\n",
      "epoch: 40 loss: 2.242222785949707 grad: 1.358624244337931\n",
      "epoch: 41 loss: 2.2411904335021973 grad: 1.3273055851006776\n",
      "epoch: 42 loss: 2.2406301498413086 grad: 1.351053212992921\n",
      "epoch: 43 loss: 2.2400407791137695 grad: 1.3021467403981775\n",
      "epoch: 44 loss: 2.238959550857544 grad: 1.3467874344501143\n",
      "epoch: 45 loss: 2.238649606704712 grad: 1.3049651190337341\n",
      "epoch: 46 loss: 2.2359657287597656 grad: 1.2539271086626242\n",
      "epoch: 47 loss: 2.235490322113037 grad: 1.2915112280447612\n",
      "epoch: 48 loss: 2.2369160652160645 grad: 1.3146018610152947\n",
      "epoch: 49 loss: 2.237521171569824 grad: 1.3358890674112083\n",
      "epoch: 50 loss: 2.2352280616760254 grad: 1.249252888796267\n",
      "epoch: 51 loss: 2.2334933280944824 grad: 1.295682066448203\n",
      "epoch: 52 loss: 2.234630584716797 grad: 1.2716385055922843\n",
      "epoch: 53 loss: 2.2339391708374023 grad: 1.2591683964886229\n",
      "epoch: 54 loss: 2.2341628074645996 grad: 1.3117621078198436\n",
      "epoch: 55 loss: 2.2327051162719727 grad: 1.2264976770827725\n",
      "epoch: 56 loss: 2.2320470809936523 grad: 1.3042525856705782\n",
      "epoch: 57 loss: 2.231860876083374 grad: 1.274544556442249\n",
      "epoch: 58 loss: 2.231691837310791 grad: 1.2793741047591163\n",
      "epoch: 59 loss: 2.2311952114105225 grad: 1.3247658240595936\n",
      "epoch: 60 loss: 2.231985092163086 grad: 1.3350849574882655\n",
      "epoch: 61 loss: 2.229860544204712 grad: 1.1891828105703646\n",
      "epoch: 62 loss: 2.2305667400360107 grad: 1.3237719788846176\n",
      "epoch: 63 loss: 2.2285330295562744 grad: 1.1603340643304696\n",
      "epoch: 64 loss: 2.2276723384857178 grad: 1.2690368510074987\n",
      "epoch: 65 loss: 2.2278177738189697 grad: 1.2836073324867776\n",
      "epoch: 66 loss: 2.228494644165039 grad: 1.3726719706005135\n",
      "epoch: 67 loss: 2.226921796798706 grad: 1.14981160492688\n",
      "epoch: 68 loss: 2.2280471324920654 grad: 1.330807894462764\n",
      "epoch: 69 loss: 2.2266299724578857 grad: 1.3122660204812528\n",
      "epoch: 70 loss: 2.226776123046875 grad: 1.365841572399303\n",
      "epoch: 71 loss: 2.226440906524658 grad: 1.2028005053030535\n",
      "epoch: 72 loss: 2.2263245582580566 grad: 1.3110927006872815\n",
      "epoch: 73 loss: 2.224344253540039 grad: 1.2621009861800954\n",
      "epoch: 74 loss: 2.2254910469055176 grad: 1.2911931538154253\n",
      "epoch: 75 loss: 2.2255003452301025 grad: 1.255303028805573\n",
      "epoch: 76 loss: 2.2245659828186035 grad: 1.2891657542407748\n",
      "epoch: 77 loss: 2.226620674133301 grad: 1.3762276514788114\n",
      "epoch: 78 loss: 2.2244277000427246 grad: 1.229504917217936\n",
      "epoch: 79 loss: 2.224186897277832 grad: 1.243323611639743\n",
      "epoch: 80 loss: 2.2240872383117676 grad: 1.352626344212146\n",
      "epoch: 81 loss: 2.222496271133423 grad: 1.1448145866641657\n",
      "epoch: 82 loss: 2.2247390747070312 grad: 1.2779091394724442\n",
      "epoch: 83 loss: 2.2233076095581055 grad: 1.2472990021323933\n",
      "epoch: 84 loss: 2.2241716384887695 grad: 1.4681192219177897\n",
      "epoch: 85 loss: 2.223201036453247 grad: 1.326284446638994\n",
      "epoch: 86 loss: 2.223102569580078 grad: 1.260929509446705\n",
      "epoch: 87 loss: 2.2214624881744385 grad: 1.2746874252902454\n",
      "epoch: 88 loss: 2.2218096256256104 grad: 1.2311444671201845\n",
      "epoch: 89 loss: 2.223159074783325 grad: 1.3863881845396782\n",
      "epoch: 90 loss: 2.222769260406494 grad: 1.4453542249402889\n",
      "epoch: 91 loss: 2.2220115661621094 grad: 1.3724498514146988\n",
      "epoch: 92 loss: 2.222090721130371 grad: 1.2664545236500941\n",
      "epoch: 93 loss: 2.2213590145111084 grad: 1.4088242256659127\n",
      "epoch: 94 loss: 2.2228288650512695 grad: 1.3310564217030159\n",
      "epoch: 95 loss: 2.220770835876465 grad: 1.2545317474254665\n",
      "epoch: 96 loss: 2.219404458999634 grad: 1.390739539430277\n",
      "epoch: 97 loss: 2.2212893962860107 grad: 1.2829132759537074\n",
      "epoch: 98 loss: 2.2210097312927246 grad: 1.3938372133841133\n",
      "epoch: 99 loss: 2.221425771713257 grad: 1.4252272937687054\n",
      "epoch: 100 loss: 2.218736171722412 grad: 1.2497331936601623\n",
      "epoch: 101 loss: 2.2193124294281006 grad: 1.4241624556293355\n",
      "epoch: 102 loss: 2.2194578647613525 grad: 1.3766968417700218\n",
      "epoch: 103 loss: 2.2189829349517822 grad: 1.4709528937958003\n",
      "epoch: 104 loss: 2.220463752746582 grad: 1.4432646773500546\n",
      "epoch: 105 loss: 2.219456911087036 grad: 1.345273716169195\n",
      "epoch: 106 loss: 2.219862937927246 grad: 1.5301562482334068\n",
      "epoch: 107 loss: 2.218400478363037 grad: 1.3339118772779504\n",
      "epoch: 108 loss: 2.219254732131958 grad: 1.4307053441963424\n",
      "epoch: 109 loss: 2.219332218170166 grad: 1.4134007771083685\n",
      "epoch: 110 loss: 2.2184066772460938 grad: 1.451002979712073\n",
      "epoch: 111 loss: 2.2209272384643555 grad: 1.5866803231368225\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 112 loss: 2.2192752361297607 grad: 1.4514969120981054\n",
      "epoch: 113 loss: 2.219820022583008 grad: 1.3907014149387131\n",
      "epoch: 114 loss: 2.2175981998443604 grad: 1.4123068186879484\n",
      "epoch: 115 loss: 2.21775221824646 grad: 1.3711622279887605\n",
      "epoch: 116 loss: 2.219252824783325 grad: 1.568453960951292\n",
      "epoch: 117 loss: 2.218724012374878 grad: 1.3976765633218862\n",
      "epoch: 118 loss: 2.2180728912353516 grad: 1.4196994207385514\n",
      "epoch: 119 loss: 2.2170143127441406 grad: 1.4761590676720342\n",
      "epoch: 120 loss: 2.217364549636841 grad: 1.596073570202977\n",
      "epoch: 121 loss: 2.2178261280059814 grad: 1.4710875498842344\n",
      "epoch: 122 loss: 2.2173683643341064 grad: 1.5722481636339725\n",
      "epoch: 123 loss: 2.2181103229522705 grad: 1.7532619038071957\n",
      "epoch: 124 loss: 2.217235565185547 grad: 1.5236334548902786\n",
      "epoch: 125 loss: 2.216848611831665 grad: 1.543439208081783\n",
      "epoch: 126 loss: 2.2168147563934326 grad: 1.5472183485509872\n",
      "epoch: 127 loss: 2.215646266937256 grad: 1.5690131438249308\n",
      "epoch: 128 loss: 2.2193305492401123 grad: 1.7419476455487755\n",
      "epoch: 129 loss: 2.217085838317871 grad: 1.5810690189366199\n",
      "epoch: 130 loss: 2.2157552242279053 grad: 1.6411204748520893\n",
      "epoch: 131 loss: 2.214548349380493 grad: 1.6302972177675525\n",
      "epoch: 132 loss: 2.216097116470337 grad: 1.606075117455995\n",
      "epoch: 133 loss: 2.2156684398651123 grad: 1.6195517055891706\n",
      "epoch: 134 loss: 2.2134926319122314 grad: 1.597301477704027\n",
      "epoch: 135 loss: 2.2158303260803223 grad: 1.8505602485540928\n",
      "epoch: 136 loss: 2.2140254974365234 grad: 1.7361195993689185\n",
      "epoch: 137 loss: 2.213057279586792 grad: 1.7516862960183062\n",
      "epoch: 138 loss: 2.2133355140686035 grad: 1.8063414006638119\n",
      "epoch: 139 loss: 2.213179349899292 grad: 1.875397457336519\n",
      "epoch: 140 loss: 2.213967800140381 grad: 1.9382892318757339\n",
      "epoch: 141 loss: 2.2129478454589844 grad: 2.0129401796600885\n",
      "epoch: 142 loss: 2.2130062580108643 grad: 2.011834719992568\n",
      "epoch: 143 loss: 2.212653160095215 grad: 1.8439332691588557\n",
      "epoch: 144 loss: 2.2130491733551025 grad: 2.134951326983153\n",
      "epoch: 145 loss: 2.214970111846924 grad: 2.137141564858168\n",
      "epoch: 146 loss: 2.2107186317443848 grad: 2.0040039883146714\n",
      "epoch: 147 loss: 2.210819959640503 grad: 2.1110030086286042\n",
      "epoch: 148 loss: 2.2095799446105957 grad: 2.1179231229018316\n",
      "epoch: 149 loss: 2.2113754749298096 grad: 2.315380947156218\n",
      "epoch: 150 loss: 2.2079362869262695 grad: 1.9696957238881465\n",
      "epoch: 151 loss: 2.2105627059936523 grad: 2.1940722141474014\n",
      "epoch: 152 loss: 2.209383964538574 grad: 2.1727244135792487\n",
      "epoch: 153 loss: 2.205918788909912 grad: 2.176231129423878\n",
      "epoch: 154 loss: 2.2088568210601807 grad: 2.168572219566346\n",
      "epoch: 155 loss: 2.2047832012176514 grad: 2.2258519761131277\n",
      "epoch: 156 loss: 2.2046751976013184 grad: 2.339220329581405\n",
      "epoch: 157 loss: 2.2055139541625977 grad: 2.2781570074277826\n",
      "epoch: 158 loss: 2.2065250873565674 grad: 2.323534898186428\n",
      "epoch: 159 loss: 2.207284927368164 grad: 2.4102921942045676\n",
      "epoch: 160 loss: 2.202878475189209 grad: 2.3995630211937833\n",
      "epoch: 161 loss: 2.206719160079956 grad: 2.469184984794877\n",
      "epoch: 162 loss: 2.202916383743286 grad: 2.5698014629380186\n",
      "epoch: 163 loss: 2.200437068939209 grad: 2.3485502289249633\n",
      "epoch: 164 loss: 2.2034826278686523 grad: 2.3964925568184947\n",
      "epoch: 165 loss: 2.1995112895965576 grad: 2.403480611724912\n",
      "epoch: 166 loss: 2.1987359523773193 grad: 2.365890298496991\n",
      "epoch: 167 loss: 2.1954257488250732 grad: 2.5334748068162876\n",
      "epoch: 168 loss: 2.195291757583618 grad: 2.467633464589848\n",
      "epoch: 169 loss: 2.1990067958831787 grad: 2.572320896642475\n",
      "epoch: 170 loss: 2.1985068321228027 grad: 2.6953199094324005\n",
      "epoch: 171 loss: 2.197493314743042 grad: 2.5892408196315437\n",
      "epoch: 172 loss: 2.194258451461792 grad: 2.5470556060447254\n",
      "epoch: 173 loss: 2.193571090698242 grad: 2.6683312188242634\n",
      "epoch: 174 loss: 2.196763038635254 grad: 2.7522384922633627\n",
      "epoch: 175 loss: 2.1946280002593994 grad: 2.5601984045896975\n",
      "epoch: 176 loss: 2.1953508853912354 grad: 2.814924436259187\n",
      "epoch: 177 loss: 2.193002462387085 grad: 2.7842990407879125\n",
      "epoch: 178 loss: 2.1916332244873047 grad: 2.7606585317915897\n",
      "epoch: 179 loss: 2.1949105262756348 grad: 2.601661150360347\n",
      "epoch: 180 loss: 2.191206693649292 grad: 2.6530056625903984\n",
      "epoch: 181 loss: 2.1906139850616455 grad: 2.7792952851048627\n",
      "epoch: 182 loss: 2.1918864250183105 grad: 2.78467287760531\n",
      "epoch: 183 loss: 2.188185453414917 grad: 2.629744516663431\n",
      "epoch: 184 loss: 2.184988498687744 grad: 2.835493233527929\n",
      "epoch: 185 loss: 2.1906847953796387 grad: 2.7185499494015755\n",
      "epoch: 186 loss: 2.1906332969665527 grad: 2.930208815553684\n",
      "epoch: 187 loss: 2.1865198612213135 grad: 2.987303764607373\n",
      "epoch: 188 loss: 2.1857481002807617 grad: 2.871140744596247\n",
      "epoch: 189 loss: 2.1868820190429688 grad: 2.8606312062521098\n",
      "epoch: 190 loss: 2.182166337966919 grad: 2.870595811914268\n",
      "epoch: 191 loss: 2.1821041107177734 grad: 2.7835568200837497\n",
      "epoch: 192 loss: 2.1818623542785645 grad: 2.8639443599570926\n",
      "epoch: 193 loss: 2.1802189350128174 grad: 2.7848097457604055\n",
      "epoch: 194 loss: 2.179901361465454 grad: 2.9762797250046527\n",
      "epoch: 195 loss: 2.1820273399353027 grad: 2.9278471898527756\n",
      "epoch: 196 loss: 2.1805198192596436 grad: 3.1059881929023607\n",
      "epoch: 197 loss: 2.179913282394409 grad: 2.7271693032124036\n",
      "epoch: 198 loss: 2.1785669326782227 grad: 3.037728634640752\n",
      "epoch: 199 loss: 2.181342840194702 grad: 2.8986099874138804\n",
      "epoch: 200 loss: 2.180070638656616 grad: 2.9356766443252416\n",
      "epoch: 201 loss: 2.177638292312622 grad: 2.929836685421862\n",
      "epoch: 202 loss: 2.1786770820617676 grad: 3.0077676134967497\n",
      "epoch: 203 loss: 2.177521228790283 grad: 3.1396080378649964\n",
      "epoch: 204 loss: 2.177460193634033 grad: 2.8789146107580836\n",
      "epoch: 205 loss: 2.176609516143799 grad: 3.024222414547001\n",
      "epoch: 206 loss: 2.1734771728515625 grad: 2.924713904743955\n",
      "epoch: 207 loss: 2.1755008697509766 grad: 3.089981318262982\n",
      "epoch: 208 loss: 2.171788215637207 grad: 2.816511964503055\n",
      "epoch: 209 loss: 2.172989845275879 grad: 2.775173997916725\n",
      "epoch: 210 loss: 2.175238609313965 grad: 2.9241117629895195\n",
      "epoch: 211 loss: 2.1749844551086426 grad: 2.785896133012434\n",
      "epoch: 212 loss: 2.17557954788208 grad: 2.957574695114061\n",
      "epoch: 213 loss: 2.170532464981079 grad: 3.254417565797219\n",
      "epoch: 214 loss: 2.1686556339263916 grad: 2.9309497013085686\n",
      "epoch: 215 loss: 2.1710622310638428 grad: 3.0286239572811784\n",
      "epoch: 216 loss: 2.1716971397399902 grad: 2.9907788873857095\n",
      "epoch: 217 loss: 2.1735055446624756 grad: 3.1044559747568288\n",
      "epoch: 218 loss: 2.1711807250976562 grad: 2.935398931263961\n",
      "epoch: 219 loss: 2.170020818710327 grad: 2.8060700126650135\n",
      "epoch: 220 loss: 2.1673812866210938 grad: 2.9755150502943066\n",
      "epoch: 221 loss: 2.1699745655059814 grad: 2.979905649088323\n",
      "epoch: 222 loss: 2.1671218872070312 grad: 2.900067999439743\n",
      "epoch: 223 loss: 2.1676974296569824 grad: 3.0756855736327697\n",
      "epoch: 224 loss: 2.169860363006592 grad: 3.0208395405798147\n",
      "epoch: 225 loss: 2.1704657077789307 grad: 2.7903455652625464\n",
      "epoch: 226 loss: 2.1641604900360107 grad: 2.976448057247104\n",
      "epoch: 227 loss: 2.1666622161865234 grad: 3.1736549624807333\n",
      "epoch: 228 loss: 2.1673338413238525 grad: 2.6081793624759904\n",
      "epoch: 229 loss: 2.1677520275115967 grad: 2.76206200665033\n",
      "epoch: 230 loss: 2.167222023010254 grad: 2.849200672013611\n",
      "epoch: 231 loss: 2.1628713607788086 grad: 2.8900880008836145\n",
      "epoch: 232 loss: 2.1636433601379395 grad: 2.7097291242209307\n",
      "epoch: 233 loss: 2.16519832611084 grad: 3.289065731630202\n",
      "epoch: 234 loss: 2.1648459434509277 grad: 3.0495704478761625\n",
      "epoch: 235 loss: 2.163112163543701 grad: 3.2284510308000747\n",
      "epoch: 236 loss: 2.1641170978546143 grad: 3.103550516196438\n",
      "epoch: 237 loss: 2.1613993644714355 grad: 3.2568951813810845\n",
      "epoch: 238 loss: 2.1669058799743652 grad: 3.2152920492817576\n",
      "epoch: 239 loss: 2.16447377204895 grad: 3.190998400445096\n",
      "epoch: 240 loss: 2.1597323417663574 grad: 2.793406413236101\n",
      "epoch: 241 loss: 2.1627557277679443 grad: 3.0338154546399085\n",
      "epoch: 242 loss: 2.161557674407959 grad: 3.2193854509276294\n",
      "epoch: 243 loss: 2.160526752471924 grad: 2.9067125663545634\n",
      "epoch: 244 loss: 2.158018112182617 grad: 2.9631417767469963\n",
      "epoch: 245 loss: 2.1587843894958496 grad: 3.2642074839511355\n",
      "epoch: 246 loss: 2.161635398864746 grad: 3.0062987467011673\n",
      "epoch: 247 loss: 2.1567420959472656 grad: 2.996217706153864\n",
      "epoch: 248 loss: 2.161051034927368 grad: 3.1333092387067154\n",
      "epoch: 249 loss: 2.157562255859375 grad: 2.8872887919923023\n",
      "epoch: 250 loss: 2.1616039276123047 grad: 3.025947978060382\n",
      "epoch: 251 loss: 2.1582653522491455 grad: 3.153077104226834\n",
      "epoch: 252 loss: 2.1583025455474854 grad: 3.2682512299922695\n",
      "epoch: 253 loss: 2.1581976413726807 grad: 2.917493768417025\n",
      "epoch: 254 loss: 2.1574389934539795 grad: 2.7413226191198365\n",
      "epoch: 255 loss: 2.154639482498169 grad: 3.113869719713601\n",
      "epoch: 256 loss: 2.1558351516723633 grad: 3.210488329039118\n",
      "epoch: 257 loss: 2.1560702323913574 grad: 3.2523794814460127\n",
      "epoch: 258 loss: 2.158402442932129 grad: 3.2978628690609533\n",
      "epoch: 259 loss: 2.1582140922546387 grad: 2.9982373656571975\n",
      "epoch: 260 loss: 2.157832622528076 grad: 3.121675987007274\n",
      "epoch: 261 loss: 2.155961513519287 grad: 3.2346943518690146\n",
      "epoch: 262 loss: 2.1578195095062256 grad: 3.082392510632792\n",
      "epoch: 263 loss: 2.154761791229248 grad: 2.878988454358593\n",
      "epoch: 264 loss: 2.157484531402588 grad: 3.0318694656977194\n",
      "epoch: 265 loss: 2.1554102897644043 grad: 2.9121686809600167\n",
      "epoch: 266 loss: 2.1550660133361816 grad: 3.0983855653894206\n",
      "epoch: 267 loss: 2.1499781608581543 grad: 2.945630404819173\n",
      "epoch: 268 loss: 2.15523624420166 grad: 2.944204566566022\n",
      "epoch: 269 loss: 2.1557486057281494 grad: 3.223558232306488\n",
      "epoch: 270 loss: 2.1551175117492676 grad: 3.011621983644242\n",
      "epoch: 271 loss: 2.152233839035034 grad: 2.8579531855629905\n",
      "epoch: 272 loss: 2.1524057388305664 grad: 2.9755135169917986\n",
      "epoch: 273 loss: 2.1532626152038574 grad: 2.833078353556745\n",
      "epoch: 274 loss: 2.1532135009765625 grad: 2.9859146823873743\n",
      "epoch: 275 loss: 2.154857635498047 grad: 3.1708215798014803\n",
      "epoch: 276 loss: 2.154402256011963 grad: 3.081251442680017\n",
      "epoch: 277 loss: 2.151200294494629 grad: 3.2849844263345447\n",
      "epoch: 278 loss: 2.1543161869049072 grad: 3.2368480473431567\n",
      "epoch: 279 loss: 2.1550848484039307 grad: 2.7831067191104273\n",
      "epoch: 280 loss: 2.1554043292999268 grad: 3.011219812161659\n",
      "epoch: 281 loss: 2.1502420902252197 grad: 2.7750856491020097\n",
      "epoch: 282 loss: 2.1509850025177 grad: 2.8715626621186465\n",
      "epoch: 283 loss: 2.151893377304077 grad: 3.0920598755280175\n",
      "epoch: 284 loss: 2.1499054431915283 grad: 2.8792062323976544\n",
      "epoch: 285 loss: 2.149989128112793 grad: 3.0709437264410395\n",
      "epoch: 286 loss: 2.149563789367676 grad: 2.960153143426093\n",
      "epoch: 287 loss: 2.1510417461395264 grad: 3.193860653682523\n",
      "epoch: 288 loss: 2.150736093521118 grad: 2.981952717893624\n",
      "epoch: 289 loss: 2.1528737545013428 grad: 3.0086639665717643\n",
      "epoch: 290 loss: 2.1510262489318848 grad: 3.1046718481285054\n",
      "epoch: 291 loss: 2.150110960006714 grad: 2.962176000902666\n",
      "epoch: 292 loss: 2.1507503986358643 grad: 3.0684726746634596\n",
      "epoch: 293 loss: 2.1500954627990723 grad: 3.0401493907436756\n",
      "epoch: 294 loss: 2.1481223106384277 grad: 3.1221211773531867\n",
      "epoch: 295 loss: 2.151425361633301 grad: 3.149219716418653\n",
      "epoch: 296 loss: 2.1506638526916504 grad: 3.4677661024921\n",
      "epoch: 297 loss: 2.1466617584228516 grad: 2.996673690439719\n",
      "epoch: 298 loss: 2.148858070373535 grad: 3.023958765472921\n",
      "epoch: 299 loss: 2.147261142730713 grad: 3.1703409615364517\n",
      "epoch: 300 loss: 2.15051007270813 grad: 3.247423165599771\n",
      "epoch: 301 loss: 2.1508560180664062 grad: 3.189931746631388\n",
      "epoch: 302 loss: 2.1499698162078857 grad: 3.1184782379025977\n",
      "epoch: 303 loss: 2.148012399673462 grad: 3.0090638652262793\n",
      "epoch: 304 loss: 2.1488499641418457 grad: 3.1816554310036795\n",
      "epoch: 305 loss: 2.1502068042755127 grad: 3.049138055323431\n",
      "epoch: 306 loss: 2.145677089691162 grad: 3.078162592438434\n",
      "epoch: 307 loss: 2.1489338874816895 grad: 3.021610395010886\n",
      "epoch: 308 loss: 2.147949457168579 grad: 3.115078319359334\n",
      "epoch: 309 loss: 2.150421380996704 grad: 3.4555627556096407\n",
      "epoch: 310 loss: 2.147142171859741 grad: 2.87569658701042\n",
      "epoch: 311 loss: 2.1458323001861572 grad: 3.0245017605290436\n",
      "epoch: 312 loss: 2.1510393619537354 grad: 3.2558258220494265\n",
      "epoch: 313 loss: 2.1473710536956787 grad: 3.298666806030457\n",
      "epoch: 314 loss: 2.145237445831299 grad: 3.0516077039600717\n",
      "epoch: 315 loss: 2.145782947540283 grad: 2.9811883756136965\n",
      "epoch: 316 loss: 2.1459851264953613 grad: 2.9137211911905085\n",
      "epoch: 317 loss: 2.1457715034484863 grad: 3.1047543123981636\n",
      "epoch: 318 loss: 2.1481449604034424 grad: 3.026084838257659\n",
      "epoch: 319 loss: 2.1461703777313232 grad: 2.963288432717072\n",
      "epoch: 320 loss: 2.1442458629608154 grad: 2.955637905920397\n",
      "epoch: 321 loss: 2.147128105163574 grad: 3.193666160372751\n",
      "epoch: 322 loss: 2.14400577545166 grad: 3.083179547070777\n",
      "epoch: 323 loss: 2.144993782043457 grad: 3.0939737756973105\n",
      "epoch: 324 loss: 2.146547555923462 grad: 3.22147770579313\n",
      "epoch: 325 loss: 2.1467013359069824 grad: 3.0740008432203756\n",
      "epoch: 326 loss: 2.148637533187866 grad: 3.4834687868539715\n",
      "epoch: 327 loss: 2.1461668014526367 grad: 2.9656951523548556\n",
      "epoch: 328 loss: 2.1417884826660156 grad: 2.8366507073819993\n",
      "epoch: 329 loss: 2.1436941623687744 grad: 3.109353172518904\n",
      "epoch: 330 loss: 2.148212432861328 grad: 3.121805384424367\n",
      "epoch: 331 loss: 2.144240617752075 grad: 2.9301329191131074\n",
      "epoch: 332 loss: 2.1426453590393066 grad: 3.329375081747356\n",
      "epoch: 333 loss: 2.1422181129455566 grad: 2.9345653956748605\n",
      "epoch: 334 loss: 2.147000789642334 grad: 3.329108996592122\n",
      "epoch: 335 loss: 2.1427719593048096 grad: 3.2100518624970897\n",
      "epoch: 336 loss: 2.143078327178955 grad: 3.161572386019139\n",
      "epoch: 337 loss: 2.1456186771392822 grad: 3.2259686407670083\n",
      "epoch: 338 loss: 2.147639274597168 grad: 3.221808123827306\n",
      "epoch: 339 loss: 2.144991159439087 grad: 3.414486561613601\n",
      "epoch: 340 loss: 2.1381354331970215 grad: 3.1458055249337726\n",
      "epoch: 341 loss: 2.1407601833343506 grad: 3.2500158072475136\n",
      "epoch: 342 loss: 2.145827054977417 grad: 3.1481818226221505\n",
      "epoch: 343 loss: 2.1446099281311035 grad: 3.1574886791215886\n",
      "epoch: 344 loss: 2.1443440914154053 grad: 3.3894219960987804\n",
      "epoch: 345 loss: 2.1421210765838623 grad: 3.0135850787480614\n",
      "epoch: 346 loss: 2.144207715988159 grad: 3.1337572005983914\n",
      "epoch: 347 loss: 2.141547918319702 grad: 3.234319808957581\n",
      "epoch: 348 loss: 2.1429948806762695 grad: 3.262939725056409\n",
      "epoch: 349 loss: 2.13925838470459 grad: 3.1975967033640553\n",
      "epoch: 350 loss: 2.1405301094055176 grad: 3.151231045404168\n",
      "epoch: 351 loss: 2.145212411880493 grad: 3.322078665973441\n",
      "epoch: 352 loss: 2.142467737197876 grad: 3.3862808052845863\n",
      "epoch: 353 loss: 2.1407666206359863 grad: 3.437470219705978\n",
      "epoch: 354 loss: 2.139983654022217 grad: 3.1859762347395724\n",
      "epoch: 355 loss: 2.1426804065704346 grad: 3.3257168175963066\n",
      "epoch: 356 loss: 2.1425187587738037 grad: 3.1783095210058883\n",
      "epoch: 357 loss: 2.1384758949279785 grad: 3.4180178732855158\n",
      "epoch: 358 loss: 2.1386468410491943 grad: 3.4911860224110858\n",
      "epoch: 359 loss: 2.1389966011047363 grad: 3.368329037132392\n",
      "epoch: 360 loss: 2.141977310180664 grad: 3.5072552485036708\n",
      "epoch: 361 loss: 2.1411423683166504 grad: 3.444784220215672\n",
      "epoch: 362 loss: 2.140808582305908 grad: 3.344667992015029\n",
      "epoch: 363 loss: 2.1393706798553467 grad: 3.54347962396042\n",
      "epoch: 364 loss: 2.1383860111236572 grad: 3.431553339515443\n",
      "epoch: 365 loss: 2.1395912170410156 grad: 3.492012737034303\n",
      "epoch: 366 loss: 2.135007381439209 grad: 3.541793062055986\n",
      "epoch: 367 loss: 2.1407549381256104 grad: 3.342833873605178\n",
      "epoch: 368 loss: 2.136848211288452 grad: 3.4348560179369376\n",
      "epoch: 369 loss: 2.1381497383117676 grad: 3.3281948736698794\n",
      "epoch: 370 loss: 2.140341281890869 grad: 3.547746763756824\n",
      "epoch: 371 loss: 2.1393158435821533 grad: 3.7238973013443193\n",
      "epoch: 372 loss: 2.1382994651794434 grad: 3.679067927301817\n",
      "epoch: 373 loss: 2.13991117477417 grad: 3.9354634414508287\n",
      "epoch: 374 loss: 2.1391665935516357 grad: 3.840686290214459\n",
      "epoch: 375 loss: 2.138418197631836 grad: 3.7202840590154724\n",
      "epoch: 376 loss: 2.1405911445617676 grad: 3.6803548051495225\n",
      "epoch: 377 loss: 2.1365959644317627 grad: 3.7192176818433733\n",
      "epoch: 378 loss: 2.137831926345825 grad: 4.124589676920709\n",
      "epoch: 379 loss: 2.138011932373047 grad: 3.7661750607436435\n",
      "epoch: 380 loss: 2.138436794281006 grad: 3.774638789347447\n",
      "epoch: 381 loss: 2.1387083530426025 grad: 3.792708438902443\n",
      "epoch: 382 loss: 2.137871742248535 grad: 3.6819499279113694\n",
      "epoch: 383 loss: 2.136472463607788 grad: 3.7066072246562394\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 384 loss: 2.1347296237945557 grad: 3.6541261289985703\n",
      "epoch: 385 loss: 2.1395208835601807 grad: 4.004581608354957\n",
      "epoch: 386 loss: 2.1431515216827393 grad: 4.034772587943793\n",
      "epoch: 387 loss: 2.132533311843872 grad: 3.853385194374751\n",
      "epoch: 388 loss: 2.137939929962158 grad: 3.808056970259973\n",
      "epoch: 389 loss: 2.136888027191162 grad: 3.7801193171993845\n",
      "epoch: 390 loss: 2.133356809616089 grad: 3.819880146773473\n",
      "epoch: 391 loss: 2.1341896057128906 grad: 4.042675975270362\n",
      "epoch: 392 loss: 2.131253242492676 grad: 4.00358084902086\n",
      "epoch: 393 loss: 2.134671688079834 grad: 4.22076379629739\n",
      "epoch: 394 loss: 2.133162498474121 grad: 3.744180041587069\n",
      "epoch: 395 loss: 2.1326048374176025 grad: 4.000321677616162\n",
      "epoch: 396 loss: 2.1385416984558105 grad: 3.8721707438503112\n",
      "epoch: 397 loss: 2.1338133811950684 grad: 4.198923709070576\n",
      "epoch: 398 loss: 2.1337802410125732 grad: 4.151540558253016\n",
      "epoch: 399 loss: 2.1255664825439453 grad: 4.052647947012225\n",
      "epoch: 400 loss: 2.131910562515259 grad: 4.117468209626774\n",
      "epoch: 401 loss: 2.1335692405700684 grad: 4.204934394279022\n",
      "epoch: 402 loss: 2.1318411827087402 grad: 4.072390369413095\n",
      "epoch: 403 loss: 2.134145736694336 grad: 4.100298696012783\n",
      "epoch: 404 loss: 2.13138747215271 grad: 4.153228235127966\n",
      "epoch: 405 loss: 2.1342380046844482 grad: 4.118133011876443\n",
      "epoch: 406 loss: 2.1327404975891113 grad: 4.022022391710105\n",
      "epoch: 407 loss: 2.1283345222473145 grad: 3.961341742599856\n",
      "epoch: 408 loss: 2.1328446865081787 grad: 4.212869702162044\n",
      "epoch: 409 loss: 2.1348986625671387 grad: 4.117880289391097\n",
      "epoch: 410 loss: 2.127445697784424 grad: 3.935844898138875\n",
      "epoch: 411 loss: 2.128833055496216 grad: 4.571226176000127\n",
      "epoch: 412 loss: 2.1286838054656982 grad: 4.152527359317959\n",
      "epoch: 413 loss: 2.132936716079712 grad: 4.4828157994844435\n",
      "epoch: 414 loss: 2.1301302909851074 grad: 4.2463893830066635\n",
      "epoch: 415 loss: 2.1288418769836426 grad: 4.214183419987204\n",
      "epoch: 416 loss: 2.1298329830169678 grad: 4.222023959726184\n",
      "epoch: 417 loss: 2.126878499984741 grad: 4.189746486370466\n",
      "epoch: 418 loss: 2.124413251876831 grad: 4.108842627282092\n",
      "epoch: 419 loss: 2.124048948287964 grad: 4.3942249767105315\n",
      "epoch: 420 loss: 2.1261003017425537 grad: 3.9729857429352013\n",
      "epoch: 421 loss: 2.1280694007873535 grad: 4.516989550741744\n",
      "epoch: 422 loss: 2.1286351680755615 grad: 4.405781228413125\n",
      "epoch: 423 loss: 2.127861738204956 grad: 4.252467950868849\n",
      "epoch: 424 loss: 2.129478931427002 grad: 4.177220970499403\n",
      "epoch: 425 loss: 2.12787127494812 grad: 4.271819471850962\n",
      "epoch: 426 loss: 2.121591091156006 grad: 4.060480205157387\n",
      "epoch: 427 loss: 2.1268327236175537 grad: 4.451829183994541\n",
      "epoch: 428 loss: 2.126561164855957 grad: 4.548175733381261\n",
      "epoch: 429 loss: 2.1246819496154785 grad: 4.201821505136433\n",
      "epoch: 430 loss: 2.127739429473877 grad: 4.442831360346948\n",
      "epoch: 431 loss: 2.128787040710449 grad: 4.522533519101137\n",
      "epoch: 432 loss: 2.125181198120117 grad: 4.402345256613834\n",
      "epoch: 433 loss: 2.1229281425476074 grad: 4.411694639706097\n",
      "epoch: 434 loss: 2.123701333999634 grad: 4.336939778685244\n",
      "epoch: 435 loss: 2.1249783039093018 grad: 4.345729302906889\n",
      "epoch: 436 loss: 2.1283364295959473 grad: 4.639541621937136\n",
      "epoch: 437 loss: 2.1255674362182617 grad: 4.447561316229107\n",
      "epoch: 438 loss: 2.1180007457733154 grad: 4.550631175900529\n",
      "epoch: 439 loss: 2.1247477531433105 grad: 4.482158321070499\n",
      "epoch: 440 loss: 2.120645523071289 grad: 4.4037850913813426\n",
      "epoch: 441 loss: 2.1215734481811523 grad: 4.475617323684255\n",
      "epoch: 442 loss: 2.125114679336548 grad: 4.628841744946493\n",
      "epoch: 443 loss: 2.1242687702178955 grad: 4.464226231041793\n",
      "epoch: 444 loss: 2.1183021068573 grad: 4.221318775651207\n",
      "epoch: 445 loss: 2.117189884185791 grad: 4.5253418516737245\n",
      "epoch: 446 loss: 2.1193578243255615 grad: 4.160943399057797\n",
      "epoch: 447 loss: 2.1223840713500977 grad: 4.578383717538109\n",
      "epoch: 448 loss: 2.1214988231658936 grad: 4.617998331160624\n",
      "epoch: 449 loss: 2.1191229820251465 grad: 4.775733269983903\n",
      "epoch: 450 loss: 2.120178461074829 grad: 4.613941879063431\n",
      "epoch: 451 loss: 2.119844436645508 grad: 4.337739103270458\n",
      "epoch: 452 loss: 2.1220767498016357 grad: 4.826542046937411\n",
      "epoch: 453 loss: 2.124295473098755 grad: 4.558328976529459\n",
      "epoch: 454 loss: 2.1236369609832764 grad: 4.6113940355116645\n",
      "epoch: 455 loss: 2.1220321655273438 grad: 4.554481323080374\n",
      "epoch: 456 loss: 2.121976137161255 grad: 4.846339457088136\n",
      "epoch: 457 loss: 2.1181118488311768 grad: 4.444933632004355\n",
      "epoch: 458 loss: 2.117565870285034 grad: 4.5094563194129265\n",
      "epoch: 459 loss: 2.1127824783325195 grad: 4.381451805554597\n",
      "epoch: 460 loss: 2.119361639022827 grad: 4.534649707846314\n",
      "epoch: 461 loss: 2.1244919300079346 grad: 4.64363983239136\n",
      "epoch: 462 loss: 2.1157662868499756 grad: 4.401983322438946\n",
      "epoch: 463 loss: 2.1182703971862793 grad: 4.532535117625865\n",
      "epoch: 464 loss: 2.1138248443603516 grad: 4.339989248770363\n",
      "epoch: 465 loss: 2.119617462158203 grad: 4.632658903342893\n",
      "epoch: 466 loss: 2.115922212600708 grad: 4.636938632772644\n",
      "epoch: 467 loss: 2.1155643463134766 grad: 4.551321747620398\n",
      "epoch: 468 loss: 2.1155996322631836 grad: 4.415562272984682\n",
      "epoch: 469 loss: 2.1160006523132324 grad: 4.72022914508402\n",
      "epoch: 470 loss: 2.1144824028015137 grad: 4.710511301167398\n",
      "epoch: 471 loss: 2.1170523166656494 grad: 4.790978794333539\n",
      "epoch: 472 loss: 2.1154873371124268 grad: 4.798718299738885\n",
      "epoch: 473 loss: 2.114236831665039 grad: 4.818837023373427\n",
      "epoch: 474 loss: 2.113455057144165 grad: 4.4694503186462775\n",
      "epoch: 475 loss: 2.1152420043945312 grad: 4.52335085754194\n",
      "epoch: 476 loss: 2.1153900623321533 grad: 4.622402370467575\n",
      "epoch: 477 loss: 2.118178129196167 grad: 4.4885491686134\n",
      "epoch: 478 loss: 2.112804651260376 grad: 4.40406835922927\n",
      "epoch: 479 loss: 2.112626314163208 grad: 4.560937808841349\n",
      "epoch: 480 loss: 2.117269515991211 grad: 4.528733001449072\n",
      "epoch: 481 loss: 2.1148183345794678 grad: 4.716438694483792\n",
      "epoch: 482 loss: 2.1133456230163574 grad: 4.6990957050732085\n",
      "epoch: 483 loss: 2.1073644161224365 grad: 4.619484431335762\n",
      "epoch: 484 loss: 2.117779493331909 grad: 4.482441396090305\n",
      "epoch: 485 loss: 2.109550952911377 grad: 4.687173675124844\n",
      "epoch: 486 loss: 2.1165926456451416 grad: 4.6902230761627415\n",
      "epoch: 487 loss: 2.1171023845672607 grad: 4.7683113621037805\n",
      "epoch: 488 loss: 2.1111865043640137 grad: 4.876063136930858\n",
      "epoch: 489 loss: 2.1160848140716553 grad: 4.65474361228934\n",
      "epoch: 490 loss: 2.117936134338379 grad: 4.5939910394353936\n",
      "epoch: 491 loss: 2.1132824420928955 grad: 4.4833165065880625\n",
      "epoch: 492 loss: 2.1074798107147217 grad: 4.82854468123396\n",
      "epoch: 493 loss: 2.113675117492676 grad: 4.795948986980384\n",
      "epoch: 494 loss: 2.107390880584717 grad: 4.901997292776489\n",
      "epoch: 495 loss: 2.1092567443847656 grad: 4.698308433616711\n",
      "epoch: 496 loss: 2.113537073135376 grad: 4.938568107473354\n",
      "epoch: 497 loss: 2.1135385036468506 grad: 4.694474358994898\n",
      "epoch: 498 loss: 2.1119916439056396 grad: 4.839958802397762\n",
      "epoch: 499 loss: 2.110513925552368 grad: 4.629559347387551\n",
      "2.192306727170944\n",
      "epoch: 0 loss: 2.30409574508667 grad: 1.032963453652522\n",
      "epoch: 1 loss: 2.3003876209259033 grad: 0.9494436210481494\n",
      "epoch: 2 loss: 2.2741472721099854 grad: 1.2911088662083439\n",
      "epoch: 3 loss: 2.228411912918091 grad: 0.9615175975779985\n",
      "epoch: 4 loss: 2.22218918800354 grad: 0.9728999837465208\n",
      "epoch: 5 loss: 2.217770576477051 grad: 0.9615086733614416\n",
      "epoch: 6 loss: 2.2150070667266846 grad: 1.0976540219892899\n",
      "epoch: 7 loss: 2.213987350463867 grad: 1.5928861397847032\n",
      "epoch: 8 loss: 2.208472967147827 grad: 1.5445853867517259\n",
      "epoch: 9 loss: 2.1966357231140137 grad: 1.777200935275427\n",
      "epoch: 10 loss: 2.192128896713257 grad: 1.902712046350066\n",
      "epoch: 11 loss: 2.179384708404541 grad: 2.012432654356142\n",
      "epoch: 12 loss: 2.168137550354004 grad: 2.088062546531012\n",
      "epoch: 13 loss: 2.160607099533081 grad: 2.782174805813055\n",
      "epoch: 14 loss: 2.161881685256958 grad: 2.7826238798032077\n",
      "epoch: 15 loss: 2.1365015506744385 grad: 3.5446510825145414\n",
      "epoch: 16 loss: 2.109306812286377 grad: 3.8797396374385924\n",
      "epoch: 17 loss: 2.096583366394043 grad: 3.833565511313426\n",
      "epoch: 18 loss: 2.085758686065674 grad: 4.258383808147979\n",
      "epoch: 19 loss: 2.0767438411712646 grad: 3.6616471444181764\n",
      "epoch: 20 loss: 2.0504109859466553 grad: 4.063666442147685\n",
      "epoch: 21 loss: 2.0521492958068848 grad: 4.395459264600446\n",
      "epoch: 22 loss: 2.0374372005462646 grad: 4.531746112032413\n",
      "epoch: 23 loss: 2.036172866821289 grad: 4.250696711537395\n",
      "epoch: 24 loss: 2.032327175140381 grad: 4.626000605213146\n",
      "epoch: 25 loss: 2.0350844860076904 grad: 4.920298912462646\n",
      "epoch: 26 loss: 2.0298516750335693 grad: 4.5623601168982635\n",
      "epoch: 27 loss: 2.003859043121338 grad: 4.650422827788307\n",
      "epoch: 28 loss: 1.99441397190094 grad: 4.53864324651289\n",
      "epoch: 29 loss: 2.0053977966308594 grad: 4.8965058387502\n",
      "epoch: 30 loss: 1.9947298765182495 grad: 4.634275249904945\n",
      "epoch: 31 loss: 1.9876315593719482 grad: 4.8051354714141725\n",
      "epoch: 32 loss: 1.97831130027771 grad: 4.424344220018524\n",
      "epoch: 33 loss: 1.9808616638183594 grad: 4.564729602318645\n",
      "epoch: 34 loss: 1.9845260381698608 grad: 4.623868317225494\n",
      "epoch: 35 loss: 1.9774045944213867 grad: 4.514045904331844\n",
      "epoch: 36 loss: 1.965017557144165 grad: 4.902822435751746\n",
      "epoch: 37 loss: 1.9830502271652222 grad: 4.827053123508073\n",
      "epoch: 38 loss: 1.9619840383529663 grad: 4.809020772352741\n",
      "epoch: 39 loss: 1.9636319875717163 grad: 4.904615625962227\n",
      "epoch: 40 loss: 1.9750226736068726 grad: 4.96115099141025\n",
      "epoch: 41 loss: 1.9661455154418945 grad: 4.945751427920417\n",
      "epoch: 42 loss: 1.958970308303833 grad: 4.921026393604402\n",
      "epoch: 43 loss: 1.9593455791473389 grad: 5.430145468681105\n",
      "epoch: 44 loss: 1.9428504705429077 grad: 5.051436218227045\n",
      "epoch: 45 loss: 1.9423255920410156 grad: 4.97081346263763\n",
      "epoch: 46 loss: 1.9593008756637573 grad: 4.936504886973934\n",
      "epoch: 47 loss: 1.9470094442367554 grad: 5.225221435100557\n",
      "epoch: 48 loss: 1.9538145065307617 grad: 5.402095411208898\n",
      "epoch: 49 loss: 1.9203014373779297 grad: 5.446020395073223\n",
      "epoch: 50 loss: 1.940382480621338 grad: 4.975850820535838\n",
      "epoch: 51 loss: 1.9448527097702026 grad: 5.1041581061833154\n",
      "epoch: 52 loss: 1.9203163385391235 grad: 5.379688884897087\n",
      "epoch: 53 loss: 1.905883550643921 grad: 5.52693353055021\n",
      "epoch: 54 loss: 1.9299219846725464 grad: 5.522782750430495\n",
      "epoch: 55 loss: 1.9265599250793457 grad: 5.5808675443889415\n",
      "epoch: 56 loss: 1.9200754165649414 grad: 5.600155835820636\n",
      "epoch: 57 loss: 1.9182536602020264 grad: 5.1557087816119225\n",
      "epoch: 58 loss: 1.931191086769104 grad: 6.594312156840239\n",
      "epoch: 59 loss: 1.9207836389541626 grad: 5.245933871351308\n",
      "epoch: 60 loss: 1.9140721559524536 grad: 5.396644704491972\n",
      "epoch: 61 loss: 1.9119541645050049 grad: 4.709038512982679\n",
      "epoch: 62 loss: 1.9085614681243896 grad: 6.02224559813834\n",
      "epoch: 63 loss: 1.9128985404968262 grad: 5.308180341004609\n",
      "epoch: 64 loss: 1.9290049076080322 grad: 6.447337914402722\n",
      "epoch: 65 loss: 1.9081522226333618 grad: 6.297638054403092\n",
      "epoch: 66 loss: 1.8986220359802246 grad: 5.363398239195775\n",
      "epoch: 67 loss: 1.9042136669158936 grad: 5.749722994684514\n",
      "epoch: 68 loss: 1.9081693887710571 grad: 6.225141286054471\n",
      "epoch: 69 loss: 1.8888052701950073 grad: 5.948348805812809\n",
      "epoch: 70 loss: 1.8809012174606323 grad: 5.569359731811259\n",
      "epoch: 71 loss: 1.902197241783142 grad: 5.291600664150633\n",
      "epoch: 72 loss: 1.8985975980758667 grad: 5.598523517931065\n",
      "epoch: 73 loss: 1.898200511932373 grad: 5.059801380135006\n",
      "epoch: 74 loss: 1.8868087530136108 grad: 5.608563243745021\n",
      "epoch: 75 loss: 1.8872277736663818 grad: 4.849427560913711\n",
      "epoch: 76 loss: 1.8900796175003052 grad: 5.803258102750757\n",
      "epoch: 77 loss: 1.8939727544784546 grad: 5.4025049841699895\n",
      "epoch: 78 loss: 1.880115032196045 grad: 5.553396147579261\n",
      "epoch: 79 loss: 1.8819276094436646 grad: 5.311668498736542\n",
      "epoch: 80 loss: 1.8782763481140137 grad: 4.553537273319162\n",
      "epoch: 81 loss: 1.8761101961135864 grad: 5.7291474332571\n",
      "epoch: 82 loss: 1.9110316038131714 grad: 5.257320060706647\n",
      "epoch: 83 loss: 1.8724641799926758 grad: 5.68119815018745\n",
      "epoch: 84 loss: 1.8752493858337402 grad: 5.802723986269687\n",
      "epoch: 85 loss: 1.891384482383728 grad: 5.614073260129238\n",
      "epoch: 86 loss: 1.8937150239944458 grad: 5.3002750684631\n",
      "epoch: 87 loss: 1.8742159605026245 grad: 5.325802821212929\n",
      "epoch: 88 loss: 1.8714863061904907 grad: 5.559662698872022\n",
      "epoch: 89 loss: 1.8822927474975586 grad: 5.930968063610693\n",
      "epoch: 90 loss: 1.879331111907959 grad: 5.698376508904316\n",
      "epoch: 91 loss: 1.882317066192627 grad: 5.511285366808546\n",
      "epoch: 92 loss: 1.887719750404358 grad: 5.598035391777918\n",
      "epoch: 93 loss: 1.8715544939041138 grad: 5.772606875448782\n",
      "epoch: 94 loss: 1.8714255094528198 grad: 5.925411048774549\n",
      "epoch: 95 loss: 1.9126968383789062 grad: 6.175727693107634\n",
      "epoch: 96 loss: 1.873867392539978 grad: 5.272573581904345\n",
      "epoch: 97 loss: 1.870028018951416 grad: 5.598964899059316\n",
      "epoch: 98 loss: 1.8799692392349243 grad: 6.19982418840121\n",
      "epoch: 99 loss: 1.872636079788208 grad: 6.120492938460851\n",
      "epoch: 100 loss: 1.8616917133331299 grad: 5.271967216273576\n",
      "epoch: 101 loss: 1.8554619550704956 grad: 5.461665772591669\n",
      "epoch: 102 loss: 1.857015609741211 grad: 5.856822725992335\n",
      "epoch: 103 loss: 1.870513677597046 grad: 5.013806336230436\n",
      "epoch: 104 loss: 1.8543121814727783 grad: 5.155267324157028\n",
      "epoch: 105 loss: 1.8612630367279053 grad: 5.410135967231846\n",
      "epoch: 106 loss: 1.86555016040802 grad: 5.441317633916494\n",
      "epoch: 107 loss: 1.8583565950393677 grad: 5.415347137734884\n",
      "epoch: 108 loss: 1.8598167896270752 grad: 5.72622328791869\n",
      "epoch: 109 loss: 1.853826880455017 grad: 6.184385274734051\n",
      "epoch: 110 loss: 1.8815367221832275 grad: 6.483028996127749\n",
      "epoch: 111 loss: 1.8604693412780762 grad: 5.751093693907947\n",
      "epoch: 112 loss: 1.8467859029769897 grad: 6.03684069935832\n",
      "epoch: 113 loss: 1.8589715957641602 grad: 6.333445113453698\n",
      "epoch: 114 loss: 1.873599886894226 grad: 6.065445467976147\n",
      "epoch: 115 loss: 1.8554511070251465 grad: 5.85157590126278\n",
      "epoch: 116 loss: 1.8250397443771362 grad: 6.156635389043322\n",
      "epoch: 117 loss: 1.8542827367782593 grad: 5.420580166984961\n",
      "epoch: 118 loss: 1.8518810272216797 grad: 6.376144427625972\n",
      "epoch: 119 loss: 1.8479441404342651 grad: 6.081646187742341\n",
      "epoch: 120 loss: 1.8433462381362915 grad: 5.530076195167596\n",
      "epoch: 121 loss: 1.84758722782135 grad: 5.430191711662846\n",
      "epoch: 122 loss: 1.851991891860962 grad: 5.670391789212267\n",
      "epoch: 123 loss: 1.849265217781067 grad: 5.466159515697712\n",
      "epoch: 124 loss: 1.855297327041626 grad: 6.299286114951962\n",
      "epoch: 125 loss: 1.8570756912231445 grad: 6.829380079755667\n",
      "epoch: 126 loss: 1.876042366027832 grad: 6.287975726105894\n",
      "epoch: 127 loss: 1.836851716041565 grad: 5.343923354672457\n",
      "epoch: 128 loss: 1.8465533256530762 grad: 6.245415357561248\n",
      "epoch: 129 loss: 1.8454694747924805 grad: 5.596537275759537\n",
      "epoch: 130 loss: 1.8398184776306152 grad: 5.833244984342148\n",
      "epoch: 131 loss: 1.839026689529419 grad: 6.253224220218221\n",
      "epoch: 132 loss: 1.8293769359588623 grad: 6.3049472893684335\n",
      "epoch: 133 loss: 1.8368306159973145 grad: 5.9349170385652945\n",
      "epoch: 134 loss: 1.830672025680542 grad: 5.988187944005374\n",
      "epoch: 135 loss: 1.8385446071624756 grad: 6.643616129574689\n",
      "epoch: 136 loss: 1.8319720029830933 grad: 5.869569797983641\n",
      "epoch: 137 loss: 1.8213582038879395 grad: 6.74914580034099\n",
      "epoch: 138 loss: 1.8369660377502441 grad: 6.363965063406564\n",
      "epoch: 139 loss: 1.8393982648849487 grad: 6.1019844454369006\n",
      "epoch: 140 loss: 1.8174117803573608 grad: 5.554473523440907\n",
      "epoch: 141 loss: 1.838545322418213 grad: 5.071344344927985\n",
      "epoch: 142 loss: 1.8236567974090576 grad: 5.82301856812941\n",
      "epoch: 143 loss: 1.8146624565124512 grad: 5.265652154261752\n",
      "epoch: 144 loss: 1.8267359733581543 grad: 6.644798901339296\n",
      "epoch: 145 loss: 1.8227158784866333 grad: 5.797564125611975\n",
      "epoch: 146 loss: 1.828565001487732 grad: 6.283927914806266\n",
      "epoch: 147 loss: 1.8079297542572021 grad: 4.949749202658408\n",
      "epoch: 148 loss: 1.814447283744812 grad: 4.992454159987184\n",
      "epoch: 149 loss: 1.866202473640442 grad: 7.521163450912961\n",
      "epoch: 150 loss: 1.872788429260254 grad: 7.674950451944794\n",
      "epoch: 151 loss: 1.8521568775177002 grad: 5.667544274626943\n",
      "epoch: 152 loss: 1.834707260131836 grad: 5.972072729388899\n",
      "epoch: 153 loss: 1.8382275104522705 grad: 5.57573460883485\n",
      "epoch: 154 loss: 1.8291822671890259 grad: 5.5066089497395\n",
      "epoch: 155 loss: 1.8093204498291016 grad: 5.657900494491471\n",
      "epoch: 156 loss: 1.829023838043213 grad: 5.733837729529374\n",
      "epoch: 157 loss: 1.822547197341919 grad: 7.5110391563731165\n",
      "epoch: 158 loss: 1.8146332502365112 grad: 6.045973304304916\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 159 loss: 1.81797194480896 grad: 6.76538336350449\n",
      "epoch: 160 loss: 1.797220230102539 grad: 5.914376685369505\n",
      "epoch: 161 loss: 1.8132460117340088 grad: 6.193766937385677\n",
      "epoch: 162 loss: 1.805995225906372 grad: 5.973830898735734\n",
      "epoch: 163 loss: 1.8303471803665161 grad: 5.873377062961351\n",
      "epoch: 164 loss: 1.8260488510131836 grad: 6.020654818546597\n",
      "epoch: 165 loss: 1.818566083908081 grad: 6.071321561920553\n",
      "epoch: 166 loss: 1.8057889938354492 grad: 6.470472837219656\n",
      "epoch: 167 loss: 1.8059303760528564 grad: 5.613734282911913\n",
      "epoch: 168 loss: 1.8151875734329224 grad: 6.888969933382077\n",
      "epoch: 169 loss: 1.8158477544784546 grad: 7.009452272006167\n",
      "epoch: 170 loss: 1.8176612854003906 grad: 7.727131125781665\n",
      "epoch: 171 loss: 1.8105509281158447 grad: 5.899046757916982\n",
      "epoch: 172 loss: 1.7996665239334106 grad: 6.056615066450744\n",
      "epoch: 173 loss: 1.8331259489059448 grad: 6.2533290329222275\n",
      "epoch: 174 loss: 1.835967779159546 grad: 6.0764937903192715\n",
      "epoch: 175 loss: 1.8173015117645264 grad: 5.09373258583259\n",
      "epoch: 176 loss: 1.8075999021530151 grad: 6.761190358077401\n",
      "epoch: 177 loss: 1.8275541067123413 grad: 6.108749406444841\n",
      "epoch: 178 loss: 1.8164986371994019 grad: 5.678011640389221\n",
      "epoch: 179 loss: 1.8104897737503052 grad: 6.686799596149719\n",
      "epoch: 180 loss: 1.8145735263824463 grad: 6.571156805432457\n",
      "epoch: 181 loss: 1.809817910194397 grad: 6.270044283728827\n",
      "epoch: 182 loss: 1.8138720989227295 grad: 6.328314627420551\n",
      "epoch: 183 loss: 1.8202095031738281 grad: 7.158489606302788\n",
      "epoch: 184 loss: 1.810936450958252 grad: 6.1867631308249695\n",
      "epoch: 185 loss: 1.8070517778396606 grad: 6.229162882495624\n",
      "epoch: 186 loss: 1.8072888851165771 grad: 6.390347552669742\n",
      "epoch: 187 loss: 1.8072916269302368 grad: 5.992714722231222\n",
      "epoch: 188 loss: 1.8068645000457764 grad: 5.672784519568975\n",
      "epoch: 189 loss: 1.7987163066864014 grad: 5.153046853950299\n",
      "epoch: 190 loss: 1.8069714307785034 grad: 6.51539411850807\n",
      "epoch: 191 loss: 1.8023185729980469 grad: 4.815222148882885\n",
      "epoch: 192 loss: 1.8091520071029663 grad: 6.784002838019602\n",
      "epoch: 193 loss: 1.7958621978759766 grad: 5.83704554536425\n",
      "epoch: 194 loss: 1.8042064905166626 grad: 6.494630750987249\n",
      "epoch: 195 loss: 1.7936121225357056 grad: 6.006808332516465\n",
      "epoch: 196 loss: 1.8023329973220825 grad: 5.847031939141512\n",
      "epoch: 197 loss: 1.8013652563095093 grad: 6.301108289965871\n",
      "epoch: 198 loss: 1.8070030212402344 grad: 6.890561284283635\n",
      "epoch: 199 loss: 1.8142986297607422 grad: 7.240397935911633\n",
      "epoch: 200 loss: 1.8233147859573364 grad: 5.874346996233581\n",
      "epoch: 201 loss: 1.8235186338424683 grad: 6.514057981897615\n",
      "epoch: 202 loss: 1.8082674741744995 grad: 5.919337293027465\n",
      "epoch: 203 loss: 1.8168104887008667 grad: 6.716229985283159\n",
      "epoch: 204 loss: 1.784069299697876 grad: 6.810456638412039\n",
      "epoch: 205 loss: 1.800484538078308 grad: 6.489688799095997\n",
      "epoch: 206 loss: 1.803954005241394 grad: 6.684614039106467\n",
      "epoch: 207 loss: 1.7917643785476685 grad: 6.02891013656653\n",
      "epoch: 208 loss: 1.7932336330413818 grad: 5.541146390880992\n",
      "epoch: 209 loss: 1.7964258193969727 grad: 7.029587723784927\n",
      "epoch: 210 loss: 1.7873623371124268 grad: 6.308568652660128\n",
      "epoch: 211 loss: 1.7994102239608765 grad: 6.413352746201781\n",
      "epoch: 212 loss: 1.7799499034881592 grad: 4.728360726300404\n",
      "epoch: 213 loss: 1.7789607048034668 grad: 5.485606500745537\n",
      "epoch: 214 loss: 1.788360357284546 grad: 5.763942081230198\n",
      "epoch: 215 loss: 1.787760615348816 grad: 6.49830555164844\n",
      "epoch: 216 loss: 1.7756000757217407 grad: 6.9542382418416855\n",
      "epoch: 217 loss: 1.793874979019165 grad: 6.3383366967988\n",
      "epoch: 218 loss: 1.7787500619888306 grad: 5.970537500091513\n",
      "epoch: 219 loss: 1.7939565181732178 grad: 6.272252978609368\n",
      "epoch: 220 loss: 1.7813328504562378 grad: 5.4736438323918035\n",
      "epoch: 221 loss: 1.8140259981155396 grad: 7.455350104821899\n",
      "epoch: 222 loss: 1.7913082838058472 grad: 6.231885220619006\n",
      "epoch: 223 loss: 1.7797666788101196 grad: 5.578775602828313\n",
      "epoch: 224 loss: 1.7744821310043335 grad: 5.545672360642447\n",
      "epoch: 225 loss: 1.7929385900497437 grad: 6.864585711519751\n",
      "epoch: 226 loss: 1.7805688381195068 grad: 5.620819715282865\n",
      "epoch: 227 loss: 1.7727493047714233 grad: 4.653130933549135\n",
      "epoch: 228 loss: 1.7724689245224 grad: 4.948399856696618\n",
      "epoch: 229 loss: 1.7796802520751953 grad: 6.282230947023703\n",
      "epoch: 230 loss: 1.778606653213501 grad: 5.685263414836848\n",
      "epoch: 231 loss: 1.7727776765823364 grad: 5.367603499980471\n",
      "epoch: 232 loss: 1.7631231546401978 grad: 4.762706610112666\n",
      "epoch: 233 loss: 1.7798349857330322 grad: 5.9888016289987425\n",
      "epoch: 234 loss: 1.7725685834884644 grad: 5.335911833123956\n",
      "epoch: 235 loss: 1.7775100469589233 grad: 6.484059845628277\n",
      "epoch: 236 loss: 1.7971810102462769 grad: 7.826458922371972\n",
      "epoch: 237 loss: 1.7863343954086304 grad: 4.653310222173974\n",
      "epoch: 238 loss: 1.7929989099502563 grad: 6.731756262975544\n",
      "epoch: 239 loss: 1.7847498655319214 grad: 5.789114575432067\n",
      "epoch: 240 loss: 1.7653357982635498 grad: 6.62184064717656\n",
      "epoch: 241 loss: 1.7706648111343384 grad: 5.360653207868468\n",
      "epoch: 242 loss: 1.7708334922790527 grad: 5.799551201477799\n",
      "epoch: 243 loss: 1.7789541482925415 grad: 5.701745882419345\n",
      "epoch: 244 loss: 1.7788166999816895 grad: 6.330951940468078\n",
      "epoch: 245 loss: 1.771948218345642 grad: 6.563259019956777\n",
      "epoch: 246 loss: 1.7760047912597656 grad: 6.404312523816193\n",
      "epoch: 247 loss: 1.773694634437561 grad: 5.407725267902765\n",
      "epoch: 248 loss: 1.790558934211731 grad: 5.751028467925016\n",
      "epoch: 249 loss: 1.7975010871887207 grad: 5.874915227871021\n",
      "epoch: 250 loss: 1.7571996450424194 grad: 5.967171543261711\n",
      "epoch: 251 loss: 1.7729310989379883 grad: 5.192903907674167\n",
      "epoch: 252 loss: 1.7626394033432007 grad: 6.147635543974632\n",
      "epoch: 253 loss: 1.760016918182373 grad: 5.524696052475938\n",
      "epoch: 254 loss: 1.7922552824020386 grad: 6.563842598052621\n",
      "epoch: 255 loss: 1.802006721496582 grad: 6.4375152560112054\n",
      "epoch: 256 loss: 1.7720290422439575 grad: 7.086345199071744\n",
      "epoch: 257 loss: 1.7711564302444458 grad: 4.835355176650424\n",
      "epoch: 258 loss: 1.793218970298767 grad: 5.965458996902993\n",
      "epoch: 259 loss: 1.7527570724487305 grad: 6.0313574891986805\n",
      "epoch: 260 loss: 1.7609599828720093 grad: 5.902707092830136\n",
      "epoch: 261 loss: 1.7536858320236206 grad: 5.22718248960631\n",
      "epoch: 262 loss: 1.7745877504348755 grad: 6.389343525110379\n",
      "epoch: 263 loss: 1.7725423574447632 grad: 4.286121064630477\n",
      "epoch: 264 loss: 1.7691746950149536 grad: 6.56800731234782\n",
      "epoch: 265 loss: 1.7802470922470093 grad: 6.649259676303036\n",
      "epoch: 266 loss: 1.7827023267745972 grad: 6.317449979600439\n",
      "epoch: 267 loss: 1.7582006454467773 grad: 4.734679856830293\n",
      "epoch: 268 loss: 1.7710613012313843 grad: 5.40345547375319\n",
      "epoch: 269 loss: 1.7560516595840454 grad: 5.580659464326875\n",
      "epoch: 270 loss: 1.7879050970077515 grad: 6.638689122642799\n",
      "epoch: 271 loss: 1.758611798286438 grad: 6.0521451402649165\n",
      "epoch: 272 loss: 1.7812455892562866 grad: 5.392641502144374\n",
      "epoch: 273 loss: 1.756171464920044 grad: 6.1047780171634045\n",
      "epoch: 274 loss: 1.7467050552368164 grad: 4.981239238389699\n",
      "epoch: 275 loss: 1.7626794576644897 grad: 5.046844935315315\n",
      "epoch: 276 loss: 1.7781184911727905 grad: 4.98699348637676\n",
      "epoch: 277 loss: 1.775923490524292 grad: 6.336600739249301\n",
      "epoch: 278 loss: 1.7636499404907227 grad: 6.536974355065959\n",
      "epoch: 279 loss: 1.7389931678771973 grad: 5.0807655716374045\n",
      "epoch: 280 loss: 1.7606559991836548 grad: 5.273051238756875\n",
      "epoch: 281 loss: 1.7518354654312134 grad: 5.275637492820164\n",
      "epoch: 282 loss: 1.7580910921096802 grad: 5.48507857032206\n",
      "epoch: 283 loss: 1.7531932592391968 grad: 4.820673230964588\n",
      "epoch: 284 loss: 1.762262225151062 grad: 5.743398563080518\n",
      "epoch: 285 loss: 1.748320460319519 grad: 5.259891195998462\n",
      "epoch: 286 loss: 1.7531741857528687 grad: 6.455083049233003\n",
      "epoch: 287 loss: 1.751047134399414 grad: 6.250478654410631\n",
      "epoch: 288 loss: 1.7700504064559937 grad: 5.328891539498265\n",
      "epoch: 289 loss: 1.7691911458969116 grad: 5.511335236580722\n",
      "epoch: 290 loss: 1.7536745071411133 grad: 6.256387004293226\n",
      "epoch: 291 loss: 1.752444863319397 grad: 6.360683737979921\n",
      "epoch: 292 loss: 1.7662047147750854 grad: 4.840702729707984\n",
      "epoch: 293 loss: 1.7622939348220825 grad: 5.361052192394536\n",
      "epoch: 294 loss: 1.756306529045105 grad: 7.041520892200569\n",
      "epoch: 295 loss: 1.7933967113494873 grad: 6.229606290252348\n",
      "epoch: 296 loss: 1.7719053030014038 grad: 5.636691929756876\n",
      "epoch: 297 loss: 1.7572933435440063 grad: 4.739326649678188\n",
      "epoch: 298 loss: 1.7626432180404663 grad: 4.326467364048601\n",
      "epoch: 299 loss: 1.755476713180542 grad: 5.628811984467561\n",
      "epoch: 300 loss: 1.7584693431854248 grad: 6.2189959330785385\n",
      "epoch: 301 loss: 1.7494537830352783 grad: 4.270318487380858\n",
      "epoch: 302 loss: 1.748164176940918 grad: 5.598993381108847\n",
      "epoch: 303 loss: 1.7610193490982056 grad: 5.836042504735937\n",
      "epoch: 304 loss: 1.761867880821228 grad: 5.588172048983758\n",
      "epoch: 305 loss: 1.769926905632019 grad: 5.68175870812994\n",
      "epoch: 306 loss: 1.7610657215118408 grad: 5.457688017743857\n",
      "epoch: 307 loss: 1.747757077217102 grad: 5.570522395977432\n",
      "epoch: 308 loss: 1.7677621841430664 grad: 6.255621936772216\n",
      "epoch: 309 loss: 1.766615390777588 grad: 5.832376557490981\n",
      "epoch: 310 loss: 1.7554080486297607 grad: 3.7524765905529027\n",
      "epoch: 311 loss: 1.763668179512024 grad: 6.666507713677886\n",
      "epoch: 312 loss: 1.7613928318023682 grad: 5.883375325791693\n",
      "epoch: 313 loss: 1.7542846202850342 grad: 6.301064068437896\n",
      "epoch: 314 loss: 1.7615079879760742 grad: 5.580736205730066\n",
      "epoch: 315 loss: 1.7564271688461304 grad: 4.53275964366101\n",
      "epoch: 316 loss: 1.7509961128234863 grad: 4.678430214379198\n",
      "epoch: 317 loss: 1.7624024152755737 grad: 6.178128591807233\n",
      "epoch: 318 loss: 1.7554335594177246 grad: 4.792333746153576\n",
      "epoch: 319 loss: 1.7516553401947021 grad: 4.951135400266581\n",
      "epoch: 320 loss: 1.7629122734069824 grad: 7.201343577084094\n",
      "epoch: 321 loss: 1.768965721130371 grad: 6.745896353451361\n",
      "epoch: 322 loss: 1.7497522830963135 grad: 5.53633341723091\n",
      "epoch: 323 loss: 1.7530097961425781 grad: 7.180944926822721\n",
      "epoch: 324 loss: 1.7738368511199951 grad: 5.931874042400537\n",
      "epoch: 325 loss: 1.7448664903640747 grad: 5.261955974098667\n",
      "epoch: 326 loss: 1.7480847835540771 grad: 6.0509473391582524\n",
      "epoch: 327 loss: 1.759549856185913 grad: 4.914988705606382\n",
      "epoch: 328 loss: 1.759398341178894 grad: 4.987717951857208\n",
      "epoch: 329 loss: 1.7643544673919678 grad: 6.007712346607164\n",
      "epoch: 330 loss: 1.7561513185501099 grad: 5.933403083236362\n",
      "epoch: 331 loss: 1.7517297267913818 grad: 4.9647844960149925\n",
      "epoch: 332 loss: 1.7531249523162842 grad: 5.40547916698838\n",
      "epoch: 333 loss: 1.7478300333023071 grad: 5.547373953503407\n",
      "epoch: 334 loss: 1.7462728023529053 grad: 6.900402118419372\n",
      "epoch: 335 loss: 1.750878930091858 grad: 5.412025023377957\n",
      "epoch: 336 loss: 1.75774085521698 grad: 5.037715506327314\n",
      "epoch: 337 loss: 1.7345073223114014 grad: 4.272933709785663\n",
      "epoch: 338 loss: 1.7415722608566284 grad: 6.025228682668859\n",
      "epoch: 339 loss: 1.7435981035232544 grad: 5.6372296778864035\n",
      "epoch: 340 loss: 1.7339487075805664 grad: 5.8998905131902575\n",
      "epoch: 341 loss: 1.7518583536148071 grad: 6.285167780664605\n",
      "epoch: 342 loss: 1.761145830154419 grad: 4.485806031897123\n",
      "epoch: 343 loss: 1.7373803853988647 grad: 5.842549540444756\n",
      "epoch: 344 loss: 1.7274892330169678 grad: 4.688338128610726\n",
      "epoch: 345 loss: 1.73556387424469 grad: 5.465753289386029\n",
      "epoch: 346 loss: 1.7372783422470093 grad: 4.712455319008968\n",
      "epoch: 347 loss: 1.7478832006454468 grad: 5.410402160437938\n",
      "epoch: 348 loss: 1.7697833776474 grad: 5.046461127856761\n",
      "epoch: 349 loss: 1.726264476776123 grad: 4.598380473700897\n",
      "epoch: 350 loss: 1.7559418678283691 grad: 5.565026109640495\n",
      "epoch: 351 loss: 1.7364487648010254 grad: 4.986926014290749\n",
      "epoch: 352 loss: 1.7645833492279053 grad: 7.613485303052758\n",
      "epoch: 353 loss: 1.7495273351669312 grad: 5.644149903369561\n",
      "epoch: 354 loss: 1.7467073202133179 grad: 5.095038353415346\n",
      "epoch: 355 loss: 1.7421584129333496 grad: 5.299399258480561\n",
      "epoch: 356 loss: 1.739630103111267 grad: 4.894172534249265\n",
      "epoch: 357 loss: 1.7542290687561035 grad: 4.628152632887837\n",
      "epoch: 358 loss: 1.7555756568908691 grad: 5.588473666099711\n",
      "epoch: 359 loss: 1.7438018321990967 grad: 4.72479318703861\n",
      "epoch: 360 loss: 1.7329944372177124 grad: 6.132505398749547\n",
      "epoch: 361 loss: 1.7610714435577393 grad: 4.902314771794438\n",
      "epoch: 362 loss: 1.734342336654663 grad: 5.232074051968972\n",
      "epoch: 363 loss: 1.7393856048583984 grad: 5.4340001415814685\n",
      "epoch: 364 loss: 1.7525460720062256 grad: 5.415488618985416\n",
      "epoch: 365 loss: 1.7508544921875 grad: 5.130536335558804\n",
      "epoch: 366 loss: 1.728873372077942 grad: 4.475795931541034\n",
      "epoch: 367 loss: 1.7388410568237305 grad: 5.76715971499921\n",
      "epoch: 368 loss: 1.745111107826233 grad: 4.586812076240113\n",
      "epoch: 369 loss: 1.7547188997268677 grad: 4.945506395577984\n",
      "epoch: 370 loss: 1.7409080266952515 grad: 6.1040850256898\n",
      "epoch: 371 loss: 1.7392181158065796 grad: 6.391230679538542\n",
      "epoch: 372 loss: 1.7473851442337036 grad: 3.988741856944656\n",
      "epoch: 373 loss: 1.733342170715332 grad: 4.267700969543723\n",
      "epoch: 374 loss: 1.7203768491744995 grad: 4.239871132989641\n",
      "epoch: 375 loss: 1.7464689016342163 grad: 4.967283984108291\n",
      "epoch: 376 loss: 1.7422137260437012 grad: 5.69497423282756\n",
      "epoch: 377 loss: 1.7297518253326416 grad: 4.965784145843423\n",
      "epoch: 378 loss: 1.7316434383392334 grad: 6.519883446329394\n",
      "epoch: 379 loss: 1.7395250797271729 grad: 5.525907129844646\n",
      "epoch: 380 loss: 1.741912841796875 grad: 5.358992235892335\n",
      "epoch: 381 loss: 1.757442593574524 grad: 5.320986086868461\n",
      "epoch: 382 loss: 1.7660903930664062 grad: 5.46766396218714\n",
      "epoch: 383 loss: 1.7451393604278564 grad: 4.9887869122472575\n",
      "epoch: 384 loss: 1.7252744436264038 grad: 4.492851452845527\n",
      "epoch: 385 loss: 1.741701364517212 grad: 5.438447974552752\n",
      "epoch: 386 loss: 1.7457314729690552 grad: 4.3656299728531485\n",
      "epoch: 387 loss: 1.73850417137146 grad: 5.140625990374348\n",
      "epoch: 388 loss: 1.735216736793518 grad: 3.5566094437163986\n",
      "epoch: 389 loss: 1.7182873487472534 grad: 4.669496800099568\n",
      "epoch: 390 loss: 1.718570590019226 grad: 5.3052136962369385\n",
      "epoch: 391 loss: 1.7381240129470825 grad: 6.000455308072589\n",
      "epoch: 392 loss: 1.733707308769226 grad: 4.7375387593107305\n",
      "epoch: 393 loss: 1.7272584438323975 grad: 4.300750023391997\n",
      "epoch: 394 loss: 1.7219403982162476 grad: 4.850704135280018\n",
      "epoch: 395 loss: 1.7302955389022827 grad: 5.190016714702749\n",
      "epoch: 396 loss: 1.7307931184768677 grad: 5.612516761286268\n",
      "epoch: 397 loss: 1.72495698928833 grad: 4.154781977044747\n",
      "epoch: 398 loss: 1.7513604164123535 grad: 6.163835069439402\n",
      "epoch: 399 loss: 1.7381831407546997 grad: 4.868073962782618\n",
      "epoch: 400 loss: 1.7272982597351074 grad: 6.854025089449351\n",
      "epoch: 401 loss: 1.742136001586914 grad: 4.277839836632701\n",
      "epoch: 402 loss: 1.7346365451812744 grad: 6.194789823749819\n",
      "epoch: 403 loss: 1.747715950012207 grad: 6.955255620391603\n",
      "epoch: 404 loss: 1.7376446723937988 grad: 5.450751577221747\n",
      "epoch: 405 loss: 1.7194300889968872 grad: 5.563665620884609\n",
      "epoch: 406 loss: 1.7304768562316895 grad: 5.377248771581545\n",
      "epoch: 407 loss: 1.7286392450332642 grad: 5.202533477300869\n",
      "epoch: 408 loss: 1.7406408786773682 grad: 4.958342492775886\n",
      "epoch: 409 loss: 1.7409706115722656 grad: 6.087179545520745\n",
      "epoch: 410 loss: 1.7373788356781006 grad: 5.721982590992933\n",
      "epoch: 411 loss: 1.7223169803619385 grad: 4.055398078546064\n",
      "epoch: 412 loss: 1.737337350845337 grad: 5.465356500221714\n",
      "epoch: 413 loss: 1.7296029329299927 grad: 4.686155347241736\n",
      "epoch: 414 loss: 1.729214072227478 grad: 5.345190955619995\n",
      "epoch: 415 loss: 1.7193015813827515 grad: 6.3142942754180575\n",
      "epoch: 416 loss: 1.738244652748108 grad: 5.349274208838004\n",
      "epoch: 417 loss: 1.7163828611373901 grad: 4.984496649008525\n",
      "epoch: 418 loss: 1.719340205192566 grad: 5.442659788756888\n",
      "epoch: 419 loss: 1.723124384880066 grad: 5.274845189609755\n",
      "epoch: 420 loss: 1.7216558456420898 grad: 4.308188127979751\n",
      "epoch: 421 loss: 1.7133665084838867 grad: 4.07908319559667\n",
      "epoch: 422 loss: 1.7094019651412964 grad: 4.820136889663712\n",
      "epoch: 423 loss: 1.719050407409668 grad: 5.0936237159231466\n",
      "epoch: 424 loss: 1.729770302772522 grad: 5.578124947072748\n",
      "epoch: 425 loss: 1.7234501838684082 grad: 4.770414782751239\n",
      "epoch: 426 loss: 1.7460721731185913 grad: 5.1890794051115146\n",
      "epoch: 427 loss: 1.7232474088668823 grad: 5.3383886275096595\n",
      "epoch: 428 loss: 1.729182481765747 grad: 4.4432318628431355\n",
      "epoch: 429 loss: 1.7202869653701782 grad: 4.657902429869131\n",
      "epoch: 430 loss: 1.7444608211517334 grad: 8.430750196395387\n",
      "epoch: 431 loss: 1.7415740489959717 grad: 5.010175735555614\n",
      "epoch: 432 loss: 1.7246333360671997 grad: 5.296279715367529\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 433 loss: 1.733674168586731 grad: 5.464232586168273\n",
      "epoch: 434 loss: 1.7344646453857422 grad: 4.859053516120459\n",
      "epoch: 435 loss: 1.7192307710647583 grad: 4.27257460705725\n",
      "epoch: 436 loss: 1.7277618646621704 grad: 4.585511683921097\n",
      "epoch: 437 loss: 1.7088868618011475 grad: 4.882768877999203\n",
      "epoch: 438 loss: 1.721104383468628 grad: 4.786355672746963\n",
      "epoch: 439 loss: 1.7348616123199463 grad: 5.361135968725248\n",
      "epoch: 440 loss: 1.7177565097808838 grad: 4.772330289254561\n",
      "epoch: 441 loss: 1.7247695922851562 grad: 4.699234685109664\n",
      "epoch: 442 loss: 1.7127333879470825 grad: 4.409009717551719\n",
      "epoch: 443 loss: 1.7365341186523438 grad: 5.3960731495800305\n",
      "epoch: 444 loss: 1.725999355316162 grad: 4.747447358474411\n",
      "epoch: 445 loss: 1.7174054384231567 grad: 3.2333962798222387\n",
      "epoch: 446 loss: 1.7137620449066162 grad: 5.445654359502048\n",
      "epoch: 447 loss: 1.7140529155731201 grad: 5.570284645515953\n",
      "epoch: 448 loss: 1.7089118957519531 grad: 4.145889943603489\n",
      "epoch: 449 loss: 1.7283238172531128 grad: 6.07588573724788\n",
      "epoch: 450 loss: 1.7129566669464111 grad: 5.365991332032505\n",
      "epoch: 451 loss: 1.7146977186203003 grad: 3.615289743792324\n",
      "epoch: 452 loss: 1.7078766822814941 grad: 3.5906887067854822\n",
      "epoch: 453 loss: 1.7243801355361938 grad: 4.314749228642869\n",
      "epoch: 454 loss: 1.7360248565673828 grad: 5.8874357922820035\n",
      "epoch: 455 loss: 1.722568392753601 grad: 4.3015846144381085\n",
      "epoch: 456 loss: 1.7081670761108398 grad: 3.507336086537382\n",
      "epoch: 457 loss: 1.7283267974853516 grad: 4.12743194700008\n",
      "epoch: 458 loss: 1.7127554416656494 grad: 4.152838436217053\n",
      "epoch: 459 loss: 1.721693754196167 grad: 4.290470882934439\n",
      "epoch: 460 loss: 1.7232683897018433 grad: 4.550732184620727\n",
      "epoch: 461 loss: 1.7410093545913696 grad: 5.775260476253722\n",
      "epoch: 462 loss: 1.7190232276916504 grad: 5.0598258502520785\n",
      "epoch: 463 loss: 1.7145754098892212 grad: 4.089780160474246\n",
      "epoch: 464 loss: 1.7105965614318848 grad: 6.102986340767818\n",
      "epoch: 465 loss: 1.7342153787612915 grad: 5.57256511994948\n",
      "epoch: 466 loss: 1.7182179689407349 grad: 5.937164905925681\n",
      "epoch: 467 loss: 1.7098984718322754 grad: 6.685860571627989\n",
      "epoch: 468 loss: 1.711512804031372 grad: 5.565508761723293\n",
      "epoch: 469 loss: 1.7315963506698608 grad: 5.580700693814631\n",
      "epoch: 470 loss: 1.7193312644958496 grad: 3.946554220232804\n",
      "epoch: 471 loss: 1.7123841047286987 grad: 3.71726499139089\n",
      "epoch: 472 loss: 1.7041243314743042 grad: 3.3680101374964413\n",
      "epoch: 473 loss: 1.703126072883606 grad: 4.046542365453088\n",
      "epoch: 474 loss: 1.7035980224609375 grad: 4.16005829850364\n",
      "epoch: 475 loss: 1.729430913925171 grad: 5.228382477370954\n",
      "epoch: 476 loss: 1.7107264995574951 grad: 5.003859381871703\n",
      "epoch: 477 loss: 1.7121045589447021 grad: 5.471210123096286\n",
      "epoch: 478 loss: 1.7175778150558472 grad: 4.394073129520159\n",
      "epoch: 479 loss: 1.7387754917144775 grad: 5.003829260777665\n",
      "epoch: 480 loss: 1.719062328338623 grad: 4.6196130897943375\n",
      "epoch: 481 loss: 1.713032841682434 grad: 5.263154513442426\n",
      "epoch: 482 loss: 1.7456817626953125 grad: 4.662877360823203\n",
      "epoch: 483 loss: 1.7171735763549805 grad: 4.899845854935884\n",
      "epoch: 484 loss: 1.7182185649871826 grad: 4.688481969580299\n",
      "epoch: 485 loss: 1.7200850248336792 grad: 4.905248033171921\n",
      "epoch: 486 loss: 1.7175521850585938 grad: 5.0996218012693815\n",
      "epoch: 487 loss: 1.7327650785446167 grad: 5.016164640067006\n",
      "epoch: 488 loss: 1.7136502265930176 grad: 4.129305467166645\n",
      "epoch: 489 loss: 1.7275047302246094 grad: 4.153681798582583\n",
      "epoch: 490 loss: 1.7174336910247803 grad: 5.001518584490681\n",
      "epoch: 491 loss: 1.7139508724212646 grad: 6.040875383641039\n",
      "epoch: 492 loss: 1.740303874015808 grad: 6.714526431983044\n",
      "epoch: 493 loss: 1.7102227210998535 grad: 3.6630628689422338\n",
      "epoch: 494 loss: 1.7224560976028442 grad: 5.059610759842685\n",
      "epoch: 495 loss: 1.716683268547058 grad: 5.529597894353271\n",
      "epoch: 496 loss: 1.7231732606887817 grad: 4.349414621046492\n",
      "epoch: 497 loss: 1.7256232500076294 grad: 5.211183650096415\n",
      "epoch: 498 loss: 1.7259048223495483 grad: 4.482785539158526\n",
      "epoch: 499 loss: 1.7378369569778442 grad: 4.936271920060819\n",
      "2.001836858689785\n",
      "epoch: 0 loss: 2.302189826965332 grad: 1.2608288716476794\n",
      "epoch: 1 loss: 2.302719831466675 grad: 1.2500399222693568\n",
      "epoch: 2 loss: 2.3036675453186035 grad: 1.2426084746340555\n",
      "epoch: 3 loss: 2.3031394481658936 grad: 1.255890761744157\n",
      "epoch: 4 loss: 2.3023698329925537 grad: 1.2650210326094002\n",
      "epoch: 5 loss: 2.3027637004852295 grad: 1.24529766832434\n",
      "epoch: 6 loss: 2.303241491317749 grad: 1.2375866143875534\n",
      "epoch: 7 loss: 2.3030200004577637 grad: 1.258877789636793\n",
      "epoch: 8 loss: 2.3030550479888916 grad: 1.2376865893011055\n",
      "epoch: 9 loss: 2.3030381202697754 grad: 1.2432270034249606\n",
      "epoch: 10 loss: 2.3032822608947754 grad: 1.2311033466350405\n",
      "epoch: 11 loss: 2.3028738498687744 grad: 1.2465794196496496\n",
      "epoch: 12 loss: 2.3025598526000977 grad: 1.2570634261475846\n",
      "epoch: 13 loss: 2.3027989864349365 grad: 1.239463013674443\n",
      "epoch: 14 loss: 2.3032703399658203 grad: 1.260069054224351\n",
      "epoch: 15 loss: 2.3026957511901855 grad: 1.2597655395511538\n",
      "epoch: 16 loss: 2.3023412227630615 grad: 1.2540125146984966\n",
      "epoch: 17 loss: 2.3027102947235107 grad: 1.2522292926940801\n",
      "epoch: 18 loss: 2.303191900253296 grad: 1.2525936617046625\n",
      "epoch: 19 loss: 2.303605556488037 grad: 1.23246797935165\n",
      "epoch: 20 loss: 2.302767515182495 grad: 1.2418994727980581\n",
      "epoch: 21 loss: 2.30316424369812 grad: 1.2409881495164767\n",
      "epoch: 22 loss: 2.302597761154175 grad: 1.2554009772286499\n",
      "epoch: 23 loss: 2.302516460418701 grad: 1.2439488756751258\n",
      "epoch: 24 loss: 2.302496910095215 grad: 1.2492733687007178\n",
      "epoch: 25 loss: 2.3026278018951416 grad: 1.2490483254216433\n",
      "epoch: 26 loss: 2.3020217418670654 grad: 1.2704087449015962\n",
      "epoch: 27 loss: 2.302356243133545 grad: 1.2500323975192649\n",
      "epoch: 28 loss: 2.3030285835266113 grad: 1.2444999870319393\n",
      "epoch: 29 loss: 2.3029160499572754 grad: 1.2459913476144835\n",
      "epoch: 30 loss: 2.302445888519287 grad: 1.250226761539659\n",
      "epoch: 31 loss: 2.302778720855713 grad: 1.251975768643047\n",
      "epoch: 32 loss: 2.301884889602661 grad: 1.2593495194312363\n",
      "epoch: 33 loss: 2.302394390106201 grad: 1.256054210480273\n",
      "epoch: 34 loss: 2.3023056983947754 grad: 1.2555758034041713\n",
      "epoch: 35 loss: 2.3030247688293457 grad: 1.2522384285527681\n",
      "epoch: 36 loss: 2.302885055541992 grad: 1.241226653309746\n",
      "epoch: 37 loss: 2.302510976791382 grad: 1.252544888834809\n",
      "epoch: 38 loss: 2.3026909828186035 grad: 1.2490942801038425\n",
      "epoch: 39 loss: 2.3025193214416504 grad: 1.2495574003809855\n",
      "epoch: 40 loss: 2.3023781776428223 grad: 1.2479046089149686\n",
      "epoch: 41 loss: 2.302241563796997 grad: 1.2609410413285895\n",
      "epoch: 42 loss: 2.3029916286468506 grad: 1.2444130819353705\n",
      "epoch: 43 loss: 2.3031535148620605 grad: 1.2426902707536809\n",
      "epoch: 44 loss: 2.302623987197876 grad: 1.256420743893758\n",
      "epoch: 45 loss: 2.302912473678589 grad: 1.2556829456154937\n",
      "epoch: 46 loss: 2.302863359451294 grad: 1.2490158356201377\n",
      "epoch: 47 loss: 2.303001642227173 grad: 1.2490322253729647\n",
      "epoch: 48 loss: 2.302508592605591 grad: 1.2427517384039386\n",
      "epoch: 49 loss: 2.302412748336792 grad: 1.257662671878712\n",
      "epoch: 50 loss: 2.302426338195801 grad: 1.2555223446586983\n",
      "epoch: 51 loss: 2.302727222442627 grad: 1.2496594940663301\n",
      "epoch: 52 loss: 2.3026862144470215 grad: 1.2416773381428645\n",
      "epoch: 53 loss: 2.3024938106536865 grad: 1.258756205929251\n",
      "epoch: 54 loss: 2.3029556274414062 grad: 1.2391647161742199\n",
      "epoch: 55 loss: 2.303100347518921 grad: 1.24542787093817\n",
      "epoch: 56 loss: 2.302520990371704 grad: 1.2471871275051927\n",
      "epoch: 57 loss: 2.3023171424865723 grad: 1.2543141430739078\n",
      "epoch: 58 loss: 2.302112102508545 grad: 1.2477431250865467\n",
      "epoch: 59 loss: 2.3024649620056152 grad: 1.2424065223617835\n",
      "epoch: 60 loss: 2.3026559352874756 grad: 1.2398408828062997\n",
      "epoch: 61 loss: 2.3031299114227295 grad: 1.240243141777769\n",
      "epoch: 62 loss: 2.3025741577148438 grad: 1.2465892293479381\n",
      "epoch: 63 loss: 2.303150177001953 grad: 1.2398056308849759\n",
      "epoch: 64 loss: 2.3028132915496826 grad: 1.2393286537844688\n",
      "epoch: 65 loss: 2.302757501602173 grad: 1.2410768434028363\n",
      "epoch: 66 loss: 2.3027265071868896 grad: 1.251597264892466\n",
      "epoch: 67 loss: 2.3024466037750244 grad: 1.2509873838696097\n",
      "epoch: 68 loss: 2.3024826049804688 grad: 1.2553437200840563\n",
      "epoch: 69 loss: 2.302262783050537 grad: 1.254219771298166\n",
      "epoch: 70 loss: 2.302286148071289 grad: 1.2501724518111184\n",
      "epoch: 71 loss: 2.3023478984832764 grad: 1.2542982271720937\n",
      "epoch: 72 loss: 2.302541971206665 grad: 1.2480761729243641\n",
      "epoch: 73 loss: 2.302450656890869 grad: 1.244497062462855\n",
      "epoch: 74 loss: 2.301947593688965 grad: 1.2630565429553537\n",
      "epoch: 75 loss: 2.3024179935455322 grad: 1.2433319698782668\n",
      "epoch: 76 loss: 2.30255126953125 grad: 1.2477819902659764\n",
      "epoch: 77 loss: 2.30265212059021 grad: 1.2481878142718905\n",
      "epoch: 78 loss: 2.3034677505493164 grad: 1.235549434605572\n",
      "epoch: 79 loss: 2.302729606628418 grad: 1.2458011037004846\n",
      "epoch: 80 loss: 2.302304744720459 grad: 1.248415240219661\n",
      "epoch: 81 loss: 2.3032965660095215 grad: 1.237028430798091\n",
      "epoch: 82 loss: 2.3026132583618164 grad: 1.2429542116587982\n",
      "epoch: 83 loss: 2.302884101867676 grad: 1.244303093763024\n",
      "epoch: 84 loss: 2.3022778034210205 grad: 1.239697852582183\n",
      "epoch: 85 loss: 2.302537202835083 grad: 1.2458068738277588\n",
      "epoch: 86 loss: 2.3030176162719727 grad: 1.234770642338498\n",
      "epoch: 87 loss: 2.303374767303467 grad: 1.2325267473767911\n",
      "epoch: 88 loss: 2.3022336959838867 grad: 1.2557945540433542\n",
      "epoch: 89 loss: 2.3025853633880615 grad: 1.2461119883209615\n",
      "epoch: 90 loss: 2.3026371002197266 grad: 1.24427762346357\n",
      "epoch: 91 loss: 2.303257703781128 grad: 1.2342717283689935\n",
      "epoch: 92 loss: 2.301612138748169 grad: 1.258160252582341\n",
      "epoch: 93 loss: 2.303105592727661 grad: 1.2473603216007292\n",
      "epoch: 94 loss: 2.302682399749756 grad: 1.2467092954006695\n",
      "epoch: 95 loss: 2.3029558658599854 grad: 1.2463392790440204\n",
      "epoch: 96 loss: 2.302940607070923 grad: 1.234198971644103\n",
      "epoch: 97 loss: 2.3021788597106934 grad: 1.2460376287030706\n",
      "epoch: 98 loss: 2.302744150161743 grad: 1.243501004421093\n",
      "epoch: 99 loss: 2.3031980991363525 grad: 1.228632582288738\n",
      "epoch: 100 loss: 2.303034782409668 grad: 1.237344356283309\n",
      "epoch: 101 loss: 2.3028602600097656 grad: 1.2457584960363983\n",
      "epoch: 102 loss: 2.3027873039245605 grad: 1.2429885676829144\n",
      "epoch: 103 loss: 2.302236318588257 grad: 1.2455376358092984\n",
      "epoch: 104 loss: 2.3033547401428223 grad: 1.2280078993201078\n",
      "epoch: 105 loss: 2.3029236793518066 grad: 1.2426413044958036\n",
      "epoch: 106 loss: 2.302954912185669 grad: 1.2349459638131695\n",
      "epoch: 107 loss: 2.3025763034820557 grad: 1.2497270652074515\n",
      "epoch: 108 loss: 2.3031153678894043 grad: 1.2405460978606864\n",
      "epoch: 109 loss: 2.3019778728485107 grad: 1.2442866045194456\n",
      "epoch: 110 loss: 2.302661895751953 grad: 1.229582668747753\n",
      "epoch: 111 loss: 2.302493095397949 grad: 1.254012656405509\n",
      "epoch: 112 loss: 2.3030033111572266 grad: 1.2363208598486843\n",
      "epoch: 113 loss: 2.3023862838745117 grad: 1.2431961541463221\n",
      "epoch: 114 loss: 2.302778959274292 grad: 1.2374764202266104\n",
      "epoch: 115 loss: 2.3022048473358154 grad: 1.2505449832154674\n",
      "epoch: 116 loss: 2.3025834560394287 grad: 1.2448204621628283\n",
      "epoch: 117 loss: 2.3030683994293213 grad: 1.2430233897508256\n",
      "epoch: 118 loss: 2.3027682304382324 grad: 1.2473806565376147\n",
      "epoch: 119 loss: 2.3027825355529785 grad: 1.251165148194155\n",
      "epoch: 120 loss: 2.302057981491089 grad: 1.2535622840292664\n",
      "epoch: 121 loss: 2.3020970821380615 grad: 1.2478107972650803\n",
      "epoch: 122 loss: 2.3024280071258545 grad: 1.2452706561279705\n",
      "epoch: 123 loss: 2.3027942180633545 grad: 1.241414230682754\n",
      "epoch: 124 loss: 2.3025078773498535 grad: 1.2460036497370945\n",
      "epoch: 125 loss: 2.3022711277008057 grad: 1.2460213097935868\n",
      "epoch: 126 loss: 2.30222225189209 grad: 1.2520125377627591\n",
      "epoch: 127 loss: 2.302051305770874 grad: 1.2507066605889814\n",
      "epoch: 128 loss: 2.3033642768859863 grad: 1.2330486710545503\n",
      "epoch: 129 loss: 2.3025083541870117 grad: 1.2407648557028363\n",
      "epoch: 130 loss: 2.3029651641845703 grad: 1.2430848902634655\n",
      "epoch: 131 loss: 2.3019793033599854 grad: 1.2451208622457224\n",
      "epoch: 132 loss: 2.303048849105835 grad: 1.2387268888904521\n",
      "epoch: 133 loss: 2.3028340339660645 grad: 1.2376924103647027\n",
      "epoch: 134 loss: 2.3031342029571533 grad: 1.2280908866382634\n",
      "epoch: 135 loss: 2.302353858947754 grad: 1.2417479356314751\n",
      "epoch: 136 loss: 2.302480697631836 grad: 1.2305812466028516\n",
      "epoch: 137 loss: 2.3026816844940186 grad: 1.2461679049061671\n",
      "epoch: 138 loss: 2.303330421447754 grad: 1.2317468361977104\n",
      "epoch: 139 loss: 2.3028666973114014 grad: 1.2451288782573853\n",
      "epoch: 140 loss: 2.302537202835083 grad: 1.2391839697088545\n",
      "epoch: 141 loss: 2.30240797996521 grad: 1.2378082084451019\n",
      "epoch: 142 loss: 2.302762269973755 grad: 1.232510701206232\n",
      "epoch: 143 loss: 2.3031883239746094 grad: 1.2441738303990975\n",
      "epoch: 144 loss: 2.3035688400268555 grad: 1.226261877109267\n",
      "epoch: 145 loss: 2.3028576374053955 grad: 1.2312138819630953\n",
      "epoch: 146 loss: 2.3030738830566406 grad: 1.237871315692448\n",
      "epoch: 147 loss: 2.302433967590332 grad: 1.2480272348796475\n",
      "epoch: 148 loss: 2.3025190830230713 grad: 1.237871206001497\n",
      "epoch: 149 loss: 2.3028757572174072 grad: 1.2415109771739927\n",
      "epoch: 150 loss: 2.302572011947632 grad: 1.2351838158802055\n",
      "epoch: 151 loss: 2.3027851581573486 grad: 1.2388364390325954\n",
      "epoch: 152 loss: 2.3031530380249023 grad: 1.2406361048453531\n",
      "epoch: 153 loss: 2.302588701248169 grad: 1.236645138901954\n",
      "epoch: 154 loss: 2.3029801845550537 grad: 1.220925206891335\n",
      "epoch: 155 loss: 2.3027822971343994 grad: 1.2399454836526678\n",
      "epoch: 156 loss: 2.302612781524658 grad: 1.2420272830123495\n",
      "epoch: 157 loss: 2.302154302597046 grad: 1.2476371138445324\n",
      "epoch: 158 loss: 2.302279472351074 grad: 1.2480440872558762\n",
      "epoch: 159 loss: 2.302889585494995 grad: 1.2426349661619742\n",
      "epoch: 160 loss: 2.302769184112549 grad: 1.2308829194600028\n",
      "epoch: 161 loss: 2.3026163578033447 grad: 1.2346674731326481\n",
      "epoch: 162 loss: 2.302931070327759 grad: 1.239600542485566\n",
      "epoch: 163 loss: 2.302412986755371 grad: 1.2457465567895847\n",
      "epoch: 164 loss: 2.302745819091797 grad: 1.232890719773307\n",
      "epoch: 165 loss: 2.3024232387542725 grad: 1.2464782371692034\n",
      "epoch: 166 loss: 2.3022873401641846 grad: 1.253905896642541\n",
      "epoch: 167 loss: 2.3027234077453613 grad: 1.245123871132761\n",
      "epoch: 168 loss: 2.302201271057129 grad: 1.246986675835658\n",
      "epoch: 169 loss: 2.3025519847869873 grad: 1.2389929036587655\n",
      "epoch: 170 loss: 2.302685499191284 grad: 1.2413363296849032\n",
      "epoch: 171 loss: 2.302325487136841 grad: 1.2342536998561597\n",
      "epoch: 172 loss: 2.3022124767303467 grad: 1.2498645149467011\n",
      "epoch: 173 loss: 2.3023087978363037 grad: 1.235050539957315\n",
      "epoch: 174 loss: 2.3027515411376953 grad: 1.2274387753235974\n",
      "epoch: 175 loss: 2.3021862506866455 grad: 1.245434744161598\n",
      "epoch: 176 loss: 2.302340269088745 grad: 1.2454561364951557\n",
      "epoch: 177 loss: 2.3028523921966553 grad: 1.2412814234849066\n",
      "epoch: 178 loss: 2.3029353618621826 grad: 1.2371906485234845\n",
      "epoch: 179 loss: 2.3036439418792725 grad: 1.2326341578829294\n",
      "epoch: 180 loss: 2.3026299476623535 grad: 1.234339662711136\n",
      "epoch: 181 loss: 2.3026649951934814 grad: 1.2472183373923014\n",
      "epoch: 182 loss: 2.3032302856445312 grad: 1.2349967400539696\n",
      "epoch: 183 loss: 2.3030354976654053 grad: 1.2379768107618605\n",
      "epoch: 184 loss: 2.302583694458008 grad: 1.2390958630657267\n",
      "epoch: 185 loss: 2.302340269088745 grad: 1.2411660834101015\n",
      "epoch: 186 loss: 2.3025524616241455 grad: 1.243762670474733\n",
      "epoch: 187 loss: 2.303415060043335 grad: 1.2141515949800137\n",
      "epoch: 188 loss: 2.3016092777252197 grad: 1.2489200046485556\n",
      "epoch: 189 loss: 2.3030271530151367 grad: 1.2280826211079128\n",
      "epoch: 190 loss: 2.302544116973877 grad: 1.2449226820294463\n",
      "epoch: 191 loss: 2.3032736778259277 grad: 1.2311163008645443\n",
      "epoch: 192 loss: 2.302368640899658 grad: 1.246049972648348\n",
      "epoch: 193 loss: 2.302730083465576 grad: 1.2339065897755237\n",
      "epoch: 194 loss: 2.3029749393463135 grad: 1.2297600132195161\n",
      "epoch: 195 loss: 2.3028767108917236 grad: 1.2286430893665445\n",
      "epoch: 196 loss: 2.3024919033050537 grad: 1.2414867200367596\n",
      "epoch: 197 loss: 2.303386926651001 grad: 1.2268331165236996\n",
      "epoch: 198 loss: 2.302509307861328 grad: 1.2387196950647714\n",
      "epoch: 199 loss: 2.3022122383117676 grad: 1.2426213215083062\n",
      "epoch: 200 loss: 2.303133010864258 grad: 1.2353864472455507\n",
      "epoch: 201 loss: 2.303342580795288 grad: 1.229421339914321\n",
      "epoch: 202 loss: 2.3022806644439697 grad: 1.2375826494110422\n",
      "epoch: 203 loss: 2.3034117221832275 grad: 1.2253974242235668\n",
      "epoch: 204 loss: 2.30281400680542 grad: 1.2376779276796335\n",
      "epoch: 205 loss: 2.3020029067993164 grad: 1.2473693238257149\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 206 loss: 2.3023295402526855 grad: 1.2379293166810559\n",
      "epoch: 207 loss: 2.3021748065948486 grad: 1.253136599789344\n",
      "epoch: 208 loss: 2.302680730819702 grad: 1.233307623986288\n",
      "epoch: 209 loss: 2.3025245666503906 grad: 1.2363148195861233\n",
      "epoch: 210 loss: 2.3025104999542236 grad: 1.2349653372001494\n",
      "epoch: 211 loss: 2.3024110794067383 grad: 1.2338025608221956\n",
      "epoch: 212 loss: 2.3026604652404785 grad: 1.2336876438764324\n",
      "epoch: 213 loss: 2.302683115005493 grad: 1.2414263527496674\n",
      "epoch: 214 loss: 2.3032476902008057 grad: 1.2319021161760217\n",
      "epoch: 215 loss: 2.302755117416382 grad: 1.2329825885383234\n",
      "epoch: 216 loss: 2.303218364715576 grad: 1.2182353182644066\n",
      "epoch: 217 loss: 2.302603006362915 grad: 1.2327669151958875\n",
      "epoch: 218 loss: 2.303220510482788 grad: 1.230847717780206\n",
      "epoch: 219 loss: 2.30220890045166 grad: 1.2516728117581575\n",
      "epoch: 220 loss: 2.3028786182403564 grad: 1.2330266390224949\n",
      "epoch: 221 loss: 2.302440643310547 grad: 1.2421243460257612\n",
      "epoch: 222 loss: 2.3031649589538574 grad: 1.2384033548083926\n",
      "epoch: 223 loss: 2.3027994632720947 grad: 1.2248922516850547\n",
      "epoch: 224 loss: 2.3024675846099854 grad: 1.24744938614793\n",
      "epoch: 225 loss: 2.302238702774048 grad: 1.2440353029422344\n",
      "epoch: 226 loss: 2.3035266399383545 grad: 1.2240879617295124\n",
      "epoch: 227 loss: 2.30283522605896 grad: 1.2342891028309833\n",
      "epoch: 228 loss: 2.3031485080718994 grad: 1.2175397742299423\n",
      "epoch: 229 loss: 2.3027379512786865 grad: 1.2246938501651\n",
      "epoch: 230 loss: 2.302072286605835 grad: 1.2485097190993468\n",
      "epoch: 231 loss: 2.303133726119995 grad: 1.2312454101629555\n",
      "epoch: 232 loss: 2.302886486053467 grad: 1.227486083596309\n",
      "epoch: 233 loss: 2.302553415298462 grad: 1.2434413770975044\n",
      "epoch: 234 loss: 2.3024137020111084 grad: 1.233738410358672\n",
      "epoch: 235 loss: 2.3023998737335205 grad: 1.2416036149656902\n",
      "epoch: 236 loss: 2.3024990558624268 grad: 1.2383075032682558\n",
      "epoch: 237 loss: 2.3032193183898926 grad: 1.2254156386867787\n",
      "epoch: 238 loss: 2.3027586936950684 grad: 1.2399292747796853\n",
      "epoch: 239 loss: 2.302870512008667 grad: 1.2377505572919276\n",
      "epoch: 240 loss: 2.302879571914673 grad: 1.234798815666831\n",
      "epoch: 241 loss: 2.3028783798217773 grad: 1.2319718831170734\n",
      "epoch: 242 loss: 2.3020403385162354 grad: 1.2402169796793412\n",
      "epoch: 243 loss: 2.3028805255889893 grad: 1.2285676335283955\n",
      "epoch: 244 loss: 2.302429676055908 grad: 1.2365841526105734\n",
      "epoch: 245 loss: 2.3024768829345703 grad: 1.2422658464509166\n",
      "epoch: 246 loss: 2.302819013595581 grad: 1.2347983362186434\n",
      "epoch: 247 loss: 2.3020880222320557 grad: 1.2424355071363231\n",
      "epoch: 248 loss: 2.3026070594787598 grad: 1.2370775188023726\n",
      "epoch: 249 loss: 2.3026440143585205 grad: 1.2355460157665972\n",
      "epoch: 250 loss: 2.3030638694763184 grad: 1.2456847379161489\n",
      "epoch: 251 loss: 2.3031206130981445 grad: 1.226789387434514\n",
      "epoch: 252 loss: 2.3025877475738525 grad: 1.2269459579856918\n",
      "epoch: 253 loss: 2.302494525909424 grad: 1.2483657231842655\n",
      "epoch: 254 loss: 2.302295207977295 grad: 1.2369373685879899\n",
      "epoch: 255 loss: 2.3021111488342285 grad: 1.2407046599250788\n",
      "epoch: 256 loss: 2.302838087081909 grad: 1.230301895949413\n",
      "epoch: 257 loss: 2.3029892444610596 grad: 1.2352068037689028\n",
      "epoch: 258 loss: 2.302299976348877 grad: 1.250179590529851\n",
      "epoch: 259 loss: 2.3029260635375977 grad: 1.2318322023909007\n",
      "epoch: 260 loss: 2.3020544052124023 grad: 1.2411045414369761\n",
      "epoch: 261 loss: 2.3035778999328613 grad: 1.2131474729745635\n",
      "epoch: 262 loss: 2.302995204925537 grad: 1.2296430605245636\n",
      "epoch: 263 loss: 2.3023459911346436 grad: 1.2382920018437924\n",
      "epoch: 264 loss: 2.302288770675659 grad: 1.2430945161179388\n",
      "epoch: 265 loss: 2.3028852939605713 grad: 1.2265801896148967\n",
      "epoch: 266 loss: 2.302739381790161 grad: 1.2291453798294127\n",
      "epoch: 267 loss: 2.3027639389038086 grad: 1.2278074902918426\n",
      "epoch: 268 loss: 2.3021957874298096 grad: 1.2353624849236526\n",
      "epoch: 269 loss: 2.302555561065674 grad: 1.2239727697331488\n",
      "epoch: 270 loss: 2.3022828102111816 grad: 1.2458335271508003\n",
      "epoch: 271 loss: 2.3024275302886963 grad: 1.2347047072964616\n",
      "epoch: 272 loss: 2.302706718444824 grad: 1.2297966496793493\n",
      "epoch: 273 loss: 2.302643060684204 grad: 1.2333212622500482\n",
      "epoch: 274 loss: 2.302887439727783 grad: 1.2369086684914128\n",
      "epoch: 275 loss: 2.302800416946411 grad: 1.2215452945055736\n",
      "epoch: 276 loss: 2.302574872970581 grad: 1.2345516996343606\n",
      "epoch: 277 loss: 2.302624225616455 grad: 1.2377289507430904\n",
      "epoch: 278 loss: 2.3021109104156494 grad: 1.23343644066832\n",
      "epoch: 279 loss: 2.303981304168701 grad: 1.2179385576626316\n",
      "epoch: 280 loss: 2.30226731300354 grad: 1.2461136484866044\n",
      "epoch: 281 loss: 2.3030412197113037 grad: 1.2320488168458854\n",
      "epoch: 282 loss: 2.302351713180542 grad: 1.2407359887498417\n",
      "epoch: 283 loss: 2.3028321266174316 grad: 1.2279936574872523\n",
      "epoch: 284 loss: 2.302393913269043 grad: 1.2311336301906508\n",
      "epoch: 285 loss: 2.3029911518096924 grad: 1.2351916630563902\n",
      "epoch: 286 loss: 2.3024280071258545 grad: 1.228000659617551\n",
      "epoch: 287 loss: 2.302570104598999 grad: 1.2421659881374725\n",
      "epoch: 288 loss: 2.302372694015503 grad: 1.236389009481562\n",
      "epoch: 289 loss: 2.302748680114746 grad: 1.231134439794539\n",
      "epoch: 290 loss: 2.302382230758667 grad: 1.2393832117622157\n",
      "epoch: 291 loss: 2.3019533157348633 grad: 1.2292229210558747\n",
      "epoch: 292 loss: 2.3024070262908936 grad: 1.2320510792353796\n",
      "epoch: 293 loss: 2.3027825355529785 grad: 1.2379882550181172\n",
      "epoch: 294 loss: 2.3027660846710205 grad: 1.2385633103937532\n",
      "epoch: 295 loss: 2.3026888370513916 grad: 1.229933441089954\n",
      "epoch: 296 loss: 2.3021199703216553 grad: 1.2452965075859712\n",
      "epoch: 297 loss: 2.3024537563323975 grad: 1.2228947562860355\n",
      "epoch: 298 loss: 2.3031277656555176 grad: 1.2297179516430736\n",
      "epoch: 299 loss: 2.30340838432312 grad: 1.2266516814947068\n",
      "epoch: 300 loss: 2.3025388717651367 grad: 1.241956417042289\n",
      "epoch: 301 loss: 2.302699327468872 grad: 1.2305352115386448\n",
      "epoch: 302 loss: 2.302273750305176 grad: 1.2315398691488164\n",
      "epoch: 303 loss: 2.3032710552215576 grad: 1.2309694173782768\n",
      "epoch: 304 loss: 2.30251145362854 grad: 1.2400669511074998\n",
      "epoch: 305 loss: 2.302295207977295 grad: 1.2347625820686863\n",
      "epoch: 306 loss: 2.3016562461853027 grad: 1.2578023085481531\n",
      "epoch: 307 loss: 2.3024563789367676 grad: 1.2320348209487126\n",
      "epoch: 308 loss: 2.302943706512451 grad: 1.227690439456926\n",
      "epoch: 309 loss: 2.3027524948120117 grad: 1.228456133462873\n",
      "epoch: 310 loss: 2.302910089492798 grad: 1.2289562944936314\n",
      "epoch: 311 loss: 2.3027710914611816 grad: 1.230816540585476\n",
      "epoch: 312 loss: 2.302363872528076 grad: 1.2342371439306243\n",
      "epoch: 313 loss: 2.302001953125 grad: 1.2373900857037081\n",
      "epoch: 314 loss: 2.303537368774414 grad: 1.2169208582693947\n",
      "epoch: 315 loss: 2.3019824028015137 grad: 1.2362028170757675\n",
      "epoch: 316 loss: 2.301670789718628 grad: 1.2400971480630456\n",
      "epoch: 317 loss: 2.3026068210601807 grad: 1.2377635732492698\n",
      "epoch: 318 loss: 2.3029375076293945 grad: 1.2239477868295379\n",
      "epoch: 319 loss: 2.3023409843444824 grad: 1.2276758841933713\n",
      "epoch: 320 loss: 2.302302122116089 grad: 1.2334937293984232\n",
      "epoch: 321 loss: 2.3024611473083496 grad: 1.2396296937284725\n",
      "epoch: 322 loss: 2.3019802570343018 grad: 1.2390675485791964\n",
      "epoch: 323 loss: 2.3029532432556152 grad: 1.22893401050371\n",
      "epoch: 324 loss: 2.3021891117095947 grad: 1.240637573385833\n",
      "epoch: 325 loss: 2.3028745651245117 grad: 1.2225601380683542\n",
      "epoch: 326 loss: 2.3020246028900146 grad: 1.249009334369533\n",
      "epoch: 327 loss: 2.303101062774658 grad: 1.2270882308375948\n",
      "epoch: 328 loss: 2.3027496337890625 grad: 1.229088219754871\n",
      "epoch: 329 loss: 2.3030409812927246 grad: 1.226613145356717\n",
      "epoch: 330 loss: 2.3027992248535156 grad: 1.2357999293248183\n",
      "epoch: 331 loss: 2.3025453090667725 grad: 1.237527496077948\n",
      "epoch: 332 loss: 2.3025553226470947 grad: 1.2378393381941206\n",
      "epoch: 333 loss: 2.302151918411255 grad: 1.2452542562580977\n",
      "epoch: 334 loss: 2.3027753829956055 grad: 1.2307482330305946\n",
      "epoch: 335 loss: 2.3025479316711426 grad: 1.2361649210723709\n",
      "epoch: 336 loss: 2.3021748065948486 grad: 1.2321745096613461\n",
      "epoch: 337 loss: 2.302619218826294 grad: 1.2198736850331198\n",
      "epoch: 338 loss: 2.3024964332580566 grad: 1.235279028211528\n",
      "epoch: 339 loss: 2.302353620529175 grad: 1.2314193609765627\n",
      "epoch: 340 loss: 2.3029489517211914 grad: 1.2359418219384102\n",
      "epoch: 341 loss: 2.3020663261413574 grad: 1.2398792775661966\n",
      "epoch: 342 loss: 2.302928924560547 grad: 1.2247698893992318\n",
      "epoch: 343 loss: 2.3027405738830566 grad: 1.227026338182715\n",
      "epoch: 344 loss: 2.302577018737793 grad: 1.2301386150232116\n",
      "epoch: 345 loss: 2.3026468753814697 grad: 1.2383521619153075\n",
      "epoch: 346 loss: 2.302020311355591 grad: 1.247550280162296\n",
      "epoch: 347 loss: 2.302978277206421 grad: 1.2183175255075127\n",
      "epoch: 348 loss: 2.3026270866394043 grad: 1.2391757019795477\n",
      "epoch: 349 loss: 2.302551031112671 grad: 1.2381242193902533\n",
      "epoch: 350 loss: 2.3016414642333984 grad: 1.2420709614793488\n",
      "epoch: 351 loss: 2.302614450454712 grad: 1.2352237800017944\n",
      "epoch: 352 loss: 2.302534818649292 grad: 1.2376004946935508\n",
      "epoch: 353 loss: 2.302057981491089 grad: 1.2434592421798567\n",
      "epoch: 354 loss: 2.3027870655059814 grad: 1.2334371355643112\n",
      "epoch: 355 loss: 2.3032498359680176 grad: 1.2244826383825893\n",
      "epoch: 356 loss: 2.30295729637146 grad: 1.2214939542122125\n",
      "epoch: 357 loss: 2.302441120147705 grad: 1.227201861419922\n",
      "epoch: 358 loss: 2.302086591720581 grad: 1.23297924901514\n",
      "epoch: 359 loss: 2.3025429248809814 grad: 1.2267960588676885\n",
      "epoch: 360 loss: 2.302140951156616 grad: 1.2480002042748743\n",
      "epoch: 361 loss: 2.301682472229004 grad: 1.2376798503895452\n",
      "epoch: 362 loss: 2.3024392127990723 grad: 1.2286776130767687\n",
      "epoch: 363 loss: 2.3029325008392334 grad: 1.2214168274797321\n",
      "epoch: 364 loss: 2.3029088973999023 grad: 1.2336961757022118\n",
      "epoch: 365 loss: 2.302583932876587 grad: 1.2299912054930622\n",
      "epoch: 366 loss: 2.3024933338165283 grad: 1.2394818267895884\n",
      "epoch: 367 loss: 2.3030240535736084 grad: 1.227997877847566\n",
      "epoch: 368 loss: 2.3020553588867188 grad: 1.2440912775706412\n",
      "epoch: 369 loss: 2.3022572994232178 grad: 1.243021565971763\n",
      "epoch: 370 loss: 2.302457332611084 grad: 1.2246015271733677\n",
      "epoch: 371 loss: 2.3027243614196777 grad: 1.2279644475174358\n",
      "epoch: 372 loss: 2.3024725914001465 grad: 1.2310942871078465\n",
      "epoch: 373 loss: 2.3029022216796875 grad: 1.2307425628966904\n",
      "epoch: 374 loss: 2.302781343460083 grad: 1.2234287651104203\n",
      "epoch: 375 loss: 2.3028249740600586 grad: 1.2362499406417122\n",
      "epoch: 376 loss: 2.3023858070373535 grad: 1.239895859531807\n",
      "epoch: 377 loss: 2.3026483058929443 grad: 1.224424865531055\n",
      "epoch: 378 loss: 2.3027400970458984 grad: 1.2308328304003688\n",
      "epoch: 379 loss: 2.302004098892212 grad: 1.2550249349137412\n",
      "epoch: 380 loss: 2.302921772003174 grad: 1.2416133225566546\n",
      "epoch: 381 loss: 2.3028576374053955 grad: 1.2304667036939738\n",
      "epoch: 382 loss: 2.3022348880767822 grad: 1.2472887540269377\n",
      "epoch: 383 loss: 2.302929639816284 grad: 1.2347311246678203\n",
      "epoch: 384 loss: 2.302349805831909 grad: 1.2336345278872325\n",
      "epoch: 385 loss: 2.3022425174713135 grad: 1.237444778593878\n",
      "epoch: 386 loss: 2.3025693893432617 grad: 1.2275068228084978\n",
      "epoch: 387 loss: 2.303210735321045 grad: 1.2274241351378372\n",
      "epoch: 388 loss: 2.302152395248413 grad: 1.2308544532288723\n",
      "epoch: 389 loss: 2.302577257156372 grad: 1.2312442602567553\n",
      "epoch: 390 loss: 2.302111864089966 grad: 1.2277826109405843\n",
      "epoch: 391 loss: 2.3023746013641357 grad: 1.2340827619024952\n",
      "epoch: 392 loss: 2.302283763885498 grad: 1.2348276320974239\n",
      "epoch: 393 loss: 2.3019654750823975 grad: 1.2408483836334199\n",
      "epoch: 394 loss: 2.3018786907196045 grad: 1.2433099011310362\n",
      "epoch: 395 loss: 2.302312135696411 grad: 1.225826826451036\n",
      "epoch: 396 loss: 2.3027091026306152 grad: 1.2311437946119685\n",
      "epoch: 397 loss: 2.302666425704956 grad: 1.2378416987494492\n",
      "epoch: 398 loss: 2.3020823001861572 grad: 1.2441587137974917\n",
      "epoch: 399 loss: 2.3031067848205566 grad: 1.2276941882076835\n",
      "epoch: 400 loss: 2.302272319793701 grad: 1.2378015837037109\n",
      "epoch: 401 loss: 2.3024401664733887 grad: 1.2337682557473373\n",
      "epoch: 402 loss: 2.3023691177368164 grad: 1.235418126495215\n",
      "epoch: 403 loss: 2.302619218826294 grad: 1.230327027905289\n",
      "epoch: 404 loss: 2.3027570247650146 grad: 1.2277004143504042\n",
      "epoch: 405 loss: 2.3027334213256836 grad: 1.2335620892108492\n",
      "epoch: 406 loss: 2.302391290664673 grad: 1.237313318576309\n",
      "epoch: 407 loss: 2.302168369293213 grad: 1.2375298079236277\n",
      "epoch: 408 loss: 2.302600622177124 grad: 1.2291003574325245\n",
      "epoch: 409 loss: 2.3026037216186523 grad: 1.2387329204329511\n",
      "epoch: 410 loss: 2.302562952041626 grad: 1.241505090117691\n",
      "epoch: 411 loss: 2.302492141723633 grad: 1.228463742096672\n",
      "epoch: 412 loss: 2.3018851280212402 grad: 1.2369987541266407\n",
      "epoch: 413 loss: 2.3028616905212402 grad: 1.2217840487950495\n",
      "epoch: 414 loss: 2.302142858505249 grad: 1.2425953391810052\n",
      "epoch: 415 loss: 2.303011178970337 grad: 1.2340955619630034\n",
      "epoch: 416 loss: 2.3028481006622314 grad: 1.2323355108299958\n",
      "epoch: 417 loss: 2.3022539615631104 grad: 1.246463287466516\n",
      "epoch: 418 loss: 2.302579402923584 grad: 1.2322908034289464\n",
      "epoch: 419 loss: 2.302129030227661 grad: 1.229154533579103\n",
      "epoch: 420 loss: 2.3021085262298584 grad: 1.232668544958523\n",
      "epoch: 421 loss: 2.302462339401245 grad: 1.2334492576201372\n",
      "epoch: 422 loss: 2.302330493927002 grad: 1.227915519781943\n",
      "epoch: 423 loss: 2.302647829055786 grad: 1.2403765163395466\n",
      "epoch: 424 loss: 2.301941394805908 grad: 1.2378464089891326\n",
      "epoch: 425 loss: 2.3025128841400146 grad: 1.2347230176600288\n",
      "epoch: 426 loss: 2.3020458221435547 grad: 1.2304000633210683\n",
      "epoch: 427 loss: 2.302327871322632 grad: 1.22934436952577\n",
      "epoch: 428 loss: 2.302767038345337 grad: 1.2390882356336252\n",
      "epoch: 429 loss: 2.3023529052734375 grad: 1.2289595458386762\n",
      "epoch: 430 loss: 2.3027291297912598 grad: 1.2338715342209778\n",
      "epoch: 431 loss: 2.302659273147583 grad: 1.2300751882102636\n",
      "epoch: 432 loss: 2.302233934402466 grad: 1.250264992192757\n",
      "epoch: 433 loss: 2.302180051803589 grad: 1.2375659522570905\n",
      "epoch: 434 loss: 2.302682876586914 grad: 1.2296273502306865\n",
      "epoch: 435 loss: 2.3024275302886963 grad: 1.234469436432442\n",
      "epoch: 436 loss: 2.3029301166534424 grad: 1.232878283880252\n",
      "epoch: 437 loss: 2.303238868713379 grad: 1.2210527275733294\n",
      "epoch: 438 loss: 2.3026645183563232 grad: 1.2260259635883222\n",
      "epoch: 439 loss: 2.30220890045166 grad: 1.2347606253488699\n",
      "epoch: 440 loss: 2.3018362522125244 grad: 1.2436600895284393\n",
      "epoch: 441 loss: 2.3026723861694336 grad: 1.2240761354499097\n",
      "epoch: 442 loss: 2.3026719093322754 grad: 1.2375821281069268\n",
      "epoch: 443 loss: 2.302746057510376 grad: 1.2313767855225632\n",
      "epoch: 444 loss: 2.3031864166259766 grad: 1.2350881642528944\n",
      "epoch: 445 loss: 2.3021111488342285 grad: 1.240883531932172\n",
      "epoch: 446 loss: 2.3016092777252197 grad: 1.2364923943366324\n",
      "epoch: 447 loss: 2.302473783493042 grad: 1.2267197594767258\n",
      "epoch: 448 loss: 2.302251100540161 grad: 1.2380565821418599\n",
      "epoch: 449 loss: 2.3029415607452393 grad: 1.2279084596324652\n",
      "epoch: 450 loss: 2.3019161224365234 grad: 1.2518422543995142\n",
      "epoch: 451 loss: 2.303138494491577 grad: 1.2227365133123442\n",
      "epoch: 452 loss: 2.3030295372009277 grad: 1.2300397443163784\n",
      "epoch: 453 loss: 2.3027665615081787 grad: 1.222511778557895\n",
      "epoch: 454 loss: 2.302771806716919 grad: 1.2376612780065024\n",
      "epoch: 455 loss: 2.3028125762939453 grad: 1.2225650319559795\n",
      "epoch: 456 loss: 2.3021316528320312 grad: 1.2349870762037527\n",
      "epoch: 457 loss: 2.30228328704834 grad: 1.2375835889806261\n",
      "epoch: 458 loss: 2.3027334213256836 grad: 1.230430047251358\n",
      "epoch: 459 loss: 2.303114891052246 grad: 1.2247596395752645\n",
      "epoch: 460 loss: 2.302802085876465 grad: 1.224293132004003\n",
      "epoch: 461 loss: 2.302882432937622 grad: 1.2269033729412875\n",
      "epoch: 462 loss: 2.302314281463623 grad: 1.2422716830328608\n",
      "epoch: 463 loss: 2.302786111831665 grad: 1.234386741386963\n",
      "epoch: 464 loss: 2.3026883602142334 grad: 1.2294925064687425\n",
      "epoch: 465 loss: 2.301894187927246 grad: 1.2374699172926031\n",
      "epoch: 466 loss: 2.302884817123413 grad: 1.226301298404689\n",
      "epoch: 467 loss: 2.3024961948394775 grad: 1.2290854891429521\n",
      "epoch: 468 loss: 2.302701234817505 grad: 1.2297628912538852\n",
      "epoch: 469 loss: 2.30265212059021 grad: 1.2202072148451522\n",
      "epoch: 470 loss: 2.3031508922576904 grad: 1.2271390764138823\n",
      "epoch: 471 loss: 2.3028018474578857 grad: 1.2320353650997968\n",
      "epoch: 472 loss: 2.303372383117676 grad: 1.225351985320375\n",
      "epoch: 473 loss: 2.3026695251464844 grad: 1.235893615273877\n",
      "epoch: 474 loss: 2.3019959926605225 grad: 1.2364769529344306\n",
      "epoch: 475 loss: 2.3024933338165283 grad: 1.2403078196581365\n",
      "epoch: 476 loss: 2.3022944927215576 grad: 1.2338992014956025\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 477 loss: 2.302215099334717 grad: 1.2410017717980766\n",
      "epoch: 478 loss: 2.3017852306365967 grad: 1.2509816501452218\n",
      "epoch: 479 loss: 2.3027939796447754 grad: 1.2357124514168216\n",
      "epoch: 480 loss: 2.3023276329040527 grad: 1.2415017563653814\n",
      "epoch: 481 loss: 2.3021161556243896 grad: 1.2328233721477555\n",
      "epoch: 482 loss: 2.3027307987213135 grad: 1.2322033696700745\n",
      "epoch: 483 loss: 2.3025336265563965 grad: 1.2409198098660756\n",
      "epoch: 484 loss: 2.302582263946533 grad: 1.2395668501987875\n",
      "epoch: 485 loss: 2.302288770675659 grad: 1.2477720018572336\n",
      "epoch: 486 loss: 2.30246639251709 grad: 1.2399934539534447\n",
      "epoch: 487 loss: 2.3028197288513184 grad: 1.2255108639069403\n",
      "epoch: 488 loss: 2.3025875091552734 grad: 1.2234087960410214\n",
      "epoch: 489 loss: 2.3024277687072754 grad: 1.2310998871745098\n",
      "epoch: 490 loss: 2.302133798599243 grad: 1.2309134828798947\n",
      "epoch: 491 loss: 2.302898645401001 grad: 1.2212921634874498\n",
      "epoch: 492 loss: 2.3022677898406982 grad: 1.239790793818732\n",
      "epoch: 493 loss: 2.302297353744507 grad: 1.2401014751170776\n",
      "epoch: 494 loss: 2.3026750087738037 grad: 1.2468480869983545\n",
      "epoch: 495 loss: 2.3024301528930664 grad: 1.2289977885416843\n",
      "epoch: 496 loss: 2.3019392490386963 grad: 1.2417694309168303\n",
      "epoch: 497 loss: 2.3022961616516113 grad: 1.2312277943073284\n",
      "epoch: 498 loss: 2.302210807800293 grad: 1.2290759159340745\n",
      "epoch: 499 loss: 2.3024861812591553 grad: 1.2362661933884882\n",
      "2.302417367696762\n",
      "optimal dropout 0.2\n",
      "optimal lambda 0.005\n",
      "optimal optimiser adam\n"
     ]
    }
   ],
   "source": [
    "##hyperparameter tuning\n",
    "la=0\n",
    "optim=''\n",
    "op=0\n",
    "lams = [0.005,0.001,0.0005,0.0001]\n",
    "optis = ['adagrad','adam','sgd']\n",
    "dp=[0.2,0.3,0.35,0.5]\n",
    "valoss=999\n",
    "for d in dp:\n",
    "    for l in lams:\n",
    "            for opt in optis:\n",
    "                modelcnn = cnnModel(13,3,d)\n",
    "                modelcnn.to(device)\n",
    "                modelcnn.train(traindl,epochs = 500, learning_rate=0.001,lam=l,opti=opt)\n",
    "                if valoss>test(modelcnn,valdl):\n",
    "                    valoss=test(modelcnn,valdl)\n",
    "                    print(valoss)\n",
    "                    la=l\n",
    "                    optim=opt\n",
    "                    op=d\n",
    "print(\"optimal dropout\",op)\n",
    "print(\"optimal lambda\",la)\n",
    "print(\"optimal optimiser\",optim)                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "id": "961a0b56",
   "metadata": {},
   "outputs": [],
   "source": [
    "la=0.005\n",
    "optim='adam'\n",
    "op=0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "08160bc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelcnn = cnnModel(13,3,op)\n",
    "modelcnn.to(device)\n",
    "loss=[]\n",
    "par=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "df00350f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of parameters: 170260\n"
     ]
    }
   ],
   "source": [
    "total_params = sum(p.numel() for p in modelcnn.parameters())\n",
    "print(\"Total number of parameters:\", total_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "9e155275",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0 loss: 1.4630231857299805 grad: 0.502038326556126\n",
      "epoch: 1 loss: 1.4632890224456787 grad: 0.22360453560389087\n",
      "epoch: 2 loss: 1.4636740684509277 grad: 0.40702705963469055\n",
      "epoch: 3 loss: 1.464397668838501 grad: 0.384072086635436\n",
      "epoch: 4 loss: 1.4642592668533325 grad: 0.12913767540332904\n",
      "epoch: 5 loss: 1.4646772146224976 grad: 1.0762555996600875\n",
      "epoch: 6 loss: 1.463280439376831 grad: 0.29592350097661263\n",
      "epoch: 7 loss: 1.4647034406661987 grad: 0.17085335864846196\n",
      "epoch: 8 loss: 1.4638891220092773 grad: 0.4956495807687248\n",
      "epoch: 9 loss: 1.4638532400131226 grad: 0.4333299077753655\n",
      "epoch: 10 loss: 1.4634393453598022 grad: 0.23015000902999144\n",
      "epoch: 11 loss: 1.4633647203445435 grad: 0.2825540389556081\n",
      "epoch: 12 loss: 1.4650592803955078 grad: 1.175547098857184\n",
      "epoch: 13 loss: 1.4633338451385498 grad: 0.5007435747690875\n",
      "epoch: 14 loss: 1.4654985666275024 grad: 0.5328450944421312\n",
      "epoch: 15 loss: 1.4658262729644775 grad: 0.5122038749383172\n",
      "epoch: 16 loss: 1.4639467000961304 grad: 0.374910143650969\n",
      "epoch: 17 loss: 1.4642586708068848 grad: 1.4088855373674654\n",
      "epoch: 18 loss: 1.4634889364242554 grad: 0.21989312615524112\n",
      "epoch: 19 loss: 1.4631456136703491 grad: 0.40364514723087114\n",
      "epoch: 20 loss: 1.4618544578552246 grad: 0.315256552868561\n",
      "epoch: 21 loss: 1.4640387296676636 grad: 0.4714470624137473\n",
      "epoch: 22 loss: 1.4624006748199463 grad: 0.5499827436431236\n",
      "epoch: 23 loss: 1.4625182151794434 grad: 0.40953215374938784\n",
      "epoch: 24 loss: 1.464850902557373 grad: 0.5420167001898374\n",
      "epoch: 25 loss: 1.4612985849380493 grad: 0.36202940605281664\n",
      "epoch: 26 loss: 1.46481192111969 grad: 0.6771457063174455\n",
      "epoch: 27 loss: 1.4630273580551147 grad: 0.08664594932542098\n",
      "epoch: 28 loss: 1.4617276191711426 grad: 0.08033240805080978\n",
      "epoch: 29 loss: 1.4640476703643799 grad: 0.3357219320199281\n",
      "epoch: 30 loss: 1.4617077112197876 grad: 0.44329205645059927\n",
      "epoch: 31 loss: 1.4627338647842407 grad: 0.20717632002340988\n",
      "epoch: 32 loss: 1.4621888399124146 grad: 0.34376753352232886\n",
      "epoch: 33 loss: 1.4637529850006104 grad: 0.45774921915764655\n",
      "epoch: 34 loss: 1.4629186391830444 grad: 0.22593411471013156\n",
      "epoch: 35 loss: 1.4618371725082397 grad: 0.2280705077762577\n",
      "epoch: 36 loss: 1.4639588594436646 grad: 0.19084156285152618\n",
      "epoch: 37 loss: 1.4634062051773071 grad: 0.3399613762216086\n",
      "epoch: 38 loss: 1.463731288909912 grad: 0.4028282190442296\n",
      "epoch: 39 loss: 1.465351939201355 grad: 1.1154890204628742\n",
      "epoch: 40 loss: 1.4642380475997925 grad: 0.7609276618734779\n",
      "epoch: 41 loss: 1.4639958143234253 grad: 0.40798703480652415\n",
      "epoch: 42 loss: 1.4649509191513062 grad: 0.5502416583057589\n",
      "epoch: 43 loss: 1.4654297828674316 grad: 0.36219064652062966\n",
      "epoch: 44 loss: 1.4630261659622192 grad: 0.14235666608716424\n",
      "epoch: 45 loss: 1.4629141092300415 grad: 0.7308660378333837\n",
      "epoch: 46 loss: 1.4641518592834473 grad: 0.01242777002704179\n",
      "epoch: 47 loss: 1.4620698690414429 grad: 0.6084971513701086\n",
      "epoch: 48 loss: 1.463511347770691 grad: 0.345499139159989\n",
      "epoch: 49 loss: 1.4641388654708862 grad: 0.09845738587802089\n",
      "epoch: 50 loss: 1.4621187448501587 grad: 0.11175481490695054\n",
      "epoch: 51 loss: 1.4650567770004272 grad: 0.5976365992782608\n",
      "epoch: 52 loss: 1.4617462158203125 grad: 0.23192686360407105\n",
      "epoch: 53 loss: 1.4636794328689575 grad: 0.13037249448397215\n",
      "epoch: 54 loss: 1.4633082151412964 grad: 0.7585844881528987\n",
      "epoch: 55 loss: 1.4621332883834839 grad: 0.010969174459757949\n",
      "epoch: 56 loss: 1.4622701406478882 grad: 0.7039752009393698\n",
      "epoch: 57 loss: 1.462628960609436 grad: 0.3051656729197315\n",
      "epoch: 58 loss: 1.464220404624939 grad: 0.2004614053945792\n",
      "epoch: 59 loss: 1.4635367393493652 grad: 0.8472550063023268\n",
      "epoch: 60 loss: 1.4646180868148804 grad: 0.5887928668896943\n",
      "epoch: 61 loss: 1.4644825458526611 grad: 0.5181921949635474\n",
      "epoch: 62 loss: 1.463417410850525 grad: 0.6782549425266922\n",
      "epoch: 63 loss: 1.4641822576522827 grad: 0.3784452619675911\n",
      "epoch: 64 loss: 1.4628711938858032 grad: 0.647182535438878\n",
      "epoch: 65 loss: 1.4622997045516968 grad: 0.2599202672823181\n",
      "epoch: 66 loss: 1.4641680717468262 grad: 0.6205596855613722\n",
      "epoch: 67 loss: 1.4626420736312866 grad: 0.23056357939411437\n",
      "epoch: 68 loss: 1.4631600379943848 grad: 0.07361306556810983\n",
      "epoch: 69 loss: 1.4628628492355347 grad: 0.7227786832570025\n",
      "epoch: 70 loss: 1.4631482362747192 grad: 0.8406656346188941\n",
      "epoch: 71 loss: 1.4649320840835571 grad: 0.2993103315511333\n",
      "epoch: 72 loss: 1.461803674697876 grad: 0.2680134129983094\n",
      "epoch: 73 loss: 1.46331787109375 grad: 0.7203042681281983\n",
      "epoch: 74 loss: 1.4632363319396973 grad: 0.22952209490536982\n",
      "epoch: 75 loss: 1.4626445770263672 grad: 0.009062037622220845\n",
      "epoch: 76 loss: 1.4645112752914429 grad: 0.13833848329505574\n",
      "epoch: 77 loss: 1.4640456438064575 grad: 0.5196036686578448\n",
      "epoch: 78 loss: 1.4631966352462769 grad: 0.10318554607213823\n",
      "epoch: 79 loss: 1.4626939296722412 grad: 0.1894643502562162\n",
      "epoch: 80 loss: 1.463944911956787 grad: 0.7364519972116669\n",
      "epoch: 81 loss: 1.461917519569397 grad: 0.271836510639549\n",
      "epoch: 82 loss: 1.461716890335083 grad: 0.710937267598464\n",
      "epoch: 83 loss: 1.4626561403274536 grad: 0.12372173692446255\n",
      "epoch: 84 loss: 1.4626494646072388 grad: 0.46636466413866823\n",
      "epoch: 85 loss: 1.4627234935760498 grad: 0.09466305859214551\n",
      "epoch: 86 loss: 1.46383535861969 grad: 0.33907436367714766\n",
      "epoch: 87 loss: 1.4639228582382202 grad: 0.5475373254556051\n",
      "epoch: 88 loss: 1.463157296180725 grad: 0.031890291115986874\n",
      "epoch: 89 loss: 1.463758945465088 grad: 0.3484306701606889\n",
      "epoch: 90 loss: 1.4627913236618042 grad: 0.22305113398637685\n",
      "epoch: 91 loss: 1.462810754776001 grad: 0.21242933956124935\n",
      "epoch: 92 loss: 1.466151237487793 grad: 0.07902291376726943\n",
      "epoch: 93 loss: 1.462080717086792 grad: 0.27248634592752574\n",
      "epoch: 94 loss: 1.4625377655029297 grad: 0.23469164469699338\n",
      "epoch: 95 loss: 1.4624933004379272 grad: 0.4221045125386635\n",
      "epoch: 96 loss: 1.4633318185806274 grad: 0.6732887084181644\n",
      "epoch: 97 loss: 1.463043451309204 grad: 0.3485109751662279\n",
      "epoch: 98 loss: 1.4626967906951904 grad: 0.4437850072296383\n",
      "epoch: 99 loss: 1.4612013101577759 grad: 0.07756754681862932\n",
      "epoch: 100 loss: 1.4619427919387817 grad: 0.15565899958126517\n",
      "epoch: 101 loss: 1.4636285305023193 grad: 0.08906489898244681\n",
      "epoch: 102 loss: 1.46263587474823 grad: 0.5530358383802639\n",
      "epoch: 103 loss: 1.4640568494796753 grad: 0.4437846858460205\n",
      "epoch: 104 loss: 1.4621621370315552 grad: 0.10697531345886352\n",
      "epoch: 105 loss: 1.4622989892959595 grad: 0.22858318872308314\n",
      "epoch: 106 loss: 1.4627374410629272 grad: 0.11958419308985273\n",
      "epoch: 107 loss: 1.4629428386688232 grad: 0.7281445837470318\n",
      "epoch: 108 loss: 1.4632259607315063 grad: 0.15910768739148115\n",
      "epoch: 109 loss: 1.4633842706680298 grad: 0.36589708675163934\n",
      "epoch: 110 loss: 1.4651238918304443 grad: 0.3607762754726796\n",
      "epoch: 111 loss: 1.4639861583709717 grad: 0.3040114188150626\n",
      "epoch: 112 loss: 1.462990164756775 grad: 0.9166834922648972\n",
      "epoch: 113 loss: 1.4637919664382935 grad: 0.3394078686334941\n",
      "epoch: 114 loss: 1.4624342918395996 grad: 0.8839981420397486\n",
      "epoch: 115 loss: 1.4625905752182007 grad: 0.10350229093240919\n",
      "epoch: 116 loss: 1.4635783433914185 grad: 0.13327225630985498\n",
      "epoch: 117 loss: 1.4636831283569336 grad: 0.36262110392930813\n",
      "epoch: 118 loss: 1.4634419679641724 grad: 0.41323909410047843\n",
      "epoch: 119 loss: 1.4626120328903198 grad: 0.7845490772786805\n",
      "epoch: 120 loss: 1.4630409479141235 grad: 0.2129985688516974\n",
      "epoch: 121 loss: 1.4644767045974731 grad: 0.44336324557107865\n",
      "epoch: 122 loss: 1.4619460105895996 grad: 0.5189195548655113\n",
      "epoch: 123 loss: 1.4625428915023804 grad: 0.6447928778537837\n",
      "epoch: 124 loss: 1.4638466835021973 grad: 0.5744258294814767\n",
      "epoch: 125 loss: 1.463612675666809 grad: 0.09069239564112334\n",
      "epoch: 126 loss: 1.4636216163635254 grad: 0.053365359224851076\n",
      "epoch: 127 loss: 1.4651209115982056 grad: 0.412153118603337\n",
      "epoch: 128 loss: 1.4632339477539062 grad: 0.6333826396120602\n",
      "epoch: 129 loss: 1.462256908416748 grad: 0.4012440813096777\n",
      "epoch: 130 loss: 1.4645071029663086 grad: 0.47954412295692456\n",
      "epoch: 131 loss: 1.4622225761413574 grad: 0.5637629509484039\n",
      "epoch: 132 loss: 1.463453769683838 grad: 0.46121056954021283\n",
      "epoch: 133 loss: 1.4642386436462402 grad: 0.2994399580367113\n",
      "epoch: 134 loss: 1.4635107517242432 grad: 0.3773934595800383\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 135 loss: 1.4630200862884521 grad: 0.07977034587685881\n",
      "epoch: 136 loss: 1.4626039266586304 grad: 0.41482352763083474\n",
      "epoch: 137 loss: 1.4626237154006958 grad: 0.21326239613318337\n",
      "epoch: 138 loss: 1.4649474620819092 grad: 0.8490300825866828\n",
      "epoch: 139 loss: 1.4642044305801392 grad: 0.48065263582824913\n",
      "epoch: 140 loss: 1.4637373685836792 grad: 0.4618312088529605\n",
      "epoch: 141 loss: 1.4644227027893066 grad: 1.0230540641767703\n",
      "epoch: 142 loss: 1.463617205619812 grad: 0.9348809710963094\n",
      "epoch: 143 loss: 1.4630087614059448 grad: 0.32549636954839767\n",
      "epoch: 144 loss: 1.4651991128921509 grad: 0.2656015968407621\n",
      "epoch: 145 loss: 1.4625216722488403 grad: 0.47587102800353515\n",
      "epoch: 146 loss: 1.4619203805923462 grad: 0.40417503434635893\n",
      "epoch: 147 loss: 1.4637446403503418 grad: 0.5257050270015368\n",
      "epoch: 148 loss: 1.4645652770996094 grad: 0.12274558581689153\n",
      "epoch: 149 loss: 1.4636590480804443 grad: 0.47443195284415035\n",
      "epoch: 150 loss: 1.4664143323898315 grad: 0.4721546922846335\n",
      "epoch: 151 loss: 1.4632624387741089 grad: 0.1949528145912849\n",
      "epoch: 152 loss: 1.4620870351791382 grad: 0.15893678528585597\n",
      "epoch: 153 loss: 1.4643747806549072 grad: 0.28068280959997854\n",
      "epoch: 154 loss: 1.4648936986923218 grad: 1.1260950292827214\n",
      "epoch: 155 loss: 1.4651834964752197 grad: 0.3190039042966275\n",
      "epoch: 156 loss: 1.4652072191238403 grad: 0.4105647296595032\n",
      "epoch: 157 loss: 1.4627914428710938 grad: 0.23023618124093073\n",
      "epoch: 158 loss: 1.4636399745941162 grad: 0.05947675589477512\n",
      "epoch: 159 loss: 1.465389609336853 grad: 0.6697230533036995\n",
      "epoch: 160 loss: 1.4635754823684692 grad: 0.7093896839712622\n",
      "epoch: 161 loss: 1.4645501375198364 grad: 0.8921054845357993\n",
      "epoch: 162 loss: 1.4618316888809204 grad: 0.5839574047908954\n",
      "epoch: 163 loss: 1.4621262550354004 grad: 0.05730553898483549\n",
      "epoch: 164 loss: 1.4612845182418823 grad: 0.09453030517184442\n",
      "epoch: 165 loss: 1.4631311893463135 grad: 0.13564471575080414\n",
      "epoch: 166 loss: 1.4631038904190063 grad: 0.5653426106982663\n",
      "epoch: 167 loss: 1.4620518684387207 grad: 0.40635277360108846\n",
      "epoch: 168 loss: 1.4640240669250488 grad: 0.6105451365498996\n",
      "epoch: 169 loss: 1.4640611410140991 grad: 0.7079318240318454\n",
      "epoch: 170 loss: 1.461656093597412 grad: 0.03974375444016158\n",
      "epoch: 171 loss: 1.4640851020812988 grad: 0.5486895895452637\n",
      "epoch: 172 loss: 1.4644618034362793 grad: 0.2591096741824418\n",
      "epoch: 173 loss: 1.4632511138916016 grad: 0.27382432448132493\n",
      "epoch: 174 loss: 1.463787317276001 grad: 0.5854162703302749\n",
      "epoch: 175 loss: 1.4622647762298584 grad: 0.28687073308109684\n",
      "epoch: 176 loss: 1.4634534120559692 grad: 0.573761580512391\n",
      "epoch: 177 loss: 1.4631481170654297 grad: 1.0726951018872533\n",
      "epoch: 178 loss: 1.463868498802185 grad: 1.042334597111289\n",
      "epoch: 179 loss: 1.464177131652832 grad: 0.8620322436833822\n",
      "epoch: 180 loss: 1.4621137380599976 grad: 0.7319163637116074\n",
      "epoch: 181 loss: 1.4645359516143799 grad: 0.5683967261753483\n",
      "epoch: 182 loss: 1.4621995687484741 grad: 0.4680718942856619\n",
      "epoch: 183 loss: 1.4616976976394653 grad: 0.11329468488103364\n",
      "epoch: 184 loss: 1.4624544382095337 grad: 0.43448223525191515\n",
      "epoch: 185 loss: 1.4626492261886597 grad: 0.6039439368756978\n",
      "epoch: 186 loss: 1.4612361192703247 grad: 0.10181396419991659\n",
      "epoch: 187 loss: 1.4647479057312012 grad: 0.515073073983476\n",
      "epoch: 188 loss: 1.4614564180374146 grad: 0.21573696207917728\n",
      "epoch: 189 loss: 1.4629091024398804 grad: 0.2908910657878175\n",
      "epoch: 190 loss: 1.4621378183364868 grad: 0.038915879232443\n",
      "epoch: 191 loss: 1.4626628160476685 grad: 0.09109634439894465\n",
      "epoch: 192 loss: 1.464808702468872 grad: 0.6657438646034751\n",
      "epoch: 193 loss: 1.4631075859069824 grad: 1.01911762644714\n",
      "epoch: 194 loss: 1.462143063545227 grad: 0.02462314895395077\n",
      "epoch: 195 loss: 1.4631681442260742 grad: 0.3809348438490035\n",
      "epoch: 196 loss: 1.4622644186019897 grad: 0.13815417970914165\n",
      "epoch: 197 loss: 1.4637354612350464 grad: 0.07704064193978372\n",
      "epoch: 198 loss: 1.4642024040222168 grad: 0.33102734302579034\n",
      "epoch: 199 loss: 1.462219476699829 grad: 0.6127435344264806\n",
      "epoch: 200 loss: 1.4621813297271729 grad: 0.03414092843340298\n",
      "epoch: 201 loss: 1.4641637802124023 grad: 0.18697346344529675\n",
      "epoch: 202 loss: 1.463034987449646 grad: 0.072926611980977\n",
      "epoch: 203 loss: 1.4621752500534058 grad: 0.1934214962940691\n",
      "epoch: 204 loss: 1.46345055103302 grad: 0.3444244028148285\n",
      "epoch: 205 loss: 1.4646048545837402 grad: 0.20585878476338793\n",
      "epoch: 206 loss: 1.463856816291809 grad: 0.5654446394551291\n",
      "epoch: 207 loss: 1.4615776538848877 grad: 0.2070380107455698\n",
      "epoch: 208 loss: 1.4642672538757324 grad: 1.0299572484706463\n",
      "epoch: 209 loss: 1.462873101234436 grad: 0.1559452231649512\n",
      "epoch: 210 loss: 1.4632494449615479 grad: 0.2366647116819853\n",
      "epoch: 211 loss: 1.4633687734603882 grad: 0.24220246969392517\n",
      "epoch: 212 loss: 1.4647516012191772 grad: 0.5805285298752048\n",
      "epoch: 213 loss: 1.463240623474121 grad: 0.6566810899363551\n",
      "epoch: 214 loss: 1.4628950357437134 grad: 0.49443398620707596\n",
      "epoch: 215 loss: 1.464106798171997 grad: 0.30550789660236427\n",
      "epoch: 216 loss: 1.464108943939209 grad: 1.1062970913183263\n",
      "epoch: 217 loss: 1.462551236152649 grad: 0.49712285991156\n",
      "epoch: 218 loss: 1.4635167121887207 grad: 0.4746561263893724\n",
      "epoch: 219 loss: 1.4633318185806274 grad: 0.3379059311050517\n",
      "epoch: 220 loss: 1.4636797904968262 grad: 1.5432563117257918\n",
      "epoch: 221 loss: 1.4631444215774536 grad: 0.01100997097735226\n",
      "epoch: 222 loss: 1.4625489711761475 grad: 0.21079679996652925\n",
      "epoch: 223 loss: 1.4638835191726685 grad: 0.3937244943369163\n",
      "epoch: 224 loss: 1.4626808166503906 grad: 0.17128457834582558\n",
      "epoch: 225 loss: 1.464403748512268 grad: 0.42310447304858545\n",
      "epoch: 226 loss: 1.4649899005889893 grad: 0.5159167936877037\n",
      "epoch: 227 loss: 1.4640605449676514 grad: 0.11770607683623915\n",
      "epoch: 228 loss: 1.4637051820755005 grad: 0.18084779510060583\n",
      "epoch: 229 loss: 1.4629935026168823 grad: 1.046665999437925\n",
      "epoch: 230 loss: 1.4631214141845703 grad: 0.41202636952514693\n",
      "epoch: 231 loss: 1.462837815284729 grad: 0.45608061496820707\n",
      "epoch: 232 loss: 1.463386058807373 grad: 0.9644881438448957\n",
      "epoch: 233 loss: 1.463128685951233 grad: 0.3233955733585784\n",
      "epoch: 234 loss: 1.4628527164459229 grad: 0.27845010235768786\n",
      "epoch: 235 loss: 1.4625904560089111 grad: 0.3477604644642169\n",
      "epoch: 236 loss: 1.4636549949645996 grad: 0.09991866118542285\n",
      "epoch: 237 loss: 1.4613728523254395 grad: 0.3168186759327873\n",
      "epoch: 238 loss: 1.4623249769210815 grad: 0.3116033828167402\n",
      "epoch: 239 loss: 1.4631595611572266 grad: 0.2015697457810617\n",
      "epoch: 240 loss: 1.4645084142684937 grad: 0.2644071029338017\n",
      "epoch: 241 loss: 1.4647406339645386 grad: 0.13599309935731685\n",
      "epoch: 242 loss: 1.464353322982788 grad: 0.5199438091014383\n",
      "epoch: 243 loss: 1.4626480340957642 grad: 0.30311324599387324\n",
      "epoch: 244 loss: 1.4622466564178467 grad: 0.21460780247729197\n",
      "epoch: 245 loss: 1.463631510734558 grad: 0.15665701329060838\n",
      "epoch: 246 loss: 1.463102102279663 grad: 0.37628790827704295\n",
      "epoch: 247 loss: 1.4626891613006592 grad: 0.16785774177029272\n",
      "epoch: 248 loss: 1.4633872509002686 grad: 0.6381762946921747\n",
      "epoch: 249 loss: 1.4627795219421387 grad: 0.3317708882622857\n",
      "epoch: 250 loss: 1.462653636932373 grad: 0.09469818373792216\n",
      "epoch: 251 loss: 1.4643975496292114 grad: 0.45337512720199097\n",
      "epoch: 252 loss: 1.464896321296692 grad: 0.7193509993485492\n",
      "epoch: 253 loss: 1.4636108875274658 grad: 0.09699347266614515\n",
      "epoch: 254 loss: 1.4633569717407227 grad: 0.6585318137372081\n",
      "epoch: 255 loss: 1.4621503353118896 grad: 0.014213522866841974\n",
      "epoch: 256 loss: 1.4636456966400146 grad: 0.6888620091154426\n",
      "epoch: 257 loss: 1.4638484716415405 grad: 0.4991874957899616\n",
      "epoch: 258 loss: 1.4635182619094849 grad: 0.6248665242526714\n",
      "epoch: 259 loss: 1.4629147052764893 grad: 0.4334930727886997\n",
      "epoch: 260 loss: 1.4621907472610474 grad: 0.363003271566666\n",
      "epoch: 261 loss: 1.4621065855026245 grad: 0.7614625798058742\n",
      "epoch: 262 loss: 1.4637640714645386 grad: 0.09596196914413573\n",
      "epoch: 263 loss: 1.4619686603546143 grad: 0.22657577304126023\n",
      "epoch: 264 loss: 1.462054967880249 grad: 0.49500296991378623\n",
      "epoch: 265 loss: 1.4642877578735352 grad: 0.9975501278076356\n",
      "epoch: 266 loss: 1.463571548461914 grad: 0.6513548510440103\n",
      "epoch: 267 loss: 1.4635976552963257 grad: 0.5833892387603344\n",
      "epoch: 268 loss: 1.4628597497940063 grad: 0.4503561618436515\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 269 loss: 1.4622548818588257 grad: 0.43617006552338894\n",
      "epoch: 270 loss: 1.463387131690979 grad: 0.5892512365460141\n",
      "epoch: 271 loss: 1.4636988639831543 grad: 0.13712042550417572\n",
      "epoch: 272 loss: 1.4624663591384888 grad: 0.4648847256191853\n",
      "epoch: 273 loss: 1.4628279209136963 grad: 0.4635027918569152\n",
      "epoch: 274 loss: 1.4642915725708008 grad: 0.9449537461569778\n",
      "epoch: 275 loss: 1.4624401330947876 grad: 0.34116730469292694\n",
      "epoch: 276 loss: 1.463219165802002 grad: 0.16864562781749598\n",
      "epoch: 277 loss: 1.4623080492019653 grad: 0.28142257527403275\n",
      "epoch: 278 loss: 1.4626308679580688 grad: 0.1031351894661257\n",
      "epoch: 279 loss: 1.46304452419281 grad: 0.3969008137730099\n",
      "epoch: 280 loss: 1.465110182762146 grad: 0.993355840457785\n",
      "epoch: 281 loss: 1.463169813156128 grad: 0.3065385190538778\n",
      "epoch: 282 loss: 1.462383508682251 grad: 0.1893318450722409\n",
      "epoch: 283 loss: 1.4625812768936157 grad: 0.38905535822394194\n",
      "epoch: 284 loss: 1.4638667106628418 grad: 0.25263327497367094\n",
      "epoch: 285 loss: 1.4628297090530396 grad: 0.5272604560080663\n",
      "epoch: 286 loss: 1.462178111076355 grad: 0.0655754496145572\n",
      "epoch: 287 loss: 1.462159276008606 grad: 0.8006037149481182\n",
      "epoch: 288 loss: 1.4625293016433716 grad: 0.1916355885801719\n",
      "epoch: 289 loss: 1.4617836475372314 grad: 0.31896578698714895\n",
      "epoch: 290 loss: 1.4648926258087158 grad: 0.37111621874510864\n",
      "epoch: 291 loss: 1.4632269144058228 grad: 0.2006207089364144\n",
      "epoch: 292 loss: 1.4630054235458374 grad: 0.4406831408320046\n",
      "epoch: 293 loss: 1.4631507396697998 grad: 0.0367356075247716\n",
      "epoch: 294 loss: 1.4618420600891113 grad: 0.3017412692689996\n",
      "epoch: 295 loss: 1.462691068649292 grad: 0.14056320260902033\n",
      "epoch: 296 loss: 1.4636530876159668 grad: 0.571763718600564\n",
      "epoch: 297 loss: 1.463455080986023 grad: 0.7003350736734548\n",
      "epoch: 298 loss: 1.4624273777008057 grad: 0.33699543609433474\n",
      "epoch: 299 loss: 1.4636623859405518 grad: 0.034338378018611275\n",
      "epoch: 300 loss: 1.4627821445465088 grad: 0.3126948372746739\n",
      "epoch: 301 loss: 1.464867115020752 grad: 0.9135436686640117\n",
      "epoch: 302 loss: 1.4652587175369263 grad: 0.9778672374836731\n",
      "epoch: 303 loss: 1.4616544246673584 grad: 0.028547835194199428\n",
      "epoch: 304 loss: 1.4641691446304321 grad: 0.44971058826447974\n",
      "epoch: 305 loss: 1.4633474349975586 grad: 0.46231021226249913\n",
      "epoch: 306 loss: 1.4620832204818726 grad: 0.5764006377550497\n",
      "epoch: 307 loss: 1.461653709411621 grad: 0.4580005293066743\n",
      "epoch: 308 loss: 1.4628647565841675 grad: 0.3915298457740765\n",
      "epoch: 309 loss: 1.4617143869400024 grad: 0.09930535455947537\n",
      "epoch: 310 loss: 1.463432788848877 grad: 0.27829434927900054\n",
      "epoch: 311 loss: 1.4636671543121338 grad: 0.5340088247221094\n",
      "epoch: 312 loss: 1.4621543884277344 grad: 0.36374505240585564\n",
      "epoch: 313 loss: 1.4625552892684937 grad: 0.5134693731550949\n",
      "epoch: 314 loss: 1.4633231163024902 grad: 0.3060013230744298\n",
      "epoch: 315 loss: 1.4622987508773804 grad: 0.20029414705393928\n",
      "epoch: 316 loss: 1.4626412391662598 grad: 1.1059232281411049\n",
      "epoch: 317 loss: 1.4625061750411987 grad: 0.43103545456107056\n",
      "epoch: 318 loss: 1.4629155397415161 grad: 0.4559399459194961\n",
      "epoch: 319 loss: 1.462935447692871 grad: 0.323306943343155\n",
      "epoch: 320 loss: 1.4632208347320557 grad: 0.8170223655528814\n",
      "epoch: 321 loss: 1.4625195264816284 grad: 0.442218924558969\n",
      "epoch: 322 loss: 1.4637690782546997 grad: 0.789714529675918\n",
      "epoch: 323 loss: 1.4632399082183838 grad: 0.23128421903236798\n",
      "epoch: 324 loss: 1.4642159938812256 grad: 0.4284164884506129\n",
      "epoch: 325 loss: 1.4621312618255615 grad: 0.07571045536543339\n",
      "epoch: 326 loss: 1.4625062942504883 grad: 0.19656495459949894\n",
      "epoch: 327 loss: 1.463181734085083 grad: 0.15467768677590701\n",
      "epoch: 328 loss: 1.4627259969711304 grad: 0.1317617704731933\n",
      "epoch: 329 loss: 1.4626896381378174 grad: 0.13501340841672488\n",
      "epoch: 330 loss: 1.4643532037734985 grad: 0.48878516520955667\n",
      "epoch: 331 loss: 1.4642455577850342 grad: 0.314810446803185\n",
      "epoch: 332 loss: 1.462146520614624 grad: 0.004664877833899907\n",
      "epoch: 333 loss: 1.462014079093933 grad: 0.1562899273311235\n",
      "epoch: 334 loss: 1.4625815153121948 grad: 0.28058963348390903\n",
      "epoch: 335 loss: 1.462631344795227 grad: 0.020011239228479038\n",
      "epoch: 336 loss: 1.4641715288162231 grad: 0.4707241639103846\n",
      "epoch: 337 loss: 1.4625263214111328 grad: 0.4540383666515738\n",
      "epoch: 338 loss: 1.462644338607788 grad: 0.22262674521120465\n",
      "epoch: 339 loss: 1.4622225761413574 grad: 0.3444889410538187\n",
      "epoch: 340 loss: 1.4634783267974854 grad: 0.4306122806656232\n",
      "epoch: 341 loss: 1.46268892288208 grad: 0.10075608299691213\n",
      "epoch: 342 loss: 1.4640661478042603 grad: 0.8130396519613567\n",
      "epoch: 343 loss: 1.4628393650054932 grad: 0.3789150963276826\n",
      "epoch: 344 loss: 1.4633581638336182 grad: 0.5109557343814172\n",
      "epoch: 345 loss: 1.465335726737976 grad: 0.514450590172648\n",
      "epoch: 346 loss: 1.4617160558700562 grad: 0.1041489573367643\n",
      "epoch: 347 loss: 1.461679220199585 grad: 0.01855356842446376\n",
      "epoch: 348 loss: 1.4620726108551025 grad: 0.2836481344537566\n",
      "epoch: 349 loss: 1.4628514051437378 grad: 0.4000916171600596\n",
      "epoch: 350 loss: 1.4626951217651367 grad: 0.7780847333320378\n",
      "epoch: 351 loss: 1.4630078077316284 grad: 0.13357705499052736\n",
      "epoch: 352 loss: 1.4641225337982178 grad: 0.19747635639255792\n",
      "epoch: 353 loss: 1.4621343612670898 grad: 0.023609780530093338\n",
      "epoch: 354 loss: 1.462860345840454 grad: 0.3825235994883469\n",
      "epoch: 355 loss: 1.4630846977233887 grad: 0.28675741748976474\n",
      "epoch: 356 loss: 1.4631762504577637 grad: 0.08834478134875919\n",
      "epoch: 357 loss: 1.46488356590271 grad: 0.6388632436234604\n",
      "epoch: 358 loss: 1.4622695446014404 grad: 0.13600365559871158\n",
      "epoch: 359 loss: 1.4627848863601685 grad: 0.2528827541055927\n",
      "epoch: 360 loss: 1.4616830348968506 grad: 0.050321518204148825\n",
      "epoch: 361 loss: 1.4626233577728271 grad: 0.020619612723258383\n",
      "epoch: 362 loss: 1.4628483057022095 grad: 0.33310344928778857\n",
      "epoch: 363 loss: 1.463493824005127 grad: 0.6026679367264056\n",
      "epoch: 364 loss: 1.4648696184158325 grad: 0.26932351286821693\n",
      "epoch: 365 loss: 1.4636292457580566 grad: 0.00698187279460744\n",
      "epoch: 366 loss: 1.462281584739685 grad: 0.3946661899902976\n",
      "epoch: 367 loss: 1.462159514427185 grad: 0.07516241571205368\n",
      "epoch: 368 loss: 1.465031623840332 grad: 0.6200464231278031\n",
      "epoch: 369 loss: 1.4644867181777954 grad: 0.30415879417175734\n",
      "epoch: 370 loss: 1.4628045558929443 grad: 0.33616626161910945\n",
      "epoch: 371 loss: 1.464354157447815 grad: 0.48970044977380267\n",
      "epoch: 372 loss: 1.4655098915100098 grad: 0.770025309570511\n",
      "epoch: 373 loss: 1.4627814292907715 grad: 0.26318545571499924\n",
      "epoch: 374 loss: 1.464045524597168 grad: 0.3561251038802371\n",
      "epoch: 375 loss: 1.4621751308441162 grad: 0.07500022619048215\n",
      "epoch: 376 loss: 1.4655983448028564 grad: 0.20244015064509896\n",
      "epoch: 377 loss: 1.4632742404937744 grad: 0.3540343843219309\n",
      "epoch: 378 loss: 1.464398980140686 grad: 0.37301681663237923\n",
      "epoch: 379 loss: 1.4626401662826538 grad: 0.12080274709041794\n",
      "epoch: 380 loss: 1.4634944200515747 grad: 0.4243043843157209\n",
      "epoch: 381 loss: 1.4628949165344238 grad: 0.5255699606115235\n",
      "epoch: 382 loss: 1.4615150690078735 grad: 0.36444181937223347\n",
      "epoch: 383 loss: 1.4630953073501587 grad: 0.05319970308718404\n",
      "epoch: 384 loss: 1.4614202976226807 grad: 0.23420852982599719\n",
      "epoch: 385 loss: 1.4639021158218384 grad: 0.7650668441934501\n",
      "epoch: 386 loss: 1.4623229503631592 grad: 0.5082710948149798\n",
      "epoch: 387 loss: 1.4620909690856934 grad: 0.2826279965696259\n",
      "epoch: 388 loss: 1.4619810581207275 grad: 0.36724587043291584\n",
      "epoch: 389 loss: 1.4626028537750244 grad: 0.6524479761208251\n",
      "epoch: 390 loss: 1.4644039869308472 grad: 0.6846514481357181\n",
      "epoch: 391 loss: 1.4635629653930664 grad: 0.08716907812966519\n",
      "epoch: 392 loss: 1.465002179145813 grad: 0.8785398549592086\n",
      "epoch: 393 loss: 1.4635515213012695 grad: 0.21195081821022488\n",
      "epoch: 394 loss: 1.4642434120178223 grad: 0.4196591719602301\n",
      "epoch: 395 loss: 1.4640110731124878 grad: 0.9583684384800049\n",
      "epoch: 396 loss: 1.4626431465148926 grad: 0.17862015758450797\n",
      "epoch: 397 loss: 1.4625252485275269 grad: 0.1890701821587698\n",
      "epoch: 398 loss: 1.4630424976348877 grad: 0.38950327874011975\n",
      "epoch: 399 loss: 1.4632837772369385 grad: 0.3866573979374611\n",
      "epoch: 400 loss: 1.4641400575637817 grad: 0.5014263386690654\n",
      "epoch: 401 loss: 1.463320016860962 grad: 0.3269440068999861\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 402 loss: 1.4636280536651611 grad: 0.09390521899723556\n",
      "epoch: 403 loss: 1.4648423194885254 grad: 0.7381302496041882\n",
      "epoch: 404 loss: 1.461777925491333 grad: 0.19553274991165065\n",
      "epoch: 405 loss: 1.4636001586914062 grad: 0.1755703762482098\n",
      "epoch: 406 loss: 1.4638572931289673 grad: 0.48750345195564815\n",
      "epoch: 407 loss: 1.461888074874878 grad: 0.1837123610177139\n",
      "epoch: 408 loss: 1.4646166563034058 grad: 0.12687635320430266\n",
      "epoch: 409 loss: 1.462654948234558 grad: 0.04912512796013351\n",
      "epoch: 410 loss: 1.4641001224517822 grad: 0.09666098321305433\n",
      "epoch: 411 loss: 1.464989423751831 grad: 0.41710028858341835\n",
      "epoch: 412 loss: 1.462537407875061 grad: 0.28420030664281026\n",
      "epoch: 413 loss: 1.4631465673446655 grad: 0.029087852857057287\n",
      "epoch: 414 loss: 1.4628335237503052 grad: 0.39259998479479313\n",
      "epoch: 415 loss: 1.4639248847961426 grad: 0.20117782583431737\n",
      "epoch: 416 loss: 1.4617602825164795 grad: 0.14954477490032192\n",
      "epoch: 417 loss: 1.4630835056304932 grad: 0.3757202484642751\n",
      "epoch: 418 loss: 1.4630688428878784 grad: 0.5107657271837301\n",
      "epoch: 419 loss: 1.4638700485229492 grad: 0.5091556285431527\n",
      "epoch: 420 loss: 1.4627578258514404 grad: 0.05843222128926176\n",
      "epoch: 421 loss: 1.4622740745544434 grad: 0.21439452537728315\n",
      "epoch: 422 loss: 1.4618804454803467 grad: 0.22240042647305053\n",
      "epoch: 423 loss: 1.4646235704421997 grad: 0.007577157335272038\n",
      "epoch: 424 loss: 1.4636660814285278 grad: 0.3143548605301432\n",
      "epoch: 425 loss: 1.4622803926467896 grad: 0.6402755759538531\n",
      "epoch: 426 loss: 1.462408185005188 grad: 0.3605022867327853\n",
      "epoch: 427 loss: 1.4627267122268677 grad: 0.28602550198409343\n",
      "epoch: 428 loss: 1.4624782800674438 grad: 0.5292824555096437\n",
      "epoch: 429 loss: 1.462429404258728 grad: 0.45121488174409147\n",
      "epoch: 430 loss: 1.4633612632751465 grad: 0.3443498923207493\n",
      "epoch: 431 loss: 1.4620301723480225 grad: 0.5740034816947588\n",
      "epoch: 432 loss: 1.4636480808258057 grad: 0.05100801848849262\n",
      "epoch: 433 loss: 1.46221125125885 grad: 0.15881362513791558\n",
      "epoch: 434 loss: 1.4630556106567383 grad: 0.5637241244850552\n",
      "epoch: 435 loss: 1.4635474681854248 grad: 0.3707630830535279\n",
      "epoch: 436 loss: 1.464033603668213 grad: 0.29223110447019035\n",
      "epoch: 437 loss: 1.462165355682373 grad: 0.028789612975812624\n",
      "epoch: 438 loss: 1.4631019830703735 grad: 0.07034408214762922\n",
      "epoch: 439 loss: 1.4627344608306885 grad: 0.12141351308006489\n",
      "epoch: 440 loss: 1.4635677337646484 grad: 0.13032009714432688\n",
      "epoch: 441 loss: 1.4614949226379395 grad: 0.22918242113648296\n",
      "epoch: 442 loss: 1.4619731903076172 grad: 0.7709204590955664\n",
      "epoch: 443 loss: 1.4639270305633545 grad: 0.416063158240716\n",
      "epoch: 444 loss: 1.4639450311660767 grad: 0.35481653526962487\n",
      "epoch: 445 loss: 1.4626649618148804 grad: 0.1770866316971835\n",
      "epoch: 446 loss: 1.4611936807632446 grad: 0.0704536056399522\n",
      "epoch: 447 loss: 1.4623278379440308 grad: 0.18886290305921927\n",
      "epoch: 448 loss: 1.4618619680404663 grad: 0.234395489940199\n",
      "epoch: 449 loss: 1.463097095489502 grad: 0.07434659803040614\n",
      "epoch: 450 loss: 1.461717963218689 grad: 0.1350705291624979\n",
      "epoch: 451 loss: 1.4630358219146729 grad: 0.4135338813188259\n",
      "epoch: 452 loss: 1.4621505737304688 grad: 0.021991790892150167\n",
      "epoch: 453 loss: 1.4624178409576416 grad: 0.3989177286378356\n",
      "epoch: 454 loss: 1.4620871543884277 grad: 0.10737593530750021\n",
      "epoch: 455 loss: 1.4631247520446777 grad: 0.2137243248944069\n",
      "epoch: 456 loss: 1.465040922164917 grad: 0.36020353771018054\n",
      "epoch: 457 loss: 1.4617021083831787 grad: 0.2145124902373798\n",
      "epoch: 458 loss: 1.4630767107009888 grad: 0.5194121137687417\n",
      "epoch: 459 loss: 1.4642189741134644 grad: 0.4739277224735276\n",
      "epoch: 460 loss: 1.4637318849563599 grad: 0.8426928406774786\n",
      "epoch: 461 loss: 1.462609052658081 grad: 0.14983972084622205\n",
      "epoch: 462 loss: 1.4630659818649292 grad: 0.6714564000993235\n",
      "epoch: 463 loss: 1.4631550312042236 grad: 0.8950325871822102\n",
      "epoch: 464 loss: 1.462854027748108 grad: 0.42813474509266836\n",
      "epoch: 465 loss: 1.4621813297271729 grad: 0.4107391951784378\n",
      "epoch: 466 loss: 1.4632724523544312 grad: 0.526510095012935\n",
      "epoch: 467 loss: 1.465707778930664 grad: 0.31793614558904054\n",
      "epoch: 468 loss: 1.4655219316482544 grad: 0.2828154320141192\n",
      "epoch: 469 loss: 1.4622355699539185 grad: 0.3568473362966899\n",
      "epoch: 470 loss: 1.4619672298431396 grad: 0.3625187428856885\n",
      "epoch: 471 loss: 1.4639126062393188 grad: 0.910879846423298\n",
      "epoch: 472 loss: 1.4624574184417725 grad: 0.25067259077769377\n",
      "epoch: 473 loss: 1.4618711471557617 grad: 0.4710182833017957\n",
      "epoch: 474 loss: 1.4623336791992188 grad: 0.2986275625748701\n",
      "epoch: 475 loss: 1.4650077819824219 grad: 0.1945795706607962\n",
      "epoch: 476 loss: 1.4625005722045898 grad: 0.8130759517733099\n",
      "epoch: 477 loss: 1.4639623165130615 grad: 0.3287611169968928\n",
      "epoch: 478 loss: 1.4630074501037598 grad: 0.569231620139352\n",
      "epoch: 479 loss: 1.4622162580490112 grad: 0.09929971452076564\n",
      "epoch: 480 loss: 1.4641371965408325 grad: 0.13598903544573585\n",
      "epoch: 481 loss: 1.4615358114242554 grad: 0.7590054930163126\n",
      "epoch: 482 loss: 1.4621919393539429 grad: 0.10535572383206293\n",
      "epoch: 483 loss: 1.463098168373108 grad: 0.5420300644150192\n",
      "epoch: 484 loss: 1.4646281003952026 grad: 0.6021213734296668\n",
      "epoch: 485 loss: 1.462846279144287 grad: 0.44810484329215333\n",
      "epoch: 486 loss: 1.4626200199127197 grad: 0.0825167565996911\n",
      "epoch: 487 loss: 1.4639371633529663 grad: 0.3326905961154624\n",
      "epoch: 488 loss: 1.4635250568389893 grad: 0.2674178275244243\n",
      "epoch: 489 loss: 1.462579607963562 grad: 0.5166337344487459\n",
      "epoch: 490 loss: 1.4631133079528809 grad: 0.09787783607208912\n",
      "epoch: 491 loss: 1.4631969928741455 grad: 0.5311895684676397\n",
      "epoch: 492 loss: 1.4616864919662476 grad: 0.040887722305908786\n",
      "epoch: 493 loss: 1.462125301361084 grad: 0.2040522145496482\n",
      "epoch: 494 loss: 1.4641517400741577 grad: 0.42017336935755556\n",
      "epoch: 495 loss: 1.4627642631530762 grad: 0.3783435002518935\n",
      "epoch: 496 loss: 1.46315336227417 grad: 0.4391793294587925\n",
      "epoch: 497 loss: 1.462162971496582 grad: 0.037266871162452385\n",
      "epoch: 498 loss: 1.4636198282241821 grad: 0.33192305153195717\n",
      "epoch: 499 loss: 1.4624971151351929 grad: 0.4800840590619839\n",
      "1.7809573411941528\n",
      "1.7809573411941528\n"
     ]
    }
   ],
   "source": [
    "loss1,par1=modelcnn.train(traindl,epochs = 500,learning_rate=0.00005,lam=la,opti=optim) #110-0.001 #500-0.0005 #500 - 0.0001 #500 0.00005\n",
    "loss+=loss1\n",
    "par+=par1\n",
    "print(test(modelcnn,valdl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "47f37250",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(modelcnn,'D:/Saarland University/NNTI/project/models/modelcnn.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "eec743b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelcnn=torch.load('D:/Saarland University/NNTI/project/models/modelcnn.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3623f5fb",
   "metadata": {},
   "source": [
    "#### Training curves\n",
    "The following shows the training curve for the CNN based model trained with the optimal hyperparameter values. It can be observed that the loss reduces with time and also the norm of the gradient of the weights also comes closer to 0 after convergence. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "7ba73af1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x504 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot(loss,par)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "f791fc6a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T-SNE plot on the training dataset: \n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"T-SNE plot on the training dataset: \")\n",
    "tsne_map(traindl,modelcnn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "996f82f9",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T-SNE plot on the testing dataset: \n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAmYAAAJcCAYAAABTzWhBAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAgAElEQVR4nOzdeZzU1Z3v/9epvemFpelmx0YQ2SKIKDoYRRnEbBpM9BdNxolBDflN7s0ksyQzv5k7N3eWODN3Ep2YGW8cY2Iy0dFcDWoUoiguHRRbBEIabNkUaOkNGuilqms5vz+qq+jq/lZv1d1V1f1+Ph48oM73W6dOC1Z96pzP+RxjrUVEREREss+V7QGIiIiISJwCMxEREZEcocBMREREJEcoMBMRERHJEQrMRERERHKEAjMRERGRHKHATERkGBljXjfGfDHb4xCR/KDATERymjGmpcuvmDGmvcvjz6d5zt3GmHeNMWeNMSeMMc8aYwo7r/2ss5/lXe5fYIyJdHn8ujEm2O21nxrmn3OeMUaFJUXGOE+2ByAi0htrbVHiz8aYI8Cd1toX091vjFkDfBu43lq72xhTCnyq222ngL8DPt7LS2+01v54sOMWERkMzZiJyGhzKVBprd0NYK1tstb+2Frb2uWeh4EVxphVmb6YMeZOY8yrxph/M8acNsbsM8Zck+ZelzHmfxhj3jfG1BtjfmyMKem8/GrnPYkZukszHZuI5B8FZiIy2rwBfMIY8zfGmN8zxvgd7mkB7gH+fohe8/eA/cBk4G+Bp4wxExzuuxP4ArAamAtMBO7rvHYVxGcIO3+9NURjE5E8osBMREYVa+024LPEZ86eBxqNMf9sjOn+fvdvwAXGmLVpuvo3Y0xzl19/08vLfgh831obttb+HDgEfMzhvs8D/9tae9haexb4S+A2h7GJyBilNwMRyVvGGHe3BP3pANbaX1lrP0l8Ruom4C7gjq7PtdYGieeZ/V2a7v9fa+2ELr++3ctQjllruybuvw9Md7hveue1rvf5gLJe+haRMUSBmYjkLWtttMvSX5G1trbb9Zi19gVgG7DEoYv/IB4U3ZDhUGZ2ezwbqHW4rxY4r9t9HUADoB2ZIqLATERGF2PMemPMLcaYiSbucuCjxHPPUlhrw8R3cH4zw5edZoz5qjHGY4z5HPH8sc0O9z0KfMMYU2GMKSae4/aotTYG1APWGHN+hmMRkTymwExERptmYCNwADgD/AT4B2vtf6W5/2fEg6LuHui2TLqjl9f8DbAYOAn8T+Az1tpTDvc9CPwX8BrxPLSzwNcAOnPOvgO82ZnTtqL3H1NERiOTmhYhIiIDYYy5E/iCtXZ1tsciIvlPM2YiIiIiOUKBmYiIiEiO0FKmiIiISI7QjJmIiIhIjhgVh5hPnjzZVlRUZHsYIiIiIn16++23G621joWlsxqYdZ4l9x/ECz9a4EvAu8S3k1cAR4Bb0mw7T6qoqKCqqmpYxyoiIiIyFIwx76e7lu2lzPuAzdbaBcBSYB/wLWCrtfYCYGvnYxEREZFRL2uBmTGmBLgKeAjAWtthrW0GbiReEJLO3z+dnRGKiIiIjKxszpidT/x8uIeNMe8YY/7DGFMITLHWfgjQ+Xu505ONMXcbY6qMMVUNDQ0jN2oRERGRYZLNHDMPsBz4b9baN40x9zGAZUtr7Q+BHwKsWLFCNT9ERETGkHA4zLFjxwgGg9keSlqBQICZM2fi9Xr7/ZxsBmbHgGPW2jc7H/+CeGBWZ4yZZq390BgzDecz7ERERGQMO3bsGMXFxVRUVGCMyfZwerDW0tTUxLFjx5gzZ06/n5e1pUxr7QngqDHmws6mNUA18DTwh51tfwhsysLwREREJIcFg0FKS0tzMigDMMZQWlo64Bm9bNcx+2/AfxpjfMAh4A7iweLjxpgNwAfAzVkcn4iIiOSoXA3KEgYzvqwGZtbaXcAKh0trRnosIiIiItmW7TpmIiIiInnp6NGjXHPNNSxcuJDFixdz3333ZdxntpcyRURERPKSx+PhX/7lX1i+fDlnz57lkksuYe3atSxatGjwfQ7h+ERERERyUsu+rTRXPkz0bAPu4jImrLqDooWZZU5NmzaNadOmAVBcXMzChQs5fvy4AjMRERGRdFr2beXki/diIyEAomfrOfnivQAZB2cJR44c4Z133mHlypUZ9aMcMxERERnVmisfTgZlCTYSorny4SHpv6Wlhc985jPce++9lJSUZNSXAjMREREZ1aJnnY9uTNc+EOFwmM985jN8/vOf56abbsq4PwVmIiIiMqq5i8sG1N5f1lo2bNjAwoUL+cY3vpFRXwkKzERERGRUm7DqDozHn9JmPH4mrLojo34rKyv56U9/yksvvcSyZctYtmwZzz33XEZ9KvlfRERERrVEgv9Q78q88sorsdYOxRCTFJiJiIjIqFe0cM2Q7cAcTlrKFBEREckRCsxEREREcoQCMxEREZEcocBMREREJEcoMBMRERHJEQrMRCSrIuEjhNo2EWp9lFDbJiLhI9kekohIv9x3330sWbKExYsXc++99w5JnwrMRCRrIuEjRDt2gG2LN9g2oh07FJyJSM7bu3cvDz74IDt27GD37t08++yzvPfeexn3q8BMRLImGt4NRLu3draLiAydLVtrWX/bNlat3cz627axZWttRv3t27ePyy+/nHHjxuHxeLj66qt56qmnMh6nAjMRyZ7ETFl/20VEBmHL1lru+e5e6uqDWAt19UHu+e7ejIKzJUuW8Oqrr9LU1ERbWxvPPfccR48ezXisqvwvItljxjkHYWbcyI9FREatBx6qIRSKpbSFQjEeeKiGdWumD6rPhQsX8s1vfpO1a9dSVFTE0qVL8XgyD6s0YyYiWeP2LgXc3Vs720VEhkZ9Q3BA7f21YcMGdu7cyauvvsqkSZO44IILMuoPNGMmIlnk8VYAnblmtg3MONzepcn2XHKgsZaq4zW0dgQp9AVYMWM+8yYP7pu2iIys8rIAdfU9g7DyskBG/dbX11NeXs4HH3zAk08+yfbt2zPqDxSYiUiWebwVORmIdfXm+y/zu4Yg1hoAWjuCvP7+XgAFZyJ5YOOG+dzz3b0py5l+v4uNG+Zn1O9nPvMZmpqa8Hq9/OAHP2DixImZDlWBmYhIb46erGT/yXNBWUI0FqPqeI0CM5E8kMgje+ChGuobgpSXBdi4Yf6g88sSXnvttaEYXgoFZiIivTjiaSIS8Tlea+3ILD9FREbOujXTMw7ERoICMxGRXoS9XtxeiIZ7Xiv0OeenHPng13ww7gyRwkI8ra3MbiuhYvZ1wzxSERkNtCtTRKQX3nCYiVPApK5kYoxlxYye+SlHPvg1hyeGiBQVgTFEioo4PDHEkQ9+PUIjFpF8psBMRKQXFZFSSkqilM4Atzfe5vFYFpcFHPPLPhh3Buv1prRZr5cPxp0ZieGKSJ7TUqaISC9mTVoFJys5UthE8YVevOEwFZHSeLuDSGHhgNpFRLpSYCYi0odZk1YxK/GgoPd7Pa2t8WVMh/a+nisioqVMEZEhNLutBBNO3SlgwmFmt5VkaUQiMly+9KUvUV5ezpIlS4asTwVmIiJDqGL2dcw55cfT0gLW4mlpYc4pv3ZlioxCX/ziF9m8efOQ9qmlTBGRIVYx+zoqEg+0fCmSE45UvsDuxx+kramecaXlLL3lLipWrc2oz6uuuoojR44MzQA7KTATERGRUe1I5QvseOifiXaEAGhrqmPHQ/8MkHFwNtS0lCkiIiKj2u7HH0wGZQnRjhC7H38wSyNKT4GZiIiIjGptTfUDas8mLWWKyKh0IlLLwUgNIc6dZ+knwFzPfKZ6cv+8PBEZOuNKy2lrqnNszzUKzEQkr52JHOVkpJqGfUcpO/UBRe4QLdEAhyfOwS6cmnJviCD7I3sBFJyJjCFLb7krJccMwO3zs/SWuzLq99Zbb2Xbtm00NjYyc+ZMvv3tb7Nhw4aM+lRgJiJ560zkKA3hXZzcX8es0wfxemIAFHuCLDz9LtX7gG7BWYwYByM1CsxExpBEgv9Q78p89NFHh2J4KRSYiUjeOhmpxhKl7NQHyaAsweuKMefUIQ4ztcfzui5visjYULFqbc7twHSi5H8RyVsR2w5AkTvkeL04TbufwLCNSUQkEwrMRCRveUy8emtL1O94/axDuwsXcz3zh3VcIiKDpcBMRPLWJM8iDG4aJs4mHEt9OwvHXHww8YKUNj8BFniWKL9MRHKWcsxEJG+VeGYB4F5YzdF9JHdltkYDhCZfzdUXXZvlEYqIDIwCMxHJayWeWZR4ZlFx8bm2ydkbjohIRrSUKSIiIjJIzc3NfPazn2XBggUsXLiQ7du3Z9SfZsxERNJ4pnIzrvkxAkWGYIslVuPiU6uuz/awRCSHfO1rX+P666/nF7/4BR0dHbS1tWXUnwIzEREHz1RuJrDU4vbEFxYKig3RpZZnKjcrOBPJQ12PaRuq49nOnDnDq6++yo9//GMAfD4fPp8voz61lCki4sA1P4bbY1La3B6Da34szTNEJFediNSyP7I3WVw6cTzbiUhtRv0eOnSIsrIy7rjjDi6++GLuvPNOWltbM+pTgZmIiINAkRlQu4jkroORGmKkfqlKHM+WiUgkws6dO/nKV77CO++8Q2FhIffcc09GfSowE5F+ORGppTK4jZeCm6kMbsv4m2auC7bYAbWLSO5KdwxbpsezzZw5k5kzZ7Jy5UoAPvvZz7Jz586M+lSOmcgYtetgLS9U1XC6Ncj4wgBrV8xn2VznfIvHf/07fvzwUZobYfxkWHt7kPA1ewFGbbHWWI2L6FKbspwZjcQ3AFCWxYGJyID5CTgGYZkezzZ16lRmzZrFu+++y4UXXsjWrVtZtGhRRn0qMBMZg3YdrGXT63sJR+NT+6dbg2x6PR5odQ/Otmyt5Qf3HSXceezk6QbYdD9ADO81NaM2MPvUquu1K1NklJjrmc/+yN6U5cyhOp7t+9//Pp///Ofp6Ojg/PPP5+GHH86oPwVmImPQC1U1yaAsIRyNsaVqX4/A7IGHapJBWfLeELzwCCy7JrNlgFyXEoQVoJkykTyV+AI51LsyAZYtW0ZVVVXG/SQoMBMZg063OgdUZ1vDnIjUprxZ1Tc433u6MfNlABGRkTLVMz0vZviV/C8yBo0vdA6o/OPosUupvMz53gmTGZJlABEROUeBmcgYtHbFfFzu1DaXG+Yu7blLaeOG+fj9qW8VXj988Y5ZefHtU0Qkn2gpU2QMWjZ3OjUd1by7O0KoLT5TNncpTJ3Tc3ly3Zp48PXAQzXUNwQpLwuwccP8ZLuIiAwdBWYiY9RVFyyifM7eHkUXI0R65JmtWzNdgZiIyAhQYCYyRiUCr5rIPiKEk+1RIuyPjO4aZSIiuUo5ZiJj2FTPdNy4OXEYKn8JL/08/nvt4cyPKhERGe02b97MhRdeyLx58zI+iilBgZnIGPf+4SD7d0CoLf441Ab7d8TbRUTEWTQa5Y/+6I94/vnnqa6u5tFHH6W6ujrjfhWYiYxxh3ZDLJraFovG20VERou3ntnMX1/7ab668Ar++tpP89YzmzPqb8eOHcybN4/zzz8fn8/H5z73OTZt2pTxOBWYiYxxwbaBtYuI5Ju3ntnMz//6Hk7VngBrOVV7gp//9T0ZBWfHjx9n1qxZycczZ87k+PHjGY9VgZnIGJeu2Gy6dhGRfPP09x4gHExNzwgHgzz9vQcG3ae1tkebMWbQ/SUoMBMZ49aumI/X3a2ArNvF2hWq6i8io8OpD+sG1N4fM2fO5OjRo8nHx44dY/r0zHeyKzATGeOWzZ3OjVcuSc6QjS8McOOVS3ocZi4ikq8mTpsyoPb+uPTSS3nvvfc4fPgwHR0dPPbYY9xwww2D7i9BdcxExqgTkVoORmoIEcQ/I8AfnDe/17plKfcTYK6n9/tFRHLFDV/fyM//+p6U5UxvIMANX9846D49Hg/3338/69atIxqN8qUvfYnFixdnPFYFZiJj0IlILfsj56r+hwj2WlR2oPeLjIQzkaOcjFQTse14TAGTPIso8czq+4ky5lz6qeuBeK7ZqQ/rmDhtCjd8fWOyfbA+/vGP8/GPf3wohpikwExkDDoYqelxFFOMeFFZp0BroPeLDLczkaM0hHdhidd6idh2GsK7ABSciaNLP3V9xoHYSFBgJjIGhXAuHhsi6Lhk2dv9ItlwMlKdDMoSLFFORqqT17vPpGmGTfKBAjORMchPwDGo8uB1XLL04E05T7NrPyLDoa8gKmLbHZ+XmDnrPpPWHm2iJXZUM2yS8xSYiYxSuw7W8kJVDadbg4wvDLB2xfzkTsu5nvkpARiACxcW67hkaXDhwtXj/rkeldSQoee0TFkffpuG8B7KvBdR4pmFxxSkCc6M40za2dj7gO3RfjJSrcBMcooCM5FRaNfBWja9vpdwNB5InW4Nsun1vXxQd4p3jzZwujVIcaGXORe5mDwnklyyrI7scewvSoRFnou0K1OGVddZMieWMPXht2kM/5ZC13Ra7NEeQVj34Kuv9q6vpaVOyQUKzERGoReqapJBWUI4GmPH/nPFEM+2htm3w8WNvouSM2mJwKs7PwGmeqYnA7FEHlp1ZI+CNBkS3WfJehOjg5bYUXxMJERjRq/rMQWOr6+lTskWFZgVGYVOt/YvKT8cjfFCVU3y8VzPfFzd3ha6L1kmSmckArhEHtqJSO0QjFzGKqdkfgATCmLbQz3aLVFCNGX8upM8i9K+ftfNBCJOgsEgl112GUuXLmXx4sX8zd/8TcZ9asZMZBQaXxjod3B2ujV1J2ZXHrzM9yxMmQ1T6QwZDmmXL31+0p0+aK0l3dGEiRy09LlocYnZsN42E4ik4/f7eemllygqKiIcDnPllVfysY99jMsvv3zQfSowExmF1q6Yn5Jj1pviQm+PjQAJEcJUR/ZwMFKTXK5U6QwZHgbnPDCLq6ODmL/nDuCmBqipdvF7q1P/7XpMARWBdcnHB9t/hXXYVQyGA+2/xGMKMHgd70ksdUr+C9btpP3IFmKhZlz+CRRUrCMwZXlGfRpjKCoqAiAcDhMOhzM+yFxLmSKjkNP5l5ctmOV4WPmEaRFe+2WMl34Olb+EE4d79td1uTJdiQyVzpDMpEvaNwSOfQDR1GXGUBCeeMTDE494u93tTi5PQjx3zBLp9TUjtr3zntQP1O59Sf4K1u2k9b0niYWaAYiFmml970mCdTsz7jsajbJs2TLKy8tZu3YtK1euzKg/zZiJjFLL5k5n6nl02UnZwOrJM9jxTkOyhMaFs8qoeu8osc7PvFAb7N8R//PUOan9JZYr05XaUOkMyURvS45t51+AiUSIRWPg8dLUGA/Ktr/iwZhzz31jW4Bf/NRLQ8PvKC87yMYN87lwVTXpg76uLC58uIxbuzJHofYjWyDWbUY0Fqb9yJaMZ83cbje7du2iubmZ9evXs3fvXpYsWTLo/hSYiYxSTudbumYf5w/OX5LMBfvH/9qaDMoSYlE4uLtnYJboY6pnOs3RU9Taczs8p5oZyi+TjEzyLKI+/HbPC53LQtbrJdJh+Y/vxgMygKsXn+CL1x2meEeQV/bN4aFNFYQ64h++dfVB7vnuXn54RXvaPLTuYnRwfuDTQ/LzSG5JzJT1t30wJkyYwOrVq9m8eXNGgVnWlzKNMW5jzDvGmGc7H88xxrxpjHnPGPNfxhhftscoko96S9KHeOB2ttUp7yY+c5bOiUgtJ+zx1DZ7XLsyJSP9mZny+gw33x5flrx68Qm+esO7TC6O5zb+5NdTCHWk3h8KxWhu6n++j/LJRi+Xf8KA2vuroaGB5uZ4cNfe3s6LL77IggULMuoz64EZ8DVgX5fH/wh8z1p7AXAK2JCVUYnkub6S9A9GavCPc37ujAvS99tXwCcyWP0JjErLAGP54nWHCHjP/TtsPO2c4/jYj90OrQblk40tBRXrwJWaj4jLG2/PwIcffsg111zDRRddxKWXXsratWv55Cc/mVGfWV3KNMbMBD4B/D3wDRPfynAtcFvnLT8B/ifw71kZoEgeS3ceZiJJP0SQuUvjOWVlM+H8ZRAYF58t8/rT96tdmTJcJnkW9Vlk1hj46dMRJryVWtts8vggDad7BnY11W7olvxf7DqPAnepqvyPIYk8sqHelXnRRRfxzjvvDMUQk7KdY3Yv8OdAcefjUqDZWpv4v+gYMMPpicaYu4G7AWbPnj3MwxTJP30l6fsJMHVOkEAhFE8Cd+e7QaCw9377CvhEBisRGPV2LJPBS5n3IqL+vSn5Qbdfe4j7n11AKHxuhsznh5tv77lc327rmOJZpkBsjAlMWZ5xIDYSshaYGWM+CdRba982xqxONDvc6ridxlr7Q+CHACtWrOjPlhuRMSWRjN/1fMtSU5Y8SslDfFp/Qnn/+0wcv6RdmTJcSjyzkgFT97Mri1sLcB2oJBx6FeMZB7gITZpIcOZslq7w84Nb2nniPwv49a/clJcFWP8HZ3rUOIN4eYxE/bLETJnOyZRckc0Zs1XADcaYjwMBoIT4DNoEY4ync9ZsJqCMYpFB6n6+ZdeAKkIYg8H2q5RAXNczMWsi+4h0FuQ0nemqXU8Q0BmakqmuQVqyDlVnyQMbaSNUWkbbeedDZ30+X5GHL3w5xsavzKDd1hGxvRdYTpyH2R5toiV2VOdkSk7IWvK/tfYvrLUzrbUVwOeAl6y1nwdeBj7bedsfApuyNESRUcUpaX8gQZkbT0qQFeuSBxQlwr7Ib6mO7NEZmjIsnOpQBWfMTAZlCZYoZ2NH+n2UUvz+93VOpuSMbOeYOfkm8Jgx5u+Ad4CHsjwekVGht+R8Fy7HI5m6Xr+wy461/gZ52ThDc9fBWl6oqkkW0V27Yj7L5mrWLt851ZuK+XrZpdLNb7a5eOIRD02NhtLJlptvj3RZ5nT+gqJzMiUbciIws9ZuA7Z1/vkQcFk2xyMyGvWWtD/XMz9lCbKAcTRzMnlP1wKyJyK1A9qBOZK7Nd+s/R1NE46y/AYItsGhXUE2vb4XQMFZnnP5J/QIzlwdIcczNLv7zTYXP7rfS0consbc1GD40f1eINwZnDmf06m6ZpINuVDHTERGwFzPfFzd/pdPJO1P9UxnVWA11wauZ65nPmdI/QBMFJBN5KkNxEjt1jwRqeVMyVEChfGSCgWFsGAlTJoZ44Uq1VjLd051qALHazE2dc+YdZj8euIRTzIoS+gIGZ54xIPBjZ9S59c0UzIbtIx67777LsuWLUv+Kikp4d57782oz5yYMROR4ee0S9MpOb+vArLpljydNhKM5G7Nmsi+ZMmPBLcnXp9t+ybVWMt3TnWoJk1eTYevjJORasKxdpoaDO/sgKt+39J1Iq2p0bn6/8lGF2Xej8RzyRwCunZbNxw/iowiF154Ibt2xTeKRKNRZsyYwfr16zPqU4GZyBjSdZdmOoMtIOvGk9ylCYz4rsyur91VYByML1SNtdHAqQ5VgPjOyfW3baOuPv5v9MD+CDffHqF0MjSfNJSX+aiv7/nvo7wsQIlnlvMZnSjHbLQ50FhL1fEaWjuCFPoCrJgxn3mTh+79aevWrcydO5fzzjsvo360lCkiKQa79Ng1MOq6RJptoTZYu0I11ka7+oZzXxy2v+LhGxsC/Ogvmyl6523+YNUu/N7UXZd+b5QvrHqbU29+h0DTacc+lWM2ehxorOX19/fS2hH/d9LaEeT19/dyoHHodo0/9thj3HrrrRn3o8BMRFI45aINVDbOznQ7LABEI9DRapT4PwaUl6V+obh68Qm++ql3KZ8QYvVH6vnqJ/dTNj6IwVI2PshXP7mf1R+pJxZqpuBIDb7GppTn6+zM0aXqeA3RWGoaRjQWo+r40LxPdXR08PTTT3PzzTdn3JeWMkUkRfdctN6k2+kJI3925oWeRVRH9qS0uT1w+fSPjOg4JDs2bpjPPd/dSygU//C9fc0hAr5zH8SrP1LP6o/U47gDMxahsPZDYmUzVfl/lErMlPW3faCef/55li9fzpQpmW8YUWAmIj10zUWrDG5LW2ZjVWB1r9dh5E4D6O/mBhk9gnU7k5sBLiuawD/9yUr+4T9c1DcEKRsfSvOsNEWVQ2epCKwbtrFKdhX6Ao5BWKFvaPJPH3300SFZxgQw1mlvcZ5ZsWKFraqqyvYwREal7kc5QTyHbKqZQZNtcAzKXLhY4FkC0OO5AB68zPcsVNAkg5Y4oinlNACXl8ILbiIwZTmn3vyOY1HadDXLEu0u/wQKKtblxWHXY92+fftYuHBhv+5N5Jh1Xc50u1xced6SjDcAtLW1MWvWLA4dOsT48eP7NU5jzNvW2hVO/SnHTER6NdUznQWeJckZMD8BppoZnLDH086ULfAsYapnumPpDYhvFNBxTZIJpyOaiIXj7TjXPcPlxTd1Zc92IBGsxULNtL73JMG6ncMwasmWeZOnc+V5S5IzZIW+wJAEZQDjxo2jqanJMSgbDC1likifupfZqAxucwy4EsubCb3lmcWIUR3Zw8FIjZYcZcCcZ8POtXevewYGYmEip/bjK7+EyKn959p75JzFAzzNmo0u8yZPH9LyGMNFM2YiMmD9TfjvT+mNEEGqI3vYH/rdkIxNxgaXf0Kf7YEpy7vMnJ2bEeuof5uCinWUXvWPpMs5Sxf4iQw3BWYiMmDpAq7u7QMpvVFrj2ppU/ot3VJlQUVqAn9fS579CfBERpICMxEZsN7O3ewqkZ/mVGPMyUjXPpP8FZiynMILbkoGUC7/hGTif1d9LXn2N8ATGSnKMRORARtIaYpEflrXshnpjHTtM8lvTkc0defyT3AMzhIBndMZnNqVKdmkwExEBqU/52463X8iUtujEGzCYI+DEkmnoGKdY1mNrjNi/QnwREaKAjMRGVFTPdNpjp6i1h5NaXdaChXJlGbEZLhVVFRQXFyM2+3G4/GQaV1VBWYiMuIW+BczITJRVfplRIzEjNiZyFFORqp1pNMY9fLLLzN58uQh6UuBmYhkxUCXQkVy1ZnIUerDO0mU3ojY9s7HKDjLIfkSPCswE5FR5WhoD22xw7iwxDCMc81hlv+ibA9LRrHG8G/pWQ/N0hj+bU5+8I9FZyJHaQjvwhIF4sFzQ3gXkHnwbIzhumezMP8AACAASURBVOuuwxjDl7/8Ze6+++6M+lNgJiKjxtHQHtpjh3B3PnZjaY8d4mgIBWcybGJ0DKhdRt7JSHUyKEuwRDkZqc44MKusrGT69OnU19ezdu1aFixYwFVXXTXo/lTHTERGjfhMWSpXZ7vIcPE2NlCy+20mvLWdkt1v421syPaQpJuIbR9Q+0BMnx5PySgvL2f9+vXs2LEjo/4UmInIqOFKc7xOunaRTAXrdlL4/iHcHR0YwN3RQeH7h/A2NmBwOixdssFjCgbU3l+tra2cPXs2+edf//rXLFmyJKM+tZQpIqNGDIPbIQiLYbIwGhkL2o9swcRiKW0mFqPg+FEC067P0qiku0meRSk5ZgAGN5M8izLqt66ujvXr1wMQiUS47bbbuP76zP7eFZiJyKgxzjWH9tihlKWAWGe7yHBId+STuyOkxP8ckvi7GOpdmeeffz67d+8eiiEmKTATkVFjlv8ijobQrkwZEWciR4n6/Lg7Qj2u6RD03FPimZUXwbICMxEZVeJBmAIxGX4nI9WYGbMofP9QynKmdbl0CLoMmgIzERGRQYjYdphcRitQcPwDXB0dxHw+2mfMZrKOfJJBUmAmIiIyCO6Ym6grSnhyGeHJZSntIoOlchkiIiKDMK6pDmO77QKORgkc+yA7A5JRQYGZiIjIAEXCRxg/oYCJNozbxsBa3DZGccMJfHUKzGTwFJiJiIgMUDS8G+N2UUiU6TbELBtkug1RMr5IOzLHmGg0ysUXX8wnP/nJIelPgZmIiMhA2TbHZuPzakfmGHPfffexcOHCIetPgZmIiMhAmXHO7dZLQDsyc1IkfIRQ2yZCrY8SattEJHwk4z6PHTvGr371K+68887MB9hJgZmIiMgAub1Lge67L914ApdmYzjSh0j4CNGOHedmOm0b0Y4dGQdnf/zHf8w//dM/4XINXTilwExERGSAPN4K3L7Lzs2cmXG4fZfh8VZkdVziLBreDV3Oyexs7WwfnGeffZby8nIuueSSjMbWneqYiYiIDILHW6FALF+kyQlM294PlZWVPP300zz33HMEg0HOnDnDF77wBX72s58Nuk/QjJmIiIiMdulyAtO198N3vvMdjh07xpEjR3jssce49tprMw7KQDNmIiIiWVG5ew++SYeZMMnSfNLQcXIOq5bqnNfh4PYujeeYpSxnujtzBXOLZsxERERGWOXuPUyYfYiJky3GBRMnWybMPkTl7j3ZHtqoNNw5gatXr+bZZ58dkr40YyYiIjLCfJMO4w+ktvkD8XbQrNlwyJecQM2YiYiIjLAJk+yA2mXsUGAmIiIywppPmgG1y9ihwExERGSEdZycQyiY2hYKxttlbFOOmYiIyAhbtfQiKnfjuCszWLeT9iNbiIWacfknUFCxTsc8jSEKzERERLIgXhqjM9G/EJgFwbqdtL73JMTCAMRCzfHHoOBsjNBSpoiISI5oP7IlGZSFJpVy+qKLObX8Eo753+PXh7ZwoLE2yyOUrr73ve+xePFilixZwq233kowGOz7SX1QYCYiIpIjYqFmIB6UtVXMJeYPgDHg93PelHb2n3pHwVmOOH78OP/6r/9KVVUVe/fuJRqN8thjj2Xcr5YyRUREcoTLP4FYqJngzNngdqdcc7ugojxM1ZEa5k2enqUR5q9dB2t5oaqG061BxhcGWLtiPsvmZvbfMRKJ0N7ejtfrpa2tjenTM/970YyZiIhIjiioWAcuLzGf3/G63wv/+idB1t+2jS1bNXPWX7sO1rLp9b2cbo0vNZ5uDbLp9b3sOjj4/4YzZszgT//0T5k9ezbTpk1j/PjxXHfddRmPVYGZiIhIjghMWU7hBTfhCocdrzc1xH+vqw9yz3f3KjjrpxeqaghHYylt4WiMF6pqBt3nqVOn2LRpE4cPH6a2tpbW1tYhOcRcgZmIiEgOCUxZzuTCK8CmfkSHgvDEI+cykEKhGP/+0L6RHl5eSsyU9be9P1588UXmzJlDWVkZXq+Xm266id/85jeD7i9BgZmIiEiOKfHMotx3McR8WAuN9fCj+z1sfyU1Nby+oYMzkaNZGmX+GF8YGFB7f8yePZs33niDtrY2rLVs3bqVhQsXDrq/BCX/i4iI5KASzyxKPLMA+PO/2EZdfersztWLT/DF6w7R8ZttnFIh2l6tXTGfTa/vTVnO9LpdrF0xf9B9rly5ks9+9rMsX74cj8fDxRdfzN13353xWDVjJiIikuM2bpiPz3/ugPOrF5/gqze8y+TiEIZ4mY3m3z5K9eYfZ22MuWzZ3OnceOWS5AzZ+MIAN165JONdmd/+9rfZv38/e/fu5ac//Sl+v/OmjYHQjJmIiEiOW7dmOg0de/ivR2I0NRq+eN0hAt7UZHavz4W/ZRdvPbOZSz91fZZGmruWzZ2ecSA2EjRjJiIikgduWLuYe38U5ZGnQ5QWhxzvGT/Rx9Pfe2CERyZDSTNmIiIieSCRb3YyUk3M58Pd0dHjntMnQ5z6sG6kh5Y11lqMMdkeRlrW2r5v6kYzZiIiInmixDOLisA6SuasJ9yRupTZEYry4lOHmDhtSpZGN7ICgQBNTU2DCn5GgrWWpqYmAoGB7fzUjJmIiEieCUxZzsl39uBv2cX4iT5Onwzx4lOH2L/nLLf97beyPbwRMXPmTI4dO0ZDQ0O2h5JWIBBg5syZA3qOAjMREZE8tOj6L/LWM5v58bcf4NSHdUycNoXb/vZbYybx3+v1MmfOnGwPY8gpMBMREclTl37q+jETiI0VCszyzJattTzwUA31DUHKywJs3DCfdWtyf/uviIiI9E2BWR7ZsrWWe767l1AonvCZOMQWUHAmIiIyCmhXZh554KGaZFCWEArFeOChmiyNSERERIaSArM8Ut8QHFC7iIiI5BctZeaR8rJAj0NsE+0iIjK2NDW9ymnPCWJeL65wmPGRqZSWXpXtYUmGNGOWRzZumI/fn/pX5ve72LhhfpZGJCIi2dDU9Cqn/A3EfD4whpjPxyl/A01Nr2Z7aJIhzZjlkUSCv3ZlioiMbac9J8DtS210uzntOUFpdoYkQ0SBWZ5Zt2Z6vwIxldUQERm9Yl7vgNolfygwyxP9CbQS93TPQ+teVuOj6zYTjZ677nbDa1tUoFBEJF+4wuH4MqZDu+Q35ZjlgUT9srr6INaeC7S2bK11vMdJoqxG96AMIBqFj67bPJw/goiIDKHxkak4vZmPj0zNzoBkyCgwywP9qV/mdE939Q3BHv8fJ6RrFxGR3FNaehUTQ2W4OjrAWlwdHUwMlWlX5iigpcw80Fv9snTLl05Kir2cPqNpbhGR0aC09Col+o9CmjHLA+nqlJUUe3tdvuyupVVBmYiISC5TYJYH0tUvs9b2uXzZVW/LlW73YEcnIiIiQ0WBWZ7w+879VY0v8fKtbyzhbEtkUH0Zk/pYuzJFRERyg3LMclxit2XXmbFgKD71le6Ipr6UlwV46uerh2qIIiIiMkQ0Y5ZlW7bWsv62baxau5n1t21LKYEBve/IdFri7A8dei4iIpKbNGOWRd1nw7oXgoXed2Qm7rn3B/sGtNtSh56LiIjkJs2YZVF/6pOlC6KshfW3bQPg+SfXDOh1dei5iIhIbspaYGaMmWWMedkYs88Y8ztjzNc62ycZY14wxrzX+fvEbI1xuPU2G5bQ23Jl1xMAppT3fxZMZ2aKiIjkpmzOmEWAP7HWLgQuB/7IGLMI+Baw1Vp7AbC18/GolG42rGv7ujXT+dY3lqQNvAaabzaQAE5ERERGVtYCM2vth9banZ1/PgvsA2YANwI/6bztJ8CnszPC4ZeuPtmqy8tSNgQAPPXz1T3KXCTU1QeTy6Kuzu5Kij14PalP8PtdWsYUERHJYTmR/G+MqQAuBt4EplhrP4R48GaMKU/znLuBuwFmz549MgMdImciRzkZqWbu77Xzb8t9PPGImy3PWsrLAqy6vIxfbTnuuCGgt/IYifZYLB6Aff2ri4B4Hlt9Q5DysgAbN8zXMqaIiEgOM9ba7A7AmCLgFeDvrbVPGmOarbUTulw/Za3tNc9sxYoVtqqqariHOiTORI7SEN6F5VwZfoObMu8ySjyzWH/bNsfga0p5PGh78umj/XqdKeWqVSYiIpKLjDFvW2tXOF3L6q5MY4wX+L/Af1prn+xsrjPGTOu8Pg2oz9b4hsPJSHVKUAZgiXIyUg2k3xBQVx/kl8/2LyjrrR8RERHJXdnclWmAh4B91trvdrn0NPCHnX/+Q2DTSI9tOEVse6/tvdUYi/X/WEzVKhMREclD2ZwxWwX8AXCtMWZX56+PA/cAa40x7wFrOx+PGh5T0Gv7YKv5d6UkfxERkfyUzV2Zr1trjbX2Imvtss5fz1lrm6y1a6y1F3T+fjJbYxwOkzyLMLhT2gxuJnkWJR93PbC8L16P4aYbZjGlPIAx8QPO/T4X/+uePY5HPImIiEjuyoldmaNRsG4n7Ue2EAs14/JPoKBiHYEpyynxzALiuWYR247HFDDJs4gSzyzHA8v7ErOWjyyeyJ/+98X9OuJJREREcpcCs2EQrNtJ63tPQix+fmUs1Bx/DMngLBGgdeV0RFNfotH489atmd7rEU8KzERERHKfzsocBu1HtiSDsqRYON7ei952UqYrLtv1ef054klERERylwKzYRALNQ+oPSHdTsqSYk+vuywT1/pzxJOIiIjkLi1lDgOXf4JjEObyT0hW/e+eX3YmcpR/+EEbHl8HTY3wxCMetr/iwe2G9vYoZ85GHF+r6w7MjRvm98hR0w5NERGR/KHAbBgUVKxLyTEDwOWF2ZemVP2P2HYawrtojzbREjuKNxBvn1wOX/pqhPElXra/4uH0mbDTy+Byncshg3MJ/jqGSUREJD8pMBsGgSnLAXrsyjwxvgFre1b9Pxt7H0g9GssfgNu/DFuedQ7K4FzB2e67LxWIyWiy/4l7qd78NKFQFL/fzaLrb2DBzX+c7WGJiAwLBWbDJDBleTJAS4i0/zLN3c7nlYZj7ZQUF6edMetKuy9lNNr/xL3sfuap5JeQUCjK7meeAlBwJiKjkpL/R1C6qv/gvOWyqQFaWsN4Pb1syexCuy9ltKne/HSPo8hisXi7iMhopMBsBKWr+l/sOq9HeygY3wAQjUIkem5GraTYQ0mx80Sndl/KaBMKRQfULiKS7xSYjaASzyzKvMuSM2ceU0CZdxlT/Mso8y6jsR5sDBrr4Uf3x3dlAtguK52hjhi/f820HudpaveljEZ+v3tA7SIi+U45ZiOsa9X/+LFNP6Opc4PAtl/N5unflPb6/FAoRuUbDXzrG0u0+1JGvUXX35CSYwbx3ciLrr8he4MSERlGCsyyxOnYpi+taaG1bT5bd03p9bl1De1cuOq3/OTqRY5HO4lk04HGWqqO19DaEaTQF2DFjPnMmzy4Lw2JBH/tyhSRscJY67wjMJ+sWLHCVlVVZXsYA3Lqze84FqFt6Sjk8/90WY+E565Ky2J870cdGNyUeZcpOJOccaCxltff30u0yz9gt8vFgoZm6p7/BeNijVTM9uL1WDzF5UxYdQdFC9dkccQiIiPPGPO2tXaF0zXNmGVJuuOZxnlbew3KfH7LzbfHTwGwRDkZqVZgJjmj6nhNSlAGQPVvObT1OcqKY8w9z4PbHf8yGD1bz8kX7wVQcCYi0kmBWZakO7ap8bS/570uiFlL6eR4UPZ7q8998EVs+7COU2QgWjuCnD0Fp+ogGga3F6bsP44/EmH2DB9ud2rpFxsJ0Vz5sAIzEZFOCsyyxOnYpmCHi0e2nt/jXmvh58+4HIOw9LXRREZe+KyHpuOR5E7iaBg+rFiNCbbj9x1wfE70bMMIjlBEJLepXEaWBKYsp/CCm3D5JwDxGbSfvrqEV343tce95WWBtDXQJnkWjch4RfrjVJ2he9qqdfuoP381oQ7n57iLy4Z9XCIi+UIzZlnU/dimi1tq2fL2XkKhc0uVifpkJZ74rraTkWoith2PKWCSR7syJbe0tjsfHxYOlPDB/khnjtm55Uzj8TNh1R0jNTwRkZynwCyHJOqQpatP1rUGmkiuaNm3lebKh4mebaCo5C5aTFGPewoiZzjbajn4foSK2T7tyhQRSUPlMkRk0Fr2beXki/diIyEADngv5LWC64gYb/Iejw1ztX2TS1ddoyBMRASVyxCRIXYmcjS+rH5eG/w/N+N68w3cBw4wL/wuAG8VXE2LKWJ8YYC1Ky5i2dxPZXnEIiL5QYGZiPRby76tNB57keMLLuNwk59QOIDf62fOsrVMg2RwNi9cw3lf35Lt4YqI5B0FZjkkfnbmFmKdZ2cWVKxL2Rwgkk2JZcvjn/gCNXUBYjaexB8KG2rqArD4amYeiJfE0E5LEZHBUbmMHJE4OzNRdDYWaqb1vScJ1u3M8shE4porH8ZGQhw+U5wMyhJi1nD4TDGgnZYiIpnQjFmOaD+yhW27J/LIS+fTeDrA5PFBbr/2ENd6t2jWTHJCohBsKGwcr4fCBrd2WoqIZESBWY54qcrH/c8uIBSOF5FtOF3A/c8uAPbzmZXZHZsIxJcno2fr8UfaCXnG9bg+zutj5p0/y8LIRERGDy1l5oifvDQvGZQlhMJuHnn5giyNSCTVhFV3YDx+5h14GVcsknLNbQyXzlyYpZGJiIwemjHLAVu21tJ42ud4rbHZuV1kpCWWJ12VD0PNrzl4/lUEfUUU+gKsmDGfeZOnZ3mEIiL5T4FZDnjgoRrAOW+nvDwwsoMR6UXRwjUULVzDTODybA9GRrUtW2vTnoIiMpopMMsB9Q3BtNc2bpg/giMRSbXrYC0vVNVwujXYWSx2Psvm6sNRhlfl7j2Mn3eYf3rQ0tQITzwS4Z7v7gVQcCajngKzHFBeFqCuvmdwVlLs0ZuQZM2ug7X88rU9RGLxx6dbg/zytT0ACs5kyCVPk7DtlF8ApnMRYXI5fOmr8ZzGBx6q0XuijHpK/s8BGzfMx+9P/avw+118/auLsjQiEfj19nNBWUIkFm8XSThS+QKbvnYLj35hNZu+dgtHKl8YcB9nIkdpCO8iYtuBc0FZgj8AN98e6XV1QWS00IxZDkh8A1Q+heSSMyHb8xMy0S5CPCjb8dA/E+2IH2Lf1lTHjof+GYCKVWuT93WdDfOYAiZ5FlHimZW8fjJSjSXa62uVTo6vLoiMdgrMcsS6NdMViElOKbJnaTElju0iALsffzAZlCVEO0LsfvzBZGCWmA1LBF4R205DeBdAMjhLzJT1pqnRKOdWxgQtZYqIo5XswWPDKW0eG2YlWsqUuLam+j7bnWbDLFFORqqTjz2moNfX6QhBtHmOvrzKmKDATEQcXbrqGj4aepmi2BmwlqLYGT4aeplLV12T7aFJjhhXWt5ne7rZsK7tkzyLMLgd7/OYAmYWXcKqpRdlMFKR/KGlzCHWVy6FSL4oWriGlcCFlQ8TPdOAu7iMCdfoHEw5Z+ktd6XkmAG4fX6W3nJX8rHHFDgGZ11nyRLvkXrvFAFjbf4n8q5YscJWVVVlexg9cikADG7KvMv0BiMiee1I5QvsfvxB2prqGVdazvRlV1C7azttTXUYlwsbi+ErGo+1lnDrWcaVlrP0lruYtHIB+177Oceeeo2Ok2fxTSpm5vqPsvCjt+l9UcYsY8zb1toVjtcUmA2dI8Etab8ZVgTWZWFEIgPXsm8rzZUPEz3bOUu2SrNko036IKs+GVB13VXZffelE5fHi7UxbPTcF1O3z8+cj36Mw689R7Sjo0u7j8s2/HnKa4iMJb0FZlrKHEL9yaUQyWUt+7Zy8sV7sZH4B3D0bD0nX7wXQMHZKOFU4uLA1l8mrzuVvHDafdldLBLu0RbtCHHw5aexsVi39o7kzs3uQWL3oFBkrFHy/xBKt7Oorx1HIrni5Mv/lgzKEmwkRHPlw1kakQy1/gRZiZIXCel2X/ZH96Csa5+JILGtqQ6wyaBwMEVqRUYLBWZDyGlnkcHNJI8q+Evua9m3FRtyrlEWPdswwqOR4dLfIKutqS5Zzd9bWDzo1zMu54+ZcaXlvdZBExmrtJQ5hLSzSPJZc+XDHPBeyFuBj9JiiimyZ7k0+Brzwu/iLi7L9vBkEJyWCceVlnfOUPVHfBbL5fFi3O6U/LHujMsNhpR7jNuNy+MjGuqZztHbGDKZoRPJdwrMhliJZ1bGgVhT06uc9pwg5vXiCocZH5lKaelVQzRCEWfvBifxWsFaIsYLQIsp4bWC6wBYuerT2RyaDEK645LiyfjP97mc2VUsEsZXNB6PP0BbUz3ewmLCbS1guyxTGpi7+lPJTQTewmKioXbHoKwv6eqjiYwFWsrMMU1Nr3LK30DM5wNjiPl8nPI30NT0araHJqPcWwVXJYOyhIjx8lbBVUr8z0Pplglrd23nsg1/xrjSKYDBVzQel6/vMyg7Wk4n/xxp7xaUEZ8pq921PTkrF24947ghoC/d66CJjDWaMcsxpz0nwO1LbXS7Oe05QWl2hiRjRGFFER9ZBoFxEGyDQ7ug7n1oMYPPL5Ls6e24pIpVa5M7Inc89M/E+jl7llh+tDHnMkuJWbmBzMadY7QrUwQFZjkn6vViHNpjXq9Dq8jQOBGpZcFKcHe+IxQUwoKV8T8HG/ueTZHckcgrA+fgyVtYzKav3UJbUz3GZdLumhwM43INKigzLheXf/kvmTzJRXPlw7y/43+rhp6MWQrMcsiWrbWMn2eY7JBe4QoPfElApL8ORmqSQVmC2wNzl8H05vnZGZQMWF+FYI3bTTTUTrj1DJB+5gtgXOmU5KaB/mwWcPv8fQZlTkVo4+OIsePBf+T889yUTYiPSTX0ZKxSjlkOeeChGp54xEMomNreEYLxkanZGZSMCSGCju2BcbBs7vQRHo0MVl81ymws1q+8L+NyddvJOaXP+8/lrTkbVzqFlXd9k8vv/gvHEhrRSJgPjqb+O1QNPRmLFJjlkLr6INtf8fCj+z001sdzaxvr4aHve7QrU4aVSbNxzm+0jJlP+iwz0c8j+OLLm+cKvk5fdgVun7+X+y0Vq9ay9Ja7etzn9vm54it/xY33PZ7MbUs3Uxfq6NmmGnoy1mgpM0fsOlhLoBCCrbD9FQ/bXzn3VzOlXB+OMnzeemYzVa9tYulffAxPQZeNJ1GY69cyZj4ZWI2yc+KHkFvHnLOuOznf+D//4JiTlihv0fUIp67ncO5+/EG2//vf91lLze/r0TQqauidiRxVfUvpN82Y5YgXqmo4/yJwpR4cgNsDGzfow1GGz9Pfe4D3n36Hnf/rGVprm7ExS2ttM7/7lxeZ6tEyZj5xmrHqj7nX3MCtP9vWy27L+E7Oy7/8l44zYl3LW1SsWsuN9z3OrT/bxtJb7uLwa8/3OHLJaQbO7fEye1bql1Dj8TNh1R0D/nlyxZnIUQ61P0d9+O3kmckR205DeBdnIkezPDrJVcb2c2o7l61YscJWVVVlexiDFqzbyYd7f0mxJ8Tm3TN45KXzaWnx4B8Hc5fCf/zt9dkeooxiX114hfMSlzHcv2/7yA9IMtK12n9/d126fX4u2/Bnnc9znnEbVzolGYB1nxFLFJXtXu4ivvuzZ3+JvrqfSpDYlRk92zDgXZlbttbywEM11DcEKS2By4u2MSf6RtoSHG89s5mnv/cApz6sY+K0Kdzw9Y1c+qlz77UDmeVq2bc1OW5XoBhrLZFZU4mtvgY8zgtTHlNARWBdv342GX2MMW9ba1c4XdNSZpYF63bS+t6TlHjjCbkfW3ac37/oQ16ov5B3W6YyvlDLmDK8Jk6bwqnaE47tkj+6H780b82NvP/GS8kdmL1JnE+59Ja70u7qTMx2Xbbhz7jxvseTr+l0ugDEZ876U0utu8HswNyytZZ7vruXUCgehDaehs2nf49rS05zIdW8t/spIovbwG9x4SPS0cGEay3rF62n8vvbeHfzPn7+1/cAcOmnrmffq49R/Yv/pOPkGXyTipmxfhXRy+MJcN2Ds5Z9Wzn54r3YSPy/QSwY/+8dW3lj2qAMSM6giXSnwCzLTu5/Dr9J3SXldcW4svQQh9qns3aFljFleH3mnjuJTT5J8ZRizp44Q+X3t3Fo22Fu+PrGbA9N+skpQDqw9Zc97vMVjU+p4N9VIlgC0s6cJQK4rvelO4S8YtXatLlkXY9ccjrPc6AFZh94qCYZlCVE8LG9ZTVXrI4y+7ZrwB+fFY7RgcsHYCiZPp613/4EV//5WgrGF9Da0Mi+Vx9jz48fJNYRAaDj5Fne/+mLANjLo5yMVFN48DSh7U/HNyYY0+MUBACKei/M7DEFA/oZZexQjlkWbdlai5ezjteKPSFuvHKJShXIsDoTOUrxRywl00owrs4Pqr/5BH/4wz9NWdaR3NZXmYwEjz+QtqRF1wT++IyYU6nr1J2fvc2IgXPOW9ectERA2T0H7UjlC33+LF3VNziXezkbK2Hm+itx+9MX6Pb4PIybOA7jMhRNKaL6F/+ZDMoSYh0Rjj9VCUC0ZjetL/2Y6Nl6wDoHZQAtzu/tAAY3kzyLev+hZMxSYJZFDzxUQ+Np50Rdd2CCgjIZdicj1VhSi316Ah4mXKSTJnLdkcoX2PS1W3j0C6v7vROzramuz2ApId1B4l3b+7qnYtXalHM5x5VO4bINf9avGbeBKC9zTvkodp3BVzqwI8U6Tjov/XacjAda7jffwEQijvd05XrzDXAoDG7wUuZdpl2ZkpYCsyyqbwjyyNbzCXak/jUEO1wUVCgpVIZfujwX5b/ktu4zTQPVW7CU0J8ALt0905ddkQwaE7lrt/5sW7KWWUJfM279tXHDfPz+1PdRDx1cUbSNjqb0M1dOfJOcA7lke0tLv/pxHziA65WX4exZsPGly3LvJcwt+ISCMumVcsyyqLwswCu/i1f0v33NISaPD9F42s+mqgv51u8vz/LoZCzwmALHIEz5L7mtv0uX6Z7bPUBy0j3fLHEOZmI2q2vyfvddmodfez7tK0WeSwAAIABJREFUhoCu+pOD1h/r1sRXF1J3Zf6GOdF91L9YxKybV4G7j046zVi/ivd/+mLKcqbL52HG+lUAhPzFBEI9g70YBhckd2XaUAu+ujNMaJpOUbmOlJL+U7mMLOq+kwjA73fxrW8sSb7RiAynM5Gj1IfeTp07j0G5/xJ9q89hj35hNYOZKYsz3PqzbUD/Eu+dzt9MlNdwCu7SlchIFLHt+joD7Xuwupa+cOHDYrGEceEjRpiu/y0NbjreaqXm/z5JW1M9BaWTmPbplZRefiEA+186xKIDL+KOnQvcoi4P1fPW8slPfH3Ixiyjm8pl5Kju3/LKywJs3DBfQZmMGNd7NbgPvUz00kviu8hazuJ+621c5xfDQgVmuWqwFf4Tz4W+S10k9LXzsrt0y5CJempOr5Pprsy+lHhmpf2i4Viv7KpZLLzqc473nJ6xiGoM895/nUDoLEF/MQfOu5KWmRcP6Zhl7NKMmcgYdaCxlujj/51AqGeys7u4nJl3/owDjbVUHa+htSNIoS/AihnzmTdZXxyy7UjlC2z/978b1HOv+MpfUbFqba/FXxN1yqC32TnDFV/5/3oEVb0Vqe3tdY5UvsDbP/1+spyHt7CEFbf/9yEP0jJ1oLGW19/fS7RL4V63y8WV5y3R/xvSb5oxE5EUiQ+X1Q5BGcQPju7+AdTaEeSVw3t45fCe5H1+t5fLZy/UB9IIq1i1dlCBma9ofHIJMV3w1H3GK93snLew2HHGbc5HP5aSY5ZO19c5UvkCbz74j8Qi53YxhlvP8MYPvwP0zE3LpsS/dX1hkeGiwExkDKo6XkM0FiPoL6bAIZHZXVzG9s57ehOKhnntyG8B9ME0wsaVThnQcqbb5+eSP/hvySXMdHxFJZ2zac7J/Im+jDGOS5yJA8/7Ohaqa4L/7scfTAnKEmw0mnbJNJvmTZ6uf+8ybFQuQ2QMONBYy2O7t/HQW5t5bPc2WjviBTkPnHclUVfq97PEwdGJe/oSs5aq4zVDPmbp3UAOLDcuVzKhvrcdnS6Pl3B7S0rB18OvPc+cj36sR3mNjhbn2dbECQKJg8z7c/B5b+UxBlo6QyTfacZMJE/19yibA421vHp4TzJLqGvAVVe+ECCZyBzylzDjmq9QtHANhV0CuL709z4ZOt0T531FJUTDHURDqeVPuu9y7C3QcfsLepytmZgF65oPdu51+y510Z8E/942Mwy0dIZIvlNgJpKHjmy6j479v2LpeZbQNC8fHG9IWytq+wfVvRZWqCtfSF35wmQCc1HnEs2KGfN7JDmnU+hzrrwuw8vpIPC+Avb0tcOmDKjgq9OB504nCKQbZ/e+uueYARi327E/kdFMS5kieaZl31bsgV/h94ExhoDfMPc8DxMLw45H2XRE0x8fkwioCn2BHrvK5k2ezpXnLekz6HIZw4oZ8wf508hI662if3+OYUro67ilgahYtZaVd30TX9H4ZJu3sITL7/6LnMsvExlumjETyTPNlQ/j6vaVyu02zJ7hYefegeXjfG7p6l6vd01yPtBYy/YPqlMCPe3KzC39qU3W19Jif2fBEn0NVeA0lH2J5DMFZiJ5Jnq2wbHd73Oe2fC7vYSiPXe8+d0DO6hcO9FyX3+LwaYLgkaq4KuIpJc2MDPGuIE7gZnAZmttZZdrf2WtHVx1QxHJiLu4jOjZnjNjHWGTMrORKA7rFJS5jOHy2QuHdZwy8obiUHDNXIlkV285Zv8HuBpoAv7VGPPdLtduGtZRiYxykfARQm2bCLU+SqhtE5HwkX4/d8KqOzCe1ByhWAx8Cz6R/EBNFId12i1Z6Avw0YqPaPZrFBpIjpiI5KbeljIvs9ZeBGCMuR/4N2PMk8CtgBmJwYmMRpHwEaIdO4BovMG2dT4Gj7eiz+efKFvIW1f8EW0xSyB0lgvq9rBo8TUULVyTvKcqTXHYQl+gz7wyyV8D2SkpIrmpt8DMl/iDtTYC3G2M+R/AS0DRcA9MZLSKhncDUQ43e9lVX0BrxEWhJ8ayKb9lwfSKXp+bPCbJAsYQDJRQPecqJpUtZF6X+/7/9u48PO7yvvv9+zuLNNZiS8arsI2IF7AhmIBsQswWbIohxdA2TWnKKRddqJulheZpEprQ5inkHNr0xORp0tKEhJOmEELSJNjPMabYWQBTxxaLiY3B2CAW78aStVnSLPfzxyya0fxGGskazYz0eV0XlzX3/GZ0a5DHn7mX752rrpjqjY1vWiMmUv4GC2bNZrbaObcp2eCc+3szOwj8a+G7JjJOuW7ebAuy7VA1URcffO6K+Nl20Eeg4uCgU4xvPv9jPrj/54R6O+iprGXfWZdxZMZimg/szXhcdUUo5zSmjG9aIyZS3nKuMXPO3ZIeytLaH3TODW87l4j0sypeOjopFcqSos4GPdqoc88W5r+6kUm9HRgwqbeDJfueYubRPXT19fDozl+w7/hBIF4c1j+gpobf51O9MRGREqcCsyJjzB9cSlfE+6/ewICVrm3rQ/hjmcVi/bEIC956NvXYZ9/axb7jB7OKw3oVkBURkdKjOmYiYywQbKQ6uI+usHdF/mTAAjKCVK76ZaHejv5rYrHUtKbqjomIlB8FM5EiaJqzJOc5lDOP7mHBW88SeLqDd2tnULfiNmoWr8xZv6ynsjbjthb4i4iUryGnMs1shZlVJ76+xcy+amZnFbpjZrbazF4zs31m9vlCfz+RsZTrHMqZR/ewZN9TqXVk0Y6jnNh8P517tnjWL4v6Auw767KMNi3wFxEpX/msMftXoNvMlgKfBd4C/r2QnUqcOvAN4DpgCfD7ZrakkN9TZKwtmNbAzUuvyghSC956NmsdmYv00rb1IWoWr2Tqqjvw184ADFd9Bq8u/A2OzOiv4K8F/iIi5S2fqcyIc86Z2Y3A15xz3zazWwvcr+XAPufcGwBm9ihwI/BKgb+vyJhrOnNRalozfb1YuuT6sprFKzMKyUaOH6T9wF66+nqorgjRdOYirSsTESlj+QSzDjO7C7gFuCIxmlXochlnAu+k3X4XuCT9AjO7HbgdYN68eQXujkjhJINU84G99FTWMskjnPlrp+d8rIKYiMj4kc9U5u8BvcAfO+cOEw9NXylor7yPfHIZN5z7pnOuyTnXNH269z9aIuUiOa0558OfwPkrMu5z/grqVtxWpJ6JiMhYGjKYOecOO+e+6px7JnH7bedcQdeYER8hm5t2ew6QXdhJZJw5PH0xryxYxanKWhxwqrKWVxas4vD0xUM+VkREyl/OqUwze9Y5d5mZdZA5WmWAc85NLmC/dgALzexs4ABwM/DxAn4/kZLQfGAvXdPP5dD0czPa2wccuSQiIuNTzmDmnLss8WdtrmsKxTkXMbNPAU8CfuA7zrndY90PkbGmw8dFRCa2fOqYrfJoK/SuTJxzG51zi5xz851zXy709xMptq1v5v7sodpkIiITQz6L///WzP7VzKrNbKaZbQBuKHTHRCaa146/k/M+1SYTEZkY8glmVwL7gZeAZ4FHnHMfLWivRCYgN8h9Wl8mIjIx5BPM6onXENtPvGzGWWbmVc5CRE5Drr9U+ssmIjJx5BPMtgFPOOdWA8uABmBrQXslMgGdM23usNpFRGT8yafy/yrn3NsAzrlTwF+Y2RWF7ZbIxLPi7POA+FozR3yk7Jxpc1PtIiIy/g0ZzJxzb5tZPbAQ0NYwkQJacfZ5CmIiIhPYkMHMzP4E+Evi1fdfAj4I/DdwdWG7JiIiIjKx5LPG7C+Jry17yzn3YeADwLGC9kpERERkAsonmPU453oAzKzSOfcqcE5huyUiIiIy8eSz+P9dM6sDfgo8ZWat6EBxERERkVGXz+L/30p8+SUz+zkwBdhU0F6JiIiInKZIuIVoeCe4brAq/MGlBIKNxe7WoPIZMUtxzv2yUB0RERERGS2RcAvRvu1ANN7guhO3Kelwls8aMxEREZGyEg3vJBXK+lsT7aVrWCNmIiIiImOl58gLnGp5klhvG77KOiY1Xkto5kX53e+6vZ80V3uJUDATERGRktNz5AW6Xv8xxMIAxHrb4reB0MyLhrwfq/IOYVY1Nj/ACCmYiYiISMk51fJkKnSlxMLxdqDrtccAl3V/12s/4FTLk0xa8EEs1EvmdKYff3BpIbt92hTMREbJvuMHaT6wl66+HqorQjSduYgF0xqK3S0RkbIU623L2R4fGXOe96eu2bOF6sUrsUnt43dXpoh423f8IM++tYtoLAZAV18Pz761C8AznCnEiYgMzldZlyOcWfZImpdYmFP7tlF/yV1pa9Ge81yrVkq0K1NkFDQf2JsKZUnRWIzmA3uzrt13/CDPtPyarr4eIB7inmn5NfuOq26ziEjSpMZrwRfMbDQ/g42UDRTrbUutRUuGvOSIW8+RF0axt6NHwUxkFCRDVj7t297eQ8xlvrHEnGPb23sK0jcRkXIUmnkR1Qt/G19lHRAfQcNXMaznsIoK+lqfHXStWqnRVKbIKKiuCHmGsEp/kEd3/iJjyrI36j0En6tdRGSiCs28KGPK8b2nP5f/g82oaJiFv6aG8NEDWXfnWsNWbApmIqOg6cxFGWvMAHxm9EXDqcCVvu5MRERGwD8JoqfyurTyrLkEz5iKc95TnxaoovVX/0/OGmnFomAmMgqSC/fTF/SHoxH6opGM6wauQ0tX4ddfRxGRwZjZ0CvMzFKhDAAXjK9VS5/OND8u0oOLxOucZdVAKyL9SyAyQl47K29eelXq/m/v2JTzsUbm8lUDLp23pFBdFREZF5JBKiefj8p5c1KhzEVjBCYto3rh/IwTAmKR3uyRt8S6MwUzkTKUT3mMXOvOkiFO5TJERHLzOm4pdwmNuMCUyfhranDO4frChI+eJHRuIxFOZF6YYzq0FNadKZiJjMBg5TGSActr3Znf50uFMAUxERFvuY5bqphxMX1Hn89ZxyzS2kakNRGufEGqF/6253PlktwBWkwqlyEyAvmUx1gwrYHLzjqf6ooQEB8pu+ys8xXIRESGkOs4pkjrqxklNHKxihoqz2rEal6j+82f5leQ1heM104rMo2YiYxArmnKc6bG6O1+PHX8R+OUpSyYdtXYd1BEpIwNdhxTegmNniMv0LVvfWpq0gJVhBovxT+ljeQZma6vN+f3SU6NalemSInK96gkr2nK903p4+KZp8Al2lw30b7tvHHiJC8cbs17PdnhyEH2R/bSSw/H3wzw5stGLBDmjNngD6I1aSIy7g12HNN7T38uFaQAcP27312km1Nv/DxjA4BVBHF92SNmvso6ai/6faLhnYkP0+8QCU8t+lmamsoUSUgu6E8/KunZt3Z5HpW0YFoDC6eeiSVuGzCjyuGzzHVnb7b5eO6dg3k9J8RD2auRXfTSw+E3Ydf2CLFAmGlz4qEsn+cQESl3nscxAcn97Mk1Z937N3hMecboO3godbOiYTaYZV7jC1I592KifdvjoQxSH6Yj4ZbR+0FGQMFMJGG4512+fuJAquSFA3YcruDNtsw3kpeOTiLqMt8Qcj0nwP7IXmLE+7B/J8SiUD8LfAP+pg72HCIi5W7gcUxg2RfFwjnLZ6SPkAXPmErlWXOxikogPlJWvfC38dedIjnd2S8aH0ErIk1lyoTWuWcLbVsfItpxjK4Vd2R/qiI+QjVwijMSjWaHOGe8dHQSZ9f1vyF0Rbw/++TaPNBLf3tv4v0m4PWhcZDnEBEZf/I/uBziZ2SmC0w9g1h3NPNoJpejJlqu9jGiETOZsDr3bOHE5vuJdhwFHKHeDs/rKvyBrCnOXOdaDgxi1QHvN5PkTs2BKulvr6yK/xnJsZko13OIiJS7ZImLIeuK+SdlT3n6goTmXQ4WfxN1sQC9b72dCmXJaVAXyzE2lXhcsSiYyYTVtvUhXKR/t878lmfweQSuvmhk0KOU0lUHg/1/qa2KixrOxD9gHjJZy8zL/MAifIm/lvOXgs8PrYdh4Lcf7DlERMqdZ7mMgXxBqhesyZjy9FXWUTHjYnrfeZ7O5ufo3tVC18u7ibz3XuZjY2H6DhwC/AOe1I8/uHTUfo6R0FSmTFjRjmMZt2cffw2A1973YSIVI/vE1BWO8JPXp9B05jIWTGtgURUc697Na8ffwRFfJbFw6pk5d1TOCsTb90f2MuvsHgLEd2Uef1e7MkVk4hhqpMxXWUeg/tyMkwGqz/k9gLyLyYaPHqBq/pq0XZlV+INLi74rU8FMJixXPRXryvwUNfv4a+x/35VEcjwmXYU/QNAfyFrrlX48E5C1SeD1EweYWVs/aDhLBjQWJ/4TEZlAcpXL8FXWUX/JXTlPBsAC+RWTTTxXINhY9CA2kKYyZULad/wgr8y5hKgv87OJ81fQU1Ez5OP9Ph+XzlvCzUuv8lzrldw1OZydniIiEudZLiOtMn+ukwFynYGZpUSq/HvRiJlMSM0H9tI1/VxizrHgrWcJ9XbQU1nLO/M/nLOqfzq/9X+myed4puHcJyIy0SUr8A88xDzZPtzDxi1QhfkrSq7KvxcFM5mQksHoyIzFHJmROVd4pUdVf58ZzrnUlGRfNMIv33yZbW/vocIfoC+az+RnP+2oFBEZXPrRSwPlmuq0QBUuFs4cTfMFqZp/Q8kGsYEUzGRCyjUqVl0RSq392vHUD4k9vRlfRzvhpRcTXnEVBDNr4/RGw/jMMPKvsqMdlSIi8ZIYuUbEhhKoP5e+w9syGxMBDHKPtJUDBTOZkLzOukwPTIHXduN/6v+Hvl7Ci5Z4hrKkmHNU+oME/P4hpyi1o1JEJrqeIy/QvX9DRtX+1OJ9GDJE9Rx5gb6jz2e1V8y4OOOxyXB2quXJvJ63VCiYyYSUDEa5Dizf+di3iPbFa5xFBgllSb3RMLdctJJHd/4i50jczUuvGtWfQUSk3AzcTZkhFuZUy5NDBqhcNc4ira96fo/hhL5SoGAmE9aCaQ05R6663zuS+trVTs7r+fYdP5hzJG7u5Omp0KZRMxGZqIYqHJvPov5c1yTbc+3YzCf0lQKVyxDxMnlK6kvraM/rIcnaZZeddX5qcX91RYiFU8/k9RMHMo50evatXew7fnCUOy0iUroi4RZCCxuovmgpVecvIVBfl3VN/6HlueW6Jtk+VHArdRoxE/HQe+mVVGzZSOR9i3CBIDjnecB5umR9spuXXpUxGvbozl/krGWmUTMRGe8i4Raifc1AGF9lfFmIVVZQeda8+P2ticCUZ22xSY3XZk+Hpj12sOK05UDBTMRD6IKL6a6djJsxC4LBoR+Q4LW+bCR1zkRExoN4KNsORLPuM7+PijMb4sHMP4nqBWvymmocqsbZUMGt1CmYiXhoOnMRvxxBcPKqTzZYaQ4RkfEsGt6JVyhLsoog1ef83rDXfg1W42yo4FbqFMxEPCyY1sAv33x5WI/JVZ9sqNIcIiLj0eHIQfZbgF6royl2kkqPao/mq6ayAIFpsOBW6rT4XySH4YxoVVeEuOys8z3XjC2Y1pC1ISDXtSIi48HhyEFejeyi1/xgRotN8hg38+MPLi1C70qbRsxEcvAa6Roo3+OYBivNISIynhyOHOSVSOaMw3FfJcSg0Z1KjJxV4K+4mECwsSh9LGUKZiPUuWcLbVsfItpxDH/tdOpW3EbN4pXF7paMomSQ2vb2HnqjmTVxDDCzVChLlsBIf5yIyESTHCnzctxXyXFXwRWBxQpkg1AwG4HOPVs4sfl+XCReGT7acZQTm+8HUDgbZ5IjXfuOH8w4JSASjWaFNZXAEJGJzGukbKBKm6RQNgQFsxFo2/pQKpQluUgvbVsfUjAbpwZORX57xybP61QCQ0Qmmp4jL9DZspFAbweLKyo5NOd9tE2blXWdDx/zA9r0NBQFsxGIdhwbtD0SbolvEXbdQJD4xFcfWBX+4FJ9WhgHVAJDRKT/XEpL1Ayr6OtlbstrAFnh7NzA+cwKaEZhKNqVOQL+2uk521PF9Fx3ojUM9MW/dN1E+7YTCbeMRTelgJrOXITfl/nXRyUwRGSi8TqX0heLMfvdN/pv42NJ4AKFsjwpmI1A3YrbsEBlRpsFKqlbcduQxfQgmjiaQsqZSmCIiOQ+fzLY17/cRyNlw6OpzBFIriNL35VZf83NBKZ3po2UDSZMJNxCINiYOe2pqc6yohIYIjLR5TqXMlxRiQ+fQtkIKJiNUM3ilamA1j99OdhIWab4yBqZZ4glpjoBhTMRESl5XudSxnw+js05R6FshBTMRsHQ05ceXHeOx0WJhncqmImISMnzOpeyuvFappfpcUilQMFsmFq2PsXOx75F93tHqTpjBks/9qfMvjCf6UsPuaY985oOFRERKb5yPpeyFGnx/zC0bH2K7d/+Ct3vHQEc3e8dYfu3v0Kkb6Qvo+VorhppF0VERKSMKZgNw87HvkW0L7OwbLSvl90/+dUIn9EB/gFtOtRVRERkolIwG4bu9456tu//2QvEC8kOk1Xhr1jeP0KWuK31ZSIiIhOT1pgNQ9UZMxLTmNnt/oomon3/PYxn86dKYyiIiYiICGjEbFiWfuxP8VdkFpb1B4LMnRHmwNf/jPbnmnGxWB7PZBoZExERkSwaMRuGxhXXAKR2ZU6aPJk503s5o6oLgO5dv8b19TL58sswv8vxLH6FMhEREfGkYDZMjSuuSQW0dx+8hWhH5rqzU3v30neojVm33pt2kLkBTpX9RUREZFAKZqch2nEsZ7vWjomIiMhwKZidBn/t9KwRs3h7Pb3dj+v8SxERERkWBbPTULfiNk5svh8X6a9tZoEKqpsu6K/er/MvRca9l/Yf5KnmvZzs6mFKdYhrmhZx4XydESgiw6dgdhqSh5i3bX2IaMcx/LXTqV62lKoFcwZcmfv8y0i4pX8tmkbXRMrO+ud2s/3Vd1K3T3b18PizuwAUzkRk2BTMTlPN4pWpgAbQ2/V97ws9zr+MhFuI9m3n+Sd288TXn6P1SAf1M2v5yB238sGbbilUl0VklLy0/2BGKEsKR2M81by3oMEsfZQusb0IgEkVAT5y6RKFQpEypWA22qzK+xByj/Mvo+GdPP/Ebn547xbCPREAWg938IMvPYDfP41lN6wudG9FJGEk05FPNe/Ned/Jrp7R7mLKS/sP8vizuwhH43UT04vznOqL8OOnXwY0YidSjlRgdpTFz7nM8/xL180TX38uFcqSwj0R1q97oGB9FJFMyaCTDFPJ6ciX9h8c9HGDha8p1aFR7WO6p5r3pkKZl5gbPDSKSOnSiNkoS64Py2vdmFXReqTD83laDx5mx4ZNGjUTGQUZ034GzpExKuYVdPKZjpxSHcoZzq5pWjSqP0O6fEbjCjliJyKFo2BWAPnWMPMHl1I/s5bWw97h7JG77wNQOBMZgfQwls4l5v3SF+nnCjEnu3r4yg9+kXN685qmRRlTiknLz51b0GnEwQJh+jUiUn40lVlEgWAjH7njVoKh/nz8gdWL+MKG2/inHX/BZ3/4++x/YWMReyhSngZOTeYSjsbYuG3PoCFmsOnNC+c3cONl56ceP6U6xEevvIA1HzpvFH6K3K5pWkTQn/vt22eFHbETkcLRiFmRffCmW/D7p/Hdv/4SH1i9iI99cRUVk4IATG2YzEc+2UQk3KISGiLDMNQarHTdvWGWnz2LF18/MORjvKY3L5zfMOaL7JPfb7R2ZaoOm0jpMOdyHbZdPpqamlxzc3Oxu3Fa7r76Jj7xb9cxtWFy9p1WRWXVjWPfKZEy9cXvbBrW9ckwkx5O8pkqLPcA89L+g2zctofu3nBGe9Dv48bLzi/rn02klJnZ8865Jq/7NJVZItbcuZb6WbXed3qV3xART0PtpPRyqi++M/qapkWpUGY2+GPy3blZqpLTvQNDGfSPDIrI2FMwKxHLblhNuHdgmY0EjxpoIuJtpIFi47Y9GevS8plMKNcA89L+g/zn0y8POnWrXZ0ixVGUYGZmXzGzV83sZTP7iZnVpd13l5ntM7PXzOzaYvSvWCZNuYS8a6CJiKeRBoru3rBnUMln5KycJEfKhgqe2tUpUhzFGjF7CjjfOXcBsBe4C8DMlgA3A+cBq4F/MbMcw0jjTyDYiL9ief8ImVXhr1iuhf8iwzDagcI5uPePVud83nILMPlsjAj6fdrVKVIkRdmV6Zz7r7Sb24CPJr6+EXjUOdcLvGlm+4DlwH+PcReLJt8aaCLiLVdtscEE/T4Cfl9qrVm6SRWBVC0zr8eVW4AZaoRPZ22KFFcplMv4I+AHia/PJB7Ukt5NtGUxs9uB2wHmzZtXyP6JSBkZWEoiHzdedj6AZ6DrDUc9A9uU6hDnzJ3OU817+dEvXy6bXZq5dpyawe9ccUHJ919kvCtYMDOzzcAsj7u+4Jx7PHHNF4AI8HDyYR7Xe66EcM59E/gmxMtlnHaHy0Ak3JLfUU8iE1yytliuka50kyoCqRAX9Ge/BcU8FmMlQ1h6kEs/SWCsw016HbKqyiDOOU71RZhUEcDM6O4Np46iqqoM4rP4eZpJKo8hUjoKFsycc6sGu9/MbgV+E1jp+oupvQvMTbtsDlCee9FHWSTcQrRvG6mc6roTt1E4E8lhqGlNn0FfpH9ELBzN7zPeya6eEZ+vOdqSi/mTfUkvf5E+0pd8l+3uDeP3GZOCfk71RcpmpE9koijKVKaZrQY+B1zpXEaRrvXAI2b2VaABWAhsL0IXS060r5nswUNHtK9ZwUxkEAG/LxVaKgJ+/D5LBZJwJOpZx2sogxWgHetdmsM55SApGnNUBAN84ZZBPz+LSBEUa43Z14FK4CmL70Xf5pxb65zbbWaPAa8Qn+L8pHMuWqQ+lhjvfzwihDnU8yRTA0uYHJjreY3IRDRwJAnAOcdHLj0vNTo03BMCks6ZO53X3jnmGcLGepfmSINguZX5EJkoilIuwzm3wDk31zl3YeK/tWn3fdk5N985d45z7oli9K+c+IGIO8Wx8Eu0R94pdndESsZgU41JIw1Rr71zjGuaFuH3Za75H6X3AAAgAElEQVRJ8/tszHdpjvRnKLcyHyITRSnsypS8VAB9Wa3RxH4JR5T3+nZQ2feCNgWIkHtEKL3daw2azyBUERx0irP/dIDM5QVDnT1ciMPCR1oepNzKfIhMFDqSqUz4Ky5m4P+uGHAyLVtHscSmgO1Ewi1j2j+RUpNPQdgL5zdw42Xnp9omVQRSoWxKdYhJFd6fXadUh3iqeW/GzkaI73TMdURTcmo1GepOdvXwo1++zPrndg/3R8sw8Geoqgym+j2pIkBVZRDoP8FgSnVIOzBFSphGzMpEcgQsGt6Jc91EMU4SoNvX/7/Qn9ocEKWvdQs97zVSs3jl2HdWpAR4jSR5jRQlS2sMXJN2sqsHv8+ySktAfI3Z9le9lw7kGqnLtUh/+6vvcPxkF28ePoFz8QC17Jy5rPnQeXn/rMmfQUTKn4JZGUmeCtAeeYdj4Zdw9O+LMOeY4uJb459/4lU2fv052g53UDf9K9z42TtYdsPqYnVbpCgGFpodaurQKzhFY46KgJ++SOYepBdfP8CkikDOwrNeBlts/8ahE6mvnSMV+oYTzkRkfFAwK0PJ3ZcnIq8QiZ3CT4wpLkI1UZ5/4lV+eO8Wwj3xfzDajrXxyN33ASicyYQznJGkXMFpYCiD+CaCYMBPMK0UBwy+dmuwEhtedrz2joKZyASkNWZlanJgLo2ha2kMXkhDIpQBPPH151KhLCnc08P6dQ8Uo5siZWO4uxS7e8MZa7uGWrs13MX2Q+wjEJFxSiNmZS659qyvdQu+qkm0HunwvK710JEx7JVI+cm1Ji3X4eZTqkPDGpG7cH4Dbx9pzbk2bSDzOqBORMY9jZiNA4FgI7H3Gjn60PeZXO39bl4/e+YY90qkvAzc3ZgcAfvIpUsI+jPfKkdabmLNh87jo1dekPE93jd7que1y85RwWiRiUgjZuNEcvfllW9+jSf+6yiRtA/4wVCINXeuzfFIEUkabARstOqPeX2P9c/tZsdr7wx7V+ZIHycipcuGKohYDpqamlxzc3Oxu1EydmzYxPp1D9B66Aj1s2ey5s61WvgvMs6sf26357To8nMVzkRKnZk975xr8rpPI2bj0LIbViuIiYxzO17zXqs22G7OQpw8ICKjS8FMRKQM5ZrsyNXuVUD38Wd3ASiciZQQLf4XESlDuXZt5mrP51B3ESk+BTMRkTKUa9dmrvZ8DnUXkeJTMBMRKUNrPnQey8+dmxohMxt84X8+h7qLSPFpjZmISJla86Hz8t6Bme+h7iJSXApmIiITwHAPdReR4lAwExGZIIZzhJSIFIfWmImIiIiUCAUzERERkRKhYCYiIiJSIhTMREREREqEgpmIiIhIiVAwExERESkRCmYiIiIiJULBTERERKREKJiJiIiIlAgFMxEREZESoWAmIiIiUiIUzERERERKhIKZiIiISIlQMBMREREpEQpmIiIiIiVCwUxERESkRCiYiYiIiJQIBTMRERGREqFgJiIiIlIiFMxERERESoSCmYiIiEiJUDATERERKREKZiIiIiIlQsFMREREpEQomImIiIiUCAUzERERkRKhYCYiIiJSIhTMREREREqEgpmIiIhIiVAwExERESkRCmYiIiIiJULBTERERKREKJiJiIiIlAgFMxEREZESoWAmIiIiUiIUzERERERKhIKZiIiISIlQMBMREREpEQpmIiIiIiVCwUxERESkRCiYiYiIiJQIBTMRERGREqFgJiIiIlIiFMxERERESoSCmYiIiEiJCBS7AyIiIuPBjg2bWL/uAVoPHaF+9kzW3LmWZTesLna3pMwomImIiJymHRs28cjd9xHu6QGg9eBhHrn7PgCFMxkWBTMREZFh8BoZW7/ugVQoSwr39LB+3QMKZjIsCmYiI6ApC5GJoXPPFtq2PkS04xj+2um8GfkAP35gQ9bI2MBQltR66MhYdlfGAQUzkWHymrJ4+K7/Sc+B3Vy+9jNF7p2IjJbOPVs4sfl+XKQXgGjHUZ54+D8J98Qyrgv39ODz+4hFY1nPUT975pj0VcYPBTORYfKasohEHE88+CPmnXoSf+0M6lbcRs3ilUXqoYiMhratD6VCWVJ7Z3b4AohFYwRDoYz3hmAoxJo71xa0jzL+qFyGyDDlmppo73RA/FP1ic3307lny1h2S0ROw44Nm7j76pv41OJLufvqm9ixYRPRjmNZ102uMc/H1zfM4uP3fJ76hllglrqtJQ4yXBoxExmm+tkzaT14OKs9+YYdmn82Ncub8Nccobf7cfzBpQSCjWPcSxHJV64dlauvnsy5czNHxy9fXsmTT/cSibhUW3JkbNkNq1m8INi/Ju3If9C5J6jRcxkWc84NfVWJa2pqcs3NzcXuhkwQOzZs4uG7/mfGG3MgANdeEeKi1ecw+YrL8AXTP/P48VcsVzgTKbKBC/mTSw7uvvomzw9bddPruP1jwYzpTAtU8lbwKv7rsWdoPXSEiy+eypWXhPBHOnJ+X6usZeqHP6GAJilm9rxzrsnrPo2YiQzTshtW03NgN088+J+0d8aYXGNcvrySJQsrqFneNCCUAUSJ9v030b5mIAxWpVE0kTHmtZD/xOb7gdzLE9qOn2Tqqnuzwty8xSu5fO1n0p4zdygDcL0dqe+lcCZDUTATGYHL136GD1x5YeIN+2iq3V9TPcijwvE/XDfRvu0ACmciY8RrIb+L9NK29aGcyxPqZ8+kZvHKnGHq6OZ/wT/gOXNJfi8FMxmKgpnICKW/YaemSDq7CNTWZF3beyrMVz76PVqPdFA/s5brPvUhLr6+UsFMZIx4LeRPtq+5886sWmRD7ajcsWET08PtYN6bAby/19GhL5IJT7syRUZBzeKVzPmT/6DyjGsAf8Z90UiMn/zDz2k93AEOWg938MN7t/D8xheK01mRCchfOz1n+7IbVufcURkJt9Db/Ti9Xd+nt/txIuEWIF42J7kTezi0W1uGohEzkVGUHAGL9m0D4m/a67/6NDs27EldM+e693Pep1dyatYUtvb8gvmBRcwKNBShtyITR92K2zLWmEF8IX/dituA+NrRgaUtIuGWxLKDaLwhbRlC66EjPP0rP6uvnEQwmP+omaYzZSgKZiKjrD+cxd/Qn31sZ+q+Ode9n4v+9gYCkyoA6KWHVyO7ABTORIapf5flUcBIfhjy2gWZ/NprV2Yu0fBOUqGsv5VoeCd106bw6v424BRXXBLKqG9mg0xv5ppSFUlSMBMpgFQ4C++kfmZtfBoTOO/TK1OhLClGjP2RvQpmIsMwcJdlMpRBfBfke0/+E0BWOBvWaJXrztl++bIKnvgveHV/BOjJe+Qs15SqSJLWmIkUSCDYSGXVjaz5zGcIhkIAVM2a4nltT+xUqtq4iAzNa5dlBhelbetDOe/u3LOFdx+8hbfWXcu7D97ivfbLqryfOuLj3Lm9XHtFfKTsiktCeYWy9KlTkVyKGszM7H+YmTOzaYnbZmb/y8z2mdnLZnZRMfsnMhrSFxZ3Hz7peU334ZOpauMKZyJDy2dKMNc1ydG2+BSoI9pxlPc2/xOtO7+SWtwP4A8uxQ04GjMWjtD+7DNYZQ1LFlbwZ39Qy5Taof8p9dfOYOqqO7S+TIZUtGBmZnOBa4C305qvAxYm/rsd+NcidE1k1C27YTX3/OynLJt3Bb4Bf+0ip/rY/c9bOHd+gNt+O8D017+a+xO8iAD5TQnmusZztC0SpXP7c0T7tqfCWSDYSMe2F4l0dOKcI9LRSfvTz3Jq717MDAtUDtkHC1RyxurPMedP/kOhTPJSzDVm64DPAo+ntd0I/LuLnxO1zczqzGy2c+5QUXooMsqS68j2R/bSEztF9+GT7P7nLdTs3ZOxRiW9KrnezEWyee2yzGD+nNOGuUbSYp1dJBf3J9eJdu/aSfeul7Kv7WlPfB8fWcNqyS7oKCYZgaIEMzNbAxxwzu0csHvlTOCdtNvvJtqygpmZ3U58VI158+YVrrMio2xWoIFZgYaM8/lu/3hNKpS98nofz2zvpb2znZqHvkis4h/43S/8VdZWfpGJLHOX5dC7MtP5a6d7Fnv1JU/uSCz679yzJV5AdrAzpV0MC1RSteQaet7cnveOT5FcChbMzGwzMMvjri8AfwP8htfDPNo8/0Y4574JfBPih5iPsJsiRbPmzrWpauPJrfavvN7Hk0/3EInEr+nsdtDdzvfuuhdA4UwkzbB3WSZ4jrYF/NQsuzj+tVWl1qHlGg1L5yK99Ly5nTl/8h/D7ovIQAULZs65VV7tZvZ+4GwgOVo2B3jBzJYTHyGbm3b5HOBgofooUkzJkBWvIN7JlFrjme29qVCWLhaJ8JN77mXxgqA+hYucpv7Rtm8R7TiBr6aammUXU7VwPuDHH1zKsa1fHHzX5wDRjmPxgrThnfERN6vCH1yqY9dk2MZ8KtM592tgRvK2mbUATc6542a2HviUmT0KXAKc1PoyGc+S1caTn87bO9tzXtveHtG6M5FRkhxtyxWmhlsItur8pTlPCVA4k+EotQKzG4HrgX1AN6CCLzIhJIPW5O/9He3tHkNmwOQaw0V6daSLyCgKBBs9g1OudWhWWQvRvqyjnWqXX0yuUwIUzGQ4il5g1jnX6Jw7nvjaOec+6Zyb75x7v3Ouudj9ExkrNYtX8lt3fxF/MJh1nxlcvjy+NV9HuogUXt2K27LKYVigkqkf/gRTV92Bv3YGYKn6ZBbIsRYt1+kBIjmU2oiZyISWXHf2oy+vo6stXow2VAkrV4RYsjB+lJOOdBEpvKHO1hw4at3b/bh3CMtxeoBILgpmIiVm4LqzgVMmOtJFpPT4gwPWmMVb8QeXFqtLUqYUzERK1FCf2JN2bNjE+nUP0HroCPWzZ7LmzrUqqyFymgZ+MArOqMY39U16Or+P+bJ3XCa/1q5MOV3mBiucVyaamppcc7OWo8nEs2PDplQttHTVdVP46BfuVEATGaF3H7wltfg/NP9sJl9xGb5g+liGH3/FcgUvGREze9451+R1n0bMRMrY+nUPZIUygK62kzxy932AitLKxHS6NcXSN9nULG8aEMpAOy6lUIq+K1NERq710JGc94V7evjuX3+Ju6++iR0bNo1hr0SKKxJuia/3Si7GT9QUSx5Ono/0TTb+5FFNA2nHpRSARsxEylj97Jmp8zbTnTs/wBWXhJhcY7R3dvLcd/4R0OiZjG+de7akzs7MrOYPwx3hSj+2KdrZRaC2Jvsi7biUAtCImUgZW3PnWoKhUEbbufMDrL5yElNqfZgZU2p9rLrUz45v/t8aOZNxK7lYP7kuLNbZRfszW+l+fX//RcMY4apZvJKpq+4A89G5vZlYOLPws4tEtONSCkIjZiJlLDkC9sMvf5XutvhxTldcEiIYtIzrgkHjsmUVPKR1ZzKO9I+QHYtXYR544HgkSueO5/tHzYY5wpXcAX1i8/20P/0sNcub8NdUE+vqxvXMIjSlcRR+CpFMCmYiZS5Z9yxZNmNyTZfndZNrjHBPD+vXPaBgJmWtc88WTvz8X3C9Hf2NOSoMxDqTfx9GVlMsvWzN8e//KGfZGpHRomAmMk4kA9ob//w7+CMdWfe3d8b/4Rpsw4BIqfMqvDwYX031adcUSx54LjIWtMZMZJyZseoTOMv8zBUOO57+VbysRv3smcXolshpi4RbaH32G3mHMgtUUn/Zp6isulFlLaRsaMRMZJxJfrI/uvlf8IXbae+Mh7JX90cIhkKsuXNtkXsokr/kFH3jBVP42N2riHV2Dv4A84FzmnKUsqVgJjIOJade+o9r6qK+YZaOa5Kykn6yxSf+7ToqQgF8NdVp68YyWaCSqavuUBiTsqYjmUREpKQkq/a7aBethzvY+I2t/ME9qzGf0f36ftqf2QqRaMZjfKHJ1F/15wplUhZ0JJOIiJSFVNV+opjPmNowmY99cRVdJ09RU1+VKn3RueN5Yp1d+GpqqL/skwpkMm4omImISEnYsWET885/l7oZmUcgVUwK0tcToe9UmIpJQaoWzk8ENB0kLuOPdmWKiEjRJdeTTZnmXQS2ekqIx+7dTOvhjnjJMqtSKJNxSSNmIiJSNMn1ZO+/qovP/vD3U1OWA7Ue6aDl5XbeeWUes+ZrA4uMXwpmIiIyppJhLP3syuR6skhfhEhfhEBF+j9PfqafdS33/OzPxr6zImNMU5kiIjJmTu76AYf+v7/i8L99g2hXdtmLQEWAnq4wJw6242KOtqNdmrKUCUUjZiIiMiY692yh7effhUgEAF9V7vVkf7fqmwRDIT5+z+eZeXbj2HVSpMgUzEREZEy0bX0oFcoAop1dBGprsq5rPdKhgsgyYSmYiYjImIh2HMu43bm9mclXXIYvqPVkIkkKZiIyJvqPhzpC/eyZqdGQXO0y/vhrpxPtOJq63bP/TQBqP7gMf3V1vARGcKnWk8mEpmAmIgWXfuYhQOvBwzxy93288cLLbPvJxqx2QOFsHKpbcRsnNt+Pi/Sm2nreeofQ+66m6vzfK2LPREqHdmWKSMGtX/dAKnwlhXt62PrYTz3b1697IKNtx4ZN3H31TXxq8aXcffVN7NiwqeB9ltFXs3glU1fdgb92BmD4a2dwxqrPMEWhTCRFI2YiUnCth454tseisSGvzzXaBhpVK0c1i1fqXEuRQWjETEQKrn72TM92n9/7LSj9+lyjbQNH1URExgONmIlIwa25c23GqBdAMBTig791Pdt+spHzr5rH9Z9cQf2sWtqOdtLxXn8wyzXalqtdRKScKZiJSMEkj9654Opuwr2/wRPfeI7Ww+9l7L686LpzmDW/nYpQ/O2oflYt9bN6iYRbCAQbqZ89k9aDh7OeO9conIhIOVMwE5GCiIRbiPZtB6IAXHzd2Vx83YKs43XmnQ+4gW9FUaLhnQSCjay5cy3fu+teYmmFSX2BAGvuXFvwn0FEZKxpjZmIFEQ0vJNkKEtrTbT377R00ezzEoHMA67NMu4aeDv9+bRzU0TKmUbMRKQw0oLVwPb0nZathzuY2jA567K2o13cc/2l+HyWtXszGg6zft0DqV2Z2rk5MXXu2ULb1oeIdhzDXzuduhW3acenlD2NmIlIYZj3AdVYVcZOy43f2ErfqXDGJX2nwvzvrz0NzuVVUmOwnZsaSRufOvds4cTm+xMnCTiiHUc5sfl+OvdsKXbXRE6LgpmIFIQ/uBTwD2zFH1yaEape3LSXx+7dzImD7biYo+1oF4/du5kXN+0d9PnTF//n3LmZGDlrPXgYnEvdVjgrf21bH8o4QQDARXrjB6WLlDFNZYpI3iLhFjpe+SGd258j1tmFv3YqdSv+1HP6KLnAPxreGZ/WTDsHceBOyxc37eXFTXupb5gVD1nODdqPYCiUsfg/185Nn9+XcyRNU5zlbeCB6EO1i5QLjZiJSF4i4RY6dj9C+9M/I9YZX7Af7TjBic3rePnhdZ7ThYFgY3zkzKrAdRMN7yQSbmHNnWsJhkIZz58MWznLYKSt968IVWbclev58pkGlfLkr50+rHaRcqFgJiJ5iYZ30rljB0Qyd1q6SB/2xkbP6cJUyYzkRgDXTbRvO3UzewmGKlLPUV03hY/f83mW3bDaM2T5AgH8gWDqdlfbyYwpyWU3rObj93ye+oZZYEZ9w6z+2x5UA6381a24DQtkBnQLVFK34rYi9UhkdGgqU0Ty47pTI2UD1VZn3k5OF16w8ja8SmbUnnGE7rb2VEtfT/9aoeQU4/p1D9B66Aj1s2fS132KrraTnt8jef2yG1Z7Tk96nTigGmjlLzl9rl2ZMt4omIlIfqwKX021Zzhr78xeExZfK+ZdMqNuRk3G7XBPDz/88lczwljyZACATy2+1PN5Wg8dYceGTVmPg/5gVz1lMsFQBd0nO7KeV8qbDkSX8UjBTETy4g8upWbZMtqfeSZjOjMcgad/1ZN1ff3smam1ZQO1Hu7Iautua0+NoqXXIQMStcyyw1/1lMlZ9cu++9dfyrimq+0kwVCIW//x7xTIRKTkaY2ZiOQlEGyk9ryPM/mKq/HVxOcu/bVT6W64jv0HMj/jBUMh/vC+28CFs56nryfCxm9sHfL7hXt6+NGX1/HI3fd5LuIPhkL09fZm7brM9Vzf/esvqY6ZiJQ8jZiJSN4CwUbql/419Uv72+YAH5+8OGM68Q/vu4155/WSvb6sgsP7q9j1i7fz+n4D15Ul+fw+Pvhb1/PM9388rP7rRAARKXXmhqgXVA6amppcc3NzsbshIgm93Y97ry+zKiqrbuT17Y8zefoxpkyr4uTxbv7fm79P98kcZ2Z6MctZuywf9Q2zuOdnPx3RY0VETpeZPe+ca/K6T1OZIjL6BjknMxJuYd55vdTNqMZ8Rt2Man7zLy/FfJkHk/uDQarqss/QjD+PG3EoA9UxE5HSpWAmIqNvkHMyo+GdDJzivOTG81hz5+UZbf5AACMzrI0W1TETkVKlYCYio26wczJzjaZdfvOFGbf7TmXXLhudvgVVx0xESpaCmYiMukCwEX/F8v6RM6vCX7E8fn5mjtE0rxIahVBZPUkL/0WkZGlXpogURCDYmDrIPJ0/uDR+TFPadGbfqXBeJTRGQ/fJsQmAIiIjoWAmMs69/PA6fC2bqJkUo/OUj1jjai74gzuL1p9kWIuGd8anNa2Kw29Ay8vtqd2Wvd3dGUc2pRiQtpHcFwhgZkTD2fXSctH6MhEpZQpmIuPYyw+vo+rgRoJVBhi1VY7wwY28/DBjHs68jk5adsONACxcDvf87MaMa7PPuKzkrBs+wIFn93Dq8EmmzJrOTX/1SQC+9/m/9yxCO5DOyRSRUqdgJjKO+Vo2JUJZv2DA8LVsAsYumA0MWkMVeh14kPmUWdM459NXMOf693MB8ft8+JgbOJ9ZgQYg+7BygOCkEBWVlXSdbNc5mSJSFhTMRMaxmkkx8Cg5EW8fO+vXPZAVmsI9Paxf90DOoLTshtWp+7b2/IJeMh8fI8b+yF5mBRqyglz97Jmcf+WH2PXL5zwPRRcRKVUKZiLjWOcpH7VV2ad7dJ4a2w3ZuQq65lvodWAo82pPD3LDHaETESkVKpchMo7FGlcTjmQGs3DEEWsc23CSa8F9vgvxKwkNq32wEToRkVKmYCYyjl3wB3fS3XA9Hd2Gc46ObqO74foxX/i/5s61BEOZIWo4C/HnBxbhS3u7envjy2y6bh3f/8Bd3H31TezYsCnj+tMdoRMRKRZNZYqMc/EQVrzyGJC9mH+4a76SC/z3R/by+sbtvPj3G4j2xEtkeE1T5jrgXKUyRKTUmXPZ60/KTVNTk2tubi52N0RkDNx99U3eoathFvf87KdArnIbIT5+z+e1xkxEis7MnnfONXndpxEzESkr+UxTnu4InYhIsSiYiUhZyXeaMn2XpohIudDifxEpK6e7kUBEpJRpxExEyoqmKUVkPFMwE5Gyo2lKERmvNJUpIiIiUiIUzERERERKhIKZiIiISIlQMBMREREpEQpmIiIiIiVCwUxERESkRCiYiYiIiJQIBTMRERGREqFgJiIiIlIiFMxERERESoSCmYiIiEiJUDATERERKREKZiIiIiIlQsFMREREpEQomImIiIiUCAUzERERkRKhYCYiIiJSIooWzMzs02b2mpntNrN/TGu/y8z2Je67tlj9ExERERlrgWJ8UzP7MHAjcIFzrtfMZiTalwA3A+cBDcBmM1vknIsWo58iIiIiY6lYI2Z/DtznnOsFcM4dTbTfCDzqnOt1zr0J7AOWF6mPIiIiImOqWMFsEXC5mf3KzH5pZssS7WcC76Rd926iLYuZ3W5mzWbWfOzYsQJ3V0RERKTwCjaVaWabgVked30h8X3rgQ8Cy4DHzOx9gHlc77ye3zn3TeCbAE1NTZ7XiIiIiJSTggUz59yqXPeZ2Z8DP3bOOWC7mcWAacRHyOamXToHOFioPoqIiIiUEotnozH+pmZrgQbn3N+a2SJgCzAPWAI8QnxdWUOifeFQi//N7Bjw1jC7MQ04Pty+S1702haOXtvC0WtbOHptC0evbeEU8rU9yzk33euOouzKBL4DfMfMdgF9wK2J0bPdZvYY8AoQAT6Zz47MXD/cYMys2TnXNNzHydD02haOXtvC0WtbOHptC0evbeEU67UtSjBzzvUBt+S478vAl8e2RyIiIiLFp8r/IiIiIiViIgezbxa7A+OYXtvC0WtbOHptC0evbeHotS2cory2RVn8LyIiIiLZJvKImYiIiEhJUTATERERKRETLpiZ2afN7DUz221m/5jWfpeZ7Uvcd20x+1jOzOx/mJkzs2mJ22Zm/yvx2r5sZhcVu4/lxsy+YmavJl6/n5hZXdp9+r09TWa2OvH67TOzzxe7P+XOzOaa2c/NbE/iffYvE+1TzewpM3s98Wd9sftajszMb2Yvmtn/Ttw+O3G84etm9gMzqyh2H8uVmdWZ2Y8S77d7zOzSYvzeTqhgZmYfJn5Q+gXOufOAf0q0LwFuBs4DVgP/Ymb+onW0TJnZXOAa4O205uuAhYn/bgf+tQhdK3dPAec75y4A9gJ3gX5vR0Pi9foG8d/TJcDvJ15XGbkI8Bnn3GLix+59MvGafh7Y4pxbSLx4uELwyPwlsCft9j8A6xKvayvwx0Xp1fjwNWCTc+5cYCnx13nMf28nVDAD/hy4zznXC+CcO5povxF41DnX65x7E9hH/PQBGZ51wGfJPN/0RuDfXdw2oM7MZheld2XKOfdfzrlI4uY24keVgX5vR8NyYJ9z7o1EfcVHib+uMkLOuUPOuRcSX3cQ/8ftTOKv63cTl30XuKk4PSxfZjYH+AjwYOK2AVcDP0pcotd1hMxsMnAF8G2I11t1zrVRhN/biRbMFgGXJ4Z9f2lmyxLtZwLvpF33bqJN8mRma4ADzrmdA+7Sazu6/gh4IvG1XtvTp9ewgMysEfgA8CtgpnPuEMTDGzCjeD0rW/cT//AbS9w+A2hL++Cm39+Rex9wDOqveo8AAARISURBVHgoMVX8oJlVU4Tf22IdyVQwZrYZmOVx1xeI/7z1xIfXlwGPmdn7APO4XnVEBhjitf0b4De8HubRptd2gMFeW+fc44lrvkB8mujh5MM8rtdrOzx6DQvEzGqA/wTucM61xwd3ZKTM7DeBo865583sqmSzx6X6/R2ZAHAR8Gnn3K/M7GsUabp93AUz59yqXPeZ2Z8DP06cy7ndzGLEDyl9F5ibdukc4GBBO1qGcr22ZvZ+4GxgZ+LNdw7wgpktR69tXgb7vQUws1uB3wRWuv7ig3ptT59ewwIwsyDxUPawc+7HieYjZjbbOXcosZzhaO5nEA8rgDVmdj0QAiYTH0GrM7NAYtRMv78j9y7wrnPuV4nbPyIezMb893aiTWX+lPh8PGa2CKggfnL8euBmM6s0s7OJL1TfXrRelhnn3K+dczOcc43OuUbiv+AXOecOE39t/zCxO/ODwMnksLDkx8xWA58D1jjnutPu0u/t6dsBLEzsbKsgvplifZH7VNYS656+Dexxzn017a71wK2Jr28FHh/rvpUz59xdzrk5iffYm4GfOef+APg58NHEZXpdRyjx79U7ZnZOomkl8ApF+L0ddyNmQ/gO8B0z2wX0AbcmRh92m9ljxP8nRIBPOueiRezneLIRuJ74wvRu4LbidqcsfR2oBJ5KjEhuc86tdc7p9/Y0OeciZvYp4EnAD3zHObe7yN0qdyuA/wv4tZm9lGj7G+A+4stH/pj4zu3fLVL/xpvPAY+a2b3AiyQWr8uIfBp4OPEh7Q3i/175GOPfWx3JJCIiIlIiJtpUpoiIiEjJUjATERERKREKZiIiIiIlQsFMREREpEQomImIiIiUCAUzEZEBzOy5YVz7KTPbZ2bOzKYVsl8iMv6pXIaIyGkwsw8ArcAvgCbn3PHi9khEyplGzERk3DOzn5rZ82a228xuT7SdZWavm9k0M/OZ2TNm9huJ+zoTf842s6fN7CUz22Vmlw98bufci865ljH9gURk3NKImYiMe2Y21Tl3wswmET+G6Urn3Htm9ifAauBXwALn3J8lru90ztWY2WeAkHPuy2bmB6qccx05vkcLGjETkdM00Y5kEpGJ6S/M7LcSX88lfq7oe865B83sd4G1wIUej9tB/Bi3IPBT59xLHteIiIwaTWWKyLhmZlcBq4BLnXNLiZ8nGErcVwXMSVxaM/CxzrmngSuAA8D3zOwPx6LPIjJxacRMRMa7KUCrc67bzM4FPph23z8ADwNvAd8CfjP9gWZ2FnDAOfctM6sGLgL+fWy6LSITkUbMRGS82wQEzOxl4B5gG4CZXQksA/7BOfcw0Gdmtw147FXAS2b2IvA7wNcGPrmZ/YWZvUt85O1lM3uwYD+JiIx7WvwvIiIiUiI0YiYiIiJSIhTMREREREqEgpmIiIhIiVAwExERESkRCmYiIiIiJULBTERERKREKJiJiIiIlIj/A0j3vhXOatsBAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"T-SNE plot on the testing dataset: \")\n",
    "tsne_map(testdl,modelcnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "6b3877d5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy:\n",
      "99.70000386238098 %\n",
      "validation accuracy:\n",
      "67.60563254356384 %\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6760563254356384"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Training accuracy:\")\n",
    "get_accuracy(traindl,modelcnn)\n",
    "print(\"validation accuracy:\")\n",
    "get_accuracy(valdl,modelcnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "98787790",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss on test:\n",
      "1.7513818740844727\n",
      "Training accuracy:\n",
      "99.85000491142273 %\n",
      "Test accuracy:\n",
      "70.17892599105835 %\n",
      "Training f1 score:\n",
      "F1 score: 1.0\n",
      "Test f1 score:\n",
      "F1 score: 0.6998012065887451\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6998012065887451"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Loss on test:\")\n",
    "test(modelcnn,testdl)\n",
    "print(\"Training accuracy:\")\n",
    "get_accuracy(traindl,modelcnn)\n",
    "print(\"Test accuracy:\")\n",
    "get_accuracy(testdl,modelcnn)\n",
    "print(\"Training f1 score:\")\n",
    "get_f1(traindl,modelcnn)\n",
    "print(\"Test f1 score:\")\n",
    "get_f1(testdl,modelcnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "987d2c17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confusion matrix on the test dataset:\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x720 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"confusion matrix on the test dataset:\")\n",
    "confusionplot(testdl,modelcnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "46bf1dca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The Classification Report for test set classification\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.79      0.79        53\n",
      "           1       0.73      0.95      0.83        55\n",
      "           2       0.59      0.48      0.53        54\n",
      "           3       0.78      0.63      0.70        46\n",
      "           4       0.70      0.41      0.52        46\n",
      "           5       0.51      0.54      0.52        50\n",
      "           6       0.64      0.80      0.71        46\n",
      "           7       0.66      0.87      0.75        47\n",
      "           8       0.93      0.75      0.83        56\n",
      "           9       0.81      0.84      0.82        50\n",
      "\n",
      "    accuracy                           0.71       503\n",
      "   macro avg       0.71      0.71      0.70       503\n",
      "weighted avg       0.72      0.71      0.70       503\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nThe Classification Report for test set classification\\n\")\n",
    "classificationReport(testdl,modelcnn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95ab4055",
   "metadata": {},
   "source": [
    "### model 2: LSTM "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94845f54",
   "metadata": {},
   "source": [
    "The data for the LSTM based model was prepared such that all the samples are of the size NX13,where N is the sequnce length of each sample.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 498,
   "id": "39cb428f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "import os\n",
    "class SDRDataset(Dataset):\n",
    "    def __init__(self, metadata, type):\n",
    "      self.metadata = metadata[metadata['split'] == type]\n",
    "    def __len__(self):       \n",
    "      return len(self.metadata)   \n",
    "    def __getitem__(self, idx):        \n",
    "      audio_file = self.metadata.iloc[idx]['identifier']      \n",
    "      digit = self.metadata.iloc[idx]['label']        \n",
    "      signal, sr = librosa.load(os.path.join(\"./speech_data\",audio_file) + \".wav\", sr=8000)  \n",
    "      mel_spectrogram = extract_melspectrogram(signal, sr, num_mels=13)\n",
    "      return torch.tensor(mel_spectrogram.T, dtype=torch.float32), torch.tensor(digit, dtype=torch.long)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 499,
   "id": "4effd73a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = SDRDataset(sdr_df, type = \"TRAIN\")\n",
    "traindl2= DataLoader(train_dataset, batch_size=1, shuffle=True)\n",
    "dev_dataset = SDRDataset(sdr_df, type = \"DEV\")\n",
    "valdl2 = DataLoader(dev_dataset, batch_size=1, shuffle=True)\n",
    "test_dataset = SDRDataset(sdr_df, type = \"TEST\")\n",
    "testdl2 = DataLoader(test_dataset, batch_size=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07e32731",
   "metadata": {},
   "source": [
    "The LSTM architecture is having 3 bidirectional LSTM layers[5] followed by 3 Linear fully connected layers. Dropout layers are applied after every layer. the dropout probability is determined later during hyperparameter tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 500,
   "id": "4dbf0ffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class lstm(nn.Module):\n",
    "     def __init__(self, input_dim, hidden_dim, layer_dim, output_dim,op):\n",
    "        super(lstm, self).__init__()\n",
    "        # Hidden dimensions\n",
    "        self.hidden_dim = hidden_dim\n",
    "\n",
    "        # Number of hidden layers\n",
    "        self.layer_dim = layer_dim\n",
    "        self.op = op\n",
    "        # Building your RNN\n",
    "        # batch_first=True causes input/output tensors to be of shape\n",
    "        # (batch_dim, seq_dim, input_dim)\n",
    "        # batch_dim = number of samples per batch\n",
    "        self.lstm = nn.LSTM(input_dim, hidden_dim, layer_dim, batch_first=True,dropout=self.op, bidirectional = True)#, nonlinearity='relu')\n",
    "\n",
    "        # Readout layer\n",
    "        self.fc1 = nn.Linear(hidden_dim * 2, 200)\n",
    "        self.fc2 = nn.Linear(200, 100)\n",
    "        self.fc3 = nn.Linear(100, 50)\n",
    "        self.fc4 = nn.Linear(50, 10)\n",
    "        self.drp = nn.Dropout(self.op) \n",
    "        self.softmax = nn.LogSoftmax(dim = 1)\n",
    "\n",
    "     def forward(self, x):\n",
    "        # Initialize hidden state with zeros\n",
    "        # (layer_dim, batch_size, hidden_dim)\n",
    "        h0 = torch.zeros(self.layer_dim*2, x.size(0), self.hidden_dim).requires_grad_().to(device)\n",
    "        c0 = torch.zeros(self.layer_dim*2, x.size(0), self.hidden_dim).requires_grad_().to(device)\n",
    "        # We need to detach the hidden state to prevent exploding/vanishing gradients\n",
    "        # This is part of truncated backpropagation through time (BPTT)\n",
    "        out, _ = self.lstm(x, (h0.detach(),c0.detach()) )\n",
    "        out = self.drp(self.fc1(out[:, -1, :])) \n",
    "        out = self.drp(self.fc2(out)) \n",
    "        out = self.drp(self.fc3(out)) \n",
    "        out = self.fc4(out) \n",
    "        return out\n",
    "    \n",
    "     \n",
    "     \n",
    "     def train(self,train_loader,learning_rate=0.01,epochs=5,lam=0.01,opti='adam'):\n",
    "            optidict={'adagrad':torch.optim.Adagrad(self.parameters(), lr=learning_rate),'adam':torch.optim.Adam(self.parameters(),lr=learning_rate),'sgd':torch.optim.SGD(self.parameters(), lr=learning_rate)}\n",
    "            loss_fn = nn.CrossEntropyLoss()\n",
    "            optimizer = optidict[opti]\n",
    "            optimizer.weight_decay = lam #torch.optim.Adam(self.parameters(),lr=learning_rate,weight_decay=lam)\n",
    "            lossrec=[]\n",
    "            par_grad=[]\n",
    "            for epoch in range(epochs):\n",
    "                tloss=0\n",
    "                total_grad=0\n",
    "                for i,(xs,ys) in enumerate(train_loader):\n",
    "                    xs=xs.to(device)\n",
    "                    ys=ys.to(device)\n",
    "                    pred = self.forward(xs.type(torch.FloatTensor).cuda())                \n",
    "                    loss = loss_fn(pred,ys) \n",
    "                    optimizer.zero_grad()\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "\n",
    "                    grad=0\n",
    "                    for p in self.parameters():\n",
    "                        grad+=torch.norm(p.grad).item()\n",
    "\n",
    "                    total_grad+=grad\n",
    "                    tloss+=loss\n",
    "                lossrec.append((tloss/len(train_loader)).log().item())\n",
    "                par_grad.append((total_grad/len(train_loader)))\n",
    "                print('epoch:',epoch,'loss:',(tloss/len(train_loader)).item(),'grad:',(total_grad/len(train_loader)))\n",
    "            return lossrec,par_grad"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a16572d4",
   "metadata": {},
   "source": [
    "#### Tuning the Hyperparameters\n",
    "The following script is for selecting the optimal values for the hyperparameter by training the model multiple times with the different set of hyperparameters and then evaluating them based on the validation loss obtained. The hyperparameter values that gives the lowest values for validation loss are reported."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 502,
   "id": "1f9e1708",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0 loss: 1.886893630027771 grad: 24.39038729888611\n",
      "epoch: 1 loss: 1.5090981721878052 grad: 41.07620384932973\n",
      "epoch: 2 loss: 1.3562276363372803 grad: 44.392443139298805\n",
      "epoch: 3 loss: 1.2639062404632568 grad: 45.47947036465509\n",
      "epoch: 4 loss: 1.1482408046722412 grad: 50.137349739227766\n",
      "epoch: 5 loss: 1.0123640298843384 grad: 54.042022064515855\n",
      "epoch: 6 loss: 0.9259719848632812 grad: 59.89673644216315\n",
      "epoch: 7 loss: 0.8652892708778381 grad: 60.82858336819418\n",
      "epoch: 8 loss: 0.7831159830093384 grad: 63.69417482276467\n",
      "epoch: 9 loss: 0.8378627300262451 grad: 92.0958751000449\n",
      "epoch: 10 loss: 0.716705858707428 grad: 68.61127998859797\n",
      "epoch: 11 loss: 0.6638830304145813 grad: 64.57827930551163\n",
      "epoch: 12 loss: 0.6382091641426086 grad: 65.50871455176578\n",
      "epoch: 13 loss: 0.5868451595306396 grad: 64.40863492850679\n",
      "epoch: 14 loss: 0.5530391931533813 grad: 65.74960945257838\n",
      "epoch: 15 loss: 0.5259122848510742 grad: 63.42939024004396\n",
      "epoch: 16 loss: 0.4940769076347351 grad: 63.15122554482368\n",
      "epoch: 17 loss: 0.44770124554634094 grad: 59.764155288773765\n",
      "epoch: 18 loss: 0.42300060391426086 grad: 58.83786005593259\n",
      "epoch: 19 loss: 0.40852099657058716 grad: 64.54506694603819\n",
      "2.2659712563764485\n",
      "2.25747538859818\n",
      "2.25747538859818\n",
      "epoch: 0 loss: 2.131746292114258 grad: 15.162917899662922\n",
      "epoch: 1 loss: 1.64976167678833 grad: 21.560146057944614\n",
      "epoch: 2 loss: 1.1580995321273804 grad: 25.567900779400574\n",
      "epoch: 3 loss: 0.8326506018638611 grad: 24.828476283791034\n",
      "epoch: 4 loss: 0.6809824705123901 grad: 22.836800173182006\n",
      "epoch: 5 loss: 0.536241888999939 grad: 19.975946474937654\n",
      "epoch: 6 loss: 0.4593864977359772 grad: 17.23715027353218\n",
      "epoch: 7 loss: 0.4438817799091339 grad: 14.42836064675058\n",
      "epoch: 8 loss: 0.42679035663604736 grad: 15.238863530446347\n",
      "epoch: 9 loss: 0.30016443133354187 grad: 12.13581145828538\n",
      "epoch: 10 loss: 0.26663216948509216 grad: 9.894164506998386\n",
      "epoch: 11 loss: 0.2592967450618744 grad: 10.394501952486644\n",
      "epoch: 12 loss: 0.22535790503025055 grad: 9.78738474598153\n",
      "epoch: 13 loss: 0.2502942383289337 grad: 9.775809944890248\n",
      "epoch: 14 loss: 0.2117682844400406 grad: 8.99826247076523\n",
      "epoch: 15 loss: 0.18923838436603546 grad: 7.928054633691512\n",
      "epoch: 16 loss: 0.20963162183761597 grad: 8.550932528344457\n",
      "epoch: 17 loss: 0.14526700973510742 grad: 5.96648428947752\n",
      "epoch: 18 loss: 0.14296367764472961 grad: 5.571853686653237\n",
      "epoch: 19 loss: 0.1617976725101471 grad: 6.293818052005685\n",
      "5.40380301137429\n",
      "epoch: 0 loss: 2.3070240020751953 grad: 3.7430833900496365\n",
      "epoch: 1 loss: 2.304443359375 grad: 3.724595163269609\n",
      "epoch: 2 loss: 2.303611993789673 grad: 3.716678435866372\n",
      "epoch: 3 loss: 2.3039166927337646 grad: 3.7250085904825827\n",
      "epoch: 4 loss: 2.302468776702881 grad: 3.7160890520167884\n",
      "epoch: 5 loss: 2.3034582138061523 grad: 3.718312424358388\n",
      "epoch: 6 loss: 2.303534746170044 grad: 3.7170669019702474\n",
      "epoch: 7 loss: 2.3031864166259766 grad: 3.709716401889804\n",
      "epoch: 8 loss: 2.3026273250579834 grad: 3.713166060898337\n",
      "epoch: 9 loss: 2.3033344745635986 grad: 3.71214018623982\n",
      "epoch: 10 loss: 2.3032572269439697 grad: 3.713641183189058\n",
      "epoch: 11 loss: 2.303926706314087 grad: 3.7058991076405507\n",
      "epoch: 12 loss: 2.303149700164795 grad: 3.700961674743856\n",
      "epoch: 13 loss: 2.30271053314209 grad: 3.6917467067698597\n",
      "epoch: 14 loss: 2.3033621311187744 grad: 3.6929833833746963\n",
      "epoch: 15 loss: 2.3030378818511963 grad: 3.6945611914020264\n",
      "epoch: 16 loss: 2.3032026290893555 grad: 3.6850475765229787\n",
      "epoch: 17 loss: 2.3025338649749756 grad: 3.686497394097445\n",
      "epoch: 18 loss: 2.3031177520751953 grad: 3.6905062563672546\n",
      "epoch: 19 loss: 2.30289888381958 grad: 3.683938600379799\n",
      "2.302006106501374\n",
      "epoch: 0 loss: 1.8954968452453613 grad: 25.712042746677938\n",
      "epoch: 1 loss: 1.3500869274139404 grad: 47.057345547386674\n",
      "epoch: 2 loss: 0.9911395311355591 grad: 54.659320738603654\n",
      "epoch: 3 loss: 0.8213134407997131 grad: 62.67445673351353\n",
      "epoch: 4 loss: 0.676245927810669 grad: 61.65918088668144\n",
      "epoch: 5 loss: 0.6152628660202026 grad: 61.41524330185222\n",
      "epoch: 6 loss: 0.5531372427940369 grad: 58.82627591687944\n",
      "epoch: 7 loss: 0.4932926893234253 grad: 56.598419478886015\n",
      "epoch: 8 loss: 0.45000702142715454 grad: 56.05685922446237\n",
      "epoch: 9 loss: 0.4200730323791504 grad: 53.90912817754327\n",
      "epoch: 10 loss: 0.39951983094215393 grad: 54.23871202870956\n",
      "epoch: 11 loss: 0.36540475487709045 grad: 50.53605269345373\n",
      "epoch: 12 loss: 0.3531267046928406 grad: 49.721115888544006\n",
      "epoch: 13 loss: 0.3362160325050354 grad: 47.09190698454428\n",
      "epoch: 14 loss: 0.3097454905509949 grad: 45.689090582920116\n",
      "epoch: 15 loss: 0.2910544276237488 grad: 45.316777113165\n",
      "epoch: 16 loss: 0.27931156754493713 grad: 46.05381863932165\n",
      "epoch: 17 loss: 0.2668313980102539 grad: 43.906276843499846\n",
      "epoch: 18 loss: 0.2535632252693176 grad: 44.70824660961833\n",
      "epoch: 19 loss: 0.2374478578567505 grad: 41.58334411796858\n",
      "2.718588450006235\n",
      "epoch: 0 loss: 2.2204835414886475 grad: 8.61485690572093\n",
      "epoch: 1 loss: 2.0496432781219482 grad: 14.3344424940067\n",
      "epoch: 2 loss: 1.820659875869751 grad: 15.419407552556246\n",
      "epoch: 3 loss: 1.5857768058776855 grad: 19.321299933254245\n",
      "epoch: 4 loss: 1.2328753471374512 grad: 20.12172965256718\n",
      "epoch: 5 loss: 1.1003093719482422 grad: 19.316361121100563\n",
      "epoch: 6 loss: 0.978580117225647 grad: 19.157033389146875\n",
      "epoch: 7 loss: 0.7699272632598877 grad: 18.300936684971415\n",
      "epoch: 8 loss: 0.6754234433174133 grad: 18.325067882806774\n",
      "epoch: 9 loss: 0.4685363173484802 grad: 15.174272950999667\n",
      "epoch: 10 loss: 0.4667224884033203 grad: 15.080618316280065\n",
      "epoch: 11 loss: 0.3696184754371643 grad: 12.242751026462653\n",
      "epoch: 12 loss: 0.31766751408576965 grad: 11.344123854149355\n",
      "epoch: 13 loss: 0.335112065076828 grad: 10.530916130514262\n",
      "epoch: 14 loss: 0.31164780259132385 grad: 11.328091019017634\n",
      "epoch: 15 loss: 0.2662865221500397 grad: 9.591047384336012\n",
      "epoch: 16 loss: 0.28788095712661743 grad: 9.673536330852798\n",
      "epoch: 17 loss: 0.24214397370815277 grad: 8.730757614214385\n",
      "epoch: 18 loss: 0.21443846821784973 grad: 7.771262102100299\n",
      "epoch: 19 loss: 0.22036190330982208 grad: 7.842464458967274\n",
      "3.156057472723129\n",
      "epoch: 0 loss: 2.306704521179199 grad: 3.8800479810075483\n",
      "epoch: 1 loss: 2.3044538497924805 grad: 3.8783447192151796\n",
      "epoch: 2 loss: 2.3038012981414795 grad: 3.8847647898675057\n",
      "epoch: 3 loss: 2.3038995265960693 grad: 3.8804266462601955\n",
      "epoch: 4 loss: 2.3045451641082764 grad: 3.876120917032589\n",
      "epoch: 5 loss: 2.3037333488464355 grad: 3.8628235353874625\n",
      "epoch: 6 loss: 2.3035221099853516 grad: 3.8665567306183513\n",
      "epoch: 7 loss: 2.3034889698028564 grad: 3.8674237880369766\n",
      "epoch: 8 loss: 2.3030664920806885 grad: 3.8529115530615674\n",
      "epoch: 9 loss: 2.304340124130249 grad: 3.8496335895982337\n",
      "epoch: 10 loss: 2.3033201694488525 grad: 3.849870759655489\n",
      "epoch: 11 loss: 2.30328106880188 grad: 3.8421126120401894\n",
      "epoch: 12 loss: 2.3025193214416504 grad: 3.8257445307144082\n",
      "epoch: 13 loss: 2.302220344543457 grad: 3.839254805690725\n",
      "epoch: 14 loss: 2.3028202056884766 grad: 3.8320857713443695\n",
      "epoch: 15 loss: 2.3026092052459717 grad: 3.8437815839793186\n",
      "epoch: 16 loss: 2.302325487136841 grad: 3.8423329525144654\n",
      "epoch: 17 loss: 2.3024840354919434 grad: 3.8429580040559523\n",
      "epoch: 18 loss: 2.3020365238189697 grad: 3.846293679343129\n",
      "epoch: 19 loss: 2.302304267883301 grad: 3.851641325818491\n",
      "2.3022360029354902\n",
      "epoch: 0 loss: 1.8802090883255005 grad: 27.801930250311795\n",
      "epoch: 1 loss: 1.3411760330200195 grad: 50.90665813883918\n",
      "epoch: 2 loss: 1.110024333000183 grad: 56.90108597456163\n",
      "epoch: 3 loss: 0.9362701773643494 grad: 60.020971215814875\n",
      "epoch: 4 loss: 0.801567792892456 grad: 63.1415820351951\n",
      "epoch: 5 loss: 0.6712958216667175 grad: 58.64161159162848\n",
      "epoch: 6 loss: 0.6022623181343079 grad: 59.02378114799502\n",
      "epoch: 7 loss: 0.5425122976303101 grad: 61.069970145290796\n",
      "epoch: 8 loss: 0.49784475564956665 grad: 61.353628984356895\n",
      "epoch: 9 loss: 0.4412033259868622 grad: 59.64852539111369\n",
      "epoch: 10 loss: 0.4028187096118927 grad: 52.83619046188019\n",
      "epoch: 11 loss: 0.3779037594795227 grad: 52.996854159500764\n",
      "epoch: 12 loss: 0.3513167202472687 grad: 50.42875130250725\n",
      "epoch: 13 loss: 0.33875250816345215 grad: 49.2744545191367\n",
      "epoch: 14 loss: 0.32332053780555725 grad: 53.165662623365016\n",
      "epoch: 15 loss: 0.3102881610393524 grad: 51.18990517962629\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 16 loss: 0.2741161584854126 grad: 44.90490864710619\n",
      "epoch: 17 loss: 0.2566972076892853 grad: 43.81845564775765\n",
      "epoch: 18 loss: 0.2488875389099121 grad: 43.53845657509771\n",
      "epoch: 19 loss: 0.23621152341365814 grad: 42.806852349341256\n",
      "2.895931725943638\n",
      "epoch: 0 loss: 2.2630372047424316 grad: 9.714893534599614\n",
      "epoch: 1 loss: 2.160337209701538 grad: 10.680916811226735\n",
      "epoch: 2 loss: 1.938913106918335 grad: 13.851092958130058\n",
      "epoch: 3 loss: 1.8015302419662476 grad: 16.660034755979105\n",
      "epoch: 4 loss: 1.471903920173645 grad: 18.54335288195086\n",
      "epoch: 5 loss: 1.263859510421753 grad: 20.36273496691409\n",
      "epoch: 6 loss: 1.048929214477539 grad: 20.38813972049688\n",
      "epoch: 7 loss: 0.9586515426635742 grad: 20.9776068884634\n",
      "epoch: 8 loss: 0.8033949136734009 grad: 20.55213015892556\n",
      "epoch: 9 loss: 0.6453853249549866 grad: 18.330342341320122\n",
      "epoch: 10 loss: 0.5698536038398743 grad: 18.6721711219038\n",
      "epoch: 11 loss: 0.5267998576164246 grad: 17.67916250957267\n",
      "epoch: 12 loss: 0.4259639382362366 grad: 14.810845382064702\n",
      "epoch: 13 loss: 0.3701436519622803 grad: 12.613698164341113\n",
      "epoch: 14 loss: 0.3022693991661072 grad: 10.66637347671753\n",
      "epoch: 15 loss: 0.3709678053855896 grad: 12.703621977078921\n",
      "epoch: 16 loss: 0.3226570785045624 grad: 12.614287861244359\n",
      "epoch: 17 loss: 0.24371501803398132 grad: 10.080405926016422\n",
      "epoch: 18 loss: 0.3147059679031372 grad: 11.231531766551385\n",
      "epoch: 19 loss: 0.23069268465042114 grad: 8.423116178186113\n",
      "3.3841321075188504\n",
      "epoch: 0 loss: 2.3057284355163574 grad: 3.7513910845202045\n",
      "epoch: 1 loss: 2.3038244247436523 grad: 3.744841741794429\n",
      "epoch: 2 loss: 2.3037939071655273 grad: 3.749445719311829\n",
      "epoch: 3 loss: 2.303292751312256 grad: 3.7549236219885063\n",
      "epoch: 4 loss: 2.30338454246521 grad: 3.761036324860121\n",
      "epoch: 5 loss: 2.3027796745300293 grad: 3.754047576882527\n",
      "epoch: 6 loss: 2.302666664123535 grad: 3.7616553692831074\n",
      "epoch: 7 loss: 2.3034377098083496 grad: 3.776600698562339\n",
      "epoch: 8 loss: 2.303318738937378 grad: 3.7629908927307114\n",
      "epoch: 9 loss: 2.3035473823547363 grad: 3.7591631491848383\n",
      "epoch: 10 loss: 2.3028125762939453 grad: 3.7490087839597837\n",
      "epoch: 11 loss: 2.3024301528930664 grad: 3.7552082275261056\n",
      "epoch: 12 loss: 2.3020362854003906 grad: 3.763387340087502\n",
      "epoch: 13 loss: 2.302699565887451 grad: 3.7662122527217727\n",
      "epoch: 14 loss: 2.3027892112731934 grad: 3.769424999276758\n",
      "epoch: 15 loss: 2.3030812740325928 grad: 3.7543119754445504\n",
      "epoch: 16 loss: 2.303483009338379 grad: 3.759492198250489\n",
      "epoch: 17 loss: 2.301988363265991 grad: 3.761541392399173\n",
      "epoch: 18 loss: 2.3016560077667236 grad: 3.7680321427018497\n",
      "epoch: 19 loss: 2.3018970489501953 grad: 3.780912271202367\n",
      "2.300594061193332\n",
      "epoch: 0 loss: 1.9296681880950928 grad: 24.735369287160633\n",
      "epoch: 1 loss: 1.334214687347412 grad: 47.12758027841657\n",
      "epoch: 2 loss: 1.1607038974761963 grad: 48.57019257319435\n",
      "epoch: 3 loss: 1.0645184516906738 grad: 53.509856965244516\n",
      "epoch: 4 loss: 0.955703854560852 grad: 53.30922600890166\n",
      "epoch: 5 loss: 0.8774105310440063 grad: 52.914998636715424\n",
      "epoch: 6 loss: 0.8096057772636414 grad: 53.636017796054816\n",
      "epoch: 7 loss: 0.72343510389328 grad: 54.79039438286073\n",
      "epoch: 8 loss: 0.6667997241020203 grad: 56.089699254908375\n",
      "epoch: 9 loss: 0.606731116771698 grad: 53.609306544143976\n",
      "epoch: 10 loss: 0.5674042701721191 grad: 55.38845242780592\n",
      "epoch: 11 loss: 0.5221878290176392 grad: 53.0010340078547\n",
      "epoch: 12 loss: 0.5000593662261963 grad: 54.362093879850555\n",
      "epoch: 13 loss: 0.4444811940193176 grad: 50.87895072334327\n",
      "epoch: 14 loss: 0.4270481467247009 grad: 51.382015491158455\n",
      "epoch: 15 loss: 0.39182740449905396 grad: 49.27497731860475\n",
      "epoch: 16 loss: 0.3888256251811981 grad: 51.288592360899685\n",
      "epoch: 17 loss: 0.35084086656570435 grad: 44.98457586565046\n",
      "epoch: 18 loss: 0.32589077949523926 grad: 44.26679200513766\n",
      "epoch: 19 loss: 0.31306391954421997 grad: 45.134458507884716\n",
      "2.61205730648608\n",
      "epoch: 0 loss: 2.3155157566070557 grad: 6.0757337092613515\n",
      "epoch: 1 loss: 2.2096550464630127 grad: 8.876436015798014\n",
      "epoch: 2 loss: 2.049009323120117 grad: 12.178260863764017\n",
      "epoch: 3 loss: 1.9607232809066772 grad: 13.915242267395248\n",
      "epoch: 4 loss: 1.8763225078582764 grad: 16.188136150007473\n",
      "epoch: 5 loss: 1.7616851329803467 grad: 18.796942656606742\n",
      "epoch: 6 loss: 1.6901395320892334 grad: 19.514602678389537\n",
      "epoch: 7 loss: 1.5577681064605713 grad: 22.0769399362116\n",
      "epoch: 8 loss: 1.3050271272659302 grad: 22.447009720011565\n",
      "epoch: 9 loss: 1.2602994441986084 grad: 23.333794007833156\n",
      "epoch: 10 loss: 1.039028286933899 grad: 21.912086738619614\n",
      "epoch: 11 loss: 0.9391025900840759 grad: 20.950105987004584\n",
      "epoch: 12 loss: 0.8512253761291504 grad: 20.470300025756693\n",
      "epoch: 13 loss: 0.7667649388313293 grad: 19.739355883402247\n",
      "epoch: 14 loss: 0.8176606893539429 grad: 20.671354536801054\n",
      "epoch: 15 loss: 0.6068260073661804 grad: 17.299640672369346\n",
      "epoch: 16 loss: 0.5962871313095093 grad: 17.34463858023567\n",
      "epoch: 17 loss: 0.5017414689064026 grad: 15.257613387811746\n",
      "epoch: 18 loss: 0.592101514339447 grad: 18.860035615902962\n",
      "epoch: 19 loss: 0.4496912956237793 grad: 15.800463364078329\n",
      "2.664599468604291\n",
      "epoch: 0 loss: 2.306286334991455 grad: 3.8991167359498213\n",
      "epoch: 1 loss: 2.3049511909484863 grad: 3.900433291643276\n",
      "epoch: 2 loss: 2.3038487434387207 grad: 3.9103879621177913\n",
      "epoch: 3 loss: 2.303887367248535 grad: 3.911302076515567\n",
      "epoch: 4 loss: 2.3034777641296387 grad: 3.9130780190200896\n",
      "epoch: 5 loss: 2.303637742996216 grad: 3.910304345094308\n",
      "epoch: 6 loss: 2.3034024238586426 grad: 3.9118874124102296\n",
      "epoch: 7 loss: 2.3033106327056885 grad: 3.9100241290209232\n",
      "epoch: 8 loss: 2.3028182983398438 grad: 3.9150052348292084\n",
      "epoch: 9 loss: 2.30264949798584 grad: 3.91148845257354\n",
      "epoch: 10 loss: 2.3035712242126465 grad: 3.917185110175167\n",
      "epoch: 11 loss: 2.303090810775757 grad: 3.901857322832511\n",
      "epoch: 12 loss: 2.303290367126465 grad: 3.9060802225451337\n",
      "epoch: 13 loss: 2.302478075027466 grad: 3.900098660634947\n",
      "epoch: 14 loss: 2.302053689956665 grad: 3.9007008572711492\n",
      "epoch: 15 loss: 2.302464246749878 grad: 3.8977572807244725\n",
      "epoch: 16 loss: 2.3022634983062744 grad: 3.90461061276542\n",
      "epoch: 17 loss: 2.3027663230895996 grad: 3.9068743757532793\n",
      "epoch: 18 loss: 2.302218437194824 grad: 3.909945778752735\n",
      "epoch: 19 loss: 2.302027940750122 grad: 3.912118242176715\n",
      "2.3019983485431017\n",
      "epoch: 0 loss: 1.9283382892608643 grad: 25.24915596621402\n",
      "epoch: 1 loss: 1.34324312210083 grad: 53.029633997011\n",
      "epoch: 2 loss: 1.101393699645996 grad: 57.16902368639788\n",
      "epoch: 3 loss: 0.9372205138206482 grad: 58.00262011006093\n",
      "epoch: 4 loss: 0.8288204669952393 grad: 58.1237277496143\n",
      "epoch: 5 loss: 0.7428758144378662 grad: 60.991294780013575\n",
      "epoch: 6 loss: 0.6376874446868896 grad: 57.77254115359189\n",
      "epoch: 7 loss: 0.5709061622619629 grad: 59.206773974155915\n",
      "epoch: 8 loss: 0.5305910706520081 grad: 58.16479981538642\n",
      "epoch: 9 loss: 0.4733225703239441 grad: 55.90661708670949\n",
      "epoch: 10 loss: 0.4414138197898865 grad: 56.085075410174326\n",
      "epoch: 11 loss: 0.3922332227230072 grad: 52.60155883807726\n",
      "epoch: 12 loss: 0.36128249764442444 grad: 50.392326969299816\n",
      "epoch: 13 loss: 0.3242069184780121 grad: 46.58570774735438\n",
      "epoch: 14 loss: 0.3247848153114319 grad: 49.360647347765344\n",
      "epoch: 15 loss: 0.2950305640697479 grad: 48.09061288507645\n",
      "epoch: 16 loss: 0.2714027464389801 grad: 41.57434914599736\n",
      "epoch: 17 loss: 0.25778594613075256 grad: 43.725678899095364\n",
      "epoch: 18 loss: 0.23270408809185028 grad: 42.012377050959664\n",
      "epoch: 19 loss: 0.22265556454658508 grad: 39.767295760528604\n",
      "2.8692793983247475\n",
      "epoch: 0 loss: 2.3205671310424805 grad: 5.21274291257864\n",
      "epoch: 1 loss: 2.3136234283447266 grad: 4.21996331805917\n",
      "epoch: 2 loss: 2.3114943504333496 grad: 3.593680376534647\n",
      "epoch: 3 loss: 2.3102190494537354 grad: 3.174083737108123\n",
      "epoch: 4 loss: 2.308537483215332 grad: 2.830453783136816\n",
      "epoch: 5 loss: 2.308530330657959 grad: 2.789475375900754\n",
      "epoch: 6 loss: 2.307171583175659 grad: 3.060986553396526\n",
      "epoch: 7 loss: 2.320383071899414 grad: 4.337306907712471\n",
      "epoch: 8 loss: 2.309659481048584 grad: 3.61594402969183\n",
      "epoch: 9 loss: 2.3086929321289062 grad: 3.5887572124476903\n",
      "epoch: 10 loss: 2.3075947761535645 grad: 2.7934442018623957\n",
      "epoch: 11 loss: 2.310729503631592 grad: 3.3626319194552576\n",
      "epoch: 12 loss: 2.3077847957611084 grad: 2.811932717066356\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 13 loss: 2.3075172901153564 grad: 2.944606220914387\n",
      "epoch: 14 loss: 2.3082430362701416 grad: 2.775676310799901\n",
      "epoch: 15 loss: 2.318783760070801 grad: 3.9128976936571447\n",
      "epoch: 16 loss: 2.1741890907287598 grad: 7.465703673995807\n",
      "epoch: 17 loss: 2.1821539402008057 grad: 10.36352795276299\n",
      "epoch: 18 loss: 2.0546836853027344 grad: 14.398540005312046\n",
      "epoch: 19 loss: 1.9214600324630737 grad: 18.25691593069977\n",
      "2.521530795040385\n",
      "epoch: 0 loss: 2.306377649307251 grad: 3.9501442703443463\n",
      "epoch: 1 loss: 2.3052256107330322 grad: 3.933023402115039\n",
      "epoch: 2 loss: 2.303947687149048 grad: 3.935228604734584\n",
      "epoch: 3 loss: 2.3037662506103516 grad: 3.948993161185412\n",
      "epoch: 4 loss: 2.303488254547119 grad: 3.945362698295503\n",
      "epoch: 5 loss: 2.30340313911438 grad: 3.938056806573295\n",
      "epoch: 6 loss: 2.3046650886535645 grad: 3.929891029480903\n",
      "epoch: 7 loss: 2.303152561187744 grad: 3.930841852853075\n",
      "epoch: 8 loss: 2.302382230758667 grad: 3.929223407166777\n",
      "epoch: 9 loss: 2.3032641410827637 grad: 3.927378471025149\n",
      "epoch: 10 loss: 2.3030645847320557 grad: 3.919381293935643\n",
      "epoch: 11 loss: 2.3026111125946045 grad: 3.9223909184110815\n",
      "epoch: 12 loss: 2.302454710006714 grad: 3.9225356421116158\n",
      "epoch: 13 loss: 2.302645444869995 grad: 3.9233480221818318\n",
      "epoch: 14 loss: 2.302713632583618 grad: 3.929512101302098\n",
      "epoch: 15 loss: 2.3025801181793213 grad: 3.9353531923610134\n",
      "epoch: 16 loss: 2.3021631240844727 grad: 3.9360860141867886\n",
      "epoch: 17 loss: 2.3024628162384033 grad: 3.944612567838165\n",
      "epoch: 18 loss: 2.3027875423431396 grad: 3.9302577430724632\n",
      "epoch: 19 loss: 2.303091287612915 grad: 3.9374024577924285\n",
      "2.3035084980594323\n",
      "epoch: 0 loss: 1.8444170951843262 grad: 26.223015972272574\n",
      "epoch: 1 loss: 1.4844799041748047 grad: 42.41090696898759\n",
      "epoch: 2 loss: 1.304986596107483 grad: 53.48244514507471\n",
      "epoch: 3 loss: 1.1782376766204834 grad: 59.77535859357228\n",
      "epoch: 4 loss: 1.0713889598846436 grad: 64.88214111517418\n",
      "epoch: 5 loss: 0.9442823529243469 grad: 68.5284883288253\n",
      "epoch: 6 loss: 0.8361315727233887 grad: 67.59449921518376\n",
      "epoch: 7 loss: 0.7489525079727173 grad: 70.15150656093068\n",
      "epoch: 8 loss: 0.6952199935913086 grad: 69.53623937065093\n",
      "epoch: 9 loss: 0.6275280714035034 grad: 69.79805282141889\n",
      "epoch: 10 loss: 0.591147780418396 grad: 70.58024302596053\n",
      "epoch: 11 loss: 0.5433964133262634 grad: 67.93762004782741\n",
      "epoch: 12 loss: 0.512803852558136 grad: 68.95360799131439\n",
      "epoch: 13 loss: 0.49007776379585266 grad: 68.21681207682126\n",
      "epoch: 14 loss: 0.4611333906650543 grad: 65.56955932119267\n",
      "epoch: 15 loss: 0.42347580194473267 grad: 65.72948541630774\n",
      "epoch: 16 loss: 0.38334184885025024 grad: 59.50306645330717\n",
      "epoch: 17 loss: 0.3780544400215149 grad: 61.891832697182224\n",
      "epoch: 18 loss: 0.3525068759918213 grad: 58.80864301628781\n",
      "epoch: 19 loss: 0.34047698974609375 grad: 61.352039691744544\n",
      "2.9657524985366406\n",
      "epoch: 0 loss: 2.321500539779663 grad: 6.105002594255115\n",
      "epoch: 1 loss: 2.3136818408966064 grad: 4.542234256788318\n",
      "epoch: 2 loss: 2.3139727115631104 grad: 4.375287002169844\n",
      "epoch: 3 loss: 2.312568426132202 grad: 3.563548300312312\n",
      "epoch: 4 loss: 2.3099186420440674 grad: 3.1240314708839687\n",
      "epoch: 5 loss: 2.311486005783081 grad: 3.946405238427668\n",
      "epoch: 6 loss: 2.308152437210083 grad: 3.313463497416259\n",
      "epoch: 7 loss: 2.308013677597046 grad: 3.2644148988940485\n",
      "epoch: 8 loss: 2.3089137077331543 grad: 3.0043098905724763\n",
      "epoch: 9 loss: 2.307847023010254 grad: 2.658613240964316\n",
      "epoch: 10 loss: 2.309217691421509 grad: 3.286691670843049\n",
      "epoch: 11 loss: 2.3080251216888428 grad: 3.384070045323496\n",
      "epoch: 12 loss: 2.2967522144317627 grad: 6.142546769251898\n",
      "epoch: 13 loss: 2.1803414821624756 grad: 9.25617121232289\n",
      "epoch: 14 loss: 2.1142983436584473 grad: 13.813214295113793\n",
      "epoch: 15 loss: 1.842764139175415 grad: 16.89120517348153\n",
      "epoch: 16 loss: 1.6993017196655273 grad: 17.830043240539176\n",
      "epoch: 17 loss: 1.5738939046859741 grad: 18.351717995903577\n",
      "epoch: 18 loss: 1.5294620990753174 grad: 19.861992171647916\n",
      "epoch: 19 loss: 1.422203540802002 grad: 19.31892973173493\n",
      "2.625877443933391\n",
      "epoch: 0 loss: 2.306002140045166 grad: 3.9633419710354065\n",
      "epoch: 1 loss: 2.304276704788208 grad: 3.961279467684217\n",
      "epoch: 2 loss: 2.3033668994903564 grad: 3.9863259664896757\n",
      "epoch: 3 loss: 2.3038618564605713 grad: 3.999766982005793\n",
      "epoch: 4 loss: 2.3036086559295654 grad: 3.981483785345801\n",
      "epoch: 5 loss: 2.3038618564605713 grad: 3.9877933745563494\n",
      "epoch: 6 loss: 2.303532600402832 grad: 3.9893685297088233\n",
      "epoch: 7 loss: 2.3035783767700195 grad: 3.981208869791997\n",
      "epoch: 8 loss: 2.302983522415161 grad: 3.9900662899833406\n",
      "epoch: 9 loss: 2.302978038787842 grad: 3.9852896691372734\n",
      "epoch: 10 loss: 2.3035998344421387 grad: 3.977209685399022\n",
      "epoch: 11 loss: 2.3028886318206787 grad: 3.971016339293943\n",
      "epoch: 12 loss: 2.30385422706604 grad: 3.9729259160345536\n",
      "epoch: 13 loss: 2.30349063873291 grad: 3.9612973485519762\n",
      "epoch: 14 loss: 2.3030760288238525 grad: 3.949119892216375\n",
      "epoch: 15 loss: 2.3035964965820312 grad: 3.9538699448739063\n",
      "epoch: 16 loss: 2.302478313446045 grad: 3.944305023605353\n",
      "epoch: 17 loss: 2.3033037185668945 grad: 3.9554281621742993\n",
      "epoch: 18 loss: 2.3034656047821045 grad: 3.943737563466013\n",
      "epoch: 19 loss: 2.3031389713287354 grad: 3.9329522642607917\n",
      "2.3035566912330614\n",
      "epoch: 0 loss: 1.9353443384170532 grad: 26.637589533524647\n",
      "epoch: 1 loss: 1.5250730514526367 grad: 42.04641537140509\n",
      "epoch: 2 loss: 1.224830985069275 grad: 51.19035833043334\n",
      "epoch: 3 loss: 1.0828028917312622 grad: 57.80405289694423\n",
      "epoch: 4 loss: 0.9407339692115784 grad: 58.79790042176742\n",
      "epoch: 5 loss: 0.8536192774772644 grad: 62.2753515059621\n",
      "epoch: 6 loss: 0.7589877247810364 grad: 62.06216443212187\n",
      "epoch: 7 loss: 0.696536123752594 grad: 62.44288831738456\n",
      "epoch: 8 loss: 0.6593950986862183 grad: 65.96016061859413\n",
      "epoch: 9 loss: 0.5791593194007874 grad: 59.87499950743653\n",
      "epoch: 10 loss: 0.5381817817687988 grad: 59.34601353643438\n",
      "epoch: 11 loss: 0.4932175278663635 grad: 61.514333033728356\n",
      "epoch: 12 loss: 0.4724864065647125 grad: 65.04582740512669\n",
      "epoch: 13 loss: 0.42483067512512207 grad: 58.21670205181521\n",
      "epoch: 14 loss: 0.3932361900806427 grad: 54.19443388883726\n",
      "epoch: 15 loss: 0.35638853907585144 grad: 52.76690627421487\n",
      "epoch: 16 loss: 0.343528151512146 grad: 49.97441978674163\n",
      "epoch: 17 loss: 0.3279220759868622 grad: 52.065929932239\n",
      "epoch: 18 loss: 0.3268738389015198 grad: 57.53992246560757\n",
      "epoch: 19 loss: 0.2907962203025818 grad: 50.607567776056904\n",
      "2.520500296506275\n",
      "epoch: 0 loss: 2.3067216873168945 grad: 8.507285935386406\n",
      "epoch: 1 loss: 2.073385715484619 grad: 13.874691285662632\n",
      "epoch: 2 loss: 1.884765863418579 grad: 17.15815566008407\n",
      "epoch: 3 loss: 1.76099693775177 grad: 20.565222016259977\n",
      "epoch: 4 loss: 1.4652445316314697 grad: 23.152747798238234\n",
      "epoch: 5 loss: 1.3190573453903198 grad: 23.887451956947633\n",
      "epoch: 6 loss: 1.1430875062942505 grad: 24.406805212854994\n",
      "epoch: 7 loss: 0.9542931914329529 grad: 23.605294939209628\n",
      "epoch: 8 loss: 0.7698459625244141 grad: 23.59346587198053\n",
      "epoch: 9 loss: 0.5995425581932068 grad: 20.060266078252212\n",
      "epoch: 10 loss: 0.5167378783226013 grad: 16.456596953924194\n",
      "epoch: 11 loss: 0.5338065028190613 grad: 17.083010663273352\n",
      "epoch: 12 loss: 0.43788185715675354 grad: 14.716363570166159\n",
      "epoch: 13 loss: 0.444348007440567 grad: 14.689653416448037\n",
      "epoch: 14 loss: 0.40237319469451904 grad: 13.650882486703907\n",
      "epoch: 15 loss: 0.33031606674194336 grad: 11.67935417413181\n",
      "epoch: 16 loss: 0.291881263256073 grad: 11.252683361691693\n",
      "epoch: 17 loss: 0.31755760312080383 grad: 14.198920334686372\n",
      "epoch: 18 loss: 0.23900790512561798 grad: 9.322578743226302\n",
      "epoch: 19 loss: 0.24911616742610931 grad: 9.435052115432532\n",
      "3.9432618274983797\n",
      "epoch: 0 loss: 2.3059887886047363 grad: 4.150224778447184\n",
      "epoch: 1 loss: 2.3054380416870117 grad: 4.130377059545309\n",
      "epoch: 2 loss: 2.3035662174224854 grad: 4.126452976935543\n",
      "epoch: 3 loss: 2.303490161895752 grad: 4.143983230066777\n",
      "epoch: 4 loss: 2.3030359745025635 grad: 4.1364879810075506\n",
      "epoch: 5 loss: 2.3041462898254395 grad: 4.139369806959003\n",
      "epoch: 6 loss: 2.3029472827911377 grad: 4.12961457543989\n",
      "epoch: 7 loss: 2.304015874862671 grad: 4.125976847234298\n",
      "epoch: 8 loss: 2.3037071228027344 grad: 4.103713590376196\n",
      "epoch: 9 loss: 2.3029329776763916 grad: 4.107595088675327\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 10 loss: 2.302549362182617 grad: 4.100930197086302\n",
      "epoch: 11 loss: 2.302765130996704 grad: 4.110909150035004\n",
      "epoch: 12 loss: 2.302828311920166 grad: 4.107038731569017\n",
      "epoch: 13 loss: 2.3034586906433105 grad: 4.104348873588373\n",
      "epoch: 14 loss: 2.303367853164673 grad: 4.102570563305519\n",
      "epoch: 15 loss: 2.3024497032165527 grad: 4.099266061108734\n",
      "epoch: 16 loss: 2.3031704425811768 grad: 4.097881898522784\n",
      "epoch: 17 loss: 2.302025318145752 grad: 4.087650120667647\n",
      "epoch: 18 loss: 2.3026788234710693 grad: 4.092268724644789\n",
      "epoch: 19 loss: 2.302828311920166 grad: 4.0964767718391375\n",
      "2.3034831220715097\n",
      "epoch: 0 loss: 2.112884283065796 grad: 17.46052364313608\n",
      "epoch: 1 loss: 1.608406662940979 grad: 42.98734911277919\n",
      "epoch: 2 loss: 1.237836241722107 grad: 60.82165473867754\n",
      "epoch: 3 loss: 0.9945682287216187 grad: 69.29594862783674\n",
      "epoch: 4 loss: 0.8483163714408875 grad: 67.34350027177926\n",
      "epoch: 5 loss: 0.7278653979301453 grad: 67.18651735355841\n",
      "epoch: 6 loss: 0.6485707759857178 grad: 69.47522427008236\n",
      "epoch: 7 loss: 0.5917313098907471 grad: 71.28501026200978\n",
      "epoch: 8 loss: 0.5107876658439636 grad: 67.76928973673563\n",
      "epoch: 9 loss: 0.4498422145843506 grad: 65.3849928300695\n",
      "epoch: 10 loss: 0.4072774350643158 grad: 63.500733579820654\n",
      "epoch: 11 loss: 0.3703018128871918 grad: 63.197405958284385\n",
      "epoch: 12 loss: 0.3451206386089325 grad: 58.831320623738634\n",
      "epoch: 13 loss: 0.3252226412296295 grad: 54.211593468380165\n",
      "epoch: 14 loss: 0.2903282046318054 grad: 54.50977864944387\n",
      "epoch: 15 loss: 0.27640029788017273 grad: 53.14301464137581\n",
      "epoch: 16 loss: 0.262726366519928 grad: 53.45026162461594\n",
      "epoch: 17 loss: 0.24987033009529114 grad: 53.02212439415994\n",
      "epoch: 18 loss: 0.2360369861125946 grad: 48.913053252248176\n",
      "epoch: 19 loss: 0.21780259907245636 grad: 47.12582720506228\n",
      "2.2400540007269663\n",
      "2.158447292053972\n",
      "2.158447292053972\n",
      "epoch: 0 loss: 2.319901704788208 grad: 5.474841365968726\n",
      "epoch: 1 loss: 2.323530912399292 grad: 5.544503705522881\n",
      "epoch: 2 loss: 2.1953070163726807 grad: 9.212125926199256\n",
      "epoch: 3 loss: 2.1659255027770996 grad: 11.926237703774138\n",
      "epoch: 4 loss: 2.055945634841919 grad: 12.485041975874658\n",
      "epoch: 5 loss: 2.0602126121520996 grad: 12.87103657393828\n",
      "epoch: 6 loss: 1.9883402585983276 grad: 15.510223614941566\n",
      "epoch: 7 loss: 1.9565304517745972 grad: 17.12862381479134\n",
      "epoch: 8 loss: 1.9337165355682373 grad: 18.080322920023185\n",
      "epoch: 9 loss: 1.8630982637405396 grad: 18.631545364144845\n",
      "epoch: 10 loss: 1.835355281829834 grad: 18.963479864914152\n",
      "epoch: 11 loss: 1.7148867845535278 grad: 19.879194701136637\n",
      "epoch: 12 loss: 1.651166558265686 grad: 19.749707281586517\n",
      "epoch: 13 loss: 1.570751667022705 grad: 20.792867337500066\n",
      "epoch: 14 loss: 1.4827090501785278 grad: 23.265693451726815\n",
      "epoch: 15 loss: 1.32893967628479 grad: 23.779532686409485\n",
      "epoch: 16 loss: 1.1566678285598755 grad: 23.608974713449093\n",
      "epoch: 17 loss: 1.0321637392044067 grad: 23.34795603387589\n",
      "epoch: 18 loss: 0.9602262377738953 grad: 21.7635329346116\n",
      "epoch: 19 loss: 0.8548838496208191 grad: 21.18452775278552\n",
      "3.8753819071588835\n",
      "epoch: 0 loss: 2.306118965148926 grad: 4.111717989652185\n",
      "epoch: 1 loss: 2.3049519062042236 grad: 4.118799144092715\n",
      "epoch: 2 loss: 2.304885149002075 grad: 4.116741729743138\n",
      "epoch: 3 loss: 2.3038716316223145 grad: 4.118413515624066\n",
      "epoch: 4 loss: 2.303579092025757 grad: 4.112505186701135\n",
      "epoch: 5 loss: 2.30344295501709 grad: 4.135638907996123\n",
      "epoch: 6 loss: 2.3041534423828125 grad: 4.122635366899019\n",
      "epoch: 7 loss: 2.302485466003418 grad: 4.117600022765807\n",
      "epoch: 8 loss: 2.303483486175537 grad: 4.121240863358602\n",
      "epoch: 9 loss: 2.303102731704712 grad: 4.116768915311608\n",
      "epoch: 10 loss: 2.30364990234375 grad: 4.122367606442072\n",
      "epoch: 11 loss: 2.3021738529205322 grad: 4.113423970277829\n",
      "epoch: 12 loss: 2.3031508922576904 grad: 4.118504323617089\n",
      "epoch: 13 loss: 2.3024518489837646 grad: 4.116099341164576\n",
      "epoch: 14 loss: 2.3024418354034424 grad: 4.110810372861859\n",
      "epoch: 15 loss: 2.302753210067749 grad: 4.126044383004483\n",
      "epoch: 16 loss: 2.3028206825256348 grad: 4.118379323090019\n",
      "epoch: 17 loss: 2.3036611080169678 grad: 4.130197497831949\n",
      "epoch: 18 loss: 2.3027889728546143 grad: 4.102056251869886\n",
      "epoch: 19 loss: 2.302686929702759 grad: 4.110109497001278\n",
      "2.3031747744116986\n",
      "epoch: 0 loss: 2.0223548412323 grad: 22.845726184435886\n",
      "epoch: 1 loss: 1.6279975175857544 grad: 38.510857961736384\n",
      "epoch: 2 loss: 1.4145641326904297 grad: 48.73920551857074\n",
      "epoch: 3 loss: 1.2552525997161865 grad: 51.97137080451194\n",
      "epoch: 4 loss: 1.0870000123977661 grad: 54.58921131821908\n",
      "epoch: 5 loss: 0.9401329159736633 grad: 54.66245558698412\n",
      "epoch: 6 loss: 0.8504698276519775 grad: 57.068628658874125\n",
      "epoch: 7 loss: 0.7781397700309753 grad: 57.25657306392298\n",
      "epoch: 8 loss: 0.7098682522773743 grad: 59.68520330079154\n",
      "epoch: 9 loss: 0.63474440574646 grad: 55.267368646419264\n",
      "epoch: 10 loss: 0.5661829113960266 grad: 56.318436812508715\n",
      "epoch: 11 loss: 0.49379241466522217 grad: 54.74466916943519\n",
      "epoch: 12 loss: 0.43960556387901306 grad: 57.2622466539692\n",
      "epoch: 13 loss: 0.4007338285446167 grad: 56.23855033245249\n",
      "epoch: 14 loss: 0.3703521192073822 grad: 53.738715062844\n",
      "epoch: 15 loss: 0.33382248878479004 grad: 55.563643222041165\n",
      "epoch: 16 loss: 0.30891308188438416 grad: 51.790113582876785\n",
      "epoch: 17 loss: 0.28210681676864624 grad: 49.03028901761358\n",
      "epoch: 18 loss: 0.2588498592376709 grad: 45.465284096066085\n",
      "epoch: 19 loss: 0.2627873122692108 grad: 51.925669781499785\n",
      "2.2798446989833154\n",
      "epoch: 0 loss: 2.2630767822265625 grad: 12.031408790239581\n",
      "epoch: 1 loss: 2.125692129135132 grad: 13.699735752117583\n",
      "epoch: 2 loss: 1.9347625970840454 grad: 17.737029528120786\n",
      "epoch: 3 loss: 2.0167877674102783 grad: 18.322730165866044\n",
      "epoch: 4 loss: 1.9636447429656982 grad: 19.764277300070397\n",
      "epoch: 5 loss: 1.4790252447128296 grad: 24.591273755716927\n",
      "epoch: 6 loss: 1.2710342407226562 grad: 25.108216858399064\n",
      "epoch: 7 loss: 1.186160922050476 grad: 24.5956027810044\n",
      "epoch: 8 loss: 0.9786699414253235 grad: 24.482196921965908\n",
      "epoch: 9 loss: 0.7863791584968567 grad: 23.1316685366287\n",
      "epoch: 10 loss: 0.6988078355789185 grad: 21.90787252941029\n",
      "epoch: 11 loss: 0.5372340679168701 grad: 17.874181052120104\n",
      "epoch: 12 loss: 0.49217894673347473 grad: 17.150013478209253\n",
      "epoch: 13 loss: 0.4244347810745239 grad: 15.800609228005161\n",
      "epoch: 14 loss: 0.41099944710731506 grad: 14.854835828282162\n",
      "epoch: 15 loss: 0.32602813839912415 grad: 13.159024900448761\n",
      "epoch: 16 loss: 0.30624687671661377 grad: 12.087577122620964\n",
      "epoch: 17 loss: 0.31721365451812744 grad: 13.117908436889634\n",
      "epoch: 18 loss: 0.22757120430469513 grad: 9.739156269718569\n",
      "epoch: 19 loss: 0.2547104060649872 grad: 10.271888729055119\n",
      "3.445011902924234\n",
      "epoch: 0 loss: 2.305110216140747 grad: 4.26313407556212\n",
      "epoch: 1 loss: 2.3049116134643555 grad: 4.258721663531905\n",
      "epoch: 2 loss: 2.3036909103393555 grad: 4.25820496604609\n",
      "epoch: 3 loss: 2.3041186332702637 grad: 4.263540199574432\n",
      "epoch: 4 loss: 2.303624391555786 grad: 4.261062934092246\n",
      "epoch: 5 loss: 2.3033175468444824 grad: 4.26050875745347\n",
      "epoch: 6 loss: 2.302535057067871 grad: 4.262931657543813\n",
      "epoch: 7 loss: 2.3033385276794434 grad: 4.263786896839622\n",
      "epoch: 8 loss: 2.304013252258301 grad: 4.270624986295704\n",
      "epoch: 9 loss: 2.3032338619232178 grad: 4.264358319545805\n",
      "epoch: 10 loss: 2.3030643463134766 grad: 4.245009870011418\n",
      "epoch: 11 loss: 2.3031110763549805 grad: 4.241381337513623\n",
      "epoch: 12 loss: 2.302581548690796 grad: 4.250461588926264\n",
      "epoch: 13 loss: 2.303187608718872 grad: 4.2355555088963595\n",
      "epoch: 14 loss: 2.3032286167144775 grad: 4.251735725726409\n",
      "epoch: 15 loss: 2.301785469055176 grad: 4.235940774738381\n",
      "epoch: 16 loss: 2.3013460636138916 grad: 4.246919649029558\n",
      "epoch: 17 loss: 2.3012874126434326 grad: 4.274119608715933\n",
      "epoch: 18 loss: 2.3025283813476562 grad: 4.273796271085041\n",
      "epoch: 19 loss: 2.301954507827759 grad: 4.283739750843845\n",
      "2.3014575389309426\n",
      "optimal lambda 0.001\n",
      "optimal optimiser adagrad\n",
      "optimal dropout 0.3\n"
     ]
    }
   ],
   "source": [
    "##hyperparameter tuning\n",
    "la2=0\n",
    "optim2=''\n",
    "op2=0\n",
    "lams = [0.005,0.001,0.0005]\n",
    "optis = ['adagrad','adam','sgd']\n",
    "valoss=999\n",
    "dp=[0.2,0.25,0.3]\n",
    "for d in dp:\n",
    "    for l in lams:\n",
    "            for opt in optis:\n",
    "                modellstm = lstm(13,300,3,10,d)\n",
    "                modellstm.to(device)\n",
    "                modellstm.train(traindl2,epochs = 20, learning_rate=0.001,lam=l,opti=opt)\n",
    "                if valoss>test(modellstm,valdl2):\n",
    "                    valoss=test(modellstm,valdl2)\n",
    "                    print(valoss)\n",
    "                    la2=l\n",
    "                    optim2=opt\n",
    "                    op2=d\n",
    "print(\"optimal lambda\",la2)\n",
    "print(\"optimal optimiser\",optim2) \n",
    "print(\"optimal dropout\",op2) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 507,
   "id": "761c38b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "la2=0.001\n",
    "optim2 = 'adagrad'\n",
    "op2 = 0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 508,
   "id": "69ec54dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "modellstm = lstm(13,300,3,10,op2)\n",
    "modellstm.to(device)\n",
    "losslstm=[]\n",
    "parlstm=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 509,
   "id": "09011e24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of parameters: 5231460\n"
     ]
    }
   ],
   "source": [
    "total_params = sum(p.numel() for p in modellstm.parameters())\n",
    "print(\"Total number of parameters:\", total_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 569,
   "id": "b3bee784",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0 loss: 0.29006949067115784 grad: 70.65696149330094\n",
      "epoch: 1 loss: 0.100715272128582 grad: 37.94345529790228\n",
      "epoch: 2 loss: 0.08786948770284653 grad: 30.114555227613142\n",
      "epoch: 3 loss: 0.06301166862249374 grad: 22.884288541586983\n",
      "epoch: 4 loss: 0.05710066109895706 grad: 19.201688987976027\n",
      "epoch: 5 loss: 0.048478346318006516 grad: 15.353685103537712\n",
      "epoch: 6 loss: 0.056079283356666565 grad: 24.159134450638557\n",
      "epoch: 7 loss: 0.042572639882564545 grad: 13.056986032744682\n",
      "epoch: 8 loss: 0.049222297966480255 grad: 16.85953566353665\n",
      "epoch: 9 loss: 0.047547709196805954 grad: 15.586507278063625\n",
      "epoch: 10 loss: 0.041832197457551956 grad: 15.428330295497107\n",
      "epoch: 11 loss: 0.04456775635480881 grad: 15.049432995212184\n",
      "epoch: 12 loss: 0.035782650113105774 grad: 11.638522618565055\n",
      "epoch: 13 loss: 0.04854654148221016 grad: 23.163851177108075\n",
      "epoch: 14 loss: 0.03994340822100639 grad: 12.766604673261888\n",
      "epoch: 15 loss: 0.035150520503520966 grad: 11.186397932418574\n",
      "epoch: 16 loss: 0.026886750012636185 grad: 10.766428433707473\n",
      "epoch: 17 loss: 0.03540817275643349 grad: 13.441788524730004\n",
      "epoch: 18 loss: 0.02917606756091118 grad: 11.128897609375533\n",
      "epoch: 19 loss: 0.03150549158453941 grad: 11.954899414083556\n",
      "epoch: 20 loss: 0.0494806282222271 grad: 21.285629343139824\n",
      "epoch: 21 loss: 0.032777339220047 grad: 12.028206325797678\n",
      "epoch: 22 loss: 0.03175855800509453 grad: 10.93274333332344\n",
      "epoch: 23 loss: 0.030319778248667717 grad: 11.078536228298246\n",
      "epoch: 24 loss: 0.02909146063029766 grad: 12.009561843537252\n",
      "epoch: 25 loss: 0.037324514240026474 grad: 16.28703536301173\n",
      "epoch: 26 loss: 0.028309522196650505 grad: 11.498164871866845\n",
      "epoch: 27 loss: 0.02968895249068737 grad: 10.999413813759721\n",
      "epoch: 28 loss: 0.023997465148568153 grad: 7.841945484484928\n",
      "epoch: 29 loss: 0.023287063464522362 grad: 8.730987666811277\n",
      "epoch: 30 loss: 0.026555515825748444 grad: 9.034829606253448\n",
      "epoch: 31 loss: 0.021219950169324875 grad: 6.8014284380175285\n",
      "epoch: 32 loss: 0.02611060068011284 grad: 8.208122730586645\n",
      "epoch: 33 loss: 0.023645125329494476 grad: 8.14635876086754\n",
      "epoch: 34 loss: 0.023974962532520294 grad: 8.105519851312685\n",
      "epoch: 35 loss: 0.020351003855466843 grad: 7.346659915242561\n",
      "epoch: 36 loss: 0.026614591479301453 grad: 10.063149195052615\n",
      "epoch: 37 loss: 0.021821267902851105 grad: 7.902546020348882\n",
      "epoch: 38 loss: 0.026544706895947456 grad: 12.357855710635052\n",
      "epoch: 39 loss: 0.020664116367697716 grad: 6.69329395105962\n",
      "epoch: 40 loss: 0.020463349297642708 grad: 7.1886974432380395\n",
      "epoch: 41 loss: 0.01991991698741913 grad: 6.3429962668701245\n",
      "epoch: 42 loss: 0.021425556391477585 grad: 8.082762768688236\n",
      "epoch: 43 loss: 0.0196617990732193 grad: 6.83923200213403\n",
      "epoch: 44 loss: 0.018921473994851112 grad: 6.667868841131019\n",
      "epoch: 45 loss: 0.019367145374417305 grad: 7.06340520321256\n",
      "epoch: 46 loss: 0.018892258405685425 grad: 7.694212601771026\n",
      "epoch: 47 loss: 0.023580817505717278 grad: 9.094532910959444\n",
      "epoch: 48 loss: 0.019459612667560577 grad: 9.747387832502453\n",
      "epoch: 49 loss: 0.018517641350626945 grad: 6.950666903242183\n",
      "epoch: 50 loss: 0.021469270810484886 grad: 13.129855552076302\n",
      "epoch: 51 loss: 0.019270870834589005 grad: 8.84645933662231\n",
      "epoch: 52 loss: 0.015157684683799744 grad: 7.47893198318314\n",
      "epoch: 53 loss: 0.01958930678665638 grad: 8.40391165201685\n",
      "epoch: 54 loss: 0.015017311088740826 grad: 6.80580431466659\n",
      "epoch: 55 loss: 0.019150730222463608 grad: 7.004516226615459\n",
      "epoch: 56 loss: 0.014906834810972214 grad: 5.706666972468847\n",
      "epoch: 57 loss: 0.016916286200284958 grad: 7.02724354078339\n",
      "epoch: 58 loss: 0.015353900380432606 grad: 5.920230697261167\n",
      "epoch: 59 loss: 0.02037038281559944 grad: 12.158562296117408\n",
      "epoch: 60 loss: 0.017378224059939384 grad: 6.855858253541677\n",
      "epoch: 61 loss: 0.01761280745267868 grad: 5.565992962522545\n",
      "epoch: 62 loss: 0.02718251943588257 grad: 18.190042553738405\n",
      "epoch: 63 loss: 0.019656116142868996 grad: 8.776335797221892\n",
      "epoch: 64 loss: 0.01962963119149208 grad: 7.958834349391818\n",
      "epoch: 65 loss: 0.012124110944569111 grad: 5.81047608106155\n",
      "epoch: 66 loss: 0.01722436398267746 grad: 5.795328404897191\n",
      "epoch: 67 loss: 0.014399521984159946 grad: 5.541277290962253\n",
      "epoch: 68 loss: 0.013003895059227943 grad: 5.099101344720987\n",
      "epoch: 69 loss: 0.014528508298099041 grad: 6.693912514143543\n",
      "epoch: 70 loss: 0.013118360191583633 grad: 5.892022049438385\n",
      "epoch: 71 loss: 0.016156034544110298 grad: 8.406192579324838\n",
      "epoch: 72 loss: 0.014006010256707668 grad: 8.535326215081533\n",
      "epoch: 73 loss: 0.015279659070074558 grad: 7.618567144935896\n",
      "epoch: 74 loss: 0.013024430721998215 grad: 5.3496187810278535\n",
      "epoch: 75 loss: 0.011841481551527977 grad: 4.322575655734138\n",
      "epoch: 76 loss: 0.011771583929657936 grad: 4.607719958932321\n",
      "epoch: 77 loss: 0.013385782949626446 grad: 5.412679327996022\n",
      "epoch: 78 loss: 0.009823625907301903 grad: 4.159079460276296\n",
      "epoch: 79 loss: 0.01599712111055851 grad: 6.737074892381377\n",
      "epoch: 80 loss: 0.012674098834395409 grad: 6.027225642815739\n",
      "epoch: 81 loss: 0.013322490267455578 grad: 5.158545927309089\n",
      "epoch: 82 loss: 0.010041841305792332 grad: 4.86658381788554\n",
      "epoch: 83 loss: 0.01764063909649849 grad: 6.943601543331885\n",
      "epoch: 84 loss: 0.011319977231323719 grad: 5.020724092543982\n",
      "epoch: 85 loss: 0.013079006224870682 grad: 6.670861931695402\n",
      "epoch: 86 loss: 0.012911852449178696 grad: 5.848586178772623\n",
      "epoch: 87 loss: 0.011694309301674366 grad: 5.113676851957606\n",
      "epoch: 88 loss: 0.012354850769042969 grad: 5.583237195651683\n",
      "epoch: 89 loss: 0.010084236972033978 grad: 5.452868508253843\n",
      "epoch: 90 loss: 0.011952420696616173 grad: 5.254077661778011\n",
      "epoch: 91 loss: 0.023984812200069427 grad: 21.12105767211422\n",
      "epoch: 92 loss: 0.01245702151209116 grad: 6.065171443419536\n",
      "epoch: 93 loss: 0.011292464099824429 grad: 6.464344021241419\n",
      "epoch: 94 loss: 0.015111944638192654 grad: 6.845112150416273\n",
      "epoch: 95 loss: 0.014154610224068165 grad: 4.7922824548762675\n",
      "epoch: 96 loss: 0.011621304787695408 grad: 4.729893236119378\n",
      "epoch: 97 loss: 0.011093377135694027 grad: 4.985862699143127\n",
      "epoch: 98 loss: 0.015639038756489754 grad: 11.879997985009032\n",
      "epoch: 99 loss: 0.010529221966862679 grad: 6.370555439125183\n",
      "epoch: 100 loss: 0.011613436974585056 grad: 4.929049076583411\n",
      "epoch: 101 loss: 0.009974119253456593 grad: 4.519735739811736\n",
      "epoch: 102 loss: 0.011143158189952374 grad: 5.683692365568173\n",
      "epoch: 103 loss: 0.007801244501024485 grad: 3.400117502133143\n",
      "epoch: 104 loss: 0.010357151739299297 grad: 3.679740030680344\n",
      "epoch: 105 loss: 0.011509782634675503 grad: 6.116180112283174\n",
      "epoch: 106 loss: 0.01412325818091631 grad: 13.366476120406324\n",
      "epoch: 107 loss: 0.010455330833792686 grad: 4.904974452767473\n",
      "epoch: 108 loss: 0.008421771228313446 grad: 4.664367230708594\n",
      "epoch: 109 loss: 0.011380153708159924 grad: 4.231411278610957\n",
      "epoch: 110 loss: 0.012956086546182632 grad: 5.767542150557995\n",
      "epoch: 111 loss: 0.011962786316871643 grad: 6.586856036817224\n",
      "epoch: 112 loss: 0.009427418000996113 grad: 4.44342871030278\n",
      "epoch: 113 loss: 0.00838632881641388 grad: 3.8347027522637935\n",
      "epoch: 114 loss: 0.009727860800921917 grad: 4.20260760849635\n",
      "epoch: 115 loss: 0.00860543828457594 grad: 4.3335703941234485\n",
      "epoch: 116 loss: 0.008244460448622704 grad: 4.081956288113764\n",
      "epoch: 117 loss: 0.007212786469608545 grad: 3.528466410828896\n",
      "epoch: 118 loss: 0.008962946012616158 grad: 4.055036318717147\n",
      "epoch: 119 loss: 0.011742686852812767 grad: 8.345789269377862\n",
      "epoch: 120 loss: 0.007333379704505205 grad: 6.650265354020084\n",
      "epoch: 121 loss: 0.00828256830573082 grad: 4.034669637624105\n",
      "epoch: 122 loss: 0.008426429703831673 grad: 3.547796843293006\n",
      "epoch: 123 loss: 0.007717909291386604 grad: 3.264731468093562\n",
      "epoch: 124 loss: 0.0123739680275321 grad: 6.35443476773607\n",
      "epoch: 125 loss: 0.009694639593362808 grad: 4.292407524984001\n",
      "epoch: 126 loss: 0.011776075698435307 grad: 5.62313508916771\n",
      "epoch: 127 loss: 0.008304628543555737 grad: 3.5903052616365665\n",
      "epoch: 128 loss: 0.012198766693472862 grad: 5.583661663285902\n",
      "epoch: 129 loss: 0.0072454591281712055 grad: 3.4105382260627115\n",
      "epoch: 130 loss: 0.007378972135484219 grad: 3.32348904740142\n",
      "epoch: 131 loss: 0.0062337531708180904 grad: 2.878079066000619\n",
      "epoch: 132 loss: 0.0083627225831151 grad: 3.875092591996105\n",
      "epoch: 133 loss: 0.010196021758019924 grad: 5.281205139846435\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 134 loss: 0.0063383677043020725 grad: 4.1157003002583235\n",
      "epoch: 135 loss: 0.01395602710545063 grad: 7.743097762263072\n",
      "epoch: 136 loss: 0.00787433236837387 grad: 4.349870258460618\n",
      "epoch: 137 loss: 0.007226372137665749 grad: 3.5826369116276\n",
      "epoch: 138 loss: 0.0083105294033885 grad: 3.8315161836649905\n",
      "epoch: 139 loss: 0.007267997600138187 grad: 4.225765592945624\n",
      "epoch: 140 loss: 0.007672966457903385 grad: 3.54402501910101\n",
      "epoch: 141 loss: 0.0096078896895051 grad: 6.221725997963756\n",
      "epoch: 142 loss: 0.00738327344879508 grad: 3.632080308446554\n",
      "epoch: 143 loss: 0.007084590382874012 grad: 4.148666499605571\n",
      "epoch: 144 loss: 0.006681727711111307 grad: 3.307129414525299\n",
      "epoch: 145 loss: 0.00866017583757639 grad: 3.9523965103977052\n",
      "epoch: 146 loss: 0.008524087257683277 grad: 4.1665510044969\n",
      "epoch: 147 loss: 0.006966063287109137 grad: 3.083062754160648\n",
      "epoch: 148 loss: 0.00825642328709364 grad: 4.517117838983163\n",
      "epoch: 149 loss: 0.02045331336557865 grad: 14.54707920203114\n",
      "epoch: 150 loss: 0.01616388000547886 grad: 9.002987583503131\n",
      "epoch: 151 loss: 0.008312532678246498 grad: 4.564576420135583\n",
      "epoch: 152 loss: 0.00872484128922224 grad: 4.23495985221973\n",
      "epoch: 153 loss: 0.008951864205300808 grad: 5.286776244403524\n",
      "epoch: 154 loss: 0.0052653104066848755 grad: 3.155113502990009\n",
      "epoch: 155 loss: 0.006126877386122942 grad: 3.5044289162614692\n",
      "epoch: 156 loss: 0.007721013389527798 grad: 5.649210745125514\n",
      "epoch: 157 loss: 0.012002432718873024 grad: 6.215395109964194\n",
      "epoch: 158 loss: 0.00771737564355135 grad: 3.5914711861145863\n",
      "epoch: 159 loss: 0.0058784387074410915 grad: 3.2018059367593894\n",
      "epoch: 160 loss: 0.004252011887729168 grad: 2.5719970516000834\n",
      "epoch: 161 loss: 0.0067789130844175816 grad: 4.510539753079955\n",
      "epoch: 162 loss: 0.013694539666175842 grad: 10.299872369192363\n",
      "epoch: 163 loss: 0.00677435752004385 grad: 3.778452142946168\n",
      "epoch: 164 loss: 0.00796438381075859 grad: 5.648045765150244\n",
      "epoch: 165 loss: 0.006900697480887175 grad: 3.761373650031994\n",
      "epoch: 166 loss: 0.006445176899433136 grad: 3.102510070194994\n",
      "epoch: 167 loss: 0.007383298594504595 grad: 4.733134863190057\n",
      "epoch: 168 loss: 0.00610407255589962 grad: 3.705492504339091\n",
      "epoch: 169 loss: 0.0064826663583517075 grad: 2.8622585692306246\n",
      "epoch: 170 loss: 0.007006209343671799 grad: 3.866685217498089\n",
      "epoch: 171 loss: 0.005181980784982443 grad: 3.0641092777771197\n",
      "epoch: 172 loss: 0.006550827529281378 grad: 2.822297448808936\n",
      "epoch: 173 loss: 0.004830834921449423 grad: 2.2874102267578755\n",
      "epoch: 174 loss: 0.00383228762075305 grad: 2.119332387346903\n",
      "epoch: 175 loss: 0.006290498189628124 grad: 3.17712103147054\n",
      "epoch: 176 loss: 0.005709824152290821 grad: 2.9437849972392125\n",
      "epoch: 177 loss: 0.0066003743559122086 grad: 3.4570525381517974\n",
      "epoch: 178 loss: 0.005330324172973633 grad: 2.659036342872469\n",
      "epoch: 179 loss: 0.00547402398660779 grad: 3.1381790088785726\n",
      "epoch: 180 loss: 0.006526767276227474 grad: 4.850333814078145\n",
      "epoch: 181 loss: 0.014249778352677822 grad: 11.564010805767706\n",
      "epoch: 182 loss: 0.005352985113859177 grad: 3.5915166261237124\n",
      "epoch: 183 loss: 0.005399724934250116 grad: 3.047742559560231\n",
      "epoch: 184 loss: 0.007795362267643213 grad: 5.00680272993208\n",
      "epoch: 185 loss: 0.006943740416318178 grad: 3.2721712817032613\n",
      "epoch: 186 loss: 0.006215357221662998 grad: 3.577619447433038\n",
      "epoch: 187 loss: 0.005520137492567301 grad: 3.1533785657333193\n",
      "epoch: 188 loss: 0.0073019154369831085 grad: 3.3687279433053536\n",
      "epoch: 189 loss: 0.006922736763954163 grad: 3.9080461532025703\n",
      "epoch: 190 loss: 0.0066432831808924675 grad: 3.726972647073883\n",
      "epoch: 191 loss: 0.02520591765642166 grad: 21.315645962193642\n",
      "epoch: 192 loss: 0.007297092117369175 grad: 4.714259008085253\n",
      "epoch: 193 loss: 0.004419312346726656 grad: 2.378980846841175\n",
      "epoch: 194 loss: 0.0064387014135718346 grad: 4.146697149748838\n",
      "epoch: 195 loss: 0.006378378253430128 grad: 3.413636030272087\n",
      "epoch: 196 loss: 0.0066476608626544476 grad: 5.555797366872134\n",
      "epoch: 197 loss: 0.004629506729543209 grad: 2.872738900550731\n",
      "epoch: 198 loss: 0.004847240634262562 grad: 2.7579419603733757\n",
      "epoch: 199 loss: 0.006113329902291298 grad: 2.7812576330555583\n",
      "4.798644358439247\n",
      "4.798644358439247\n"
     ]
    }
   ],
   "source": [
    "loss2,par2=modellstm.train(traindl2,epochs = 200,learning_rate=0.0005,lam=la2,opti=optim2)#100-0.001 #50-0.05 #100-0.01 #300-0.005 #1260 -  \n",
    "losslstm+=loss2\n",
    "parlstm+=par2\n",
    "print(test(modellstm,valdl2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43437f0f",
   "metadata": {},
   "source": [
    "#### Training curves\n",
    "The following shows the training curve for the LSTM based model trained with the optimal hyperparameter values. It can be observed that the loss reduces with time and also the norm of the gradient of the weights also comes closer to 0 after convergence. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 570,
   "id": "c412c257",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x504 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot(losslstm,parlstm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 571,
   "id": "a4eeeec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(modellstm,'D:/Saarland University/NNTI/project/models/modellstm.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 572,
   "id": "79b4ecaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "modellstm=torch.load('D:/Saarland University/NNTI/project/models/modellstm.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 573,
   "id": "4dc0e759",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T-SNE plot on the testing dataset:\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"T-SNE plot on the testing dataset:\")\n",
    "tsne_map(testdl2,modellstm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 574,
   "id": "c31c0195",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy:\n",
      "99.85000491142273 %\n",
      "validation accuracy:\n",
      "51.91146731376648 %\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5191146731376648"
      ]
     },
     "execution_count": 574,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Training accuracy:\")\n",
    "get_accuracy(traindl2,modellstm)\n",
    "print(\"validation accuracy:\")\n",
    "get_accuracy(valdl2,modellstm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 622,
   "id": "19f1c5d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss on test:\n",
      "4.605543970769243\n",
      "Training accuracy:\n",
      "99.9000072479248 %\n",
      "Test accuracy:\n",
      "52.08747386932373 %\n",
      "Training f1 score:\n",
      "F1 score: 0.9995\n",
      "Test f1 score:\n",
      "F1 score: 0.536779324055666\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 622,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Loss on test:\")\n",
    "test(modellstm,testdl2)\n",
    "print(\"Training accuracy:\")\n",
    "get_accuracy(traindl2,modellstm)\n",
    "print(\"Test accuracy:\")\n",
    "get_accuracy(testdl2,modellstm)\n",
    "print(\"Training f1 score:\")\n",
    "get_f1(traindl2,modellstm)\n",
    "print(\"Test f1 score:\")\n",
    "get_f1(testdl2,modellstm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 576,
   "id": "a2a6b7a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confusion matrix on the test dataset:\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x720 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"confusion matrix on the test dataset:\")\n",
    "confusionplot(testdl2,modellstm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 577,
   "id": "fdc50459",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The Classification Report for test set classification\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.83      0.88        53\n",
      "           1       0.56      0.82      0.66        55\n",
      "           2       0.41      0.39      0.40        54\n",
      "           3       0.88      0.83      0.85        46\n",
      "           4       0.41      0.15      0.22        46\n",
      "           5       0.23      0.16      0.19        50\n",
      "           6       0.36      0.83      0.50        46\n",
      "           7       0.52      0.91      0.67        47\n",
      "           8       0.36      0.14      0.21        56\n",
      "           9       0.79      0.30      0.43        50\n",
      "\n",
      "    accuracy                           0.53       503\n",
      "   macro avg       0.55      0.54      0.50       503\n",
      "weighted avg       0.55      0.53      0.50       503\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nThe Classification Report for test set classification\\n\")\n",
    "classificationReport(testdl2,modellstm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee461fc6",
   "metadata": {},
   "source": [
    "## Model 3: GRU nodes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6bcd219",
   "metadata": {},
   "source": [
    "The GRU architecture is having 3 GRU layers[6] followed by 3 Linear fully connected layers. Dropout layers are applied after every layer. the dropout probability is determined later during hyperparameter tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 505,
   "id": "d030732d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class gru(nn.Module):\n",
    "     def __init__(self, input_dim, hidden_dim, layer_dim, output_dim,op):\n",
    "        super(gru, self).__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.layer_dim = layer_dim\n",
    "        self.op = op\n",
    "        self.lstm = nn.GRU(input_dim, hidden_dim, layer_dim, batch_first=True,dropout=self.op, bidirectional = False)#, nonlinearity='relu')\n",
    "        \n",
    "        # Readout layer\n",
    "        self.fc1 = nn.Linear(hidden_dim, 200)\n",
    "        self.fc2 = nn.Linear(200, 100)\n",
    "        self.fc3 = nn.Linear(100, 50)\n",
    "        self.fc4 = nn.Linear(50, 10)\n",
    "        self.drp = nn.Dropout(self.op) \n",
    "\n",
    "     def forward(self, x):\n",
    "        h0 = torch.zeros(self.layer_dim, x.size(0), self.hidden_dim).requires_grad_().to(device)\n",
    "        out, _ = self.lstm(x, h0.detach() )\n",
    "        out = self.drp(self.fc1(out[:, -1, :])) \n",
    "        out = self.drp(self.fc2(out)) \n",
    "        out = self.drp(self.fc3(out)) \n",
    "        out = self.fc4(out) \n",
    "        return out\n",
    "     \n",
    "     def train(self,train_loader,learning_rate=0.01,epochs=5,lam=0.01,opti='adam'):\n",
    "            optidict={'adagrad':torch.optim.Adagrad(self.parameters(), lr=learning_rate),'adam':torch.optim.Adam(self.parameters(),lr=learning_rate),'sgd':torch.optim.SGD(self.parameters(), lr=learning_rate)}\n",
    "            loss_fn = nn.CrossEntropyLoss()\n",
    "            optimizer = optidict[opti]\n",
    "            optimizer.weight_decay = lam #torch.optim.Adam(self.parameters(),lr=learning_rate,weight_decay=lam)\n",
    "            lossrec=[]\n",
    "            par_grad=[]\n",
    "            for epoch in range(epochs):\n",
    "                tloss=0\n",
    "                total_grad=0\n",
    "                for i,(xs,ys) in enumerate(train_loader):\n",
    "                    xs=xs.to(device)\n",
    "                    ys=ys.to(device)\n",
    "                    pred = self.forward(xs.type(torch.FloatTensor).cuda())                \n",
    "                    loss = loss_fn(pred,ys) \n",
    "                    optimizer.zero_grad()\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "\n",
    "                    grad=0\n",
    "                    for p in self.parameters():\n",
    "                        grad+=torch.norm(p.grad).item()\n",
    "\n",
    "                    total_grad+=grad\n",
    "                    tloss+=loss\n",
    "                lossrec.append((tloss/len(train_loader)).log().item())\n",
    "                par_grad.append((total_grad/len(train_loader)))\n",
    "                print('epoch:',epoch,'loss:',(tloss/len(train_loader)).item(),'grad:',(total_grad/len(train_loader)))\n",
    "            return lossrec,par_grad"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e01a1e92",
   "metadata": {},
   "source": [
    "#### Tuning the Hyperparameters\n",
    "The following script is for selecting the optimal values for the hyperparameter by training the model multiple times with the different set of hyperparameters and then evaluating them based on the validation loss obtained. The hyperparameter values that gives the lowest values for validation loss are reported."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 506,
   "id": "deba2a8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0 loss: 1.7856202125549316 grad: 27.84880131639936\n",
      "epoch: 1 loss: 1.4441555738449097 grad: 40.70689341772627\n",
      "epoch: 2 loss: 1.2757692337036133 grad: 44.192594334236\n",
      "epoch: 3 loss: 1.1589734554290771 grad: 46.788749010769415\n",
      "epoch: 4 loss: 1.0788260698318481 grad: 47.76001072949474\n",
      "epoch: 5 loss: 1.0011959075927734 grad: 48.77970116989967\n",
      "epoch: 6 loss: 0.9396648406982422 grad: 48.754435664050284\n",
      "epoch: 7 loss: 0.8946279883384705 grad: 48.994496397767335\n",
      "epoch: 8 loss: 0.8373995423316956 grad: 48.86666957046062\n",
      "epoch: 9 loss: 0.7839179039001465 grad: 48.03751586283819\n",
      "epoch: 10 loss: 0.7335975766181946 grad: 47.334648642257335\n",
      "epoch: 11 loss: 0.6897276043891907 grad: 46.77948890905516\n",
      "epoch: 12 loss: 0.6471343040466309 grad: 46.716038548893486\n",
      "epoch: 13 loss: 0.6137343049049377 grad: 45.7118731013545\n",
      "epoch: 14 loss: 0.5598127245903015 grad: 44.216803745553975\n",
      "epoch: 15 loss: 0.5270741581916809 grad: 44.35322416058572\n",
      "epoch: 16 loss: 0.5089881420135498 grad: 43.567652926186014\n",
      "epoch: 17 loss: 0.491177499294281 grad: 43.568890814133404\n",
      "epoch: 18 loss: 0.4675857424736023 grad: 42.163876329514544\n",
      "epoch: 19 loss: 0.4421910345554352 grad: 41.3446953911186\n",
      "1.886782077498082\n",
      "1.8603128175882686\n",
      "1.8603128175882686\n",
      "epoch: 0 loss: 1.888830304145813 grad: 29.44434969641605\n",
      "epoch: 1 loss: 0.8540156483650208 grad: 28.1473204211463\n",
      "epoch: 2 loss: 0.5862944722175598 grad: 22.88044519730725\n",
      "epoch: 3 loss: 0.508606493473053 grad: 22.09503933917854\n",
      "epoch: 4 loss: 0.37855714559555054 grad: 17.790183023193734\n",
      "epoch: 5 loss: 0.42588576674461365 grad: 20.41735385452242\n",
      "epoch: 6 loss: 0.39775097370147705 grad: 21.004405002491502\n",
      "epoch: 7 loss: 0.3867076337337494 grad: 22.16325114300655\n",
      "epoch: 8 loss: 0.3123563528060913 grad: 17.818661438837225\n",
      "epoch: 9 loss: 0.34633150696754456 grad: 20.54339434450471\n",
      "epoch: 10 loss: 0.2963014245033264 grad: 16.314292767920495\n",
      "epoch: 11 loss: 0.39741483330726624 grad: 23.817711838114352\n",
      "epoch: 12 loss: 0.26622048020362854 grad: 17.588377563650802\n",
      "epoch: 13 loss: 0.33657434582710266 grad: 21.099793359040603\n",
      "epoch: 14 loss: 0.27965253591537476 grad: 17.828024838920413\n",
      "epoch: 15 loss: 0.3467453122138977 grad: 23.981599497504142\n",
      "epoch: 16 loss: 0.3413311243057251 grad: 22.031204472783145\n",
      "epoch: 17 loss: 0.2807874381542206 grad: 17.314859650867014\n",
      "epoch: 18 loss: 0.3648521602153778 grad: 23.95018740061473\n",
      "epoch: 19 loss: 0.36021217703819275 grad: 24.065171317238526\n",
      "4.702589422816468\n",
      "epoch: 0 loss: 2.307342052459717 grad: 5.135219343056902\n",
      "epoch: 1 loss: 2.302093505859375 grad: 5.157633983073756\n",
      "epoch: 2 loss: 2.2985799312591553 grad: 5.2589870873373\n",
      "epoch: 3 loss: 2.295548915863037 grad: 5.406341215113178\n",
      "epoch: 4 loss: 2.2904562950134277 grad: 5.693279987636954\n",
      "epoch: 5 loss: 2.2821571826934814 grad: 6.10188925973326\n",
      "epoch: 6 loss: 2.2679600715637207 grad: 6.761704167396761\n",
      "epoch: 7 loss: 2.2345447540283203 grad: 8.307276376727037\n",
      "epoch: 8 loss: 2.093675374984741 grad: 12.266377040285617\n",
      "epoch: 9 loss: 1.9072813987731934 grad: 19.061513317367993\n",
      "epoch: 10 loss: 1.7823503017425537 grad: 23.11589345924836\n",
      "epoch: 11 loss: 1.6505606174468994 grad: 27.451136837784667\n",
      "epoch: 12 loss: 1.512521505355835 grad: 32.21571379128448\n",
      "epoch: 13 loss: 1.3351709842681885 grad: 38.10269420984038\n",
      "epoch: 14 loss: 1.242415189743042 grad: 42.132697912588014\n",
      "epoch: 15 loss: 1.1866637468338013 grad: 44.35258193386893\n",
      "epoch: 16 loss: 1.1432673931121826 grad: 46.24834208332596\n",
      "epoch: 17 loss: 1.1016483306884766 grad: 45.69281027793535\n",
      "epoch: 18 loss: 1.068013072013855 grad: 45.2895390229905\n",
      "epoch: 19 loss: 1.0285780429840088 grad: 45.89830463137051\n",
      "2.4100029967440446\n",
      "epoch: 0 loss: 1.640136957168579 grad: 31.846861604474718\n",
      "epoch: 1 loss: 1.1886957883834839 grad: 46.76953225561324\n",
      "epoch: 2 loss: 1.033816933631897 grad: 50.67324337750714\n",
      "epoch: 3 loss: 0.9213627576828003 grad: 51.416874390551705\n",
      "epoch: 4 loss: 0.850883424282074 grad: 53.22819633848214\n",
      "epoch: 5 loss: 0.7859130501747131 grad: 53.09712780541973\n",
      "epoch: 6 loss: 0.7429958581924438 grad: 53.197102180842485\n",
      "epoch: 7 loss: 0.7049992084503174 grad: 52.482920876621336\n",
      "epoch: 8 loss: 0.6831583976745605 grad: 53.473501713341314\n",
      "epoch: 9 loss: 0.6386377811431885 grad: 52.11829138123989\n",
      "epoch: 10 loss: 0.5956054329872131 grad: 51.05148991674077\n",
      "epoch: 11 loss: 0.56557297706604 grad: 50.79890546350555\n",
      "epoch: 12 loss: 0.5363959670066833 grad: 49.30935573101814\n",
      "epoch: 13 loss: 0.5259928703308105 grad: 50.78900170977976\n",
      "epoch: 14 loss: 0.4969308376312256 grad: 49.447055612840124\n",
      "epoch: 15 loss: 0.48049458861351013 grad: 47.86075902570669\n",
      "epoch: 16 loss: 0.454076886177063 grad: 48.28930617686986\n",
      "epoch: 17 loss: 0.4362788200378418 grad: 45.95189177602616\n",
      "epoch: 18 loss: 0.4371151626110077 grad: 47.672123849121114\n",
      "epoch: 19 loss: 0.41089245676994324 grad: 46.02924412461137\n",
      "2.2640806018680304\n",
      "epoch: 0 loss: 2.030303716659546 grad: 27.61645041987369\n",
      "epoch: 1 loss: 0.8558399677276611 grad: 28.16987197429277\n",
      "epoch: 2 loss: 0.5572586059570312 grad: 21.808500300590957\n",
      "epoch: 3 loss: 0.4204309284687042 grad: 18.409825882935646\n",
      "epoch: 4 loss: 0.3707544803619385 grad: 16.29591429087464\n",
      "epoch: 5 loss: 0.4018021523952484 grad: 18.413832205164216\n",
      "epoch: 6 loss: 0.4010371267795563 grad: 19.97190066269607\n",
      "epoch: 7 loss: 0.24859768152236938 grad: 13.582823482444914\n",
      "epoch: 8 loss: 0.35164180397987366 grad: 18.253531935444805\n",
      "epoch: 9 loss: 0.31745803356170654 grad: 16.98008950900507\n",
      "epoch: 10 loss: 0.23593486845493317 grad: 13.920540368375777\n",
      "epoch: 11 loss: 0.30424922704696655 grad: 17.50452168545276\n",
      "epoch: 12 loss: 0.2797243595123291 grad: 16.18898370136294\n",
      "epoch: 13 loss: 0.2944644093513489 grad: 15.9104141693884\n",
      "epoch: 14 loss: 0.30738821625709534 grad: 18.69740230640955\n",
      "epoch: 15 loss: 0.25910916924476624 grad: 17.6858907774169\n",
      "epoch: 16 loss: 0.3451339602470398 grad: 22.32486430129831\n",
      "epoch: 17 loss: 0.38053271174430847 grad: 22.214613824735704\n",
      "epoch: 18 loss: 0.311526358127594 grad: 19.540982285145457\n",
      "epoch: 19 loss: 0.31719231605529785 grad: 22.321709726921533\n",
      "4.766778702013597\n",
      "epoch: 0 loss: 2.304882764816284 grad: 5.188282559970859\n",
      "epoch: 1 loss: 2.3021507263183594 grad: 5.222567417722195\n",
      "epoch: 2 loss: 2.3000872135162354 grad: 5.288571855397895\n",
      "epoch: 3 loss: 2.2962920665740967 grad: 5.373730561750941\n",
      "epoch: 4 loss: 2.2933363914489746 grad: 5.557856259055436\n",
      "epoch: 5 loss: 2.286790370941162 grad: 5.842864801277407\n",
      "epoch: 6 loss: 2.2742583751678467 grad: 6.395459344992414\n",
      "epoch: 7 loss: 2.2403485774993896 grad: 7.907912461587228\n",
      "epoch: 8 loss: 2.119279384613037 grad: 12.574651485696435\n",
      "epoch: 9 loss: 1.9836150407791138 grad: 18.78159104101546\n",
      "epoch: 10 loss: 1.8344886302947998 grad: 23.606351005032657\n",
      "epoch: 11 loss: 1.6365801095962524 grad: 30.440795445170952\n",
      "epoch: 12 loss: 1.5298279523849487 grad: 34.8467983972258\n",
      "epoch: 13 loss: 1.4759572744369507 grad: 37.95014061418292\n",
      "epoch: 14 loss: 1.4174613952636719 grad: 38.414958668039645\n",
      "epoch: 15 loss: 1.3907599449157715 grad: 41.071133996872234\n",
      "epoch: 16 loss: 1.3284586668014526 grad: 41.263430133002814\n",
      "epoch: 17 loss: 1.2910175323486328 grad: 42.44774521381641\n",
      "epoch: 18 loss: 1.2641475200653076 grad: 43.155554086237444\n",
      "epoch: 19 loss: 1.209804892539978 grad: 43.084765306802\n",
      "2.723168529510138\n",
      "epoch: 0 loss: 1.786495566368103 grad: 27.643168696140403\n",
      "epoch: 1 loss: 1.1781524419784546 grad: 45.375422414205445\n",
      "epoch: 2 loss: 1.0027103424072266 grad: 48.37250958845601\n",
      "epoch: 3 loss: 0.9161911010742188 grad: 49.663366397692236\n",
      "epoch: 4 loss: 0.859492301940918 grad: 49.46459049477318\n",
      "epoch: 5 loss: 0.8002930283546448 grad: 49.803519479652024\n",
      "epoch: 6 loss: 0.7493515610694885 grad: 49.20299618144665\n",
      "epoch: 7 loss: 0.7121222615242004 grad: 49.04967193364774\n",
      "epoch: 8 loss: 0.6674509644508362 grad: 47.9665650713388\n",
      "epoch: 9 loss: 0.6381620764732361 grad: 47.69781484706312\n",
      "epoch: 10 loss: 0.6001335382461548 grad: 46.335116748666394\n",
      "epoch: 11 loss: 0.5718438029289246 grad: 47.58175567111784\n",
      "epoch: 12 loss: 0.5387611985206604 grad: 45.448958710620886\n",
      "epoch: 13 loss: 0.5222699046134949 grad: 45.71144458708902\n",
      "epoch: 14 loss: 0.5003209114074707 grad: 45.2617782361356\n",
      "epoch: 15 loss: 0.4765234589576721 grad: 44.56359605410579\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 16 loss: 0.44288748502731323 grad: 41.85683545819364\n",
      "epoch: 17 loss: 0.4287336468696594 grad: 42.75775927193831\n",
      "epoch: 18 loss: 0.42176488041877747 grad: 41.866019275281175\n",
      "epoch: 19 loss: 0.3894976079463959 grad: 39.973589790429195\n",
      "1.9225804201951269\n",
      "epoch: 0 loss: 1.7202337980270386 grad: 31.26142902672579\n",
      "epoch: 1 loss: 0.788078784942627 grad: 29.220587387325647\n",
      "epoch: 2 loss: 0.5592096447944641 grad: 24.406382968400916\n",
      "epoch: 3 loss: 0.4656345248222351 grad: 21.843034961476803\n",
      "epoch: 4 loss: 0.4299066662788391 grad: 21.921633366724233\n",
      "epoch: 5 loss: 0.32148241996765137 grad: 18.48417718454964\n",
      "epoch: 6 loss: 0.3550991415977478 grad: 20.505217564837377\n",
      "epoch: 7 loss: 0.3338538110256195 grad: 20.3319923993439\n",
      "epoch: 8 loss: 0.30977392196655273 grad: 19.333349570726337\n",
      "epoch: 9 loss: 0.31869199872016907 grad: 20.303183399265997\n",
      "epoch: 10 loss: 0.3380860686302185 grad: 22.55317016446735\n",
      "epoch: 11 loss: 0.32694700360298157 grad: 23.06039809943519\n",
      "epoch: 12 loss: 0.34908977150917053 grad: 24.820359837741922\n",
      "epoch: 13 loss: 0.34051501750946045 grad: 24.22291959586306\n",
      "epoch: 14 loss: 0.37364932894706726 grad: 29.792068619063542\n",
      "epoch: 15 loss: 0.38786065578460693 grad: 28.74667418022926\n",
      "epoch: 16 loss: 0.3703877329826355 grad: 26.821335521415747\n",
      "epoch: 17 loss: 0.35788121819496155 grad: 25.905243360438664\n",
      "epoch: 18 loss: 0.3268580734729767 grad: 26.01592543099899\n",
      "epoch: 19 loss: 0.3511500656604767 grad: 27.445091578135123\n",
      "4.585833674499329\n",
      "epoch: 0 loss: 2.3038055896759033 grad: 5.046822147645056\n",
      "epoch: 1 loss: 2.302469491958618 grad: 5.0782774417237375\n",
      "epoch: 2 loss: 2.299740791320801 grad: 5.161624321861193\n",
      "epoch: 3 loss: 2.2966678142547607 grad: 5.291334345125593\n",
      "epoch: 4 loss: 2.2930872440338135 grad: 5.477624411104247\n",
      "epoch: 5 loss: 2.288651704788208 grad: 5.811367836828343\n",
      "epoch: 6 loss: 2.2803614139556885 grad: 6.222409551008605\n",
      "epoch: 7 loss: 2.2654225826263428 grad: 7.21456912591774\n",
      "epoch: 8 loss: 2.230465888977051 grad: 8.857756004615688\n",
      "epoch: 9 loss: 2.1268393993377686 grad: 12.799717178414575\n",
      "epoch: 10 loss: 1.9882268905639648 grad: 19.17875990369171\n",
      "epoch: 11 loss: 1.9055005311965942 grad: 23.251558182667008\n",
      "epoch: 12 loss: 1.768887996673584 grad: 26.609333332510666\n",
      "epoch: 13 loss: 1.6222267150878906 grad: 31.919821816746147\n",
      "epoch: 14 loss: 1.5041577816009521 grad: 35.6520609755849\n",
      "epoch: 15 loss: 1.378797173500061 grad: 38.81219944475824\n",
      "epoch: 16 loss: 1.2808971405029297 grad: 41.63161197807582\n",
      "epoch: 17 loss: 1.2264376878738403 grad: 44.61675005683745\n",
      "epoch: 18 loss: 1.1568697690963745 grad: 46.90878047359822\n",
      "epoch: 19 loss: 1.1105308532714844 grad: 47.696016905506085\n",
      "2.5073896116142347\n",
      "epoch: 0 loss: 1.7912956476211548 grad: 30.283283511071698\n",
      "epoch: 1 loss: 1.354007601737976 grad: 44.948438289931275\n",
      "epoch: 2 loss: 1.2257870435714722 grad: 47.797709946559856\n",
      "epoch: 3 loss: 1.1386158466339111 grad: 50.26223322108359\n",
      "epoch: 4 loss: 1.0618470907211304 grad: 50.45203870325885\n",
      "epoch: 5 loss: 0.9846460223197937 grad: 50.57093012296682\n",
      "epoch: 6 loss: 0.8873893022537231 grad: 50.85943387315317\n",
      "epoch: 7 loss: 0.8302769660949707 grad: 51.90960394278978\n",
      "epoch: 8 loss: 0.7868852019309998 grad: 52.34752442866328\n",
      "epoch: 9 loss: 0.7444666624069214 grad: 52.753250152568015\n",
      "epoch: 10 loss: 0.6984502673149109 grad: 51.39213744561553\n",
      "epoch: 11 loss: 0.6509435176849365 grad: 51.09887769811562\n",
      "epoch: 12 loss: 0.6335378289222717 grad: 49.677861395809366\n",
      "epoch: 13 loss: 0.5946435332298279 grad: 50.71837612171857\n",
      "epoch: 14 loss: 0.5705051422119141 grad: 50.24159320813895\n",
      "epoch: 15 loss: 0.5496068596839905 grad: 48.72783894985177\n",
      "epoch: 16 loss: 0.515727698802948 grad: 47.308697578075815\n",
      "epoch: 17 loss: 0.48852303624153137 grad: 46.921922337104554\n",
      "epoch: 18 loss: 0.48289909958839417 grad: 45.69592232456488\n",
      "epoch: 19 loss: 0.4594344198703766 grad: 44.86529956907099\n",
      "2.4232776263931117\n",
      "epoch: 0 loss: 1.916060447692871 grad: 31.224317681195515\n",
      "epoch: 1 loss: 0.9886859655380249 grad: 35.0094531712203\n",
      "epoch: 2 loss: 0.6160791516304016 grad: 27.865415726032516\n",
      "epoch: 3 loss: 0.5612163543701172 grad: 29.117094740280056\n",
      "epoch: 4 loss: 0.40317806601524353 grad: 20.822661629923726\n",
      "epoch: 5 loss: 0.4011094570159912 grad: 21.742451872677904\n",
      "epoch: 6 loss: 0.467731773853302 grad: 26.72621966880055\n",
      "epoch: 7 loss: 0.4168117642402649 grad: 25.151816545038056\n",
      "epoch: 8 loss: 0.32413843274116516 grad: 22.05044479392503\n",
      "epoch: 9 loss: 0.4447951912879944 grad: 28.673682814961314\n",
      "epoch: 10 loss: 0.3464459180831909 grad: 23.887691037621508\n",
      "epoch: 11 loss: 0.3340957462787628 grad: 22.34936030016851\n",
      "epoch: 12 loss: 0.39838168025016785 grad: 25.840494556201033\n",
      "epoch: 13 loss: 0.37649431824684143 grad: 25.577950540468915\n",
      "epoch: 14 loss: 0.3322034478187561 grad: 25.759317956873417\n",
      "epoch: 15 loss: 0.43612951040267944 grad: 33.13332013395357\n",
      "epoch: 16 loss: 0.4168502986431122 grad: 34.691572986024866\n",
      "epoch: 17 loss: 0.4773501753807068 grad: 35.79446673963707\n",
      "epoch: 18 loss: 0.42009907960891724 grad: 34.056211763740585\n",
      "epoch: 19 loss: 0.5287569761276245 grad: 41.155824302073135\n",
      "6.113618661785802\n",
      "epoch: 0 loss: 2.306521415710449 grad: 5.463298017043621\n",
      "epoch: 1 loss: 2.303156614303589 grad: 5.493045112058055\n",
      "epoch: 2 loss: 2.2978546619415283 grad: 5.597209884125739\n",
      "epoch: 3 loss: 2.295231580734253 grad: 5.761455905881711\n",
      "epoch: 4 loss: 2.288670063018799 grad: 6.024331927744671\n",
      "epoch: 5 loss: 2.279805898666382 grad: 6.496621275557205\n",
      "epoch: 6 loss: 2.2578766345977783 grad: 7.497410190301947\n",
      "epoch: 7 loss: 2.1843624114990234 grad: 10.334871594809927\n",
      "epoch: 8 loss: 2.0501832962036133 grad: 16.645472226032986\n",
      "epoch: 9 loss: 1.9716012477874756 grad: 20.576063858347943\n",
      "epoch: 10 loss: 1.9009495973587036 grad: 23.48979887359403\n",
      "epoch: 11 loss: 1.718295931816101 grad: 26.020516226359177\n",
      "epoch: 12 loss: 1.5235729217529297 grad: 33.48004689616955\n",
      "epoch: 13 loss: 1.3601570129394531 grad: 39.11294845196442\n",
      "epoch: 14 loss: 1.2881728410720825 grad: 44.25564198982099\n",
      "epoch: 15 loss: 1.2080378532409668 grad: 45.31676292395673\n",
      "epoch: 16 loss: 1.1814515590667725 grad: 47.41755313389527\n",
      "epoch: 17 loss: 1.123690128326416 grad: 46.883917107391404\n",
      "epoch: 18 loss: 1.0981082916259766 grad: 47.95365650623778\n",
      "epoch: 19 loss: 1.0584408044815063 grad: 47.40301731853705\n",
      "2.474726599309466\n",
      "epoch: 0 loss: 1.8358954191207886 grad: 30.293875142452308\n",
      "epoch: 1 loss: 1.2920230627059937 grad: 45.809867455569155\n",
      "epoch: 2 loss: 1.0513155460357666 grad: 49.90960593391082\n",
      "epoch: 3 loss: 0.9328755140304565 grad: 52.20136760161596\n",
      "epoch: 4 loss: 0.846133828163147 grad: 53.02624756615132\n",
      "epoch: 5 loss: 0.7718810439109802 grad: 51.08333503445185\n",
      "epoch: 6 loss: 0.7278838753700256 grad: 52.062834047823635\n",
      "epoch: 7 loss: 0.6859701871871948 grad: 51.628952502569895\n",
      "epoch: 8 loss: 0.6504579186439514 grad: 51.75698073633533\n",
      "epoch: 9 loss: 0.5942603349685669 grad: 49.535790125921835\n",
      "epoch: 10 loss: 0.5687205195426941 grad: 49.01598419841236\n",
      "epoch: 11 loss: 0.5424771308898926 grad: 48.35872806504679\n",
      "epoch: 12 loss: 0.5299651026725769 grad: 48.35153651003848\n",
      "epoch: 13 loss: 0.5010952353477478 grad: 48.941578903363244\n",
      "epoch: 14 loss: 0.4806635081768036 grad: 48.620439323881364\n",
      "epoch: 15 loss: 0.4711666405200958 grad: 49.3843271270307\n",
      "epoch: 16 loss: 0.43591567873954773 grad: 46.69957601917443\n",
      "epoch: 17 loss: 0.41588300466537476 grad: 46.060121956307874\n",
      "epoch: 18 loss: 0.40947386622428894 grad: 45.241527524468864\n",
      "epoch: 19 loss: 0.3850061297416687 grad: 43.76199577847308\n",
      "2.0429142594219876\n",
      "epoch: 0 loss: 1.9337821006774902 grad: 33.4099856267107\n",
      "epoch: 1 loss: 0.9116144180297852 grad: 32.02746046317676\n",
      "epoch: 2 loss: 0.6029580235481262 grad: 26.501895670866812\n",
      "epoch: 3 loss: 0.5169850587844849 grad: 23.85394452442295\n",
      "epoch: 4 loss: 0.4845696687698364 grad: 24.756090900001507\n",
      "epoch: 5 loss: 0.3783757984638214 grad: 19.637684678041975\n",
      "epoch: 6 loss: 0.40451404452323914 grad: 21.72069631349487\n",
      "epoch: 7 loss: 0.3382827043533325 grad: 19.196893815543863\n",
      "epoch: 8 loss: 0.35219892859458923 grad: 20.347641491898557\n",
      "epoch: 9 loss: 0.38117215037345886 grad: 24.25481105816449\n",
      "epoch: 10 loss: 0.3979211449623108 grad: 24.838685394224832\n",
      "epoch: 11 loss: 0.30801922082901 grad: 19.44294245904596\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 12 loss: 0.3957425653934479 grad: 23.618285645697693\n",
      "epoch: 13 loss: 0.4070846438407898 grad: 25.867609221920368\n",
      "epoch: 14 loss: 0.3233645558357239 grad: 24.780148674844266\n",
      "epoch: 15 loss: 0.4531673789024353 grad: 31.102822365422437\n",
      "epoch: 16 loss: 0.36091241240501404 grad: 23.783936792429543\n",
      "epoch: 17 loss: 0.36214885115623474 grad: 26.48288272896824\n",
      "epoch: 18 loss: 0.33529114723205566 grad: 24.4558421965783\n",
      "epoch: 19 loss: 0.41186246275901794 grad: 29.578749520201175\n",
      "6.064666621820429\n",
      "epoch: 0 loss: 2.304198980331421 grad: 5.52162345301127\n",
      "epoch: 1 loss: 2.3018813133239746 grad: 5.588463360508904\n",
      "epoch: 2 loss: 2.2982871532440186 grad: 5.735841956838965\n",
      "epoch: 3 loss: 2.2948684692382812 grad: 5.954993304458447\n",
      "epoch: 4 loss: 2.2905421257019043 grad: 6.3071763280578885\n",
      "epoch: 5 loss: 2.281625747680664 grad: 6.909874833306298\n",
      "epoch: 6 loss: 2.269798755645752 grad: 7.8875790926832705\n",
      "epoch: 7 loss: 2.2424988746643066 grad: 9.06841341610672\n",
      "epoch: 8 loss: 2.1909399032592773 grad: 11.137969571234658\n",
      "epoch: 9 loss: 2.083390235900879 grad: 15.598110427729786\n",
      "epoch: 10 loss: 1.980569839477539 grad: 20.30227316791471\n",
      "epoch: 11 loss: 1.881675124168396 grad: 23.276415242777205\n",
      "epoch: 12 loss: 1.6854591369628906 grad: 28.763867572281974\n",
      "epoch: 13 loss: 1.5576324462890625 grad: 34.716695246587506\n",
      "epoch: 14 loss: 1.4826185703277588 grad: 38.420356042326425\n",
      "epoch: 15 loss: 1.401879906654358 grad: 39.091773540187624\n",
      "epoch: 16 loss: 1.3207415342330933 grad: 41.297387624563186\n",
      "epoch: 17 loss: 1.24015474319458 grad: 43.78675935274176\n",
      "epoch: 18 loss: 1.1626160144805908 grad: 45.71539582210896\n",
      "epoch: 19 loss: 1.1046297550201416 grad: 47.41874159870579\n",
      "2.464958655305012\n",
      "epoch: 0 loss: 1.841636300086975 grad: 26.801089366025526\n",
      "epoch: 1 loss: 1.387393832206726 grad: 42.121649965287304\n",
      "epoch: 2 loss: 1.169830083847046 grad: 47.1449234143995\n",
      "epoch: 3 loss: 1.0080777406692505 grad: 47.95133565195727\n",
      "epoch: 4 loss: 0.917215883731842 grad: 48.89429762687589\n",
      "epoch: 5 loss: 0.8488981127738953 grad: 49.4148334663448\n",
      "epoch: 6 loss: 0.7712410688400269 grad: 49.15196104645931\n",
      "epoch: 7 loss: 0.7276984453201294 grad: 49.99105933382391\n",
      "epoch: 8 loss: 0.6781660914421082 grad: 48.41477068072446\n",
      "epoch: 9 loss: 0.6347599029541016 grad: 48.34278877648292\n",
      "epoch: 10 loss: 0.5847163796424866 grad: 47.03768253418218\n",
      "epoch: 11 loss: 0.5499088168144226 grad: 46.78660690645122\n",
      "epoch: 12 loss: 0.5344408750534058 grad: 45.80557369081511\n",
      "epoch: 13 loss: 0.5071626901626587 grad: 44.96936742075545\n",
      "epoch: 14 loss: 0.5018163919448853 grad: 45.90327345392051\n",
      "epoch: 15 loss: 0.4838843047618866 grad: 44.97143682359411\n",
      "epoch: 16 loss: 0.4709819555282593 grad: 45.12670761665472\n",
      "epoch: 17 loss: 0.4614650309085846 grad: 43.11194687332835\n",
      "epoch: 18 loss: 0.44024184346199036 grad: 43.000604249553064\n",
      "epoch: 19 loss: 0.42470788955688477 grad: 42.52823425661674\n",
      "2.2619488191127055\n",
      "epoch: 0 loss: 1.8776413202285767 grad: 32.851177721856644\n",
      "epoch: 1 loss: 1.052828311920166 grad: 37.16931025456665\n",
      "epoch: 2 loss: 0.6276053786277771 grad: 28.322115041620208\n",
      "epoch: 3 loss: 0.5047189593315125 grad: 25.257534439891753\n",
      "epoch: 4 loss: 0.47398641705513 grad: 25.929757286578564\n",
      "epoch: 5 loss: 0.374340295791626 grad: 20.583599578739573\n",
      "epoch: 6 loss: 0.4305276572704315 grad: 28.576288295401998\n",
      "epoch: 7 loss: 0.4265974164009094 grad: 26.453541493296083\n",
      "epoch: 8 loss: 0.41168537735939026 grad: 25.226620771905058\n",
      "epoch: 9 loss: 0.33713412284851074 grad: 22.184027200322312\n",
      "epoch: 10 loss: 0.3534092307090759 grad: 24.64575757088083\n",
      "epoch: 11 loss: 0.34455156326293945 grad: 23.508627813393502\n",
      "epoch: 12 loss: 0.4313857853412628 grad: 31.5086989917247\n",
      "epoch: 13 loss: 0.40283772349357605 grad: 29.626603518722057\n",
      "epoch: 14 loss: 0.4992847740650177 grad: 35.52135767593409\n",
      "epoch: 15 loss: 0.3578478693962097 grad: 27.8669644142178\n",
      "epoch: 16 loss: 0.3999885022640228 grad: 35.691800466073126\n",
      "epoch: 17 loss: 0.44333332777023315 grad: 35.89460284542602\n",
      "epoch: 18 loss: 0.4426751434803009 grad: 40.517426590904684\n",
      "epoch: 19 loss: 0.48385441303253174 grad: 37.7301791888164\n",
      "5.174313308887169\n",
      "epoch: 0 loss: 2.3054258823394775 grad: 5.293075660786592\n",
      "epoch: 1 loss: 2.302834987640381 grad: 5.294254846497439\n",
      "epoch: 2 loss: 2.2998597621917725 grad: 5.346003492290154\n",
      "epoch: 3 loss: 2.297220468521118 grad: 5.435942303448916\n",
      "epoch: 4 loss: 2.2941901683807373 grad: 5.6220137737644835\n",
      "epoch: 5 loss: 2.290006399154663 grad: 5.847582997138612\n",
      "epoch: 6 loss: 2.2824761867523193 grad: 6.233397307331674\n",
      "epoch: 7 loss: 2.2680511474609375 grad: 6.986479272769764\n",
      "epoch: 8 loss: 2.2392992973327637 grad: 8.531067524293437\n",
      "epoch: 9 loss: 2.1313514709472656 grad: 12.661918279441073\n",
      "epoch: 10 loss: 1.9170246124267578 grad: 21.24829085509479\n",
      "epoch: 11 loss: 1.7098846435546875 grad: 28.202840265881736\n",
      "epoch: 12 loss: 1.5684902667999268 grad: 34.523175689991795\n",
      "epoch: 13 loss: 1.4957717657089233 grad: 36.88099858717853\n",
      "epoch: 14 loss: 1.4306178092956543 grad: 38.78985648573702\n",
      "epoch: 15 loss: 1.345252275466919 grad: 39.7883938541885\n",
      "epoch: 16 loss: 1.2459723949432373 grad: 41.42766476200858\n",
      "epoch: 17 loss: 1.185331106185913 grad: 45.41958500882599\n",
      "epoch: 18 loss: 1.1271626949310303 grad: 46.13829866584012\n",
      "epoch: 19 loss: 1.0936287641525269 grad: 47.2580180643388\n",
      "2.5661491978149\n",
      "epoch: 0 loss: 1.8367077112197876 grad: 28.244521876454236\n",
      "epoch: 1 loss: 1.2977755069732666 grad: 47.55125988964725\n",
      "epoch: 2 loss: 1.1481704711914062 grad: 51.507467353429064\n",
      "epoch: 3 loss: 1.0243064165115356 grad: 51.51272880676418\n",
      "epoch: 4 loss: 0.9727855920791626 grad: 52.59492151664163\n",
      "epoch: 5 loss: 0.9296064376831055 grad: 53.31150048829106\n",
      "epoch: 6 loss: 0.8567929863929749 grad: 50.735029813088595\n",
      "epoch: 7 loss: 0.8320386409759521 grad: 51.72902503889951\n",
      "epoch: 8 loss: 0.7772730588912964 grad: 51.46098640137701\n",
      "epoch: 9 loss: 0.7610278725624084 grad: 51.064612046034775\n",
      "epoch: 10 loss: 0.71968013048172 grad: 50.20569136074197\n",
      "epoch: 11 loss: 0.6952274441719055 grad: 51.56378857777739\n",
      "epoch: 12 loss: 0.6555950045585632 grad: 48.96642613520936\n",
      "epoch: 13 loss: 0.6156498789787292 grad: 47.69960236778311\n",
      "epoch: 14 loss: 0.5907132029533386 grad: 48.53093935486791\n",
      "epoch: 15 loss: 0.5803746581077576 grad: 47.308180281003146\n",
      "epoch: 16 loss: 0.5531008839607239 grad: 46.75714145128776\n",
      "epoch: 17 loss: 0.5324532389640808 grad: 45.86019855911218\n",
      "epoch: 18 loss: 0.5242483615875244 grad: 46.21571776539964\n",
      "epoch: 19 loss: 0.5103297233581543 grad: 45.60592643466591\n",
      "1.6770854818813177\n",
      "1.6993859059016185\n",
      "1.6993859059016185\n",
      "epoch: 0 loss: 1.8968219757080078 grad: 32.259638234075624\n",
      "epoch: 1 loss: 0.9837687611579895 grad: 35.69965032662796\n",
      "epoch: 2 loss: 1.0743154287338257 grad: 34.96820556521915\n",
      "epoch: 3 loss: 0.5688951015472412 grad: 25.590348569249926\n",
      "epoch: 4 loss: 0.5136889219284058 grad: 27.655604319206965\n",
      "epoch: 5 loss: 0.42520609498023987 grad: 22.890303130601115\n",
      "epoch: 6 loss: 0.4732072055339813 grad: 28.9273233726757\n",
      "epoch: 7 loss: 0.3356255888938904 grad: 22.528353332463258\n",
      "epoch: 8 loss: 0.4724816083908081 grad: 30.472719305967235\n",
      "epoch: 9 loss: 0.3515068590641022 grad: 25.392301474972488\n",
      "epoch: 10 loss: 0.43492308259010315 grad: 28.932997602916362\n",
      "epoch: 11 loss: 0.39213475584983826 grad: 29.80210357085652\n",
      "epoch: 12 loss: 0.443982869386673 grad: 30.861699934372517\n",
      "epoch: 13 loss: 0.36179545521736145 grad: 27.780816999543\n",
      "epoch: 14 loss: 0.4271610379219055 grad: 31.77374108406998\n",
      "epoch: 15 loss: 0.5907683372497559 grad: 47.347131501535806\n",
      "epoch: 16 loss: 0.38734087347984314 grad: 32.691441440995355\n",
      "epoch: 17 loss: 0.49665704369544983 grad: 35.01984971009637\n",
      "epoch: 18 loss: 0.6151984930038452 grad: 46.994584421422864\n",
      "epoch: 19 loss: 0.3165237009525299 grad: 30.507674446394038\n",
      "9.224018050499014\n",
      "epoch: 0 loss: 2.30472731590271 grad: 5.990497626367025\n",
      "epoch: 1 loss: 2.300861358642578 grad: 6.060830500547774\n",
      "epoch: 2 loss: 2.2983922958374023 grad: 6.077256320737303\n",
      "epoch: 3 loss: 2.2942099571228027 grad: 6.1740830556415025\n",
      "epoch: 4 loss: 2.2881791591644287 grad: 6.422705919610336\n",
      "epoch: 5 loss: 2.2769410610198975 grad: 6.984050041414798\n",
      "epoch: 6 loss: 2.254746675491333 grad: 8.052702214402146\n",
      "epoch: 7 loss: 2.182114601135254 grad: 10.727673952795564\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 8 loss: 2.016057252883911 grad: 17.499211101057007\n",
      "epoch: 9 loss: 1.849097490310669 grad: 24.069992690088228\n",
      "epoch: 10 loss: 1.6659859418869019 grad: 30.814330939451583\n",
      "epoch: 11 loss: 1.5731362104415894 grad: 36.01873979200283\n",
      "epoch: 12 loss: 1.4886794090270996 grad: 38.527341115170856\n",
      "epoch: 13 loss: 1.454525113105774 grad: 40.88369936203584\n",
      "epoch: 14 loss: 1.3761563301086426 grad: 41.73264808942005\n",
      "epoch: 15 loss: 1.2883497476577759 grad: 43.170345583171354\n",
      "epoch: 16 loss: 1.1874593496322632 grad: 45.66879068114143\n",
      "epoch: 17 loss: 1.1274690628051758 grad: 47.39908451693866\n",
      "epoch: 18 loss: 1.103464961051941 grad: 48.71026367665333\n",
      "epoch: 19 loss: 1.0691518783569336 grad: 47.76688225298366\n",
      "2.435771085440895\n",
      "epoch: 0 loss: 1.8789472579956055 grad: 27.959486121595372\n",
      "epoch: 1 loss: 1.3924376964569092 grad: 43.379893261984805\n",
      "epoch: 2 loss: 1.191699743270874 grad: 48.3197538423863\n",
      "epoch: 3 loss: 1.0759263038635254 grad: 48.65398221433442\n",
      "epoch: 4 loss: 0.9933781623840332 grad: 51.47358571886859\n",
      "epoch: 5 loss: 0.925893247127533 grad: 50.75851608604836\n",
      "epoch: 6 loss: 0.8628743290901184 grad: 51.15286846501044\n",
      "epoch: 7 loss: 0.8115233182907104 grad: 51.77380681604698\n",
      "epoch: 8 loss: 0.7795912027359009 grad: 51.98530662165814\n",
      "epoch: 9 loss: 0.7531418204307556 grad: 52.37773230031297\n",
      "epoch: 10 loss: 0.7061554193496704 grad: 51.88351434572047\n",
      "epoch: 11 loss: 0.6866296529769897 grad: 52.08527939117384\n",
      "epoch: 12 loss: 0.627357006072998 grad: 50.64321103975165\n",
      "epoch: 13 loss: 0.6250399947166443 grad: 51.490984673127194\n",
      "epoch: 14 loss: 0.5919836163520813 grad: 49.419042631912994\n",
      "epoch: 15 loss: 0.5688589811325073 grad: 50.26669438716206\n",
      "epoch: 16 loss: 0.5559043884277344 grad: 50.783341335013596\n",
      "epoch: 17 loss: 0.5305622816085815 grad: 49.264145852222924\n",
      "epoch: 18 loss: 0.5203003883361816 grad: 49.88540437935649\n",
      "epoch: 19 loss: 0.48670074343681335 grad: 47.256795369811755\n",
      "2.0285628762047447\n",
      "epoch: 0 loss: 2.344296932220459 grad: 28.718271622758067\n",
      "epoch: 1 loss: 2.1085286140441895 grad: 26.63464654851706\n",
      "epoch: 2 loss: 1.7051804065704346 grad: 32.12468106885871\n",
      "epoch: 3 loss: 1.3528611660003662 grad: 35.96948926242322\n",
      "epoch: 4 loss: 1.2679747343063354 grad: 38.79604621778639\n",
      "epoch: 5 loss: 1.1016764640808105 grad: 38.72428708222869\n",
      "epoch: 6 loss: 0.9374194145202637 grad: 36.52636803359212\n",
      "epoch: 7 loss: 0.8919875025749207 grad: 36.595029814118696\n",
      "epoch: 8 loss: 0.7742885947227478 grad: 32.550870126977514\n",
      "epoch: 9 loss: 0.6829639077186584 grad: 31.873686022294255\n",
      "epoch: 10 loss: 0.637218177318573 grad: 29.206826483288467\n",
      "epoch: 11 loss: 0.6055386066436768 grad: 26.22990283497137\n",
      "epoch: 12 loss: 0.5503359436988831 grad: 25.41364478706478\n",
      "epoch: 13 loss: 0.5227255821228027 grad: 26.02134454295644\n",
      "epoch: 14 loss: 0.5853961706161499 grad: 28.985958098564314\n",
      "epoch: 15 loss: 0.47910192608833313 grad: 26.026219912019627\n",
      "epoch: 16 loss: 0.5295174717903137 grad: 30.962471361902903\n",
      "epoch: 17 loss: 0.5217522382736206 grad: 28.35333374363014\n",
      "epoch: 18 loss: 0.41513684391975403 grad: 24.409817980846036\n",
      "epoch: 19 loss: 0.42121899127960205 grad: 23.464968891411555\n",
      "3.149612467109635\n",
      "epoch: 0 loss: 2.3066518306732178 grad: 5.86197043377161\n",
      "epoch: 1 loss: 2.301907539367676 grad: 5.935142918341793\n",
      "epoch: 2 loss: 2.3007185459136963 grad: 5.996949984747917\n",
      "epoch: 3 loss: 2.297591209411621 grad: 6.1185670099165295\n",
      "epoch: 4 loss: 2.2943286895751953 grad: 6.306388687124476\n",
      "epoch: 5 loss: 2.2917771339416504 grad: 6.56737184587121\n",
      "epoch: 6 loss: 2.2845938205718994 grad: 6.969577724366449\n",
      "epoch: 7 loss: 2.272296190261841 grad: 7.747416980720125\n",
      "epoch: 8 loss: 2.255009651184082 grad: 8.867053495689294\n",
      "epoch: 9 loss: 2.21303391456604 grad: 10.486375563701614\n",
      "epoch: 10 loss: 2.1048340797424316 grad: 14.306936582269147\n",
      "epoch: 11 loss: 1.8935357332229614 grad: 22.29962404686399\n",
      "epoch: 12 loss: 1.689819574356079 grad: 30.371623217892367\n",
      "epoch: 13 loss: 1.5732678174972534 grad: 35.072058077797294\n",
      "epoch: 14 loss: 1.4985361099243164 grad: 38.12594855107181\n",
      "epoch: 15 loss: 1.3914554119110107 grad: 39.91903030297346\n",
      "epoch: 16 loss: 1.3136051893234253 grad: 42.686832489278984\n",
      "epoch: 17 loss: 1.230255126953125 grad: 45.684810830418485\n",
      "epoch: 18 loss: 1.1902825832366943 grad: 47.47645306126436\n",
      "epoch: 19 loss: 1.132851004600525 grad: 48.51516485990002\n",
      "2.5362775240213398\n",
      "epoch: 0 loss: 1.7994223833084106 grad: 28.775667464148487\n",
      "epoch: 1 loss: 1.3764187097549438 grad: 44.223732887538496\n",
      "epoch: 2 loss: 1.2765809297561646 grad: 48.10970584839105\n",
      "epoch: 3 loss: 1.153852939605713 grad: 48.147178574887455\n",
      "epoch: 4 loss: 1.0734132528305054 grad: 49.63578429849213\n",
      "epoch: 5 loss: 0.9989110827445984 grad: 50.44506111036567\n",
      "epoch: 6 loss: 0.9639535546302795 grad: 50.8932898443481\n",
      "epoch: 7 loss: 0.8869832754135132 grad: 50.87025881088216\n",
      "epoch: 8 loss: 0.8544652462005615 grad: 51.583058811635595\n",
      "epoch: 9 loss: 0.8122473359107971 grad: 51.05209561360488\n",
      "epoch: 10 loss: 0.7568143606185913 grad: 50.96648183458869\n",
      "epoch: 11 loss: 0.7117282152175903 grad: 50.1355172230076\n",
      "epoch: 12 loss: 0.6710574626922607 grad: 49.36040993944133\n",
      "epoch: 13 loss: 0.6396552920341492 grad: 49.08753194424976\n",
      "epoch: 14 loss: 0.5880881547927856 grad: 47.06349495404419\n",
      "epoch: 15 loss: 0.5524322390556335 grad: 45.923940890242626\n",
      "epoch: 16 loss: 0.5281714797019958 grad: 45.486522545750994\n",
      "epoch: 17 loss: 0.5107242465019226 grad: 45.67741567863141\n",
      "epoch: 18 loss: 0.4712960422039032 grad: 43.08710821495219\n",
      "epoch: 19 loss: 0.46646037697792053 grad: 43.52099033942782\n",
      "2.153540189984635\n",
      "epoch: 0 loss: 1.8095099925994873 grad: 39.209436562069754\n",
      "epoch: 1 loss: 0.9946427941322327 grad: 38.849852825331716\n",
      "epoch: 2 loss: 0.6302536129951477 grad: 29.10399587150982\n",
      "epoch: 3 loss: 0.6064691543579102 grad: 31.419813125495025\n",
      "epoch: 4 loss: 0.43580496311187744 grad: 23.606152944939822\n",
      "epoch: 5 loss: 0.48639485239982605 grad: 29.460769930921995\n",
      "epoch: 6 loss: 0.4140351712703705 grad: 25.269700584189962\n",
      "epoch: 7 loss: 0.4308273494243622 grad: 30.087392147933894\n",
      "epoch: 8 loss: 0.46794286370277405 grad: 31.544185983722585\n",
      "epoch: 9 loss: 0.41680750250816345 grad: 26.87097636280145\n",
      "epoch: 10 loss: 0.4483465254306793 grad: 33.81663439856792\n",
      "epoch: 11 loss: 0.3558027446269989 grad: 26.0653274447753\n",
      "epoch: 12 loss: 0.5428465008735657 grad: 41.159019393192146\n",
      "epoch: 13 loss: 0.41167739033699036 grad: 31.43597530629429\n",
      "epoch: 14 loss: 0.47973203659057617 grad: 40.423126018759255\n",
      "epoch: 15 loss: 0.5080013275146484 grad: 43.4159648750067\n",
      "epoch: 16 loss: 0.49441173672676086 grad: 44.9604293273034\n",
      "epoch: 17 loss: 0.5969517230987549 grad: 51.11326151462607\n",
      "epoch: 18 loss: 0.47562506794929504 grad: 45.11317515396988\n",
      "epoch: 19 loss: 0.5441364645957947 grad: 52.8330160150868\n",
      "6.044741371739965\n",
      "epoch: 0 loss: 2.306217670440674 grad: 5.883376551927999\n",
      "epoch: 1 loss: 2.3018980026245117 grad: 5.923096359530464\n",
      "epoch: 2 loss: 2.2981772422790527 grad: 6.039093981748447\n",
      "epoch: 3 loss: 2.2953994274139404 grad: 6.241428373273462\n",
      "epoch: 4 loss: 2.2911996841430664 grad: 6.490841237280984\n",
      "epoch: 5 loss: 2.2819056510925293 grad: 7.007460248424672\n",
      "epoch: 6 loss: 2.2675344944000244 grad: 7.940518927824684\n",
      "epoch: 7 loss: 2.2293050289154053 grad: 9.48670676981751\n",
      "epoch: 8 loss: 2.1322426795959473 grad: 13.254539214371704\n",
      "epoch: 9 loss: 2.0309531688690186 grad: 18.527262949803845\n",
      "epoch: 10 loss: 1.9766359329223633 grad: 21.93051696384512\n",
      "epoch: 11 loss: 1.9198577404022217 grad: 24.221532232784668\n",
      "epoch: 12 loss: 1.8258657455444336 grad: 25.87121778392419\n",
      "epoch: 13 loss: 1.6347836256027222 grad: 29.73026640809467\n",
      "epoch: 14 loss: 1.4547579288482666 grad: 37.572580531027285\n",
      "epoch: 15 loss: 1.3371633291244507 grad: 43.09036112830089\n",
      "epoch: 16 loss: 1.2500033378601074 grad: 47.54421509537479\n",
      "epoch: 17 loss: 1.2100449800491333 grad: 48.65914547682805\n",
      "epoch: 18 loss: 1.1829198598861694 grad: 48.27256200271565\n",
      "epoch: 19 loss: 1.1337817907333374 grad: 49.246362359269845\n",
      "2.550735568459065\n",
      "optimal lambda 0.005\n",
      "optimal optimiser adagrad\n",
      "optimal dropout 0.3\n"
     ]
    }
   ],
   "source": [
    "##hyperparameter tuning\n",
    "la3=0\n",
    "optim3=''\n",
    "op3=0\n",
    "lams = [0.005,0.001,0.0005]\n",
    "optis = ['adagrad','adam','sgd']\n",
    "dp=[0.2,0.25,0.3]\n",
    "valoss=999\n",
    "for d in dp:\n",
    "    for l in lams:\n",
    "            for opt in optis:\n",
    "                modelgru = gru(13,300,3,10,d)\n",
    "                modelgru.to(device)\n",
    "                modelgru.train(traindl2,epochs = 20, learning_rate=0.001,lam=l,opti=opt)\n",
    "                if valoss>test(modelgru,valdl2):\n",
    "                    valoss=test(modelgru,valdl2)\n",
    "                    print(valoss)\n",
    "                    la3=l\n",
    "                    optim3=opt\n",
    "                    op3=d\n",
    "\n",
    "print(\"optimal lambda\",la3)\n",
    "print(\"optimal optimiser\",optim3) \n",
    "print(\"optimal dropout\",op3) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 511,
   "id": "f934ca61",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelgru = gru(13,300,3,10,op3)\n",
    "modelgru.to(device)\n",
    "lossgru=[]\n",
    "pargru=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 512,
   "id": "e9ec633a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of parameters: 1452960\n"
     ]
    }
   ],
   "source": [
    "total_params = sum(p.numel() for p in modelgru.parameters())\n",
    "print(\"Total number of parameters:\", total_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 559,
   "id": "948f9776",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0 loss: 0.6332976222038269 grad: 133.79882162413293\n",
      "epoch: 1 loss: 0.18335086107254028 grad: 58.917047492460014\n",
      "epoch: 2 loss: 0.12488298118114471 grad: 49.44904610343962\n",
      "epoch: 3 loss: 0.07201915979385376 grad: 37.364247169436105\n",
      "epoch: 4 loss: 0.06383931636810303 grad: 27.2248356979623\n",
      "epoch: 5 loss: 0.047340795397758484 grad: 23.00502389903448\n",
      "epoch: 6 loss: 0.0375472828745842 grad: 16.6797374738456\n",
      "epoch: 7 loss: 0.028213681653141975 grad: 12.85903928160482\n",
      "epoch: 8 loss: 0.034599773585796356 grad: 13.366337544754526\n",
      "epoch: 9 loss: 0.02229805663228035 grad: 9.968232261259969\n",
      "epoch: 10 loss: 0.02132926695048809 grad: 8.642990513749075\n",
      "epoch: 11 loss: 0.01735709048807621 grad: 10.448235379025034\n",
      "epoch: 12 loss: 0.019435623660683632 grad: 10.196479083364949\n",
      "epoch: 13 loss: 0.0168759785592556 grad: 7.218092347625197\n",
      "epoch: 14 loss: 0.015266474336385727 grad: 6.749232732104528\n",
      "epoch: 15 loss: 0.015245450660586357 grad: 5.402481257151225\n",
      "epoch: 16 loss: 0.016001282259821892 grad: 5.989834908223361\n",
      "epoch: 17 loss: 0.0104224206879735 grad: 4.614618443607241\n",
      "epoch: 18 loss: 0.013343075290322304 grad: 4.996659063423672\n",
      "epoch: 19 loss: 0.011863197200000286 grad: 5.335005233047686\n",
      "epoch: 20 loss: 0.013655991293489933 grad: 4.91757098934206\n",
      "epoch: 21 loss: 0.009917661547660828 grad: 4.278448357762038\n",
      "epoch: 22 loss: 0.008585002273321152 grad: 3.4467030725229253\n",
      "epoch: 23 loss: 0.011519565246999264 grad: 3.950543723329035\n",
      "epoch: 24 loss: 0.010635428130626678 grad: 4.018478175276481\n",
      "epoch: 25 loss: 0.011843361891806126 grad: 4.445146397712401\n",
      "epoch: 26 loss: 0.00926069263368845 grad: 3.3235340963020548\n",
      "epoch: 27 loss: 0.01142830029129982 grad: 4.241534242943532\n",
      "epoch: 28 loss: 0.007822167128324509 grad: 3.0653953911962635\n",
      "epoch: 29 loss: 0.008577181026339531 grad: 3.0315991060818153\n",
      "epoch: 30 loss: 0.009133406914770603 grad: 3.1938575801719535\n",
      "epoch: 31 loss: 0.007710708305239677 grad: 2.818566245202638\n",
      "epoch: 32 loss: 0.00881639402359724 grad: 3.619305856344308\n",
      "epoch: 33 loss: 0.007932973094284534 grad: 3.2814403637738914\n",
      "epoch: 34 loss: 0.007442947011440992 grad: 2.662344501638336\n",
      "epoch: 35 loss: 0.008857046253979206 grad: 3.355922620157557\n",
      "epoch: 36 loss: 0.007889117114245892 grad: 2.648439198889512\n",
      "epoch: 37 loss: 0.009876458905637264 grad: 3.6304977209723006\n",
      "epoch: 38 loss: 0.007871722802519798 grad: 2.453569431579681\n",
      "epoch: 39 loss: 0.009235715493559837 grad: 3.2686662650585134\n",
      "epoch: 40 loss: 0.008369039744138718 grad: 3.195917230658466\n",
      "epoch: 41 loss: 0.009908027946949005 grad: 3.006473430932058\n",
      "epoch: 42 loss: 0.008598859421908855 grad: 2.5129270641954036\n",
      "epoch: 43 loss: 0.007924468256533146 grad: 2.12294532150072\n",
      "epoch: 44 loss: 0.008202610537409782 grad: 2.7698173859097768\n",
      "epoch: 45 loss: 0.00841948576271534 grad: 2.8743122779321273\n",
      "epoch: 46 loss: 0.006276499945670366 grad: 2.6422758694517596\n",
      "epoch: 47 loss: 0.007143754977732897 grad: 2.178157249682622\n",
      "epoch: 48 loss: 0.006859426386654377 grad: 2.072299321627006\n",
      "epoch: 49 loss: 0.006229628808796406 grad: 2.3083605354622243\n",
      "epoch: 50 loss: 0.005804114509373903 grad: 2.105381132326432\n",
      "epoch: 51 loss: 0.007795535493642092 grad: 2.3473236663313037\n",
      "epoch: 52 loss: 0.0075498055666685104 grad: 3.123823009479586\n",
      "epoch: 53 loss: 0.007725260220468044 grad: 2.6120524086789954\n",
      "epoch: 54 loss: 0.007306575775146484 grad: 2.1530361404242564\n",
      "epoch: 55 loss: 0.006257703062146902 grad: 2.183347742573716\n",
      "epoch: 56 loss: 0.00534173334017396 grad: 2.048163188153586\n",
      "epoch: 57 loss: 0.00644309725612402 grad: 1.8506971065817424\n",
      "epoch: 58 loss: 0.007864359766244888 grad: 2.5044962630777023\n",
      "epoch: 59 loss: 0.005507354158908129 grad: 2.2166886695283248\n",
      "epoch: 60 loss: 0.006250289734452963 grad: 2.030108201269233\n",
      "epoch: 61 loss: 0.0075929737649858 grad: 2.6775463774724426\n",
      "epoch: 62 loss: 0.005799881648272276 grad: 1.8859170231350955\n",
      "epoch: 63 loss: 0.008384406566619873 grad: 3.7343573447836564\n",
      "epoch: 64 loss: 0.011423515155911446 grad: 4.615987287637783\n",
      "epoch: 65 loss: 0.005879192613065243 grad: 1.7467816694619975\n",
      "epoch: 66 loss: 0.006392957642674446 grad: 2.3282552166917134\n",
      "epoch: 67 loss: 0.006029194686561823 grad: 2.473935620760493\n",
      "epoch: 68 loss: 0.008020475506782532 grad: 2.359779304686731\n",
      "epoch: 69 loss: 0.005031868815422058 grad: 1.9850227266745815\n",
      "epoch: 70 loss: 0.0107275964692235 grad: 2.9402231761419575\n",
      "epoch: 71 loss: 0.004129583481699228 grad: 1.7012148040095638\n",
      "epoch: 72 loss: 0.007953936234116554 grad: 2.3024126580424333\n",
      "epoch: 73 loss: 0.005087860859930515 grad: 1.5848924673351636\n",
      "epoch: 74 loss: 0.006123036611825228 grad: 1.8856755418718723\n",
      "epoch: 75 loss: 0.006612285040318966 grad: 2.16890991326626\n",
      "epoch: 76 loss: 0.007991107180714607 grad: 2.6695526324712877\n",
      "epoch: 77 loss: 0.006308081094175577 grad: 1.676047584134028\n",
      "epoch: 78 loss: 0.006746921222656965 grad: 2.607867839163233\n",
      "epoch: 79 loss: 0.008153225295245647 grad: 1.9937100897645426\n",
      "epoch: 80 loss: 0.0055377185344696045 grad: 2.2146646139184396\n",
      "epoch: 81 loss: 0.004987543448805809 grad: 1.5838287355283924\n",
      "epoch: 82 loss: 0.0054806675761938095 grad: 1.7224548857293034\n",
      "epoch: 83 loss: 0.007162652909755707 grad: 2.1558748939217294\n",
      "epoch: 84 loss: 0.00529628898948431 grad: 2.031024908255909\n",
      "epoch: 85 loss: 0.005885121878236532 grad: 2.0822429547500736\n",
      "epoch: 86 loss: 0.007573130074888468 grad: 2.9324478567400685\n",
      "epoch: 87 loss: 0.00609706062823534 grad: 2.1963972967235876\n",
      "epoch: 88 loss: 0.005109821446239948 grad: 2.0459452134285354\n",
      "epoch: 89 loss: 0.005663808435201645 grad: 2.8312192661287283\n",
      "epoch: 90 loss: 0.004234722349792719 grad: 1.8049683810371544\n",
      "epoch: 91 loss: 0.006887017283588648 grad: 2.1475773752660303\n",
      "epoch: 92 loss: 0.0062240478582680225 grad: 1.7954425463851087\n",
      "epoch: 93 loss: 0.005008946172893047 grad: 1.4763726089303615\n",
      "epoch: 94 loss: 0.005688167177140713 grad: 2.1127845795761093\n",
      "epoch: 95 loss: 0.004831466358155012 grad: 1.4195168833474006\n",
      "epoch: 96 loss: 0.004768491722643375 grad: 1.4595830351390817\n",
      "epoch: 97 loss: 0.00417016027495265 grad: 1.3711184184632839\n",
      "epoch: 98 loss: 0.005765887908637524 grad: 1.828414859593716\n",
      "epoch: 99 loss: 0.006158940028399229 grad: 1.6786257453435034\n",
      "epoch: 100 loss: 0.006364540662616491 grad: 1.9664249110636471\n",
      "epoch: 101 loss: 0.005913836881518364 grad: 1.862335004967076\n",
      "epoch: 102 loss: 0.006429782137274742 grad: 1.8709164384890178\n",
      "epoch: 103 loss: 0.004390905611217022 grad: 1.3461276323113138\n",
      "epoch: 104 loss: 0.0060983155854046345 grad: 2.19410770722848\n",
      "epoch: 105 loss: 0.00411918293684721 grad: 1.5929096133807212\n",
      "epoch: 106 loss: 0.005334137938916683 grad: 1.5885139254339906\n",
      "epoch: 107 loss: 0.0038106413558125496 grad: 1.2907191788319945\n",
      "epoch: 108 loss: 0.005690603982657194 grad: 1.6921455707347186\n",
      "epoch: 109 loss: 0.006106499582529068 grad: 2.18431092936359\n",
      "epoch: 110 loss: 0.004318004008382559 grad: 1.7251655161709263\n",
      "epoch: 111 loss: 0.003930767998099327 grad: 1.5191050932250614\n",
      "epoch: 112 loss: 0.005517654120922089 grad: 1.5583367940652761\n",
      "epoch: 113 loss: 0.005748809780925512 grad: 1.4387888998629574\n",
      "epoch: 114 loss: 0.0054541053250432014 grad: 1.5503455340882566\n",
      "epoch: 115 loss: 0.004013380501419306 grad: 1.2944921484272156\n",
      "epoch: 116 loss: 0.005110913887619972 grad: 1.7650663476412465\n",
      "epoch: 117 loss: 0.004564863163977861 grad: 1.2423504149637816\n",
      "epoch: 118 loss: 0.004679091274738312 grad: 1.654858026556886\n",
      "epoch: 119 loss: 0.004460883792489767 grad: 1.3800192611222328\n",
      "epoch: 120 loss: 0.005408470518887043 grad: 1.9377092935173428\n",
      "epoch: 121 loss: 0.003670153208076954 grad: 1.3345565351454212\n",
      "epoch: 122 loss: 0.00517700519412756 grad: 1.8326005770300438\n",
      "epoch: 123 loss: 0.005138682201504707 grad: 1.5520708541063637\n",
      "epoch: 124 loss: 0.004286065697669983 grad: 1.6132065764644452\n",
      "epoch: 125 loss: 0.004533798899501562 grad: 1.558066062620234\n",
      "epoch: 126 loss: 0.0037026330828666687 grad: 1.4449774370086366\n",
      "epoch: 127 loss: 0.004087683279067278 grad: 1.4490346277699049\n",
      "epoch: 128 loss: 0.004695497453212738 grad: 1.6527136758508139\n",
      "epoch: 129 loss: 0.004831021651625633 grad: 1.4822846322823346\n",
      "epoch: 130 loss: 0.004217914771288633 grad: 1.1539205940719637\n",
      "epoch: 131 loss: 0.003554483875632286 grad: 1.3949018666768072\n",
      "epoch: 132 loss: 0.0031488751992583275 grad: 1.3449250798993446\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 133 loss: 0.004186295438557863 grad: 1.095335564123306\n",
      "epoch: 134 loss: 0.006453741807490587 grad: 1.5441812869410396\n",
      "epoch: 135 loss: 0.004052225966006517 grad: 1.3133600917262747\n",
      "epoch: 136 loss: 0.004484320059418678 grad: 1.5995006839982935\n",
      "epoch: 137 loss: 0.005967681761831045 grad: 1.7636549147096534\n",
      "epoch: 138 loss: 0.004064831882715225 grad: 1.2765995761275657\n",
      "epoch: 139 loss: 0.00463382201269269 grad: 1.3277035739609113\n",
      "epoch: 140 loss: 0.0034560326021164656 grad: 1.1594324987771993\n",
      "epoch: 141 loss: 0.004224528092890978 grad: 1.3424262380094267\n",
      "epoch: 142 loss: 0.0056365192867815495 grad: 1.5216367649907723\n",
      "epoch: 143 loss: 0.003946993965655565 grad: 1.3328328609371047\n",
      "epoch: 144 loss: 0.003444319823756814 grad: 1.0082840847809644\n",
      "epoch: 145 loss: 0.004156783223152161 grad: 1.2522371270836279\n",
      "epoch: 146 loss: 0.0038189191836863756 grad: 1.4255046987363302\n",
      "epoch: 147 loss: 0.004333038814365864 grad: 1.5998452011977937\n",
      "epoch: 148 loss: 0.0032086982391774654 grad: 1.0142044398806513\n",
      "epoch: 149 loss: 0.004866027273237705 grad: 1.5980437891826693\n",
      "epoch: 150 loss: 0.005115254782140255 grad: 1.5647950854985646\n",
      "epoch: 151 loss: 0.0035348606761544943 grad: 1.1476196926510331\n",
      "epoch: 152 loss: 0.0038877492770552635 grad: 1.191602894540707\n",
      "epoch: 153 loss: 0.003695535007864237 grad: 1.144769373443533\n",
      "epoch: 154 loss: 0.004580377135425806 grad: 1.2751589659250286\n",
      "epoch: 155 loss: 0.005844836123287678 grad: 1.2864646802033652\n",
      "epoch: 156 loss: 0.002718317788094282 grad: 1.036392352532477\n",
      "epoch: 157 loss: 0.004836131818592548 grad: 1.3690758366782547\n",
      "epoch: 158 loss: 0.0033645168878138065 grad: 1.1418815274893976\n",
      "epoch: 159 loss: 0.0042097605764865875 grad: 1.1489680138892586\n",
      "epoch: 160 loss: 0.005023242440074682 grad: 1.887446194585612\n",
      "epoch: 161 loss: 0.0035254391841590405 grad: 1.1893041291168516\n",
      "epoch: 162 loss: 0.004740558099001646 grad: 1.0837642857646645\n",
      "epoch: 163 loss: 0.005257092881947756 grad: 1.7220532564240933\n",
      "epoch: 164 loss: 0.003297264687716961 grad: 0.9827981584294315\n",
      "epoch: 165 loss: 0.00382672855630517 grad: 1.6835542738587268\n",
      "epoch: 166 loss: 0.004111696965992451 grad: 1.1142436418425623\n",
      "epoch: 167 loss: 0.003258387092500925 grad: 1.2110136546945842\n",
      "epoch: 168 loss: 0.004427548497915268 grad: 1.7722687015360037\n",
      "epoch: 169 loss: 0.00405433215200901 grad: 1.8560620169952733\n",
      "epoch: 170 loss: 0.003092194441705942 grad: 1.0705403358929502\n",
      "epoch: 171 loss: 0.003989629913121462 grad: 1.2917344531169153\n",
      "epoch: 172 loss: 0.004586204886436462 grad: 1.3026393794335744\n",
      "epoch: 173 loss: 0.0033338393550366163 grad: 1.1549624937250031\n",
      "epoch: 174 loss: 0.00305946939624846 grad: 0.9603390726748151\n",
      "epoch: 175 loss: 0.006110692396759987 grad: 2.0033778767816597\n",
      "epoch: 176 loss: 0.005255098454654217 grad: 2.5708627638151635\n",
      "epoch: 177 loss: 0.029607387259602547 grad: 19.011856025442388\n",
      "epoch: 178 loss: 0.05133318156003952 grad: 28.94354532584183\n",
      "epoch: 179 loss: 0.059189729392528534 grad: 43.174926098373064\n",
      "epoch: 180 loss: 0.029058322310447693 grad: 16.32962970692457\n",
      "epoch: 181 loss: 0.005551143083721399 grad: 2.967224098488605\n",
      "epoch: 182 loss: 0.0073633030988276005 grad: 3.767668007227227\n",
      "epoch: 183 loss: 0.004225046839565039 grad: 2.04114408952628\n",
      "epoch: 184 loss: 0.004273133352398872 grad: 2.673266729477383\n",
      "epoch: 185 loss: 0.005604968406260014 grad: 1.7954574262680136\n",
      "epoch: 186 loss: 0.0045396736823022366 grad: 1.6849173502383847\n",
      "epoch: 187 loss: 0.005925934296101332 grad: 2.1260178019330094\n",
      "epoch: 188 loss: 0.004391323309391737 grad: 1.9091427636248117\n",
      "epoch: 189 loss: 0.004778961185365915 grad: 2.514350027026665\n",
      "epoch: 190 loss: 0.005452266428619623 grad: 1.7270528727329477\n",
      "epoch: 191 loss: 0.0035619509872049093 grad: 1.3577333054613934\n",
      "epoch: 192 loss: 0.0063462527468800545 grad: 2.451446215066752\n",
      "epoch: 193 loss: 0.004304519854485989 grad: 1.7040754085929521\n",
      "epoch: 194 loss: 0.006523931864649057 grad: 2.720198514919984\n",
      "epoch: 195 loss: 0.004398304503411055 grad: 1.5533173751725033\n",
      "epoch: 196 loss: 0.00393271166831255 grad: 1.6431465304518178\n",
      "epoch: 197 loss: 0.004918043036013842 grad: 2.019695624322814\n",
      "epoch: 198 loss: 0.005312047898769379 grad: 1.6532449642079012\n",
      "epoch: 199 loss: 0.004993883892893791 grad: 1.5372481416061416\n",
      "5.951313466641522\n",
      "5.951313466641522\n"
     ]
    }
   ],
   "source": [
    "loss3,par3=modelgru.train(traindl2,epochs = 200,learning_rate=0.0005,lam=la3,opti=optim3) #100-0.001 #200-0.05 #500-0.005 #150-0.001\n",
    "\n",
    "lossgru+=loss3\n",
    "pargru+=par3\n",
    "print(test(modelgru,valdl2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 561,
   "id": "3af789ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.831251793309299\n",
      "5.831251793309299\n"
     ]
    }
   ],
   "source": [
    "print(test(modelgru,valdl2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dff03b42",
   "metadata": {},
   "source": [
    "#### Training curves\n",
    "The following shows the training curve for the GRU based model trained with the optimal hyperparameter values. It can be observed that the loss reduces with time and also the norm of the gradient of the weights also comes closer to 0 after convergence. The convergence of the GRU architecture is faster than the LSTM network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 560,
   "id": "53600440",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x504 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot(lossgru,pargru)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 578,
   "id": "3bcd4b61",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(modelgru,'D:/Saarland University/NNTI/project/models/modelgru.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 579,
   "id": "0ef5025b",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelgru=torch.load('D:/Saarland University/NNTI/project/models/modellstm.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 564,
   "id": "995ef776",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T-SNE plot on the testing dataset:\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"T-SNE plot on the testing dataset:\")\n",
    "tsne_map(testdl2,modelgru)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 565,
   "id": "e09e9fd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy:\n",
      "99.9500036239624 %\n",
      "validation accuracy:\n",
      "53.118711709976196 %\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.531187117099762"
      ]
     },
     "execution_count": 565,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Training accuracy:\")\n",
    "get_accuracy(traindl2,modelgru)\n",
    "print(\"validation accuracy:\")\n",
    "get_accuracy(valdl2,modelgru)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 566,
   "id": "4872c17a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss on test:\n",
      "5.562884283624471\n",
      "Training accuracy:\n",
      "99.9000072479248 %\n",
      "Test accuracy:\n",
      "55.06957769393921 %\n",
      "Training f1 score:\n",
      "F1 score: 0.9995\n",
      "Test f1 score:\n",
      "F1 score: 0.5347912524850894\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 566,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Loss on test:\")\n",
    "test(modelgru,testdl2)\n",
    "print(\"Training accuracy:\")\n",
    "get_accuracy(traindl2,modelgru)\n",
    "print(\"Test accuracy:\")\n",
    "get_accuracy(testdl2,modelgru)\n",
    "print(\"Training f1 score:\")\n",
    "get_f1(traindl2,modelgru)\n",
    "print(\"Test f1 score:\")\n",
    "get_f1(testdl2,modelgru)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 567,
   "id": "74ccf9c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confusion matrix on the test dataset:\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x720 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"confusion matrix on the test dataset:\")\n",
    "confusionplot(testdl2,modelgru)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 568,
   "id": "692e5d8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The Classification Report for test set classification\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.64      0.73        53\n",
      "           1       0.66      0.84      0.74        55\n",
      "           2       0.41      0.52      0.46        54\n",
      "           3       0.71      0.70      0.70        46\n",
      "           4       0.58      0.24      0.34        46\n",
      "           5       0.26      0.20      0.23        50\n",
      "           6       0.36      0.63      0.46        46\n",
      "           7       0.55      0.89      0.68        47\n",
      "           8       0.53      0.34      0.41        56\n",
      "           9       0.52      0.32      0.40        50\n",
      "\n",
      "    accuracy                           0.53       503\n",
      "   macro avg       0.54      0.53      0.51       503\n",
      "weighted avg       0.54      0.53      0.52       503\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nThe Classification Report for test set classification\\n\")\n",
    "classificationReport(testdl2,modelgru)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d0b7b19",
   "metadata": {},
   "source": [
    "## Analysing statistical significance Between models:\n",
    "we tested the two best performing models for the analysis, namely the CNN based model and the GRU based model and also the baseline Linear is also compared"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70810f4a",
   "metadata": {},
   "source": [
    "#### Creating bootstrapped Data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 595,
   "id": "d7639fb0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "70.37773132324219 %\n",
      "72.76341915130615 %\n",
      "73.95625710487366 %\n",
      "69.98011469841003 %\n",
      "75.94432830810547 %\n",
      "70.37773132324219 %\n",
      "72.16699719429016 %\n",
      "72.365802526474 %\n",
      "67.99204349517822 %\n",
      "71.76938056945801 %\n",
      "70.77534198760986 %\n",
      "67.39562153816223 %\n",
      "66.40158891677856 %\n",
      "71.57057523727417 %\n",
      "68.78727078437805 %\n",
      "69.1848874092102 %\n",
      "67.79323816299438 %\n",
      "67.39562153816223 %\n",
      "70.17892599105835 %\n",
      "71.37176394462585 %\n",
      "69.98011469841003 %\n",
      "69.7813093662262 %\n",
      "70.17892599105835 %\n",
      "66.6003942489624 %\n",
      "67.99204349517822 %\n",
      "71.96818590164185 %\n",
      "68.58846545219421 %\n",
      "72.76341915130615 %\n",
      "70.57653665542603 %\n",
      "73.55864644050598 %\n",
      "68.78727078437805 %\n",
      "72.16699719429016 %\n",
      "70.97415328025818 %\n",
      "68.58846545219421 %\n",
      "68.58846545219421 %\n",
      "71.17295861244202 %\n",
      "70.97415328025818 %\n",
      "73.55864644050598 %\n",
      "69.1848874092102 %\n",
      "71.76938056945801 %\n",
      "69.38369274139404 %\n",
      "68.98608207702637 %\n",
      "70.77534198760986 %\n",
      "68.19085478782654 %\n",
      "68.78727078437805 %\n",
      "66.79919958114624 %\n",
      "69.1848874092102 %\n",
      "68.78727078437805 %\n",
      "67.39562153816223 %\n",
      "71.17295861244202 %\n",
      "69.98011469841003 %\n",
      "70.57653665542603 %\n",
      "71.57057523727417 %\n",
      "67.39562153816223 %\n",
      "70.17892599105835 %\n",
      "72.16699719429016 %\n",
      "72.16699719429016 %\n",
      "72.365802526474 %\n",
      "70.77534198760986 %\n",
      "70.37773132324219 %\n",
      "68.98608207702637 %\n",
      "68.98608207702637 %\n",
      "71.17295861244202 %\n",
      "66.40158891677856 %\n",
      "67.79323816299438 %\n",
      "68.58846545219421 %\n",
      "65.20874500274658 %\n",
      "67.59443283081055 %\n",
      "65.60636162757874 %\n",
      "68.98608207702637 %\n",
      "70.17892599105835 %\n",
      "70.77534198760986 %\n",
      "70.17892599105835 %\n",
      "71.57057523727417 %\n",
      "69.1848874092102 %\n",
      "68.58846545219421 %\n",
      "71.57057523727417 %\n",
      "72.96222448348999 %\n",
      "68.19085478782654 %\n",
      "68.98608207702637 %\n",
      "71.17295861244202 %\n",
      "72.365802526474 %\n",
      "75.94432830810547 %\n",
      "69.38369274139404 %\n",
      "70.57653665542603 %\n",
      "67.59443283081055 %\n",
      "70.17892599105835 %\n",
      "68.78727078437805 %\n",
      "70.37773132324219 %\n",
      "70.97415328025818 %\n",
      "73.35983514785767 %\n",
      "66.6003942489624 %\n",
      "70.97415328025818 %\n",
      "69.7813093662262 %\n",
      "68.38966012001038 %\n",
      "71.17295861244202 %\n",
      "70.97415328025818 %\n",
      "69.38369274139404 %\n",
      "71.57057523727417 %\n",
      "73.95625710487366 %\n",
      "72.96222448348999 %\n",
      "72.76341915130615 %\n",
      "73.35983514785767 %\n",
      "71.76938056945801 %\n",
      "72.16699719429016 %\n",
      "72.96222448348999 %\n",
      "68.98608207702637 %\n",
      "72.76341915130615 %\n",
      "69.1848874092102 %\n",
      "68.38966012001038 %\n",
      "73.75745177268982 %\n",
      "69.98011469841003 %\n",
      "71.96818590164185 %\n",
      "70.37773132324219 %\n",
      "72.56460785865784 %\n",
      "70.97415328025818 %\n",
      "68.19085478782654 %\n",
      "70.77534198760986 %\n",
      "70.97415328025818 %\n",
      "73.75745177268982 %\n",
      "70.97415328025818 %\n",
      "67.79323816299438 %\n",
      "67.59443283081055 %\n",
      "69.7813093662262 %\n",
      "72.96222448348999 %\n",
      "71.37176394462585 %\n",
      "71.17295861244202 %\n",
      "70.77534198760986 %\n",
      "68.78727078437805 %\n",
      "66.20277762413025 %\n",
      "71.96818590164185 %\n",
      "70.17892599105835 %\n",
      "71.57057523727417 %\n",
      "67.39562153816223 %\n",
      "70.17892599105835 %\n",
      "66.79919958114624 %\n",
      "69.98011469841003 %\n",
      "73.35983514785767 %\n",
      "72.56460785865784 %\n",
      "74.55267906188965 %\n",
      "69.58250403404236 %\n",
      "68.38966012001038 %\n",
      "71.17295861244202 %\n",
      "70.37773132324219 %\n",
      "72.16699719429016 %\n",
      "71.76938056945801 %\n",
      "67.79323816299438 %\n",
      "70.97415328025818 %\n",
      "67.99204349517822 %\n",
      "68.78727078437805 %\n",
      "69.98011469841003 %\n",
      "68.98608207702637 %\n",
      "71.17295861244202 %\n",
      "70.37773132324219 %\n",
      "69.98011469841003 %\n",
      "69.38369274139404 %\n",
      "70.37773132324219 %\n",
      "70.17892599105835 %\n",
      "69.1848874092102 %\n",
      "69.98011469841003 %\n",
      "70.57653665542603 %\n",
      "69.98011469841003 %\n",
      "67.79323816299438 %\n",
      "71.76938056945801 %\n",
      "67.1968162059784 %\n",
      "71.96818590164185 %\n",
      "68.58846545219421 %\n",
      "69.7813093662262 %\n",
      "72.56460785865784 %\n",
      "70.57653665542603 %\n",
      "73.16102981567383 %\n",
      "71.37176394462585 %\n",
      "68.19085478782654 %\n",
      "74.55267906188965 %\n",
      "69.7813093662262 %\n",
      "68.98608207702637 %\n",
      "73.95625710487366 %\n",
      "72.76341915130615 %\n",
      "74.15506839752197 %\n",
      "69.7813093662262 %\n",
      "71.37176394462585 %\n",
      "70.77534198760986 %\n",
      "67.59443283081055 %\n",
      "70.37773132324219 %\n",
      "70.17892599105835 %\n",
      "72.76341915130615 %\n",
      "70.17892599105835 %\n",
      "69.58250403404236 %\n",
      "69.98011469841003 %\n",
      "68.19085478782654 %\n",
      "70.17892599105835 %\n",
      "71.57057523727417 %\n",
      "68.78727078437805 %\n",
      "70.57653665542603 %\n",
      "71.76938056945801 %\n",
      "71.37176394462585 %\n",
      "71.96818590164185 %\n",
      "69.1848874092102 %\n",
      "70.77534198760986 %\n",
      "72.16699719429016 %\n",
      "73.95625710487366 %\n",
      "73.35983514785767 %\n",
      "71.57057523727417 %\n",
      "68.58846545219421 %\n",
      "68.98608207702637 %\n",
      "67.99204349517822 %\n",
      "70.37773132324219 %\n",
      "66.40158891677856 %\n",
      "71.17295861244202 %\n",
      "73.55864644050598 %\n",
      "71.96818590164185 %\n",
      "69.38369274139404 %\n",
      "69.38369274139404 %\n",
      "75.34790635108948 %\n",
      "70.57653665542603 %\n",
      "70.77534198760986 %\n",
      "69.38369274139404 %\n",
      "67.99204349517822 %\n",
      "72.76341915130615 %\n",
      "67.99204349517822 %\n",
      "66.99801087379456 %\n",
      "68.98608207702637 %\n",
      "71.37176394462585 %\n",
      "70.17892599105835 %\n",
      "68.58846545219421 %\n",
      "68.98608207702637 %\n",
      "69.98011469841003 %\n",
      "74.35387372970581 %\n",
      "69.58250403404236 %\n",
      "67.79323816299438 %\n",
      "71.76938056945801 %\n",
      "68.78727078437805 %\n",
      "74.15506839752197 %\n",
      "69.98011469841003 %\n",
      "70.17892599105835 %\n",
      "69.1848874092102 %\n",
      "71.57057523727417 %\n",
      "72.56460785865784 %\n",
      "72.76341915130615 %\n",
      "68.19085478782654 %\n",
      "69.58250403404236 %\n",
      "71.76938056945801 %\n",
      "72.56460785865784 %\n",
      "69.58250403404236 %\n",
      "70.97415328025818 %\n",
      "71.96818590164185 %\n",
      "71.76938056945801 %\n",
      "69.7813093662262 %\n",
      "71.76938056945801 %\n",
      "74.75149035453796 %\n",
      "67.1968162059784 %\n",
      "69.98011469841003 %\n",
      "70.77534198760986 %\n",
      "65.60636162757874 %\n",
      "68.19085478782654 %\n",
      "70.97415328025818 %\n",
      "68.19085478782654 %\n",
      "70.77534198760986 %\n",
      "68.19085478782654 %\n",
      "70.57653665542603 %\n",
      "69.1848874092102 %\n",
      "67.99204349517822 %\n",
      "68.98608207702637 %\n",
      "66.6003942489624 %\n",
      "72.16699719429016 %\n",
      "68.98608207702637 %\n",
      "69.7813093662262 %\n",
      "69.7813093662262 %\n",
      "71.17295861244202 %\n",
      "68.78727078437805 %\n",
      "66.00397229194641 %\n",
      "70.57653665542603 %\n",
      "73.55864644050598 %\n",
      "69.38369274139404 %\n",
      "69.7813093662262 %\n",
      "66.20277762413025 %\n",
      "66.6003942489624 %\n",
      "72.96222448348999 %\n",
      "72.76341915130615 %\n",
      "74.75149035453796 %\n",
      "69.7813093662262 %\n",
      "75.5467176437378 %\n",
      "73.55864644050598 %\n",
      "70.37773132324219 %\n",
      "70.17892599105835 %\n",
      "75.74552297592163 %\n",
      "66.20277762413025 %\n",
      "66.99801087379456 %\n",
      "71.57057523727417 %\n",
      "71.76938056945801 %\n",
      "70.77534198760986 %\n",
      "67.79323816299438 %\n",
      "69.38369274139404 %\n",
      "67.79323816299438 %\n",
      "73.75745177268982 %\n",
      "67.79323816299438 %\n",
      "70.37773132324219 %\n",
      "69.1848874092102 %\n",
      "71.57057523727417 %\n",
      "67.59443283081055 %\n",
      "68.78727078437805 %\n",
      "71.96818590164185 %\n",
      "69.1848874092102 %\n",
      "67.59443283081055 %\n",
      "70.57653665542603 %\n",
      "65.00993967056274 %\n",
      "70.97415328025818 %\n",
      "71.37176394462585 %\n",
      "74.15506839752197 %\n",
      "69.38369274139404 %\n",
      "73.16102981567383 %\n",
      "69.58250403404236 %\n",
      "68.58846545219421 %\n",
      "69.58250403404236 %\n",
      "70.37773132324219 %\n",
      "69.7813093662262 %\n",
      "69.7813093662262 %\n",
      "70.77534198760986 %\n",
      "70.17892599105835 %\n",
      "71.17295861244202 %\n",
      "73.16102981567383 %\n",
      "68.98608207702637 %\n",
      "66.40158891677856 %\n",
      "68.98608207702637 %\n",
      "74.55267906188965 %\n",
      "74.15506839752197 %\n",
      "71.76938056945801 %\n",
      "68.78727078437805 %\n",
      "72.76341915130615 %\n",
      "73.35983514785767 %\n",
      "68.98608207702637 %\n",
      "71.57057523727417 %\n",
      "69.98011469841003 %\n",
      "70.57653665542603 %\n",
      "67.39562153816223 %\n",
      "67.59443283081055 %\n",
      "73.16102981567383 %\n",
      "67.99204349517822 %\n",
      "71.96818590164185 %\n",
      "71.57057523727417 %\n",
      "69.7813093662262 %\n",
      "75.14910101890564 %\n",
      "71.17295861244202 %\n",
      "72.76341915130615 %\n",
      "70.57653665542603 %\n",
      "72.365802526474 %\n",
      "69.58250403404236 %\n",
      "69.58250403404236 %\n",
      "69.98011469841003 %\n",
      "67.39562153816223 %\n",
      "71.76938056945801 %\n",
      "70.77534198760986 %\n",
      "70.37773132324219 %\n",
      "70.57653665542603 %\n",
      "72.76341915130615 %\n",
      "69.1848874092102 %\n",
      "72.76341915130615 %\n",
      "65.60636162757874 %\n",
      "71.76938056945801 %\n",
      "68.78727078437805 %\n",
      "72.76341915130615 %\n",
      "73.16102981567383 %\n",
      "64.61232304573059 %\n",
      "69.58250403404236 %\n",
      "70.57653665542603 %\n",
      "71.76938056945801 %\n",
      "66.40158891677856 %\n",
      "72.16699719429016 %\n",
      "72.96222448348999 %\n",
      "72.76341915130615 %\n",
      "73.95625710487366 %\n",
      "69.1848874092102 %\n",
      "70.97415328025818 %\n",
      "68.78727078437805 %\n",
      "72.76341915130615 %\n",
      "72.96222448348999 %\n",
      "70.97415328025818 %\n",
      "68.58846545219421 %\n",
      "71.57057523727417 %\n",
      "73.55864644050598 %\n",
      "72.365802526474 %\n",
      "75.34790635108948 %\n",
      "73.35983514785767 %\n",
      "72.76341915130615 %\n",
      "68.19085478782654 %\n",
      "67.59443283081055 %\n",
      "67.79323816299438 %\n",
      "71.57057523727417 %\n",
      "71.96818590164185 %\n",
      "72.76341915130615 %\n",
      "67.99204349517822 %\n",
      "67.39562153816223 %\n",
      "70.97415328025818 %\n",
      "72.365802526474 %\n",
      "71.17295861244202 %\n",
      "71.37176394462585 %\n",
      "70.37773132324219 %\n",
      "67.99204349517822 %\n",
      "69.38369274139404 %\n",
      "68.38966012001038 %\n",
      "71.57057523727417 %\n",
      "67.99204349517822 %\n",
      "66.20277762413025 %\n",
      "72.365802526474 %\n",
      "67.99204349517822 %\n",
      "67.79323816299438 %\n",
      "72.16699719429016 %\n",
      "70.37773132324219 %\n",
      "72.56460785865784 %\n",
      "72.56460785865784 %\n",
      "69.1848874092102 %\n",
      "71.57057523727417 %\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "70.37773132324219 %\n",
      "68.78727078437805 %\n",
      "67.59443283081055 %\n",
      "68.98608207702637 %\n",
      "69.1848874092102 %\n",
      "69.98011469841003 %\n",
      "66.40158891677856 %\n",
      "71.96818590164185 %\n",
      "73.35983514785767 %\n",
      "72.16699719429016 %\n",
      "69.98011469841003 %\n",
      "72.16699719429016 %\n",
      "73.55864644050598 %\n",
      "69.58250403404236 %\n",
      "67.39562153816223 %\n",
      "71.37176394462585 %\n",
      "69.98011469841003 %\n",
      "70.97415328025818 %\n",
      "73.35983514785767 %\n",
      "69.7813093662262 %\n",
      "75.5467176437378 %\n",
      "70.37773132324219 %\n",
      "74.15506839752197 %\n",
      "71.96818590164185 %\n",
      "71.37176394462585 %\n",
      "69.1848874092102 %\n",
      "69.38369274139404 %\n",
      "69.1848874092102 %\n",
      "69.98011469841003 %\n",
      "68.98608207702637 %\n",
      "70.77534198760986 %\n",
      "69.1848874092102 %\n",
      "69.7813093662262 %\n",
      "71.37176394462585 %\n",
      "72.96222448348999 %\n",
      "68.58846545219421 %\n",
      "72.16699719429016 %\n",
      "70.97415328025818 %\n",
      "69.7813093662262 %\n",
      "70.97415328025818 %\n",
      "71.96818590164185 %\n",
      "73.55864644050598 %\n",
      "66.79919958114624 %\n",
      "66.99801087379456 %\n",
      "69.7813093662262 %\n",
      "67.79323816299438 %\n",
      "73.16102981567383 %\n",
      "72.16699719429016 %\n",
      "72.76341915130615 %\n",
      "71.17295861244202 %\n",
      "68.58846545219421 %\n",
      "70.37773132324219 %\n",
      "70.57653665542603 %\n",
      "71.17295861244202 %\n",
      "71.57057523727417 %\n",
      "73.75745177268982 %\n",
      "70.97415328025818 %\n",
      "70.77534198760986 %\n",
      "73.55864644050598 %\n",
      "71.57057523727417 %\n",
      "70.77534198760986 %\n",
      "70.17892599105835 %\n",
      "68.78727078437805 %\n",
      "67.79323816299438 %\n",
      "69.58250403404236 %\n",
      "69.1848874092102 %\n",
      "70.97415328025818 %\n",
      "70.97415328025818 %\n",
      "71.57057523727417 %\n",
      "69.58250403404236 %\n",
      "67.79323816299438 %\n",
      "72.76341915130615 %\n",
      "66.99801087379456 %\n",
      "69.7813093662262 %\n",
      "71.57057523727417 %\n",
      "70.37773132324219 %\n",
      "70.77534198760986 %\n",
      "70.37773132324219 %\n",
      "70.97415328025818 %\n",
      "67.99204349517822 %\n",
      "72.56460785865784 %\n",
      "67.79323816299438 %\n",
      "71.57057523727417 %\n",
      "70.17892599105835 %\n",
      "74.75149035453796 %\n",
      "73.75745177268982 %\n",
      "68.58846545219421 %\n",
      "68.58846545219421 %\n",
      "69.38369274139404 %\n",
      "72.76341915130615 %\n",
      "70.97415328025818 %\n"
     ]
    }
   ],
   "source": [
    "acc=[]\n",
    "for i in tqdm(range(503)):\n",
    "    dummystats=np.zeros((1,melspectrogram.shape[0],maxlength+27))\n",
    "    datadictstats = {'TEST':dummy}\n",
    "    labeldictstats = {'TEST':[]}\n",
    "\n",
    "    for j in range(503):\n",
    "        idx = randint(0, 502)\n",
    "        path = sdr_df[sdr_df['split']=='TEST']['file'].iloc[idx]\n",
    "        label = sdr_df[sdr_df['split']=='TEST']['label'].iloc[idx]\n",
    "        x, sr = librosa.load(path, sr=SAMPLING_RATE)\n",
    "        melspectrogram = extract_melspectrogram(x, sr, num_mels=13)/max_val\n",
    "        data = torch.tensor(np.concatenate((melspectrogram,np.zeros((melspectrogram.shape[0],maxlength-melspectrogram.shape[1]+27))),axis = 1))## the dimension is made to be 256 so that it works with the maxpooling layers in the architecture.\n",
    "        data = data.view(1,melspectrogram.shape[0],-1) \n",
    "        datadictstats['TEST']=torch.tensor(np.concatenate((datadictstats['TEST'],data),axis=0))\n",
    "        labeldictstats['TEST'].append(label)\n",
    "\n",
    "    test_datastats = datadictstats['TEST'][1:] \n",
    "    test_ystats = labeldictstats['TEST']\n",
    "\n",
    "    custom_test_dataset = customDataset(test_datastats, test_ystats)\n",
    "    custom_test_loader = customDataLoader(custom_test_dataset, batch_size=503)\n",
    "    testdlstats = custom_test_loader.loader()\n",
    "\n",
    "    acc.append(get_accuracy(testdlstats,modelcnn))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 598,
   "id": "0a6b0e90",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  0%|                                                                                          | 0/503 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "54.07554507255554 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  0%|â–                                                                                 | 1/503 [00:03<26:13,  3.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52.485084533691406 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  0%|â–Ž                                                                                 | 2/503 [00:05<25:27,  3.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53.67792844772339 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  1%|â–                                                                                 | 3/503 [00:08<24:52,  2.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53.28031778335571 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  1%|â–‹                                                                                 | 4/503 [00:11<24:28,  2.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51.68985724449158 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  1%|â–Š                                                                                 | 5/503 [00:14<24:15,  2.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52.485084533691406 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  1%|â–‰                                                                                 | 6/503 [00:17<24:05,  2.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52.08747386932373 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  1%|â–ˆâ–                                                                                | 7/503 [00:20<24:13,  2.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52.68389582633972 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  2%|â–ˆâ–Ž                                                                                | 8/503 [00:23<24:07,  2.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "54.47315573692322 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  2%|â–ˆâ–                                                                                | 9/503 [00:26<24:03,  2.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53.0815064907074 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  2%|â–ˆâ–Œ                                                                               | 10/503 [00:29<24:08,  2.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53.47912311553955 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  2%|â–ˆâ–Š                                                                               | 11/503 [00:32<23:56,  2.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52.485084533691406 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  2%|â–ˆâ–‰                                                                               | 12/503 [00:35<23:56,  2.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52.28627920150757 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  3%|â–ˆâ–ˆ                                                                               | 13/503 [00:37<23:51,  2.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53.0815064907074 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  3%|â–ˆâ–ˆâ–Ž                                                                              | 14/503 [00:40<23:44,  2.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52.485084533691406 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  3%|â–ˆâ–ˆâ–                                                                              | 15/503 [00:43<23:55,  2.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53.67792844772339 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  3%|â–ˆâ–ˆâ–Œ                                                                              | 16/503 [00:46<23:57,  2.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52.08747386932373 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  3%|â–ˆâ–ˆâ–‹                                                                              | 17/503 [00:49<23:44,  2.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51.49105191230774 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  4%|â–ˆâ–ˆâ–‰                                                                              | 18/503 [00:52<23:38,  2.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52.28627920150757 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  4%|â–ˆâ–ˆâ–ˆ                                                                              | 19/503 [00:55<23:24,  2.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53.0815064907074 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  4%|â–ˆâ–ˆâ–ˆâ–                                                                             | 20/503 [00:58<23:19,  2.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52.88270115852356 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  4%|â–ˆâ–ˆâ–ˆâ–                                                                             | 21/503 [01:01<23:13,  2.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53.876739740371704 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  4%|â–ˆâ–ˆâ–ˆâ–Œ                                                                             | 22/503 [01:04<23:08,  2.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52.28627920150757 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  5%|â–ˆâ–ˆâ–ˆâ–‹                                                                             | 23/503 [01:06<23:02,  2.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53.28031778335571 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  5%|â–ˆâ–ˆâ–ˆâ–Š                                                                             | 24/503 [01:09<23:01,  2.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53.67792844772339 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  5%|â–ˆâ–ˆâ–ˆâ–ˆ                                                                             | 25/503 [01:12<22:55,  2.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53.47912311553955 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  5%|â–ˆâ–ˆâ–ˆâ–ˆâ–                                                                            | 26/503 [01:15<22:56,  2.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53.0815064907074 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  5%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž                                                                            | 27/503 [01:18<22:48,  2.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "54.47315573692322 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  6%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ                                                                            | 28/503 [01:21<22:45,  2.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52.28627920150757 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  6%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹                                                                            | 29/503 [01:24<22:41,  2.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53.28031778335571 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  6%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š                                                                            | 30/503 [01:27<22:40,  2.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53.67792844772339 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  6%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰                                                                            | 31/503 [01:29<22:36,  2.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52.28627920150757 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  6%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                                                                           | 32/503 [01:32<22:29,  2.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52.485084533691406 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  7%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž                                                                           | 33/503 [01:35<22:24,  2.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53.47912311553955 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  7%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                                                                           | 34/503 [01:38<22:22,  2.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53.28031778335571 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  7%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                                                                           | 35/503 [01:41<22:24,  2.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52.88270115852356 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  7%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                                                                           | 36/503 [01:44<22:23,  2.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "54.07554507255554 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  7%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                                                                           | 37/503 [01:47<22:16,  2.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51.68985724449158 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  8%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                                                                           | 38/503 [01:50<22:12,  2.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53.47912311553955 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  8%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž                                                                          | 39/503 [01:52<22:12,  2.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52.88270115852356 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  8%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                                                                          | 40/503 [01:55<22:10,  2.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "54.07554507255554 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  8%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                                                                          | 41/503 [01:58<22:12,  2.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52.68389582633972 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  8%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                                                                          | 42/503 [02:01<22:09,  2.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52.28627920150757 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  9%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                                                                          | 43/503 [02:04<22:08,  2.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53.0815064907074 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  9%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                                                                          | 44/503 [02:07<22:08,  2.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52.28627920150757 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  9%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                                                                         | 45/503 [02:10<22:04,  2.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51.88866853713989 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  9%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                                                                         | 46/503 [02:13<22:20,  2.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52.88270115852356 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  9%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                                                                         | 47/503 [02:16<22:24,  2.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53.28031778335571 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 10%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                                                                         | 48/503 [02:19<22:24,  2.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52.485084533691406 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 10%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                                                                         | 49/503 [02:22<22:28,  2.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52.68389582633972 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 10%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                                                                         | 50/503 [02:25<22:21,  2.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52.485084533691406 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 10%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                                                                        | 51/503 [02:28<22:20,  2.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52.485084533691406 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 10%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž                                                                        | 52/503 [02:31<22:20,  2.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52.68389582633972 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 11%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                                                                        | 53/503 [02:34<22:05,  2.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51.88866853713989 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 11%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                                                                        | 54/503 [02:36<21:58,  2.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53.28031778335571 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 11%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                                                                        | 55/503 [02:39<22:04,  2.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52.68389582633972 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 11%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                                                                        | 56/503 [02:42<21:54,  2.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51.2922465801239 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 11%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                                                                       | 57/503 [02:45<21:43,  2.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52.28627920150757 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 12%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž                                                                       | 58/503 [02:48<21:42,  2.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "54.07554507255554 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 12%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                                                                       | 59/503 [02:51<21:35,  2.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53.876739740371704 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 12%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                                                                       | 60/503 [02:54<21:34,  2.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "54.67196702957153 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 12%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                                                                       | 61/503 [02:57<21:26,  2.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52.28627920150757 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 12%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                                                                       | 62/503 [03:00<21:29,  2.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52.28627920150757 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 13%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                                                                      | 63/503 [03:03<21:27,  2.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53.28031778335571 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 13%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž                                                                      | 64/503 [03:06<21:20,  2.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51.88866853713989 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 13%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                                                                      | 65/503 [03:09<21:14,  2.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52.88270115852356 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 13%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                                                                      | 66/503 [03:11<21:06,  2.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51.49105191230774 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 13%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                                                                      | 67/503 [03:14<21:04,  2.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52.08747386932373 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 14%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                                                                      | 68/503 [03:17<21:18,  2.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53.28031778335571 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 14%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                                                                      | 69/503 [03:20<21:20,  2.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52.88270115852356 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 14%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž                                                                     | 70/503 [03:23<21:27,  2.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53.28031778335571 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 14%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                                                                     | 71/503 [03:26<21:14,  2.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53.67792844772339 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 14%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                                                                     | 72/503 [03:29<21:10,  2.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51.49105191230774 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 15%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                                                                     | 73/503 [03:32<21:07,  2.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52.28627920150757 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 15%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                                                                     | 74/503 [03:35<20:59,  2.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53.28031778335571 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 15%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                                                                     | 75/503 [03:38<20:55,  2.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53.47912311553955 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 15%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                                                                    | 76/503 [03:41<20:51,  2.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52.68389582633972 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 15%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                                                                    | 77/503 [03:44<20:43,  2.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52.88270115852356 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 16%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                                                                    | 78/503 [03:47<20:53,  2.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53.28031778335571 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 16%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                                                                    | 79/503 [03:50<20:49,  2.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52.68389582633972 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 16%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                                                                    | 80/503 [03:53<20:41,  2.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53.47912311553955 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 16%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                                                                    | 81/503 [03:56<20:34,  2.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52.88270115852356 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 16%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                                                                   | 82/503 [03:59<20:35,  2.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52.485084533691406 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 17%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž                                                                   | 83/503 [04:01<20:28,  2.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52.08747386932373 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 17%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                                                                   | 84/503 [04:04<20:18,  2.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52.68389582633972 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 17%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                                                                   | 85/503 [04:07<20:16,  2.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53.28031778335571 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 17%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                                                                   | 86/503 [04:10<20:15,  2.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51.88866853713989 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 17%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                                                                   | 87/503 [04:13<20:09,  2.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51.68985724449158 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 17%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                                                                  | 88/503 [04:16<20:04,  2.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52.28627920150757 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 18%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž                                                                  | 89/503 [04:19<20:08,  2.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52.485084533691406 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 18%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                                                                  | 90/503 [04:22<20:11,  2.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51.2922465801239 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 18%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                                                                  | 91/503 [04:25<20:03,  2.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53.67792844772339 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 18%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                                                                  | 92/503 [04:28<20:01,  2.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51.2922465801239 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 18%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                                                                  | 93/503 [04:31<20:03,  2.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51.68985724449158 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 19%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                                                                 | 94/503 [04:34<20:05,  2.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53.876739740371704 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 19%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž                                                                 | 95/503 [04:37<19:56,  2.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53.67792844772339 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 19%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                                                                 | 96/503 [04:40<20:01,  2.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52.485084533691406 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 19%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                                                                 | 97/503 [04:42<19:56,  2.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53.0815064907074 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 19%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                                                                 | 98/503 [04:45<19:45,  2.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52.88270115852356 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 20%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                                                                 | 99/503 [04:48<20:02,  2.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53.876739740371704 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 20%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                                                                | 100/503 [04:51<20:00,  2.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52.08747386932373 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 20%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                                                                | 101/503 [04:54<19:50,  2.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52.68389582633972 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 20%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                                                               | 102/503 [04:57<19:40,  2.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53.0815064907074 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 20%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                                                               | 103/503 [05:00<19:27,  2.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51.49105191230774 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 21%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                                                               | 104/503 [05:03<19:26,  2.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51.49105191230774 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 21%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                                                               | 105/503 [05:06<19:17,  2.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51.88866853713989 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 21%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                                                               | 106/503 [05:09<19:26,  2.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52.68389582633972 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 21%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                                                               | 107/503 [05:12<19:24,  2.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52.08747386932373 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 21%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                                                              | 108/503 [05:15<19:32,  2.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52.08747386932373 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 22%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž                                                              | 109/503 [05:18<19:26,  2.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52.08747386932373 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 22%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                                                              | 110/503 [05:21<19:20,  2.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52.485084533691406 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 22%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                                                              | 111/503 [05:24<19:13,  2.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53.876739740371704 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 22%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                                                              | 112/503 [05:27<19:12,  2.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52.88270115852356 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 22%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                                                              | 113/503 [05:30<19:18,  2.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53.47912311553955 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 23%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                                                             | 114/503 [05:33<19:08,  2.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53.28031778335571 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 23%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž                                                             | 115/503 [05:35<18:57,  2.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52.485084533691406 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 23%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                                                             | 116/503 [05:38<18:53,  2.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52.08747386932373 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 23%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                                                             | 117/503 [05:41<19:06,  2.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52.08747386932373 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 23%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                                                             | 118/503 [05:44<19:11,  2.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51.88866853713989 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 24%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                                                             | 119/503 [05:48<19:22,  3.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52.08747386932373 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 24%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                                                             | 120/503 [05:51<19:20,  3.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52.88270115852356 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 24%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                                                            | 121/503 [05:54<19:13,  3.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52.28627920150757 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 24%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                                                            | 122/503 [05:57<19:13,  3.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53.47912311553955 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 24%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                                                            | 123/503 [06:00<19:05,  3.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52.68389582633972 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 25%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                                                            | 124/503 [06:03<19:05,  3.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52.08747386932373 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 25%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                                                            | 125/503 [06:06<18:59,  3.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52.88270115852356 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 25%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                                                            | 126/503 [06:09<19:07,  3.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52.08747386932373 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 25%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                                                           | 127/503 [06:12<18:50,  3.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "54.27435040473938 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 25%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž                                                           | 128/503 [06:15<18:45,  3.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52.28627920150757 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 26%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                                                           | 129/503 [06:18<18:41,  3.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52.68389582633972 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 26%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                                                           | 130/503 [06:21<18:37,  3.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52.68389582633972 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 26%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                                                           | 131/503 [06:24<18:28,  2.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53.876739740371704 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 26%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                                                           | 132/503 [06:27<18:19,  2.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51.49105191230774 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 26%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                                                          | 133/503 [06:30<18:14,  2.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53.0815064907074 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 27%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž                                                          | 134/503 [06:33<18:26,  3.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52.68389582633972 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 27%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                                                          | 135/503 [06:36<18:23,  3.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53.0815064907074 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 27%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                                                          | 136/503 [06:39<18:25,  3.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53.28031778335571 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 27%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                                                          | 137/503 [06:42<18:19,  3.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52.68389582633972 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 27%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                                                          | 138/503 [06:45<18:08,  2.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53.47912311553955 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 28%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                                                          | 139/503 [06:48<18:01,  2.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53.28031778335571 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 28%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž                                                         | 140/503 [06:51<18:05,  2.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51.49105191230774 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 28%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                                                         | 141/503 [06:53<17:53,  2.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52.485084533691406 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 28%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                                                         | 142/503 [06:56<17:54,  2.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53.0815064907074 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 28%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                                                         | 143/503 [07:00<18:04,  3.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52.88270115852356 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 29%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                                                         | 144/503 [07:03<18:00,  3.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50.69582462310791 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 29%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                                                         | 145/503 [07:05<17:44,  2.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52.28627920150757 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 29%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                                                        | 146/503 [07:08<17:36,  2.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "54.07554507255554 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 29%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                                                        | 147/503 [07:11<17:30,  2.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51.49105191230774 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 29%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                                                        | 148/503 [07:14<17:26,  2.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53.67792844772339 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 30%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                                                        | 149/503 [07:17<17:22,  2.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53.47912311553955 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 30%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                                                        | 150/503 [07:20<17:20,  2.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51.88866853713989 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 30%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                                                        | 151/503 [07:23<17:14,  2.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53.0815064907074 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 30%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                                                       | 152/503 [07:26<17:20,  2.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53.876739740371704 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 30%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž                                                       | 153/503 [07:29<17:14,  2.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52.485084533691406 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 31%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                                                       | 154/503 [07:32<17:06,  2.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51.49105191230774 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 31%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                                                       | 155/503 [07:35<17:09,  2.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53.876739740371704 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 31%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                                                       | 156/503 [07:38<17:06,  2.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51.49105191230774 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 31%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                                                       | 157/503 [07:41<17:01,  2.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52.88270115852356 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 31%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                                                      | 158/503 [07:44<16:57,  2.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52.28627920150757 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 32%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž                                                      | 159/503 [07:47<16:48,  2.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51.88866853713989 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 32%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                                                      | 160/503 [07:50<16:45,  2.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52.28627920150757 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 32%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                                                      | 161/503 [07:52<16:40,  2.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53.0815064907074 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 32%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                                                      | 162/503 [07:55<16:37,  2.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52.08747386932373 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 32%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                                                      | 163/503 [07:58<16:32,  2.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53.0815064907074 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 33%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                                                      | 164/503 [08:01<16:29,  2.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52.485084533691406 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 33%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                                                     | 165/503 [08:04<16:31,  2.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53.0815064907074 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 33%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                                                     | 166/503 [08:07<16:25,  2.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51.68985724449158 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 33%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                                                     | 167/503 [08:10<16:24,  2.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53.47912311553955 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 33%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                                                     | 168/503 [08:13<16:28,  2.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52.08747386932373 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 34%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                                                     | 169/503 [08:16<16:30,  2.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53.47912311553955 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 34%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                                                     | 170/503 [08:19<16:26,  2.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52.08747386932373 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 34%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                                                    | 171/503 [08:22<16:37,  3.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53.28031778335571 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 34%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž                                                    | 172/503 [08:25<16:26,  2.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53.28031778335571 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 34%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                                                    | 173/503 [08:28<16:34,  3.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "54.07554507255554 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 35%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                                                    | 174/503 [08:31<16:34,  3.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51.68985724449158 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 35%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                                                    | 175/503 [08:34<16:25,  3.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53.28031778335571 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 35%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                                                    | 176/503 [08:37<16:20,  3.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52.28627920150757 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 35%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                                                   | 177/503 [08:40<16:13,  2.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52.485084533691406 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 35%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž                                                   | 178/503 [08:43<16:03,  2.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51.88866853713989 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 36%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                                                   | 179/503 [08:46<15:57,  2.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "54.27435040473938 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 36%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                                                   | 180/503 [08:49<15:52,  2.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53.67792844772339 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 36%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                                                   | 181/503 [08:52<15:46,  2.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53.28031778335571 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 36%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                                                   | 182/503 [08:55<15:48,  2.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52.88270115852356 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 36%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                                                   | 183/503 [08:58<15:42,  2.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53.67792844772339 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 37%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž                                                  | 184/503 [09:01<15:40,  2.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52.68389582633972 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 37%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                                                  | 185/503 [09:04<15:34,  2.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52.485084533691406 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 37%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                                                  | 186/503 [09:06<15:30,  2.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51.88866853713989 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 37%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                                                  | 187/503 [09:09<15:25,  2.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50.69582462310791 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 37%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                                                  | 188/503 [09:12<15:24,  2.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51.88866853713989 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 38%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                                                  | 189/503 [09:15<15:20,  2.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50.497013330459595 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 38%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                                                 | 190/503 [09:18<15:22,  2.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51.49105191230774 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 38%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                                                 | 191/503 [09:21<15:17,  2.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51.88866853713989 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 38%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                                                 | 192/503 [09:24<15:16,  2.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52.68389582633972 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 38%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                                                 | 193/503 [09:27<15:09,  2.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "54.27435040473938 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 39%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                                                 | 194/503 [09:30<15:08,  2.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "54.07554507255554 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 39%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                                                 | 195/503 [09:33<15:01,  2.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52.08747386932373 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 39%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                                                | 196/503 [09:36<14:57,  2.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52.68389582633972 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 39%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž                                                | 197/503 [09:39<14:56,  2.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53.0815064907074 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 39%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                                                | 198/503 [09:42<14:53,  2.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52.68389582633972 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 40%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                                                | 199/503 [09:45<14:53,  2.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52.08747386932373 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 40%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                                                | 200/503 [09:48<14:49,  2.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53.47912311553955 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 40%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                                                | 201/503 [09:50<14:44,  2.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52.88270115852356 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 40%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                                               | 202/503 [09:53<14:39,  2.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51.68985724449158 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 40%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž                                               | 203/503 [09:56<14:33,  2.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52.68389582633972 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 41%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                                               | 204/503 [09:59<14:35,  2.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53.0815064907074 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 41%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                                               | 205/503 [10:02<14:28,  2.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52.08747386932373 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 41%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                                               | 206/503 [10:05<14:27,  2.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52.08747386932373 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 41%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                                               | 207/503 [10:08<14:22,  2.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52.28627920150757 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 41%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                                               | 208/503 [10:11<14:18,  2.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52.88270115852356 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                                              | 209/503 [10:14<14:19,  2.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "54.07554507255554 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                                              | 210/503 [10:17<14:17,  2.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52.88270115852356 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                                              | 211/503 [10:20<14:11,  2.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52.68389582633972 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                                              | 212/503 [10:23<14:06,  2.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51.88866853713989 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                                              | 213/503 [10:25<14:02,  2.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52.68389582633972 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                                              | 214/503 [10:28<14:01,  2.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53.47912311553955 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                                             | 215/503 [10:31<13:56,  2.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53.67792844772339 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž                                             | 216/503 [10:34<14:04,  2.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52.88270115852356 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                                             | 217/503 [10:37<14:08,  2.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52.08747386932373 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                                             | 218/503 [10:40<14:05,  2.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51.2922465801239 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                                             | 219/503 [10:43<13:59,  2.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52.68389582633972 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                                             | 220/503 [10:46<13:53,  2.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52.08747386932373 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                                            | 221/503 [10:49<13:50,  2.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52.68389582633972 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž                                            | 222/503 [10:52<13:46,  2.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52.28627920150757 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                                            | 223/503 [10:55<13:49,  2.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53.67792844772339 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                                            | 224/503 [10:58<13:52,  2.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51.2922465801239 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                                            | 225/503 [11:01<14:00,  3.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52.28627920150757 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                                            | 226/503 [11:04<13:57,  3.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53.0815064907074 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                                            | 227/503 [11:07<13:55,  3.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52.28627920150757 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž                                           | 228/503 [11:10<13:52,  3.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51.68985724449158 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                                           | 229/503 [11:13<13:47,  3.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52.88270115852356 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                                           | 230/503 [11:16<13:42,  3.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53.876739740371704 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                                           | 231/503 [11:19<13:39,  3.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52.08747386932373 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                                           | 232/503 [11:22<13:37,  3.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51.88866853713989 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                                           | 233/503 [11:25<13:29,  3.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53.0815064907074 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                                          | 234/503 [11:28<13:27,  3.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52.485084533691406 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                                          | 235/503 [11:31<13:27,  3.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52.485084533691406 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                                          | 236/503 [11:34<13:26,  3.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52.485084533691406 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                                          | 237/503 [11:37<13:13,  2.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53.67792844772339 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                                          | 238/503 [11:40<13:07,  2.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51.68985724449158 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                                          | 239/503 [11:43<12:59,  2.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51.68985724449158 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                                         | 240/503 [11:46<12:56,  2.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51.49105191230774 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž                                         | 241/503 [11:49<12:57,  2.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53.876739740371704 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                                         | 242/503 [11:52<12:49,  2.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52.485084533691406 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                                         | 243/503 [11:55<12:43,  2.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "54.07554507255554 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                                         | 244/503 [11:58<12:40,  2.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53.47912311553955 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                                         | 245/503 [12:01<12:39,  2.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50.89462995529175 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                                        | 246/503 [12:04<12:34,  2.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51.88866853713989 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž                                        | 247/503 [12:07<12:28,  2.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52.08747386932373 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                                        | 248/503 [12:09<12:27,  2.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52.28627920150757 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                                        | 249/503 [12:12<12:27,  2.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53.28031778335571 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                                        | 250/503 [12:15<12:22,  2.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52.28627920150757 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                                        | 251/503 [12:18<12:16,  2.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52.88270115852356 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                                        | 252/503 [12:21<12:16,  2.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53.28031778335571 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                                       | 253/503 [12:24<12:10,  2.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53.67792844772339 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                                       | 254/503 [12:27<12:07,  2.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53.28031778335571 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                                       | 255/503 [12:30<12:09,  2.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53.876739740371704 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                                       | 256/503 [12:33<12:02,  2.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53.47912311553955 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                                       | 257/503 [12:36<11:57,  2.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52.88270115852356 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                                       | 258/503 [12:39<11:52,  2.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52.68389582633972 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                                      | 259/503 [12:42<11:54,  2.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51.68985724449158 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž                                      | 260/503 [12:45<11:52,  2.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52.68389582633972 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                                      | 261/503 [12:48<11:48,  2.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51.49105191230774 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                                      | 262/503 [12:50<11:42,  2.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53.47912311553955 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                                      | 263/503 [12:53<11:37,  2.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52.08747386932373 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                                      | 264/503 [12:56<11:34,  2.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52.68389582633972 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                                     | 265/503 [12:59<11:35,  2.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52.68389582633972 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž                                     | 266/503 [13:02<11:33,  2.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52.485084533691406 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                                     | 267/503 [13:05<11:34,  2.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53.47912311553955 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                                     | 268/503 [13:08<11:29,  2.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52.08747386932373 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                                     | 269/503 [13:11<11:25,  2.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53.67792844772339 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                                     | 270/503 [13:14<11:21,  2.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52.08747386932373 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                                     | 271/503 [13:17<11:20,  2.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "54.07554507255554 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž                                    | 272/503 [13:20<11:14,  2.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51.2922465801239 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                                    | 273/503 [13:23<11:11,  2.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53.67792844772339 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                                    | 274/503 [13:26<11:11,  2.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52.68389582633972 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                                    | 275/503 [13:29<11:08,  2.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53.28031778335571 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                                    | 276/503 [13:31<11:05,  2.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53.0815064907074 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                                    | 277/503 [13:34<11:00,  2.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53.0815064907074 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                                   | 278/503 [13:37<10:55,  2.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52.88270115852356 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž                                   | 279/503 [13:40<10:53,  2.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53.0815064907074 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                                   | 280/503 [13:43<10:52,  2.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53.67792844772339 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                                   | 281/503 [13:46<10:47,  2.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52.68389582633972 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                                   | 282/503 [13:49<10:44,  2.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52.28627920150757 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                                   | 283/503 [13:52<10:41,  2.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53.0815064907074 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                                  | 284/503 [13:55<10:39,  2.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53.47912311553955 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž                                  | 285/503 [13:58<10:36,  2.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52.88270115852356 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                                  | 286/503 [14:01<10:37,  2.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53.67792844772339 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                                  | 287/503 [14:04<10:32,  2.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51.093435287475586 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                                  | 288/503 [14:07<10:30,  2.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53.47912311553955 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                                  | 289/503 [14:09<10:26,  2.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52.485084533691406 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                                  | 290/503 [14:12<10:23,  2.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51.88866853713989 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž                                 | 291/503 [14:15<10:21,  2.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52.485084533691406 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                                 | 292/503 [14:18<10:15,  2.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53.876739740371704 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                                 | 293/503 [14:21<10:13,  2.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51.88866853713989 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                                 | 294/503 [14:24<10:10,  2.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52.28627920150757 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                                 | 295/503 [14:27<10:06,  2.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52.28627920150757 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                                 | 296/503 [14:30<10:04,  2.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53.0815064907074 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                                | 297/503 [14:33<10:04,  2.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51.68985724449158 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                                | 298/503 [14:36<10:02,  2.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52.88270115852356 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                                | 299/503 [14:39<09:59,  2.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53.0815064907074 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                                | 300/503 [14:42<09:57,  2.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53.0815064907074 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                                | 301/503 [14:45<09:53,  2.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52.485084533691406 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                                | 302/503 [14:48<09:51,  2.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53.28031778335571 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                               | 303/503 [14:50<09:46,  2.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52.68389582633972 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž                               | 304/503 [14:53<09:43,  2.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53.47912311553955 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                               | 305/503 [14:56<09:40,  2.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52.68389582633972 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                               | 306/503 [14:59<09:36,  2.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51.2922465801239 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                               | 307/503 [15:02<09:33,  2.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52.68389582633972 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                               | 308/503 [15:05<09:28,  2.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51.88866853713989 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                              | 309/503 [15:08<09:27,  2.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52.88270115852356 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž                              | 310/503 [15:11<09:22,  2.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "54.27435040473938 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                              | 311/503 [15:14<09:21,  2.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52.485084533691406 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                              | 312/503 [15:17<09:17,  2.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52.485084533691406 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                              | 313/503 [15:20<09:17,  2.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53.28031778335571 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                              | 314/503 [15:23<09:14,  2.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52.88270115852356 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                              | 315/503 [15:26<09:11,  2.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53.0815064907074 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž                             | 316/503 [15:29<09:09,  2.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52.485084533691406 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                             | 317/503 [15:31<09:03,  2.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51.68985724449158 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                             | 318/503 [15:34<09:01,  2.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53.47912311553955 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                             | 319/503 [15:37<08:58,  2.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52.08747386932373 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                             | 320/503 [15:40<08:56,  2.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52.88270115852356 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                             | 321/503 [15:43<08:54,  2.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51.68985724449158 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                            | 322/503 [15:46<08:50,  2.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52.08747386932373 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž                            | 323/503 [15:49<08:51,  2.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53.0815064907074 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                            | 324/503 [15:52<08:47,  2.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53.67792844772339 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                            | 325/503 [15:55<08:42,  2.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51.68985724449158 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                            | 326/503 [15:58<08:38,  2.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51.2922465801239 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                            | 327/503 [16:01<08:35,  2.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53.0815064907074 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                           | 328/503 [16:04<08:35,  2.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53.28031778335571 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž                           | 329/503 [16:07<08:41,  3.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52.28627920150757 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                           | 330/503 [16:10<08:38,  3.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53.28031778335571 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                           | 331/503 [16:13<08:33,  2.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52.08747386932373 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                           | 332/503 [16:16<08:31,  2.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53.67792844772339 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                           | 333/503 [16:19<08:26,  2.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52.68389582633972 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                           | 334/503 [16:22<08:21,  2.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52.485084533691406 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž                          | 335/503 [16:25<08:17,  2.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53.0815064907074 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                          | 336/503 [16:28<08:14,  2.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52.68389582633972 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                          | 337/503 [16:31<08:10,  2.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52.485084533691406 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                          | 338/503 [16:33<08:05,  2.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52.28627920150757 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                          | 339/503 [16:36<08:03,  2.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53.0815064907074 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                          | 340/503 [16:39<08:00,  2.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52.28627920150757 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                         | 341/503 [16:42<08:02,  2.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52.485084533691406 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                         | 342/503 [16:45<08:01,  2.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51.49105191230774 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                         | 343/503 [16:48<07:59,  2.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52.485084533691406 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                         | 344/503 [16:51<07:57,  3.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52.08747386932373 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                         | 345/503 [16:54<07:52,  2.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51.68985724449158 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                         | 346/503 [16:57<07:49,  2.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52.88270115852356 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                        | 347/503 [17:00<07:44,  2.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52.28627920150757 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž                        | 348/503 [17:03<07:42,  2.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52.88270115852356 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                        | 349/503 [17:06<07:38,  2.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53.67792844772339 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                        | 350/503 [17:09<07:32,  2.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53.28031778335571 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                        | 351/503 [17:12<07:28,  2.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51.49105191230774 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                        | 352/503 [17:15<07:25,  2.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52.68389582633972 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                       | 353/503 [17:18<07:20,  2.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52.28627920150757 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž                       | 354/503 [17:21<07:17,  2.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52.28627920150757 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                       | 355/503 [17:24<07:14,  2.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51.88866853713989 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                       | 356/503 [17:27<07:10,  2.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53.67792844772339 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                       | 357/503 [17:30<07:07,  2.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52.68389582633972 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                       | 358/503 [17:33<07:06,  2.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53.0815064907074 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                       | 359/503 [17:36<07:02,  2.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52.88270115852356 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž                      | 360/503 [17:39<07:00,  2.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51.88866853713989 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                      | 361/503 [17:42<06:57,  2.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51.68985724449158 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                      | 362/503 [17:44<06:53,  2.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "54.07554507255554 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                      | 363/503 [17:47<06:52,  2.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52.485084533691406 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                      | 364/503 [17:50<06:48,  2.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53.0815064907074 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                      | 365/503 [17:53<06:43,  2.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52.68389582633972 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                     | 366/503 [17:56<06:39,  2.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52.485084533691406 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž                     | 367/503 [17:59<06:39,  2.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52.88270115852356 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                     | 368/503 [18:02<06:38,  2.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52.485084533691406 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                     | 369/503 [18:05<06:34,  2.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53.28031778335571 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                     | 370/503 [18:08<06:29,  2.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52.28627920150757 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                     | 371/503 [18:11<06:26,  2.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53.0815064907074 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                    | 372/503 [18:14<06:22,  2.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53.47912311553955 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž                    | 373/503 [18:17<06:19,  2.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51.49105191230774 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                    | 374/503 [18:20<06:17,  2.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52.08747386932373 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                    | 375/503 [18:23<06:14,  2.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53.67792844772339 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                    | 376/503 [18:25<06:11,  2.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52.485084533691406 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                    | 377/503 [18:28<06:11,  2.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53.28031778335571 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                    | 378/503 [18:31<06:07,  2.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52.68389582633972 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž                   | 379/503 [18:34<06:02,  2.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52.88270115852356 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                   | 380/503 [18:37<05:58,  2.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53.47912311553955 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                   | 381/503 [18:40<05:56,  2.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52.88270115852356 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                   | 382/503 [18:43<05:53,  2.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52.485084533691406 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                   | 383/503 [18:46<05:50,  2.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52.88270115852356 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                   | 384/503 [18:49<05:48,  2.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53.47912311553955 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                  | 385/503 [18:52<05:45,  2.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52.88270115852356 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                  | 386/503 [18:55<05:41,  2.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52.08747386932373 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                  | 387/503 [18:58<05:38,  2.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53.47912311553955 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                  | 388/503 [19:01<05:35,  2.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53.47912311553955 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                  | 389/503 [19:03<05:32,  2.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52.68389582633972 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                  | 390/503 [19:06<05:28,  2.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52.28627920150757 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                 | 391/503 [19:09<05:27,  2.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53.28031778335571 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž                 | 392/503 [19:12<05:25,  2.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51.68985724449158 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                 | 393/503 [19:15<05:21,  2.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51.68985724449158 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                 | 394/503 [19:18<05:17,  2.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53.67792844772339 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                 | 395/503 [19:21<05:14,  2.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51.88866853713989 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                 | 396/503 [19:24<05:12,  2.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51.68985724449158 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                | 397/503 [19:27<05:08,  2.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52.28627920150757 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž                | 398/503 [19:30<05:06,  2.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53.47912311553955 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                | 399/503 [19:33<05:02,  2.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50.89462995529175 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                | 400/503 [19:36<05:01,  2.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51.49105191230774 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                | 401/503 [19:39<05:01,  2.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "54.07554507255554 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                | 402/503 [19:42<04:59,  2.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51.88866853713989 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                | 403/503 [19:45<05:00,  3.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52.28627920150757 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž               | 404/503 [19:48<04:58,  3.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52.28627920150757 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–               | 405/503 [19:51<04:53,  3.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51.49105191230774 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ               | 406/503 [19:54<04:48,  2.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53.0815064907074 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹               | 407/503 [19:57<04:43,  2.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52.08747386932373 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰               | 408/503 [19:59<04:39,  2.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52.485084533691406 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ               | 409/503 [20:02<04:35,  2.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52.88270115852356 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–              | 410/503 [20:05<04:31,  2.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53.0815064907074 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž              | 411/503 [20:08<04:29,  2.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52.485084533691406 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ              | 412/503 [20:11<04:25,  2.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53.47912311553955 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹              | 413/503 [20:14<04:22,  2.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52.28627920150757 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š              | 414/503 [20:17<04:19,  2.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52.28627920150757 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ              | 415/503 [20:20<04:17,  2.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52.88270115852356 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–             | 416/503 [20:23<04:17,  2.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52.88270115852356 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž             | 417/503 [20:26<04:13,  2.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52.08747386932373 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–             | 418/503 [20:29<04:09,  2.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50.89462995529175 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹             | 419/503 [20:32<04:06,  2.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52.68389582633972 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š             | 420/503 [20:35<04:02,  2.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53.67792844772339 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰             | 421/503 [20:37<03:59,  2.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52.485084533691406 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ             | 422/503 [20:40<03:56,  2.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53.28031778335571 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž            | 423/503 [20:43<03:55,  2.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52.88270115852356 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–            | 424/503 [20:46<03:51,  2.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52.68389582633972 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ            | 425/503 [20:49<03:49,  2.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "54.67196702957153 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š            | 426/503 [20:52<03:45,  2.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53.876739740371704 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰            | 427/503 [20:55<03:43,  2.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52.28627920150757 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ            | 428/503 [20:58<03:40,  2.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53.0815064907074 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–           | 429/503 [21:01<03:37,  2.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53.47912311553955 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–           | 430/503 [21:04<03:34,  2.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51.2922465801239 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ           | 431/503 [21:07<03:31,  2.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53.47912311553955 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹           | 432/503 [21:10<03:28,  2.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52.88270115852356 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š           | 433/503 [21:13<03:24,  2.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52.68389582633972 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ           | 434/503 [21:16<03:21,  2.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51.49105191230774 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–          | 435/503 [21:19<03:18,  2.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50.89462995529175 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž          | 436/503 [21:21<03:16,  2.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52.485084533691406 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ          | 437/503 [21:24<03:13,  2.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53.0815064907074 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹          | 438/503 [21:27<03:11,  2.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52.28627920150757 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š          | 439/503 [21:30<03:08,  2.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52.28627920150757 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰          | 440/503 [21:33<03:06,  2.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53.0815064907074 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–         | 441/503 [21:36<03:02,  2.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52.88270115852356 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž         | 442/503 [21:39<02:59,  2.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52.68389582633972 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–         | 443/503 [21:42<02:56,  2.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53.876739740371704 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ         | 444/503 [21:45<02:53,  2.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52.68389582633972 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š         | 445/503 [21:48<02:51,  2.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52.88270115852356 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰         | 446/503 [21:51<02:47,  2.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51.88866853713989 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ         | 447/503 [21:54<02:43,  2.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52.28627920150757 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž        | 448/503 [21:57<02:40,  2.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53.28031778335571 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–        | 449/503 [22:00<02:37,  2.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52.68389582633972 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ        | 450/503 [22:03<02:34,  2.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52.28627920150757 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹        | 451/503 [22:06<02:33,  2.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52.28627920150757 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰        | 452/503 [22:09<02:29,  2.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52.28627920150757 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ        | 453/503 [22:11<02:26,  2.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53.28031778335571 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–       | 454/503 [22:14<02:23,  2.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52.28627920150757 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž       | 455/503 [22:17<02:20,  2.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53.28031778335571 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ       | 456/503 [22:20<02:17,  2.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52.68389582633972 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹       | 457/503 [22:23<02:14,  2.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53.28031778335571 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š       | 458/503 [22:26<02:11,  2.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52.88270115852356 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ       | 459/503 [22:29<02:09,  2.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52.28627920150757 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–      | 460/503 [22:32<02:06,  2.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "54.07554507255554 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž      | 461/503 [22:35<02:02,  2.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53.0815064907074 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–      | 462/503 [22:38<01:59,  2.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51.49105191230774 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹      | 463/503 [22:41<01:57,  2.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52.485084533691406 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š      | 464/503 [22:44<01:53,  2.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52.08747386932373 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰      | 465/503 [22:47<01:51,  2.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53.47912311553955 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ      | 466/503 [22:49<01:48,  2.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52.88270115852356 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 467/503 [22:52<01:45,  2.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53.67792844772339 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–     | 468/503 [22:55<01:42,  2.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53.28031778335571 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 469/503 [22:58<01:39,  2.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53.67792844772339 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 470/503 [23:01<01:36,  2.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52.68389582633972 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 471/503 [23:04<01:33,  2.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53.47912311553955 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 472/503 [23:07<01:31,  2.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51.88866853713989 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 473/503 [23:10<01:28,  2.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53.0815064907074 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 474/503 [23:13<01:25,  2.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51.49105191230774 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 475/503 [23:16<01:22,  2.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52.68389582633972 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 476/503 [23:19<01:19,  2.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52.08747386932373 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 477/503 [23:22<01:16,  2.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53.0815064907074 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 478/503 [23:25<01:13,  2.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52.485084533691406 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 479/503 [23:28<01:10,  2.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52.485084533691406 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 480/503 [23:31<01:07,  2.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52.28627920150757 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 481/503 [23:34<01:04,  2.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50.69582462310791 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 482/503 [23:37<01:01,  2.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51.88866853713989 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 483/503 [23:39<00:58,  2.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53.0815064907074 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 484/503 [23:42<00:56,  2.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53.0815064907074 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 485/503 [23:45<00:52,  2.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52.88270115852356 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 486/503 [23:48<00:49,  2.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52.485084533691406 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 487/503 [23:51<00:47,  2.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53.0815064907074 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 488/503 [23:54<00:44,  2.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53.47912311553955 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 489/503 [23:57<00:41,  2.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52.08747386932373 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 490/503 [24:00<00:37,  2.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53.47912311553955 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 491/503 [24:03<00:35,  2.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52.08747386932373 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 492/503 [24:06<00:32,  2.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53.28031778335571 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 493/503 [24:09<00:29,  2.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52.68389582633972 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 494/503 [24:12<00:26,  2.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50.69582462310791 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 495/503 [24:15<00:23,  2.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52.08747386932373 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 496/503 [24:18<00:20,  2.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53.47912311553955 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 497/503 [24:21<00:17,  2.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53.0815064907074 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 498/503 [24:24<00:14,  2.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51.88866853713989 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 499/503 [24:27<00:11,  2.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51.68985724449158 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 500/503 [24:30<00:08,  2.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53.47912311553955 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 501/503 [24:33<00:05,  2.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51.88866853713989 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 502/503 [24:36<00:03,  3.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51.68985724449158 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 503/503 [24:39<00:00,  2.94s/it]\n"
     ]
    }
   ],
   "source": [
    "acc2=[]\n",
    "for i in tqdm(range(503)):\n",
    "    dummystats2=np.zeros((1,melspectrogram.shape[0],maxlength+27))\n",
    "    datadictstats2 = {'TEST':dummy}\n",
    "    labeldictstats2 = {'TEST':[]}\n",
    "    test_datasetstats2 = SDRDataset(sdr_df, type = \"TEST\")\n",
    "    testdl2stats2 = DataLoader(test_datasetstats2, batch_size=1, shuffle=True)##shuffle =True ensures resampling same samples\n",
    "    acc2.append(get_accuracy(testdl2stats2,modelgru))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 601,
   "id": "1100017d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  0%|                                                                                          | 0/503 [00:00<?, ?it/s]\n",
      "\n",
      "  0%|â–                                                                                 | 1/503 [00:02<21:39,  2.59s/it]\n",
      "\n",
      "  0%|â–Ž                                                                                 | 2/503 [00:05<21:39,  2.59s/it]\n",
      "\n",
      "  1%|â–                                                                                 | 3/503 [00:07<21:29,  2.58s/it]\n",
      "\n",
      "  1%|â–‹                                                                                 | 4/503 [00:10<21:33,  2.59s/it]\n",
      "\n",
      "  1%|â–Š                                                                                 | 5/503 [00:12<21:19,  2.57s/it]\n",
      "\n",
      "  1%|â–‰                                                                                 | 6/503 [00:15<21:02,  2.54s/it]\n",
      "\n",
      "  1%|â–ˆâ–                                                                                | 7/503 [00:17<21:01,  2.54s/it]\n",
      "\n",
      "  2%|â–ˆâ–Ž                                                                                | 8/503 [00:20<20:52,  2.53s/it]\n",
      "\n",
      "  2%|â–ˆâ–                                                                                | 9/503 [00:22<20:43,  2.52s/it]\n",
      "\n",
      "  2%|â–ˆâ–Œ                                                                               | 10/503 [00:25<20:34,  2.50s/it]\n",
      "\n",
      "  2%|â–ˆâ–Š                                                                               | 11/503 [00:27<20:33,  2.51s/it]\n",
      "\n",
      "  2%|â–ˆâ–‰                                                                               | 12/503 [00:30<20:35,  2.52s/it]\n",
      "\n",
      "  3%|â–ˆâ–ˆ                                                                               | 13/503 [00:32<20:24,  2.50s/it]\n",
      "\n",
      "  3%|â–ˆâ–ˆâ–Ž                                                                              | 14/503 [00:35<20:44,  2.54s/it]\n",
      "\n",
      "  3%|â–ˆâ–ˆâ–                                                                              | 15/503 [00:38<20:50,  2.56s/it]\n",
      "\n",
      "  3%|â–ˆâ–ˆâ–Œ                                                                              | 16/503 [00:40<20:32,  2.53s/it]\n",
      "\n",
      "  3%|â–ˆâ–ˆâ–‹                                                                              | 17/503 [00:43<20:18,  2.51s/it]\n",
      "\n",
      "  4%|â–ˆâ–ˆâ–‰                                                                              | 18/503 [00:45<20:06,  2.49s/it]\n",
      "\n",
      "  4%|â–ˆâ–ˆâ–ˆ                                                                              | 19/503 [00:48<20:10,  2.50s/it]\n",
      "\n",
      "  4%|â–ˆâ–ˆâ–ˆâ–                                                                             | 20/503 [00:50<20:15,  2.52s/it]\n",
      "\n",
      "  4%|â–ˆâ–ˆâ–ˆâ–                                                                             | 21/503 [00:53<20:10,  2.51s/it]\n",
      "\n",
      "  4%|â–ˆâ–ˆâ–ˆâ–Œ                                                                             | 22/503 [00:55<20:05,  2.51s/it]\n",
      "\n",
      "  5%|â–ˆâ–ˆâ–ˆâ–‹                                                                             | 23/503 [00:58<19:55,  2.49s/it]\n",
      "\n",
      "  5%|â–ˆâ–ˆâ–ˆâ–Š                                                                             | 24/503 [01:00<19:50,  2.48s/it]\n",
      "\n",
      "  5%|â–ˆâ–ˆâ–ˆâ–ˆ                                                                             | 25/503 [01:02<19:50,  2.49s/it]\n",
      "\n",
      "  5%|â–ˆâ–ˆâ–ˆâ–ˆâ–                                                                            | 26/503 [01:05<19:38,  2.47s/it]\n",
      "\n",
      "  5%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž                                                                            | 27/503 [01:07<19:48,  2.50s/it]\n",
      "\n",
      "  6%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ                                                                            | 28/503 [01:10<19:54,  2.52s/it]\n",
      "\n",
      "  6%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹                                                                            | 29/503 [01:13<19:51,  2.51s/it]\n",
      "\n",
      "  6%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š                                                                            | 30/503 [01:15<19:46,  2.51s/it]\n",
      "\n",
      "  6%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰                                                                            | 31/503 [01:18<19:47,  2.52s/it]\n",
      "\n",
      "  6%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                                                                           | 32/503 [01:20<19:57,  2.54s/it]\n",
      "\n",
      "  7%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž                                                                           | 33/503 [01:23<19:55,  2.54s/it]\n",
      "\n",
      "  7%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                                                                           | 34/503 [01:25<19:40,  2.52s/it]\n",
      "\n",
      "  7%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                                                                           | 35/503 [01:28<19:27,  2.49s/it]\n",
      "\n",
      "  7%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                                                                           | 36/503 [01:30<19:16,  2.48s/it]\n",
      "\n",
      "  7%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                                                                           | 37/503 [01:33<19:15,  2.48s/it]\n",
      "\n",
      "  8%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                                                                           | 38/503 [01:35<19:17,  2.49s/it]\n",
      "\n",
      "  8%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž                                                                          | 39/503 [01:38<19:17,  2.49s/it]\n",
      "\n",
      "  8%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                                                                          | 40/503 [01:40<19:11,  2.49s/it]\n",
      "\n",
      "  8%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                                                                          | 41/503 [01:42<19:05,  2.48s/it]\n",
      "\n",
      "  8%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                                                                          | 42/503 [01:45<18:56,  2.47s/it]\n",
      "\n",
      "  9%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                                                                          | 43/503 [01:47<18:50,  2.46s/it]\n",
      "\n",
      "  9%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                                                                          | 44/503 [01:50<18:59,  2.48s/it]\n",
      "\n",
      "  9%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                                                                         | 45/503 [01:52<18:53,  2.47s/it]\n",
      "\n",
      "  9%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                                                                         | 46/503 [01:55<18:55,  2.48s/it]\n",
      "\n",
      "  9%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                                                                         | 47/503 [01:57<18:52,  2.48s/it]\n",
      "\n",
      " 10%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                                                                         | 48/503 [02:00<18:42,  2.47s/it]\n",
      "\n",
      " 10%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                                                                         | 49/503 [02:02<18:37,  2.46s/it]\n",
      "\n",
      " 10%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                                                                         | 50/503 [02:05<18:36,  2.47s/it]\n",
      "\n",
      " 10%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                                                                        | 51/503 [02:07<18:37,  2.47s/it]\n",
      "\n",
      " 10%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž                                                                        | 52/503 [02:10<18:29,  2.46s/it]\n",
      "\n",
      " 11%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                                                                        | 53/503 [02:12<18:33,  2.47s/it]\n",
      "\n",
      " 11%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                                                                        | 54/503 [02:15<18:31,  2.48s/it]\n",
      "\n",
      " 11%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                                                                        | 55/503 [02:17<18:34,  2.49s/it]\n",
      "\n",
      " 11%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                                                                        | 56/503 [02:20<18:46,  2.52s/it]\n",
      "\n",
      " 11%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                                                                       | 57/503 [02:22<18:37,  2.51s/it]\n",
      "\n",
      " 12%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž                                                                       | 58/503 [02:25<18:20,  2.47s/it]\n",
      "\n",
      " 12%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                                                                       | 59/503 [02:27<18:12,  2.46s/it]\n",
      "\n",
      " 12%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                                                                       | 60/503 [02:29<18:06,  2.45s/it]\n",
      "\n",
      " 12%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                                                                       | 61/503 [02:32<18:13,  2.47s/it]\n",
      "\n",
      " 12%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                                                                       | 62/503 [02:34<18:02,  2.45s/it]\n",
      "\n",
      " 13%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                                                                      | 63/503 [02:37<18:07,  2.47s/it]\n",
      "\n",
      " 13%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž                                                                      | 64/503 [02:39<18:12,  2.49s/it]\n",
      "\n",
      " 13%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                                                                      | 65/503 [02:42<18:04,  2.48s/it]\n",
      "\n",
      " 13%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                                                                      | 66/503 [02:44<18:00,  2.47s/it]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                                                                      | 67/503 [02:47<17:58,  2.47s/it]\n",
      "\n",
      " 14%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                                                                      | 68/503 [02:49<18:02,  2.49s/it]\n",
      "\n",
      " 14%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                                                                      | 69/503 [02:52<17:50,  2.47s/it]\n",
      "\n",
      " 14%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž                                                                     | 70/503 [02:54<17:41,  2.45s/it]\n",
      "\n",
      " 14%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                                                                     | 71/503 [02:57<17:35,  2.44s/it]\n",
      "\n",
      " 14%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                                                                     | 72/503 [02:59<17:34,  2.45s/it]\n",
      "\n",
      " 15%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                                                                     | 73/503 [03:01<17:29,  2.44s/it]\n",
      "\n",
      " 15%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                                                                     | 74/503 [03:04<17:30,  2.45s/it]\n",
      "\n",
      " 15%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                                                                     | 75/503 [03:06<17:32,  2.46s/it]\n",
      "\n",
      " 15%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                                                                    | 76/503 [03:09<17:27,  2.45s/it]\n",
      "\n",
      " 15%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                                                                    | 77/503 [03:11<17:22,  2.45s/it]\n",
      "\n",
      " 16%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                                                                    | 78/503 [03:14<17:20,  2.45s/it]\n",
      "\n",
      " 16%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                                                                    | 79/503 [03:16<17:19,  2.45s/it]\n",
      "\n",
      " 16%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                                                                    | 80/503 [03:19<17:20,  2.46s/it]\n",
      "\n",
      " 16%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                                                                    | 81/503 [03:21<17:22,  2.47s/it]\n",
      "\n",
      " 16%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                                                                   | 82/503 [03:24<17:21,  2.47s/it]\n",
      "\n",
      " 17%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž                                                                   | 83/503 [03:26<17:13,  2.46s/it]\n",
      "\n",
      " 17%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                                                                   | 84/503 [03:29<17:04,  2.44s/it]\n",
      "\n",
      " 17%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                                                                   | 85/503 [03:31<17:00,  2.44s/it]\n",
      "\n",
      " 17%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                                                                   | 86/503 [03:33<17:03,  2.45s/it]\n",
      "\n",
      " 17%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                                                                   | 87/503 [03:36<16:58,  2.45s/it]\n",
      "\n",
      " 17%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                                                                  | 88/503 [03:38<16:51,  2.44s/it]\n",
      "\n",
      " 18%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž                                                                  | 89/503 [03:41<16:50,  2.44s/it]\n",
      "\n",
      " 18%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                                                                  | 90/503 [03:43<16:46,  2.44s/it]\n",
      "\n",
      " 18%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                                                                  | 91/503 [03:46<16:52,  2.46s/it]\n",
      "\n",
      " 18%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                                                                  | 92/503 [03:48<16:49,  2.46s/it]\n",
      "\n",
      " 18%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                                                                  | 93/503 [03:51<16:47,  2.46s/it]\n",
      "\n",
      " 19%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                                                                 | 94/503 [03:53<16:41,  2.45s/it]\n",
      "\n",
      " 19%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž                                                                 | 95/503 [03:55<16:36,  2.44s/it]\n",
      "\n",
      " 19%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                                                                 | 96/503 [03:58<16:32,  2.44s/it]\n",
      "\n",
      " 19%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                                                                 | 97/503 [04:00<16:34,  2.45s/it]\n",
      "\n",
      " 19%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                                                                 | 98/503 [04:03<16:30,  2.44s/it]\n",
      "\n",
      " 20%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                                                                 | 99/503 [04:05<16:30,  2.45s/it]\n",
      "\n",
      " 20%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                                                                | 100/503 [04:08<16:22,  2.44s/it]\n",
      "\n",
      " 20%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                                                                | 101/503 [04:10<16:29,  2.46s/it]\n",
      "\n",
      " 20%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                                                               | 102/503 [04:13<16:30,  2.47s/it]\n",
      "\n",
      " 20%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                                                               | 103/503 [04:15<16:44,  2.51s/it]\n",
      "\n",
      " 21%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                                                               | 104/503 [04:18<16:36,  2.50s/it]\n",
      "\n",
      " 21%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                                                               | 105/503 [04:20<16:33,  2.50s/it]\n",
      "\n",
      " 21%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                                                               | 106/503 [04:23<16:25,  2.48s/it]\n",
      "\n",
      " 21%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                                                               | 107/503 [04:25<16:22,  2.48s/it]\n",
      "\n",
      " 21%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                                                              | 108/503 [04:28<16:19,  2.48s/it]\n",
      "\n",
      " 22%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž                                                              | 109/503 [04:30<16:09,  2.46s/it]\n",
      "\n",
      " 22%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                                                              | 110/503 [04:32<16:06,  2.46s/it]\n",
      "\n",
      " 22%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                                                              | 111/503 [04:35<16:01,  2.45s/it]\n",
      "\n",
      " 22%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                                                              | 112/503 [04:37<15:58,  2.45s/it]\n",
      "\n",
      " 22%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                                                              | 113/503 [04:40<15:55,  2.45s/it]\n",
      "\n",
      " 23%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                                                             | 114/503 [04:42<15:52,  2.45s/it]\n",
      "\n",
      " 23%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž                                                             | 115/503 [04:45<15:54,  2.46s/it]\n",
      "\n",
      " 23%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                                                             | 116/503 [04:47<15:49,  2.45s/it]\n",
      "\n",
      " 23%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                                                             | 117/503 [04:50<15:53,  2.47s/it]\n",
      "\n",
      " 23%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                                                             | 118/503 [04:52<15:59,  2.49s/it]\n",
      "\n",
      " 24%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                                                             | 119/503 [04:55<16:14,  2.54s/it]\n",
      "\n",
      " 24%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                                                             | 120/503 [04:57<16:15,  2.55s/it]\n",
      "\n",
      " 24%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                                                            | 121/503 [05:00<16:12,  2.55s/it]\n",
      "\n",
      " 24%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                                                            | 122/503 [05:02<16:02,  2.53s/it]\n",
      "\n",
      " 24%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                                                            | 123/503 [05:05<16:01,  2.53s/it]\n",
      "\n",
      " 25%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                                                            | 124/503 [05:07<15:46,  2.50s/it]\n",
      "\n",
      " 25%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                                                            | 125/503 [05:10<15:33,  2.47s/it]\n",
      "\n",
      " 25%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                                                            | 126/503 [05:12<15:30,  2.47s/it]\n",
      "\n",
      " 25%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                                                           | 127/503 [05:15<15:34,  2.49s/it]\n",
      "\n",
      " 25%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž                                                           | 128/503 [05:17<15:33,  2.49s/it]\n",
      "\n",
      " 26%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                                                           | 129/503 [05:20<15:33,  2.49s/it]\n",
      "\n",
      " 26%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                                                           | 130/503 [05:23<15:51,  2.55s/it]\n",
      "\n",
      " 26%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                                                           | 131/503 [05:25<15:59,  2.58s/it]\n",
      "\n",
      " 26%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                                                           | 132/503 [05:28<16:10,  2.62s/it]\n",
      "\n",
      " 26%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                                                          | 133/503 [05:31<16:23,  2.66s/it]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž                                                          | 134/503 [05:33<16:15,  2.64s/it]\n",
      "\n",
      " 27%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                                                          | 135/503 [05:36<16:00,  2.61s/it]\n",
      "\n",
      " 27%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                                                          | 136/503 [05:38<15:48,  2.58s/it]\n",
      "\n",
      " 27%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                                                          | 137/503 [05:41<15:41,  2.57s/it]\n",
      "\n",
      " 27%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                                                          | 138/503 [05:43<15:25,  2.54s/it]\n",
      "\n",
      " 28%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                                                          | 139/503 [05:46<15:28,  2.55s/it]\n",
      "\n",
      " 28%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž                                                         | 140/503 [05:49<15:40,  2.59s/it]\n",
      "\n",
      " 28%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                                                         | 141/503 [05:51<15:41,  2.60s/it]\n",
      "\n",
      " 28%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                                                         | 142/503 [05:54<15:35,  2.59s/it]\n",
      "\n",
      " 28%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                                                         | 143/503 [05:56<15:33,  2.59s/it]\n",
      "\n",
      " 29%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                                                         | 144/503 [05:59<15:21,  2.57s/it]\n",
      "\n",
      " 29%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                                                         | 145/503 [06:01<15:06,  2.53s/it]\n",
      "\n",
      " 29%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                                                        | 146/503 [06:04<15:03,  2.53s/it]\n",
      "\n",
      " 29%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                                                        | 147/503 [06:06<14:56,  2.52s/it]\n",
      "\n",
      " 29%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                                                        | 148/503 [06:09<14:52,  2.51s/it]\n",
      "\n",
      " 30%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                                                        | 149/503 [06:11<14:42,  2.49s/it]\n",
      "\n",
      " 30%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                                                        | 150/503 [06:14<14:36,  2.48s/it]\n",
      "\n",
      " 30%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                                                        | 151/503 [06:16<14:32,  2.48s/it]\n",
      "\n",
      " 30%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                                                       | 152/503 [06:19<14:34,  2.49s/it]\n",
      "\n",
      " 30%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž                                                       | 153/503 [06:21<14:38,  2.51s/it]\n",
      "\n",
      " 31%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                                                       | 154/503 [06:24<14:36,  2.51s/it]\n",
      "\n",
      " 31%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                                                       | 155/503 [06:26<14:26,  2.49s/it]\n",
      "\n",
      " 31%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                                                       | 156/503 [06:29<14:22,  2.49s/it]\n",
      "\n",
      " 31%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                                                       | 157/503 [06:31<14:19,  2.48s/it]\n",
      "\n",
      " 31%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                                                      | 158/503 [06:34<14:19,  2.49s/it]\n",
      "\n",
      " 32%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž                                                      | 159/503 [06:36<14:25,  2.52s/it]\n",
      "\n",
      " 32%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                                                      | 160/503 [06:39<14:20,  2.51s/it]\n",
      "\n",
      " 32%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                                                      | 161/503 [06:41<14:11,  2.49s/it]\n",
      "\n",
      " 32%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                                                      | 162/503 [06:44<14:01,  2.47s/it]\n",
      "\n",
      " 32%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                                                      | 163/503 [06:46<13:55,  2.46s/it]\n",
      "\n",
      " 33%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                                                      | 164/503 [06:49<13:57,  2.47s/it]\n",
      "\n",
      " 33%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                                                     | 165/503 [06:51<13:55,  2.47s/it]\n",
      "\n",
      " 33%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                                                     | 166/503 [06:53<13:52,  2.47s/it]\n",
      "\n",
      " 33%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                                                     | 167/503 [06:56<13:48,  2.46s/it]\n",
      "\n",
      " 33%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                                                     | 168/503 [06:58<13:50,  2.48s/it]\n",
      "\n",
      " 34%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                                                     | 169/503 [07:01<13:49,  2.48s/it]\n",
      "\n",
      " 34%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                                                     | 170/503 [07:03<13:43,  2.47s/it]\n",
      "\n",
      " 34%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                                                    | 171/503 [07:06<13:41,  2.48s/it]\n",
      "\n",
      " 34%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž                                                    | 172/503 [07:08<13:33,  2.46s/it]\n",
      "\n",
      " 34%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                                                    | 173/503 [07:11<13:30,  2.45s/it]\n",
      "\n",
      " 35%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                                                    | 174/503 [07:13<13:27,  2.45s/it]\n",
      "\n",
      " 35%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                                                    | 175/503 [07:16<13:23,  2.45s/it]\n",
      "\n",
      " 35%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                                                    | 176/503 [07:18<13:25,  2.46s/it]\n",
      "\n",
      " 35%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                                                   | 177/503 [07:21<13:23,  2.46s/it]\n",
      "\n",
      " 35%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž                                                   | 178/503 [07:23<13:19,  2.46s/it]\n",
      "\n",
      " 36%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                                                   | 179/503 [07:25<13:14,  2.45s/it]\n",
      "\n",
      " 36%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                                                   | 180/503 [07:28<13:13,  2.46s/it]\n",
      "\n",
      " 36%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                                                   | 181/503 [07:31<13:20,  2.49s/it]\n",
      "\n",
      " 36%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                                                   | 182/503 [07:33<13:26,  2.51s/it]\n",
      "\n",
      " 36%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                                                   | 183/503 [07:36<13:25,  2.52s/it]\n",
      "\n",
      " 37%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž                                                  | 184/503 [07:38<13:23,  2.52s/it]\n",
      "\n",
      " 37%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                                                  | 185/503 [07:41<13:18,  2.51s/it]\n",
      "\n",
      " 37%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                                                  | 186/503 [07:43<13:10,  2.49s/it]\n",
      "\n",
      " 37%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                                                  | 187/503 [07:46<13:07,  2.49s/it]\n",
      "\n",
      " 37%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                                                  | 188/503 [07:48<13:03,  2.49s/it]\n",
      "\n",
      " 38%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                                                  | 189/503 [07:51<13:03,  2.49s/it]\n",
      "\n",
      " 38%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                                                 | 190/503 [07:53<12:55,  2.48s/it]\n",
      "\n",
      " 38%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                                                 | 191/503 [07:55<12:47,  2.46s/it]\n",
      "\n",
      " 38%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                                                 | 192/503 [07:58<12:41,  2.45s/it]\n",
      "\n",
      " 38%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                                                 | 193/503 [08:00<12:38,  2.45s/it]\n",
      "\n",
      " 39%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                                                 | 194/503 [08:03<12:37,  2.45s/it]\n",
      "\n",
      " 39%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                                                 | 195/503 [08:05<12:40,  2.47s/it]\n",
      "\n",
      " 39%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                                                | 196/503 [08:08<12:42,  2.48s/it]\n",
      "\n",
      " 39%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž                                                | 197/503 [08:10<12:40,  2.48s/it]\n",
      "\n",
      " 39%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                                                | 198/503 [08:13<12:39,  2.49s/it]\n",
      "\n",
      " 40%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                                                | 199/503 [08:15<12:42,  2.51s/it]\n",
      "\n",
      " 40%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                                                | 200/503 [08:18<12:35,  2.49s/it]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                                                | 201/503 [08:20<12:36,  2.50s/it]\n",
      "\n",
      " 40%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                                               | 202/503 [08:23<12:31,  2.50s/it]\n",
      "\n",
      " 40%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž                                               | 203/503 [08:25<12:26,  2.49s/it]\n",
      "\n",
      " 41%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                                               | 204/503 [08:28<12:31,  2.51s/it]\n",
      "\n",
      " 41%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                                               | 205/503 [08:30<12:23,  2.50s/it]\n",
      "\n",
      " 41%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                                               | 206/503 [08:33<12:16,  2.48s/it]\n",
      "\n",
      " 41%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                                               | 207/503 [08:35<12:14,  2.48s/it]\n",
      "\n",
      " 41%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                                               | 208/503 [08:38<12:07,  2.47s/it]\n",
      "\n",
      " 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                                              | 209/503 [08:40<12:00,  2.45s/it]\n",
      "\n",
      " 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                                              | 210/503 [08:42<11:58,  2.45s/it]\n",
      "\n",
      " 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                                              | 211/503 [08:45<12:03,  2.48s/it]\n",
      "\n",
      " 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                                              | 212/503 [08:48<12:00,  2.48s/it]\n",
      "\n",
      " 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                                              | 213/503 [08:50<11:58,  2.48s/it]\n",
      "\n",
      " 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                                              | 214/503 [08:52<11:58,  2.49s/it]\n",
      "\n",
      " 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                                             | 215/503 [08:55<12:02,  2.51s/it]\n",
      "\n",
      " 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž                                             | 216/503 [08:58<12:00,  2.51s/it]\n",
      "\n",
      " 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                                             | 217/503 [09:00<11:59,  2.51s/it]\n",
      "\n",
      " 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                                             | 218/503 [09:03<11:55,  2.51s/it]\n",
      "\n",
      " 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                                             | 219/503 [09:05<11:51,  2.51s/it]\n",
      "\n",
      " 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                                             | 220/503 [09:08<11:51,  2.52s/it]\n",
      "\n",
      " 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                                            | 221/503 [09:10<11:50,  2.52s/it]\n",
      "\n",
      " 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž                                            | 222/503 [09:13<11:47,  2.52s/it]\n",
      "\n",
      " 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                                            | 223/503 [09:15<11:41,  2.50s/it]\n",
      "\n",
      " 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                                            | 224/503 [09:18<11:36,  2.50s/it]\n",
      "\n",
      " 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                                            | 225/503 [09:20<11:36,  2.51s/it]\n",
      "\n",
      " 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                                            | 226/503 [09:23<11:33,  2.50s/it]\n",
      "\n",
      " 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                                            | 227/503 [09:25<11:29,  2.50s/it]\n",
      "\n",
      " 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž                                           | 228/503 [09:28<11:29,  2.51s/it]\n",
      "\n",
      " 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                                           | 229/503 [09:30<11:20,  2.49s/it]\n",
      "\n",
      " 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                                           | 230/503 [09:33<11:22,  2.50s/it]\n",
      "\n",
      " 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                                           | 231/503 [09:35<11:14,  2.48s/it]\n",
      "\n",
      " 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                                           | 232/503 [09:38<11:10,  2.47s/it]\n",
      "\n",
      " 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                                           | 233/503 [09:40<11:04,  2.46s/it]\n",
      "\n",
      " 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                                          | 234/503 [09:42<11:04,  2.47s/it]\n",
      "\n",
      " 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                                          | 235/503 [09:45<11:05,  2.48s/it]\n",
      "\n",
      " 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                                          | 236/503 [09:47<11:04,  2.49s/it]\n",
      "\n",
      " 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                                          | 237/503 [09:50<11:01,  2.49s/it]\n",
      "\n",
      " 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                                          | 238/503 [09:52<10:56,  2.48s/it]\n",
      "\n",
      " 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                                          | 239/503 [09:55<10:59,  2.50s/it]\n",
      "\n",
      " 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                                         | 240/503 [09:57<10:59,  2.51s/it]\n",
      "\n",
      " 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž                                         | 241/503 [10:00<10:55,  2.50s/it]\n",
      "\n",
      " 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                                         | 242/503 [10:02<10:53,  2.50s/it]\n",
      "\n",
      " 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                                         | 243/503 [10:05<10:49,  2.50s/it]\n",
      "\n",
      " 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                                         | 244/503 [10:07<10:44,  2.49s/it]\n",
      "\n",
      " 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                                         | 245/503 [10:10<10:40,  2.48s/it]\n",
      "\n",
      " 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                                        | 246/503 [10:12<10:38,  2.48s/it]\n",
      "\n",
      " 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž                                        | 247/503 [10:15<10:35,  2.48s/it]\n",
      "\n",
      " 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                                        | 248/503 [10:17<10:30,  2.47s/it]\n",
      "\n",
      " 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                                        | 249/503 [10:20<10:33,  2.49s/it]\n",
      "\n",
      " 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                                        | 250/503 [10:22<10:28,  2.48s/it]\n",
      "\n",
      " 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                                        | 251/503 [10:25<10:23,  2.47s/it]\n",
      "\n",
      " 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                                        | 252/503 [10:27<10:21,  2.48s/it]\n",
      "\n",
      " 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                                       | 253/503 [10:30<10:20,  2.48s/it]\n",
      "\n",
      " 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                                       | 254/503 [10:32<10:16,  2.48s/it]\n",
      "\n",
      " 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                                       | 255/503 [10:35<10:13,  2.47s/it]\n",
      "\n",
      " 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                                       | 256/503 [10:37<10:11,  2.48s/it]\n",
      "\n",
      " 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                                       | 257/503 [10:40<10:08,  2.47s/it]\n",
      "\n",
      " 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                                       | 258/503 [10:42<10:06,  2.48s/it]\n",
      "\n",
      " 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                                      | 259/503 [10:45<10:06,  2.48s/it]\n",
      "\n",
      " 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž                                      | 260/503 [10:47<10:04,  2.49s/it]\n",
      "\n",
      " 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                                      | 261/503 [10:50<10:00,  2.48s/it]\n",
      "\n",
      " 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                                      | 262/503 [10:52<10:01,  2.50s/it]\n",
      "\n",
      " 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                                      | 263/503 [10:55<10:01,  2.51s/it]\n",
      "\n",
      " 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                                      | 264/503 [10:57<10:00,  2.51s/it]\n",
      "\n",
      " 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                                     | 265/503 [11:00<09:56,  2.50s/it]\n",
      "\n",
      " 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž                                     | 266/503 [11:02<09:52,  2.50s/it]\n",
      "\n",
      " 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                                     | 267/503 [11:05<09:48,  2.49s/it]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                                     | 268/503 [11:07<09:42,  2.48s/it]\n",
      "\n",
      " 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                                     | 269/503 [11:09<09:38,  2.47s/it]\n",
      "\n",
      " 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                                     | 270/503 [11:12<09:38,  2.48s/it]\n",
      "\n",
      " 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                                     | 271/503 [11:14<09:33,  2.47s/it]\n",
      "\n",
      " 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž                                    | 272/503 [11:17<09:32,  2.48s/it]\n",
      "\n",
      " 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                                    | 273/503 [11:19<09:33,  2.49s/it]\n",
      "\n",
      " 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                                    | 274/503 [11:22<09:28,  2.48s/it]\n",
      "\n",
      " 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                                    | 275/503 [11:24<09:24,  2.48s/it]\n",
      "\n",
      " 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                                    | 276/503 [11:27<09:23,  2.48s/it]\n",
      "\n",
      " 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                                    | 277/503 [11:29<09:16,  2.46s/it]\n",
      "\n",
      " 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                                   | 278/503 [11:32<09:12,  2.46s/it]\n",
      "\n",
      " 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž                                   | 279/503 [11:34<09:13,  2.47s/it]\n",
      "\n",
      " 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                                   | 280/503 [11:37<09:14,  2.49s/it]\n",
      "\n",
      " 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                                   | 281/503 [11:39<09:14,  2.50s/it]\n",
      "\n",
      " 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                                   | 282/503 [11:42<09:14,  2.51s/it]\n",
      "\n",
      " 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                                   | 283/503 [11:44<09:14,  2.52s/it]\n",
      "\n",
      " 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                                  | 284/503 [11:47<09:11,  2.52s/it]\n",
      "\n",
      " 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž                                  | 285/503 [11:49<09:07,  2.51s/it]\n",
      "\n",
      " 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                                  | 286/503 [11:52<09:05,  2.51s/it]\n",
      "\n",
      " 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                                  | 287/503 [11:54<09:00,  2.50s/it]\n",
      "\n",
      " 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                                  | 288/503 [11:57<09:00,  2.52s/it]\n",
      "\n",
      " 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                                  | 289/503 [11:59<09:00,  2.52s/it]\n",
      "\n",
      " 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                                  | 290/503 [12:02<08:52,  2.50s/it]\n",
      "\n",
      " 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž                                 | 291/503 [12:04<08:47,  2.49s/it]\n",
      "\n",
      " 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                                 | 292/503 [12:07<08:48,  2.51s/it]\n",
      "\n",
      " 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                                 | 293/503 [12:10<08:53,  2.54s/it]\n",
      "\n",
      " 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                                 | 294/503 [12:12<08:50,  2.54s/it]\n",
      "\n",
      " 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                                 | 295/503 [12:15<08:48,  2.54s/it]\n",
      "\n",
      " 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                                 | 296/503 [12:17<08:47,  2.55s/it]\n",
      "\n",
      " 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                                | 297/503 [12:20<08:46,  2.56s/it]\n",
      "\n",
      " 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                                | 298/503 [12:22<08:41,  2.54s/it]\n",
      "\n",
      " 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                                | 299/503 [12:25<08:37,  2.54s/it]\n",
      "\n",
      " 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                                | 300/503 [12:27<08:31,  2.52s/it]\n",
      "\n",
      " 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                                | 301/503 [12:30<08:27,  2.51s/it]\n",
      "\n",
      " 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                                | 302/503 [12:32<08:25,  2.52s/it]\n",
      "\n",
      " 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                               | 303/503 [12:35<08:22,  2.51s/it]\n",
      "\n",
      " 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž                               | 304/503 [12:37<08:17,  2.50s/it]\n",
      "\n",
      " 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                               | 305/503 [12:40<08:21,  2.53s/it]\n",
      "\n",
      " 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                               | 306/503 [12:42<08:18,  2.53s/it]\n",
      "\n",
      " 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                               | 307/503 [12:45<08:11,  2.51s/it]\n",
      "\n",
      " 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                               | 308/503 [12:47<08:06,  2.50s/it]\n",
      "\n",
      " 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                              | 309/503 [12:50<08:05,  2.50s/it]\n",
      "\n",
      " 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž                              | 310/503 [12:52<08:04,  2.51s/it]\n",
      "\n",
      " 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                              | 311/503 [12:55<08:04,  2.52s/it]\n",
      "\n",
      " 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                              | 312/503 [12:57<08:01,  2.52s/it]\n",
      "\n",
      " 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                              | 313/503 [13:00<07:55,  2.50s/it]\n",
      "\n",
      " 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                              | 314/503 [13:02<07:56,  2.52s/it]\n",
      "\n",
      " 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                              | 315/503 [13:05<07:56,  2.53s/it]\n",
      "\n",
      " 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž                             | 316/503 [13:08<07:50,  2.52s/it]\n",
      "\n",
      " 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                             | 317/503 [13:10<07:44,  2.50s/it]\n",
      "\n",
      " 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                             | 318/503 [13:12<07:41,  2.49s/it]\n",
      "\n",
      " 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                             | 319/503 [13:15<07:36,  2.48s/it]\n",
      "\n",
      " 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                             | 320/503 [13:17<07:32,  2.47s/it]\n",
      "\n",
      " 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                             | 321/503 [13:20<07:32,  2.49s/it]\n",
      "\n",
      " 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                            | 322/503 [13:22<07:29,  2.48s/it]\n",
      "\n",
      " 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž                            | 323/503 [13:25<07:27,  2.49s/it]\n",
      "\n",
      " 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                            | 324/503 [13:27<07:25,  2.49s/it]\n",
      "\n",
      " 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                            | 325/503 [13:30<07:21,  2.48s/it]\n",
      "\n",
      " 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                            | 326/503 [13:32<07:18,  2.48s/it]\n",
      "\n",
      " 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                            | 327/503 [13:35<07:14,  2.47s/it]\n",
      "\n",
      " 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                           | 328/503 [13:37<07:12,  2.47s/it]\n",
      "\n",
      " 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž                           | 329/503 [13:40<07:11,  2.48s/it]\n",
      "\n",
      " 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                           | 330/503 [13:42<07:13,  2.51s/it]\n",
      "\n",
      " 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                           | 331/503 [13:45<07:10,  2.51s/it]\n",
      "\n",
      " 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                           | 332/503 [13:47<07:06,  2.49s/it]\n",
      "\n",
      " 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                           | 333/503 [13:50<07:01,  2.48s/it]\n",
      "\n",
      " 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                           | 334/503 [13:52<07:01,  2.49s/it]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž                          | 335/503 [13:55<06:58,  2.49s/it]\n",
      "\n",
      " 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                          | 336/503 [13:57<06:57,  2.50s/it]\n",
      "\n",
      " 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                          | 337/503 [14:00<06:55,  2.50s/it]\n",
      "\n",
      " 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                          | 338/503 [14:02<06:53,  2.51s/it]\n",
      "\n",
      " 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                          | 339/503 [14:05<06:50,  2.50s/it]\n",
      "\n",
      " 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                          | 340/503 [14:07<06:45,  2.49s/it]\n",
      "\n",
      " 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                         | 341/503 [14:10<06:46,  2.51s/it]\n",
      "\n",
      " 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                         | 342/503 [14:12<06:44,  2.51s/it]\n",
      "\n",
      " 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                         | 343/503 [14:15<06:40,  2.50s/it]\n",
      "\n",
      " 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                         | 344/503 [14:17<06:36,  2.49s/it]\n",
      "\n",
      " 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                         | 345/503 [14:20<06:36,  2.51s/it]\n",
      "\n",
      " 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                         | 346/503 [14:22<06:34,  2.51s/it]\n",
      "\n",
      " 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                        | 347/503 [14:25<06:29,  2.49s/it]\n",
      "\n",
      " 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž                        | 348/503 [14:27<06:25,  2.49s/it]\n",
      "\n",
      " 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                        | 349/503 [14:30<06:23,  2.49s/it]\n",
      "\n",
      " 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                        | 350/503 [14:32<06:20,  2.49s/it]\n",
      "\n",
      " 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                        | 351/503 [14:35<06:19,  2.49s/it]\n",
      "\n",
      " 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                        | 352/503 [14:37<06:17,  2.50s/it]\n",
      "\n",
      " 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                       | 353/503 [14:40<06:12,  2.49s/it]\n",
      "\n",
      " 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž                       | 354/503 [14:42<06:07,  2.47s/it]\n",
      "\n",
      " 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                       | 355/503 [14:45<06:04,  2.46s/it]\n",
      "\n",
      " 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                       | 356/503 [14:47<06:05,  2.48s/it]\n",
      "\n",
      " 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                       | 357/503 [14:50<06:05,  2.50s/it]\n",
      "\n",
      " 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                       | 358/503 [14:52<06:03,  2.51s/it]\n",
      "\n",
      " 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                       | 359/503 [14:55<06:00,  2.50s/it]\n",
      "\n",
      " 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž                      | 360/503 [14:57<05:58,  2.51s/it]\n",
      "\n",
      " 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                      | 361/503 [15:00<05:54,  2.50s/it]\n",
      "\n",
      " 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                      | 362/503 [15:02<05:50,  2.49s/it]\n",
      "\n",
      " 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                      | 363/503 [15:05<05:49,  2.50s/it]\n",
      "\n",
      " 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                      | 364/503 [15:07<05:48,  2.50s/it]\n",
      "\n",
      " 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                      | 365/503 [15:10<05:48,  2.52s/it]\n",
      "\n",
      " 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                     | 366/503 [15:12<05:43,  2.51s/it]\n",
      "\n",
      " 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž                     | 367/503 [15:15<05:41,  2.51s/it]\n",
      "\n",
      " 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                     | 368/503 [15:17<05:39,  2.51s/it]\n",
      "\n",
      " 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                     | 369/503 [15:20<05:37,  2.52s/it]\n",
      "\n",
      " 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                     | 370/503 [15:22<05:32,  2.50s/it]\n",
      "\n",
      " 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                     | 371/503 [15:25<05:29,  2.49s/it]\n",
      "\n",
      " 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                    | 372/503 [15:27<05:26,  2.49s/it]\n",
      "\n",
      " 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž                    | 373/503 [15:30<05:23,  2.49s/it]\n",
      "\n",
      " 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                    | 374/503 [15:32<05:20,  2.48s/it]\n",
      "\n",
      " 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                    | 375/503 [15:35<05:17,  2.48s/it]\n",
      "\n",
      " 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                    | 376/503 [15:37<05:14,  2.48s/it]\n",
      "\n",
      " 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                    | 377/503 [15:40<05:15,  2.50s/it]\n",
      "\n",
      " 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                    | 378/503 [15:42<05:14,  2.51s/it]\n",
      "\n",
      " 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž                   | 379/503 [15:45<05:11,  2.51s/it]\n",
      "\n",
      " 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                   | 380/503 [15:47<05:10,  2.53s/it]\n",
      "\n",
      " 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                   | 381/503 [15:50<05:06,  2.51s/it]\n",
      "\n",
      " 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                   | 382/503 [15:52<05:01,  2.49s/it]\n",
      "\n",
      " 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                   | 383/503 [15:55<04:56,  2.47s/it]\n",
      "\n",
      " 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                   | 384/503 [15:57<04:52,  2.46s/it]\n",
      "\n",
      " 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                  | 385/503 [15:59<04:48,  2.45s/it]\n",
      "\n",
      " 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                  | 386/503 [16:02<04:45,  2.44s/it]\n",
      "\n",
      " 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                  | 387/503 [16:04<04:42,  2.43s/it]\n",
      "\n",
      " 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                  | 388/503 [16:07<04:39,  2.43s/it]\n",
      "\n",
      " 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                  | 389/503 [16:09<04:36,  2.43s/it]\n",
      "\n",
      " 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                  | 390/503 [16:11<04:33,  2.42s/it]\n",
      "\n",
      " 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                 | 391/503 [16:14<04:31,  2.43s/it]\n",
      "\n",
      " 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž                 | 392/503 [16:16<04:29,  2.42s/it]\n",
      "\n",
      " 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                 | 393/503 [16:19<04:27,  2.43s/it]\n",
      "\n",
      " 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                 | 394/503 [16:21<04:25,  2.43s/it]\n",
      "\n",
      " 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                 | 395/503 [16:24<04:23,  2.44s/it]\n",
      "\n",
      " 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                 | 396/503 [16:26<04:21,  2.44s/it]\n",
      "\n",
      " 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                | 397/503 [16:29<04:18,  2.44s/it]\n",
      "\n",
      " 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž                | 398/503 [16:31<04:15,  2.43s/it]\n",
      "\n",
      " 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                | 399/503 [16:33<04:13,  2.44s/it]\n",
      "\n",
      " 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                | 400/503 [16:36<04:10,  2.43s/it]\n",
      "\n",
      " 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                | 401/503 [16:38<04:07,  2.43s/it]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                | 402/503 [16:41<04:05,  2.43s/it]\n",
      "\n",
      " 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                | 403/503 [16:43<04:02,  2.43s/it]\n",
      "\n",
      " 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž               | 404/503 [16:46<04:01,  2.44s/it]\n",
      "\n",
      " 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–               | 405/503 [16:48<03:59,  2.44s/it]\n",
      "\n",
      " 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ               | 406/503 [16:50<03:57,  2.45s/it]\n",
      "\n",
      " 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹               | 407/503 [16:53<03:55,  2.45s/it]\n",
      "\n",
      " 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰               | 408/503 [16:55<03:52,  2.44s/it]\n",
      "\n",
      " 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ               | 409/503 [16:58<03:50,  2.45s/it]\n",
      "\n",
      " 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–              | 410/503 [17:00<03:47,  2.44s/it]\n",
      "\n",
      " 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž              | 411/503 [17:03<03:43,  2.43s/it]\n",
      "\n",
      " 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ              | 412/503 [17:05<03:41,  2.43s/it]\n",
      "\n",
      " 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹              | 413/503 [17:08<03:39,  2.43s/it]\n",
      "\n",
      " 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š              | 414/503 [17:10<03:36,  2.44s/it]\n",
      "\n",
      " 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ              | 415/503 [17:12<03:34,  2.43s/it]\n",
      "\n",
      " 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–             | 416/503 [17:15<03:32,  2.44s/it]\n",
      "\n",
      " 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž             | 417/503 [17:17<03:29,  2.44s/it]\n",
      "\n",
      " 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–             | 418/503 [17:20<03:28,  2.45s/it]\n",
      "\n",
      " 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹             | 419/503 [17:22<03:25,  2.45s/it]\n",
      "\n",
      " 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š             | 420/503 [17:25<03:23,  2.46s/it]\n",
      "\n",
      " 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰             | 421/503 [17:27<03:20,  2.45s/it]\n",
      "\n",
      " 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ             | 422/503 [17:30<03:17,  2.44s/it]\n",
      "\n",
      " 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž            | 423/503 [17:32<03:17,  2.47s/it]\n",
      "\n",
      " 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–            | 424/503 [17:35<03:14,  2.47s/it]\n",
      "\n",
      " 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ            | 425/503 [17:37<03:12,  2.47s/it]\n",
      "\n",
      " 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š            | 426/503 [17:39<03:09,  2.46s/it]\n",
      "\n",
      " 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰            | 427/503 [17:42<03:06,  2.46s/it]\n",
      "\n",
      " 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ            | 428/503 [17:44<03:03,  2.45s/it]\n",
      "\n",
      " 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–           | 429/503 [17:47<03:00,  2.44s/it]\n",
      "\n",
      " 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–           | 430/503 [17:49<02:58,  2.44s/it]\n",
      "\n",
      " 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ           | 431/503 [17:52<02:55,  2.44s/it]\n",
      "\n",
      " 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹           | 432/503 [17:54<02:53,  2.44s/it]\n",
      "\n",
      " 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š           | 433/503 [17:57<02:50,  2.44s/it]\n",
      "\n",
      " 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ           | 434/503 [17:59<02:48,  2.44s/it]\n",
      "\n",
      " 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–          | 435/503 [18:01<02:45,  2.43s/it]\n",
      "\n",
      " 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž          | 436/503 [18:04<02:44,  2.45s/it]\n",
      "\n",
      " 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ          | 437/503 [18:06<02:43,  2.48s/it]\n",
      "\n",
      " 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹          | 438/503 [18:09<02:41,  2.48s/it]\n",
      "\n",
      " 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š          | 439/503 [18:11<02:38,  2.47s/it]\n",
      "\n",
      " 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰          | 440/503 [18:14<02:35,  2.47s/it]\n",
      "\n",
      " 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–         | 441/503 [18:16<02:33,  2.48s/it]\n",
      "\n",
      " 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž         | 442/503 [18:19<02:31,  2.49s/it]\n",
      "\n",
      " 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–         | 443/503 [18:21<02:28,  2.48s/it]\n",
      "\n",
      " 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ         | 444/503 [18:24<02:26,  2.48s/it]\n",
      "\n",
      " 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š         | 445/503 [18:26<02:23,  2.47s/it]\n",
      "\n",
      " 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰         | 446/503 [18:29<02:20,  2.47s/it]\n",
      "\n",
      " 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ         | 447/503 [18:31<02:18,  2.47s/it]\n",
      "\n",
      " 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž        | 448/503 [18:34<02:14,  2.45s/it]\n",
      "\n",
      " 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–        | 449/503 [18:36<02:12,  2.45s/it]\n",
      "\n",
      " 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ        | 450/503 [18:38<02:09,  2.44s/it]\n",
      "\n",
      " 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹        | 451/503 [18:41<02:07,  2.45s/it]\n",
      "\n",
      " 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰        | 452/503 [18:43<02:04,  2.44s/it]\n",
      "\n",
      " 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ        | 453/503 [18:46<02:03,  2.46s/it]\n",
      "\n",
      " 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–       | 454/503 [18:48<02:02,  2.49s/it]\n",
      "\n",
      " 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž       | 455/503 [18:51<02:00,  2.50s/it]\n",
      "\n",
      " 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ       | 456/503 [18:53<01:58,  2.52s/it]\n",
      "\n",
      " 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹       | 457/503 [18:56<01:54,  2.49s/it]\n",
      "\n",
      " 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š       | 458/503 [18:58<01:51,  2.47s/it]\n",
      "\n",
      " 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ       | 459/503 [19:01<01:48,  2.46s/it]\n",
      "\n",
      " 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–      | 460/503 [19:03<01:45,  2.46s/it]\n",
      "\n",
      " 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž      | 461/503 [19:06<01:43,  2.46s/it]\n",
      "\n",
      " 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–      | 462/503 [19:08<01:40,  2.46s/it]\n",
      "\n",
      " 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹      | 463/503 [19:11<01:38,  2.46s/it]\n",
      "\n",
      " 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š      | 464/503 [19:13<01:35,  2.45s/it]\n",
      "\n",
      " 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰      | 465/503 [19:15<01:32,  2.45s/it]\n",
      "\n",
      " 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ      | 466/503 [19:18<01:31,  2.47s/it]\n",
      "\n",
      " 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 467/503 [19:20<01:28,  2.47s/it]\n",
      "\n",
      " 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–     | 468/503 [19:23<01:26,  2.47s/it]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 469/503 [19:25<01:23,  2.46s/it]\n",
      "\n",
      " 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 470/503 [19:28<01:21,  2.47s/it]\n",
      "\n",
      " 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 471/503 [19:30<01:18,  2.47s/it]\n",
      "\n",
      " 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 472/503 [19:33<01:16,  2.46s/it]\n",
      "\n",
      " 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 473/503 [19:35<01:13,  2.45s/it]\n",
      "\n",
      " 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 474/503 [19:38<01:10,  2.44s/it]\n",
      "\n",
      " 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 475/503 [19:40<01:08,  2.43s/it]\n",
      "\n",
      " 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 476/503 [19:43<01:06,  2.46s/it]\n",
      "\n",
      " 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 477/503 [19:45<01:04,  2.47s/it]\n",
      "\n",
      " 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 478/503 [19:47<01:01,  2.46s/it]\n",
      "\n",
      " 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 479/503 [19:50<00:58,  2.45s/it]\n",
      "\n",
      " 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 480/503 [19:52<00:56,  2.45s/it]\n",
      "\n",
      " 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 481/503 [19:55<00:53,  2.44s/it]\n",
      "\n",
      " 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 482/503 [19:57<00:51,  2.44s/it]\n",
      "\n",
      " 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 483/503 [20:00<00:48,  2.43s/it]\n",
      "\n",
      " 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 484/503 [20:02<00:46,  2.43s/it]\n",
      "\n",
      " 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 485/503 [20:05<00:43,  2.44s/it]\n",
      "\n",
      " 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 486/503 [20:07<00:41,  2.44s/it]\n",
      "\n",
      " 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 487/503 [20:09<00:38,  2.44s/it]\n",
      "\n",
      " 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 488/503 [20:12<00:36,  2.44s/it]\n",
      "\n",
      " 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 489/503 [20:14<00:34,  2.44s/it]\n",
      "\n",
      " 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 490/503 [20:17<00:31,  2.46s/it]\n",
      "\n",
      " 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 491/503 [20:19<00:29,  2.49s/it]\n",
      "\n",
      " 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 492/503 [20:22<00:27,  2.48s/it]\n",
      "\n",
      " 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 493/503 [20:24<00:24,  2.47s/it]\n",
      "\n",
      " 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 494/503 [20:27<00:22,  2.46s/it]\n",
      "\n",
      " 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 495/503 [20:29<00:19,  2.45s/it]\n",
      "\n",
      " 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 496/503 [20:32<00:17,  2.44s/it]\n",
      "\n",
      " 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 497/503 [20:34<00:14,  2.43s/it]\n",
      "\n",
      " 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 498/503 [20:36<00:12,  2.43s/it]\n",
      "\n",
      " 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 499/503 [20:39<00:09,  2.43s/it]\n",
      "\n",
      " 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 500/503 [20:41<00:07,  2.43s/it]\n",
      "\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 501/503 [20:44<00:04,  2.43s/it]\n",
      "\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 502/503 [20:46<00:02,  2.44s/it]\n",
      "\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 503/503 [20:49<00:00,  2.48s/it]\n"
     ]
    }
   ],
   "source": [
    "N=25\n",
    "acc3=[]\n",
    "for i in tqdm(range(503)):\n",
    "    dummy=np.zeros((1,N*13))\n",
    "    datadictstatslin = {'TEST':dummy}\n",
    "    labeldictstatslin = {'TEST':[]}\n",
    "    for _ in range(503) :\n",
    "            idx = randint(0, 502)\n",
    "            path = sdr_df[sdr_df['split']=='TEST']['file'].iloc[idx]\n",
    "            label = sdr_df[sdr_df['split']=='TEST']['label'].iloc[idx]\n",
    "            x, sr = librosa.load(path, sr=SAMPLING_RATE)\n",
    "            melspectrogram = extract_melspectrogram(x, sr, num_mels=13)\n",
    "            data=downsample_spectrogram(melspectrogram, N)\n",
    "            datadictstatslin['TEST']=np.concatenate((datadictstatslin['TEST'],data),axis=0)\n",
    "            labeldictstatslin['TEST'].append(label)\n",
    "\n",
    "    test_data = datadictstatslin['TEST'][1:]\n",
    "    test_y = labeldictstatslin['TEST']\n",
    "    Xtest = PPD.transform(test_data)\n",
    "    acc3.append(accuracy_score(test_y, model1.predict(Xtest)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 615,
   "id": "f021b0f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_mean_acc=np.array(acc).mean()\n",
    "cnn_std_acc=np.array(acc).std()\n",
    "\n",
    "gru_mean_acc = np.array(acc2).mean()\n",
    "gru_std_acc = np.array(acc2).std()\n",
    "\n",
    "linear_mean_acc = np.array(acc3).mean()\n",
    "linear_std_acc =np.array(acc3).std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 616,
   "id": "78215c5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7041567398113\n",
      "0.021007194370289205\n",
      "0.5268784674925074\n",
      "0.007567391184445204\n",
      "0.4014679319707995\n",
      "0.022001346912426594\n"
     ]
    }
   ],
   "source": [
    "print(cnn_mean_acc)\n",
    "print(cnn_std_acc)\n",
    "print(gru_mean_acc)\n",
    "print(gru_std_acc)\n",
    "print(linear_mean_acc)\n",
    "print(linear_std_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6ed933e",
   "metadata": {},
   "source": [
    "### CNN vs Linear model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 617,
   "id": "ca7d963c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the value is p-value: 0.000000000000000\n",
      "\n",
      "The difference between the mean accuracy of the CNN and linear regression models is statistically significant.\n"
     ]
    }
   ],
   "source": [
    "#Difference in mean accuracy between the CNN and linear model\n",
    "mean_diff1 = cnn_mean_acc - linear_mean_acc\n",
    "\n",
    "# Concatenate the accuracy values for both models\n",
    "combined_acc1 = np.concatenate((np.random.normal(cnn_mean_acc, cnn_std_acc, size=503), \n",
    "                               np.random.normal(linear_mean_acc, linear_std_acc, size=503)))\n",
    "\n",
    "n_bootstrap1 = 503\n",
    "bootstrap_diff1 = np.zeros(n_bootstrap1)\n",
    "for i in range(n_bootstrap1):\n",
    "    resampled_acc1 = np.random.choice(combined_acc1, size=len(combined_acc1), replace=True)\n",
    "    cnn_mean = np.mean(resampled_acc1[:503])\n",
    "    linear_mean1 = np.mean(resampled_acc1[503:])\n",
    "    bootstrap_diff1[i] = cnn_mean - linear_mean1\n",
    "\n",
    "# Calculate the p-value\n",
    "p_value1 = np.mean(bootstrap_diff1 >= mean_diff1)\n",
    "\n",
    "print(\"the value is p-value: {:.15f}\".format(p_value1))\n",
    "if p_value1 < 0.05:\n",
    "    print(\"\\nThe difference between the mean accuracy of the CNN and linear regression models is statistically significant.\")\n",
    "else:\n",
    "    print(\"\\nThe difference between the mean accuracy of the CNN and linear regression models is statistically insignificant.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c975e144",
   "metadata": {},
   "source": [
    "### GRU vs Linear model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 618,
   "id": "fff567bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the value is p-value: 0.00000\n",
      "\n",
      "The difference between the mean accuracy of the GRU and linear regression models is statistically significant.\n"
     ]
    }
   ],
   "source": [
    "#Difference in mean accuracy between the GRU and linear model\n",
    "mean_diff2 = gru_mean_acc - linear_mean_acc\n",
    "\n",
    "# Concatenate the accuracy values for both models\n",
    "combined_acc2 = np.concatenate((np.random.normal(gru_mean_acc, gru_std_acc, size=503), \n",
    "                               np.random.normal(linear_mean_acc, linear_std_acc, size=503)))\n",
    "\n",
    "n_bootstrap2 = 503\n",
    "bootstrap_diff2 = np.zeros(n_bootstrap2)\n",
    "for i in range(n_bootstrap2):\n",
    "    resampled_acc2 = np.random.choice(combined_acc2, size=len(combined_acc2), replace=True)\n",
    "    gru_mean = np.mean(resampled_acc2[:503])\n",
    "    linear_mean2 = np.mean(resampled_acc2[503:])\n",
    "    bootstrap_diff2[i] = gru_mean - linear_mean2\n",
    "\n",
    "# Calculate the p-value\n",
    "p_value2 = np.mean(bootstrap_diff2 >= mean_diff2)\n",
    "\n",
    "print(\"the value is p-value: {:.5f}\".format(p_value2))\n",
    "if p_value2 < 0.05:\n",
    "    print(\"\\nThe difference between the mean accuracy of the GRU and linear regression models is statistically significant.\")\n",
    "else:\n",
    "    print(\"\\nThe difference between the mean accuracy of the GRU and linear regression models is statistically insignificant.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 619,
   "id": "25e24ef9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the value is p-value: 0.00000\n",
      "\n",
      "The difference between the mean accuracy of the GRU and linear regression models is statistically insignificant.\n"
     ]
    }
   ],
   "source": [
    "#Difference in mean accuracy between the GRU and linear model\n",
    "mean_diff3 = gru_mean_acc - cnn_mean_acc\n",
    "\n",
    "# Concatenate the accuracy values for both models\n",
    "combined_acc3 = np.concatenate((np.random.normal(gru_mean_acc, gru_std_acc, size=503), \n",
    "                               np.random.normal(cnn_mean_acc, cnn_std_acc, size=503)))\n",
    "\n",
    "n_bootstrap3 = 503\n",
    "bootstrap_diff3 = np.zeros(n_bootstrap3)\n",
    "for i in range(n_bootstrap3):\n",
    "    resampled_acc3 = np.random.choice(combined_acc3, size=len(combined_acc3), replace=True)\n",
    "    gru_mean = np.mean(resampled_acc3[:503])\n",
    "    cnn_mean2 = np.mean(resampled_acc3[503:])\n",
    "    bootstrap_diff3[i] = gru_mean - cnn_mean2\n",
    "\n",
    "# Calculate the p-value\n",
    "p_value3 = np.mean(bootstrap_diff3 >= mean_diff3)\n",
    "\n",
    "print(\"the value is p-value: {:.5f}\".format(p_value2))\n",
    "if p_value3 < 0.05:\n",
    "    print(\"\\nThe difference between the mean accuracy of the GRU and linear regression models is statistically significant.\")\n",
    "else:\n",
    "    print(\"\\nThe difference between the mean accuracy of the GRU and linear regression models is statistically insignificant.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16296976",
   "metadata": {
    "id": "8f95e312"
   },
   "source": [
    "## Task III (Open Ended)\n",
    "1. Consider the case where we have speech data from a single speaker (e.g., george). Train your models on this subset of the data. What do you observe? How does this affect the model performance? \n",
    "\n",
    "2. Even though a model is trained on a single speaker, we would like the model to generalizes to any speaker. To this end, one can use data augmentation techniques to artificially create more samples for each class. Some of these augmentations can be applied on the spectrogram (e.g., SpecAugment https://ai.googleblog.com/2019/04/specaugment-new-data-augmentation.html), and other can be applied on the raw waveform before creating the spectrogram such as pitch manipulation (https://github.com/facebookresearch/WavAugment). Explore the effect of one type of augmentation from each type. Report your observation and anaylze the confusion matrices.\n",
    "\n",
    "3. Data augmentation techniques create different \"views\" of each training sample in a stochastic or determinstic approach. One can leaverage speech data augmentation to create views for training a neural network in a contrastive learning setting with margin-based objective function (for more info, read http://proceedings.mlr.press/v130/al-tahan21a/al-tahan21a.pdf). Implement at least one model using a contrastive loss based on different views of the training samples. Does this model improve over the model without contrastive learning? Report and discuss your observations. \n",
    "\n",
    "For more information on the contrastive learning framework, you can refer to this paper\n",
    "https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9226466"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caee8fde",
   "metadata": {},
   "source": [
    "## 3. Contrastive learning [7,8]\n",
    "\n",
    "For this task we have trained an initial model based on the Siamese Network[9]. To do this we took the CNN model took earlier and added few fully connected layers to it so that it produces an embedding of 128 dimensions for each input audio sample. further fully connected layes are applied to this output which will predict the class of the input audio signal. The loss is a combination of the contrastive loss that is obtained by comparing the embeddings of two sample pairs(positive and negative) and the cross entropy loss obtained by the predicted class by the model for each sample.\n",
    "Once this training is done we then extract the trained CNN layers of the model and use for the downsampling task. For that two  fully connected layers with 350 and 10 nodes respectively are used. 10 nodes for each class is added to the extracted CNN layers and the new model is then trained on the downsampling task dataset (same as the dataset used to train the CNN based architecture in Task 2) for 100 epochs. We tried freezing the CNN layers but it didnot gave good results hence we ended up fining tuning the entire trained model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 533,
   "id": "585b99e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import randint\n",
    "class ContrastiveLoss(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    Source: https://gist.github.com/dimartinot/80abaabaea9a6ef3d9ab0ab199927ee4#file-contrastive_loss-py\n",
    "    TODO: rewrite\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, margin=2.0):\n",
    "        super(ContrastiveLoss, self).__init__()\n",
    "        self.margin = margin\n",
    "\n",
    "    def forward(self, dist, label):\n",
    "\n",
    "        loss = torch.mean(1/2*(label) * torch.pow(dist, 2) +\n",
    "                                      1/2*(1-label) * torch.pow(torch.clamp(self.margin - dist, min=0.0), 2))\n",
    "\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 534,
   "id": "25a81ed0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class customSiameseDataset(Dataset):\n",
    "    def __init__(self, datalistx1,datalistx2, labelsx1,labelsx2,labelsx1x2):\n",
    "        self.labelsx1 = labelsx1\n",
    "        self.labelsx2 = labelsx2\n",
    "        self.labelsx1x2 = labelsx1x2\n",
    "        self.datalistx1 = datalistx1 \n",
    "        self.datalistx2 = datalistx2\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.datalistx1.shape[0]\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        labelsx1 = self.labelsx1[idx]\n",
    "        labelsx2 = self.labelsx2[idx]\n",
    "        labelsx1x2 = self.labelsx1x2[idx]\n",
    "        datax1 = self.datalistx1[idx]\n",
    "        datax2 = self.datalistx2[idx]\n",
    "        return datax1,datax2,labelsx1,labelsx2,labelsx1x2\n",
    "\n",
    "\n",
    "class customSiameseDataLoader(DataLoader):\n",
    "    def __init__(self, customdata, batch_size, collate_fn=None):\n",
    "        self.customdata = customdata\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "    def loader(self):\n",
    "        return DataLoader(self.customdata, self.batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46874bc0",
   "metadata": {},
   "source": [
    "#### Creating the audio pairs\n",
    "The below script is to create the sample pairs. The postive pairs are prepared by adding noise to the input audio and the negative pairs are created by taking another sample and adding noise to it. The noise is added to the new sample so that there is no correlation between the different samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 466,
   "id": "93c02dd5",
   "metadata": {
    "executionInfo": {
     "elapsed": 26,
     "status": "aborted",
     "timestamp": 1674212543223,
     "user": {
      "displayName": "Hyoseung Kang",
      "userId": "00233629824676120159"
     },
     "user_tz": -60
    },
    "id": "6aab3876"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "0it [00:00, ?it/s]\n",
      "\n",
      "21it [00:00, 202.46it/s]\n",
      "\n",
      "38it [00:00, 187.24it/s]\n",
      "\n",
      "52it [00:00, 164.80it/s]\n",
      "\n",
      "63it [00:00, 139.18it/s]\n",
      "\n",
      "75it [00:00, 129.91it/s]\n",
      "\n",
      "86it [00:00, 116.31it/s]\n",
      "\n",
      "97it [00:00, 106.17it/s]\n",
      "\n",
      "107it [00:00, 102.41it/s]\n",
      "\n",
      "117it [00:00, 96.75it/s] \n",
      "\n",
      "127it [00:01, 87.53it/s]\n",
      "\n",
      "136it [00:01, 78.84it/s]\n",
      "\n",
      "145it [00:01, 70.76it/s]\n",
      "\n",
      "153it [00:01, 68.65it/s]\n",
      "\n",
      "161it [00:01, 68.98it/s]\n",
      "\n",
      "169it [00:01, 61.84it/s]\n",
      "\n",
      "176it [00:01, 60.48it/s]\n",
      "\n",
      "183it [00:02, 56.00it/s]\n",
      "\n",
      "189it [00:02, 56.54it/s]\n",
      "\n",
      "195it [00:02, 57.25it/s]\n",
      "\n",
      "201it [00:02, 54.47it/s]\n",
      "\n",
      "207it [00:02, 54.09it/s]\n",
      "\n",
      "213it [00:02, 49.95it/s]\n",
      "\n",
      "219it [00:02, 49.75it/s]\n",
      "\n",
      "226it [00:02, 54.39it/s]\n",
      "\n",
      "232it [00:03, 54.18it/s]\n",
      "\n",
      "238it [00:03, 54.34it/s]\n",
      "\n",
      "244it [00:03, 52.18it/s]\n",
      "\n",
      "250it [00:03, 47.74it/s]\n",
      "\n",
      "255it [00:03, 47.88it/s]\n",
      "\n",
      "260it [00:03, 42.81it/s]\n",
      "\n",
      "265it [00:03, 37.96it/s]\n",
      "\n",
      "270it [00:03, 37.88it/s]\n",
      "\n",
      "274it [00:04, 37.03it/s]\n",
      "\n",
      "279it [00:04, 38.60it/s]\n",
      "\n",
      "283it [00:04, 38.48it/s]\n",
      "\n",
      "287it [00:04, 37.74it/s]\n",
      "\n",
      "292it [00:04, 40.37it/s]\n",
      "\n",
      "298it [00:04, 41.89it/s]\n",
      "\n",
      "303it [00:04, 38.84it/s]\n",
      "\n",
      "307it [00:04, 38.76it/s]\n",
      "\n",
      "311it [00:05, 35.99it/s]\n",
      "\n",
      "315it [00:05, 35.00it/s]\n",
      "\n",
      "319it [00:05, 34.69it/s]\n",
      "\n",
      "324it [00:05, 35.46it/s]\n",
      "\n",
      "328it [00:05, 33.18it/s]\n",
      "\n",
      "332it [00:05, 33.76it/s]\n",
      "\n",
      "336it [00:05, 33.32it/s]\n",
      "\n",
      "340it [00:05, 30.96it/s]\n",
      "\n",
      "344it [00:06, 29.49it/s]\n",
      "\n",
      "348it [00:06, 31.81it/s]\n",
      "\n",
      "352it [00:06, 31.44it/s]\n",
      "\n",
      "356it [00:06, 30.97it/s]\n",
      "\n",
      "362it [00:06, 34.44it/s]\n",
      "\n",
      "366it [00:06, 31.11it/s]\n",
      "\n",
      "370it [00:06, 30.26it/s]\n",
      "\n",
      "374it [00:06, 32.35it/s]\n",
      "\n",
      "378it [00:07, 31.29it/s]\n",
      "\n",
      "382it [00:07, 30.94it/s]\n",
      "\n",
      "386it [00:07, 29.35it/s]\n",
      "\n",
      "390it [00:07, 30.33it/s]\n",
      "\n",
      "394it [00:07, 31.19it/s]\n",
      "\n",
      "398it [00:07, 28.87it/s]\n",
      "\n",
      "402it [00:07, 29.44it/s]\n",
      "\n",
      "406it [00:08, 30.53it/s]\n",
      "\n",
      "410it [00:08, 28.06it/s]\n",
      "\n",
      "413it [00:08, 26.31it/s]\n",
      "\n",
      "416it [00:08, 27.11it/s]\n",
      "\n",
      "419it [00:08, 25.14it/s]\n",
      "\n",
      "422it [00:08, 26.10it/s]\n",
      "\n",
      "425it [00:08, 24.58it/s]\n",
      "\n",
      "428it [00:08, 25.87it/s]\n",
      "\n",
      "434it [00:09, 30.31it/s]\n",
      "\n",
      "438it [00:09, 28.58it/s]\n",
      "\n",
      "442it [00:09, 29.81it/s]\n",
      "\n",
      "446it [00:09, 28.57it/s]\n",
      "\n",
      "450it [00:09, 25.83it/s]\n",
      "\n",
      "453it [00:09, 24.06it/s]\n",
      "\n",
      "456it [00:09, 22.75it/s]\n",
      "\n",
      "459it [00:10, 22.31it/s]\n",
      "\n",
      "462it [00:10, 21.44it/s]\n",
      "\n",
      "465it [00:10, 22.51it/s]\n",
      "\n",
      "468it [00:10, 22.96it/s]\n",
      "\n",
      "472it [00:10, 26.08it/s]\n",
      "\n",
      "475it [00:10, 25.70it/s]\n",
      "\n",
      "480it [00:10, 29.83it/s]\n",
      "\n",
      "484it [00:11, 27.25it/s]\n",
      "\n",
      "488it [00:11, 26.29it/s]\n",
      "\n",
      "491it [00:11, 26.05it/s]\n",
      "\n",
      "494it [00:11, 23.51it/s]\n",
      "\n",
      "497it [00:11, 23.96it/s]\n",
      "\n",
      "500it [00:11, 23.93it/s]\n",
      "\n",
      "503it [00:11, 25.43it/s]\n",
      "\n",
      "506it [00:11, 22.84it/s]\n",
      "\n",
      "509it [00:12, 23.03it/s]\n",
      "\n",
      "512it [00:12, 23.28it/s]\n",
      "\n",
      "515it [00:12, 23.35it/s]\n",
      "\n",
      "518it [00:12, 23.28it/s]\n",
      "\n",
      "521it [00:12, 23.03it/s]\n",
      "\n",
      "525it [00:12, 26.19it/s]\n",
      "\n",
      "529it [00:12, 26.62it/s]\n",
      "\n",
      "532it [00:13, 23.12it/s]\n",
      "\n",
      "535it [00:13, 20.99it/s]\n",
      "\n",
      "538it [00:13, 21.83it/s]\n",
      "\n",
      "541it [00:13, 21.96it/s]\n",
      "\n",
      "544it [00:13, 22.16it/s]\n",
      "\n",
      "547it [00:13, 20.39it/s]\n",
      "\n",
      "551it [00:13, 23.54it/s]\n",
      "\n",
      "554it [00:14, 21.32it/s]\n",
      "\n",
      "558it [00:14, 22.36it/s]\n",
      "\n",
      "561it [00:14, 22.54it/s]\n",
      "\n",
      "566it [00:14, 25.87it/s]\n",
      "\n",
      "569it [00:14, 24.50it/s]\n",
      "\n",
      "572it [00:14, 23.79it/s]\n",
      "\n",
      "575it [00:14, 21.06it/s]\n",
      "\n",
      "578it [00:15, 21.14it/s]\n",
      "\n",
      "581it [00:15, 20.80it/s]\n",
      "\n",
      "585it [00:15, 23.71it/s]\n",
      "\n",
      "588it [00:15, 20.72it/s]\n",
      "\n",
      "591it [00:15, 20.81it/s]\n",
      "\n",
      "595it [00:15, 23.59it/s]\n",
      "\n",
      "598it [00:15, 22.81it/s]\n",
      "\n",
      "601it [00:16, 22.00it/s]\n",
      "\n",
      "604it [00:16, 21.38it/s]\n",
      "\n",
      "607it [00:16, 21.14it/s]\n",
      "\n",
      "610it [00:16, 20.89it/s]\n",
      "\n",
      "614it [00:16, 23.25it/s]\n",
      "\n",
      "617it [00:16, 24.64it/s]\n",
      "\n",
      "620it [00:16, 25.46it/s]\n",
      "\n",
      "623it [00:17, 21.12it/s]\n",
      "\n",
      "626it [00:17, 19.24it/s]\n",
      "\n",
      "630it [00:17, 21.68it/s]\n",
      "\n",
      "633it [00:17, 23.33it/s]\n",
      "\n",
      "636it [00:17, 24.65it/s]\n",
      "\n",
      "639it [00:17, 20.47it/s]\n",
      "\n",
      "642it [00:17, 18.57it/s]\n",
      "\n",
      "645it [00:18, 18.40it/s]\n",
      "\n",
      "647it [00:18, 17.31it/s]\n",
      "\n",
      "650it [00:18, 17.15it/s]\n",
      "\n",
      "652it [00:18, 15.92it/s]\n",
      "\n",
      "654it [00:18, 15.09it/s]\n",
      "\n",
      "656it [00:18, 16.19it/s]\n",
      "\n",
      "658it [00:18, 15.69it/s]\n",
      "\n",
      "660it [00:19, 15.15it/s]\n",
      "\n",
      "662it [00:19, 15.62it/s]\n",
      "\n",
      "664it [00:19, 15.24it/s]\n",
      "\n",
      "667it [00:19, 17.64it/s]\n",
      "\n",
      "669it [00:19, 15.94it/s]\n",
      "\n",
      "671it [00:19, 14.94it/s]\n",
      "\n",
      "674it [00:19, 15.89it/s]\n",
      "\n",
      "676it [00:20, 16.74it/s]\n",
      "\n",
      "678it [00:20, 17.52it/s]\n",
      "\n",
      "680it [00:20, 16.50it/s]\n",
      "\n",
      "683it [00:20, 18.45it/s]\n",
      "\n",
      "685it [00:20, 16.05it/s]\n",
      "\n",
      "687it [00:20, 15.21it/s]\n",
      "\n",
      "689it [00:20, 14.86it/s]\n",
      "\n",
      "691it [00:21, 14.11it/s]\n",
      "\n",
      "693it [00:21, 15.34it/s]\n",
      "\n",
      "696it [00:21, 17.58it/s]\n",
      "\n",
      "699it [00:21, 19.53it/s]\n",
      "\n",
      "702it [00:21, 16.62it/s]\n",
      "\n",
      "705it [00:21, 17.10it/s]\n",
      "\n",
      "708it [00:21, 19.08it/s]\n",
      "\n",
      "711it [00:22, 17.15it/s]\n",
      "\n",
      "713it [00:22, 15.73it/s]\n",
      "\n",
      "716it [00:22, 16.25it/s]\n",
      "\n",
      "718it [00:22, 15.30it/s]\n",
      "\n",
      "720it [00:22, 14.60it/s]\n",
      "\n",
      "722it [00:22, 14.27it/s]\n",
      "\n",
      "724it [00:23, 13.81it/s]\n",
      "\n",
      "727it [00:23, 14.74it/s]\n",
      "\n",
      "729it [00:23, 15.94it/s]\n",
      "\n",
      "732it [00:23, 18.09it/s]\n",
      "\n",
      "735it [00:23, 18.06it/s]\n",
      "\n",
      "737it [00:23, 18.41it/s]\n",
      "\n",
      "739it [00:23, 16.50it/s]\n",
      "\n",
      "742it [00:23, 16.81it/s]\n",
      "\n",
      "744it [00:24, 17.21it/s]\n",
      "\n",
      "746it [00:24, 15.88it/s]\n",
      "\n",
      "748it [00:24, 14.27it/s]\n",
      "\n",
      "752it [00:24, 16.88it/s]\n",
      "\n",
      "754it [00:24, 17.54it/s]\n",
      "\n",
      "757it [00:24, 17.64it/s]\n",
      "\n",
      "759it [00:24, 18.25it/s]\n",
      "\n",
      "762it [00:25, 17.95it/s]\n",
      "\n",
      "764it [00:25, 16.24it/s]\n",
      "\n",
      "766it [00:25, 17.09it/s]\n",
      "\n",
      "768it [00:25, 15.59it/s]\n",
      "\n",
      "771it [00:25, 16.09it/s]\n",
      "\n",
      "773it [00:25, 14.76it/s]\n",
      "\n",
      "775it [00:25, 15.55it/s]\n",
      "\n",
      "778it [00:26, 17.30it/s]\n",
      "\n",
      "780it [00:26, 17.90it/s]\n",
      "\n",
      "783it [00:26, 19.50it/s]\n",
      "\n",
      "787it [00:26, 20.83it/s]\n",
      "\n",
      "790it [00:26, 21.38it/s]\n",
      "\n",
      "793it [00:26, 19.38it/s]\n",
      "\n",
      "796it [00:27, 16.22it/s]\n",
      "\n",
      "798it [00:27, 14.65it/s]\n",
      "\n",
      "800it [00:27, 15.71it/s]\n",
      "\n",
      "802it [00:27, 16.39it/s]\n",
      "\n",
      "804it [00:27, 14.42it/s]\n",
      "\n",
      "806it [00:27, 15.60it/s]\n",
      "\n",
      "808it [00:27, 16.39it/s]\n",
      "\n",
      "810it [00:27, 14.90it/s]\n",
      "\n",
      "812it [00:28, 13.98it/s]\n",
      "\n",
      "814it [00:28, 13.12it/s]\n",
      "\n",
      "816it [00:28, 14.48it/s]\n",
      "\n",
      "818it [00:28, 13.28it/s]\n",
      "\n",
      "820it [00:28, 14.28it/s]\n",
      "\n",
      "822it [00:28, 14.60it/s]\n",
      "\n",
      "824it [00:28, 15.39it/s]\n",
      "\n",
      "826it [00:29, 13.23it/s]\n",
      "\n",
      "828it [00:29, 12.82it/s]\n",
      "\n",
      "830it [00:29, 13.87it/s]\n",
      "\n",
      "832it [00:29, 13.07it/s]\n",
      "\n",
      "834it [00:29, 11.89it/s]\n",
      "\n",
      "836it [00:30, 11.36it/s]\n",
      "\n",
      "838it [00:30, 12.29it/s]\n",
      "\n",
      "840it [00:30, 11.90it/s]\n",
      "\n",
      "843it [00:30, 13.63it/s]\n",
      "\n",
      "845it [00:30, 14.58it/s]\n",
      "\n",
      "847it [00:30, 15.03it/s]\n",
      "\n",
      "849it [00:30, 15.86it/s]\n",
      "\n",
      "851it [00:30, 15.84it/s]\n",
      "\n",
      "853it [00:31, 14.18it/s]\n",
      "\n",
      "856it [00:31, 15.55it/s]\n",
      "\n",
      "858it [00:31, 16.15it/s]\n",
      "\n",
      "860it [00:31, 16.39it/s]\n",
      "\n",
      "862it [00:31, 13.91it/s]\n",
      "\n",
      "865it [00:31, 15.46it/s]\n",
      "\n",
      "867it [00:32, 14.02it/s]\n",
      "\n",
      "870it [00:32, 15.34it/s]\n",
      "\n",
      "873it [00:32, 16.37it/s]\n",
      "\n",
      "875it [00:32, 16.64it/s]\n",
      "\n",
      "877it [00:32, 16.70it/s]\n",
      "\n",
      "879it [00:32, 14.62it/s]\n",
      "\n",
      "881it [00:32, 13.34it/s]\n",
      "\n",
      "883it [00:33, 14.14it/s]\n",
      "\n",
      "885it [00:33, 14.73it/s]\n",
      "\n",
      "887it [00:33, 15.31it/s]\n",
      "\n",
      "889it [00:33, 15.78it/s]\n",
      "\n",
      "891it [00:33, 16.05it/s]\n",
      "\n",
      "893it [00:33, 13.94it/s]\n",
      "\n",
      "895it [00:33, 14.57it/s]\n",
      "\n",
      "897it [00:34, 13.34it/s]\n",
      "\n",
      "899it [00:34, 12.45it/s]\n",
      "\n",
      "901it [00:34, 11.92it/s]\n",
      "\n",
      "903it [00:34, 12.97it/s]\n",
      "\n",
      "905it [00:34, 13.84it/s]\n",
      "\n",
      "907it [00:34, 12.90it/s]\n",
      "\n",
      "909it [00:34, 13.79it/s]\n",
      "\n",
      "911it [00:35, 14.56it/s]\n",
      "\n",
      "913it [00:35, 12.41it/s]\n",
      "\n",
      "915it [00:35, 13.32it/s]\n",
      "\n",
      "917it [00:35, 13.55it/s]\n",
      "\n",
      "919it [00:35, 13.60it/s]\n",
      "\n",
      "921it [00:35, 14.16it/s]\n",
      "\n",
      "923it [00:35, 14.52it/s]\n",
      "\n",
      "925it [00:36, 12.80it/s]\n",
      "\n",
      "928it [00:36, 14.34it/s]\n",
      "\n",
      "930it [00:36, 14.68it/s]\n",
      "\n",
      "932it [00:36, 14.90it/s]\n",
      "\n",
      "934it [00:36, 15.02it/s]\n",
      "\n",
      "938it [00:36, 16.79it/s]\n",
      "\n",
      "940it [00:37, 14.32it/s]\n",
      "\n",
      "942it [00:37, 14.67it/s]\n",
      "\n",
      "944it [00:37, 14.96it/s]\n",
      "\n",
      "946it [00:37, 13.03it/s]\n",
      "\n",
      "948it [00:37, 11.81it/s]\n",
      "\n",
      "950it [00:37, 12.75it/s]\n",
      "\n",
      "953it [00:37, 14.36it/s]\n",
      "\n",
      "955it [00:38, 12.91it/s]\n",
      "\n",
      "957it [00:38, 13.71it/s]\n",
      "\n",
      "959it [00:38, 14.27it/s]\n",
      "\n",
      "961it [00:38, 14.63it/s]\n",
      "\n",
      "963it [00:38, 14.83it/s]\n",
      "\n",
      "965it [00:38, 14.97it/s]\n",
      "\n",
      "967it [00:38, 14.87it/s]\n",
      "\n",
      "969it [00:39, 13.04it/s]\n",
      "\n",
      "971it [00:39, 12.07it/s]\n",
      "\n",
      "974it [00:39, 13.43it/s]\n",
      "\n",
      "976it [00:39, 12.23it/s]\n",
      "\n",
      "978it [00:39, 11.34it/s]\n",
      "\n",
      "980it [00:40, 10.95it/s]\n",
      "\n",
      "982it [00:40, 10.64it/s]\n",
      "\n",
      "984it [00:40, 11.73it/s]\n",
      "\n",
      "987it [00:40, 13.27it/s]\n",
      "\n",
      "989it [00:40, 12.19it/s]\n",
      "\n",
      "991it [00:40, 12.96it/s]\n",
      "\n",
      "993it [00:41, 11.83it/s]\n",
      "\n",
      "995it [00:41, 11.13it/s]\n",
      "\n",
      "997it [00:41, 10.76it/s]\n",
      "\n",
      "999it [00:41, 10.56it/s]\n",
      "\n",
      "1001it [00:41, 10.14it/s]\n",
      "\n",
      "1003it [00:42, 11.17it/s]\n",
      "\n",
      "1005it [00:42, 10.84it/s]\n",
      "\n",
      "1009it [00:42, 13.61it/s]\n",
      "\n",
      "1012it [00:42, 14.84it/s]\n",
      "\n",
      "1014it [00:42, 14.94it/s]\n",
      "\n",
      "1016it [00:42, 13.00it/s]\n",
      "\n",
      "1018it [00:43, 11.81it/s]\n",
      "\n",
      "1020it [00:43, 11.08it/s]\n",
      "\n",
      "1022it [00:43, 12.04it/s]\n",
      "\n",
      "1024it [00:43, 12.70it/s]\n",
      "\n",
      "1026it [00:43, 11.61it/s]\n",
      "\n",
      "1028it [00:43, 10.94it/s]\n",
      "\n",
      "1030it [00:44, 11.71it/s]\n",
      "\n",
      "1032it [00:44, 12.48it/s]\n",
      "\n",
      "1034it [00:44, 11.35it/s]\n",
      "\n",
      "1036it [00:44, 12.13it/s]\n",
      "\n",
      "1038it [00:44, 12.83it/s]\n",
      "\n",
      "1040it [00:44, 11.67it/s]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1042it [00:45, 11.02it/s]\n",
      "\n",
      "1044it [00:45, 11.88it/s]\n",
      "\n",
      "1046it [00:45, 11.83it/s]\n",
      "\n",
      "1048it [00:45, 12.55it/s]\n",
      "\n",
      "1050it [00:45, 11.47it/s]\n",
      "\n",
      "1052it [00:45, 12.18it/s]\n",
      "\n",
      "1054it [00:46, 11.27it/s]\n",
      "\n",
      "1056it [00:46, 10.74it/s]\n",
      "\n",
      "1058it [00:46, 10.42it/s]\n",
      "\n",
      "1060it [00:46, 11.21it/s]\n",
      "\n",
      "1062it [00:46, 11.95it/s]\n",
      "\n",
      "1064it [00:46, 12.65it/s]\n",
      "\n",
      "1066it [00:47, 11.51it/s]\n",
      "\n",
      "1068it [00:47, 10.88it/s]\n",
      "\n",
      "1070it [00:47, 11.72it/s]\n",
      "\n",
      "1073it [00:47, 13.13it/s]\n",
      "\n",
      "1075it [00:47, 11.80it/s]\n",
      "\n",
      "1077it [00:48, 12.53it/s]\n",
      "\n",
      "1080it [00:48, 13.73it/s]\n",
      "\n",
      "1082it [00:48, 11.94it/s]\n",
      "\n",
      "1084it [00:48, 12.50it/s]\n",
      "\n",
      "1086it [00:48, 11.34it/s]\n",
      "\n",
      "1088it [00:48, 12.10it/s]\n",
      "\n",
      "1090it [00:49, 12.69it/s]\n",
      "\n",
      "1092it [00:49, 11.39it/s]\n",
      "\n",
      "1094it [00:49, 10.61it/s]\n",
      "\n",
      "1096it [00:49, 11.31it/s]\n",
      "\n",
      "1098it [00:49, 12.03it/s]\n",
      "\n",
      "1100it [00:50, 10.92it/s]\n",
      "\n",
      "1102it [00:50, 11.74it/s]\n",
      "\n",
      "1104it [00:50, 12.39it/s]\n",
      "\n",
      "1106it [00:50, 11.18it/s]\n",
      "\n",
      "1108it [00:50, 11.91it/s]\n",
      "\n",
      "1110it [00:50, 12.45it/s]\n",
      "\n",
      "1112it [00:50, 12.83it/s]\n",
      "\n",
      "1115it [00:51, 15.48it/s]\n",
      "\n",
      "1117it [00:51, 12.70it/s]\n",
      "\n",
      "1119it [00:51, 11.34it/s]\n",
      "\n",
      "1121it [00:51, 11.99it/s]\n",
      "\n",
      "1123it [00:51, 10.81it/s]\n",
      "\n",
      "1127it [00:52, 12.49it/s]\n",
      "\n",
      "1129it [00:52, 12.69it/s]\n",
      "\n",
      "1131it [00:52, 13.04it/s]\n",
      "\n",
      "1133it [00:52, 13.32it/s]\n",
      "\n",
      "1135it [00:52, 13.52it/s]\n",
      "\n",
      "1137it [00:52, 13.61it/s]\n",
      "\n",
      "1139it [00:53, 11.75it/s]\n",
      "\n",
      "1141it [00:53, 10.71it/s]\n",
      "\n",
      "1143it [00:53, 10.11it/s]\n",
      "\n",
      "1145it [00:53,  9.69it/s]\n",
      "\n",
      "1147it [00:53,  9.46it/s]\n",
      "\n",
      "1149it [00:54, 10.43it/s]\n",
      "\n",
      "1151it [00:54,  9.90it/s]\n",
      "\n",
      "1153it [00:54,  9.51it/s]\n",
      "\n",
      "1155it [00:54, 10.48it/s]\n",
      "\n",
      "1157it [00:54,  9.91it/s]\n",
      "\n",
      "1159it [00:55,  9.48it/s]\n",
      "\n",
      "1160it [00:55,  9.19it/s]\n",
      "\n",
      "1162it [00:55, 10.06it/s]\n",
      "\n",
      "1164it [00:55,  9.67it/s]\n",
      "\n",
      "1166it [00:55, 10.43it/s]\n",
      "\n",
      "1168it [00:56,  9.71it/s]\n",
      "\n",
      "1170it [00:56, 10.46it/s]\n",
      "\n",
      "1173it [00:56, 11.85it/s]\n",
      "\n",
      "1175it [00:56, 12.16it/s]\n",
      "\n",
      "1177it [00:56, 10.75it/s]\n",
      "\n",
      "1179it [00:56,  9.97it/s]\n",
      "\n",
      "1181it [00:57, 10.78it/s]\n",
      "\n",
      "1183it [00:57, 10.00it/s]\n",
      "\n",
      "1185it [00:57, 10.62it/s]\n",
      "\n",
      "1187it [00:57,  9.86it/s]\n",
      "\n",
      "1189it [00:58,  9.25it/s]\n",
      "\n",
      "1190it [00:58,  8.92it/s]\n",
      "\n",
      "1193it [00:58, 11.26it/s]\n",
      "\n",
      "1195it [00:58, 10.15it/s]\n",
      "\n",
      "1197it [00:58, 10.70it/s]\n",
      "\n",
      "1199it [00:58, 11.06it/s]\n",
      "\n",
      "1201it [00:59, 10.17it/s]\n",
      "\n",
      "1203it [00:59,  9.59it/s]\n",
      "\n",
      "1205it [00:59, 10.43it/s]\n",
      "\n",
      "1207it [00:59,  9.69it/s]\n",
      "\n",
      "1209it [00:59, 10.43it/s]\n",
      "\n",
      "1211it [01:00,  9.67it/s]\n",
      "\n",
      "1214it [01:00, 12.06it/s]\n",
      "\n",
      "1216it [01:00, 10.70it/s]\n",
      "\n",
      "1218it [01:00, 11.30it/s]\n",
      "\n",
      "1220it [01:00, 10.21it/s]\n",
      "\n",
      "1222it [01:00, 10.90it/s]\n",
      "\n",
      "1224it [01:01, 11.36it/s]\n",
      "\n",
      "1226it [01:01, 11.83it/s]\n",
      "\n",
      "1228it [01:01, 10.52it/s]\n",
      "\n",
      "1230it [01:01,  9.70it/s]\n",
      "\n",
      "1232it [01:01, 10.47it/s]\n",
      "\n",
      "1234it [01:02, 11.05it/s]\n",
      "\n",
      "1237it [01:02, 12.14it/s]\n",
      "\n",
      "1239it [01:02, 12.28it/s]\n",
      "\n",
      "1241it [01:02, 12.38it/s]\n",
      "\n",
      "1243it [01:02, 10.69it/s]\n",
      "\n",
      "1245it [01:03,  9.82it/s]\n",
      "\n",
      "1247it [01:03, 10.42it/s]\n",
      "\n",
      "1249it [01:03, 11.01it/s]\n",
      "\n",
      "1251it [01:03, 11.41it/s]\n",
      "\n",
      "1254it [01:03, 13.98it/s]\n",
      "\n",
      "1256it [01:03, 13.22it/s]\n",
      "\n",
      "1258it [01:03, 12.81it/s]\n",
      "\n",
      "1260it [01:04, 10.49it/s]\n",
      "\n",
      "1262it [01:04,  9.53it/s]\n",
      "\n",
      "1264it [01:04, 10.26it/s]\n",
      "\n",
      "1266it [01:04, 10.88it/s]\n",
      "\n",
      "1268it [01:05,  9.41it/s]\n",
      "\n",
      "1270it [01:05,  8.83it/s]\n",
      "\n",
      "1272it [01:05,  9.50it/s]\n",
      "\n",
      "1274it [01:05,  8.86it/s]\n",
      "\n",
      "1275it [01:05,  8.52it/s]\n",
      "\n",
      "1276it [01:06,  8.30it/s]\n",
      "\n",
      "1277it [01:06,  8.16it/s]\n",
      "\n",
      "1279it [01:06,  9.09it/s]\n",
      "\n",
      "1280it [01:06,  8.63it/s]\n",
      "\n",
      "1282it [01:06,  9.46it/s]\n",
      "\n",
      "1283it [01:06,  8.86it/s]\n",
      "\n",
      "1284it [01:06,  8.46it/s]\n",
      "\n",
      "1286it [01:07,  9.24it/s]\n",
      "\n",
      "1288it [01:07,  9.93it/s]\n",
      "\n",
      "1290it [01:07, 10.51it/s]\n",
      "\n",
      "1292it [01:07,  9.32it/s]\n",
      "\n",
      "1293it [01:07,  8.82it/s]\n",
      "\n",
      "1294it [01:07,  8.37it/s]\n",
      "\n",
      "1295it [01:08,  8.16it/s]\n",
      "\n",
      "1296it [01:08,  7.65it/s]\n",
      "\n",
      "1297it [01:08,  7.58it/s]\n",
      "\n",
      "1298it [01:08,  7.50it/s]\n",
      "\n",
      "1301it [01:08,  9.50it/s]\n",
      "\n",
      "1303it [01:08, 10.04it/s]\n",
      "\n",
      "1305it [01:09,  9.08it/s]\n",
      "\n",
      "1307it [01:09,  9.63it/s]\n",
      "\n",
      "1310it [01:09, 11.87it/s]\n",
      "\n",
      "1312it [01:09, 11.68it/s]\n",
      "\n",
      "1314it [01:09, 11.55it/s]\n",
      "\n",
      "1316it [01:09,  9.62it/s]\n",
      "\n",
      "1318it [01:10,  8.79it/s]\n",
      "\n",
      "1320it [01:10,  9.40it/s]\n",
      "\n",
      "1322it [01:10,  8.68it/s]\n",
      "\n",
      "1324it [01:10,  9.44it/s]\n",
      "\n",
      "1326it [01:11, 10.18it/s]\n",
      "\n",
      "1328it [01:11,  9.28it/s]\n",
      "\n",
      "1329it [01:11,  8.46it/s]\n",
      "\n",
      "1331it [01:11,  9.25it/s]\n",
      "\n",
      "1332it [01:11,  8.62it/s]\n",
      "\n",
      "1333it [01:11,  8.20it/s]\n",
      "\n",
      "1335it [01:12,  9.06it/s]\n",
      "\n",
      "1336it [01:12,  8.42it/s]\n",
      "\n",
      "1337it [01:12,  8.07it/s]\n",
      "\n",
      "1339it [01:12,  8.95it/s]\n",
      "\n",
      "1340it [01:12,  8.50it/s]\n",
      "\n",
      "1341it [01:12,  8.07it/s]\n",
      "\n",
      "1342it [01:12,  7.75it/s]\n",
      "\n",
      "1345it [01:13,  8.99it/s]\n",
      "\n",
      "1347it [01:13,  9.68it/s]\n",
      "\n",
      "1349it [01:13,  8.86it/s]\n",
      "\n",
      "1350it [01:13,  8.33it/s]\n",
      "\n",
      "1351it [01:13,  7.96it/s]\n",
      "\n",
      "1352it [01:13,  7.70it/s]\n",
      "\n",
      "1353it [01:14,  7.57it/s]\n",
      "\n",
      "1354it [01:14,  7.44it/s]\n",
      "\n",
      "1355it [01:14,  7.49it/s]\n",
      "\n",
      "1356it [01:14,  7.40it/s]\n",
      "\n",
      "1357it [01:14,  7.39it/s]\n",
      "\n",
      "1358it [01:14,  7.42it/s]\n",
      "\n",
      "1359it [01:14,  7.31it/s]\n",
      "\n",
      "1360it [01:15,  7.19it/s]\n",
      "\n",
      "1361it [01:15,  7.03it/s]\n",
      "\n",
      "1362it [01:15,  7.16it/s]\n",
      "\n",
      "1365it [01:15,  9.02it/s]\n",
      "\n",
      "1367it [01:15,  8.24it/s]\n",
      "\n",
      "1369it [01:15,  8.86it/s]\n",
      "\n",
      "1371it [01:16,  9.18it/s]\n",
      "\n",
      "1373it [01:16,  8.63it/s]\n",
      "\n",
      "1374it [01:16,  8.15it/s]\n",
      "\n",
      "1375it [01:16,  7.79it/s]\n",
      "\n",
      "1377it [01:16,  8.53it/s]\n",
      "\n",
      "1378it [01:17,  8.07it/s]\n",
      "\n",
      "1379it [01:17,  7.68it/s]\n",
      "\n",
      "1380it [01:17,  7.50it/s]\n",
      "\n",
      "1381it [01:17,  7.38it/s]\n",
      "\n",
      "1382it [01:17,  7.30it/s]\n",
      "\n",
      "1383it [01:17,  7.27it/s]\n",
      "\n",
      "1384it [01:17,  7.10it/s]\n",
      "\n",
      "1385it [01:18,  7.04it/s]\n",
      "\n",
      "1386it [01:18,  7.08it/s]\n",
      "\n",
      "1387it [01:18,  7.10it/s]\n",
      "\n",
      "1388it [01:18,  6.59it/s]\n",
      "\n",
      "1390it [01:18,  7.49it/s]\n",
      "\n",
      "1392it [01:18,  8.30it/s]\n",
      "\n",
      "1394it [01:19,  8.89it/s]\n",
      "\n",
      "1395it [01:19,  8.05it/s]\n",
      "\n",
      "1398it [01:19,  9.27it/s]\n",
      "\n",
      "1400it [01:19,  8.39it/s]\n",
      "\n",
      "1401it [01:19,  7.79it/s]\n",
      "\n",
      "1402it [01:19,  7.54it/s]\n",
      "\n",
      "1403it [01:20,  7.31it/s]\n",
      "\n",
      "1404it [01:20,  7.16it/s]\n",
      "\n",
      "1405it [01:20,  7.14it/s]\n",
      "\n",
      "1406it [01:20,  7.09it/s]\n",
      "\n",
      "1407it [01:20,  6.99it/s]\n",
      "\n",
      "1408it [01:20,  6.97it/s]\n",
      "\n",
      "1409it [01:20,  6.89it/s]\n",
      "\n",
      "1410it [01:21,  6.91it/s]\n",
      "\n",
      "1412it [01:21,  7.71it/s]\n",
      "\n",
      "1414it [01:21,  8.49it/s]\n",
      "\n",
      "1415it [01:21,  7.94it/s]\n",
      "\n",
      "1417it [01:21,  8.70it/s]\n",
      "\n",
      "1418it [01:21,  8.06it/s]\n",
      "\n",
      "1419it [01:22,  7.52it/s]\n",
      "\n",
      "1420it [01:22,  7.38it/s]\n",
      "\n",
      "1423it [01:22,  8.57it/s]\n",
      "\n",
      "1425it [01:22,  9.19it/s]\n",
      "\n",
      "1427it [01:22,  9.72it/s]\n",
      "\n",
      "1429it [01:23,  8.73it/s]\n",
      "\n",
      "1430it [01:23,  8.03it/s]\n",
      "\n",
      "1431it [01:23,  7.52it/s]\n",
      "\n",
      "1433it [01:23,  8.35it/s]\n",
      "\n",
      "1434it [01:23,  7.88it/s]\n",
      "\n",
      "1437it [01:23,  9.91it/s]\n",
      "\n",
      "1440it [01:24, 10.73it/s]\n",
      "\n",
      "1442it [01:24, 10.78it/s]\n",
      "\n",
      "1444it [01:24,  9.14it/s]\n",
      "\n",
      "1446it [01:24,  8.37it/s]\n",
      "\n",
      "1447it [01:25,  7.54it/s]\n",
      "\n",
      "1449it [01:25,  8.08it/s]\n",
      "\n",
      "1450it [01:25,  7.71it/s]\n",
      "\n",
      "1451it [01:25,  7.17it/s]\n",
      "\n",
      "1452it [01:25,  6.96it/s]\n",
      "\n",
      "1453it [01:25,  6.99it/s]\n",
      "\n",
      "1454it [01:25,  6.91it/s]\n",
      "\n",
      "1455it [01:26,  6.69it/s]\n",
      "\n",
      "1456it [01:26,  6.71it/s]\n",
      "\n",
      "1458it [01:26,  7.59it/s]\n",
      "\n",
      "1461it [01:26,  9.54it/s]\n",
      "\n",
      "1463it [01:26,  9.84it/s]\n",
      "\n",
      "1465it [01:26, 10.12it/s]\n",
      "\n",
      "1467it [01:27,  8.90it/s]\n",
      "\n",
      "1469it [01:27,  9.28it/s]\n",
      "\n",
      "1472it [01:27, 10.22it/s]\n",
      "\n",
      "1474it [01:27, 10.22it/s]\n",
      "\n",
      "1477it [01:27, 12.45it/s]\n",
      "\n",
      "1479it [01:28,  9.68it/s]\n",
      "\n",
      "1481it [01:28,  9.95it/s]\n",
      "\n",
      "1483it [01:28, 10.03it/s]\n",
      "\n",
      "1485it [01:28, 10.19it/s]\n",
      "\n",
      "1487it [01:29,  8.76it/s]\n",
      "\n",
      "1489it [01:29,  9.19it/s]\n",
      "\n",
      "1490it [01:29,  8.12it/s]\n",
      "\n",
      "1491it [01:29,  7.61it/s]\n",
      "\n",
      "1493it [01:29,  8.32it/s]\n",
      "\n",
      "1494it [01:30,  7.70it/s]\n",
      "\n",
      "1495it [01:30,  7.31it/s]\n",
      "\n",
      "1497it [01:30,  8.03it/s]\n",
      "\n",
      "1498it [01:30,  7.32it/s]\n",
      "\n",
      "1499it [01:30,  7.10it/s]\n",
      "\n",
      "1500it [01:30,  6.84it/s]\n",
      "\n",
      "1501it [01:30,  6.71it/s]\n",
      "\n",
      "1503it [01:31,  7.40it/s]\n",
      "\n",
      "1504it [01:31,  7.16it/s]\n",
      "\n",
      "1505it [01:31,  6.84it/s]\n",
      "\n",
      "1507it [01:31,  7.67it/s]\n",
      "\n",
      "1508it [01:31,  7.30it/s]\n",
      "\n",
      "1510it [01:32,  8.03it/s]\n",
      "\n",
      "1511it [01:32,  7.44it/s]\n",
      "\n",
      "1512it [01:32,  7.07it/s]\n",
      "\n",
      "1513it [01:32,  6.89it/s]\n",
      "\n",
      "1516it [01:32,  8.76it/s]\n",
      "\n",
      "1518it [01:32,  7.98it/s]\n",
      "\n",
      "1521it [01:33,  8.99it/s]\n",
      "\n",
      "1524it [01:33, 10.00it/s]\n",
      "\n",
      "1526it [01:33,  8.73it/s]\n",
      "\n",
      "1528it [01:34,  7.94it/s]\n",
      "\n",
      "1529it [01:34,  7.42it/s]\n",
      "\n",
      "1530it [01:34,  7.15it/s]\n",
      "\n",
      "1531it [01:34,  6.87it/s]\n",
      "\n",
      "1533it [01:34,  7.66it/s]\n",
      "\n",
      "1534it [01:34,  7.15it/s]\n",
      "\n",
      "1535it [01:34,  6.76it/s]\n",
      "\n",
      "1536it [01:35,  6.59it/s]\n",
      "\n",
      "1537it [01:35,  6.56it/s]\n",
      "\n",
      "1538it [01:35,  6.44it/s]\n",
      "\n",
      "1540it [01:35,  7.24it/s]\n",
      "\n",
      "1541it [01:35,  6.93it/s]\n",
      "\n",
      "1542it [01:35,  6.70it/s]\n",
      "\n",
      "1543it [01:36,  6.59it/s]\n",
      "\n",
      "1544it [01:36,  6.52it/s]\n",
      "\n",
      "1545it [01:36,  6.41it/s]\n",
      "\n",
      "1546it [01:36,  6.38it/s]\n",
      "\n",
      "1547it [01:36,  6.29it/s]\n",
      "\n",
      "1548it [01:36,  6.27it/s]\n",
      "\n",
      "1550it [01:37,  7.04it/s]\n",
      "\n",
      "1551it [01:37,  6.73it/s]\n",
      "\n",
      "1552it [01:37,  6.67it/s]\n",
      "\n",
      "1554it [01:37,  7.38it/s]\n",
      "\n",
      "1555it [01:37,  6.99it/s]\n",
      "\n",
      "1556it [01:37,  6.72it/s]\n",
      "\n",
      "1558it [01:38,  7.41it/s]\n",
      "\n",
      "1559it [01:38,  6.97it/s]\n",
      "\n",
      "1561it [01:38,  7.70it/s]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1564it [01:38,  9.68it/s]\n",
      "\n",
      "1567it [01:38, 11.82it/s]\n",
      "\n",
      "1569it [01:38, 11.18it/s]\n",
      "\n",
      "1571it [01:39, 10.84it/s]\n",
      "\n",
      "1573it [01:39, 10.69it/s]\n",
      "\n",
      "1575it [01:39, 10.53it/s]\n",
      "\n",
      "1577it [01:39,  8.91it/s]\n",
      "\n",
      "1579it [01:40,  9.19it/s]\n",
      "\n",
      "1581it [01:40,  8.04it/s]\n",
      "\n",
      "1582it [01:40,  7.27it/s]\n",
      "\n",
      "1583it [01:40,  6.99it/s]\n",
      "\n",
      "1584it [01:40,  6.74it/s]\n",
      "\n",
      "1587it [01:41,  7.82it/s]\n",
      "\n",
      "1589it [01:41,  8.32it/s]\n",
      "\n",
      "1590it [01:41,  7.53it/s]\n",
      "\n",
      "1592it [01:41,  8.13it/s]\n",
      "\n",
      "1593it [01:41,  7.37it/s]\n",
      "\n",
      "1594it [01:42,  7.01it/s]\n",
      "\n",
      "1595it [01:42,  6.64it/s]\n",
      "\n",
      "1596it [01:42,  6.53it/s]\n",
      "\n",
      "1598it [01:42,  7.27it/s]\n",
      "\n",
      "1600it [01:42,  7.94it/s]\n",
      "\n",
      "1601it [01:42,  7.27it/s]\n",
      "\n",
      "1602it [01:43,  6.91it/s]\n",
      "\n",
      "1603it [01:43,  6.65it/s]\n",
      "\n",
      "1605it [01:43,  7.32it/s]\n",
      "\n",
      "1607it [01:43,  7.98it/s]\n",
      "\n",
      "1608it [01:43,  7.34it/s]\n",
      "\n",
      "1609it [01:43,  6.93it/s]\n",
      "\n",
      "1610it [01:44,  6.67it/s]\n",
      "\n",
      "1611it [01:44,  6.53it/s]\n",
      "\n",
      "1612it [01:44,  6.39it/s]\n",
      "\n",
      "1615it [01:44,  7.50it/s]\n",
      "\n",
      "1617it [01:44,  8.05it/s]\n",
      "\n",
      "1620it [01:45, 10.02it/s]\n",
      "\n",
      "1622it [01:45, 10.00it/s]\n",
      "\n",
      "1624it [01:45,  8.44it/s]\n",
      "\n",
      "1626it [01:45,  7.64it/s]\n",
      "\n",
      "1628it [01:46,  8.19it/s]\n",
      "\n",
      "1631it [01:46, 10.17it/s]\n",
      "\n",
      "1633it [01:46, 10.16it/s]\n",
      "\n",
      "1635it [01:46, 10.09it/s]\n",
      "\n",
      "1637it [01:46,  8.54it/s]\n",
      "\n",
      "1639it [01:47,  7.68it/s]\n",
      "\n",
      "1640it [01:47,  7.09it/s]\n",
      "\n",
      "1641it [01:47,  6.70it/s]\n",
      "\n",
      "1642it [01:47,  6.45it/s]\n",
      "\n",
      "1643it [01:47,  6.37it/s]\n",
      "\n",
      "1646it [01:48,  7.39it/s]\n",
      "\n",
      "1648it [01:48,  8.01it/s]\n",
      "\n",
      "1649it [01:48,  7.13it/s]\n",
      "\n",
      "1652it [01:48,  8.87it/s]\n",
      "\n",
      "1654it [01:48,  9.02it/s]\n",
      "\n",
      "1656it [01:49,  7.87it/s]\n",
      "\n",
      "1659it [01:49,  8.89it/s]\n",
      "\n",
      "1661it [01:49,  9.11it/s]\n",
      "\n",
      "1663it [01:49,  9.28it/s]\n",
      "\n",
      "1665it [01:50,  8.00it/s]\n",
      "\n",
      "1666it [01:50,  7.31it/s]\n",
      "\n",
      "1667it [01:50,  6.78it/s]\n",
      "\n",
      "1668it [01:50,  6.54it/s]\n",
      "\n",
      "1669it [01:50,  6.40it/s]\n",
      "\n",
      "1670it [01:51,  6.20it/s]\n",
      "\n",
      "1671it [01:51,  6.10it/s]\n",
      "\n",
      "1674it [01:51,  7.18it/s]\n",
      "\n",
      "1676it [01:51,  7.80it/s]\n",
      "\n",
      "1677it [01:51,  7.08it/s]\n",
      "\n",
      "1678it [01:52,  6.65it/s]\n",
      "\n",
      "1681it [01:52,  7.64it/s]\n",
      "\n",
      "1684it [01:52,  8.62it/s]\n",
      "\n",
      "1685it [01:52,  7.49it/s]\n",
      "\n",
      "1686it [01:52,  6.90it/s]\n",
      "\n",
      "1689it [01:53,  7.89it/s]\n",
      "\n",
      "1690it [01:53,  7.18it/s]\n",
      "\n",
      "1693it [01:53,  8.13it/s]\n",
      "\n",
      "1694it [01:53,  7.22it/s]\n",
      "\n",
      "1696it [01:53,  7.71it/s]\n",
      "\n",
      "1698it [01:54,  8.13it/s]\n",
      "\n",
      "1701it [01:54,  9.06it/s]\n",
      "\n",
      "1702it [01:54,  7.77it/s]\n",
      "\n",
      "1705it [01:54,  8.66it/s]\n",
      "\n",
      "1707it [01:55,  8.79it/s]\n",
      "\n",
      "1709it [01:55,  8.97it/s]\n",
      "\n",
      "1710it [01:55,  7.76it/s]\n",
      "\n",
      "1711it [01:55,  7.13it/s]\n",
      "\n",
      "1712it [01:55,  6.72it/s]\n",
      "\n",
      "1713it [01:55,  6.42it/s]\n",
      "\n",
      "1714it [01:56,  6.18it/s]\n",
      "\n",
      "1715it [01:56,  5.98it/s]\n",
      "\n",
      "1717it [01:56,  6.70it/s]\n",
      "\n",
      "1719it [01:56,  7.33it/s]\n",
      "\n",
      "1721it [01:56,  7.76it/s]\n",
      "\n",
      "1723it [01:57,  8.19it/s]\n",
      "\n",
      "1724it [01:57,  6.98it/s]\n",
      "\n",
      "1725it [01:57,  6.41it/s]\n",
      "\n",
      "1726it [01:57,  6.09it/s]\n",
      "\n",
      "1727it [01:57,  5.92it/s]\n",
      "\n",
      "1729it [01:58,  6.51it/s]\n",
      "\n",
      "1731it [01:58,  7.00it/s]\n",
      "\n",
      "1732it [01:58,  6.56it/s]\n",
      "\n",
      "1735it [01:58,  7.57it/s]\n",
      "\n",
      "1737it [01:58,  9.00it/s]\n",
      "\n",
      "1740it [01:59,  9.65it/s]\n",
      "\n",
      "1742it [01:59,  9.55it/s]\n",
      "\n",
      "1744it [01:59,  9.48it/s]\n",
      "\n",
      "1746it [01:59,  7.99it/s]\n",
      "\n",
      "1747it [02:00,  7.14it/s]\n",
      "\n",
      "1749it [02:00,  7.65it/s]\n",
      "\n",
      "1750it [02:00,  7.05it/s]\n",
      "\n",
      "1751it [02:00,  6.65it/s]\n",
      "\n",
      "1753it [02:00,  7.24it/s]\n",
      "\n",
      "1754it [02:01,  6.67it/s]\n",
      "\n",
      "1757it [02:01,  7.68it/s]\n",
      "\n",
      "1758it [02:01,  7.04it/s]\n",
      "\n",
      "1759it [02:01,  6.62it/s]\n",
      "\n",
      "1760it [02:01,  6.30it/s]\n",
      "\n",
      "1761it [02:02,  6.13it/s]\n",
      "\n",
      "1762it [02:02,  6.06it/s]\n",
      "\n",
      "1764it [02:02,  6.73it/s]\n",
      "\n",
      "1765it [02:02,  6.36it/s]\n",
      "\n",
      "1766it [02:02,  6.17it/s]\n",
      "\n",
      "1767it [02:02,  6.12it/s]\n",
      "\n",
      "1768it [02:03,  6.00it/s]\n",
      "\n",
      "1771it [02:03,  6.95it/s]\n",
      "\n",
      "1773it [02:03,  7.45it/s]\n",
      "\n",
      "1775it [02:03,  7.86it/s]\n",
      "\n",
      "1776it [02:04,  6.70it/s]\n",
      "\n",
      "1778it [02:04,  7.18it/s]\n",
      "\n",
      "1780it [02:04,  7.69it/s]\n",
      "\n",
      "1782it [02:04,  9.35it/s]\n",
      "\n",
      "1784it [02:04,  7.46it/s]\n",
      "\n",
      "1785it [02:05,  6.56it/s]\n",
      "\n",
      "1786it [02:05,  6.24it/s]\n",
      "\n",
      "1788it [02:05,  6.75it/s]\n",
      "\n",
      "1789it [02:05,  6.32it/s]\n",
      "\n",
      "1790it [02:05,  6.09it/s]\n",
      "\n",
      "1793it [02:06,  6.95it/s]\n",
      "\n",
      "1794it [02:06,  6.56it/s]\n",
      "\n",
      "1796it [02:06,  7.16it/s]\n",
      "\n",
      "1798it [02:06,  7.54it/s]\n",
      "\n",
      "1799it [02:07,  6.89it/s]\n",
      "\n",
      "1800it [02:07,  6.46it/s]\n",
      "\n",
      "1803it [02:07,  8.16it/s]\n",
      "\n",
      "1805it [02:07,  8.39it/s]\n",
      "\n",
      "1807it [02:07,  8.50it/s]\n",
      "\n",
      "1808it [02:07,  7.39it/s]\n",
      "\n",
      "1811it [02:08,  8.23it/s]\n",
      "\n",
      "1813it [02:08,  8.44it/s]\n",
      "\n",
      "1814it [02:08,  7.30it/s]\n",
      "\n",
      "1815it [02:08,  6.60it/s]\n",
      "\n",
      "1816it [02:09,  6.20it/s]\n",
      "\n",
      "1817it [02:09,  5.91it/s]\n",
      "\n",
      "1820it [02:09,  7.56it/s]\n",
      "\n",
      "1822it [02:09,  6.79it/s]\n",
      "\n",
      "1824it [02:09,  7.28it/s]\n",
      "\n",
      "1825it [02:10,  6.64it/s]\n",
      "\n",
      "1826it [02:10,  6.29it/s]\n",
      "\n",
      "1827it [02:10,  6.04it/s]\n",
      "\n",
      "1828it [02:10,  5.90it/s]\n",
      "\n",
      "1829it [02:10,  5.71it/s]\n",
      "\n",
      "1830it [02:11,  5.70it/s]\n",
      "\n",
      "1831it [02:11,  5.64it/s]\n",
      "\n",
      "1834it [02:11,  7.23it/s]\n",
      "\n",
      "1836it [02:11,  7.31it/s]\n",
      "\n",
      "1837it [02:11,  6.67it/s]\n",
      "\n",
      "1839it [02:12,  7.21it/s]\n",
      "\n",
      "1841it [02:12,  8.90it/s]\n",
      "\n",
      "1843it [02:12,  7.66it/s]\n",
      "\n",
      "1845it [02:12,  6.90it/s]\n",
      "\n",
      "1846it [02:12,  6.45it/s]\n",
      "\n",
      "1847it [02:13,  6.09it/s]\n",
      "\n",
      "1848it [02:13,  5.88it/s]\n",
      "\n",
      "1850it [02:13,  7.44it/s]\n",
      "\n",
      "1852it [02:13,  7.79it/s]\n",
      "\n",
      "1853it [02:13,  6.93it/s]\n",
      "\n",
      "1854it [02:14,  6.35it/s]\n",
      "\n",
      "1855it [02:14,  6.10it/s]\n",
      "\n",
      "1857it [02:14,  6.58it/s]\n",
      "\n",
      "1858it [02:14,  6.13it/s]\n",
      "\n",
      "1860it [02:14,  7.72it/s]\n",
      "\n",
      "1862it [02:15,  6.86it/s]\n",
      "\n",
      "1864it [02:15,  7.33it/s]\n",
      "\n",
      "1865it [02:15,  6.55it/s]\n",
      "\n",
      "1866it [02:15,  6.23it/s]\n",
      "\n",
      "1867it [02:15,  5.96it/s]\n",
      "\n",
      "1868it [02:16,  5.77it/s]\n",
      "\n",
      "1869it [02:16,  5.67it/s]\n",
      "\n",
      "1871it [02:16,  6.32it/s]\n",
      "\n",
      "1872it [02:16,  6.03it/s]\n",
      "\n",
      "1873it [02:16,  5.85it/s]\n",
      "\n",
      "1875it [02:17,  6.37it/s]\n",
      "\n",
      "1876it [02:17,  5.85it/s]\n",
      "\n",
      "1877it [02:17,  5.62it/s]\n",
      "\n",
      "1878it [02:17,  5.38it/s]\n",
      "\n",
      "1880it [02:17,  6.88it/s]\n",
      "\n",
      "1881it [02:18,  6.34it/s]\n",
      "\n",
      "1882it [02:18,  6.04it/s]\n",
      "\n",
      "1884it [02:18,  6.47it/s]\n",
      "\n",
      "1885it [02:18,  6.00it/s]\n",
      "\n",
      "1886it [02:18,  5.80it/s]\n",
      "\n",
      "1887it [02:19,  5.65it/s]\n",
      "\n",
      "1888it [02:19,  5.60it/s]\n",
      "\n",
      "1889it [02:19,  5.48it/s]\n",
      "\n",
      "1892it [02:19,  6.44it/s]\n",
      "\n",
      "1894it [02:19,  6.93it/s]\n",
      "\n",
      "1895it [02:20,  6.33it/s]\n",
      "\n",
      "1896it [02:20,  5.92it/s]\n",
      "\n",
      "1898it [02:20,  6.48it/s]\n",
      "\n",
      "1900it [02:20,  6.94it/s]\n",
      "\n",
      "1901it [02:20,  6.35it/s]\n",
      "\n",
      "1903it [02:21,  6.81it/s]\n",
      "\n",
      "1905it [02:21,  8.44it/s]\n",
      "\n",
      "1907it [02:21,  8.38it/s]\n",
      "\n",
      "1909it [02:21,  7.26it/s]\n",
      "\n",
      "1911it [02:22,  8.90it/s]\n",
      "\n",
      "1913it [02:22,  8.65it/s]\n",
      "\n",
      "1915it [02:22,  8.63it/s]\n",
      "\n",
      "1917it [02:22,  8.55it/s]\n",
      "\n",
      "1918it [02:22,  7.20it/s]\n",
      "\n",
      "1919it [02:23,  6.45it/s]\n",
      "\n",
      "1920it [02:23,  5.86it/s]\n",
      "\n",
      "1922it [02:23,  6.45it/s]\n",
      "\n",
      "1923it [02:23,  6.05it/s]\n",
      "\n",
      "1925it [02:23,  7.59it/s]\n",
      "\n",
      "1927it [02:24,  7.82it/s]\n",
      "\n",
      "1928it [02:24,  6.88it/s]\n",
      "\n",
      "1929it [02:24,  6.29it/s]\n",
      "\n",
      "1931it [02:24,  7.90it/s]\n",
      "\n",
      "1933it [02:24,  6.96it/s]\n",
      "\n",
      "1934it [02:25,  6.19it/s]\n",
      "\n",
      "1935it [02:25,  5.89it/s]\n",
      "\n",
      "1936it [02:25,  5.62it/s]\n",
      "\n",
      "1938it [02:25,  7.04it/s]\n",
      "\n",
      "1939it [02:25,  6.29it/s]\n",
      "\n",
      "1940it [02:26,  5.90it/s]\n",
      "\n",
      "1941it [02:26,  5.61it/s]\n",
      "\n",
      "1942it [02:26,  5.47it/s]\n",
      "\n",
      "1943it [02:26,  5.41it/s]\n",
      "\n",
      "1944it [02:26,  5.39it/s]\n",
      "\n",
      "1946it [02:27,  6.01it/s]\n",
      "\n",
      "1947it [02:27,  5.76it/s]\n",
      "\n",
      "1948it [02:27,  5.56it/s]\n",
      "\n",
      "1949it [02:27,  5.48it/s]\n",
      "\n",
      "1950it [02:27,  5.33it/s]\n",
      "\n",
      "1952it [02:28,  5.92it/s]\n",
      "\n",
      "1954it [02:28,  7.34it/s]\n",
      "\n",
      "1955it [02:28,  6.65it/s]\n",
      "\n",
      "1957it [02:28,  8.25it/s]\n",
      "\n",
      "1959it [02:28,  6.91it/s]\n",
      "\n",
      "1961it [02:29,  7.19it/s]\n",
      "\n",
      "1962it [02:29,  6.44it/s]\n",
      "\n",
      "1963it [02:29,  5.81it/s]\n",
      "\n",
      "1964it [02:29,  5.57it/s]\n",
      "\n",
      "1966it [02:29,  7.06it/s]\n",
      "\n",
      "1968it [02:30,  6.37it/s]\n",
      "\n",
      "1969it [02:30,  5.92it/s]\n",
      "\n",
      "1970it [02:30,  5.70it/s]\n",
      "\n",
      "1971it [02:30,  5.50it/s]\n",
      "\n",
      "1973it [02:31,  6.08it/s]\n",
      "\n",
      "1974it [02:31,  5.73it/s]\n",
      "\n",
      "1975it [02:31,  5.57it/s]\n",
      "\n",
      "1976it [02:31,  5.41it/s]\n",
      "\n",
      "1978it [02:31,  6.87it/s]\n",
      "\n",
      "1979it [02:31,  6.25it/s]\n",
      "\n",
      "1980it [02:32,  5.89it/s]\n",
      "\n",
      "1982it [02:32,  6.41it/s]\n",
      "\n",
      "1983it [02:32,  5.86it/s]\n",
      "\n",
      "1984it [02:32,  5.62it/s]\n",
      "\n",
      "1985it [02:33,  5.45it/s]\n",
      "\n",
      "1986it [02:33,  5.35it/s]\n",
      "\n",
      "1988it [02:33,  5.96it/s]\n",
      "\n",
      "1990it [02:33,  7.50it/s]\n",
      "\n",
      "1992it [02:33,  6.58it/s]\n",
      "\n",
      "1994it [02:34,  8.11it/s]\n",
      "\n",
      "1996it [02:34,  8.04it/s]\n",
      "\n",
      "1998it [02:34,  6.93it/s]\n",
      "\n",
      "2000it [02:34,  7.24it/s]\n",
      "\n",
      "2001it [02:35,  6.39it/s]\n",
      "\n",
      "2002it [02:35,  5.93it/s]\n",
      "\n",
      "2004it [02:35,  7.42it/s]\n",
      "\n",
      "2006it [02:35,  7.60it/s]\n",
      "\n",
      "2007it [02:35,  6.65it/s]\n",
      "\n",
      "2008it [02:36,  6.07it/s]\n",
      "\n",
      "2009it [02:36,  5.74it/s]\n",
      "\n",
      "2011it [02:36,  6.26it/s]\n",
      "\n",
      "2012it [02:36,  5.86it/s]\n",
      "\n",
      "2013it [02:36,  5.57it/s]\n",
      "\n",
      "2015it [02:37,  6.12it/s]\n",
      "\n",
      "2016it [02:37,  5.71it/s]\n",
      "\n",
      "2017it [02:37,  5.40it/s]\n",
      "\n",
      "2018it [02:37,  5.25it/s]\n",
      "\n",
      "2019it [02:38,  5.19it/s]\n",
      "\n",
      "2020it [02:38,  5.14it/s]\n",
      "\n",
      "2022it [02:38,  5.78it/s]\n",
      "\n",
      "2023it [02:38,  5.52it/s]\n",
      "\n",
      "2024it [02:38,  5.34it/s]\n",
      "\n",
      "2025it [02:39,  5.20it/s]\n",
      "\n",
      "2026it [02:39,  5.10it/s]\n",
      "\n",
      "2028it [02:39,  6.45it/s]\n",
      "\n",
      "2029it [02:39,  5.73it/s]\n",
      "\n",
      "2031it [02:39,  7.16it/s]\n",
      "\n",
      "2033it [02:40,  6.32it/s]\n",
      "\n",
      "2035it [02:40,  7.78it/s]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2037it [02:40,  9.43it/s]\n",
      "\n",
      "2039it [02:40,  8.96it/s]\n",
      "\n",
      "2041it [02:40,  7.38it/s]\n",
      "\n",
      "2042it [02:41,  6.52it/s]\n",
      "\n",
      "2043it [02:41,  5.99it/s]\n",
      "\n",
      "2045it [02:41,  6.46it/s]\n",
      "\n",
      "2046it [02:41,  5.92it/s]\n",
      "\n",
      "2047it [02:42,  5.58it/s]\n",
      "\n",
      "2048it [02:42,  5.40it/s]\n",
      "\n",
      "2049it [02:42,  5.29it/s]\n",
      "\n",
      "2050it [02:42,  5.14it/s]\n",
      "\n",
      "2051it [02:42,  5.12it/s]\n",
      "\n",
      "2052it [02:43,  5.02it/s]\n",
      "\n",
      "2053it [02:43,  5.02it/s]\n",
      "\n",
      "2055it [02:43,  5.65it/s]\n",
      "\n",
      "2056it [02:43,  5.43it/s]\n",
      "\n",
      "2057it [02:43,  5.28it/s]\n",
      "\n",
      "2058it [02:44,  5.19it/s]\n",
      "\n",
      "2059it [02:44,  5.13it/s]\n",
      "\n",
      "2060it [02:44,  4.99it/s]\n",
      "\n",
      "2062it [02:44,  6.39it/s]\n",
      "\n",
      "2064it [02:44,  6.65it/s]\n",
      "\n",
      "2065it [02:45,  5.94it/s]\n",
      "\n",
      "2066it [02:45,  5.42it/s]\n",
      "\n",
      "2067it [02:45,  5.26it/s]\n",
      "\n",
      "2068it [02:45,  5.12it/s]\n",
      "\n",
      "2069it [02:45,  5.08it/s]\n",
      "\n",
      "2070it [02:46,  5.05it/s]\n",
      "\n",
      "2071it [02:46,  5.00it/s]\n",
      "\n",
      "2072it [02:46,  4.99it/s]\n",
      "\n",
      "2074it [02:46,  6.38it/s]\n",
      "\n",
      "2075it [02:46,  5.79it/s]\n",
      "\n",
      "2077it [02:47,  6.30it/s]\n",
      "\n",
      "2078it [02:47,  5.83it/s]\n",
      "\n",
      "2079it [02:47,  5.28it/s]\n",
      "\n",
      "2081it [02:47,  5.84it/s]\n",
      "\n",
      "2082it [02:48,  5.37it/s]\n",
      "\n",
      "2083it [02:48,  5.28it/s]\n",
      "\n",
      "2084it [02:48,  5.11it/s]\n",
      "\n",
      "2085it [02:48,  4.72it/s]\n",
      "\n",
      "2086it [02:48,  4.79it/s]\n",
      "\n",
      "2088it [02:49,  5.41it/s]\n",
      "\n",
      "2089it [02:49,  5.28it/s]\n",
      "\n",
      "2090it [02:49,  5.15it/s]\n",
      "\n",
      "2092it [02:49,  5.69it/s]\n",
      "\n",
      "2093it [02:50,  5.36it/s]\n",
      "\n",
      "2095it [02:50,  5.81it/s]\n",
      "\n",
      "2097it [02:50,  6.25it/s]\n",
      "\n",
      "2098it [02:50,  5.72it/s]\n",
      "\n",
      "2100it [02:51,  6.20it/s]\n",
      "\n",
      "2101it [02:51,  5.68it/s]\n",
      "\n",
      "2103it [02:51,  6.17it/s]\n",
      "\n",
      "2105it [02:51,  6.59it/s]\n",
      "\n",
      "2106it [02:51,  5.97it/s]\n",
      "\n",
      "2107it [02:52,  5.51it/s]\n",
      "\n",
      "2108it [02:52,  5.29it/s]\n",
      "\n",
      "2110it [02:52,  5.85it/s]\n",
      "\n",
      "2112it [02:52,  6.31it/s]\n",
      "\n",
      "2114it [02:53,  6.69it/s]\n",
      "\n",
      "2115it [02:53,  6.02it/s]\n",
      "\n",
      "2117it [02:53,  7.41it/s]\n",
      "\n",
      "2119it [02:53,  7.58it/s]\n",
      "\n",
      "2120it [02:53,  6.44it/s]\n",
      "\n",
      "2121it [02:54,  5.89it/s]\n",
      "\n",
      "2123it [02:54,  6.35it/s]\n",
      "\n",
      "2124it [02:54,  5.81it/s]\n",
      "\n",
      "2125it [02:54,  5.51it/s]\n",
      "\n",
      "2127it [02:55,  5.97it/s]\n",
      "\n",
      "2128it [02:55,  5.53it/s]\n",
      "\n",
      "2129it [02:55,  5.33it/s]\n",
      "\n",
      "2130it [02:55,  5.19it/s]\n",
      "\n",
      "2132it [02:55,  6.55it/s]\n",
      "\n",
      "2133it [02:56,  5.90it/s]\n",
      "\n",
      "2134it [02:56,  5.49it/s]\n",
      "\n",
      "2136it [02:56,  5.91it/s]\n",
      "\n",
      "2137it [02:56,  5.48it/s]\n",
      "\n",
      "2138it [02:56,  5.31it/s]\n",
      "\n",
      "2140it [02:57,  5.79it/s]\n",
      "\n",
      "2141it [02:57,  5.58it/s]\n",
      "\n",
      "2142it [02:57,  5.31it/s]\n",
      "\n",
      "2143it [02:57,  5.15it/s]\n",
      "\n",
      "2145it [02:58,  5.71it/s]\n",
      "\n",
      "2146it [02:58,  5.41it/s]\n",
      "\n",
      "2147it [02:58,  5.23it/s]\n",
      "\n",
      "2149it [02:58,  5.79it/s]\n",
      "\n",
      "2151it [02:58,  7.25it/s]\n",
      "\n",
      "2153it [02:59,  7.35it/s]\n",
      "\n",
      "2154it [02:59,  6.26it/s]\n",
      "\n",
      "2156it [02:59,  6.58it/s]\n",
      "\n",
      "2158it [02:59,  8.05it/s]\n",
      "\n",
      "2160it [03:00,  7.81it/s]\n",
      "\n",
      "2161it [03:00,  6.51it/s]\n",
      "\n",
      "2163it [03:00,  8.11it/s]\n",
      "\n",
      "2165it [03:00,  6.75it/s]\n",
      "\n",
      "2167it [03:00,  8.23it/s]\n",
      "\n",
      "2169it [03:01,  6.74it/s]\n",
      "\n",
      "2170it [03:01,  6.01it/s]\n",
      "\n",
      "2171it [03:01,  5.49it/s]\n",
      "\n",
      "2172it [03:01,  5.28it/s]\n",
      "\n",
      "2173it [03:02,  5.05it/s]\n",
      "\n",
      "2174it [03:02,  4.98it/s]\n",
      "\n",
      "2176it [03:02,  5.52it/s]\n",
      "\n",
      "2178it [03:02,  6.01it/s]\n",
      "\n",
      "2179it [03:03,  5.56it/s]\n",
      "\n",
      "2180it [03:03,  5.28it/s]\n",
      "\n",
      "2182it [03:03,  6.64it/s]\n",
      "\n",
      "2183it [03:03,  5.84it/s]\n",
      "\n",
      "2184it [03:03,  5.44it/s]\n",
      "\n",
      "2186it [03:04,  5.75it/s]\n",
      "\n",
      "2187it [03:04,  5.40it/s]\n",
      "\n",
      "2188it [03:04,  5.13it/s]\n",
      "\n",
      "2189it [03:04,  5.02it/s]\n",
      "\n",
      "2191it [03:04,  6.35it/s]\n",
      "\n",
      "2192it [03:05,  5.78it/s]\n",
      "\n",
      "2193it [03:05,  5.36it/s]\n",
      "\n",
      "2194it [03:05,  5.00it/s]\n",
      "\n",
      "2195it [03:05,  4.79it/s]\n",
      "\n",
      "2196it [03:06,  4.75it/s]\n",
      "\n",
      "2198it [03:06,  5.33it/s]\n",
      "\n",
      "2199it [03:06,  5.10it/s]\n",
      "\n",
      "2200it [03:06,  4.97it/s]\n",
      "\n",
      "2201it [03:06,  4.88it/s]\n",
      "\n",
      "2202it [03:07,  4.81it/s]\n",
      "\n",
      "2204it [03:07,  5.39it/s]\n",
      "\n",
      "2205it [03:07,  5.18it/s]\n",
      "\n",
      "2206it [03:07,  5.02it/s]\n",
      "\n",
      "2207it [03:08,  4.89it/s]\n",
      "\n",
      "2208it [03:08,  4.78it/s]\n",
      "\n",
      "2209it [03:08,  4.80it/s]\n",
      "\n",
      "2210it [03:08,  4.78it/s]\n",
      "\n",
      "2211it [03:08,  4.75it/s]\n",
      "\n",
      "2212it [03:09,  4.73it/s]\n",
      "\n",
      "2213it [03:09,  4.75it/s]\n",
      "\n",
      "2214it [03:09,  4.71it/s]\n",
      "\n",
      "2215it [03:09,  4.70it/s]\n",
      "\n",
      "2216it [03:09,  4.70it/s]\n",
      "\n",
      "2217it [03:10,  4.67it/s]\n",
      "\n",
      "2219it [03:10,  5.27it/s]\n",
      "\n",
      "2220it [03:10,  5.04it/s]\n",
      "\n",
      "2221it [03:10,  4.91it/s]\n",
      "\n",
      "2222it [03:11,  4.84it/s]\n",
      "\n",
      "2223it [03:11,  4.80it/s]\n",
      "\n",
      "2224it [03:11,  4.72it/s]\n",
      "\n",
      "2225it [03:11,  4.68it/s]\n",
      "\n",
      "2226it [03:11,  4.63it/s]\n",
      "\n",
      "2227it [03:12,  4.63it/s]\n",
      "\n",
      "2228it [03:12,  4.65it/s]\n",
      "\n",
      "2229it [03:12,  4.68it/s]\n",
      "\n",
      "2230it [03:12,  4.67it/s]\n",
      "\n",
      "2232it [03:13,  5.21it/s]\n",
      "\n",
      "2234it [03:13,  5.71it/s]\n",
      "\n",
      "2235it [03:13,  5.17it/s]\n",
      "\n",
      "2236it [03:13,  4.97it/s]\n",
      "\n",
      "2237it [03:14,  4.86it/s]\n",
      "\n",
      "2238it [03:14,  4.81it/s]\n",
      "\n",
      "2239it [03:14,  4.77it/s]\n",
      "\n",
      "2240it [03:14,  4.71it/s]\n",
      "\n",
      "2241it [03:14,  4.67it/s]\n",
      "\n",
      "2243it [03:15,  5.96it/s]\n",
      "\n",
      "2245it [03:15,  7.40it/s]\n",
      "\n",
      "2247it [03:15,  7.38it/s]\n",
      "\n",
      "2248it [03:15,  6.02it/s]\n",
      "\n",
      "2249it [03:15,  5.52it/s]\n",
      "\n",
      "2251it [03:16,  6.73it/s]\n",
      "\n",
      "2252it [03:16,  5.89it/s]\n",
      "\n",
      "2254it [03:16,  6.21it/s]\n",
      "\n",
      "2255it [03:16,  5.61it/s]\n",
      "\n",
      "2256it [03:16,  5.27it/s]\n",
      "\n",
      "2257it [03:17,  5.04it/s]\n",
      "\n",
      "2258it [03:17,  4.95it/s]\n",
      "\n",
      "2259it [03:17,  4.82it/s]\n",
      "\n",
      "2261it [03:17,  6.13it/s]\n",
      "\n",
      "2263it [03:17,  7.59it/s]\n",
      "\n",
      "2265it [03:17,  9.10it/s]\n",
      "\n",
      "2267it [03:18,  6.97it/s]\n",
      "\n",
      "2269it [03:18,  6.97it/s]\n",
      "\n",
      "2270it [03:18,  5.98it/s]\n",
      "\n",
      "2271it [03:19,  5.44it/s]\n",
      "\n",
      "2273it [03:19,  6.73it/s]\n",
      "\n",
      "2275it [03:19,  6.79it/s]\n",
      "\n",
      "2276it [03:19,  5.91it/s]\n",
      "\n",
      "2277it [03:19,  5.38it/s]\n",
      "\n",
      "2278it [03:20,  5.09it/s]\n",
      "\n",
      "2280it [03:20,  6.40it/s]\n",
      "\n",
      "2281it [03:20,  5.67it/s]\n",
      "\n",
      "2282it [03:20,  5.31it/s]\n",
      "\n",
      "2283it [03:21,  5.02it/s]\n",
      "\n",
      "2284it [03:21,  4.82it/s]\n",
      "\n",
      "2285it [03:21,  4.74it/s]\n",
      "\n",
      "2286it [03:21,  4.60it/s]\n",
      "\n",
      "2287it [03:21,  4.53it/s]\n",
      "\n",
      "2288it [03:22,  4.50it/s]\n",
      "\n",
      "2289it [03:22,  4.55it/s]\n",
      "\n",
      "2290it [03:22,  4.51it/s]\n",
      "\n",
      "2292it [03:22,  5.74it/s]\n",
      "\n",
      "2293it [03:22,  5.27it/s]\n",
      "\n",
      "2294it [03:23,  4.96it/s]\n",
      "\n",
      "2296it [03:23,  6.28it/s]\n",
      "\n",
      "2297it [03:23,  5.59it/s]\n",
      "\n",
      "2299it [03:23,  6.94it/s]\n",
      "\n",
      "2301it [03:24,  6.01it/s]\n",
      "\n",
      "2302it [03:24,  5.42it/s]\n",
      "\n",
      "2304it [03:24,  6.77it/s]\n",
      "\n",
      "2305it [03:24,  5.90it/s]\n",
      "\n",
      "2306it [03:24,  5.38it/s]\n",
      "\n",
      "2307it [03:25,  5.08it/s]\n",
      "\n",
      "2309it [03:25,  5.52it/s]\n",
      "\n",
      "2310it [03:25,  5.13it/s]\n",
      "\n",
      "2312it [03:25,  5.56it/s]\n",
      "\n",
      "2313it [03:26,  5.06it/s]\n",
      "\n",
      "2314it [03:26,  4.81it/s]\n",
      "\n",
      "2315it [03:26,  4.49it/s]\n",
      "\n",
      "2316it [03:26,  4.37it/s]\n",
      "\n",
      "2317it [03:27,  4.28it/s]\n",
      "\n",
      "2318it [03:27,  4.24it/s]\n",
      "\n",
      "2320it [03:27,  5.43it/s]\n",
      "\n",
      "2322it [03:27,  6.72it/s]\n",
      "\n",
      "2323it [03:27,  5.67it/s]\n",
      "\n",
      "2324it [03:28,  4.96it/s]\n",
      "\n",
      "2325it [03:28,  4.64it/s]\n",
      "\n",
      "2327it [03:28,  4.83it/s]\n",
      "\n",
      "2328it [03:28,  4.54it/s]\n",
      "\n",
      "2329it [03:29,  4.34it/s]\n",
      "\n",
      "2331it [03:29,  4.85it/s]\n",
      "\n",
      "2333it [03:29,  5.25it/s]\n",
      "\n",
      "2335it [03:30,  5.63it/s]\n",
      "\n",
      "2336it [03:30,  5.11it/s]\n",
      "\n",
      "2338it [03:30,  5.49it/s]\n",
      "\n",
      "2340it [03:30,  6.84it/s]\n",
      "\n",
      "2342it [03:31,  6.91it/s]\n",
      "\n",
      "2343it [03:31,  5.82it/s]\n",
      "\n",
      "2344it [03:31,  5.26it/s]\n",
      "\n",
      "2345it [03:31,  4.94it/s]\n",
      "\n",
      "2347it [03:31,  6.25it/s]\n",
      "\n",
      "2349it [03:32,  7.66it/s]\n",
      "\n",
      "2351it [03:32,  7.30it/s]\n",
      "\n",
      "2352it [03:32,  6.18it/s]\n",
      "\n",
      "2353it [03:32,  5.52it/s]\n",
      "\n",
      "2354it [03:33,  5.14it/s]\n",
      "\n",
      "2355it [03:33,  4.92it/s]\n",
      "\n",
      "2356it [03:33,  4.69it/s]\n",
      "\n",
      "2358it [03:33,  5.93it/s]\n",
      "\n",
      "2360it [03:33,  6.19it/s]\n",
      "\n",
      "2361it [03:34,  5.39it/s]\n",
      "\n",
      "2363it [03:34,  5.72it/s]\n",
      "\n",
      "2364it [03:34,  5.07it/s]\n",
      "\n",
      "2365it [03:34,  4.80it/s]\n",
      "\n",
      "2367it [03:35,  6.04it/s]\n",
      "\n",
      "2368it [03:35,  5.46it/s]\n",
      "\n",
      "2369it [03:35,  4.89it/s]\n",
      "\n",
      "2370it [03:35,  4.74it/s]\n",
      "\n",
      "2371it [03:35,  4.47it/s]\n",
      "\n",
      "2372it [03:36,  4.39it/s]\n",
      "\n",
      "2374it [03:36,  4.82it/s]\n",
      "\n",
      "2375it [03:36,  4.52it/s]\n",
      "\n",
      "2377it [03:37,  5.05it/s]\n",
      "\n",
      "2379it [03:37,  6.29it/s]\n",
      "\n",
      "2380it [03:37,  5.54it/s]\n",
      "\n",
      "2381it [03:37,  5.11it/s]\n",
      "\n",
      "2382it [03:37,  4.88it/s]\n",
      "\n",
      "2384it [03:38,  5.23it/s]\n",
      "\n",
      "2385it [03:38,  4.98it/s]\n",
      "\n",
      "2387it [03:38,  6.27it/s]\n",
      "\n",
      "2388it [03:38,  5.50it/s]\n",
      "\n",
      "2389it [03:39,  5.04it/s]\n",
      "\n",
      "2390it [03:39,  4.81it/s]\n",
      "\n",
      "2392it [03:39,  5.29it/s]\n",
      "\n",
      "2393it [03:39,  4.99it/s]\n",
      "\n",
      "2395it [03:40,  5.42it/s]\n",
      "\n",
      "2397it [03:40,  5.78it/s]\n",
      "\n",
      "2399it [03:40,  7.10it/s]\n",
      "\n",
      "2400it [03:40,  5.82it/s]\n",
      "\n",
      "2402it [03:41,  5.97it/s]\n",
      "\n",
      "2403it [03:41,  5.36it/s]\n",
      "\n",
      "2405it [03:41,  5.77it/s]\n",
      "\n",
      "2406it [03:41,  5.11it/s]\n",
      "\n",
      "2408it [03:41,  6.41it/s]\n",
      "\n",
      "2410it [03:42,  6.58it/s]\n",
      "\n",
      "2411it [03:42,  5.70it/s]\n",
      "\n",
      "2413it [03:42,  6.03it/s]\n",
      "\n",
      "2414it [03:43,  5.40it/s]\n",
      "\n",
      "2415it [03:43,  5.02it/s]\n",
      "\n",
      "2417it [03:43,  5.46it/s]\n",
      "\n",
      "2418it [03:43,  5.03it/s]\n",
      "\n",
      "2420it [03:43,  6.32it/s]\n",
      "\n",
      "2421it [03:44,  5.52it/s]\n",
      "\n",
      "2422it [03:44,  5.13it/s]\n",
      "\n",
      "2423it [03:44,  4.83it/s]\n",
      "\n",
      "2424it [03:44,  4.62it/s]\n",
      "\n",
      "2425it [03:45,  4.52it/s]\n",
      "\n",
      "2426it [03:45,  4.41it/s]\n",
      "\n",
      "2427it [03:45,  4.37it/s]\n",
      "\n",
      "2428it [03:45,  4.38it/s]\n",
      "\n",
      "2429it [03:45,  4.36it/s]\n",
      "\n",
      "2430it [03:46,  4.32it/s]\n",
      "\n",
      "2431it [03:46,  4.35it/s]\n",
      "\n",
      "2433it [03:46,  4.87it/s]\n",
      "\n",
      "2434it [03:46,  4.67it/s]\n",
      "\n",
      "2435it [03:47,  4.53it/s]\n",
      "\n",
      "2436it [03:47,  4.37it/s]\n",
      "\n",
      "2437it [03:47,  4.30it/s]\n",
      "\n",
      "2438it [03:47,  4.29it/s]\n",
      "\n",
      "2439it [03:48,  4.27it/s]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2440it [03:48,  4.29it/s]\n",
      "\n",
      "2442it [03:48,  4.79it/s]\n",
      "\n",
      "2443it [03:48,  4.59it/s]\n",
      "\n",
      "2444it [03:49,  4.39it/s]\n",
      "\n",
      "2445it [03:49,  4.32it/s]\n",
      "\n",
      "2446it [03:49,  4.17it/s]\n",
      "\n",
      "2448it [03:49,  5.36it/s]\n",
      "\n",
      "2449it [03:50,  4.85it/s]\n",
      "\n",
      "2450it [03:50,  4.64it/s]\n",
      "\n",
      "2451it [03:50,  4.37it/s]\n",
      "\n",
      "2452it [03:50,  4.30it/s]\n",
      "\n",
      "2453it [03:51,  4.30it/s]\n",
      "\n",
      "2454it [03:51,  4.27it/s]\n",
      "\n",
      "2455it [03:51,  4.26it/s]\n",
      "\n",
      "2456it [03:51,  4.24it/s]\n",
      "\n",
      "2457it [03:52,  4.18it/s]\n",
      "\n",
      "2458it [03:52,  4.18it/s]\n",
      "\n",
      "2460it [03:52,  4.70it/s]\n",
      "\n",
      "2461it [03:52,  4.51it/s]\n",
      "\n",
      "2462it [03:53,  4.38it/s]\n",
      "\n",
      "2463it [03:53,  4.29it/s]\n",
      "\n",
      "2465it [03:53,  4.70it/s]\n",
      "\n",
      "2467it [03:53,  5.14it/s]\n",
      "\n",
      "2468it [03:54,  4.79it/s]\n",
      "\n",
      "2469it [03:54,  4.53it/s]\n",
      "\n",
      "2471it [03:54,  4.91it/s]\n",
      "\n",
      "2472it [03:54,  4.63it/s]\n",
      "\n",
      "2473it [03:55,  4.38it/s]\n",
      "\n",
      "2474it [03:55,  4.34it/s]\n",
      "\n",
      "2475it [03:55,  4.27it/s]\n",
      "\n",
      "2476it [03:55,  4.25it/s]\n",
      "\n",
      "2477it [03:56,  4.20it/s]\n",
      "\n",
      "2478it [03:56,  4.24it/s]\n",
      "\n",
      "2479it [03:56,  4.18it/s]\n",
      "\n",
      "2480it [03:56,  4.22it/s]\n",
      "\n",
      "2481it [03:57,  4.22it/s]\n",
      "\n",
      "2482it [03:57,  4.18it/s]\n",
      "\n",
      "2483it [03:57,  4.14it/s]\n",
      "\n",
      "2484it [03:57,  4.11it/s]\n",
      "\n",
      "2486it [03:58,  5.27it/s]\n",
      "\n",
      "2487it [03:58,  4.84it/s]\n",
      "\n",
      "2488it [03:58,  4.63it/s]\n",
      "\n",
      "2490it [03:58,  5.84it/s]\n",
      "\n",
      "2491it [03:58,  5.14it/s]\n",
      "\n",
      "2492it [03:59,  4.85it/s]\n",
      "\n",
      "2493it [03:59,  4.60it/s]\n",
      "\n",
      "2494it [03:59,  4.48it/s]\n",
      "\n",
      "2495it [03:59,  4.35it/s]\n",
      "\n",
      "2497it [03:59,  5.53it/s]\n",
      "\n",
      "2498it [04:00,  4.93it/s]\n",
      "\n",
      "2500it [04:00,  6.24it/s]\n",
      "\n",
      "2501it [04:00,  5.47it/s]\n",
      "\n",
      "2503it [04:00,  5.76it/s]\n",
      "\n",
      "2505it [04:01,  5.96it/s]\n",
      "\n",
      "2506it [04:01,  5.18it/s]\n",
      "\n",
      "2507it [04:01,  4.74it/s]\n",
      "\n",
      "2509it [04:02,  5.17it/s]\n",
      "\n",
      "2510it [04:02,  4.75it/s]\n",
      "\n",
      "2511it [04:02,  4.54it/s]\n",
      "\n",
      "2512it [04:02,  4.43it/s]\n",
      "\n",
      "2513it [04:02,  4.35it/s]\n",
      "\n",
      "2515it [04:03,  5.53it/s]\n",
      "\n",
      "2516it [04:03,  4.94it/s]\n",
      "\n",
      "2517it [04:03,  4.67it/s]\n",
      "\n",
      "2519it [04:03,  5.10it/s]\n",
      "\n",
      "2521it [04:04,  5.42it/s]\n",
      "\n",
      "2522it [04:04,  5.05it/s]\n",
      "\n",
      "2524it [04:04,  5.28it/s]\n",
      "\n",
      "2526it [04:04,  6.61it/s]\n",
      "\n",
      "2527it [04:05,  5.58it/s]\n",
      "\n",
      "2528it [04:05,  5.08it/s]\n",
      "\n",
      "2529it [04:05,  4.73it/s]\n",
      "\n",
      "2530it [04:05,  4.50it/s]\n",
      "\n",
      "2532it [04:06,  5.70it/s]\n",
      "\n",
      "2534it [04:06,  5.96it/s]\n",
      "\n",
      "2535it [04:06,  5.26it/s]\n",
      "\n",
      "2536it [04:06,  4.80it/s]\n",
      "\n",
      "2537it [04:07,  4.50it/s]\n",
      "\n",
      "2539it [04:07,  4.98it/s]\n",
      "\n",
      "2540it [04:07,  4.68it/s]\n",
      "\n",
      "2541it [04:07,  4.45it/s]\n",
      "\n",
      "2542it [04:08,  4.33it/s]\n",
      "\n",
      "2543it [04:08,  4.26it/s]\n",
      "\n",
      "2544it [04:08,  4.21it/s]\n",
      "\n",
      "2545it [04:08,  4.15it/s]\n",
      "\n",
      "2546it [04:09,  4.11it/s]\n",
      "\n",
      "2548it [04:09,  4.61it/s]\n",
      "\n",
      "2550it [04:09,  4.97it/s]\n",
      "\n",
      "2551it [04:09,  4.64it/s]\n",
      "\n",
      "2552it [04:10,  4.43it/s]\n",
      "\n",
      "2553it [04:10,  4.31it/s]\n",
      "\n",
      "2554it [04:10,  4.21it/s]\n",
      "\n",
      "2556it [04:11,  4.71it/s]\n",
      "\n",
      "2558it [04:11,  5.11it/s]\n",
      "\n",
      "2560it [04:11,  6.37it/s]\n",
      "\n",
      "2561it [04:11,  5.41it/s]\n",
      "\n",
      "2563it [04:12,  5.68it/s]\n",
      "\n",
      "2564it [04:12,  5.09it/s]\n",
      "\n",
      "2565it [04:12,  4.71it/s]\n",
      "\n",
      "2567it [04:12,  5.10it/s]\n",
      "\n",
      "2568it [04:13,  4.60it/s]\n",
      "\n",
      "2570it [04:13,  4.96it/s]\n",
      "\n",
      "2571it [04:13,  4.36it/s]\n",
      "\n",
      "2573it [04:14,  4.83it/s]\n",
      "\n",
      "2574it [04:14,  4.57it/s]\n",
      "\n",
      "2575it [04:14,  4.44it/s]\n",
      "\n",
      "2576it [04:14,  4.18it/s]\n",
      "\n",
      "2577it [04:15,  4.14it/s]\n",
      "\n",
      "2579it [04:15,  4.54it/s]\n",
      "\n",
      "2580it [04:15,  4.33it/s]\n",
      "\n",
      "2582it [04:15,  5.48it/s]\n",
      "\n",
      "2584it [04:16,  5.64it/s]\n",
      "\n",
      "2586it [04:16,  5.78it/s]\n",
      "\n",
      "2587it [04:16,  4.95it/s]\n",
      "\n",
      "2588it [04:16,  4.64it/s]\n",
      "\n",
      "2589it [04:17,  4.40it/s]\n",
      "\n",
      "2591it [04:17,  4.90it/s]\n",
      "\n",
      "2592it [04:17,  4.58it/s]\n",
      "\n",
      "2593it [04:18,  4.36it/s]\n",
      "\n",
      "2595it [04:18,  4.82it/s]\n",
      "\n",
      "2596it [04:18,  4.34it/s]\n",
      "\n",
      "2598it [04:18,  4.79it/s]\n",
      "\n",
      "2599it [04:19,  4.48it/s]\n",
      "\n",
      "2601it [04:19,  4.94it/s]\n",
      "\n",
      "2603it [04:19,  5.31it/s]\n",
      "\n",
      "2605it [04:19,  6.55it/s]\n",
      "\n",
      "2606it [04:20,  5.47it/s]\n",
      "\n",
      "2607it [04:20,  4.89it/s]\n",
      "\n",
      "2609it [04:20,  6.07it/s]\n",
      "\n",
      "2610it [04:20,  5.25it/s]\n",
      "\n",
      "2612it [04:21,  5.53it/s]\n",
      "\n",
      "2613it [04:21,  4.95it/s]\n",
      "\n",
      "2614it [04:21,  4.59it/s]\n",
      "\n",
      "2615it [04:21,  4.40it/s]\n",
      "\n",
      "2616it [04:22,  4.23it/s]\n",
      "\n",
      "2617it [04:22,  4.17it/s]\n",
      "\n",
      "2618it [04:22,  4.08it/s]\n",
      "\n",
      "2619it [04:22,  4.04it/s]\n",
      "\n",
      "2620it [04:23,  4.01it/s]\n",
      "\n",
      "2621it [04:23,  4.02it/s]\n",
      "\n",
      "2623it [04:23,  4.50it/s]\n",
      "\n",
      "2624it [04:24,  4.31it/s]\n",
      "\n",
      "2625it [04:24,  4.15it/s]\n",
      "\n",
      "2627it [04:24,  5.30it/s]\n",
      "\n",
      "2628it [04:24,  4.79it/s]\n",
      "\n",
      "2629it [04:24,  4.50it/s]\n",
      "\n",
      "2630it [04:25,  4.32it/s]\n",
      "\n",
      "2631it [04:25,  4.20it/s]\n",
      "\n",
      "2632it [04:25,  4.05it/s]\n",
      "\n",
      "2633it [04:25,  3.97it/s]\n",
      "\n",
      "2634it [04:26,  3.96it/s]\n",
      "\n",
      "2636it [04:26,  5.07it/s]\n",
      "\n",
      "2638it [04:26,  5.26it/s]\n",
      "\n",
      "2640it [04:27,  5.45it/s]\n",
      "\n",
      "2642it [04:27,  6.69it/s]\n",
      "\n",
      "2643it [04:27,  5.36it/s]\n",
      "\n",
      "2644it [04:27,  4.70it/s]\n",
      "\n",
      "2646it [04:28,  5.06it/s]\n",
      "\n",
      "2647it [04:28,  4.47it/s]\n",
      "\n",
      "2649it [04:28,  4.89it/s]\n",
      "\n",
      "2650it [04:28,  4.56it/s]\n",
      "\n",
      "2651it [04:29,  4.33it/s]\n",
      "\n",
      "2653it [04:29,  4.75it/s]\n",
      "\n",
      "2654it [04:29,  4.48it/s]\n",
      "\n",
      "2655it [04:30,  4.13it/s]\n",
      "\n",
      "2657it [04:30,  4.62it/s]\n",
      "\n",
      "2658it [04:30,  4.38it/s]\n",
      "\n",
      "2659it [04:30,  4.22it/s]\n",
      "\n",
      "2660it [04:31,  4.10it/s]\n",
      "\n",
      "2661it [04:31,  4.04it/s]\n",
      "\n",
      "2662it [04:31,  3.99it/s]\n",
      "\n",
      "2663it [04:31,  3.95it/s]\n",
      "\n",
      "2664it [04:32,  3.93it/s]\n",
      "\n",
      "2665it [04:32,  3.91it/s]\n",
      "\n",
      "2666it [04:32,  3.91it/s]\n",
      "\n",
      "2667it [04:32,  3.88it/s]\n",
      "\n",
      "2669it [04:33,  4.98it/s]\n",
      "\n",
      "2670it [04:33,  4.56it/s]\n",
      "\n",
      "2671it [04:33,  4.33it/s]\n",
      "\n",
      "2673it [04:33,  4.74it/s]\n",
      "\n",
      "2674it [04:34,  4.41it/s]\n",
      "\n",
      "2675it [04:34,  4.19it/s]\n",
      "\n",
      "2676it [04:34,  4.03it/s]\n",
      "\n",
      "2678it [04:34,  5.14it/s]\n",
      "\n",
      "2680it [04:35,  6.28it/s]\n",
      "\n",
      "2682it [04:35,  7.58it/s]\n",
      "\n",
      "2684it [04:35,  6.99it/s]\n",
      "\n",
      "2685it [04:35,  5.44it/s]\n",
      "\n",
      "2686it [04:36,  4.73it/s]\n",
      "\n",
      "2687it [04:36,  4.39it/s]\n",
      "\n",
      "2688it [04:36,  4.18it/s]\n",
      "\n",
      "2689it [04:36,  3.92it/s]\n",
      "\n",
      "2690it [04:37,  3.88it/s]\n",
      "\n",
      "2692it [04:37,  4.90it/s]\n",
      "\n",
      "2693it [04:37,  4.54it/s]\n",
      "\n",
      "2694it [04:37,  4.27it/s]\n",
      "\n",
      "2695it [04:38,  4.14it/s]\n",
      "\n",
      "2697it [04:38,  5.24it/s]\n",
      "\n",
      "2699it [04:38,  6.53it/s]\n",
      "\n",
      "2700it [04:38,  5.41it/s]\n",
      "\n",
      "2701it [04:38,  4.84it/s]\n",
      "\n",
      "2702it [04:39,  4.50it/s]\n",
      "\n",
      "2703it [04:39,  4.26it/s]\n",
      "\n",
      "2704it [04:39,  4.13it/s]\n",
      "\n",
      "2706it [04:39,  4.58it/s]\n",
      "\n",
      "2708it [04:40,  4.94it/s]\n",
      "\n",
      "2709it [04:40,  4.55it/s]\n",
      "\n",
      "2710it [04:40,  4.30it/s]\n",
      "\n",
      "2711it [04:41,  4.16it/s]\n",
      "\n",
      "2713it [04:41,  5.26it/s]\n",
      "\n",
      "2714it [04:41,  4.73it/s]\n",
      "\n",
      "2715it [04:41,  4.38it/s]\n",
      "\n",
      "2716it [04:42,  4.16it/s]\n",
      "\n",
      "2717it [04:42,  3.78it/s]\n",
      "\n",
      "2719it [04:42,  4.18it/s]\n",
      "\n",
      "2721it [04:42,  5.24it/s]\n",
      "\n",
      "2722it [04:43,  4.71it/s]\n",
      "\n",
      "2724it [04:43,  4.94it/s]\n",
      "\n",
      "2725it [04:43,  4.50it/s]\n",
      "\n",
      "2727it [04:44,  4.89it/s]\n",
      "\n",
      "2728it [04:44,  4.54it/s]\n",
      "\n",
      "2729it [04:44,  4.32it/s]\n",
      "\n",
      "2730it [04:44,  4.16it/s]\n",
      "\n",
      "2731it [04:45,  4.06it/s]\n",
      "\n",
      "2732it [04:45,  3.99it/s]\n",
      "\n",
      "2734it [04:45,  5.08it/s]\n",
      "\n",
      "2735it [04:45,  4.60it/s]\n",
      "\n",
      "2736it [04:46,  4.34it/s]\n",
      "\n",
      "2737it [04:46,  4.16it/s]\n",
      "\n",
      "2738it [04:46,  4.04it/s]\n",
      "\n",
      "2740it [04:46,  5.14it/s]\n",
      "\n",
      "2742it [04:46,  6.35it/s]\n",
      "\n",
      "2743it [04:47,  5.24it/s]\n",
      "\n",
      "2744it [04:47,  4.71it/s]\n",
      "\n",
      "2746it [04:47,  5.04it/s]\n",
      "\n",
      "2747it [04:47,  4.58it/s]\n",
      "\n",
      "2748it [04:48,  4.23it/s]\n",
      "\n",
      "2749it [04:48,  4.03it/s]\n",
      "\n",
      "2751it [04:48,  5.09it/s]\n",
      "\n",
      "2752it [04:48,  4.56it/s]\n",
      "\n",
      "2753it [04:49,  4.24it/s]\n",
      "\n",
      "2755it [04:49,  5.39it/s]\n",
      "\n",
      "2756it [04:49,  4.80it/s]\n",
      "\n",
      "2757it [04:49,  4.45it/s]\n",
      "\n",
      "2758it [04:50,  4.20it/s]\n",
      "\n",
      "2760it [04:50,  5.34it/s]\n",
      "\n",
      "2762it [04:50,  6.59it/s]\n",
      "\n",
      "2763it [04:50,  5.40it/s]\n",
      "\n",
      "2764it [04:50,  4.77it/s]\n",
      "\n",
      "2765it [04:51,  4.39it/s]\n",
      "\n",
      "2766it [04:51,  4.18it/s]\n",
      "\n",
      "2768it [04:51,  4.60it/s]\n",
      "\n",
      "2769it [04:52,  4.29it/s]\n",
      "\n",
      "2771it [04:52,  4.71it/s]\n",
      "\n",
      "2772it [04:52,  4.28it/s]\n",
      "\n",
      "2773it [04:53,  4.09it/s]\n",
      "\n",
      "2774it [04:53,  3.95it/s]\n",
      "\n",
      "2775it [04:53,  3.89it/s]\n",
      "\n",
      "2776it [04:53,  3.86it/s]\n",
      "\n",
      "2777it [04:54,  3.81it/s]\n",
      "\n",
      "2778it [04:54,  3.81it/s]\n",
      "\n",
      "2780it [04:54,  4.84it/s]\n",
      "\n",
      "2781it [04:54,  4.45it/s]\n",
      "\n",
      "2782it [04:55,  4.19it/s]\n",
      "\n",
      "2784it [04:55,  5.28it/s]\n",
      "\n",
      "2785it [04:55,  4.71it/s]\n",
      "\n",
      "2786it [04:55,  4.36it/s]\n",
      "\n",
      "2788it [04:56,  4.72it/s]\n",
      "\n",
      "2790it [04:56,  5.01it/s]\n",
      "\n",
      "2791it [04:56,  4.47it/s]\n",
      "\n",
      "2792it [04:56,  4.07it/s]\n",
      "\n",
      "2793it [04:57,  3.91it/s]\n",
      "\n",
      "2794it [04:57,  3.83it/s]\n",
      "\n",
      "2795it [04:57,  3.69it/s]\n",
      "\n",
      "2796it [04:58,  3.69it/s]\n",
      "\n",
      "2797it [04:58,  3.63it/s]\n",
      "\n",
      "2798it [04:58,  3.64it/s]\n",
      "\n",
      "2799it [04:58,  3.59it/s]\n",
      "\n",
      "2801it [04:59,  4.57it/s]\n",
      "\n",
      "2802it [04:59,  4.24it/s]\n",
      "\n",
      "2803it [04:59,  4.07it/s]\n",
      "\n",
      "2804it [04:59,  3.79it/s]\n",
      "\n",
      "2805it [05:00,  3.73it/s]\n",
      "\n",
      "2806it [05:00,  3.70it/s]\n",
      "\n",
      "2808it [05:00,  4.14it/s]\n",
      "\n",
      "2809it [05:01,  3.94it/s]\n",
      "\n",
      "2810it [05:01,  3.80it/s]\n",
      "\n",
      "2811it [05:01,  3.67it/s]\n",
      "\n",
      "2812it [05:01,  3.65it/s]\n",
      "\n",
      "2814it [05:02,  4.61it/s]\n",
      "\n",
      "2816it [05:02,  4.93it/s]\n",
      "\n",
      "2818it [05:02,  5.14it/s]\n",
      "\n",
      "2820it [05:03,  5.37it/s]\n",
      "\n",
      "2821it [05:03,  4.71it/s]\n",
      "\n",
      "2822it [05:03,  4.33it/s]\n",
      "\n",
      "2823it [05:04,  4.06it/s]\n",
      "\n",
      "2825it [05:04,  5.12it/s]\n",
      "\n",
      "2826it [05:04,  4.52it/s]\n",
      "\n",
      "2828it [05:04,  5.62it/s]\n",
      "\n",
      "2829it [05:04,  4.63it/s]\n",
      "\n",
      "2831it [05:05,  4.88it/s]\n",
      "\n",
      "2833it [05:05,  6.01it/s]\n",
      "\n",
      "2834it [05:05,  5.01it/s]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2835it [05:05,  4.47it/s]\n",
      "\n",
      "2836it [05:06,  4.13it/s]\n",
      "\n",
      "2837it [05:06,  4.02it/s]\n",
      "\n",
      "2839it [05:06,  5.11it/s]\n",
      "\n",
      "2840it [05:06,  4.55it/s]\n",
      "\n",
      "2841it [05:07,  4.25it/s]\n",
      "\n",
      "2842it [05:07,  4.10it/s]\n",
      "\n",
      "2844it [05:07,  4.51it/s]\n",
      "\n",
      "2845it [05:08,  4.21it/s]\n",
      "\n",
      "2846it [05:08,  4.04it/s]\n",
      "\n",
      "2847it [05:08,  3.78it/s]\n",
      "\n",
      "2849it [05:09,  4.22it/s]\n",
      "\n",
      "2850it [05:09,  3.84it/s]\n",
      "\n",
      "2851it [05:09,  3.79it/s]\n",
      "\n",
      "2852it [05:09,  3.74it/s]\n",
      "\n",
      "2854it [05:10,  4.18it/s]\n",
      "\n",
      "2855it [05:10,  4.05it/s]\n",
      "\n",
      "2857it [05:10,  5.06it/s]\n",
      "\n",
      "2859it [05:10,  6.22it/s]\n",
      "\n",
      "2861it [05:10,  7.37it/s]\n",
      "\n",
      "2862it [05:11,  5.57it/s]\n",
      "\n",
      "2864it [05:11,  5.69it/s]\n",
      "\n",
      "2865it [05:11,  4.87it/s]\n",
      "\n",
      "2866it [05:12,  4.37it/s]\n",
      "\n",
      "2867it [05:12,  4.12it/s]\n",
      "\n",
      "2869it [05:12,  5.20it/s]\n",
      "\n",
      "2871it [05:12,  6.35it/s]\n",
      "\n",
      "2872it [05:12,  5.15it/s]\n",
      "\n",
      "2873it [05:13,  4.59it/s]\n",
      "\n",
      "2874it [05:13,  4.27it/s]\n",
      "\n",
      "2875it [05:13,  4.03it/s]\n",
      "\n",
      "2876it [05:14,  3.88it/s]\n",
      "\n",
      "2877it [05:14,  3.77it/s]\n",
      "\n",
      "2878it [05:14,  3.69it/s]\n",
      "\n",
      "2879it [05:14,  3.63it/s]\n",
      "\n",
      "2880it [05:15,  3.59it/s]\n",
      "\n",
      "2881it [05:15,  3.62it/s]\n",
      "\n",
      "2883it [05:15,  4.04it/s]\n",
      "\n",
      "2885it [05:16,  4.41it/s]\n",
      "\n",
      "2886it [05:16,  4.10it/s]\n",
      "\n",
      "2887it [05:16,  3.92it/s]\n",
      "\n",
      "2888it [05:17,  3.80it/s]\n",
      "\n",
      "2890it [05:17,  4.22it/s]\n",
      "\n",
      "2891it [05:17,  4.03it/s]\n",
      "\n",
      "2892it [05:17,  3.89it/s]\n",
      "\n",
      "2893it [05:18,  3.77it/s]\n",
      "\n",
      "2894it [05:18,  3.61it/s]\n",
      "\n",
      "2896it [05:18,  4.05it/s]\n",
      "\n",
      "2897it [05:19,  3.90it/s]\n",
      "\n",
      "2898it [05:19,  3.79it/s]\n",
      "\n",
      "2899it [05:19,  3.72it/s]\n",
      "\n",
      "2900it [05:20,  3.63it/s]\n",
      "\n",
      "2901it [05:20,  3.63it/s]\n",
      "\n",
      "2902it [05:20,  3.61it/s]\n",
      "\n",
      "2903it [05:20,  3.59it/s]\n",
      "\n",
      "2904it [05:21,  3.56it/s]\n",
      "\n",
      "2905it [05:21,  3.55it/s]\n",
      "\n",
      "2906it [05:21,  3.52it/s]\n",
      "\n",
      "2907it [05:22,  3.53it/s]\n",
      "\n",
      "2908it [05:22,  3.53it/s]\n",
      "\n",
      "2909it [05:22,  3.53it/s]\n",
      "\n",
      "2911it [05:22,  4.53it/s]\n",
      "\n",
      "2912it [05:23,  4.18it/s]\n",
      "\n",
      "2913it [05:23,  3.96it/s]\n",
      "\n",
      "2914it [05:23,  3.82it/s]\n",
      "\n",
      "2915it [05:23,  3.72it/s]\n",
      "\n",
      "2916it [05:24,  3.63it/s]\n",
      "\n",
      "2917it [05:24,  3.57it/s]\n",
      "\n",
      "2918it [05:24,  3.55it/s]\n",
      "\n",
      "2919it [05:25,  3.54it/s]\n",
      "\n",
      "2920it [05:25,  3.52it/s]\n",
      "\n",
      "2921it [05:25,  3.54it/s]\n",
      "\n",
      "2922it [05:25,  3.53it/s]\n",
      "\n",
      "2923it [05:26,  3.51it/s]\n",
      "\n",
      "2924it [05:26,  3.51it/s]\n",
      "\n",
      "2925it [05:26,  3.52it/s]\n",
      "\n",
      "2927it [05:27,  3.94it/s]\n",
      "\n",
      "2928it [05:27,  3.76it/s]\n",
      "\n",
      "2930it [05:27,  4.16it/s]\n",
      "\n",
      "2932it [05:28,  4.49it/s]\n",
      "\n",
      "2934it [05:28,  5.48it/s]\n",
      "\n",
      "2936it [05:28,  5.55it/s]\n",
      "\n",
      "2937it [05:28,  4.74it/s]\n",
      "\n",
      "2938it [05:29,  4.26it/s]\n",
      "\n",
      "2939it [05:29,  3.96it/s]\n",
      "\n",
      "2940it [05:29,  3.74it/s]\n",
      "\n",
      "2941it [05:30,  3.49it/s]\n",
      "\n",
      "2942it [05:30,  4.33it/s]\n",
      "\n",
      "2943it [05:30,  4.00it/s]\n",
      "\n",
      "2944it [05:30,  3.73it/s]\n",
      "\n",
      "2946it [05:31,  4.06it/s]\n",
      "\n",
      "2947it [05:31,  3.80it/s]\n",
      "\n",
      "2948it [05:31,  3.58it/s]\n",
      "\n",
      "2949it [05:32,  3.49it/s]\n",
      "\n",
      "2950it [05:32,  3.38it/s]\n",
      "\n",
      "2952it [05:32,  4.34it/s]\n",
      "\n",
      "2954it [05:32,  5.34it/s]\n",
      "\n",
      "2955it [05:33,  4.57it/s]\n",
      "\n",
      "2956it [05:33,  4.15it/s]\n",
      "\n",
      "2957it [05:33,  3.91it/s]\n",
      "\n",
      "2959it [05:34,  4.27it/s]\n",
      "\n",
      "2961it [05:34,  4.53it/s]\n",
      "\n",
      "2962it [05:34,  4.14it/s]\n",
      "\n",
      "2964it [05:35,  4.47it/s]\n",
      "\n",
      "2966it [05:35,  4.70it/s]\n",
      "\n",
      "2968it [05:35,  4.89it/s]\n",
      "\n",
      "2969it [05:36,  4.31it/s]\n",
      "\n",
      "2971it [05:36,  4.60it/s]\n",
      "\n",
      "2972it [05:36,  4.15it/s]\n",
      "\n",
      "2973it [05:37,  3.89it/s]\n",
      "\n",
      "2974it [05:37,  3.74it/s]\n",
      "\n",
      "2975it [05:37,  3.62it/s]\n",
      "\n",
      "2976it [05:37,  3.53it/s]\n",
      "\n",
      "2977it [05:38,  3.50it/s]\n",
      "\n",
      "2979it [05:38,  3.92it/s]\n",
      "\n",
      "2980it [05:38,  3.74it/s]\n",
      "\n",
      "2981it [05:39,  3.62it/s]\n",
      "\n",
      "2983it [05:39,  4.03it/s]\n",
      "\n",
      "2984it [05:39,  3.82it/s]\n",
      "\n",
      "2985it [05:40,  3.68it/s]\n",
      "\n",
      "2986it [05:40,  3.60it/s]\n",
      "\n",
      "2988it [05:40,  4.59it/s]\n",
      "\n",
      "2989it [05:40,  3.99it/s]\n",
      "\n",
      "2990it [05:41,  3.78it/s]\n",
      "\n",
      "2991it [05:41,  3.57it/s]\n",
      "\n",
      "2992it [05:41,  4.26it/s]\n",
      "\n",
      "2994it [05:41,  5.29it/s]\n",
      "\n",
      "2996it [05:42,  6.43it/s]\n",
      "\n",
      "2997it [05:42,  5.01it/s]\n",
      "\n",
      "3000it [05:42,  8.75it/s]\n"
     ]
    }
   ],
   "source": [
    "dummy=np.zeros((1,melspectrogram.shape[0],maxlength+27))\n",
    "datadict4 = {'TRAINx1':dummy,'TRAINx2':dummy,'DEVx1':dummy,'DEVx2':dummy,'TESTx1':dummy,'TESTx2':dummy}\n",
    "labeldict4 = {'TRAINx1':[],'TRAINx2':[],'TRAINx1x2':[],'DEVx1':[],'DEVx2':[],'DEVx1x2':[],'TESTx1':[],'TESTx2':[],'TESTx1x2':[]}\n",
    "i=0\n",
    "for path,split,label in tqdm(zip(sdr_df['file'],sdr_df['split'],sdr_df['label'])):\n",
    "    x, sr = librosa.load(path, sr=SAMPLING_RATE)\n",
    "    melspectrogram = extract_melspectrogram(x, sr, num_mels=13)/max_val\n",
    "    data = torch.tensor(np.concatenate((melspectrogram,np.zeros((melspectrogram.shape[0],maxlength-melspectrogram.shape[1]+27))),axis = 1))\n",
    "    data = data.view(1,melspectrogram.shape[0],-1) \n",
    "    datadict4[split+str('x1')]=torch.tensor(np.concatenate((datadict4[split+str('x1')],data),axis=0))\n",
    "    labeldict4[split+str('x1')].append(label)\n",
    "    \n",
    "    noise = np.random.normal(scale=0.001, size=len(x))\n",
    "    x_with_noise = x + noise\n",
    "    melspectrogram1 = extract_melspectrogram(x_with_noise, sr, num_mels=13)/max_val\n",
    "    data1 = torch.tensor(np.concatenate((melspectrogram1,np.zeros((melspectrogram1.shape[0],maxlength-melspectrogram1.shape[1]+27))),axis = 1))## the dimension is made to be 256 so that it works with the maxpooling layers in the architecture.\n",
    "    data1 = data1.view(1,melspectrogram1.shape[0],-1)\n",
    "    datadict4[split+str('x2')]=torch.tensor(np.concatenate((datadict4[split+str('x2')],data1),axis=0))\n",
    "    labeldict4[split+str('x2')].append(label)\n",
    "    labeldict4[split+str('x1x2')].append(1)\n",
    "    \n",
    "    idx=i\n",
    "    index = randint(0, len(sdr_df))\n",
    "    while label==sdr_df['label'].iloc[index]:\n",
    "        index = randint(0, len(sdr_df))\n",
    "        \n",
    "    path2=sdr_df['file'].iloc[index]\n",
    "    split2=sdr_df['split'].iloc[index]\n",
    "    x2, sr2 = librosa.load(path2, sr=SAMPLING_RATE)\n",
    "    noise2 = np.random.normal(scale=0.001, size=len(x2))\n",
    "    x2_w_noise = x2 + noise2\n",
    "    melspectrogram2 = extract_melspectrogram(x2_w_noise, sr2, num_mels=13)/max_val\n",
    "    data2 = torch.tensor(np.concatenate((melspectrogram2,np.zeros((melspectrogram2.shape[0],maxlength-melspectrogram2.shape[1]+27))),axis = 1))\n",
    "    data2 = data2.view(1,melspectrogram2.shape[0],-1) \n",
    "    datadict4[split+str('x1')] = torch.tensor(np.concatenate((datadict4[split+str('x1')],data),axis=0))\n",
    "    labeldict4[split+str('x1')].append(label)\n",
    "    datadict4[split+str('x2')] = torch.tensor(np.concatenate((datadict4[split+str('x2')],data2),axis=0))\n",
    "    labeldict4[split+str('x2')].append(sdr_df['label'].iloc[index])\n",
    "    labeldict4[split+str('x1x2')].append(0)\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 535,
   "id": "96770d8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datax1 = datadict4['TRAINx1'][1:]\n",
    "train_datax2 = datadict4['TRAINx2'][1:]\n",
    "test_datax1 = datadict4['TESTx1'][1:]\n",
    "test_datax2 = datadict4['TESTx2'][1:]\n",
    "val_datax1 = datadict4['DEVx1'][1:]\n",
    "val_datax2 = datadict4['DEVx2'][1:]\n",
    "\n",
    "train_y1 = labeldict4['TRAINx1'] \n",
    "train_y2 = labeldict4['TRAINx2']\n",
    "train_y12 = labeldict4['TRAINx1x2']\n",
    "test_y1 = labeldict4['TESTx1']\n",
    "test_y2 = labeldict4['TESTx2']\n",
    "test_y12 = labeldict4['TESTx1x2']\n",
    "\n",
    "val_y1 = labeldict4['DEVx1']\n",
    "val_y2 = labeldict4['DEVx2'] \n",
    "val_y12 = labeldict4['DEVx1x2'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 536,
   "id": "b6c7d560",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4000, 13, 256])\n",
      "torch.Size([4000, 13, 256])\n",
      "4000\n",
      "4000\n",
      "4000\n",
      "torch.Size([1006, 13, 256])\n",
      "torch.Size([1006, 13, 256])\n",
      "1006\n",
      "1006\n",
      "1006\n",
      "torch.Size([994, 13, 256])\n",
      "torch.Size([994, 13, 256])\n",
      "994\n",
      "994\n",
      "994\n"
     ]
    }
   ],
   "source": [
    "print(train_datax1.shape)\n",
    "print(train_datax2.shape)\n",
    "print(len(train_y1))\n",
    "print(len(train_y2))\n",
    "print(len(train_y12))\n",
    "\n",
    "print(test_datax1.shape)\n",
    "print(test_datax2.shape)\n",
    "print(len(test_y1))\n",
    "print(len(test_y2))\n",
    "print(len(test_y12))\n",
    "\n",
    "print(val_datax1.shape)\n",
    "print(val_datax2.shape)\n",
    "print(len(val_y1))\n",
    "print(len(val_y2))\n",
    "print(len(val_y12))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 537,
   "id": "17db251c",
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_train_dataset = customSiameseDataset(train_datax1,train_datax2, train_y1,train_y2,train_y12)\n",
    "custom_train_loader = customSiameseDataLoader(custom_train_dataset, batch_size=32)\n",
    "traindl = custom_train_loader.loader()\n",
    "\n",
    "custom_test_dataset = customSiameseDataset(test_datax1,test_datax2, test_y1,test_y2,test_y12)\n",
    "custom_test_loader = customSiameseDataLoader(custom_test_dataset, batch_size=503)\n",
    "testdl = custom_test_loader.loader()\n",
    "\n",
    "custom_val_dataset = customSiameseDataset(val_datax1,val_datax2, val_y1,val_y2,val_y12)\n",
    "custom_val_loader = customSiameseDataLoader(custom_val_dataset, batch_size=32)\n",
    "valdl = custom_val_loader.loader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 538,
   "id": "a25ffa65",
   "metadata": {},
   "outputs": [],
   "source": [
    "class siameseModel(nn.Module):\n",
    "    def __init__(self, input_dim, kernel_size,d):\n",
    "        super(siameseModel, self).__init__() \n",
    "        self.input_dim = input_dim\n",
    "        self.k_size = kernel_size \n",
    "        self.d=d\n",
    "        layers = []\n",
    "        layers.append(nn.Conv1d(in_channels=self.input_dim, out_channels=26, kernel_size=self.k_size, padding='same',bias=False, stride=1))\n",
    "        layers.append(nn.Dropout(p=self.d))\n",
    "        layers.append(nn.Conv1d(in_channels=26, out_channels=26, kernel_size=self.k_size, padding='same',bias=False, stride=1))\n",
    "        layers.append(nn.Dropout(p=self.d))\n",
    "        layers.append(nn.BatchNorm1d(26))\n",
    "        layers.append(nn.ReLU())\n",
    "        layers.append(nn.MaxPool1d(kernel_size=2, stride=2))\n",
    "        \n",
    "        \n",
    "        layers.append(nn.Conv1d(in_channels=26, out_channels=52, kernel_size=self.k_size, padding='same',bias=False, stride=1))\n",
    "        layers.append(nn.Dropout(p=self.d))\n",
    "        layers.append(nn.Conv1d(in_channels=52, out_channels=52, kernel_size=self.k_size, padding='same',bias=False, stride=1))\n",
    "        layers.append(nn.Dropout(p=self.d))\n",
    "        layers.append(nn.BatchNorm1d(52))\n",
    "        layers.append(nn.ReLU())\n",
    "        layers.append(nn.MaxPool1d(kernel_size=2, stride=2))\n",
    "        \n",
    "        \n",
    "        layers.append(nn.Conv1d(in_channels=52, out_channels=104, kernel_size=self.k_size, padding='same',bias=False, stride=1))\n",
    "        layers.append(nn.Dropout(p=self.d))\n",
    "        layers.append(nn.Conv1d(in_channels=104, out_channels=104, kernel_size=self.k_size, padding='same',bias=False, stride=1))\n",
    "        layers.append(nn.Dropout(p=self.d))\n",
    "        layers.append(nn.BatchNorm1d(104))\n",
    "        layers.append(nn.ReLU())\n",
    "        layers.append(nn.MaxPool1d(kernel_size=2, stride=2))\n",
    "        \n",
    "        layers.append(nn.Conv1d(in_channels=104, out_channels=104, kernel_size=self.k_size, padding='same',bias=False, stride=1))\n",
    "        layers.append(nn.Dropout(p=self.d))\n",
    "        layers.append(nn.Conv1d(in_channels=104, out_channels=52, kernel_size=self.k_size, padding='same',bias=False, stride=1))\n",
    "        layers.append(nn.Dropout(p=self.d))\n",
    "        layers.append(nn.BatchNorm1d(52))\n",
    "        layers.append(nn.ReLU())\n",
    "        layers.append(nn.MaxPool1d(kernel_size=2, stride=2))\n",
    "        \n",
    "        \n",
    "        layers.append(nn.Conv1d(in_channels=52, out_channels=52, kernel_size=self.k_size, padding='same',bias=False, stride=1))\n",
    "        layers.append(nn.Dropout(p=self.d))\n",
    "        layers.append(nn.Conv1d(in_channels=52, out_channels=26, kernel_size=self.k_size, padding='same',bias=False, stride=1))\n",
    "        layers.append(nn.Dropout(p=self.d))\n",
    "        layers.append(nn.BatchNorm1d(26))\n",
    "        layers.append(nn.ReLU())\n",
    "        layers.append(nn.MaxPool1d(kernel_size=2, stride=2))\n",
    "        \n",
    "        layers.append(nn.Conv1d(in_channels=26, out_channels=26, kernel_size=self.k_size, padding='same',bias=False, stride=1))\n",
    "        layers.append(nn.Dropout(p=self.d))\n",
    "        layers.append(nn.Conv1d(in_channels=26, out_channels=26, kernel_size=self.k_size, padding='same',bias=False, stride=1))\n",
    "        layers.append(nn.Dropout(p=self.d))\n",
    "        layers.append(nn.BatchNorm1d(26))\n",
    "        layers.append(nn.ReLU())\n",
    "        layers.append(nn.MaxPool1d(kernel_size=2, stride=2))\n",
    "        layers.append(torch.nn.Flatten())\n",
    "        layers.append(torch.nn.Linear(26 * 4, 256))\n",
    "        layers.append(torch.nn.ReLU())\n",
    "        layers.append(torch.nn.Linear(256, 128))\n",
    "        \n",
    "        self.embed = nn.Sequential(*layers)\n",
    "        \n",
    "        self.fc_layers = nn.Sequential(\n",
    "            nn.Linear(128, 10, bias=True),\n",
    "        )\n",
    "        \n",
    "    def convlay(self):\n",
    "        return self.embed ##this is used for creating the downsampled model\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Reshape input tensor to be compatible with convolutional layers\n",
    "        embed = self.embed(x.type(torch.FloatTensor).cuda())\n",
    "        pred = self.fc_layers(embed)\n",
    "        return embed,pred\n",
    "    \n",
    "    def train(self,train_loader,learning_rate=0.01,epochs=5,lam=0.01,opti='adam'):\n",
    "        optidict={'adagrad':torch.optim.Adagrad(self.parameters(), lr=learning_rate),'adam':torch.optim.Adam(self.parameters(),lr=learning_rate),'sgd':torch.optim.SGD(self.parameters(), lr=learning_rate)}\n",
    "        loss_fn1 = ContrastiveLoss()\n",
    "        loss_fn2 = nn.CrossEntropyLoss()\n",
    "        dist =  nn.CosineSimilarity(dim=1, eps=1e-6)\n",
    "        optimizer = optidict[opti]\n",
    "        optimizer.weight_decay = lam #torch.optim.Adam(self.parameters(),lr=learning_rate,weight_decay=lam)\n",
    "        lossrec=[]\n",
    "        par_grad=[]\n",
    "        for epoch in range(epochs):\n",
    "            tloss=0\n",
    "            total_grad=0\n",
    "            for i,(x1s,x2s,y1s,y2s,y1y2s) in enumerate(train_loader): #for datax1,datax2,labelsx1,labelsx2,labelsx1x2 in traindl:\n",
    "                x1s=x1s.to(device)\n",
    "                x2s=x2s.to(device)\n",
    "                y1s=y1s.to(device)\n",
    "                y2s=y2s.to(device)\n",
    "                y1y2s=y1y2s.to(device)\n",
    "                \n",
    "                embed1,pred1 = self.forward(x1s.type(torch.FloatTensor).cuda())  \n",
    "                embed2,pred2 = self.forward(x2s.type(torch.FloatTensor).cuda())\n",
    "                \n",
    "                lossCE = 0.5*(loss_fn2(pred2,y2s.cuda()) + loss_fn2(pred1,y1s.cuda())) \n",
    "                \n",
    "                distance= 1 - dist(embed1, embed2)\n",
    "                \n",
    "                lossCL = loss_fn1(distance, y1y2s)\n",
    "                \n",
    "                loss = lossCE+lossCL \n",
    "                \n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                \n",
    "                grad=0\n",
    "                for p in self.parameters():\n",
    "                    grad+=torch.norm(p.grad).item()\n",
    "                    \n",
    "                total_grad+=grad\n",
    "                tloss+=loss\n",
    "            lossrec.append((tloss/len(train_loader)).log().item())\n",
    "            par_grad.append((total_grad/len(train_loader)))\n",
    "            print('epoch:',epoch,'loss:',(tloss/len(train_loader)).item(),'grad:',(total_grad/len(train_loader)))\n",
    "        return lossrec,par_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 539,
   "id": "1a8b3d7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class downsample(nn.Module):\n",
    "    def __init__(self,cnn):\n",
    "        super(downsample, self).__init__()\n",
    "        self.conv_layers=cnn\n",
    "        self.fc_layers = nn.Sequential(\n",
    "            nn.Linear(128, 350, bias=True),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(350, 10, bias=True),\n",
    "            nn.Softmax(dim=1)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        # Reshape input tensor to be compatible with convolutional layers\n",
    "        x = self.conv_layers(x.type(torch.FloatTensor).cuda())\n",
    "        x = x.view(x.size(0), -1)  # Flatten tensor\n",
    "        x = self.fc_layers(x)\n",
    "        return x\n",
    "    \n",
    "    def train(self,train_loader,learning_rate=0.01,epochs=5,lam=0.01,opti='adam'):\n",
    "        optidict={'adagrad':torch.optim.Adagrad(self.parameters(), lr=learning_rate),'adam':torch.optim.Adam(self.parameters(),lr=learning_rate),'sgd':torch.optim.SGD(self.parameters(), lr=learning_rate)}\n",
    "        loss_fn =  nn.CrossEntropyLoss()\n",
    "        optimizer = optidict[opti]\n",
    "        optimizer.weight_decay = lam #torch.optim.Adam(self.parameters(),lr=learning_rate,weight_decay=lam)\n",
    "        lossrec=[]\n",
    "        par_grad=[]\n",
    "        for epoch in range(epochs):\n",
    "            tloss=0\n",
    "            total_grad=0\n",
    "            for i,(xs,ys) in enumerate(train_loader):\n",
    "                xs=xs.to(device)\n",
    "                ys=ys.to(device)\n",
    "                pred = self.forward(xs.type(torch.FloatTensor).cuda()) \n",
    "                \n",
    "                loss = loss_fn(pred,ys) \n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                \n",
    "                grad=0\n",
    "                for p in self.parameters():\n",
    "                    grad+=torch.norm(p.grad).item()\n",
    "                    \n",
    "                total_grad+=grad\n",
    "                tloss+=loss\n",
    "            lossrec.append((tloss/len(train_loader)).log().item())\n",
    "            par_grad.append((total_grad/len(train_loader)))\n",
    "            print('epoch:',epoch,'loss:',(tloss/len(train_loader)).item(),'grad:',(total_grad/len(train_loader)))\n",
    "        return lossrec,par_grad\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 540,
   "id": "aa97bfd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this model will be used for the similarity finding task to train the model initially\n",
    "modelSia=siameseModel(13,3,0.2)\n",
    "modelSia.to('cuda')\n",
    "losssia=[]\n",
    "parsia=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 541,
   "id": "d6609b9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0 loss: 2.588728189468384 grad: 4.982971076278948\n",
      "epoch: 1 loss: 2.1496520042419434 grad: 4.920015956340357\n",
      "epoch: 2 loss: 1.905318260192871 grad: 4.791583287376911\n",
      "epoch: 3 loss: 1.7615715265274048 grad: 4.810147609788925\n",
      "epoch: 4 loss: 1.6475387811660767 grad: 5.371626103512943\n",
      "epoch: 5 loss: 1.5631893873214722 grad: 5.615270646594465\n",
      "epoch: 6 loss: 1.4445481300354004 grad: 5.411753021597862\n",
      "epoch: 7 loss: 1.367249846458435 grad: 5.542062719963491\n",
      "epoch: 8 loss: 1.2997629642486572 grad: 5.630604948222637\n",
      "epoch: 9 loss: 1.258231282234192 grad: 5.656412811934948\n",
      "epoch: 10 loss: 1.1766276359558105 grad: 5.664038297623396\n",
      "epoch: 11 loss: 1.166700839996338 grad: 5.780725960619748\n",
      "epoch: 12 loss: 1.1052030324935913 grad: 5.510539942085743\n",
      "epoch: 13 loss: 1.0899767875671387 grad: 5.696154460258782\n",
      "epoch: 14 loss: 1.0807257890701294 grad: 5.642205059230328\n",
      "epoch: 15 loss: 0.9991105198860168 grad: 5.368619159758091\n",
      "epoch: 16 loss: 0.9483726024627686 grad: 5.3754723965600135\n",
      "epoch: 17 loss: 0.9450648427009583 grad: 5.437252783507109\n",
      "epoch: 18 loss: 0.8737601637840271 grad: 5.1160678277760745\n",
      "epoch: 19 loss: 0.8863828182220459 grad: 5.385248781986535\n",
      "epoch: 20 loss: 0.8281401991844177 grad: 5.183834803901613\n",
      "epoch: 21 loss: 0.8061118721961975 grad: 5.039290129005909\n",
      "epoch: 22 loss: 0.7729592323303223 grad: 4.9331698673069475\n",
      "epoch: 23 loss: 0.8188170790672302 grad: 5.5921426193863155\n",
      "epoch: 24 loss: 0.7185516953468323 grad: 4.9656079666540025\n",
      "epoch: 25 loss: 0.69377601146698 grad: 4.73783473931998\n",
      "epoch: 26 loss: 0.6964794397354126 grad: 4.677272179462015\n",
      "epoch: 27 loss: 0.6666837334632874 grad: 4.630390144500882\n",
      "epoch: 28 loss: 0.615575909614563 grad: 4.395141806289554\n",
      "epoch: 29 loss: 0.6558722257614136 grad: 4.739246572680772\n",
      "epoch: 30 loss: 0.6201988458633423 grad: 4.63321706981957\n",
      "epoch: 31 loss: 0.6678046584129333 grad: 4.703525374740362\n",
      "epoch: 32 loss: 0.6231414079666138 grad: 4.579883212774992\n",
      "epoch: 33 loss: 0.5815355181694031 grad: 4.2784193238057195\n",
      "epoch: 34 loss: 0.5820611715316772 grad: 4.266160801924765\n",
      "epoch: 35 loss: 0.550022304058075 grad: 4.019051376380026\n",
      "epoch: 36 loss: 0.5535816550254822 grad: 4.101395462818444\n",
      "epoch: 37 loss: 0.5515721440315247 grad: 4.239539979927242\n",
      "epoch: 38 loss: 0.551561713218689 grad: 4.259411306858063\n",
      "epoch: 39 loss: 0.517082929611206 grad: 3.9424597977474334\n",
      "epoch: 40 loss: 0.5364646315574646 grad: 4.13561041149497\n",
      "epoch: 41 loss: 0.49517306685447693 grad: 3.9725087139345705\n",
      "epoch: 42 loss: 0.507392406463623 grad: 3.973208139684051\n",
      "epoch: 43 loss: 0.4881094992160797 grad: 3.7783846195340156\n",
      "epoch: 44 loss: 0.5161442160606384 grad: 4.117713711354882\n",
      "epoch: 45 loss: 0.4740552306175232 grad: 3.5625274489298464\n",
      "epoch: 46 loss: 0.49365198612213135 grad: 3.9253710898719727\n",
      "epoch: 47 loss: 0.48980578780174255 grad: 3.893519194148481\n",
      "epoch: 48 loss: 0.46570900082588196 grad: 3.8813267650157215\n",
      "epoch: 49 loss: 0.47182780504226685 grad: 4.019522802427411\n",
      "epoch: 50 loss: 0.47237440943717957 grad: 3.81573252620548\n",
      "epoch: 51 loss: 0.4477498233318329 grad: 3.658199660141021\n",
      "epoch: 52 loss: 0.45910879969596863 grad: 3.8309653778690844\n",
      "epoch: 53 loss: 0.4691294729709625 grad: 3.957725766979158\n",
      "epoch: 54 loss: 0.5000388026237488 grad: 4.1142054441794755\n",
      "epoch: 55 loss: 0.4583572745323181 grad: 3.750490209646523\n",
      "epoch: 56 loss: 0.4744405448436737 grad: 4.076635600004345\n",
      "epoch: 57 loss: 0.44740739464759827 grad: 3.8008798158913852\n",
      "epoch: 58 loss: 0.4223777651786804 grad: 3.3869701456837356\n",
      "epoch: 59 loss: 0.4251265525817871 grad: 3.504199538320303\n",
      "epoch: 60 loss: 0.4223857522010803 grad: 3.453901227954775\n",
      "epoch: 61 loss: 0.43672487139701843 grad: 3.7640181135497985\n",
      "epoch: 62 loss: 0.4303680658340454 grad: 3.4414659548960627\n",
      "epoch: 63 loss: 0.4045903980731964 grad: 3.278950619269162\n",
      "epoch: 64 loss: 0.38892289996147156 grad: 2.9840168108828364\n",
      "epoch: 65 loss: 0.37688857316970825 grad: 2.9303500065766275\n",
      "epoch: 66 loss: 0.39866116642951965 grad: 3.169035665269941\n",
      "epoch: 67 loss: 0.3936477303504944 grad: 3.356508244920522\n",
      "epoch: 68 loss: 0.38347798585891724 grad: 3.0327369914799926\n",
      "epoch: 69 loss: 0.379669725894928 grad: 3.1468411556854843\n",
      "epoch: 70 loss: 0.40232589840888977 grad: 3.4092443838473407\n",
      "epoch: 71 loss: 0.3733697235584259 grad: 3.0940252080634236\n",
      "epoch: 72 loss: 0.42036858201026917 grad: 3.6015016500968486\n",
      "epoch: 73 loss: 0.4014945924282074 grad: 3.2956026807911694\n",
      "epoch: 74 loss: 0.39690133929252625 grad: 3.3701380201280116\n",
      "epoch: 75 loss: 0.34993574023246765 grad: 2.7239531569648534\n",
      "epoch: 76 loss: 0.35212358832359314 grad: 2.9404392245914788\n",
      "epoch: 77 loss: 0.3665594458580017 grad: 3.1120421685110777\n",
      "epoch: 78 loss: 0.3581642210483551 grad: 2.7805539829600603\n",
      "epoch: 79 loss: 0.33229973912239075 grad: 2.7108157862089572\n",
      "epoch: 80 loss: 0.34339842200279236 grad: 2.6695530383018777\n",
      "epoch: 81 loss: 0.37463802099227905 grad: 3.298241972502321\n",
      "epoch: 82 loss: 0.36687928438186646 grad: 2.84692193107307\n",
      "epoch: 83 loss: 0.3398504853248596 grad: 2.6459679476991296\n",
      "epoch: 84 loss: 0.3471122980117798 grad: 2.9294719065297397\n",
      "epoch: 85 loss: 0.3803555369377136 grad: 3.3033993757739664\n",
      "epoch: 86 loss: 0.36642301082611084 grad: 3.0989217530824242\n",
      "epoch: 87 loss: 0.3437890112400055 grad: 2.860058449998498\n",
      "epoch: 88 loss: 0.33300477266311646 grad: 2.6705653112847356\n",
      "epoch: 89 loss: 0.35418879985809326 grad: 2.7199662763774395\n",
      "epoch: 90 loss: 0.3422471582889557 grad: 2.689905290039256\n",
      "epoch: 91 loss: 0.33226343989372253 grad: 2.6442678803820163\n",
      "epoch: 92 loss: 0.3549042344093323 grad: 2.687618650777731\n",
      "epoch: 93 loss: 0.33646443486213684 grad: 2.829553621770814\n",
      "epoch: 94 loss: 0.3525291681289673 grad: 2.8271512242518364\n",
      "epoch: 95 loss: 0.34350645542144775 grad: 2.6389233031328767\n",
      "epoch: 96 loss: 0.32120081782341003 grad: 2.459522680078633\n",
      "epoch: 97 loss: 0.3111516535282135 grad: 2.4448298930944876\n",
      "epoch: 98 loss: 0.35883060097694397 grad: 2.9570053272824732\n",
      "epoch: 99 loss: 0.3216008245944977 grad: 2.363875827224925\n",
      "epoch: 100 loss: 0.33999931812286377 grad: 2.651357832333073\n",
      "epoch: 101 loss: 0.31390857696533203 grad: 2.3299630355155094\n",
      "epoch: 102 loss: 0.3705517649650574 grad: 3.145036921652034\n",
      "epoch: 103 loss: 0.33981916308403015 grad: 2.779425913343206\n",
      "epoch: 104 loss: 0.3235023021697998 grad: 2.673965367970057\n",
      "epoch: 105 loss: 0.3188662827014923 grad: 2.501981693330221\n",
      "epoch: 106 loss: 0.311199426651001 grad: 2.450043170475401\n",
      "epoch: 107 loss: 0.3128467798233032 grad: 2.549253608890809\n",
      "epoch: 108 loss: 0.2982967495918274 grad: 2.161022693451494\n",
      "epoch: 109 loss: 0.28323668241500854 grad: 2.1776600305614995\n",
      "epoch: 110 loss: 0.331618070602417 grad: 2.5046059017088265\n",
      "epoch: 111 loss: 0.3021775484085083 grad: 2.283811371590011\n",
      "epoch: 112 loss: 0.3021562397480011 grad: 2.204071989459917\n",
      "epoch: 113 loss: 0.3009780943393707 grad: 2.4299585430934094\n",
      "epoch: 114 loss: 0.3416522443294525 grad: 2.930261384507641\n",
      "epoch: 115 loss: 0.33972424268722534 grad: 2.691216561642941\n",
      "epoch: 116 loss: 0.31559237837791443 grad: 2.5037579100178555\n",
      "epoch: 117 loss: 0.30178630352020264 grad: 2.141690232641064\n",
      "epoch: 118 loss: 0.28432247042655945 grad: 1.9613398716002703\n",
      "epoch: 119 loss: 0.2980462908744812 grad: 2.2181856059189884\n",
      "epoch: 120 loss: 0.29870346188545227 grad: 2.2054712772658096\n",
      "epoch: 121 loss: 0.2804216146469116 grad: 1.9118013379070908\n",
      "epoch: 122 loss: 0.285490483045578 grad: 2.119361560505582\n",
      "epoch: 123 loss: 0.288301557302475 grad: 1.984651270119939\n",
      "epoch: 124 loss: 0.2843223810195923 grad: 1.9500278402268887\n",
      "epoch: 125 loss: 0.2893497049808502 grad: 2.219893147922121\n",
      "epoch: 126 loss: 0.28892919421195984 grad: 1.9499229609491304\n",
      "epoch: 127 loss: 0.34684962034225464 grad: 2.926842229919508\n",
      "epoch: 128 loss: 0.2898450493812561 grad: 2.10556022406742\n",
      "epoch: 129 loss: 0.31363189220428467 grad: 2.3804414080008867\n",
      "epoch: 130 loss: 0.2953716814517975 grad: 2.1863210423681885\n",
      "epoch: 131 loss: 0.30093199014663696 grad: 2.2379121457994917\n",
      "epoch: 132 loss: 0.2792924642562866 grad: 1.916968798762653\n",
      "epoch: 133 loss: 0.2824876010417938 grad: 1.9799956290228293\n",
      "epoch: 134 loss: 0.2980080842971802 grad: 2.030368931335863\n",
      "epoch: 135 loss: 0.28901949524879456 grad: 2.126194447025191\n",
      "epoch: 136 loss: 0.29473093152046204 grad: 2.3054830938511297\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 137 loss: 0.28829267621040344 grad: 2.0553343972694127\n",
      "epoch: 138 loss: 0.2894260287284851 grad: 1.913904849091079\n",
      "epoch: 139 loss: 0.2970614731311798 grad: 2.2677145447600635\n",
      "epoch: 140 loss: 0.3037671744823456 grad: 2.391025595160667\n",
      "epoch: 141 loss: 0.2798402011394501 grad: 1.9068503945497797\n",
      "epoch: 142 loss: 0.26541826128959656 grad: 1.5888156232098118\n",
      "epoch: 143 loss: 0.29449453949928284 grad: 2.334298830886837\n",
      "epoch: 144 loss: 0.28685954213142395 grad: 1.9996611058395355\n",
      "epoch: 145 loss: 0.29953432083129883 grad: 2.2215669236034157\n",
      "epoch: 146 loss: 0.2797195017337799 grad: 1.8269572454830632\n",
      "epoch: 147 loss: 0.27334657311439514 grad: 1.9853208893492702\n",
      "epoch: 148 loss: 0.2813369035720825 grad: 1.979347647344228\n",
      "epoch: 149 loss: 0.2795417904853821 grad: 1.9371785907151644\n",
      "epoch: 150 loss: 0.27630025148391724 grad: 1.8815200825901701\n",
      "epoch: 151 loss: 0.2789258360862732 grad: 2.0966866154824384\n",
      "epoch: 152 loss: 0.3122113347053528 grad: 2.303245818592608\n",
      "epoch: 153 loss: 0.27053728699684143 grad: 1.8044164914018475\n",
      "epoch: 154 loss: 0.29782283306121826 grad: 2.236879386352841\n",
      "epoch: 155 loss: 0.26129236817359924 grad: 1.6478355833319946\n",
      "epoch: 156 loss: 0.2654741406440735 grad: 1.6539729884606786\n",
      "epoch: 157 loss: 0.2661603093147278 grad: 1.6692652327115647\n",
      "epoch: 158 loss: 0.2752642333507538 grad: 1.8993915858780965\n",
      "epoch: 159 loss: 0.27820149064064026 grad: 1.9303078044392168\n",
      "epoch: 160 loss: 0.26355522871017456 grad: 1.7665163119179197\n",
      "epoch: 161 loss: 0.26191237568855286 grad: 1.7434761228235438\n",
      "epoch: 162 loss: 0.28292495012283325 grad: 2.056182465341408\n",
      "epoch: 163 loss: 0.2787764072418213 grad: 1.9827845295509323\n",
      "epoch: 164 loss: 0.2819814383983612 grad: 1.9892530393956696\n",
      "epoch: 165 loss: 0.26403090357780457 grad: 1.6505519661419095\n",
      "epoch: 166 loss: 0.2565399408340454 grad: 1.4949941485216842\n",
      "epoch: 167 loss: 0.24822814762592316 grad: 1.3270146503136493\n",
      "epoch: 168 loss: 0.24733176827430725 grad: 1.3069518260345794\n",
      "epoch: 169 loss: 0.25969642400741577 grad: 1.5959448871368076\n",
      "epoch: 170 loss: 0.27098384499549866 grad: 1.8104121383312157\n",
      "epoch: 171 loss: 0.26687049865722656 grad: 1.8150784613797442\n",
      "epoch: 172 loss: 0.2899179756641388 grad: 1.9926941095534711\n",
      "epoch: 173 loss: 0.27507254481315613 grad: 1.9933692472223192\n",
      "epoch: 174 loss: 0.27398306131362915 grad: 1.776990671715932\n",
      "epoch: 175 loss: 0.24631260335445404 grad: 1.5060455792074499\n",
      "epoch: 176 loss: 0.293247789144516 grad: 2.2127148560630157\n",
      "epoch: 177 loss: 0.28046879172325134 grad: 1.9538844193071128\n",
      "epoch: 178 loss: 0.2666582465171814 grad: 1.6391736595411786\n",
      "epoch: 179 loss: 0.2629493772983551 grad: 1.676023496392183\n",
      "epoch: 180 loss: 0.2782389521598816 grad: 1.8390226203599014\n",
      "epoch: 181 loss: 0.2648201584815979 grad: 1.7904991521174087\n",
      "epoch: 182 loss: 0.2695122957229614 grad: 1.7239768560649826\n",
      "epoch: 183 loss: 0.26100969314575195 grad: 1.8050533348405733\n",
      "epoch: 184 loss: 0.2672542333602905 grad: 1.7061674721720628\n",
      "epoch: 185 loss: 0.2693864107131958 grad: 1.8156009727488271\n",
      "epoch: 186 loss: 0.2606040835380554 grad: 1.6997945574165787\n",
      "epoch: 187 loss: 0.28178808093070984 grad: 2.2113758118017577\n",
      "epoch: 188 loss: 0.27072083950042725 grad: 1.7749970129763242\n",
      "epoch: 189 loss: 0.25983065366744995 grad: 1.5012547919265926\n",
      "epoch: 190 loss: 0.2695524990558624 grad: 1.921657198973\n",
      "epoch: 191 loss: 0.2666887640953064 grad: 1.6678501097436529\n",
      "epoch: 192 loss: 0.2748360335826874 grad: 1.883512911570724\n",
      "epoch: 193 loss: 0.24530917406082153 grad: 1.5158939698335017\n",
      "epoch: 194 loss: 0.24696873128414154 grad: 1.5045578607866774\n",
      "epoch: 195 loss: 0.248618483543396 grad: 1.2953755239853635\n",
      "epoch: 196 loss: 0.26824524998664856 grad: 1.7644206537229474\n",
      "epoch: 197 loss: 0.2839548587799072 grad: 1.9375149507310707\n",
      "epoch: 198 loss: 0.2471296638250351 grad: 1.3589045222691494\n",
      "epoch: 199 loss: 0.25359708070755005 grad: 1.6557271270685596\n",
      "epoch: 200 loss: 0.259995698928833 grad: 1.547867448218167\n",
      "epoch: 201 loss: 0.2582812011241913 grad: 1.7161089518982917\n",
      "epoch: 202 loss: 0.2630902826786041 grad: 1.705491506641265\n",
      "epoch: 203 loss: 0.2532837688922882 grad: 1.6109644012639766\n",
      "epoch: 204 loss: 0.26438090205192566 grad: 1.7732610969196538\n",
      "epoch: 205 loss: 0.23972702026367188 grad: 1.2393344589129556\n",
      "epoch: 206 loss: 0.24965521693229675 grad: 1.42701675719989\n",
      "epoch: 207 loss: 0.24186158180236816 grad: 1.1879579495915096\n",
      "epoch: 208 loss: 0.24747072160243988 grad: 1.523238020898425\n",
      "epoch: 209 loss: 0.23878872394561768 grad: 1.0556783945087809\n",
      "epoch: 210 loss: 0.25484469532966614 grad: 1.4540757863705511\n",
      "epoch: 211 loss: 0.26228857040405273 grad: 1.7455985587134493\n",
      "epoch: 212 loss: 0.31171804666519165 grad: 2.4093941168785094\n",
      "epoch: 213 loss: 0.27634209394454956 grad: 1.7414606733569526\n",
      "epoch: 214 loss: 0.25470152497291565 grad: 1.5008077781700995\n",
      "epoch: 215 loss: 0.2498815506696701 grad: 1.3730472636084305\n",
      "epoch: 216 loss: 0.2676091492176056 grad: 1.6258011995214037\n",
      "epoch: 217 loss: 0.2347334921360016 grad: 1.2923158114664257\n",
      "epoch: 218 loss: 0.25125133991241455 grad: 1.3654865553239361\n",
      "epoch: 219 loss: 0.240436851978302 grad: 1.2261045504251962\n",
      "epoch: 220 loss: 0.2583601176738739 grad: 1.4882887912753504\n",
      "epoch: 221 loss: 0.24799993634223938 grad: 1.3583096153505612\n",
      "epoch: 222 loss: 0.23798952996730804 grad: 1.2656946798386053\n",
      "epoch: 223 loss: 0.24571919441223145 grad: 1.3800998513740488\n",
      "epoch: 224 loss: 0.2480289787054062 grad: 1.4177947222623042\n",
      "epoch: 225 loss: 0.2540208399295807 grad: 1.5337100055464543\n",
      "epoch: 226 loss: 0.26399511098861694 grad: 1.616640798649518\n",
      "epoch: 227 loss: 0.24573954939842224 grad: 1.3359315467115958\n",
      "epoch: 228 loss: 0.2571678161621094 grad: 1.3962627746294312\n",
      "epoch: 229 loss: 0.24379652738571167 grad: 1.2913323011801112\n",
      "epoch: 230 loss: 0.26849600672721863 grad: 1.6473443063749\n",
      "epoch: 231 loss: 0.25699174404144287 grad: 1.6241552834999748\n",
      "epoch: 232 loss: 0.27818265557289124 grad: 1.7469091599117965\n",
      "epoch: 233 loss: 0.2568146884441376 grad: 1.4255681170038879\n",
      "epoch: 234 loss: 0.2779126763343811 grad: 1.9395067243487574\n",
      "epoch: 235 loss: 0.2540460228919983 grad: 1.3758876721005655\n",
      "epoch: 236 loss: 0.23355726897716522 grad: 1.1111089347532253\n",
      "epoch: 237 loss: 0.2464675009250641 grad: 1.48820218314277\n",
      "epoch: 238 loss: 0.24306409060955048 grad: 1.3798953232273925\n",
      "epoch: 239 loss: 0.2769033908843994 grad: 1.8402392417839728\n",
      "epoch: 240 loss: 0.25837650895118713 grad: 1.5201959110787138\n",
      "epoch: 241 loss: 0.24342574179172516 grad: 1.205737792487489\n",
      "epoch: 242 loss: 0.2313949167728424 grad: 1.0619641189991962\n",
      "epoch: 243 loss: 0.22761665284633636 grad: 0.9929452537749894\n",
      "epoch: 244 loss: 0.23572911322116852 grad: 1.2181792839172996\n",
      "epoch: 245 loss: 0.26725006103515625 grad: 1.7616822632662952\n",
      "epoch: 246 loss: 0.2408866584300995 grad: 1.1901837698679882\n",
      "epoch: 247 loss: 0.2533569633960724 grad: 1.4198639648684765\n",
      "epoch: 248 loss: 0.2456393837928772 grad: 1.313810400691058\n",
      "epoch: 249 loss: 0.2527981996536255 grad: 1.4982916937083937\n",
      "epoch: 250 loss: 0.2550712525844574 grad: 1.5420844068219886\n",
      "epoch: 251 loss: 0.24441108107566833 grad: 1.3681475231017102\n",
      "epoch: 252 loss: 0.23337529599666595 grad: 1.119640694886446\n",
      "epoch: 253 loss: 0.2308676391839981 grad: 1.0566729849812109\n",
      "epoch: 254 loss: 0.2472825050354004 grad: 1.3737930096425115\n",
      "epoch: 255 loss: 0.24210867285728455 grad: 1.0977060170241166\n",
      "epoch: 256 loss: 0.23061956465244293 grad: 0.9786474123287481\n",
      "epoch: 257 loss: 0.23483958840370178 grad: 1.0332927030134014\n",
      "epoch: 258 loss: 0.24483223259449005 grad: 1.4918266708923038\n",
      "epoch: 259 loss: 0.26922762393951416 grad: 1.5476159834841965\n",
      "epoch: 260 loss: 0.2523639500141144 grad: 1.3617038737195544\n",
      "epoch: 261 loss: 0.24167893826961517 grad: 1.1373631980410428\n",
      "epoch: 262 loss: 0.24570147693157196 grad: 1.2644001769182505\n",
      "epoch: 263 loss: 0.26264142990112305 grad: 1.6301757721037138\n",
      "epoch: 264 loss: 0.23505979776382446 grad: 1.192087648302957\n",
      "epoch: 265 loss: 0.28791913390159607 grad: 2.0099282094025983\n",
      "epoch: 266 loss: 0.2453100085258484 grad: 1.3270097977459663\n",
      "epoch: 267 loss: 0.2356252521276474 grad: 1.1090001117564388\n",
      "epoch: 268 loss: 0.23443803191184998 grad: 1.2818329368724954\n",
      "epoch: 269 loss: 0.22726567089557648 grad: 0.9426518263111356\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 270 loss: 0.23315143585205078 grad: 1.1472108303556452\n",
      "epoch: 271 loss: 0.23221220076084137 grad: 1.0765623962378594\n",
      "epoch: 272 loss: 0.24916869401931763 grad: 1.3205887539847754\n",
      "epoch: 273 loss: 0.2555699944496155 grad: 1.3407725467880955\n",
      "epoch: 274 loss: 0.23913292586803436 grad: 1.3088510321422364\n",
      "epoch: 275 loss: 0.25863566994667053 grad: 1.6225752941254759\n",
      "epoch: 276 loss: 0.2657531797885895 grad: 1.7010410694882738\n",
      "epoch: 277 loss: 0.2350764125585556 grad: 1.1417444028025494\n",
      "epoch: 278 loss: 0.23898980021476746 grad: 1.209687032513204\n",
      "epoch: 279 loss: 0.24262447655200958 grad: 1.289507767290459\n",
      "epoch: 280 loss: 0.23086532950401306 grad: 1.02934847776033\n",
      "epoch: 281 loss: 0.23847004771232605 grad: 1.1932566686429782\n",
      "epoch: 282 loss: 0.2463306486606598 grad: 1.3749753556640498\n",
      "epoch: 283 loss: 0.23304519057273865 grad: 1.1487957660451065\n",
      "epoch: 284 loss: 0.24205175042152405 grad: 1.2737614566423\n",
      "epoch: 285 loss: 0.2387499064207077 grad: 1.158941071200883\n",
      "epoch: 286 loss: 0.2265535593032837 grad: 0.8889218575041741\n",
      "epoch: 287 loss: 0.2675773799419403 grad: 1.61264625372889\n",
      "epoch: 288 loss: 0.24527861177921295 grad: 1.403689488591801\n",
      "epoch: 289 loss: 0.25949832797050476 grad: 1.4600116831697523\n",
      "epoch: 290 loss: 0.2386980950832367 grad: 1.144233989282744\n",
      "epoch: 291 loss: 0.2297663539648056 grad: 1.0752764648464508\n",
      "epoch: 292 loss: 0.25733065605163574 grad: 1.507820604667184\n",
      "epoch: 293 loss: 0.23843251168727875 grad: 1.1115552295348026\n",
      "epoch: 294 loss: 0.23582203686237335 grad: 1.035851984146808\n",
      "epoch: 295 loss: 0.23317761719226837 grad: 1.0294500313476602\n",
      "epoch: 296 loss: 0.22223389148712158 grad: 0.856965245055093\n",
      "epoch: 297 loss: 0.2403525561094284 grad: 1.1505728783298983\n",
      "epoch: 298 loss: 0.23252461850643158 grad: 1.0161370774082608\n",
      "epoch: 299 loss: 0.23181474208831787 grad: 1.0331223801715241\n",
      "epoch: 300 loss: 0.25287723541259766 grad: 1.449506562423252\n",
      "epoch: 301 loss: 0.24984197318553925 grad: 1.3239232816373696\n",
      "epoch: 302 loss: 0.25961223244667053 grad: 1.623199137761636\n",
      "epoch: 303 loss: 0.2599901854991913 grad: 1.51627411035361\n",
      "epoch: 304 loss: 0.275028258562088 grad: 1.716987896736886\n",
      "epoch: 305 loss: 0.2510530948638916 grad: 1.4577844532614108\n",
      "epoch: 306 loss: 0.24850629270076752 grad: 1.336415779999952\n",
      "epoch: 307 loss: 0.25039535760879517 grad: 1.4153516956208623\n",
      "epoch: 308 loss: 0.23252485692501068 grad: 1.2787974391248427\n",
      "epoch: 309 loss: 0.2439863532781601 grad: 1.2068459922433832\n",
      "epoch: 310 loss: 0.23162250220775604 grad: 1.15525182644694\n",
      "epoch: 311 loss: 0.24957439303398132 grad: 1.3313370386393508\n",
      "epoch: 312 loss: 0.24259844422340393 grad: 1.368338534816052\n",
      "epoch: 313 loss: 0.23444634675979614 grad: 1.0251940870677936\n",
      "epoch: 314 loss: 0.21442122757434845 grad: 0.7428881499714044\n",
      "epoch: 315 loss: 0.23057276010513306 grad: 1.077344569873996\n",
      "epoch: 316 loss: 0.23020341992378235 grad: 1.2170524583011866\n",
      "epoch: 317 loss: 0.2312561422586441 grad: 1.0236015578651567\n",
      "epoch: 318 loss: 0.24430689215660095 grad: 1.1209614850289071\n",
      "epoch: 319 loss: 0.22228270769119263 grad: 0.7418719200658379\n",
      "epoch: 320 loss: 0.22139222919940948 grad: 0.797958183133509\n",
      "epoch: 321 loss: 0.2389248013496399 grad: 1.1951575134658925\n",
      "epoch: 322 loss: 0.23555460572242737 grad: 1.2326558130254561\n",
      "epoch: 323 loss: 0.250981867313385 grad: 1.3461094500409672\n",
      "epoch: 324 loss: 0.253910630941391 grad: 1.6947066226695315\n",
      "epoch: 325 loss: 0.24024434387683868 grad: 1.051361318238356\n",
      "epoch: 326 loss: 0.24005265533924103 grad: 1.431941188665107\n",
      "epoch: 327 loss: 0.24070629477500916 grad: 1.1878992377994582\n",
      "epoch: 328 loss: 0.25430989265441895 grad: 1.3638652185329703\n",
      "epoch: 329 loss: 0.24434436857700348 grad: 1.2633173579602734\n",
      "epoch: 330 loss: 0.23314949870109558 grad: 1.122730398689164\n",
      "epoch: 331 loss: 0.2312929630279541 grad: 1.0503973125452757\n",
      "epoch: 332 loss: 0.2139110267162323 grad: 0.758142207729281\n",
      "epoch: 333 loss: 0.2169084995985031 grad: 0.7245861288763699\n",
      "epoch: 334 loss: 0.22534440457820892 grad: 0.9250587791390718\n",
      "epoch: 335 loss: 0.2209591418504715 grad: 0.8174900612800847\n",
      "epoch: 336 loss: 0.2321191430091858 grad: 1.0198063404929416\n",
      "epoch: 337 loss: 0.2563983201980591 grad: 1.6367505743297515\n",
      "epoch: 338 loss: 0.25996583700180054 grad: 1.4825823095843662\n",
      "epoch: 339 loss: 0.23856863379478455 grad: 1.0225566431708866\n",
      "epoch: 340 loss: 0.24304385483264923 grad: 1.2368138131385202\n",
      "epoch: 341 loss: 0.2442564219236374 grad: 1.247448592862551\n",
      "epoch: 342 loss: 0.22692999243736267 grad: 0.9486452475241968\n",
      "epoch: 343 loss: 0.23237816989421844 grad: 0.9869619834688201\n",
      "epoch: 344 loss: 0.23471835255622864 grad: 0.9634492238025414\n",
      "epoch: 345 loss: 0.23863068222999573 grad: 1.2107369570311857\n",
      "epoch: 346 loss: 0.2381467968225479 grad: 1.2102041082311188\n",
      "epoch: 347 loss: 0.24146245419979095 grad: 1.3348774799574166\n",
      "epoch: 348 loss: 0.24577300250530243 grad: 1.5563079449334327\n",
      "epoch: 349 loss: 0.2418302744626999 grad: 1.0928695925978245\n",
      "epoch: 350 loss: 0.22733202576637268 grad: 0.8741698821432655\n",
      "epoch: 351 loss: 0.22123920917510986 grad: 0.9218154703146428\n",
      "epoch: 352 loss: 0.23437026143074036 grad: 0.9005991226747865\n",
      "epoch: 353 loss: 0.23930850625038147 grad: 1.0712421880235197\n",
      "epoch: 354 loss: 0.23191508650779724 grad: 1.0808701159211924\n",
      "epoch: 355 loss: 0.22066372632980347 grad: 0.8305894981512975\n",
      "epoch: 356 loss: 0.23646479845046997 grad: 1.0705245792654459\n",
      "epoch: 357 loss: 0.23649205267429352 grad: 1.2216569788010092\n",
      "epoch: 358 loss: 0.2328101545572281 grad: 0.9878353892698651\n",
      "epoch: 359 loss: 0.22544258832931519 grad: 0.8424032711102045\n",
      "epoch: 360 loss: 0.23418858647346497 grad: 1.0186461686404655\n",
      "epoch: 361 loss: 0.2377648502588272 grad: 1.0132297177083092\n",
      "epoch: 362 loss: 0.22840817272663116 grad: 0.9152284491737082\n",
      "epoch: 363 loss: 0.23963260650634766 grad: 1.1428219016953662\n",
      "epoch: 364 loss: 0.2373161017894745 grad: 0.9561254414605792\n",
      "epoch: 365 loss: 0.2266734391450882 grad: 0.8446570309047821\n",
      "epoch: 366 loss: 0.263930082321167 grad: 1.644090391332691\n",
      "epoch: 367 loss: 0.2416006624698639 grad: 1.20299968677375\n",
      "epoch: 368 loss: 0.23541384935379028 grad: 0.969626328874845\n",
      "epoch: 369 loss: 0.22279463708400726 grad: 0.8923440080892906\n",
      "epoch: 370 loss: 0.2319750338792801 grad: 1.1206836589248852\n",
      "epoch: 371 loss: 0.233287051320076 grad: 0.9537687992162537\n",
      "epoch: 372 loss: 0.23786993324756622 grad: 0.9142462820473302\n",
      "epoch: 373 loss: 0.21978850662708282 grad: 0.8566078872606159\n",
      "epoch: 374 loss: 0.2643413245677948 grad: 1.606490222394932\n",
      "epoch: 375 loss: 0.22768595814704895 grad: 0.8741967971184204\n",
      "epoch: 376 loss: 0.23446372151374817 grad: 0.9537911905069195\n",
      "epoch: 377 loss: 0.23401638865470886 grad: 1.0161284460826645\n",
      "epoch: 378 loss: 0.23891831934452057 grad: 1.0090606096199481\n",
      "epoch: 379 loss: 0.2408277839422226 grad: 1.0719577221310466\n",
      "epoch: 380 loss: 0.25748664140701294 grad: 1.5364461563186487\n",
      "epoch: 381 loss: 0.24510207772254944 grad: 1.3978038244233466\n",
      "epoch: 382 loss: 0.25418856739997864 grad: 1.3907767188890139\n",
      "epoch: 383 loss: 0.22028829157352448 grad: 0.7249876079116948\n",
      "epoch: 384 loss: 0.21800123155117035 grad: 0.7723170879942918\n",
      "epoch: 385 loss: 0.2671303153038025 grad: 1.4647518603774952\n",
      "epoch: 386 loss: 0.22607621550559998 grad: 0.9436653802405927\n",
      "epoch: 387 loss: 0.2186063677072525 grad: 0.7552141912048537\n",
      "epoch: 388 loss: 0.22116072475910187 grad: 0.8450736763336172\n",
      "epoch: 389 loss: 0.2285178005695343 grad: 0.8400022316533723\n",
      "epoch: 390 loss: 0.2283792346715927 grad: 0.9782869323244958\n",
      "epoch: 391 loss: 0.22778697311878204 grad: 0.9477044037683227\n",
      "epoch: 392 loss: 0.22347554564476013 grad: 0.8880846794174285\n",
      "epoch: 393 loss: 0.25043216347694397 grad: 1.4223366948884213\n",
      "epoch: 394 loss: 0.22062498331069946 grad: 0.7514013644577353\n",
      "epoch: 395 loss: 0.24303890764713287 grad: 1.2012298541866766\n",
      "epoch: 396 loss: 0.23570014536380768 grad: 1.1909993886757002\n",
      "epoch: 397 loss: 0.25161823630332947 grad: 1.1459922074546338\n",
      "epoch: 398 loss: 0.23098212480545044 grad: 0.9111094613284222\n",
      "epoch: 399 loss: 0.251743882894516 grad: 1.291838981843408\n",
      "epoch: 400 loss: 0.23995983600616455 grad: 1.1390833542196068\n",
      "epoch: 401 loss: 0.2300039678812027 grad: 1.0123180089349626\n",
      "epoch: 402 loss: 0.2323872148990631 grad: 1.1667730329458137\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 403 loss: 0.23019729554653168 grad: 0.7744783946458483\n",
      "epoch: 404 loss: 0.22653718292713165 grad: 0.9084788078077254\n",
      "epoch: 405 loss: 0.21963651478290558 grad: 0.7466270744421927\n",
      "epoch: 406 loss: 0.2247868776321411 grad: 0.7917722257047135\n",
      "epoch: 407 loss: 0.2275983989238739 grad: 0.76941034881433\n",
      "epoch: 408 loss: 0.22546669840812683 grad: 0.8083285168517031\n",
      "epoch: 409 loss: 0.2247069776058197 grad: 0.8675022172682512\n",
      "epoch: 410 loss: 0.25175487995147705 grad: 1.3566008744532592\n",
      "epoch: 411 loss: 0.2559056580066681 grad: 1.391931758052786\n",
      "epoch: 412 loss: 0.22624672949314117 grad: 0.9020166361048468\n",
      "epoch: 413 loss: 0.22880136966705322 grad: 0.9295251491060189\n",
      "epoch: 414 loss: 0.22318348288536072 grad: 0.8167176791122766\n",
      "epoch: 415 loss: 0.2296953648328781 grad: 1.0469961347664065\n",
      "epoch: 416 loss: 0.23260490596294403 grad: 0.9983835396390641\n",
      "epoch: 417 loss: 0.22856873273849487 grad: 0.8968969062974793\n",
      "epoch: 418 loss: 0.22953027486801147 grad: 0.8736849852144369\n",
      "epoch: 419 loss: 0.25566837191581726 grad: 1.662375629274582\n",
      "epoch: 420 loss: 0.22276639938354492 grad: 0.7635427298816939\n",
      "epoch: 421 loss: 0.2316783219575882 grad: 1.007272765980495\n",
      "epoch: 422 loss: 0.23724277317523956 grad: 0.9991006163766142\n",
      "epoch: 423 loss: 0.22141309082508087 grad: 0.9042708787201554\n",
      "epoch: 424 loss: 0.2254866063594818 grad: 0.84046264370883\n",
      "epoch: 425 loss: 0.24058254063129425 grad: 1.1819764669975703\n",
      "epoch: 426 loss: 0.2252260446548462 grad: 0.7679180659409612\n",
      "epoch: 427 loss: 0.25651630759239197 grad: 1.3943357676331651\n",
      "epoch: 428 loss: 0.2373119592666626 grad: 0.9920446771297138\n",
      "epoch: 429 loss: 0.22986353933811188 grad: 0.918637988281691\n",
      "epoch: 430 loss: 0.22826914489269257 grad: 0.9567730210447335\n",
      "epoch: 431 loss: 0.2292187511920929 grad: 0.8954012941178807\n",
      "epoch: 432 loss: 0.21832390129566193 grad: 0.7011232867664948\n",
      "epoch: 433 loss: 0.22641593217849731 grad: 0.8530837696123054\n",
      "epoch: 434 loss: 0.22781223058700562 grad: 1.0588337969180284\n",
      "epoch: 435 loss: 0.22370541095733643 grad: 0.8510786885868874\n",
      "epoch: 436 loss: 0.225344717502594 grad: 0.9560411993072776\n",
      "epoch: 437 loss: 0.23099307715892792 grad: 0.9366567046447454\n",
      "epoch: 438 loss: 0.23973849415779114 grad: 1.0104811682928994\n",
      "epoch: 439 loss: 0.2688239514827728 grad: 1.6857802347380202\n",
      "epoch: 440 loss: 0.23835955560207367 grad: 1.1894930474367285\n",
      "epoch: 441 loss: 0.22115807235240936 grad: 0.871412107004784\n",
      "epoch: 442 loss: 0.22024761140346527 grad: 0.7852664081920011\n",
      "epoch: 443 loss: 0.22325986623764038 grad: 0.9383293156266446\n",
      "epoch: 444 loss: 0.22565214335918427 grad: 0.9036802402196336\n",
      "epoch: 445 loss: 0.22061848640441895 grad: 0.7923383541932126\n",
      "epoch: 446 loss: 0.2286449670791626 grad: 0.9108016438857303\n",
      "epoch: 447 loss: 0.23514340817928314 grad: 1.0634501053507557\n",
      "epoch: 448 loss: 0.23454467952251434 grad: 1.094481941847218\n",
      "epoch: 449 loss: 0.22743074595928192 grad: 0.9217132202598732\n",
      "epoch: 450 loss: 0.22236524522304535 grad: 0.7531690323210205\n",
      "epoch: 451 loss: 0.21772821247577667 grad: 0.7165077474685823\n",
      "epoch: 452 loss: 0.22826237976551056 grad: 0.7825719243018975\n",
      "epoch: 453 loss: 0.22613520920276642 grad: 0.922741261021758\n",
      "epoch: 454 loss: 0.233188658952713 grad: 0.9378918494815007\n",
      "epoch: 455 loss: 0.21933375298976898 grad: 0.607363365129917\n",
      "epoch: 456 loss: 0.22561988234519958 grad: 0.8507203864405747\n",
      "epoch: 457 loss: 0.2292909324169159 grad: 0.8985278153021645\n",
      "epoch: 458 loss: 0.23298875987529755 grad: 0.984170810731477\n",
      "epoch: 459 loss: 0.22071808576583862 grad: 0.7892578186775209\n",
      "epoch: 460 loss: 0.22860589623451233 grad: 0.7475840700768531\n",
      "epoch: 461 loss: 0.22903943061828613 grad: 0.8335056433443387\n",
      "epoch: 462 loss: 0.22982220351696014 grad: 0.8212525314316445\n",
      "epoch: 463 loss: 0.21448998153209686 grad: 0.6975802389465098\n",
      "epoch: 464 loss: 0.2456013709306717 grad: 1.1669041489201772\n",
      "epoch: 465 loss: 0.25299936532974243 grad: 1.3614594603230943\n",
      "epoch: 466 loss: 0.24034325778484344 grad: 1.0178623686215724\n",
      "epoch: 467 loss: 0.21065753698349 grad: 0.6054355972660851\n",
      "epoch: 468 loss: 0.22781185805797577 grad: 0.8788104090963971\n",
      "epoch: 469 loss: 0.21551355719566345 grad: 0.6260048165971457\n",
      "epoch: 470 loss: 0.23135562241077423 grad: 0.8334203710464644\n",
      "epoch: 471 loss: 0.2319074422121048 grad: 1.006550489675312\n",
      "epoch: 472 loss: 0.2302713245153427 grad: 0.8069743326141324\n",
      "epoch: 473 loss: 0.2612374424934387 grad: 1.3166214272304932\n",
      "epoch: 474 loss: 0.2257593870162964 grad: 0.9071099524690072\n",
      "epoch: 475 loss: 0.21395348012447357 grad: 0.6357444082230795\n",
      "epoch: 476 loss: 0.22868677973747253 grad: 0.9299123835952778\n",
      "epoch: 477 loss: 0.24647152423858643 grad: 1.4214616777520277\n",
      "epoch: 478 loss: 0.2799219489097595 grad: 1.7501075293287867\n",
      "epoch: 479 loss: 0.22607161104679108 grad: 0.9025727985834965\n",
      "epoch: 480 loss: 0.22692997753620148 grad: 0.8948194799644988\n",
      "epoch: 481 loss: 0.22970923781394958 grad: 0.8998617507575473\n",
      "epoch: 482 loss: 0.22368459403514862 grad: 0.8768704811817807\n",
      "epoch: 483 loss: 0.22686707973480225 grad: 0.773663366122637\n",
      "epoch: 484 loss: 0.22310395538806915 grad: 0.838515303236607\n",
      "epoch: 485 loss: 0.22609679400920868 grad: 0.87710751474672\n",
      "epoch: 486 loss: 0.21312007308006287 grad: 0.6568625270965603\n",
      "epoch: 487 loss: 0.22625961899757385 grad: 0.8450468618180458\n",
      "epoch: 488 loss: 0.2201269119977951 grad: 0.7924279687560193\n",
      "epoch: 489 loss: 0.21627677977085114 grad: 0.6996217147621246\n",
      "epoch: 490 loss: 0.21555069088935852 grad: 0.6692151179303255\n",
      "epoch: 491 loss: 0.22740189731121063 grad: 0.8075892133074521\n",
      "epoch: 492 loss: 0.22073666751384735 grad: 0.7448224069807111\n",
      "epoch: 493 loss: 0.24099309742450714 grad: 1.1386331522207473\n",
      "epoch: 494 loss: 0.23476570844650269 grad: 0.9628829451544734\n",
      "epoch: 495 loss: 0.23569349944591522 grad: 0.9875188002254\n",
      "epoch: 496 loss: 0.22658990323543549 grad: 0.937009079642492\n",
      "epoch: 497 loss: 0.22188225388526917 grad: 0.7891986048558319\n",
      "epoch: 498 loss: 0.24918772280216217 grad: 1.2918819568610924\n",
      "epoch: 499 loss: 0.25920647382736206 grad: 1.4458416701956813\n",
      "epoch: 500 loss: 0.23128527402877808 grad: 0.8479731002571643\n",
      "epoch: 501 loss: 0.22053338587284088 grad: 0.7200226432942727\n",
      "epoch: 502 loss: 0.21816107630729675 grad: 0.7261426358358222\n",
      "epoch: 503 loss: 0.20559725165367126 grad: 0.504564150179558\n",
      "epoch: 504 loss: 0.215163454413414 grad: 0.6377374623360847\n",
      "epoch: 505 loss: 0.22206725180149078 grad: 0.7977976339827292\n",
      "epoch: 506 loss: 0.2173316329717636 grad: 0.721525313188482\n",
      "epoch: 507 loss: 0.22851303219795227 grad: 0.9317298564871307\n",
      "epoch: 508 loss: 0.23617543280124664 grad: 1.0685568281872255\n",
      "epoch: 509 loss: 0.22394239902496338 grad: 0.7110320783868664\n",
      "epoch: 510 loss: 0.22205284237861633 grad: 0.7960373125671467\n",
      "epoch: 511 loss: 0.22751188278198242 grad: 0.7796345687970243\n",
      "epoch: 512 loss: 0.24897556006908417 grad: 1.2742926449382794\n",
      "epoch: 513 loss: 0.23903006315231323 grad: 1.1837523422110754\n",
      "epoch: 514 loss: 0.2279234081506729 grad: 0.9730848838561796\n",
      "epoch: 515 loss: 0.24074143171310425 grad: 1.2687589142069338\n",
      "epoch: 516 loss: 0.2231077402830124 grad: 0.8226176061131846\n",
      "epoch: 517 loss: 0.22598721086978912 grad: 0.8265297644810052\n",
      "epoch: 518 loss: 0.21785786747932434 grad: 0.7194935236409947\n",
      "epoch: 519 loss: 0.22886234521865845 grad: 0.9152212413588422\n",
      "epoch: 520 loss: 0.22776007652282715 grad: 0.8242633686646587\n",
      "epoch: 521 loss: 0.22039848566055298 grad: 0.7377297036514792\n",
      "epoch: 522 loss: 0.22575286030769348 grad: 0.7872974659738975\n",
      "epoch: 523 loss: 0.21673178672790527 grad: 0.6021506467682921\n",
      "epoch: 524 loss: 0.22125665843486786 grad: 0.748406800651901\n",
      "epoch: 525 loss: 0.23069880902767181 grad: 0.9937639381534537\n",
      "epoch: 526 loss: 0.22568757832050323 grad: 0.8991469294572598\n",
      "epoch: 527 loss: 0.2311108261346817 grad: 0.9353024603002559\n",
      "epoch: 528 loss: 0.2170829474925995 grad: 0.6817050119164487\n",
      "epoch: 529 loss: 0.22671589255332947 grad: 0.7968793321462726\n",
      "epoch: 530 loss: 0.24112258851528168 grad: 1.1401243841680697\n",
      "epoch: 531 loss: 0.21892057359218597 grad: 0.7325469981034548\n",
      "epoch: 532 loss: 0.20535556972026825 grad: 0.46991667920524927\n",
      "epoch: 533 loss: 0.21983632445335388 grad: 0.8853671986976078\n",
      "epoch: 534 loss: 0.22565311193466187 grad: 0.8933025048081763\n",
      "epoch: 535 loss: 0.215816468000412 grad: 0.6562169291641549\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 536 loss: 0.22462421655654907 grad: 0.8588494714135886\n",
      "epoch: 537 loss: 0.2247108370065689 grad: 0.8447180745101941\n",
      "epoch: 538 loss: 0.22204096615314484 grad: 0.8660259241943131\n",
      "epoch: 539 loss: 0.2275739461183548 grad: 0.8852840046105702\n",
      "epoch: 540 loss: 0.21007753908634186 grad: 0.5692645131840145\n",
      "epoch: 541 loss: 0.22835633158683777 grad: 1.0087400952536045\n",
      "epoch: 542 loss: 0.22647444903850555 grad: 0.8186186674761193\n",
      "epoch: 543 loss: 0.24246318638324738 grad: 1.0545777212419198\n",
      "epoch: 544 loss: 0.23098477721214294 grad: 0.9955018559322343\n",
      "epoch: 545 loss: 0.22781750559806824 grad: 0.907923740563885\n",
      "epoch: 546 loss: 0.22107304632663727 grad: 0.6961659334221914\n",
      "epoch: 547 loss: 0.21349765360355377 grad: 0.6330049345562293\n",
      "epoch: 548 loss: 0.22155176103115082 grad: 0.7686044404744607\n",
      "epoch: 549 loss: 0.21478593349456787 grad: 0.4975510050873054\n",
      "epoch: 550 loss: 0.2137478142976761 grad: 0.4708382647393155\n",
      "epoch: 551 loss: 0.20935265719890594 grad: 0.5931727159834208\n",
      "epoch: 552 loss: 0.23351241648197174 grad: 0.915630576831114\n",
      "epoch: 553 loss: 0.23458461463451385 grad: 1.1171913510340965\n",
      "epoch: 554 loss: 0.22755703330039978 grad: 0.998142223362207\n",
      "epoch: 555 loss: 0.23175540566444397 grad: 0.921339280850807\n",
      "epoch: 556 loss: 0.22115588188171387 grad: 0.5788810972985521\n",
      "epoch: 557 loss: 0.22175298631191254 grad: 0.7313406557084964\n",
      "epoch: 558 loss: 0.22676464915275574 grad: 0.7860071838691365\n",
      "epoch: 559 loss: 0.24108083546161652 grad: 1.0044121538422623\n",
      "epoch: 560 loss: 0.2311214804649353 grad: 0.9075689027317567\n",
      "epoch: 561 loss: 0.22201545536518097 grad: 0.8145382761085639\n",
      "epoch: 562 loss: 0.2236696183681488 grad: 0.8026967237670906\n",
      "epoch: 563 loss: 0.23337647318840027 grad: 1.0245963028901168\n",
      "epoch: 564 loss: 0.23620550334453583 grad: 0.9127926106138621\n",
      "epoch: 565 loss: 0.2181890606880188 grad: 0.7493203938632869\n",
      "epoch: 566 loss: 0.22563371062278748 grad: 0.879991181018253\n",
      "epoch: 567 loss: 0.2119002342224121 grad: 0.5644199262615511\n",
      "epoch: 568 loss: 0.20922614634037018 grad: 0.5114433432223595\n",
      "epoch: 569 loss: 0.22357527911663055 grad: 0.7097767063730025\n",
      "epoch: 570 loss: 0.22509843111038208 grad: 0.9177671230928972\n",
      "epoch: 571 loss: 0.22486133873462677 grad: 0.6433770688734476\n",
      "epoch: 572 loss: 0.20829245448112488 grad: 0.4743435702882998\n",
      "epoch: 573 loss: 0.2186492383480072 grad: 0.6309551049270667\n",
      "epoch: 574 loss: 0.22957023978233337 grad: 0.95728251401952\n",
      "epoch: 575 loss: 0.23052236437797546 grad: 1.010516487113433\n",
      "epoch: 576 loss: 0.22152701020240784 grad: 0.8032974161654493\n",
      "epoch: 577 loss: 0.2172679305076599 grad: 0.7165248913682626\n",
      "epoch: 578 loss: 0.22383426129817963 grad: 0.8219773603010307\n",
      "epoch: 579 loss: 0.22503413259983063 grad: 0.7242993206639657\n",
      "epoch: 580 loss: 0.2233550250530243 grad: 0.7735506825445918\n",
      "epoch: 581 loss: 0.20632688701152802 grad: 0.5320287925257581\n",
      "epoch: 582 loss: 0.21732750535011292 grad: 0.6846305850104655\n",
      "epoch: 583 loss: 0.21658839285373688 grad: 0.6714087489081648\n",
      "epoch: 584 loss: 0.22792454063892365 grad: 0.909015249850876\n",
      "epoch: 585 loss: 0.22366194427013397 grad: 0.7334917616222228\n",
      "epoch: 586 loss: 0.2252107560634613 grad: 0.8012845303000359\n",
      "epoch: 587 loss: 0.2190077304840088 grad: 0.7437503413148042\n",
      "epoch: 588 loss: 0.23232272267341614 grad: 0.9712811700663878\n",
      "epoch: 589 loss: 0.2358449399471283 grad: 1.089492483107955\n",
      "epoch: 590 loss: 0.2130928784608841 grad: 0.5601761370517852\n",
      "epoch: 591 loss: 0.22370269894599915 grad: 0.7429987763572717\n",
      "epoch: 592 loss: 0.21528874337673187 grad: 0.6412225436091249\n",
      "epoch: 593 loss: 0.22270065546035767 grad: 0.7658662250803027\n",
      "epoch: 594 loss: 0.22254402935504913 grad: 0.6193121056636665\n",
      "epoch: 595 loss: 0.22940155863761902 grad: 0.8390706300218371\n",
      "epoch: 596 loss: 0.21048447489738464 grad: 0.554713773990843\n",
      "epoch: 597 loss: 0.2144303172826767 grad: 0.7579592054105379\n",
      "epoch: 598 loss: 0.23484785854816437 grad: 1.092434803451848\n",
      "epoch: 599 loss: 0.2284286618232727 grad: 0.7872258721170656\n",
      "epoch: 600 loss: 0.22630493342876434 grad: 0.826159683328122\n",
      "epoch: 601 loss: 0.22661274671554565 grad: 0.9080324702992221\n",
      "epoch: 602 loss: 0.21505986154079437 grad: 0.5995713147425049\n",
      "epoch: 603 loss: 0.2110634446144104 grad: 0.5100869719969778\n",
      "epoch: 604 loss: 0.2147350162267685 grad: 0.6711646768582213\n",
      "epoch: 605 loss: 0.21098175644874573 grad: 0.6668305022665372\n",
      "epoch: 606 loss: 0.2366633266210556 grad: 1.1676732808623491\n",
      "epoch: 607 loss: 0.2601754665374756 grad: 1.7617937624842999\n",
      "epoch: 608 loss: 0.2648545205593109 grad: 1.6328545510693075\n",
      "epoch: 609 loss: 0.2750592529773712 grad: 1.6190431054452201\n",
      "epoch: 610 loss: 0.22530877590179443 grad: 0.9564840916416979\n",
      "epoch: 611 loss: 0.22274808585643768 grad: 0.7683122064152177\n",
      "epoch: 612 loss: 0.21799041330814362 grad: 0.764037650979737\n",
      "epoch: 613 loss: 0.23821866512298584 grad: 1.04863569326764\n",
      "epoch: 614 loss: 0.2159281224012375 grad: 0.7814407846274553\n",
      "epoch: 615 loss: 0.24174225330352783 grad: 1.0284438631545345\n",
      "epoch: 616 loss: 0.2218203991651535 grad: 0.7222370561155403\n",
      "epoch: 617 loss: 0.20694637298583984 grad: 0.5109295985301433\n",
      "epoch: 618 loss: 0.2244306206703186 grad: 0.8357450646859361\n",
      "epoch: 619 loss: 0.20593242347240448 grad: 0.48910967255657306\n",
      "epoch: 620 loss: 0.21208767592906952 grad: 0.5829727557284641\n",
      "epoch: 621 loss: 0.2164723128080368 grad: 0.7137958009759896\n",
      "epoch: 622 loss: 0.22074978053569794 grad: 0.7754761163301446\n",
      "epoch: 623 loss: 0.22852054238319397 grad: 0.8581340961632413\n",
      "epoch: 624 loss: 0.22410814464092255 grad: 0.7415511163350457\n",
      "epoch: 625 loss: 0.21128983795642853 grad: 0.5742773157364655\n",
      "epoch: 626 loss: 0.2279217541217804 grad: 1.0145610834589096\n",
      "epoch: 627 loss: 0.2250688225030899 grad: 0.8582749349853439\n",
      "epoch: 628 loss: 0.2353067547082901 grad: 0.9886099234710082\n",
      "epoch: 629 loss: 0.23315592110157013 grad: 0.9269460790977255\n",
      "epoch: 630 loss: 0.2235407531261444 grad: 0.6963993770804955\n",
      "epoch: 631 loss: 0.20590440928936005 grad: 0.44522165182362367\n",
      "epoch: 632 loss: 0.21424201130867004 grad: 0.6473799128383689\n",
      "epoch: 633 loss: 0.21429292857646942 grad: 0.5378524687863883\n",
      "epoch: 634 loss: 0.2516331374645233 grad: 1.07725264494156\n",
      "epoch: 635 loss: 0.2322118729352951 grad: 0.8132387320674607\n",
      "epoch: 636 loss: 0.22184959053993225 grad: 0.8119763913092902\n",
      "epoch: 637 loss: 0.22797872126102448 grad: 0.8254363605949256\n",
      "epoch: 638 loss: 0.21428921818733215 grad: 0.6769387472805902\n",
      "epoch: 639 loss: 0.2075960636138916 grad: 0.4940052047025092\n",
      "epoch: 640 loss: 0.20856505632400513 grad: 0.47651165322490485\n",
      "epoch: 641 loss: 0.2153845578432083 grad: 0.5541303181911353\n",
      "epoch: 642 loss: 0.21495558321475983 grad: 0.7177977576212433\n",
      "epoch: 643 loss: 0.2191290259361267 grad: 0.7449333682657744\n",
      "epoch: 644 loss: 0.21488556265830994 grad: 0.7520295175879074\n",
      "epoch: 645 loss: 0.23521876335144043 grad: 0.9043886785765062\n",
      "epoch: 646 loss: 0.21055607497692108 grad: 0.5562521318316103\n",
      "epoch: 647 loss: 0.23504570126533508 grad: 0.9230404549481463\n",
      "epoch: 648 loss: 0.2199907898902893 grad: 0.7241035710295218\n",
      "epoch: 649 loss: 0.2739957869052887 grad: 1.4714782783918199\n",
      "epoch: 650 loss: 0.2408391535282135 grad: 1.1487422875848934\n",
      "epoch: 651 loss: 0.22095362842082977 grad: 0.7573103262068398\n",
      "epoch: 652 loss: 0.23152384161949158 grad: 0.996914736668974\n",
      "epoch: 653 loss: 0.2230268120765686 grad: 0.8197452800054016\n",
      "epoch: 654 loss: 0.21807046234607697 grad: 0.8160478790756278\n",
      "epoch: 655 loss: 0.22542256116867065 grad: 0.8150425303283774\n",
      "epoch: 656 loss: 0.2435513138771057 grad: 1.2025179274269904\n",
      "epoch: 657 loss: 0.21812526881694794 grad: 0.6483992465144547\n",
      "epoch: 658 loss: 0.21216748654842377 grad: 0.5264814994495682\n",
      "epoch: 659 loss: 0.20512355864048004 grad: 0.4607848615173425\n",
      "epoch: 660 loss: 0.21900883316993713 grad: 0.7496843119032401\n",
      "epoch: 661 loss: 0.21129444241523743 grad: 0.5553841742214282\n",
      "epoch: 662 loss: 0.215134859085083 grad: 0.5999081972695348\n",
      "epoch: 663 loss: 0.21584157645702362 grad: 0.7285211673024642\n",
      "epoch: 664 loss: 0.21310853958129883 grad: 0.5947254784494362\n",
      "epoch: 665 loss: 0.2111738622188568 grad: 0.6496979019800201\n",
      "epoch: 666 loss: 0.2601639926433563 grad: 1.4098000569656723\n",
      "epoch: 667 loss: 0.24255746603012085 grad: 1.1096010342521767\n",
      "epoch: 668 loss: 0.23837155103683472 grad: 1.0527419606363109\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 669 loss: 0.21342232823371887 grad: 0.696460003395614\n",
      "epoch: 670 loss: 0.2148514986038208 grad: 0.5358399077876893\n",
      "epoch: 671 loss: 0.20398224890232086 grad: 0.3621082884512234\n",
      "epoch: 672 loss: 0.23090505599975586 grad: 0.8341773140134828\n",
      "epoch: 673 loss: 0.21434251964092255 grad: 0.5696809907004353\n",
      "epoch: 674 loss: 0.20830944180488586 grad: 0.45948754312942536\n",
      "epoch: 675 loss: 0.20572379231452942 grad: 0.4368706820248044\n",
      "epoch: 676 loss: 0.22474659979343414 grad: 0.8465465283888188\n",
      "epoch: 677 loss: 0.2125055342912674 grad: 0.6392992771170466\n",
      "epoch: 678 loss: 0.21156767010688782 grad: 0.5897424554545933\n",
      "epoch: 679 loss: 0.21754604578018188 grad: 0.7207779943451605\n",
      "epoch: 680 loss: 0.22277654707431793 grad: 0.6329297484667186\n",
      "epoch: 681 loss: 0.2178650200366974 grad: 0.819853161977444\n",
      "epoch: 682 loss: 0.2437276542186737 grad: 1.0590328907412185\n",
      "epoch: 683 loss: 0.21463951468467712 grad: 0.619416487764509\n",
      "epoch: 684 loss: 0.23282156884670258 grad: 0.9197848694643762\n",
      "epoch: 685 loss: 0.22271937131881714 grad: 0.7907955491910252\n",
      "epoch: 686 loss: 0.20660068094730377 grad: 0.43444303915879573\n",
      "epoch: 687 loss: 0.2105453461408615 grad: 0.5345417898369378\n",
      "epoch: 688 loss: 0.2189020961523056 grad: 0.6981900763939848\n",
      "epoch: 689 loss: 0.2242133766412735 grad: 0.8351835313814663\n",
      "epoch: 690 loss: 0.2198970764875412 grad: 0.6969452099652481\n",
      "epoch: 691 loss: 0.22020144760608673 grad: 0.6664672852589574\n",
      "epoch: 692 loss: 0.22377397119998932 grad: 0.8710768944968222\n",
      "epoch: 693 loss: 0.2239532321691513 grad: 0.7706411511833305\n",
      "epoch: 694 loss: 0.21523642539978027 grad: 0.5618824974975516\n",
      "epoch: 695 loss: 0.2142869085073471 grad: 0.6057495739174665\n",
      "epoch: 696 loss: 0.21093879640102386 grad: 0.5419237004646711\n",
      "epoch: 697 loss: 0.2135629653930664 grad: 0.5444179435113374\n",
      "epoch: 698 loss: 0.23103104531764984 grad: 1.015102529429434\n",
      "epoch: 699 loss: 0.2385147511959076 grad: 1.1321871907055028\n",
      "epoch: 700 loss: 0.23274564743041992 grad: 0.8808362343604677\n",
      "epoch: 701 loss: 0.2084374576807022 grad: 0.37465227103525833\n",
      "epoch: 702 loss: 0.23182730376720428 grad: 0.9233909084992592\n",
      "epoch: 703 loss: 0.2184331715106964 grad: 0.7122190617652959\n",
      "epoch: 704 loss: 0.21233704686164856 grad: 0.5109387694411053\n",
      "epoch: 705 loss: 0.21990704536437988 grad: 0.7091661954004521\n",
      "epoch: 706 loss: 0.2179921567440033 grad: 0.629393148225452\n",
      "epoch: 707 loss: 0.23940713703632355 grad: 1.0738933887184685\n",
      "epoch: 708 loss: 0.2167212814092636 grad: 0.6265299578057347\n",
      "epoch: 709 loss: 0.21546219289302826 grad: 0.6366617056089781\n",
      "epoch: 710 loss: 0.2069418877363205 grad: 0.47810657872914725\n",
      "epoch: 711 loss: 0.21026642620563507 grad: 0.5679487602503887\n",
      "epoch: 712 loss: 0.21015943586826324 grad: 0.4487605360867601\n",
      "epoch: 713 loss: 0.20499607920646667 grad: 0.4069780432208936\n",
      "epoch: 714 loss: 0.20534861087799072 grad: 0.4566734662606641\n",
      "epoch: 715 loss: 0.21679075062274933 grad: 0.5140392495768356\n",
      "epoch: 716 loss: 0.2083575576543808 grad: 0.584028680010857\n",
      "epoch: 717 loss: 0.21551169455051422 grad: 0.6518324526315664\n",
      "epoch: 718 loss: 0.24640420079231262 grad: 1.345286634512555\n",
      "epoch: 719 loss: 0.2682963013648987 grad: 1.3125392783018615\n",
      "epoch: 720 loss: 0.22480516135692596 grad: 0.7943773981720442\n",
      "epoch: 721 loss: 0.23087146878242493 grad: 1.1589947936845129\n",
      "epoch: 722 loss: 0.2375100553035736 grad: 1.0106020137486922\n",
      "epoch: 723 loss: 0.21795882284641266 grad: 0.7617683692521204\n",
      "epoch: 724 loss: 0.2561458647251129 grad: 1.2092256497866183\n",
      "epoch: 725 loss: 0.246742382645607 grad: 1.2647919350897427\n",
      "epoch: 726 loss: 0.2272970974445343 grad: 0.7651591908579867\n",
      "epoch: 727 loss: 0.2093295305967331 grad: 0.460765857802322\n",
      "epoch: 728 loss: 0.2460426688194275 grad: 1.0788469182758418\n",
      "epoch: 729 loss: 0.22188282012939453 grad: 0.7171034334463475\n",
      "epoch: 730 loss: 0.21527928113937378 grad: 0.7752113013669732\n",
      "epoch: 731 loss: 0.23706664144992828 grad: 0.8789851657539693\n",
      "epoch: 732 loss: 0.21537348628044128 grad: 0.7319682659265091\n",
      "epoch: 733 loss: 0.21300384402275085 grad: 0.5387889494587508\n",
      "epoch: 734 loss: 0.21346981823444366 grad: 0.6507777230228748\n",
      "epoch: 735 loss: 0.2295139729976654 grad: 0.7441377369257535\n",
      "epoch: 736 loss: 0.21186533570289612 grad: 0.5317415425195068\n",
      "epoch: 737 loss: 0.20838342607021332 grad: 0.56365551996883\n",
      "epoch: 738 loss: 0.20773407816886902 grad: 0.4263947689697707\n",
      "epoch: 739 loss: 0.20754219591617584 grad: 0.4498569115391074\n",
      "epoch: 740 loss: 0.23704469203948975 grad: 1.0692471102492564\n",
      "epoch: 741 loss: 0.23036593198776245 grad: 0.8894716349549125\n",
      "epoch: 742 loss: 0.21525338292121887 grad: 0.6260689547511065\n",
      "epoch: 743 loss: 0.2346341907978058 grad: 0.8830319597158377\n",
      "epoch: 744 loss: 0.2068977802991867 grad: 0.4224029858381182\n",
      "epoch: 745 loss: 0.21913021802902222 grad: 0.7394942660224452\n",
      "epoch: 746 loss: 0.21026556193828583 grad: 0.5374410273907426\n",
      "epoch: 747 loss: 0.212354838848114 grad: 0.6248617973359142\n",
      "epoch: 748 loss: 0.209745854139328 grad: 0.5248481314383607\n",
      "epoch: 749 loss: 0.22437888383865356 grad: 0.7251016267567829\n",
      "epoch: 750 loss: 0.21539948880672455 grad: 0.5574450630806678\n",
      "epoch: 751 loss: 0.21673975884914398 grad: 0.5987391965858042\n",
      "epoch: 752 loss: 0.21392567455768585 grad: 0.5446725430458318\n",
      "epoch: 753 loss: 0.22234997153282166 grad: 0.7547808544871659\n",
      "epoch: 754 loss: 0.22234900295734406 grad: 0.5871573100368914\n",
      "epoch: 755 loss: 0.22643138468265533 grad: 0.8242454183335067\n",
      "epoch: 756 loss: 0.2155253291130066 grad: 0.7571230284446793\n",
      "epoch: 757 loss: 0.21954180300235748 grad: 0.7548266390299541\n",
      "epoch: 758 loss: 0.22766351699829102 grad: 0.9157204831751878\n",
      "epoch: 759 loss: 0.22454160451889038 grad: 0.9219109824434563\n",
      "epoch: 760 loss: 0.23518826067447662 grad: 0.8476073147312855\n",
      "epoch: 761 loss: 0.2070649415254593 grad: 0.36712275684922496\n",
      "epoch: 762 loss: 0.2154189944267273 grad: 0.5320078916906495\n",
      "epoch: 763 loss: 0.2060229331254959 grad: 0.5435568816345913\n",
      "epoch: 764 loss: 0.23262248933315277 grad: 0.9366171461806225\n",
      "epoch: 765 loss: 0.2101573348045349 grad: 0.5208497769138376\n",
      "epoch: 766 loss: 0.2123163640499115 grad: 0.6527557305251576\n",
      "epoch: 767 loss: 0.2111792117357254 grad: 0.5774688646323776\n",
      "epoch: 768 loss: 0.22659943997859955 grad: 0.8527271322378001\n",
      "epoch: 769 loss: 0.22137869894504547 grad: 0.6357624750641262\n",
      "epoch: 770 loss: 0.22776836156845093 grad: 0.9811241172601922\n",
      "epoch: 771 loss: 0.21722480654716492 grad: 0.5335344424571377\n",
      "epoch: 772 loss: 0.22234438359737396 grad: 0.7907176468663892\n",
      "epoch: 773 loss: 0.2222713828086853 grad: 0.7030139790141547\n",
      "epoch: 774 loss: 0.21914200484752655 grad: 0.6226898183632474\n",
      "epoch: 775 loss: 0.22905118763446808 grad: 0.8906747580706724\n",
      "epoch: 776 loss: 0.20995061099529266 grad: 0.5637855836837043\n",
      "epoch: 777 loss: 0.22193215787410736 grad: 0.724589538252345\n",
      "epoch: 778 loss: 0.20451386272907257 grad: 0.427481822116235\n",
      "epoch: 779 loss: 0.21148312091827393 grad: 0.5510010253245491\n",
      "epoch: 780 loss: 0.20684383809566498 grad: 0.43737877734695574\n",
      "epoch: 781 loss: 0.21141038835048676 grad: 0.5705423933361963\n",
      "epoch: 782 loss: 0.21894483268260956 grad: 0.7691313455296404\n",
      "epoch: 783 loss: 0.21555808186531067 grad: 0.60868705448338\n",
      "epoch: 784 loss: 0.21715658903121948 grad: 0.6121515770208061\n",
      "epoch: 785 loss: 0.21238087117671967 grad: 0.5771780719329254\n",
      "epoch: 786 loss: 0.2149234265089035 grad: 0.5867788048914372\n",
      "epoch: 787 loss: 0.23642662167549133 grad: 1.2910270862260786\n",
      "epoch: 788 loss: 0.25703537464141846 grad: 1.4720129339149752\n",
      "epoch: 789 loss: 0.262152761220932 grad: 1.431934190388969\n",
      "epoch: 790 loss: 0.24248360097408295 grad: 1.1068322009564453\n",
      "epoch: 791 loss: 0.22942708432674408 grad: 0.8540193262163921\n",
      "epoch: 792 loss: 0.2308184951543808 grad: 0.9024120997718382\n",
      "epoch: 793 loss: 0.22548164427280426 grad: 0.7969928153147066\n",
      "epoch: 794 loss: 0.21547843515872955 grad: 0.6388885353099354\n",
      "epoch: 795 loss: 0.20845165848731995 grad: 0.5614104074644756\n",
      "epoch: 796 loss: 0.20967179536819458 grad: 0.4916804106412965\n",
      "epoch: 797 loss: 0.21552087366580963 grad: 0.660513335297399\n",
      "epoch: 798 loss: 0.21462973952293396 grad: 0.5467821076543351\n",
      "epoch: 799 loss: 0.22692818939685822 grad: 0.8124517913141571\n",
      "epoch: 800 loss: 0.2345503866672516 grad: 0.9873713522268371\n",
      "epoch: 801 loss: 0.21589064598083496 grad: 0.7065684908700641\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 802 loss: 0.21166858077049255 grad: 0.5442447294493722\n",
      "epoch: 803 loss: 0.21004125475883484 grad: 0.5382158016213052\n",
      "epoch: 804 loss: 0.205446258187294 grad: 0.436180209119153\n",
      "epoch: 805 loss: 0.2027825266122818 grad: 0.4052993612271989\n",
      "epoch: 806 loss: 0.2108377367258072 grad: 0.5313011757944878\n",
      "epoch: 807 loss: 0.21123065054416656 grad: 0.561837336649296\n",
      "epoch: 808 loss: 0.2145601361989975 grad: 0.5625783397466002\n",
      "epoch: 809 loss: 0.2043798267841339 grad: 0.4149890567536504\n",
      "epoch: 810 loss: 0.22105582058429718 grad: 0.8000269529515645\n",
      "epoch: 811 loss: 0.2373274713754654 grad: 1.2097725858698796\n",
      "epoch: 812 loss: 0.20845384895801544 grad: 0.5059197983344333\n",
      "epoch: 813 loss: 0.2319311648607254 grad: 0.8856015665885607\n",
      "epoch: 814 loss: 0.24265295267105103 grad: 1.212991093589717\n",
      "epoch: 815 loss: 0.22506077587604523 grad: 0.7550757909038294\n",
      "epoch: 816 loss: 0.2230152189731598 grad: 0.7729951171254797\n",
      "epoch: 817 loss: 0.23775772750377655 grad: 0.8652885160246806\n",
      "epoch: 818 loss: 0.2367461770772934 grad: 1.068967627757207\n",
      "epoch: 819 loss: 0.2123972624540329 grad: 0.6103460717171929\n",
      "epoch: 820 loss: 0.2282267063856125 grad: 1.0370727864964282\n",
      "epoch: 821 loss: 0.2348964363336563 grad: 1.0347496951646318\n",
      "epoch: 822 loss: 0.21036870777606964 grad: 0.4809139798494216\n",
      "epoch: 823 loss: 0.21186913549900055 grad: 0.567576956761357\n",
      "epoch: 824 loss: 0.20120202004909515 grad: 0.4015441578065111\n",
      "epoch: 825 loss: 0.20839881896972656 grad: 0.4989977287218098\n",
      "epoch: 826 loss: 0.20718282461166382 grad: 0.42442617126493315\n",
      "epoch: 827 loss: 0.20645639300346375 grad: 0.4174966756077374\n",
      "epoch: 828 loss: 0.20853057503700256 grad: 0.4829271615289072\n",
      "epoch: 829 loss: 0.20670635998249054 grad: 0.4884166017465286\n",
      "epoch: 830 loss: 0.23397468030452728 grad: 0.8206836642119997\n",
      "epoch: 831 loss: 0.21484246850013733 grad: 0.5742523703904153\n",
      "epoch: 832 loss: 0.21300704777240753 grad: 0.71607782277948\n",
      "epoch: 833 loss: 0.21992482244968414 grad: 0.6715548968458024\n",
      "epoch: 834 loss: 0.22616367042064667 grad: 0.8157201387446039\n",
      "epoch: 835 loss: 0.21474139392375946 grad: 0.7773967909445564\n",
      "epoch: 836 loss: 0.22426646947860718 grad: 0.7647327743035858\n",
      "epoch: 837 loss: 0.21632176637649536 grad: 0.6431129576160747\n",
      "epoch: 838 loss: 0.2106296420097351 grad: 0.5097079059328243\n",
      "epoch: 839 loss: 0.21575085818767548 grad: 0.6346435113144253\n",
      "epoch: 840 loss: 0.2147092968225479 grad: 0.49801290465977943\n",
      "epoch: 841 loss: 0.21520856022834778 grad: 0.6270597900227513\n",
      "epoch: 842 loss: 0.21850596368312836 grad: 0.6112566219514992\n",
      "epoch: 843 loss: 0.21432353556156158 grad: 0.6059670360428572\n",
      "epoch: 844 loss: 0.20011025667190552 grad: 0.30488591569976964\n",
      "epoch: 845 loss: 0.20699739456176758 grad: 0.7086343761951698\n",
      "epoch: 846 loss: 0.22371773421764374 grad: 0.7603220520296163\n",
      "epoch: 847 loss: 0.2095659226179123 grad: 0.5121354827814139\n",
      "epoch: 848 loss: 0.21195581555366516 grad: 0.6290351861423319\n",
      "epoch: 849 loss: 0.21720445156097412 grad: 0.5978851943874033\n",
      "epoch: 850 loss: 0.20867936313152313 grad: 0.5372125823777641\n",
      "epoch: 851 loss: 0.21479037404060364 grad: 0.6128354426668693\n",
      "epoch: 852 loss: 0.22092102468013763 grad: 0.6907086293498215\n",
      "epoch: 853 loss: 0.21943189203739166 grad: 0.7443929311536267\n",
      "epoch: 854 loss: 0.22639253735542297 grad: 0.7621621873035328\n",
      "epoch: 855 loss: 0.21101053059101105 grad: 0.5131843853776518\n",
      "epoch: 856 loss: 0.2268514484167099 grad: 0.954816471691036\n",
      "epoch: 857 loss: 0.21934953331947327 grad: 0.6171724695923331\n",
      "epoch: 858 loss: 0.21540731191635132 grad: 0.5525731653072362\n",
      "epoch: 859 loss: 0.20728528499603271 grad: 0.3979931164001173\n",
      "epoch: 860 loss: 0.22033768892288208 grad: 0.7199255666899117\n",
      "epoch: 861 loss: 0.2219899296760559 grad: 0.5775251507807707\n",
      "epoch: 862 loss: 0.24605178833007812 grad: 1.0690662435293052\n",
      "epoch: 863 loss: 0.2580324113368988 grad: 1.4515025287017451\n",
      "epoch: 864 loss: 0.23148797452449799 grad: 0.9477748067508365\n",
      "epoch: 865 loss: 0.21505999565124512 grad: 0.6588162727680829\n",
      "epoch: 866 loss: 0.216054767370224 grad: 0.6774023493070818\n",
      "epoch: 867 loss: 0.2032022327184677 grad: 0.45398644253993553\n",
      "epoch: 868 loss: 0.22187699377536774 grad: 0.7189020694494466\n",
      "epoch: 869 loss: 0.20394988358020782 grad: 0.43410577957625446\n",
      "epoch: 870 loss: 0.21552731096744537 grad: 0.6583332515682959\n",
      "epoch: 871 loss: 0.21290943026542664 grad: 0.5693253991532056\n",
      "epoch: 872 loss: 0.2191930115222931 grad: 0.694933831630391\n",
      "epoch: 873 loss: 0.21708530187606812 grad: 0.5711140380062661\n",
      "epoch: 874 loss: 0.21996937692165375 grad: 0.8697681715298567\n",
      "epoch: 875 loss: 0.21546484529972076 grad: 0.5900132514639045\n",
      "epoch: 876 loss: 0.20917469263076782 grad: 0.4484069779420097\n",
      "epoch: 877 loss: 0.20884843170642853 grad: 0.58833456301982\n",
      "epoch: 878 loss: 0.21343354880809784 grad: 0.7988673142758125\n",
      "epoch: 879 loss: 0.224789097905159 grad: 0.7456996096136791\n",
      "epoch: 880 loss: 0.21356360614299774 grad: 0.48182009097804984\n",
      "epoch: 881 loss: 0.21864381432533264 grad: 0.6642970004964954\n",
      "epoch: 882 loss: 0.20690596103668213 grad: 0.3637107996830964\n",
      "epoch: 883 loss: 0.19978493452072144 grad: 0.3568651384574441\n",
      "epoch: 884 loss: 0.1996048241853714 grad: 0.2806161272502977\n",
      "epoch: 885 loss: 0.20896989107131958 grad: 0.5477517841122462\n",
      "epoch: 886 loss: 0.20847858488559723 grad: 0.5342871266193288\n",
      "epoch: 887 loss: 0.20935790240764618 grad: 0.5096906364553725\n",
      "epoch: 888 loss: 0.20449507236480713 grad: 0.4349530386186052\n",
      "epoch: 889 loss: 0.21147792041301727 grad: 0.5393569690256418\n",
      "epoch: 890 loss: 0.21937932074069977 grad: 0.6001304567534352\n",
      "epoch: 891 loss: 0.22261613607406616 grad: 0.6226110923484439\n",
      "epoch: 892 loss: 0.2070426344871521 grad: 0.43659035050883177\n",
      "epoch: 893 loss: 0.2157544493675232 grad: 0.6229869248891154\n",
      "epoch: 894 loss: 0.23379004001617432 grad: 1.0043442516938084\n",
      "epoch: 895 loss: 0.24022579193115234 grad: 1.0242031807256136\n",
      "epoch: 896 loss: 0.2399923950433731 grad: 0.9296950969580503\n",
      "epoch: 897 loss: 0.2152193784713745 grad: 0.7073410391612706\n",
      "epoch: 898 loss: 0.21282851696014404 grad: 0.5360774605562292\n",
      "epoch: 899 loss: 0.20900802314281464 grad: 0.5156372600600225\n",
      "epoch: 900 loss: 0.21045176684856415 grad: 0.5340122313114262\n",
      "epoch: 901 loss: 0.2224532812833786 grad: 0.6358495293110754\n",
      "epoch: 902 loss: 0.21096572279930115 grad: 0.5259751161921158\n",
      "epoch: 903 loss: 0.2082352340221405 grad: 0.4700836142891967\n",
      "epoch: 904 loss: 0.20393216609954834 grad: 0.36494891268603535\n",
      "epoch: 905 loss: 0.2122853398323059 grad: 0.5772264239122596\n",
      "epoch: 906 loss: 0.20702441036701202 grad: 0.4443574432717869\n",
      "epoch: 907 loss: 0.21542209386825562 grad: 0.4677516114024329\n",
      "epoch: 908 loss: 0.21040081977844238 grad: 0.49819795799852\n",
      "epoch: 909 loss: 0.20435914397239685 grad: 0.39487083986269683\n",
      "epoch: 910 loss: 0.21428672969341278 grad: 0.6059818628291505\n",
      "epoch: 911 loss: 0.21433936059474945 grad: 0.6969725515665414\n",
      "epoch: 912 loss: 0.2203313410282135 grad: 0.6997701250142382\n",
      "epoch: 913 loss: 0.20815293490886688 grad: 0.45869391901390033\n",
      "epoch: 914 loss: 0.21269844472408295 grad: 0.5770421451402153\n",
      "epoch: 915 loss: 0.20990663766860962 grad: 0.5502513432526734\n",
      "epoch: 916 loss: 0.21173158288002014 grad: 0.5525300566422138\n",
      "epoch: 917 loss: 0.209272563457489 grad: 0.5261440237045408\n",
      "epoch: 918 loss: 0.20902936160564423 grad: 0.5283060053434019\n",
      "epoch: 919 loss: 0.23061662912368774 grad: 0.9998712788290868\n",
      "epoch: 920 loss: 0.21905072033405304 grad: 0.753487833768384\n",
      "epoch: 921 loss: 0.22849859297275543 grad: 0.8548487647017028\n",
      "epoch: 922 loss: 0.21157270669937134 grad: 0.5038101000938695\n",
      "epoch: 923 loss: 0.21553218364715576 grad: 0.5878250106977521\n",
      "epoch: 924 loss: 0.21253347396850586 grad: 0.566502872569713\n",
      "epoch: 925 loss: 0.2105444371700287 grad: 0.43554540951587295\n",
      "epoch: 926 loss: 0.20583613216876984 grad: 0.41665652615553883\n",
      "epoch: 927 loss: 0.21632982790470123 grad: 0.591002119735851\n",
      "epoch: 928 loss: 0.21124449372291565 grad: 0.49679029516921036\n",
      "epoch: 929 loss: 0.2125832587480545 grad: 0.5969255203711509\n",
      "epoch: 930 loss: 0.22210511565208435 grad: 0.7493472709100961\n",
      "epoch: 931 loss: 0.20896612107753754 grad: 0.4936015484043201\n",
      "epoch: 932 loss: 0.21243895590305328 grad: 0.5235848390656583\n",
      "epoch: 933 loss: 0.20930692553520203 grad: 0.4794355623115443\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 934 loss: 0.2103026956319809 grad: 0.5171251232228824\n",
      "epoch: 935 loss: 0.21652550995349884 grad: 0.684830076373124\n",
      "epoch: 936 loss: 0.22105926275253296 grad: 0.7202243941693669\n",
      "epoch: 937 loss: 0.22886107861995697 grad: 0.9155982295773974\n",
      "epoch: 938 loss: 0.2712208926677704 grad: 1.6744779576185391\n",
      "epoch: 939 loss: 0.2526593804359436 grad: 1.182774329294254\n",
      "epoch: 940 loss: 0.2244289517402649 grad: 0.7332293940587696\n",
      "epoch: 941 loss: 0.2159750908613205 grad: 0.6038484494215609\n",
      "epoch: 942 loss: 0.2094620168209076 grad: 0.49589543230185334\n",
      "epoch: 943 loss: 0.20932459831237793 grad: 0.4677409076969197\n",
      "epoch: 944 loss: 0.22106531262397766 grad: 0.667463095885847\n",
      "epoch: 945 loss: 0.22025957703590393 grad: 0.6278347033985919\n",
      "epoch: 946 loss: 0.2038843333721161 grad: 0.38146105088633614\n",
      "epoch: 947 loss: 0.21477293968200684 grad: 0.5508487942629545\n",
      "epoch: 948 loss: 0.20450326800346375 grad: 0.3780568995869744\n",
      "epoch: 949 loss: 0.21229387819766998 grad: 0.6078519836902596\n",
      "epoch: 950 loss: 0.21065735816955566 grad: 0.5277679232315459\n",
      "epoch: 951 loss: 0.21030890941619873 grad: 0.4817095285614123\n",
      "epoch: 952 loss: 0.2338773012161255 grad: 0.9283820079513025\n",
      "epoch: 953 loss: 0.21941903233528137 grad: 0.6082670944748825\n",
      "epoch: 954 loss: 0.21184541285037994 grad: 0.6450950860450976\n",
      "epoch: 955 loss: 0.21001359820365906 grad: 0.549097460781606\n",
      "epoch: 956 loss: 0.21283581852912903 grad: 0.6148793455181513\n",
      "epoch: 957 loss: 0.21287333965301514 grad: 0.6428832731729636\n",
      "epoch: 958 loss: 0.22760221362113953 grad: 0.9655507456782798\n",
      "epoch: 959 loss: 0.2578014135360718 grad: 1.1155313774341158\n",
      "epoch: 960 loss: 0.21995623409748077 grad: 0.7688851750251524\n",
      "epoch: 961 loss: 0.2234702706336975 grad: 0.6456723810755212\n",
      "epoch: 962 loss: 0.22956636548042297 grad: 0.8464991648015566\n",
      "epoch: 963 loss: 0.2228376865386963 grad: 0.7426668488918294\n",
      "epoch: 964 loss: 0.2179543823003769 grad: 0.7646781073605016\n",
      "epoch: 965 loss: 0.2259819209575653 grad: 0.7269697895986044\n",
      "epoch: 966 loss: 0.20879846811294556 grad: 0.5990921310909325\n",
      "epoch: 967 loss: 0.20229238271713257 grad: 0.4409431433755235\n",
      "epoch: 968 loss: 0.21516141295433044 grad: 0.709965312281347\n",
      "epoch: 969 loss: 0.20906858146190643 grad: 0.5195328472040037\n",
      "epoch: 970 loss: 0.21478159725666046 grad: 0.782718726919451\n",
      "epoch: 971 loss: 0.21223440766334534 grad: 0.556383539150349\n",
      "epoch: 972 loss: 0.21630637347698212 grad: 0.6778419264242083\n",
      "epoch: 973 loss: 0.20856943726539612 grad: 0.5622029405304402\n",
      "epoch: 974 loss: 0.20117059350013733 grad: 0.3313036068909787\n",
      "epoch: 975 loss: 0.21129460632801056 grad: 0.5636910609634423\n",
      "epoch: 976 loss: 0.21056652069091797 grad: 0.5365781231927212\n",
      "epoch: 977 loss: 0.20558644831180573 grad: 0.49445237546276255\n",
      "epoch: 978 loss: 0.20862431824207306 grad: 0.5085355274279117\n",
      "epoch: 979 loss: 0.20486854016780853 grad: 0.4465522368335569\n",
      "epoch: 980 loss: 0.21275882422924042 grad: 0.5320539776318458\n",
      "epoch: 981 loss: 0.20428228378295898 grad: 0.4808364840445538\n",
      "epoch: 982 loss: 0.2161046266555786 grad: 0.5725389624696691\n",
      "epoch: 983 loss: 0.21174746751785278 grad: 0.4494886303548428\n",
      "epoch: 984 loss: 0.21988588571548462 grad: 0.7572532325028878\n",
      "epoch: 985 loss: 0.22237853705883026 grad: 0.6911241531391279\n",
      "epoch: 986 loss: 0.2200838327407837 grad: 0.6645749216090698\n",
      "epoch: 987 loss: 0.2054154872894287 grad: 0.5588705135343189\n",
      "epoch: 988 loss: 0.21733936667442322 grad: 0.8759411571476579\n",
      "epoch: 989 loss: 0.21411418914794922 grad: 0.5655641333563053\n",
      "epoch: 990 loss: 0.20705541968345642 grad: 0.41379743116603096\n",
      "epoch: 991 loss: 0.2223595529794693 grad: 0.9231144993622602\n",
      "epoch: 992 loss: 0.24799484014511108 grad: 1.2072173562728858\n",
      "epoch: 993 loss: 0.24917568266391754 grad: 1.2301481677185075\n",
      "epoch: 994 loss: 0.2209300845861435 grad: 0.5773736769267707\n",
      "epoch: 995 loss: 0.22313183546066284 grad: 0.8018735540644703\n",
      "epoch: 996 loss: 0.2050696462392807 grad: 0.45958232305529234\n",
      "epoch: 997 loss: 0.210159033536911 grad: 0.5538247672816087\n",
      "epoch: 998 loss: 0.2129059135913849 grad: 0.5618533108320262\n",
      "epoch: 999 loss: 0.2099834531545639 grad: 0.5593264434782995\n",
      "epoch: 1000 loss: 0.20714424550533295 grad: 0.49269658768171937\n",
      "epoch: 1001 loss: 0.21015705168247223 grad: 0.6174472809224789\n",
      "epoch: 1002 loss: 0.2896730601787567 grad: 1.6399687879204938\n",
      "epoch: 1003 loss: 0.2147979736328125 grad: 0.5313140079367731\n",
      "epoch: 1004 loss: 0.2038610875606537 grad: 0.4052953743996768\n",
      "epoch: 1005 loss: 0.213293194770813 grad: 0.4527249181656116\n",
      "epoch: 1006 loss: 0.21282386779785156 grad: 0.5776850354077178\n",
      "epoch: 1007 loss: 0.20810551941394806 grad: 0.5147229007977294\n",
      "epoch: 1008 loss: 0.20410801470279694 grad: 0.4699472780106171\n",
      "epoch: 1009 loss: 0.205978661775589 grad: 0.4025466633463002\n",
      "epoch: 1010 loss: 0.21541446447372437 grad: 0.6881812366298745\n",
      "epoch: 1011 loss: 0.20472441613674164 grad: 0.48196150149842926\n",
      "epoch: 1012 loss: 0.2087622731924057 grad: 0.5442367485699652\n",
      "epoch: 1013 loss: 0.2228548377752304 grad: 0.7787284528190066\n",
      "epoch: 1014 loss: 0.21753990650177002 grad: 0.6039172936212781\n",
      "epoch: 1015 loss: 0.21094165742397308 grad: 0.5485673403238106\n",
      "epoch: 1016 loss: 0.2112291157245636 grad: 0.5860008172563176\n",
      "epoch: 1017 loss: 0.20975537598133087 grad: 0.6160001830928231\n",
      "epoch: 1018 loss: 0.2133582979440689 grad: 0.5671950444759132\n",
      "epoch: 1019 loss: 0.25377723574638367 grad: 1.1492409684712692\n",
      "epoch: 1020 loss: 0.21290898323059082 grad: 0.6513224721978604\n",
      "epoch: 1021 loss: 0.21402929723262787 grad: 0.6100529838766088\n",
      "epoch: 1022 loss: 0.20875488221645355 grad: 0.5226203271853738\n",
      "epoch: 1023 loss: 0.21492330729961395 grad: 0.643297231028002\n",
      "epoch: 1024 loss: 0.20716343820095062 grad: 0.5459118814204521\n",
      "epoch: 1025 loss: 0.21285380423069 grad: 0.5779544732583963\n",
      "epoch: 1026 loss: 0.21274878084659576 grad: 0.5385644018757448\n",
      "epoch: 1027 loss: 0.2204672396183014 grad: 0.7644430837615291\n",
      "epoch: 1028 loss: 0.2304660975933075 grad: 0.9488122728066791\n",
      "epoch: 1029 loss: 0.2157028615474701 grad: 0.685695728198174\n",
      "epoch: 1030 loss: 0.20904278755187988 grad: 0.47514847433910107\n",
      "epoch: 1031 loss: 0.2104748785495758 grad: 0.6668040696773405\n",
      "epoch: 1032 loss: 0.2107611447572708 grad: 0.6167708640157948\n",
      "epoch: 1033 loss: 0.20158651471138 grad: 0.4475065660586315\n",
      "epoch: 1034 loss: 0.2055053412914276 grad: 0.4671631279518424\n",
      "epoch: 1035 loss: 0.20160406827926636 grad: 0.3982262942396101\n",
      "epoch: 1036 loss: 0.20522339642047882 grad: 0.5690877663797855\n",
      "epoch: 1037 loss: 0.20838765799999237 grad: 0.6322297067021454\n",
      "epoch: 1038 loss: 0.21346504986286163 grad: 0.6179192554340243\n",
      "epoch: 1039 loss: 0.2135745882987976 grad: 0.665077052768931\n",
      "epoch: 1040 loss: 0.20562110841274261 grad: 0.5069041519790554\n",
      "epoch: 1041 loss: 0.2099529653787613 grad: 0.4797346134060963\n",
      "epoch: 1042 loss: 0.21053555607795715 grad: 0.5765806746852177\n",
      "epoch: 1043 loss: 0.20447543263435364 grad: 0.4434187434606356\n",
      "epoch: 1044 loss: 0.20774425566196442 grad: 0.48929068728292624\n",
      "epoch: 1045 loss: 0.2086498737335205 grad: 0.42656397379223565\n",
      "epoch: 1046 loss: 0.21632376313209534 grad: 0.5741997509395551\n",
      "epoch: 1047 loss: 0.21769562363624573 grad: 0.6814821122141657\n",
      "epoch: 1048 loss: 0.2700313925743103 grad: 1.6367275271465842\n",
      "epoch: 1049 loss: 0.22117990255355835 grad: 0.632224706186389\n",
      "epoch: 1050 loss: 0.21928220987319946 grad: 0.7273855405725844\n",
      "epoch: 1051 loss: 0.20675000548362732 grad: 0.5140927273069865\n",
      "epoch: 1052 loss: 0.22179381549358368 grad: 0.7290766593495973\n",
      "epoch: 1053 loss: 0.20970191061496735 grad: 0.5403973950237078\n",
      "epoch: 1054 loss: 0.21731531620025635 grad: 0.6059203116359567\n",
      "epoch: 1055 loss: 0.20771722495555878 grad: 0.522317273762781\n",
      "epoch: 1056 loss: 0.21060527861118317 grad: 0.5714747375477004\n",
      "epoch: 1057 loss: 0.20372237265110016 grad: 0.3823391833686364\n",
      "epoch: 1058 loss: 0.20641618967056274 grad: 0.3792119834984769\n",
      "epoch: 1059 loss: 0.20704184472560883 grad: 0.4061162706288742\n",
      "epoch: 1060 loss: 0.21963559091091156 grad: 0.7366885285089502\n",
      "epoch: 1061 loss: 0.2125348001718521 grad: 0.5864664640933043\n",
      "epoch: 1062 loss: 0.21053098142147064 grad: 0.5316152794055305\n",
      "epoch: 1063 loss: 0.20133548974990845 grad: 0.3651057019471391\n",
      "epoch: 1064 loss: 0.20478171110153198 grad: 0.37764805270459395\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1065 loss: 0.20192012190818787 grad: 0.3586594772533881\n",
      "epoch: 1066 loss: 0.2039490044116974 grad: 0.4715349902732232\n",
      "epoch: 1067 loss: 0.22840487957000732 grad: 0.7938772716306048\n",
      "epoch: 1068 loss: 0.2258756160736084 grad: 0.8103243488430162\n",
      "epoch: 1069 loss: 0.21519267559051514 grad: 0.6993056757473964\n",
      "epoch: 1070 loss: 0.22622516751289368 grad: 0.9329875925855886\n",
      "epoch: 1071 loss: 0.3014635741710663 grad: 1.8042555348287497\n",
      "epoch: 1072 loss: 0.23208816349506378 grad: 0.8978011551461786\n",
      "epoch: 1073 loss: 0.22407816350460052 grad: 0.7666470044937523\n",
      "epoch: 1074 loss: 0.2135757952928543 grad: 0.7000851864644319\n",
      "epoch: 1075 loss: 0.21076975762844086 grad: 0.5131333468092525\n",
      "epoch: 1076 loss: 0.20614883303642273 grad: 0.4743448206815519\n",
      "epoch: 1077 loss: 0.21047230064868927 grad: 0.4380225396951646\n",
      "epoch: 1078 loss: 0.20350542664527893 grad: 0.4808232931398161\n",
      "epoch: 1079 loss: 0.21064455807209015 grad: 0.5798283973922389\n",
      "epoch: 1080 loss: 0.20836316049098969 grad: 0.4423708111233136\n",
      "epoch: 1081 loss: 0.21182119846343994 grad: 0.5283075605930871\n",
      "epoch: 1082 loss: 0.23134984076023102 grad: 0.9119354686301085\n",
      "epoch: 1083 loss: 0.21289299428462982 grad: 0.6546610182259683\n",
      "epoch: 1084 loss: 0.2214289903640747 grad: 0.5989975319971645\n",
      "epoch: 1085 loss: 0.21377700567245483 grad: 0.4697078842865558\n",
      "epoch: 1086 loss: 0.2025367021560669 grad: 0.3676903968367769\n",
      "epoch: 1087 loss: 0.20030762255191803 grad: 0.3235827004803159\n",
      "epoch: 1088 loss: 0.20064572989940643 grad: 0.4026154233097836\n",
      "epoch: 1089 loss: 0.23071448504924774 grad: 0.8798818260941407\n",
      "epoch: 1090 loss: 0.21402768790721893 grad: 0.5919172424917051\n",
      "epoch: 1091 loss: 0.20742018520832062 grad: 0.4988901137028215\n",
      "epoch: 1092 loss: 0.2155868113040924 grad: 0.6199650125051921\n",
      "epoch: 1093 loss: 0.20462699234485626 grad: 0.4924382913396021\n",
      "epoch: 1094 loss: 0.20648351311683655 grad: 0.44811239528454644\n",
      "epoch: 1095 loss: 0.20470257103443146 grad: 0.47515034475768336\n",
      "epoch: 1096 loss: 0.2108207792043686 grad: 0.48506325761421615\n",
      "epoch: 1097 loss: 0.20196451246738434 grad: 0.41393774747624595\n",
      "epoch: 1098 loss: 0.21134258806705475 grad: 0.5603395264125247\n",
      "epoch: 1099 loss: 0.27966657280921936 grad: 1.6182745172646806\n",
      "epoch: 1100 loss: 0.27854713797569275 grad: 1.5230035407114095\n",
      "epoch: 1101 loss: 0.23837688565254211 grad: 1.1562527779402112\n",
      "epoch: 1102 loss: 0.22624805569648743 grad: 0.877060535321929\n",
      "epoch: 1103 loss: 0.2115778923034668 grad: 0.5674041266153627\n",
      "epoch: 1104 loss: 0.2336747944355011 grad: 0.9059512316874061\n",
      "epoch: 1105 loss: 0.22556830942630768 grad: 0.8409567290873602\n",
      "epoch: 1106 loss: 0.2091200053691864 grad: 0.4708543139374542\n",
      "epoch: 1107 loss: 0.21623922884464264 grad: 0.7128113663222102\n",
      "epoch: 1108 loss: 0.20555172860622406 grad: 0.40516139270550594\n",
      "epoch: 1109 loss: 0.19976839423179626 grad: 0.3273837944301149\n",
      "epoch: 1110 loss: 0.22567497193813324 grad: 0.9624529206542265\n",
      "epoch: 1111 loss: 0.2175837755203247 grad: 0.6608523181713724\n",
      "epoch: 1112 loss: 0.21106059849262238 grad: 0.6229001699340279\n",
      "epoch: 1113 loss: 0.2131810039281845 grad: 0.6401726806465667\n",
      "epoch: 1114 loss: 0.2109679877758026 grad: 0.559997286331698\n",
      "epoch: 1115 loss: 0.20564866065979004 grad: 0.5060914711000151\n",
      "epoch: 1116 loss: 0.21468529105186462 grad: 0.5910675445533561\n",
      "epoch: 1117 loss: 0.2154012769460678 grad: 0.5838853686877519\n",
      "epoch: 1118 loss: 0.21294885873794556 grad: 0.55716523434989\n",
      "epoch: 1119 loss: 0.20254014432430267 grad: 0.3573370611990049\n",
      "epoch: 1120 loss: 0.20521675050258636 grad: 0.43643086832215433\n",
      "epoch: 1121 loss: 0.20791110396385193 grad: 0.48495748275126244\n",
      "epoch: 1122 loss: 0.20299310982227325 grad: 0.4891038040188287\n",
      "epoch: 1123 loss: 0.20708313584327698 grad: 0.44822562842761726\n",
      "epoch: 1124 loss: 0.20024068653583527 grad: 0.3709550389547012\n",
      "epoch: 1125 loss: 0.20800313353538513 grad: 0.46823913374589166\n",
      "epoch: 1126 loss: 0.19725872576236725 grad: 0.291853414504939\n",
      "epoch: 1127 loss: 0.2085387259721756 grad: 0.4209234781746136\n",
      "epoch: 1128 loss: 0.20972657203674316 grad: 0.4522463711637829\n",
      "epoch: 1129 loss: 0.2079155147075653 grad: 0.5345419795568487\n",
      "epoch: 1130 loss: 0.2258683294057846 grad: 0.6611770851525544\n",
      "epoch: 1131 loss: 0.2090473771095276 grad: 0.5097481552435856\n",
      "epoch: 1132 loss: 0.20026575028896332 grad: 0.33892444774651903\n",
      "epoch: 1133 loss: 0.20808330178260803 grad: 0.512444611248895\n",
      "epoch: 1134 loss: 0.2099907100200653 grad: 0.5218029767824596\n",
      "epoch: 1135 loss: 0.2070407122373581 grad: 0.5636025912949808\n",
      "epoch: 1136 loss: 0.2165946364402771 grad: 0.5657079037380282\n",
      "epoch: 1137 loss: 0.22389091551303864 grad: 0.837323535820944\n",
      "epoch: 1138 loss: 0.2790990471839905 grad: 1.535504241978604\n",
      "epoch: 1139 loss: 0.2278040647506714 grad: 0.8873995695392668\n",
      "epoch: 1140 loss: 0.20960384607315063 grad: 0.4687217667753466\n",
      "epoch: 1141 loss: 0.21589535474777222 grad: 0.5355719254260867\n",
      "epoch: 1142 loss: 0.21477000415325165 grad: 0.5663797849032803\n",
      "epoch: 1143 loss: 0.2124653160572052 grad: 0.5483831798111969\n",
      "epoch: 1144 loss: 0.20024381577968597 grad: 0.34410358298107896\n",
      "epoch: 1145 loss: 0.20995080471038818 grad: 0.6031038483593512\n",
      "epoch: 1146 loss: 0.20440243184566498 grad: 0.4455728180222632\n",
      "epoch: 1147 loss: 0.21816328167915344 grad: 0.6268972348061507\n",
      "epoch: 1148 loss: 0.20830652117729187 grad: 0.5325781911322083\n",
      "epoch: 1149 loss: 0.2069120556116104 grad: 0.4860423306305095\n",
      "epoch: 1150 loss: 0.23559913039207458 grad: 0.9630952745145773\n",
      "epoch: 1151 loss: 0.29113996028900146 grad: 1.9211292470368508\n",
      "epoch: 1152 loss: 0.23560616374015808 grad: 0.9056729176551062\n",
      "epoch: 1153 loss: 0.2367950826883316 grad: 0.8087958335277854\n",
      "epoch: 1154 loss: 0.2138253003358841 grad: 0.5654059992417133\n",
      "epoch: 1155 loss: 0.20818673074245453 grad: 0.48137284929448376\n",
      "epoch: 1156 loss: 0.19951999187469482 grad: 0.29127698503080685\n",
      "epoch: 1157 loss: 0.2032860964536667 grad: 0.38351322058045845\n",
      "epoch: 1158 loss: 0.20914305746555328 grad: 0.5344171377588298\n",
      "epoch: 1159 loss: 0.21215267479419708 grad: 0.6351651365320077\n",
      "epoch: 1160 loss: 0.20792503654956818 grad: 0.49302099882136824\n",
      "epoch: 1161 loss: 0.2094944566488266 grad: 0.6182835400045856\n",
      "epoch: 1162 loss: 0.20950964093208313 grad: 0.5647368591722279\n",
      "epoch: 1163 loss: 0.20563994348049164 grad: 0.4987680496191642\n",
      "epoch: 1164 loss: 0.20280157029628754 grad: 0.38503603019629007\n",
      "epoch: 1165 loss: 0.2297361195087433 grad: 0.9345918289418551\n",
      "epoch: 1166 loss: 0.2218894213438034 grad: 0.7697533380312088\n",
      "epoch: 1167 loss: 0.2058223932981491 grad: 0.5314901263176834\n",
      "epoch: 1168 loss: 0.20918944478034973 grad: 0.5491750861011169\n",
      "epoch: 1169 loss: 0.21071895956993103 grad: 0.5178861544773208\n",
      "epoch: 1170 loss: 0.20831115543842316 grad: 0.5102743197328528\n",
      "epoch: 1171 loss: 0.2014886885881424 grad: 0.37993573498697836\n",
      "epoch: 1172 loss: 0.21746933460235596 grad: 0.8000272828053835\n",
      "epoch: 1173 loss: 0.22964631021022797 grad: 0.6351223974795849\n",
      "epoch: 1174 loss: 0.2168792486190796 grad: 0.5388657940804406\n",
      "epoch: 1175 loss: 0.21441183984279633 grad: 0.6979064745027462\n",
      "epoch: 1176 loss: 0.21742525696754456 grad: 0.7364402514878775\n",
      "epoch: 1177 loss: 0.21027448773384094 grad: 0.47806921850945855\n",
      "epoch: 1178 loss: 0.20599959790706635 grad: 0.455996248162279\n",
      "epoch: 1179 loss: 0.21208499372005463 grad: 0.49965436778891037\n",
      "epoch: 1180 loss: 0.20582391321659088 grad: 0.44681386607666446\n",
      "epoch: 1181 loss: 0.20353630185127258 grad: 0.4372835669281558\n",
      "epoch: 1182 loss: 0.2099446952342987 grad: 0.49427570699479656\n",
      "epoch: 1183 loss: 0.2186759114265442 grad: 0.7077825446140269\n",
      "epoch: 1184 loss: 0.21253862977027893 grad: 0.7290381004828087\n",
      "epoch: 1185 loss: 0.2124091237783432 grad: 0.6794396723819427\n",
      "epoch: 1186 loss: 0.22541458904743195 grad: 0.8989272871032954\n",
      "epoch: 1187 loss: 0.22471916675567627 grad: 0.842700336393086\n",
      "epoch: 1188 loss: 0.21411584317684174 grad: 0.5233456824181162\n",
      "epoch: 1189 loss: 0.20719389617443085 grad: 0.5080697907723427\n",
      "epoch: 1190 loss: 0.2143917828798294 grad: 0.573920928417323\n",
      "epoch: 1191 loss: 0.21938751637935638 grad: 0.8149061974389188\n",
      "epoch: 1192 loss: 0.22616271674633026 grad: 0.8863715756725069\n",
      "epoch: 1193 loss: 0.2136155068874359 grad: 0.5937652063125716\n",
      "epoch: 1194 loss: 0.2048029750585556 grad: 0.3972097588808101\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1195 loss: 0.20604853332042694 grad: 0.43396147746399605\n",
      "epoch: 1196 loss: 0.20308302342891693 grad: 0.4475153064515689\n",
      "epoch: 1197 loss: 0.20030349493026733 grad: 0.45239204749249917\n",
      "epoch: 1198 loss: 0.22597740590572357 grad: 0.7111572255525992\n",
      "epoch: 1199 loss: 0.20526348054409027 grad: 0.3669337641102029\n",
      "epoch: 1200 loss: 0.20987333357334137 grad: 0.4924346671983894\n",
      "epoch: 1201 loss: 0.2031756043434143 grad: 0.3668242874170064\n",
      "epoch: 1202 loss: 0.20568032562732697 grad: 0.40622659996651417\n",
      "epoch: 1203 loss: 0.2059287428855896 grad: 0.47692754556677025\n",
      "epoch: 1204 loss: 0.20442228019237518 grad: 0.5055192184729312\n",
      "epoch: 1205 loss: 0.2306138277053833 grad: 0.9192103551787277\n",
      "epoch: 1206 loss: 0.2213703989982605 grad: 0.8067912504610504\n",
      "epoch: 1207 loss: 0.21127428114414215 grad: 0.5013655141944519\n",
      "epoch: 1208 loss: 0.2023748755455017 grad: 0.3932434414250287\n",
      "epoch: 1209 loss: 0.24685856699943542 grad: 1.4134068777733915\n",
      "epoch: 1210 loss: 0.2645207941532135 grad: 1.645244562716456\n",
      "epoch: 1211 loss: 0.2134971022605896 grad: 0.611809966261772\n",
      "epoch: 1212 loss: 0.2536498010158539 grad: 1.2873443065283137\n",
      "epoch: 1213 loss: 0.21680255234241486 grad: 0.6113265226677977\n",
      "epoch: 1214 loss: 0.2103201150894165 grad: 0.5706255156420739\n",
      "epoch: 1215 loss: 0.20737497508525848 grad: 0.4458478350721671\n",
      "epoch: 1216 loss: 0.20482666790485382 grad: 0.40115397422410753\n",
      "epoch: 1217 loss: 0.20530083775520325 grad: 0.4285335737236992\n",
      "epoch: 1218 loss: 0.20749694108963013 grad: 0.45786564289537274\n",
      "epoch: 1219 loss: 0.20523987710475922 grad: 0.35653731287047047\n",
      "epoch: 1220 loss: 0.2235402762889862 grad: 0.6809844291806894\n",
      "epoch: 1221 loss: 0.20641553401947021 grad: 0.4214339505737225\n",
      "epoch: 1222 loss: 0.20177167654037476 grad: 0.39314990392381877\n",
      "epoch: 1223 loss: 0.205080047249794 grad: 0.39852144756151575\n",
      "epoch: 1224 loss: 0.20325174927711487 grad: 0.4222373326730791\n",
      "epoch: 1225 loss: 0.20082753896713257 grad: 0.3059384800901703\n",
      "epoch: 1226 loss: 0.21529431641101837 grad: 0.501154563477471\n",
      "epoch: 1227 loss: 0.20489554107189178 grad: 0.5176901845793281\n",
      "epoch: 1228 loss: 0.21397435665130615 grad: 0.4939740138593079\n",
      "epoch: 1229 loss: 0.206156387925148 grad: 0.42239761787458985\n",
      "epoch: 1230 loss: 0.21604986488819122 grad: 0.600072627524296\n",
      "epoch: 1231 loss: 0.21285098791122437 grad: 0.5525839296311333\n",
      "epoch: 1232 loss: 0.21620547771453857 grad: 0.5053419223700112\n",
      "epoch: 1233 loss: 0.20552165806293488 grad: 0.36585520848091435\n",
      "epoch: 1234 loss: 0.20559166371822357 grad: 0.4755896844238814\n",
      "epoch: 1235 loss: 0.22008366882801056 grad: 0.6860318566574278\n",
      "epoch: 1236 loss: 0.21113769710063934 grad: 0.5028293429962268\n",
      "epoch: 1237 loss: 0.20706410706043243 grad: 0.4540206743507069\n",
      "epoch: 1238 loss: 0.2108093798160553 grad: 0.549381861865133\n",
      "epoch: 1239 loss: 0.21706749498844147 grad: 0.6063495030821777\n",
      "epoch: 1240 loss: 0.21064646542072296 grad: 0.4832766929136069\n",
      "epoch: 1241 loss: 0.20568951964378357 grad: 0.47048863965139254\n",
      "epoch: 1242 loss: 0.21165834367275238 grad: 0.4873213018551573\n",
      "epoch: 1243 loss: 0.2353355437517166 grad: 0.9660410627957609\n",
      "epoch: 1244 loss: 0.21017985045909882 grad: 0.5122890884799334\n",
      "epoch: 1245 loss: 0.208952397108078 grad: 0.4357731282806403\n",
      "epoch: 1246 loss: 0.20166553556919098 grad: 0.41435187476993224\n",
      "epoch: 1247 loss: 0.22111140191555023 grad: 0.6060075898229081\n",
      "epoch: 1248 loss: 0.2027927190065384 grad: 0.46197895638264164\n",
      "epoch: 1249 loss: 0.1983114331960678 grad: 0.3284804767868718\n",
      "epoch: 1250 loss: 0.20166462659835815 grad: 0.38846767436279334\n",
      "epoch: 1251 loss: 0.1977279782295227 grad: 0.2886789335436617\n",
      "epoch: 1252 loss: 0.22410807013511658 grad: 0.671901279365603\n",
      "epoch: 1253 loss: 0.20716048777103424 grad: 0.47402511457650487\n",
      "epoch: 1254 loss: 0.22085286676883698 grad: 0.7351723086637071\n",
      "epoch: 1255 loss: 0.21432258188724518 grad: 0.5904143980220687\n",
      "epoch: 1256 loss: 0.20117712020874023 grad: 0.36599024674909286\n",
      "epoch: 1257 loss: 0.2065442055463791 grad: 0.4617693268024668\n",
      "epoch: 1258 loss: 0.19711962342262268 grad: 0.36549440462416194\n",
      "epoch: 1259 loss: 0.21587100625038147 grad: 0.6680736907002819\n",
      "epoch: 1260 loss: 0.23040886223316193 grad: 0.8191450149326829\n",
      "epoch: 1261 loss: 0.24746371805667877 grad: 1.3302897248454393\n",
      "epoch: 1262 loss: 0.24174615740776062 grad: 1.1413419194771406\n",
      "epoch: 1263 loss: 0.22556529939174652 grad: 0.7706744505175702\n",
      "epoch: 1264 loss: 0.21263441443443298 grad: 0.6549228769388201\n",
      "epoch: 1265 loss: 0.2180844396352768 grad: 0.7051939099566298\n",
      "epoch: 1266 loss: 0.20207330584526062 grad: 0.41192502958523164\n",
      "epoch: 1267 loss: 0.20231401920318604 grad: 0.4152823923316678\n",
      "epoch: 1268 loss: 0.20418386161327362 grad: 0.39245217990051995\n",
      "epoch: 1269 loss: 0.19877158105373383 grad: 0.36794214407979137\n",
      "epoch: 1270 loss: 0.20033514499664307 grad: 0.38340336020684207\n",
      "epoch: 1271 loss: 0.23116855323314667 grad: 0.9712576736889995\n",
      "epoch: 1272 loss: 0.2116592824459076 grad: 0.4848311391425632\n",
      "epoch: 1273 loss: 0.21901404857635498 grad: 0.7643731796366119\n",
      "epoch: 1274 loss: 0.20735308527946472 grad: 0.5359748497495657\n",
      "epoch: 1275 loss: 0.2077866494655609 grad: 0.44246838007247424\n",
      "epoch: 1276 loss: 0.20785458385944366 grad: 0.5136269553700902\n",
      "epoch: 1277 loss: 0.21000628173351288 grad: 0.5066977310885804\n",
      "epoch: 1278 loss: 0.21625731885433197 grad: 0.5936840494735416\n",
      "epoch: 1279 loss: 0.212159663438797 grad: 0.5923358588277496\n",
      "epoch: 1280 loss: 0.21366716921329498 grad: 0.6202592946684418\n",
      "epoch: 1281 loss: 0.21537712216377258 grad: 0.5624964139460046\n",
      "epoch: 1282 loss: 0.20771504938602448 grad: 0.49285117829089675\n",
      "epoch: 1283 loss: 0.2196130007505417 grad: 0.7897608401436291\n",
      "epoch: 1284 loss: 0.21165065467357635 grad: 0.61955602602832\n",
      "epoch: 1285 loss: 0.20237599313259125 grad: 0.40499003149088364\n",
      "epoch: 1286 loss: 0.20686721801757812 grad: 0.441937404405493\n",
      "epoch: 1287 loss: 0.20611241459846497 grad: 0.4962009409026259\n",
      "epoch: 1288 loss: 0.2037159949541092 grad: 0.4306462342252109\n",
      "epoch: 1289 loss: 0.20120751857757568 grad: 0.36447028680899407\n",
      "epoch: 1290 loss: 0.20408527553081512 grad: 0.42981644288057497\n",
      "epoch: 1291 loss: 0.21231549978256226 grad: 0.5265729980865685\n",
      "epoch: 1292 loss: 0.20129817724227905 grad: 0.41166120175083754\n",
      "epoch: 1293 loss: 0.2099589854478836 grad: 0.5527779822115589\n",
      "epoch: 1294 loss: 0.21250243484973907 grad: 0.5743820547382784\n",
      "epoch: 1295 loss: 0.21338532865047455 grad: 0.5913997594275539\n",
      "epoch: 1296 loss: 0.1996760070323944 grad: 0.40305212136463936\n",
      "epoch: 1297 loss: 0.19655796885490417 grad: 0.2777083836852171\n",
      "epoch: 1298 loss: 0.20124337077140808 grad: 0.312355545125342\n",
      "epoch: 1299 loss: 0.2004193365573883 grad: 0.37138971873760285\n",
      "epoch: 1300 loss: 0.19671685993671417 grad: 0.3087378166680786\n",
      "epoch: 1301 loss: 0.20262371003627777 grad: 0.3958950243855261\n",
      "epoch: 1302 loss: 0.2150414139032364 grad: 0.6189886383147204\n",
      "epoch: 1303 loss: 0.20632252097129822 grad: 0.46812118568176536\n",
      "epoch: 1304 loss: 0.19918441772460938 grad: 0.27287871974774713\n",
      "epoch: 1305 loss: 0.20957735180854797 grad: 0.5060536937956731\n",
      "epoch: 1306 loss: 0.2111910581588745 grad: 0.6433548720986382\n",
      "epoch: 1307 loss: 0.23479294776916504 grad: 0.9927939884400911\n",
      "epoch: 1308 loss: 0.23890112340450287 grad: 1.0481011823855733\n",
      "epoch: 1309 loss: 0.24495084583759308 grad: 1.1215273295344559\n",
      "epoch: 1310 loss: 0.22294294834136963 grad: 0.7542879773202004\n",
      "epoch: 1311 loss: 0.22034652531147003 grad: 0.8264585605646639\n",
      "epoch: 1312 loss: 0.21082265675067902 grad: 0.5074034411697312\n",
      "epoch: 1313 loss: 0.20498287677764893 grad: 0.4395755859879685\n",
      "epoch: 1314 loss: 0.213751420378685 grad: 0.5383932232986317\n",
      "epoch: 1315 loss: 0.2030213326215744 grad: 0.43522874799643163\n",
      "epoch: 1316 loss: 0.20228998363018036 grad: 0.33405308714322884\n",
      "epoch: 1317 loss: 0.20144116878509521 grad: 0.4084631231022719\n",
      "epoch: 1318 loss: 0.2367621511220932 grad: 1.0025945290110903\n",
      "epoch: 1319 loss: 0.21066899597644806 grad: 0.37803272444391767\n",
      "epoch: 1320 loss: 0.20507235825061798 grad: 0.49826449409378115\n",
      "epoch: 1321 loss: 0.22998499870300293 grad: 0.8781832502702237\n",
      "epoch: 1322 loss: 0.20613370835781097 grad: 0.38939223480032137\n",
      "epoch: 1323 loss: 0.21538539230823517 grad: 0.5355467612357864\n",
      "epoch: 1324 loss: 0.21103297173976898 grad: 0.4814995290279835\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1325 loss: 0.20700526237487793 grad: 0.43100021981127246\n",
      "epoch: 1326 loss: 0.20299221575260162 grad: 0.38425064466317416\n",
      "epoch: 1327 loss: 0.20220890641212463 grad: 0.3127249911860895\n",
      "epoch: 1328 loss: 0.20492295920848846 grad: 0.4880669120289817\n",
      "epoch: 1329 loss: 0.22377027571201324 grad: 0.8790425895486769\n",
      "epoch: 1330 loss: 0.21282188594341278 grad: 0.59623612932369\n",
      "epoch: 1331 loss: 0.20103539526462555 grad: 0.4039802250868647\n",
      "epoch: 1332 loss: 0.21820615231990814 grad: 0.7381586208855915\n",
      "epoch: 1333 loss: 0.21084368228912354 grad: 0.5050165590980323\n",
      "epoch: 1334 loss: 0.2081693410873413 grad: 0.5329383178375474\n",
      "epoch: 1335 loss: 0.20088492333889008 grad: 0.4073421687954069\n",
      "epoch: 1336 loss: 0.2103363275527954 grad: 0.607438257324214\n",
      "epoch: 1337 loss: 0.20391523838043213 grad: 0.4513159237930577\n",
      "epoch: 1338 loss: 0.20277002453804016 grad: 0.39604086184245124\n",
      "epoch: 1339 loss: 0.19624382257461548 grad: 0.31620375252840194\n",
      "epoch: 1340 loss: 0.21647384762763977 grad: 0.6956628163794796\n",
      "epoch: 1341 loss: 0.21506410837173462 grad: 0.5410690357079461\n",
      "epoch: 1342 loss: 0.2155747413635254 grad: 0.6980457017206864\n",
      "epoch: 1343 loss: 0.20645730197429657 grad: 0.5105785144656202\n",
      "epoch: 1344 loss: 0.20143191516399384 grad: 0.365439976317778\n",
      "epoch: 1345 loss: 0.21064993739128113 grad: 0.5507797859722668\n",
      "epoch: 1346 loss: 0.20242121815681458 grad: 0.38485503269015225\n",
      "epoch: 1347 loss: 0.21311244368553162 grad: 0.5715143018120216\n",
      "epoch: 1348 loss: 0.20719829201698303 grad: 0.44127812419853946\n",
      "epoch: 1349 loss: 0.20088239014148712 grad: 0.5348304335319609\n",
      "epoch: 1350 loss: 0.2143811583518982 grad: 0.6352002437873328\n",
      "epoch: 1351 loss: 0.22874104976654053 grad: 1.1119102495436286\n",
      "epoch: 1352 loss: 0.2662689983844757 grad: 1.2832348565256746\n",
      "epoch: 1353 loss: 0.22447170317173004 grad: 0.8116584002692853\n",
      "epoch: 1354 loss: 0.21737070381641388 grad: 0.8019925893030241\n",
      "epoch: 1355 loss: 0.21670664846897125 grad: 0.6626875791614475\n",
      "epoch: 1356 loss: 0.21623286604881287 grad: 0.6234500765252087\n",
      "epoch: 1357 loss: 0.20726598799228668 grad: 0.49385303844719236\n",
      "epoch: 1358 loss: 0.20516978204250336 grad: 0.4999054052914762\n",
      "epoch: 1359 loss: 0.21498197317123413 grad: 0.5271111868736853\n",
      "epoch: 1360 loss: 0.20177045464515686 grad: 0.4401201980544629\n",
      "epoch: 1361 loss: 0.20229965448379517 grad: 0.4298945547619886\n",
      "epoch: 1362 loss: 0.23109742999076843 grad: 0.836740772935127\n",
      "epoch: 1363 loss: 0.20164386928081512 grad: 0.3635173461583222\n",
      "epoch: 1364 loss: 0.20535686612129211 grad: 0.4227419206391005\n",
      "epoch: 1365 loss: 0.20576095581054688 grad: 0.46580812746007905\n",
      "epoch: 1366 loss: 0.20204760134220123 grad: 0.4539495863604316\n",
      "epoch: 1367 loss: 0.20624858140945435 grad: 0.4947576868527485\n",
      "epoch: 1368 loss: 0.20814159512519836 grad: 0.543489250246048\n",
      "epoch: 1369 loss: 0.2148343175649643 grad: 0.5683205020721889\n",
      "epoch: 1370 loss: 0.2218988835811615 grad: 0.692460555434196\n",
      "epoch: 1371 loss: 0.20402508974075317 grad: 0.4232140580999931\n",
      "epoch: 1372 loss: 0.2107318937778473 grad: 0.4669855468689348\n",
      "epoch: 1373 loss: 0.2092767059803009 grad: 0.43103439111582703\n",
      "epoch: 1374 loss: 0.2169608473777771 grad: 0.5240235475414374\n",
      "epoch: 1375 loss: 0.2023850381374359 grad: 0.3943286081984443\n",
      "epoch: 1376 loss: 0.20875334739685059 grad: 0.5181532558922954\n",
      "epoch: 1377 loss: 0.2102067768573761 grad: 0.5372408734880991\n",
      "epoch: 1378 loss: 0.20364218950271606 grad: 0.3683363972347806\n",
      "epoch: 1379 loss: 0.20390616357326508 grad: 0.4337740155597537\n",
      "epoch: 1380 loss: 0.20823736488819122 grad: 0.5144759265114235\n",
      "epoch: 1381 loss: 0.20509855449199677 grad: 0.39124503799521154\n",
      "epoch: 1382 loss: 0.21597060561180115 grad: 0.6825739156984346\n",
      "epoch: 1383 loss: 0.19949480891227722 grad: 0.299454672307229\n",
      "epoch: 1384 loss: 0.21352407336235046 grad: 0.7388430413310889\n",
      "epoch: 1385 loss: 0.21556812524795532 grad: 0.7793617845716353\n",
      "epoch: 1386 loss: 0.263370156288147 grad: 1.4213130279455153\n",
      "epoch: 1387 loss: 0.22437304258346558 grad: 1.034029174128428\n",
      "epoch: 1388 loss: 0.23358628153800964 grad: 0.9718696905276929\n",
      "epoch: 1389 loss: 0.2211560606956482 grad: 0.7881604148575497\n",
      "epoch: 1390 loss: 0.20923207700252533 grad: 0.42116588476231254\n",
      "epoch: 1391 loss: 0.20452101528644562 grad: 0.47377022993591206\n",
      "epoch: 1392 loss: 0.20491330325603485 grad: 0.42005156417828016\n",
      "epoch: 1393 loss: 0.21438807249069214 grad: 0.5574833306715515\n",
      "epoch: 1394 loss: 0.20971953868865967 grad: 0.49037323750254835\n",
      "epoch: 1395 loss: 0.20117278397083282 grad: 0.39934535419154416\n",
      "epoch: 1396 loss: 0.2063232660293579 grad: 0.49154325504168356\n",
      "epoch: 1397 loss: 0.20938563346862793 grad: 0.47757792546918415\n",
      "epoch: 1398 loss: 0.19981811940670013 grad: 0.3714925133091574\n",
      "epoch: 1399 loss: 0.22114916145801544 grad: 0.6623288937466641\n",
      "epoch: 1400 loss: 0.20905593037605286 grad: 0.4759682654906146\n",
      "epoch: 1401 loss: 0.21155303716659546 grad: 0.5468736959610583\n",
      "epoch: 1402 loss: 0.21972142159938812 grad: 0.7797822992351284\n",
      "epoch: 1403 loss: 0.2026447206735611 grad: 0.3879288657064337\n",
      "epoch: 1404 loss: 0.21513202786445618 grad: 0.6212352112850558\n",
      "epoch: 1405 loss: 0.22058381140232086 grad: 0.8772427591047172\n",
      "epoch: 1406 loss: 0.21893338859081268 grad: 0.5512166255216625\n",
      "epoch: 1407 loss: 0.21523313224315643 grad: 0.7164538465939823\n",
      "epoch: 1408 loss: 0.20402687788009644 grad: 0.3669959949257172\n",
      "epoch: 1409 loss: 0.20681314170360565 grad: 0.38576524931574024\n",
      "epoch: 1410 loss: 0.2104109823703766 grad: 0.5744597314887269\n",
      "epoch: 1411 loss: 0.20854568481445312 grad: 0.5214481209454198\n",
      "epoch: 1412 loss: 0.20758840441703796 grad: 0.43846686335597873\n",
      "epoch: 1413 loss: 0.20299114286899567 grad: 0.41959934903291923\n",
      "epoch: 1414 loss: 0.2327744960784912 grad: 1.190526417010011\n",
      "epoch: 1415 loss: 0.2387513369321823 grad: 1.0139805717310955\n",
      "epoch: 1416 loss: 0.21121898293495178 grad: 0.4846183088121925\n",
      "epoch: 1417 loss: 0.2110435515642166 grad: 0.5156049423177755\n",
      "epoch: 1418 loss: 0.22109586000442505 grad: 0.860285724559526\n",
      "epoch: 1419 loss: 0.20754875242710114 grad: 0.5915726510796563\n",
      "epoch: 1420 loss: 0.23626680672168732 grad: 0.9375840847377395\n",
      "epoch: 1421 loss: 0.21510833501815796 grad: 0.535407706773105\n",
      "epoch: 1422 loss: 0.20911118388175964 grad: 0.5595929313192928\n",
      "epoch: 1423 loss: 0.21072563529014587 grad: 0.47518845844660607\n",
      "epoch: 1424 loss: 0.1984170377254486 grad: 0.26571732218197347\n",
      "epoch: 1425 loss: 0.21869929134845734 grad: 0.825376882667249\n",
      "epoch: 1426 loss: 0.21210287511348724 grad: 0.5392768917517811\n",
      "epoch: 1427 loss: 0.2078222632408142 grad: 0.47843194582487014\n",
      "epoch: 1428 loss: 0.2066052109003067 grad: 0.4638087405888127\n",
      "epoch: 1429 loss: 0.21639320254325867 grad: 0.5839327453838851\n",
      "epoch: 1430 loss: 0.21036723256111145 grad: 0.4634732818987359\n",
      "epoch: 1431 loss: 0.21978504955768585 grad: 0.7967064490734774\n",
      "epoch: 1432 loss: 0.24980613589286804 grad: 1.2645946403660056\n",
      "epoch: 1433 loss: 0.22505462169647217 grad: 0.7785676635935961\n",
      "epoch: 1434 loss: 0.20204301178455353 grad: 0.36315467756636644\n",
      "epoch: 1435 loss: 0.20107285678386688 grad: 0.34112369422429767\n",
      "epoch: 1436 loss: 0.20155861973762512 grad: 0.3279305954000174\n",
      "epoch: 1437 loss: 0.20012985169887543 grad: 0.3325982256749403\n",
      "epoch: 1438 loss: 0.22784645855426788 grad: 0.8388841216440346\n",
      "epoch: 1439 loss: 0.21302269399166107 grad: 0.49136927324689167\n",
      "epoch: 1440 loss: 0.20511366426944733 grad: 0.4479048213893766\n",
      "epoch: 1441 loss: 0.21321891248226166 grad: 0.5862128055826251\n",
      "epoch: 1442 loss: 0.21199364960193634 grad: 0.5011699109800247\n",
      "epoch: 1443 loss: 0.20824554562568665 grad: 0.605253129055004\n",
      "epoch: 1444 loss: 0.21603181958198547 grad: 0.7379804130166706\n",
      "epoch: 1445 loss: 0.231421560049057 grad: 0.8727870293767506\n",
      "epoch: 1446 loss: 0.20300307869911194 grad: 0.3530329415945416\n",
      "epoch: 1447 loss: 0.21777845919132233 grad: 0.6067341459257232\n",
      "epoch: 1448 loss: 0.2001917064189911 grad: 0.30916345819561775\n",
      "epoch: 1449 loss: 0.21002431213855743 grad: 0.5825032604222932\n",
      "epoch: 1450 loss: 0.20987801253795624 grad: 0.5678058209684508\n",
      "epoch: 1451 loss: 0.21687167882919312 grad: 0.6051336902099577\n",
      "epoch: 1452 loss: 0.21765336394309998 grad: 0.637579627219704\n",
      "epoch: 1453 loss: 0.21449969708919525 grad: 0.6867047103445694\n",
      "epoch: 1454 loss: 0.2034364640712738 grad: 0.36434836028027257\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1455 loss: 0.2853825092315674 grad: 1.9473133592093628\n",
      "epoch: 1456 loss: 0.25875744223594666 grad: 1.1259787819568592\n",
      "epoch: 1457 loss: 0.20997850596904755 grad: 0.549173822700388\n",
      "epoch: 1458 loss: 0.20756053924560547 grad: 0.42391751242539977\n",
      "epoch: 1459 loss: 0.21494485437870026 grad: 0.5525285147611249\n",
      "epoch: 1460 loss: 0.2119295448064804 grad: 0.634537238077708\n",
      "epoch: 1461 loss: 0.21512341499328613 grad: 0.5881677065159902\n",
      "epoch: 1462 loss: 0.2055191695690155 grad: 0.48443324800495974\n",
      "epoch: 1463 loss: 0.2079511433839798 grad: 0.459276670972823\n",
      "epoch: 1464 loss: 0.20563149452209473 grad: 0.44250167947427416\n",
      "epoch: 1465 loss: 0.20842613279819489 grad: 0.5024445096555137\n",
      "epoch: 1466 loss: 0.1988779604434967 grad: 0.32315318654820907\n",
      "epoch: 1467 loss: 0.217299684882164 grad: 0.5645634828382681\n",
      "epoch: 1468 loss: 0.20330122113227844 grad: 0.528509166507618\n",
      "epoch: 1469 loss: 0.2230253517627716 grad: 0.6095018226269767\n",
      "epoch: 1470 loss: 0.22097048163414001 grad: 0.5805219269559275\n",
      "epoch: 1471 loss: 0.20537985861301422 grad: 0.5273209581639385\n",
      "epoch: 1472 loss: 0.21467925608158112 grad: 0.5350196007960767\n",
      "epoch: 1473 loss: 0.19908463954925537 grad: 0.3172756593593406\n",
      "epoch: 1474 loss: 0.20188072323799133 grad: 0.4893460629629581\n",
      "epoch: 1475 loss: 0.20476694405078888 grad: 0.45083693482136367\n",
      "epoch: 1476 loss: 0.21219778060913086 grad: 0.5557881712382827\n",
      "epoch: 1477 loss: 0.2074255496263504 grad: 0.5409492445058095\n",
      "epoch: 1478 loss: 0.20868277549743652 grad: 0.43689009386680844\n",
      "epoch: 1479 loss: 0.2081541270017624 grad: 0.47882129763337433\n",
      "epoch: 1480 loss: 0.2052130550146103 grad: 0.41448339590596517\n",
      "epoch: 1481 loss: 0.2044927477836609 grad: 0.4221830838952328\n",
      "epoch: 1482 loss: 0.20431175827980042 grad: 0.38592472758895063\n",
      "epoch: 1483 loss: 0.19584587216377258 grad: 0.24887180705071507\n",
      "epoch: 1484 loss: 0.20898695290088654 grad: 0.47827961935065466\n",
      "epoch: 1485 loss: 0.20784065127372742 grad: 0.5503365616885476\n",
      "epoch: 1486 loss: 0.21367241442203522 grad: 0.5612718845259865\n",
      "epoch: 1487 loss: 0.19754044711589813 grad: 0.33743814025609414\n",
      "epoch: 1488 loss: 0.20643645524978638 grad: 0.5424113908096552\n",
      "epoch: 1489 loss: 0.21341648697853088 grad: 0.5712996948216011\n",
      "epoch: 1490 loss: 0.21328453719615936 grad: 0.5795429252130998\n",
      "epoch: 1491 loss: 0.20516681671142578 grad: 0.41884929049423775\n",
      "epoch: 1492 loss: 0.19760635495185852 grad: 0.27179948136288534\n",
      "epoch: 1493 loss: 0.20421554148197174 grad: 0.379196643376421\n",
      "epoch: 1494 loss: 0.20736590027809143 grad: 0.44792157925770154\n",
      "epoch: 1495 loss: 0.203958660364151 grad: 0.4261430589095776\n",
      "epoch: 1496 loss: 0.20692230761051178 grad: 0.49606684873109136\n",
      "epoch: 1497 loss: 0.22126264870166779 grad: 0.7749635079401341\n",
      "epoch: 1498 loss: 0.2098965346813202 grad: 0.5423241237333388\n",
      "epoch: 1499 loss: 0.21482159197330475 grad: 0.6000968492757931\n"
     ]
    }
   ],
   "source": [
    "loss4,par4=modelSia.train(traindl,epochs = 1500,learning_rate=0.01,lam=0.001,opti='adam') #110-0.001 #500-0.0005 #500 - 0.0001 #500 0.00005\n",
    "losssia+=loss4\n",
    "parsia+=par4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 542,
   "id": "a49693ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x504 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot(losssia,parsia)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 543,
   "id": "0b079702",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(modelSia,'D:/Saarland University/NNTI/project/models/modelSia.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 544,
   "id": "2f3b1921",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Conv1d(13, 26, kernel_size=(3,), stride=(1,), padding=same, bias=False)\n",
       "  (1): Dropout(p=0.2, inplace=False)\n",
       "  (2): Conv1d(26, 26, kernel_size=(3,), stride=(1,), padding=same, bias=False)\n",
       "  (3): Dropout(p=0.2, inplace=False)\n",
       "  (4): BatchNorm1d(26, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (5): ReLU()\n",
       "  (6): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (7): Conv1d(26, 52, kernel_size=(3,), stride=(1,), padding=same, bias=False)\n",
       "  (8): Dropout(p=0.2, inplace=False)\n",
       "  (9): Conv1d(52, 52, kernel_size=(3,), stride=(1,), padding=same, bias=False)\n",
       "  (10): Dropout(p=0.2, inplace=False)\n",
       "  (11): BatchNorm1d(52, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (12): ReLU()\n",
       "  (13): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (14): Conv1d(52, 104, kernel_size=(3,), stride=(1,), padding=same, bias=False)\n",
       "  (15): Dropout(p=0.2, inplace=False)\n",
       "  (16): Conv1d(104, 104, kernel_size=(3,), stride=(1,), padding=same, bias=False)\n",
       "  (17): Dropout(p=0.2, inplace=False)\n",
       "  (18): BatchNorm1d(104, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (19): ReLU()\n",
       "  (20): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (21): Conv1d(104, 104, kernel_size=(3,), stride=(1,), padding=same, bias=False)\n",
       "  (22): Dropout(p=0.2, inplace=False)\n",
       "  (23): Conv1d(104, 52, kernel_size=(3,), stride=(1,), padding=same, bias=False)\n",
       "  (24): Dropout(p=0.2, inplace=False)\n",
       "  (25): BatchNorm1d(52, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (26): ReLU()\n",
       "  (27): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (28): Conv1d(52, 52, kernel_size=(3,), stride=(1,), padding=same, bias=False)\n",
       "  (29): Dropout(p=0.2, inplace=False)\n",
       "  (30): Conv1d(52, 26, kernel_size=(3,), stride=(1,), padding=same, bias=False)\n",
       "  (31): Dropout(p=0.2, inplace=False)\n",
       "  (32): BatchNorm1d(26, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (33): ReLU()\n",
       "  (34): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (35): Conv1d(26, 26, kernel_size=(3,), stride=(1,), padding=same, bias=False)\n",
       "  (36): Dropout(p=0.2, inplace=False)\n",
       "  (37): Conv1d(26, 26, kernel_size=(3,), stride=(1,), padding=same, bias=False)\n",
       "  (38): Dropout(p=0.2, inplace=False)\n",
       "  (39): BatchNorm1d(26, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (40): ReLU()\n",
       "  (41): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (42): Flatten(start_dim=1, end_dim=-1)\n",
       "  (43): Linear(in_features=104, out_features=256, bias=True)\n",
       "  (44): ReLU()\n",
       "  (45): Linear(in_features=256, out_features=128, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 544,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we then extract the trained CNN layers from the previous model\n",
    "cnn=modelSia.convlay()\n",
    "for param in cnn.parameters():\n",
    "    param.requires_grad = True\n",
    "cnn.to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 545,
   "id": "2f5c5d4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy=np.zeros((1,melspectrogram.shape[0],maxlength+27))\n",
    "datadict = {'TRAIN':dummy,'DEV':dummy,'TEST':dummy}\n",
    "labeldict = {'TRAIN':[],'DEV':[],'TEST':[]}\n",
    "for path,split,label in zip(sdr_df['file'],sdr_df['split'],sdr_df['label']):\n",
    "        x, sr = librosa.load(path, sr=SAMPLING_RATE)\n",
    "        melspectrogram = extract_melspectrogram(x, sr, num_mels=13)/max_val\n",
    "        data = torch.tensor(np.concatenate((melspectrogram,np.zeros((melspectrogram.shape[0],maxlength-melspectrogram.shape[1]+27))),axis = 1))## the dimension is made to be 256 so that it works with the maxpooling layers in the architecture.\n",
    "        data = data.view(1,melspectrogram.shape[0],-1) \n",
    "        datadict[split]=torch.tensor(np.concatenate((datadict[split],data),axis=0))\n",
    "        labeldict[split].append(label)\n",
    "train_data = datadict['TRAIN'][1:]\n",
    "test_data = datadict['TEST'][1:]\n",
    "val_data = datadict['DEV'][1:]\n",
    "train_y = labeldict['TRAIN'] \n",
    "test_y = labeldict['TEST']\n",
    "val_y = labeldict['DEV']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 546,
   "id": "b8ea0a48",
   "metadata": {},
   "outputs": [],
   "source": [
    "## same as the one for cnn architecture\n",
    "custom_train_dataset = customDataset(train_data, train_y)\n",
    "custom_train_loader = customDataLoader(custom_train_dataset, batch_size=32)\n",
    "traindl = custom_train_loader.loader()\n",
    "\n",
    "custom_test_dataset = customDataset(test_data, test_y)\n",
    "custom_test_loader = customDataLoader(custom_test_dataset, batch_size=503)\n",
    "testdl = custom_test_loader.loader()\n",
    "\n",
    "custom_val_dataset = customDataset(val_data, val_y)\n",
    "custom_val_loader = customDataLoader(custom_val_dataset, batch_size=32)\n",
    "valdl = custom_val_loader.loader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 551,
   "id": "aab5a1d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "downsample(\n",
       "  (conv_layers): Sequential(\n",
       "    (0): Conv1d(13, 26, kernel_size=(3,), stride=(1,), padding=same, bias=False)\n",
       "    (1): Dropout(p=0.2, inplace=False)\n",
       "    (2): Conv1d(26, 26, kernel_size=(3,), stride=(1,), padding=same, bias=False)\n",
       "    (3): Dropout(p=0.2, inplace=False)\n",
       "    (4): BatchNorm1d(26, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): ReLU()\n",
       "    (6): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (7): Conv1d(26, 52, kernel_size=(3,), stride=(1,), padding=same, bias=False)\n",
       "    (8): Dropout(p=0.2, inplace=False)\n",
       "    (9): Conv1d(52, 52, kernel_size=(3,), stride=(1,), padding=same, bias=False)\n",
       "    (10): Dropout(p=0.2, inplace=False)\n",
       "    (11): BatchNorm1d(52, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (12): ReLU()\n",
       "    (13): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (14): Conv1d(52, 104, kernel_size=(3,), stride=(1,), padding=same, bias=False)\n",
       "    (15): Dropout(p=0.2, inplace=False)\n",
       "    (16): Conv1d(104, 104, kernel_size=(3,), stride=(1,), padding=same, bias=False)\n",
       "    (17): Dropout(p=0.2, inplace=False)\n",
       "    (18): BatchNorm1d(104, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (19): ReLU()\n",
       "    (20): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (21): Conv1d(104, 104, kernel_size=(3,), stride=(1,), padding=same, bias=False)\n",
       "    (22): Dropout(p=0.2, inplace=False)\n",
       "    (23): Conv1d(104, 52, kernel_size=(3,), stride=(1,), padding=same, bias=False)\n",
       "    (24): Dropout(p=0.2, inplace=False)\n",
       "    (25): BatchNorm1d(52, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (26): ReLU()\n",
       "    (27): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (28): Conv1d(52, 52, kernel_size=(3,), stride=(1,), padding=same, bias=False)\n",
       "    (29): Dropout(p=0.2, inplace=False)\n",
       "    (30): Conv1d(52, 26, kernel_size=(3,), stride=(1,), padding=same, bias=False)\n",
       "    (31): Dropout(p=0.2, inplace=False)\n",
       "    (32): BatchNorm1d(26, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (33): ReLU()\n",
       "    (34): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (35): Conv1d(26, 26, kernel_size=(3,), stride=(1,), padding=same, bias=False)\n",
       "    (36): Dropout(p=0.2, inplace=False)\n",
       "    (37): Conv1d(26, 26, kernel_size=(3,), stride=(1,), padding=same, bias=False)\n",
       "    (38): Dropout(p=0.2, inplace=False)\n",
       "    (39): BatchNorm1d(26, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (40): ReLU()\n",
       "    (41): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (42): Flatten(start_dim=1, end_dim=-1)\n",
       "    (43): Linear(in_features=104, out_features=256, bias=True)\n",
       "    (44): ReLU()\n",
       "    (45): Linear(in_features=256, out_features=128, bias=True)\n",
       "  )\n",
       "  (fc_layers): Sequential(\n",
       "    (0): Linear(in_features=128, out_features=350, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=350, out_features=10, bias=True)\n",
       "    (3): Softmax(dim=1)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 551,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#creating the network for the downsample task\n",
    "downmodel=downsample(cnn)\n",
    "downmodel.to('cuda')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 552,
   "id": "f0648303",
   "metadata": {},
   "outputs": [],
   "source": [
    "lossdown=[]\n",
    "pardown=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 553,
   "id": "0829237d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of parameters: 237786\n"
     ]
    }
   ],
   "source": [
    "total_params = sum(p.numel() for p in downmodel.parameters())\n",
    "print(\"Total number of parameters:\", total_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7802313",
   "metadata": {},
   "source": [
    "The same hyperparameters are used that are obtained from the CNN based architecture in task 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 554,
   "id": "d5b10114",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0 loss: 1.6290206909179688 grad: 0.5567023538995504\n",
      "epoch: 1 loss: 1.5570411682128906 grad: 0.08987300841666486\n",
      "epoch: 2 loss: 1.4683914184570312 grad: 0.11508636128723135\n",
      "epoch: 3 loss: 1.4616585969924927 grad: 0.02141493692623239\n",
      "epoch: 4 loss: 1.4624667167663574 grad: 0.04217420989926727\n",
      "epoch: 5 loss: 1.4619059562683105 grad: 0.020649170101511787\n",
      "epoch: 6 loss: 1.4630279541015625 grad: 0.04145168013504223\n",
      "epoch: 7 loss: 1.4628103971481323 grad: 0.021264579339886257\n",
      "epoch: 8 loss: 1.461591124534607 grad: 0.024334570534639614\n",
      "epoch: 9 loss: 1.462347149848938 grad: 0.06738515776248596\n",
      "epoch: 10 loss: 1.4614243507385254 grad: 0.01690831811324093\n",
      "epoch: 11 loss: 1.46139395236969 grad: 0.017663857418671967\n",
      "epoch: 12 loss: 1.4617739915847778 grad: 0.015056364516263092\n",
      "epoch: 13 loss: 1.4611663818359375 grad: 0.0010203646813270726\n",
      "epoch: 14 loss: 1.4635556936264038 grad: 0.015881893945867462\n",
      "epoch: 15 loss: 1.4625413417816162 grad: 0.014439145118542102\n",
      "epoch: 16 loss: 1.4617984294891357 grad: 0.009376583873204045\n",
      "epoch: 17 loss: 1.461374044418335 grad: 0.023960725847833184\n",
      "epoch: 18 loss: 1.461390733718872 grad: 0.0190634258425297\n",
      "epoch: 19 loss: 1.46159029006958 grad: 0.02603531379576424\n",
      "epoch: 20 loss: 1.4617549180984497 grad: 0.007170046812775941\n",
      "epoch: 21 loss: 1.4614064693450928 grad: 0.01617137960306935\n",
      "epoch: 22 loss: 1.4625012874603271 grad: 0.06041885734998902\n",
      "epoch: 23 loss: 1.4619930982589722 grad: 0.04176498149178414\n",
      "epoch: 24 loss: 1.4623022079467773 grad: 0.011490631927020312\n",
      "epoch: 25 loss: 1.4617441892623901 grad: 0.012039325420722462\n",
      "epoch: 26 loss: 1.4616338014602661 grad: 0.007624063221077356\n",
      "epoch: 27 loss: 1.4616559743881226 grad: 0.0009724891407032293\n",
      "epoch: 28 loss: 1.461789846420288 grad: 0.03255316026115333\n",
      "epoch: 29 loss: 1.4622465372085571 grad: 0.06570517565812452\n",
      "epoch: 30 loss: 1.4611729383468628 grad: 0.0019616514238106177\n",
      "epoch: 31 loss: 1.4625180959701538 grad: 0.05977293558540863\n",
      "epoch: 32 loss: 1.4636417627334595 grad: 0.0010935762130088328\n",
      "epoch: 33 loss: 1.461258888244629 grad: 0.018847139018362154\n",
      "epoch: 34 loss: 1.4617356061935425 grad: 0.019611405815025584\n",
      "epoch: 35 loss: 1.4611573219299316 grad: 0.0008204705980015076\n",
      "epoch: 36 loss: 1.4616539478302002 grad: 0.0014599815295252396\n",
      "epoch: 37 loss: 1.461670160293579 grad: 0.0017762601434126325\n",
      "epoch: 38 loss: 1.4611856937408447 grad: 0.003268350898628843\n",
      "epoch: 39 loss: 1.4611517190933228 grad: 5.8387057350884074e-05\n",
      "epoch: 40 loss: 1.461431622505188 grad: 0.019742321570557737\n",
      "epoch: 41 loss: 1.4611562490463257 grad: 0.0004729154949320877\n",
      "epoch: 42 loss: 1.46234130859375 grad: 0.05528013897546666\n",
      "epoch: 43 loss: 1.4619224071502686 grad: 0.025300851388019532\n",
      "epoch: 44 loss: 1.4617732763290405 grad: 0.08427434060095622\n",
      "epoch: 45 loss: 1.4612423181533813 grad: 0.005704685971643984\n",
      "epoch: 46 loss: 1.4624707698822021 grad: 0.046770280193227515\n",
      "epoch: 47 loss: 1.461655855178833 grad: 0.001638832509907968\n",
      "epoch: 48 loss: 1.461165428161621 grad: 0.0037409204269224527\n",
      "epoch: 49 loss: 1.4611520767211914 grad: 9.208593241494419e-05\n",
      "epoch: 50 loss: 1.4612153768539429 grad: 0.02427146134947907\n",
      "epoch: 51 loss: 1.4626346826553345 grad: 0.007020789978890147\n",
      "epoch: 52 loss: 1.4611635208129883 grad: 0.003076000320849836\n",
      "epoch: 53 loss: 1.4616492986679077 grad: 0.0002044336206815131\n",
      "epoch: 54 loss: 1.461661458015442 grad: 0.003702212290349816\n",
      "epoch: 55 loss: 1.4616529941558838 grad: 0.002444351847621356\n",
      "epoch: 56 loss: 1.4616624116897583 grad: 0.001486981454420175\n",
      "epoch: 57 loss: 1.4625414609909058 grad: 0.09006087248144054\n",
      "epoch: 58 loss: 1.4616771936416626 grad: 0.0034793288758669396\n",
      "epoch: 59 loss: 1.462276577949524 grad: 0.025920858414943963\n",
      "epoch: 60 loss: 1.4632138013839722 grad: 0.03130002715137949\n",
      "epoch: 61 loss: 1.4611517190933228 grad: 7.276643616881598e-05\n",
      "epoch: 62 loss: 1.4611527919769287 grad: 0.0002674820777351614\n",
      "epoch: 63 loss: 1.4613324403762817 grad: 0.01139988758668781\n",
      "epoch: 64 loss: 1.4621437788009644 grad: 0.0002121434658894477\n",
      "epoch: 65 loss: 1.4616540670394897 grad: 0.001332833461561576\n",
      "epoch: 66 loss: 1.4616488218307495 grad: 0.0002840651912039633\n",
      "epoch: 67 loss: 1.4618338346481323 grad: 0.07285576814461603\n",
      "epoch: 68 loss: 1.461748480796814 grad: 0.03777913533875971\n",
      "epoch: 69 loss: 1.4616724252700806 grad: 0.005878813246087911\n",
      "epoch: 70 loss: 1.4611519575119019 grad: 0.00012705297737934668\n",
      "epoch: 71 loss: 1.4622673988342285 grad: 0.01487356180550298\n",
      "epoch: 72 loss: 1.4623830318450928 grad: 0.10474091242315628\n",
      "epoch: 73 loss: 1.461654782295227 grad: 0.0032715419604399934\n",
      "epoch: 74 loss: 1.4621433019638062 grad: 2.276687115021678e-05\n",
      "epoch: 75 loss: 1.4621367454528809 grad: 0.001780261083162454\n",
      "epoch: 76 loss: 1.4611761569976807 grad: 0.00921097383795091\n",
      "epoch: 77 loss: 1.461151361465454 grad: 8.527917476630511e-05\n",
      "epoch: 78 loss: 1.46176016330719 grad: 0.018436128718688015\n",
      "epoch: 79 loss: 1.461155891418457 grad: 0.000981147321049221\n",
      "epoch: 80 loss: 1.4614460468292236 grad: 0.05849956408444326\n",
      "epoch: 81 loss: 1.461670160293579 grad: 0.00674342953120317\n",
      "epoch: 82 loss: 1.461855411529541 grad: 0.02515445364048569\n",
      "epoch: 83 loss: 1.4611918926239014 grad: 0.015536202123184668\n",
      "epoch: 84 loss: 1.4618934392929077 grad: 0.035765192459937735\n",
      "epoch: 85 loss: 1.4618089199066162 grad: 0.05086425334914501\n",
      "epoch: 86 loss: 1.461647629737854 grad: 7.228692347159408e-05\n",
      "epoch: 87 loss: 1.4621403217315674 grad: 0.001528265554090464\n",
      "epoch: 88 loss: 1.4621987342834473 grad: 0.07811072057583805\n",
      "epoch: 89 loss: 1.4616392850875854 grad: 0.002261000373124634\n",
      "epoch: 90 loss: 1.4611557722091675 grad: 0.0004450294733704954\n",
      "epoch: 91 loss: 1.4616491794586182 grad: 0.00045496764349685907\n",
      "epoch: 92 loss: 1.462146282196045 grad: 0.00024358780422320794\n",
      "epoch: 93 loss: 1.4611703157424927 grad: 0.0043340896996322455\n",
      "epoch: 94 loss: 1.4626113176345825 grad: 0.022759985549238596\n",
      "epoch: 95 loss: 1.4611796140670776 grad: 0.005479115583891815\n",
      "epoch: 96 loss: 1.4621431827545166 grad: 8.66658281872793e-06\n",
      "epoch: 97 loss: 1.4611514806747437 grad: 4.8518263212768244e-05\n",
      "epoch: 98 loss: 1.4616472721099854 grad: 3.0519462295947804e-05\n",
      "epoch: 99 loss: 1.4617631435394287 grad: 0.053984011543737845\n",
      "1.5219362005591393\n",
      "1.5219362005591393\n"
     ]
    }
   ],
   "source": [
    "loss5,par5=downmodel.train(traindl,epochs = 100,learning_rate=0.001,lam=la,opti=optim) #100-0.01 #500-0.005 #500 - 0.001 #500 - 0.0001 #500 0.00005\n",
    "lossdown+=loss5\n",
    "pardown+=par5\n",
    "print(test(downmodel,valdl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 555,
   "id": "8e2f0a64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x504 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot(lossdown,pardown)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 556,
   "id": "dee0834b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T-SNE plot on the testing dataset: \n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"T-SNE plot on the testing dataset: \")\n",
    "tsne_map(testdl,downmodel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 557,
   "id": "338388d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy:\n",
      "99.80000257492065 %\n",
      "validation accuracy:\n",
      "93.36015582084656 %\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9336015582084656"
      ]
     },
     "execution_count": 557,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Training accuracy:\")\n",
    "get_accuracy(traindl,downmodel)\n",
    "print(\"validation accuracy:\")\n",
    "get_accuracy(valdl,downmodel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 558,
   "id": "fac17299",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss on test:\n",
      "1.5068379640579224\n",
      "Training accuracy:\n",
      "99.9500036239624 %\n",
      "Test accuracy:\n",
      "94.43339705467224 %\n",
      "Training f1 score:\n",
      "F1 score: 0.031484375\n",
      "Test f1 score:\n",
      "F1 score: 0.0018813560307618402\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9463220834732056"
      ]
     },
     "execution_count": 558,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Loss on test:\")\n",
    "test(downmodel,testdl)\n",
    "print(\"Training accuracy:\")\n",
    "get_accuracy(traindl,downmodel)\n",
    "print(\"Test accuracy:\")\n",
    "get_accuracy(testdl,downmodel)\n",
    "print(\"Training f1 score:\")\n",
    "get_f1(traindl,downmodel)\n",
    "print(\"Test f1 score:\")\n",
    "get_f1(testdl,downmodel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 620,
   "id": "efd0decd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confusion matrix on the test dataset:\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x720 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"confusion matrix on the test dataset:\")\n",
    "confusionplot(testdl,downmodel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 621,
   "id": "7772a6e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The Classification Report for test set classification\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.96      0.94        53\n",
      "           1       0.98      0.98      0.98        55\n",
      "           2       0.98      1.00      0.99        54\n",
      "           3       0.98      0.91      0.94        46\n",
      "           4       1.00      0.80      0.89        46\n",
      "           5       0.98      1.00      0.99        50\n",
      "           6       0.96      0.93      0.95        46\n",
      "           7       0.90      1.00      0.95        47\n",
      "           8       0.97      1.00      0.98        56\n",
      "           9       0.94      0.98      0.96        50\n",
      "\n",
      "    accuracy                           0.96       503\n",
      "   macro avg       0.96      0.96      0.96       503\n",
      "weighted avg       0.96      0.96      0.96       503\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nThe Classification Report for test set classification\\n\")\n",
    "classificationReport(testdl,downmodel)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2760b6e",
   "metadata": {},
   "source": [
    "## References:\n",
    "[1]Y. Sunaga, R. Natsuaki and A. Hirose, \"Similar343\n",
    "land-form discovery: Complex absolute-value max344\n",
    "pooling in complex-valued convolutional neural net-345\n",
    "works in interferometric synthetic aperture radar,\"346\n",
    "2020 International Joint Conference on Neural Net-347\n",
    "works (IJCNN), Glasgow, UK, 2020, pp. 1-7, doi:348\n",
    "10.1109/IJCNN48605.2020.9207122\n",
    "\n",
    "[2]Zou, H., & Hastie, T. (2005). Regularization and Variable Selection via the Elastic Net. Journal of the Royal Statistical Society. Series B (Statistical Methodology), 67(2), 301-320. https://doi.org/10.2307/3647580\n",
    "\n",
    "[3]Lei Huang, Jie Qin, Yi Zhou, Fan Zhu, Li Liu,360\n",
    "and Ling Shao. Normalization Techniques in Train-361\n",
    "ing DNNs: Methodology, Analysis and Application.362\n",
    "arXiv preprint arXiv:2106.05345, 2021\n",
    "\n",
    "[4] https://towardsdatascience.com/translational-invariance-vs-translational-equivariance-f9fbc8fca63a\n",
    "\n",
    "[5] Sepp Hochreiter and JÃ¼rgen Schmidhuber. Long367\n",
    "short-term memory. Neural Computation, 9(8):1735â€“368\n",
    "1780, November 1997. ISSN 0899-7667.369\n",
    "10.1162/neco.1997.9.8.1735. URL https://doi.370\n",
    "org/10.1162/neco.1997.9.8.1735.3715\n",
    "\n",
    "[6]Junyoung Chung, Ã‡aglar GÃ¼lÃ§ehre, KyungHyun Cho,362\n",
    "and Yoshua Bengio. Empirical Evaluation of Gated363\n",
    "Recurrent Neural Networks on Sequence Modeling.364\n",
    "CoRR, abs/1412.3555, 2014. http://arxiv.org/365\n",
    "abs/1412.3555\n",
    "[7]https://gist.github.com/dimartinot/80abaabaea9a6ef3d9ab0ab199927ee4#file-contrastive_loss-py\n",
    "\n",
    "[8]Mohsenzadeh, Y. (2020). CLAR: Contrastive350\n",
    "Learning of Auditory Representations. ArXiv.351\n",
    "/abs/2010.09542\n",
    "\n",
    "[9]Gregory Koch, Richard Zemel, Ruslan Salakhutdi-378\n",
    "nov. Siamese Neural Networks for One-shot Image379\n",
    "Recognition\n",
    "\n",
    "[10]van der Maaten, Laurens and Hinton, Geoffrey. Visu-372\n",
    "alizing Data using t-SNE. Journal of Machine Learn-373\n",
    "ing Research 2008"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73406878",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
